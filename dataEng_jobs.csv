title,company,location,link,job_description
Data Lake - Data Engineer 1,"Hy-Vee, Inc.","Remote in West Des Moines, IA+1 location",https://www.indeed.com/rc/clk?jk=405228706fc3b28e&fccid=6837147f8d33dcd7&vjs=3,"At Hy-Vee our people are our strength. We promise “a helpful smile in every aisle” and those smiles can only come from a workforce that is fully engaged and committed to supporting our customers and each other. Job Description: Job Title: Data Engineer 1 Department: Information Technology FLSA : Exempt General Function An entry level professional who assists in development, implementation, and support of data pipelines for a specific area with strong mentorship and guidance. Core Competencies Partnerships Growth mindset Results oriented Customer focused Professionalism Reporting Relations Accountable and Reports to: TBD Positions that Report to you: TBD Primary Duties and Responsibilities Design, Create and maintain on premise and cloud based data integration pipelines. Assemble large, complex data sets that meet functional/non functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources. Build analytics tools that utilize the data pipeline to provide actionable insights into key business performance metrics. Research and work on data-related technical issues and support tickets. Create data pipelines to enable BI, Analytics and Data Science teams that assist them in building and optimizing their systems Knowledge, Skills, Abilities, and Worker Characteristics Basic Understanding of Database Programming Language (T-SQL, SQL, PLSQL, etc.) Basic understanding of RDMS systems Basic understanding of ETL Tools Experience and Education Bachelor degree preferred, or relevant experience. Supervisory Responsibilities (Direct Reports) None Physical Requirements Visual requirements include: ability to see detail at near range with or without correction. Must be physically able to perform sedentary work: operating a computer, occasionally lifting or carrying objects of no more than 10 pounds, and occasionally standing or walking. Must be able to perform the following physical activities: meeting with customers, kneeling, reaching, handling, grasping, feeling, talking, hearing, and repetitive motions. Working Conditions The duties for this position are performed in a general or remote office setting. There is weekly pressure to meet deadlines and handle multiple tasks in a day. Equipment Used to Perform Job Laptop and desktop computer, telephone, copier, Fax, printer, PC with Microsoft Office programs and other software relevant to specific position. Financial Responsibility None Contacts Has frequent contact with office personnel in other departments related to the position as well as occasional contact with users and customers. Confidentiality Has access to confidential information. Are you ready to smile, apply today."
Data Engineer,Abbott Laboratories,"Chicago, IL+1 location",https://www.indeed.com/rc/clk?jk=7fcdadbbd3418a62&fccid=77426fa86bb11d7c&vjs=3,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 113,000 colleagues serve people in more than 160 countries. Our location in Chicago, IL currently has an opportunity for an entry leve Data Engineer. This would be a role in the newly formed Big Data Advanced Analytics group of the organization. This role will assist in development of data platforms, business solutions, and proof of concept to assist the big data team in realizing business goals WHAT YOU’LL DO Demonstrate high degree of analytic agility to meet fluid and dynamic business needs Use data engineering techniques to design and build solutions/ products for analyzing large data sets and identify patterns and relationships Create, deploy and optimize large scale data Assist in rapid development of new data and analytics prototypes Explore data sources to better understand the availability and quality of data. Document available data sources and how they are being transformed. Embrace an environment that supports innovation and process improvement Manage data sources, organize data and create data assets using identified open source or proprietary tools Work closely with SMEs, functional experts in Commercial, R&D, finance, etc. for building data pipeline from structure and unstructured data sources Work on newest tools and technologies to achieve results - Scala, Scalding, Spark, Hadoop EDUCATION AND EXPERIENCE YOU’LL BRING Required Bachelor’s degree in any of the following – Physics, Computer Science, Statistics, Quantitative Sciences (preferred) 1+ years of experience Strong problem-solving skills Experience in data analytics solution components from AWS and Microsoft Azure. Preferred Scala and Spark experience Experience with Python, and/or R will be a plus Ability and desire to learn new software languages and technologies Attention to detail and organization/ documentation skills Ability to prioritize and triage deadline-driven tasks in a high-pressure environment Experience manipulating and analyzing complex, high-volume data from varying sources Ability to communicate complex quantitative analysis in a clear, precise, actionable manner WHAT WE OFFER At Abbott, you can have a good job that can grow into a great career. We offer: Training and career development, with onboarding programs for new employees and tuition assistance Financial security through competitive compensation, incentives and retirement plans Health care and well-being programs including medical, dental, vision, wellness and occupational health programs Paid time off 401(k) retirement savings with a generous company match The stability of a company with a record of strong financial performance and history of being actively involved in local communities Learn more about our benefits that add real value to your life to help you live fully: www.abbottbenefits.com Follow your career aspirations to Abbott for diverse opportunities with a company that provides the growth and strength to build your future. Abbott is an Equal Opportunity Employer, committed to employee diversity. Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal."
Data Engineer,Farmers Insurance Group,Remote,https://www.indeed.com/rc/clk?jk=a6adae584983c7ee&fccid=77a32bcb59e7f031&vjs=3,"We are Farmers! We are… more than just your favorite commercials. We are a passionate, award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn’t just our business – it’s our culture! We are Farmers! Do you thrive in a high-volume, fast-paced environment? Do you enjoy the challenge of a position where no two days are alike? We are looking for positive, high-energy professionals who are not just looking for a job, but a meaningful career! Job Summary Provides expertise in the design and functionality of business applications; Creates and validates the detailed technical designs to ensure alignment with business requirements; Develops and performs quality checks on project deliverables; Creates and validates estimates for new application functionality; Performs impact analysis of application changes across various components, holding an end-to-end view of the system; Specifies integration and testing criteria; Supports the implementation activities as well as troubleshoots application/system/environmental issues, as required. Preferred Skills Work within structure of SAFe Agile team on the successful delivery of Business Intelligence projects, enhancements, and defects. Independently lead and deliver new projects and enhancements. Collaborate with Agile team members to understand functional and technical requirements. Prepare estimates based on high-level requirements and assumptions. Translate functional requirements into technical specifications for ETL development; develop source-to-target mappings and actively manage Development, Unit Testing and Implementation efforts. Troubleshoot production defects, perform root cause analysis and provide guidance to team on the fixes. 1 year experience in developing business data systems – (Use of Microsoft SQL Server preferred) Experience with Python and semi-structured data manipulation is a plus. Experience working in an Agile Environment is a plus. Understanding of business practices, processes, and methodologies. Highly committed, motivated, enthusiastic and a natural team player. Good interpersonal and communication skills (both verbal and written) and ability to interact with and effectively address concerns. Good prioritization, time management, analytical, and organization skills. Essential Job Functions Use MS SQL Server databases to create new business functionalities as well to solve business problems: Respond to new requests for reports/data understanding business objectives and processes; review and refine technical requirements/User Stories; and communicate estimated hours and timeline to complete; Extract data directly from relational databases (e.g. SQL Server, DB2, Oracle), data warehouses, or other data stores using SQL; Ability to create manual as well as automated data exports/reports; and Support application unit testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. Work productively on assigned tasks; Collaborate effectively with other team members; Demonstrate accountability to management and business for hours spent on assigned tasks; and diligently strive to deliver value. Physical Actions Essentially sedentary work consisting of occasional walking, standing, and lifting/carrying 10 lbs. maximum Functional ability of seeing, hearing and speaking Ability to type proficiently Physical Environment Work in a climate-controlled office, with occasional travel by car or airplane. Education Requirements High school diploma or equivalent required. Bachelor’s degree preferred, in Information Systems or related field. Experience Requirements Experience with data extraction, manipulation and presentation in usable format. Special Skill Requirement Experience with Python and cloud technologies is a plus. Benefits Farmers offers a competitive salary commensurate with experience, qualifications and location CO Only: The pay range for this job being performed in Colorado would be $64,100-85,500 Bonus Opportunity (based on Company and Individual Performance) 401(k) Medical Dental Vision Health Savings and Flexible Spending Accounts Life Insurance Paid Time Off Paid Parental Leave Tuition Assistance Job Location(s): US - RW - Remote Work - Farmers"
"Data Engineer (Open to remote work, except the following loc...",Nike,"Remote in Atlanta, GA+8 locations",https://www.indeed.com/rc/clk?jk=3843153749cd57a6&fccid=2c62e4de04b8f952&vjs=3,"Become a Part of the NIKE, Inc. Team NIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game. NIKE is a technology company. From our flagship website and five-star mobile apps to developing products, managing big data and providing leading edge engineering and systems support, our teams at NIKE Global Technology exist to revolutionize the future at the confluence of tech and sport. We invest and develop advances in technology and employ the most creative people in the world, and then give them the support to constantly innovate, iterate and serve consumers more directly and personally. Our teams are innovative, diverse, multidisciplinary and collaborative, taking technology into the future and bringing the world with it. Who we are: Our Enterprise Data & Analytics team is a capability-driven organization that connects an end-to-end view of data & analytics across Nike, Inc. We deliver consistent, trusted, and available data products, integration, and analytics capabilities that drive informed and efficient decisions fueling growth by serving athletes* personally at scale. Who we are looking for: We are looking for Data Engineers with a history of developing complex data solutions and experience working on end-to-end solution design. You are a passionate, data evangelist who loves finding relationships between disparate data sets and clarity in a muddied data environment and are continually learning as well as finding opportunities to share knowledge with others. You will be part of an organization focusing on the development and delivery of data solutions and capabilities for Nike’s data platforms. We look for motivated, curious individuals who thrive in collaborative and innovative settings, have aptitude and communication skills to navigate dynamic environments and are willing to fail forward! What you bring: Bachelor’s Degree in Information Technology, Information Security/Assurance, Computer Science, Engineering, or related field of study, or any combination of relevant equivalent experience, education and training. 0-3 years of experience in the industry Demonstrated a conceptual understanding in cloud environments such as Microsoft Azure, Google Cloud, AWS, MPP, Big Data and NoSQL technologies like Hadoop, Spark, Impala, Hive, MongoDB, HBase or Cassandra Demonstrated proficiency in Python and SQL Open to remote work, except cannot work in South Dakota, Vermont, and West Virginia. These candidates will be required to relocate. For employees based in Colorado, this position starts at $83,000 per year. Information about benefits can be found here. Nike requires all applicants for this position to be vaccinated for COVID-19 as a condition of hire, unless otherwise required by law. As an equal opportunity employer, Nike will make accommodations to individuals who cannot be vaccinated in accordance with applicable law. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world. NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability."
Data Engineer entry level,Fisker Inc,"Manhattan Beach, CA 90266",https://www.indeed.com/rc/clk?jk=b25a9682949f26e1&fccid=38c354bb9b09f488&vjs=3,"About Fisker Inc. California-based Fisker Inc. is revolutionizing the automotive industry by developing the most emotionally desirable and eco-friendly electric vehicles on Earth. Passionately driven by a vision of a clean future for all, the company is on a mission to become the No. 1 e-mobility service provider with the world’s most sustainable vehicles. To learn more, visit www.FiskerInc.com – and enjoy exclusive content across Fisker’s social media channels: Facebook , Instagram , Twitter , YouTube and LinkedIn . Download the revolutionary new Fisker mobile app from the App Store or Google Play store. Job Responsibilities Be part of a team solving data and machine learning problems that constantly advance the state-of-the-art for electric vehicles. Work with software engineers, devops, ML engineers, and data scientists. Help in the development of data and training pipelines for supporting ML infrastructure. Build large scale training and inference pipelines Build metrics, dashboards to measure both ML and system performance Job Qualifications BS or Master’s Degree in Computer Science, Statistics or related field. Strong coding skills in Python, C/C++, or Go. Familiarity with large-scale data processing and distributed systems such as Hadoop, Kafka. Understanding of relational and columnar databases, SQL and data models. Mathematical knowledge; understanding of machine learning, statistics Expertise in crafting Data Models for high performance and scalability Preferred Experience working with IoT sensor data, ideally automotive. Experience with applied data analytics and predictive modelling Experience in distributed training and model deployment Related course work or experience with vehicle systems: Battery, powertrain, embedded, etc. Experience framework such as Airflow, MLflow, Kubeflow, etc Fisker Inc. is an Equal Opportunity Employer; employment at Fisker Inc. is governed based on merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status. Applicants wishing to view a copy of Fisker Inc.’s Affirmative Action Plan for veterans and individuals with disabilities, or applicants requiring reasonable accommodation to the application/interview process should notify the Human Resources Department"
Data Engineer,"Gametime United, Inc.",Remote,https://www.indeed.com/company/Gametime/jobs/Data-Engineer-0d0b58bccab981a1?fccid=e532a19a6be3c2bc&vjs=3,"About us: Live experiences help make us human, bringing us across today’s social and digital divides to focus on what truly connects us - the here, the now, the once-in-a-lifetime moment that we share - together. To fulfill Gametime’s vision to unite the world through shared experiences, we deliver fans an extraordinary experience for enjoying, discovering, and purchasing last-minute tickets to live events. With platforms on iOS, Android, mobile web, and desktop supporting events across the US and Canada, we are reimagining the event ticket experience in a mobile-first world. *The Role: *We are looking for an organized, data-driven, and curious team player to work cross-functionally across the data, product, marketing, finance, and operations teams. As a Data Engineer, you will support and inform various functions throughout the company to solve business-critical issues, specifically related to our product, features, etc. You will develop new ETL processes and deploy new technologies into the ecosystem. The ideal candidate will be able to thrive in a fast-paced environment and able to adapt to changes within the business and the industry. What you'll do/own: Develop data pipelines and infrastructure that is fast, reliable, and accurate Create ingest processes for new data sources Maintain and develop data alerting infrastructure to quickly respond to and fix production issues Influence and build relationships with people across all levels of the organization, internally and externally Our ideal candidate has: 1-3+ years of Data Engineer experience, ideally at a technology company Proficient in SQL Experience with a programming language (Python a plus) Ability to identify, analyze, and provide recommendations to complex business understanding of database concepts and architecture Ability to work across disparate data sources to obtain sensible results Strong collaboration and communication skills Experience analyzing user-centric products, preferably in the gaming or marketplace industries Strong problem-solving skills Some experience with Python or R Experience with a data visualization software What we can offer you: Flexible PTO Medical, dental, & vision insurance Life insurance and disability benefits 401K, HSA, pre-tax savings programs New equipment setup provided Wellness programs Tenure recognition Gametime is committed to bringing together individuals from different backgrounds and perspectives. We strive to create an inclusive environment where everyone can thrive, feel a sense of belonging, and do great work together. As an equal opportunity employer, we prohibit any unlawful discrimination against a job applicant on the basis of their race, color, religion, veteran status, sex, parental status, gender identity or expression, transgender status, sexual orientation, national origin, age, disability or genetic information. We respect the laws enforced by the EEOC and are dedicated to going above and beyond in fostering diversity across our company. Job Type: Full-time"
Data Engineer,O'Reilly Media,Remote,https://www.indeed.com/rc/clk?jk=464d0e0ec778fa77&fccid=f6b4585215cfe949&vjs=3,"About Your Team Our data engineering team has a strong focus on delivering high-quality, reliable data to platforms and people within O’Reilly as well as building high-performance, scalable and extensible systems. We are intentional in our search for teammates who are helpful, respectful, communicate openly, and are always willing to do what’s best for our users. We keep a close eye on our pipelines and processes to make sure we’re delivering useful, timely improvements to aid decision-making and data visualization within O’Reilly. The team is broadly distributed across the US in multiple cities and timezones and constantly encourages each other to deliver work that instills pride and fulfillment. About the Job We are looking for a thoughtful and experienced data engineer to help grow a suite of systems and tools written primarily in Python. The ideal candidate will have a deep understanding of modern data engineering concepts and will have shipped or supported code and infrastructure with a user base in the millions and datasets with billions of records. The candidate will be routinely implementing features, fixing bugs, performing maintenance, consulting with product managers, and troubleshooting problems. Changes you make will be accompanied by tests to confirm desired behavior. Code reviews, in the form of pull requests reviewed by peers, are a regular and expected part of the job as well. Job Details In a normal week, you might: Develop a new feature from a user story using Python and PostgreSQL or BigQuery Collaborate with product managers to define clear requirements, deliverables, and milestones Team up with other groups within O’Reilly (e.g. data science or machine learning) to leverage experience and consult on data engineering best practices Review a pull request from a coworker and pair on a tricky problem Provide a consistent and reliable estimate to assess risk for a project manager Learn about a new technology or paper and present it to the team Identify opportunities to improve our pipelines through research and proof-of-concepts Help QA and troubleshoot a pesky production problem Participate in agile process and scrum ceremonies Why you'll love working on our team: You'll be working for a company that embraces and pursues new technology You'll be working with a company that trusts and engages its employees We believe in giving engineers the tools and hardware that they need to do their job Bi-weekly virtual team hangouts and space to learn new skills (we’re a learning company after all!) Great company benefits (health/dental/vision insurance, 401k, etc.) We care deeply about work-life balance and treat everyone like human beings first About You What we like to see for anyone joining our data engineering teams: Proficiency in building highly scalable ETL and streaming-based data pipelines using Google Cloud Platform services and products Proficiency in large scale data platforms and data processing systems such as Google BigQuery and Amazon Redshift Excellent Python and PostgreSQL development and debugging skills Experience building systems to retrieve and aggregate data from event-driven messaging frameworks (e.g. RabbitMQ and Pub/Sub) Strong drive to experiment, learn and improve your skills Respect for the craft—you write self-documenting code with modern techniques Great written communication skills—we do a lot of work asynchronously in Slack and Google Docs Empathy for our users—a willingness to spend time understanding their needs and difficulties is central to the team Desire to be part of a compact, fun, and hard-working team Not required, but for bonus points: Experience with Google Cloud Dataflow/Apache Beam Experience with Django RESTful endpoints Experience working in a distributed team Knowledge and experience with machine learning pipelines Contributions to open source projects Knack for benchmarking and optimization Minimum Qualifications 2+ years of professional data engineering (or equivalent) experience 1+ year experience of working in an agile environment About O’Reilly Media O’Reilly’s mission is to change the world by sharing the knowledge of innovators. For over 40 years, we’ve inspired companies and individuals to do new things—and do things better—by providing them with the skills and understanding that’s necessary for success. At the heart of our business is a unique network of experts and innovators who share their knowledge through us. O’Reilly Learning offers exclusive live training, interactive learning, a certification experience, books, videos, and more, making it easier for our customers to develop the expertise they need to get ahead. And our books have been heralded for decades as the definitive place to learn about the technologies that are shaping the future. Everything we do is to help professionals from a variety of fields learn best practices and discover emerging trends that will shape the future of the tech industry. Our customers are hungry to build the innovations that propel the world forward. And we help you do just that. Learn more: https://www.oreilly.com/about/ Diversity At O’Reilly, we believe that true innovation depends on hearing from, and listening to, people with a variety of perspectives. We want our whole organization to recognize, include, and encourage people of all races, ethnicities, genders, ages, abilities, religions, sexual orientations, and professional roles. Learn more: https://www.oreilly.com/diversity"
Claims Data Engineer (Remote),HealthFirst,+50 locationsRemote,https://www.indeed.com/rc/clk?jk=6c7dcb78eecce291&fccid=33b2d0072564c18e&vjs=3,"The Claims Data Engineer is responsible for data acquisition strategies and integration scripting and tools, data migrations, conversions, purging and back-ups; fulfills data acquisition strategy requirements. They work with product, financial control, analysts, users and other stakeholders to understand business requirements and supports data architecture to translate into data acquisition strategies. The Claims Data Engineer will author artifacts defining standards and definitions for storing, processing and moving data, including associated processes and business rules. Additionally, the Claims Data Engineer will map the details within these their artifacts to business processes, non-functional characteristics, QA criteria and technical enablement. The role is responsible to be constantly thinking through the needs of the business to support efficient and error free processes. The Claims Data Engineer will be responsible for finding trends in datasets and developing workflows and algorithms to help make raw data more useful to the enterprise. He or she will also be responsible for creating data acquisition strategy and develops data set processes. Designs and implements standardized data management procedures around data staging, data ingestion, data preparation, data provisioning and data destruction (scripts, programs, automation, assisted by automation, etc.). Ensures quality of technical solutions as data moves across Healthfirst environments Provide insight into the changing data environment, data processing, data storage and utilization requirements for the company and offer suggestions for solutions Ensures managed analytic assets support Healthfirst’s strategic goals by creating and verifying data acquisition requirements and strategy Develop, construct, test and maintain architectures Align architecture with business requirements and use programming language and tools Identify ways to improve data reliability, efficiency and quality Conduct research for industry and business questions Deploy sophisticated analytics programs, machine learning and statistical methods Prepare data for predictive and prescriptive modeling and find hidden patterns using data Use data to discover tasks that can be automated Create data monitoring capabilities for each business process and work with data consumers on updates Aligns data architecture to Healthfirst solution architecture; contributes to overall solution architecture Help maintain the integrity and security of the company data Minimum Qualifications: Bachelor’s Degree in Computer Engineering or related field Experience in a data engineering Experience in data programing languages such as java or python Experience working in a Big Data ecosystem processing data; includes file systems, data structures/databases, automation, security, messaging, movement, etc. Experience working in a production cloud infrastructure Preferred Qualifications: Proven track record of success directing the efforts of data engineers and business analysts within a deadline-driven and fast-paced environment Experience working with Alteryx, Tableau, SQL, Python, and/or AWS Hands on experience in leading healthcare data transformation initiatives from on-premise to cloud deployment Demonstrated experience working in an Agile environment as a Data Engineer Hands on work with Amazon Web Services, including creating Redshift data structures, accessing them with Spectrum and storing data in S3 Knowledge of SQL and multiple programming languages in order to optimize data processes and retrieval. Proven results using an analytical perspective to identify engineering patterns within complex strategies and ideas, and break them down into engineered code components Knowledge of provider-sponsored health insurance systems/processes and the Healthcare industry Experience developing, prototyping, and testing engineered processes, products or services Proven ability to work in distributed systems Proficiency with relational, graph and NoSQL databases required; expertise in SQL Must be able to develop creative solutions to problems Demonstrates critical thinking skills with ability to communicate across functional departments to achieve desired outcomes Excellent interpersonal skills with proven ability to influence with impact across functions and disciplines Ability to work independently and as part of a team Ability to manage multiple projects/deadlines, identifying the necessary steps and moving forward through completion Skilled in Microsoft Office including Project, PowerPoint, Word, Excel and Visio Please note: Since we care so greatly about our employees' and members' wellbeing, Healthfirst is moving to an environment where our employees are fully vaccinated against COVID-19. As a prospective new team member, you must be fully vaccinated with a CDC/FDA approved COVID-19 shot(s) to work in our offices. If you are selected to interview for this role, we will explain our vaccination policy in further detail and ensure you are comfortable moving forward with this company policy. WE ARE AN EQUAL OPPORTUNITY EMPLOYER. Applicants and employees are considered for positions and are evaluated without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, age, genetic information, military or veteran status, marital status, mental or physical disability or any other protected Federal, State/Province or Local status unrelated to the performance of the work involved. If you have a disability under the Americans with Disability Act or a similar law and want a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to careers@Healthfirst.org or calling 212-519-1798 . In your email please include a description of the accommodation you are requesting and a description of the position for which you are applying. Only reasonable accommodation requests related to applying for a position within Healthfirst Management Services will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with Healthfirst Management Services. EEO Law Poster and Supplement All hiring and recruitment at Healthfirst is transacted with a valid “@healthfirst.org” email address only or from a recruitment firm representing our Company. Any recruitment firm representing Healthfirst will readily provide you with the name and contact information of the recruiting professional representing the opportunity you are inquiring about. If you receive a communication from a sender whose domain is not @healthfirst.org, or not one of our recruitment partners, please be aware that those communications are not coming from or authorized by Healthfirst. Healthfirst will never ask you for money during the recruitment or onboarding process."
Data Engineer,Banco Itau International- Miami,"Miami, FL 33131",https://www.indeed.com/rc/clk?jk=28fe64b3d746e3e9&fccid=dd616958bd9ddc12&vjs=3,"The Data Engineer will be responsible to develop an enterprise solution for the International Private Bank data-warehouse, data analytics and data visualization structure. Additionally, the Data Engineer is responsible to apply good software engineering and solution architecture practices to the design and construction of the data analysis self-service platform, and to propose decoupled and reusable solutions, as well as rationalization of tools and inner source culture. This position represents a key function for Itaú International Private Bank and US operations, requiring an individual with advanced knowledge with data structuring, as well as ability to collaborate and communicate with counterparties in other areas and offices Duties & Responsibilities Ø Access current data structure and connections in order to design the data models that support the bank's transactional and analytical systems Ø Work with IT team to restructure current DW set up, including new satellites systems, and set of data Ø Create patterns that facilitate the understanding of information Ø Generate optimized solutions for data consumption, looking for and specialized structures Ø Develop software and automate tasks Ø Draw architecture of business and data-oriented solutions Ø Build data pipelines for data lake Ø Define solution architecture Ø Compliance with BSA/AML laws, rules, regulations and the bank's BSA/AML policies and procedures Qualifications Ø Bachelor's degree in computer and information science, or related subject area required Ø Event-oriented architecture (Kafta) Ø Hadoo Ecosystem (Hive, Impala, Spark), SQL and NoSQL database (mongoDB, Cassandra) Ø Microservices and containers, Cloud computing (AWS) Ø Continuous integration and continuous delivery Ø Expertise in collaborative environment such as Git and Jira Ø Experience with design, construction, and documentation of APIs Ø Experience in Agile Methodologies Ø Clean Code Experience Ø Multi-tasker, strong ability to prioritize Ø Strong initiative and resourcefulness. Ø Cultural awareness to deal with people from different countries Ø Fluency in English, Portuguese is desirable"
Analytics Data Engineer-REMOTE,John Deere,"Remote in Johnston, IA 50131+7 locations",https://www.indeed.com/rc/clk?jk=f721d1b9a54fe88a&fccid=38eb72d608d80c79&vjs=3,"There are over 7 billion people on this planet. And by 2050, there will be 2 billion more... many moving into urban centers at an unprecedented rate. Making sure there is enough food, fiber and infrastructure for our rapidly growing world is what we're all about at John Deere. And it's why we're investing in our people and our technology like never before! Here the world's brightest minds are tackling the world's biggest challenges. If you believe one person can make the world a better place, we'll put you to work. RIGHT NOW. John Deere is an equal opportunity employer. All qualified applicants will receive consideration for employment without regards to, among other things, race, religion, color, national origin, sex, age, sexual orientation, gender identify or expression, status as a protected veteran, or status as a qualified individual with disability. Primary Location: United States (US) - Iowa - Johnston Function: Data & Analytics (CA) Title: Analytics Data Engineer-REMOTE Onsite/Remote:Remote Position Your Responsibilities As an Analytics Data Engineer for the John Deere Financial Sales, Marketing and Operational Analytics team located in Johnston, IA or can be Remote you will…. Manage data pipelines to generate datasets for modeling support, feature engineering, and data prep for APIs in collaboration with data scientists. Provide automation architecture & process support (scheduling, code management, etc.), leveraging tools like Databricks and Apache Airflow for task orchestration. Develop and implement best practices that drive consistent and sustainable reporting and descriptive analytics workflows and support data literacy for analytics practitioners. Creates ad hoc reports, visualizations and interactive applications that support data-driven decisions. Research new tools and technology for reporting processes; collaborate with analytics enablement teams to facilitate training and adoption by other analytics practitioners. Visa Sponsorship is not available for this position. What Skills You Need Expertise in SQL Proficiency in at least one other programming language (R, Python, SAS, etc.) Ability to work independently and with teams to solve problems, gather requirements and manage conflicting priorities Strong written and oral communications, especially around communicating analytical concepts What Makes You Stand Out Proficiency in Python programming language Experience in leveraging cloud services (AWS) and interacting with a Data Lake environment Experience with reporting & visualization tools (Excel, Tableau, Power BI, R Shiny) Understanding of various functions within John Deere Financial operation Education Ideally you will have a degree or equivalent related work experience in the following: Master’s degree in quantitative field (e.g. mathematics, statistics, analytics, computer science, information technology, economics) OR Bachelor’s degree in quantitative field (e.g. mathematics, statistics, analytics, computer science, information technology, economics) and 2-3 yrs related work experience What You'll Get At John Deere, you are empowered to create a career that will take you to where you want to go while working in an inclusive team environment. Here, you'll enjoy the freedom to explore new projects, the support to think outside the box and the advanced tools and technology that foster innovation and achievement. Additionally, we offer a comprehensive reward package to help you get started on your new career path, including: Flexible work arrangements Highly competitive base pay and performance bonuses Savings & Retirement benefits (401K and Defined Benefit Pension) Healthcare benefits with a generous company contribution in the Health Savings Account Adoption assistance Employee Assistance Programs Tuition assistance Fitness subsidies and on-site gyms at specific Deere locations Charitable contribution match Employee Purchase Plan & numerous discount programs for personal use Click Here to find out more about our Total Rewards Package. The information contained herein is not intended to be an exhaustive list of all responsibilities and qualifications required of individuals performing the job. The qualifications detailed in this job description are not considered the minimum requirements necessary to perform the job, but rather as guidelines. The terms of the applicable benefit plans, and all company actions administering or interpreting these plans, continue to control. Deere & Company reserves the right to suspend, amend, modify, or terminate the Plan(s) in any manner at any time, including the right to modify or eliminate any cost-sharing between the company and participants. Changes, which can be made at any time, are made by action of the company's board of directors, or to the extend authorized by resolution of its board of directors, or by the Deere & Company Compensation Committee. In the event of a conflict between the language of the official Plan Documents and this document, the language of the official Plan Documents will control. ACA Section 1557 Nondiscrimination Notice The John Deere Health Benefit Plans for Salaried and Wage Employees comply with applicable Federal civil rights laws and do not discriminate on the basis of race, color, national origin, age, disability, or sex."
Data Engineer,AmSurg,Remote,https://www.indeed.com/rc/clk?jk=17ecc4c1577e7a09&fccid=681be0cd380eaa96&vjs=3,"AMSURG, the Envision Healthcare solution for ambulatory surgery centers (ASCs), collaborates with physicians and health systems across the country to provide and promote quality patient care. We are the nationally recognized leader in the strategic and operations management of ASCs that deliver high quality, high value, same-day surgical services with a superior patient experience. Launched in 1992 as an ASC industry pioneer, AMSURG is currently partnered with nearly 2,000 specialty physicians providing outpatient surgical services in more than 250 facilities in 34 states. POSITION SUMMARY: In this role the Data Engineer’s primary job responsibilities involve preparing data for analytical or operational uses. The specific tasks handled by the Data Engineers include, but not limited to, building data pipelines to pull together information from different source systems; integrating, consolidating and cleansing data; and structuring it for use in individual analytics applications. The Data Engineer often works as part of an analytics team providing data aggregations to executives, business analysts and other end users for more basic types of analysis to aid in ongoing operations. This is a remote position, allowing the Data Engineer position to be based anywhere in the country. Candidate must be willing to work a Central Time Zone schedule Monday - Friday. ESSENTIAL RESPONSIBILITIES: The Data Engineer is required to have a thorough understanding of tools for creating and managing data integration jobs, and providing data analysts and business users with simplified access to prepared data sets. Design, construct, install, test and maintain highly scalable data management systems Ensure systems meet business requirements and industry practices Build high-performance algorithms, prototypes, predictive models and proof of concepts Research opportunities for data acquisition and new uses for existing data Develop data set processes for data modeling, mining and production Integrate new data management technologies and software engineering tools into existing structures Employ a variety of techniques and tools to marry systems together Recommend ways to improve data reliability, efficiency and quality Collaborate with data architects, modelers and IT team members on project goals KNOWLEDGE AND SKILLS: To perform this job successfully, an individual must be able to perform each essential responsibility satisfactorily. The requirements listed below are representative of the knowledge, skills and/or abilities required. Intermediate to Advanced level user of Microsoft Office products. Advanced/power user of Excel Knowledge of relational database principles including SQL and MS-Office products Excellent quantitative and analytical skills as well as the ability to translate findings into meaningful information appropriate to the audience/stakeholder High level of comfort with many types of data including financial, quality, clinic and security Ability to work independently and prioritize work appropriately Ability to work under tight deadlines and switch quickly and comfortably between projects as business needs dictate Displays a positive morale and a sense of teamwork Excellent organizational skills and strong oral and written communication skills a must Regular and reliable attendance required. Education/Experience: Bachelor’s degree from an accredited college or university with a minimum of three (3) years previous data management/data services experience. Highly proficient in database management and query tools, including SQL and/or other query languages, required. Language Skills: Ability to understand, read, write and speak English. Ability to read, analyze and interpret general business periodicals, professional journals, technical procedures or governmental regulations. Ability to successfully write business correspondence. Ability to effectively present information, respond to questions and professionally interact with managers, employees, clients, vendors and the general public. Other Qualifications: Must be able to handle multiple, simultaneous tasks effectively and efficiently while maintaining a professional, courteous manner. Must be able to work well with others. Strong verbal and written communication skills required. Must be detail oriented and organized. High integrity, including maintenance of confidential information. Must be able to exercise good judgment and positively influence and lead others, including handling confrontations with poise and efficiency. Based on business need, the ability to work a flexible schedule, including some evenings and weekends as approved in advance. CORPORATE CORE VALUES Puzzle Solving-Turning challenges into opportunities in a collaborative, agile and creative way Excellence-On a never-ending quest to improve and exceed expectations Ownership-Taking responsibility for our actions, relationships and partners’ success Positive Environment-Respectful, caring, trusting and supportive of the team Leadership-Leading by example, staying true to our values and dreams Ethics-Committing to always doing the right thing guided by integrity and transparency Effective November 1, 2021, AMSURG’s Vaccination Policy requires all teammates, including clinicians and independent contractors, to be fully vaccinated for COVID-19 as a condition of employment or engagement. Regardless of position, all new hires must submit proof of vaccination and or obtain an approved medical or religious exemption as a condition of employment. This policy is designed to protect the health and safety of our patients, communities and each other. Must pass a background check and drug screen. We do not discriminate in practices or employment opportunities on the basis of an individual's race, color, national or ethnic origin, religion, age, sex, gender, sexual orientation, marital status, veteran status, disability, or any other prohibited category set forth in federal or state regulations. We are an equal opportunity employer."
Data Engineer,Edmunds.com,"Santa Monica, CA 90404 (Mid-City area)",https://www.indeed.com/rc/clk?jk=94a4f4dc0df165f0&fccid=f69fe5673875c177&vjs=3,"At Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how! What You’re Applying For: Edmunds is looking for a data engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to Data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make sense of the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth. What You’ll Do: Create and maintain scalable, maintainable and reliable pipelines that process very large quantities of structured and unstructured data Unify streaming and batch processing modes into one cohesive framework of processing including monitoring and alerting that fit into a unified and reliable Big Data infrastructure Build streaming data pipelines that enable the business to adapt in real-time Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Regularly reviews work with/from peers with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices Regularly interacts and collaborates with personnel across functions (product, technology, analytics, operations) within the assigned team and technology chapter Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs What You Need: Excellent problem solving, troubleshooting, and communication skills Desire to learn new technologies Demonstrated ability to design and write maintainable software Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms Experience enhancing and evolving existing systems Have experience with the following software/tools: Experience building ETL pipelines Proficiency in Java Proficiency in SQL Nice to have: Knowledge of Spark, Scala and Python Nice to have: Knowledge of AWS services like S3, EC2, RDS, Lamda Nice to have: Knowledge of pipeline and workflow management tools like Airflow, Oozie, etc. Edmunds Perks: Flexible time off 13 Paid Holidays Comprehensive Health Benefits (medical, dental, vision, life and disability) Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions) 401K Plan with Company Matching at 50%, up to 6% of employee eligible contribution and vesting after 1 year Up to 4 months Paid Parental Leave HeartCash matches employee donations to the causes that are important to them 2 Days of Paid Time Off for time to dedicate to social impact causes FitCash covers a portion of gym or fitness activity fees Well being sessions and events such as yoga, meditation and walking challenges On-going career development sessions and an annual learning event Pet insurance Sabbatical leave Education Reimbursement Plus a coffee bar, frozen yogurt and more! Working @ Edmunds.com: Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you! Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws. #LI-DNP Flexible work from home options available."
Data Engineer,Paramount,"New York, NY 10036+12 locations",https://www.indeed.com/rc/clk?jk=beafe741ba4a2e91&fccid=30cb52ad6dd37131&vjs=3,"Paramount (NASDAQ: PARA; PARAA) is a leading global media and entertainment company that creates premium content and experiences for audiences worldwide. Driven by iconic studios, networks and streaming services, its portfolio of consumer brands includes CBS, Showtime Networks, Paramount Pictures, Nickelodeon, MTV, Comedy Central, BET, Paramount+, Pluto TV and Simon & Schuster, among others. The company delivers the largest share of the U.S. television audience and boasts one of the industry's most important and extensive libraries of TV and film titles. In addition to offering innovative streaming services and digital video products, Paramount provides powerful capabilities in production, distribution and advertising solutions. Overview: We are seeking a curious and motivated Data Engineer to join our Data Strategy & Operations team at Paramount. This position supports the data ingestion needs within Corporate Research. The role services Brands across the Paramount portfolio and works across data from Streaming, Social, Digital and external platforms. This person will develop and support data pipelines to pull data through various ingestion methods (API, feed, S3, Snowflake, etc.) based on business needs. They will also work closely with datasets which are then used as inputs into downstreaming data flows and dashboarding/reporting. Day-to-Day Responsibilities: Maintain pre-existing data pipelines Develop & support new ingestion pipelines Expand upon existing processes to pull in new metrics/data needs based on business requirements Troubleshoot failures, data delays, and data anomalies to ensure data accuracy. Monitor jobs and find opportunities for efficiency in scheduling, dependencies, and functionality. Optimize data processes to ensure data timeliness and completeness. Qualifications: Undergraduate degree 2 years’ of working experience with Python - strong internship and project experience will be considered Demonstrated ability to import, clean, transform, and aggregate data with the purpose of translating large data sources into meaningful datasets for decision making purposes. Familiarity with data transfer methods/protocols required (including but not limited to APIs, feeds, S3, S/FTP, Google Cloud Storage, querying data out of data warehouses, snowflake, etc.) AWS or GCP knowledge Familiar with ETL tools Demonstrated usage of engineering best practices. Curiosity about all things data related Nice to have: Experience in Linux/UNIX environments, SQL & R Experience contributing and collaborating via Git. A broad understanding of datasets from streaming, social, and digital platforms including but not limited to Adobe Analytics, Facebook, YouTube, Twitter, Instagram, etc. Familiar with SVOD & AVOD datasets. Experience with RESTful services Familiar with Domo or other BI tools. Paramount is an equal opportunity employer (EOE) including disability/vet. At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to viacomaccommodations@viacom.com. Only messages left for this purpose will be returned."
Satellite Imagery Data Engineer,Google,"Mountain View, CA+4 locations",https://www.indeed.com/rc/clk?jk=516b66ec6ef5fe70&fccid=a5b4499d9e91a5c6&vjs=3,"Minimum qualifications: Bachelor's degree in Computer Science, Engineering, a related field, or equivalent practical experience. 3 years of experience in technical project management, stakeholder management, professional services, solution engineering, or technical consulting. 1 year of experience in technical troubleshooting and writing code in one or more programming languages. Preferred qualifications: Master’s degree in Engineering, Computer Science, Business, or a related field. 5 years of experience developing large scale Information storage and retrieval, mapping technologies, or Geographic Information System (GIS) data visualization tools or GIS oriented web applications. 1 year of experience working with customer-side web technologies (e.g., HTTP, HTML, JavaScript, XML, TypeScript) and database technologies (e.g., SQL, NoSQL). 1 year of experience using Machine Learning and building solutions. About the job As a Satelite Imagery Data Engineer you will strategize, acquire, process, and publish images from various overhead sources, including drones, planes, and satellites. As a part of the Overhead Imagery Operations Team you will help manage the overhead imagery database that's directly used by Users in Maps/Earth and is also used by internal teams to build and maintain our basemap. You will also get to work on projects like Flood Forecasting, Current Events, and AI for Social Good. Responsibilities Design, develop, optimize, and maintain data storage and reporting. Work closely with engineering teams to design and acquire log level data. Create and optimize dashboards. Write and review technical documents, including requirements and design documents for existing and future data systems, and data standards and policies. Coordinate cross-functionally to enable a seamless communication of risks, dependencies and schedules across hardware and software teams. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form."
Data Engineer,Dispatch,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=6676ed4620f2fdbf&fccid=46293e53c03acd75&vjs=3,"The Role (Remote) Dispatch is seeking inventive and motivated data engineers at all levels of experience to join the Data Engineering group. In this role, you will build critical data infrastructure that surfaces data and insights across the company. Our data team is at the intersection of business analytics, data warehousing, and software engineering. As a Data Engineer you will focus on the software engineering related to data replication, storage, centralized computation, and data APIs. You will help reduce data redundancy by creating systems and datasets that serve as sources of record, enable discovery and governance of our data, and support key business goals. This is a full-time exempt role (learned professional exemption) that reports to the Manager of Data Science. What You’ll Do Executes all job duties in alignment with Dispatch’s core values, mission, and purpose Acts ethically, with integrity and complies with legal standards to deliver an environment that promotes respect, innovation, and creativity Encourages and fosters an inclusive environment. An environment where the strengths and expertise of our workforce are welcomed, amplified and exhibited in the work at Dispatch Develops an in-depth understanding of Dispatch, industry trends, and competition Run and support a production enterprise data platform Design, develop, and test data models using dbt Work with languages like Python, Go, Bash, LookML, and SQL Build batch and streaming data pipelines with cloud-based data tools like dbt, AWS Aurora, AWS Athena, and AWS Kinesis Firehose Create, maintain, and test the data pipelines that power our business intelligence tools (Looker) Analyze and test changes to our data architectures and processes, and determine the possible downstream effects and potential impacts to data consumers Perform other duties as assigned (to be less than 10% of your responsibilities) What We’re Looking For You are excited about data and motivated to learn new technologies You have the ability to quickly pivot as needed while consistently delivering results on time You courageously identify opportunities and the determination to create solutions to meet the needs of the business You are comfortable collaborating with engineers from other teams, product owners, business teams, and data analysts and data scientists. You are eager to resolve upstream data issues at the source instead of applying workarounds Must be a positive, self-driven team-member with a desire to learn What You’ll Need Bachelor’s degree or equivalent experience required 3+ years experience in a data or software engineering role Experience with python required Professionalism; being both resolute and diligent Even if you don’t match 100% of the requirements, we still encourage you to apply so that we may possibly talk and see how you could still contribute to Dispatch in meaningful ways! ABOUT US Dispatch is a technology-based company that redefines the way same-day deliveries are made in the B2B space. With our network of independent contractor drivers, Dispatch puts suppliers, businesses, and technicians in control of local deliveries with real-time tracking and transparency. We strive to deliver the best value and service to our customers every day. Dispatch started in the Twin Cities, but is now in dozens of markets across the country. With all of this growth, we maintain a strong focus on our company culture. Dispatch operates on five core values: People First, Belief, Speed to Value, Driven to Deliver, and Transparency. If you connect with these values, we’d love to learn more about you!"
Data Engineer Trainee,Booz Allen Hamilton,"Arlington, VA+39 locations",https://www.indeed.com/rc/clk?jk=e1749587931efcb6&fccid=4e041af1d0af1bc8&vjs=3,"The Challenge: Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by cloud engineering and loosely coupled architectures? In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As an aspiring cloud data scientist, you know you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors — from fraud detection, to cancer research, to national intelligence — you see data scientists turning data into actions and you want to be part of the team. We have an opportunity for you to develop your analytical skills and establish your career in data science. You’ll join a rigorous training program that combines skills assessments, a comprehensive curriculum, functional mentorship, a capstone analytic challenge, and support to place you on your first data science project. You’ll learn how to write scripts to integrate data, conduct exploratory data analysis to discover hidden trends, apply machine learning in AWS to train predictive models, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers that inform decisions. Equipped with the foundational data science skills to accelerate your career, you’ll join a team and apply those skills to support our clients’ critical national security missions. Embrace the challenge and join us in driving change through data science. Empower change with us. You Have: Experience with data engineering, including querying or analyzing data to answer questions and solve problems Experience with python Knowledge of basic concepts in mathematics and statistics Knowledge of Cloud environments Ability to obtain a security clearance Scheduled to obtain a Bachelor's degree by Summer 2022 Nice If You Have: Experience with systems engineering or systems administration Experience with Amazon Web Services Experience with Azure Experience with Docker, Kubernetes, and Ansible Knowledge of SQL and GitHub Ability to learn a programming language Bachelor’s degree in Data Science, Mathematics, Engineering, Physics, Statistics, or CS Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. Build Your Career: At Booz Allen, we know the power of analytics and we’re dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you can expect: access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk a chance to change the world with the Data Science Bowl—the world’s premier data science for social good competition participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government You’ll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications? Take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We’ll help you develop the career you want, as you chart your own course for success. We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law."
Associate Data Engineer -Streaming,"Amazon Web Services, Inc.",+126 locationsRemote,https://www.indeed.com/rc/clk?jk=408d64830055d3c5&fccid=5cc0cdc6dbb121cc&vjs=3,"• Bachelor’s degree, or equivalent experience, in Computer Science, Engineering, Mathematics or a related field • 2+ years’ industry experience as a Data Engineer with demonstrated experience in data modeling, ETL Development, Data Warehousing, Data Lakes, and/or consoliding data from distributed systems • 1+ years’ experience building enterprise level streaming and real-time architecture • Experience with implementation, integration and administration with at least one of the following Streaming Data-Streaming frameworks or services: Apache Kafka, Kinesis Data Streams, Apache Spark Streaming, Apache Flink, Apache Storm, Apache NiFi, Azure Stream Analytics, or Confluent Job summary Are you a streaming systems specialist? Do you have real-time systems experience? Do you like to solve the most complex and high scale (billions + records) data challenges in the world today? Would you like a career that gives you opportunities to help customers and partners use cloud computing to do big new things faster and at lower cost? Do you want to be part of history and transform businesses through cloud computing adoption? Do you like to work in a variety of business environments, leading teams through high impact projects that use the newest data analytic technologies? Would you like a career path that enables you to progress with the rapid adoption of cloud computing? At Amazon Web Services (AWS), we’re hiring highly technical streaming data engineers to collaborate with our customers and partners on key engagements. Our consultants develop and deliver proof-of-concepts, technical workshops, deliver implementation projects and create solutions and tools. These professional services engagements involve emerging technologies like AI, IoT, and Data Analytics. The focus of this role is helping our customers and partners with design, implementation and integration of solutions using Amazon managed streaming services. AWS Professional Services engage in a wide variety of projects for customers and partners, providing collective experience from across the AWS customer base and are obsessed about customer success. Our team collaborates across the entire AWS organization to get the right solution delivered and drive feature innovation based upon customer needs. Solution - Deliver on-site technical engagements with partners and customers. This includes participating in pre-sales on-site visits, understanding customer requirements, supporting consulting proposals, contributing to internal Area of Depth programs and Technical Field Community, authoring AWS Data Analytics best practice and creating packaged data service offerings. Delivery - Engagements include on-site projects to design and build customer’s data streaming implementations and helping customers to migrate existing self-managed and on-premises solutions to AWS. Ability to travel to client locations to deliver professional services, as needed. Inclusive Team Culture Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have thirteen employee-led affinity groups, reaching 85,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. Work/Life Balance Our team puts a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success here. We are a customer-obsessed organization—leaders start with the customer and work backwards. They work vigorously to earn and keep customer trust. Mentorship & Career Growth Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future. • Hands on experience contributing to large-scale data science/data analytics projects • Experienced developing innovative solutions to complex business and technology problems • Written and verbal technical communication skills with an ability to present complex technical information in a clear and concise manner to a variety of audiences. • Experienced in queuing theory with message-broker software like RabbitMQ or similar Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. The pay range for this position in Colorado is $98,200 - $160,000/yr.; however, base pay offered may vary depending on job-related knowledge, skills, and experience. A sign-on bonus and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. Applicants should apply via Amazon's internal or external careers site. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Junior Data Engineer,GitLab,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=85389079e52acab4&fccid=d8c987644cc029b0&vjs=3,"The GitLab DevOps platform empowers 100,000+ organizations to deliver software faster and more efficiently. We are one of the world’s largest all-remote companies with 1,600+ team members and values that guide a culture where people embrace the belief that everyone can contribute. Location - This position is 100% remote, based in APAC. The Data Engineer job family is focused on an analytical and business-oriented mindset with the ability to implement rigorous database solutions and best practices in order to produce and influence the adoption of strong quality data insights to drive business decisions in all areas of GitLab. The Data Engineer job family is essentially software engineers who have a particular focus on data movement and orchestration. Don’t have a ton of knowledge about GitLab yet? Don’t worry. We have an extensive onboarding and training program at GitLab and you will be provided with necessary DevOps and GitLab knowledge to fulfill your role. What you'll do in this role... Maintain our data platform with timely and quality data Build and maintain data pipelines from internal databases and SaaS applications Create and maintain systems documentation Write maintainable, performant code Implement the DataOps philosophy in everything you do Plan and execute system expansion as needed to support the company's growth and analytic needs Collaborate with Analytics Engineers and Data Analysts to drive efficiencies for their work Collaborate with other functions to ensure data needs are addressed This position is always central and reports to the Manager, Data We're looking for... Experience using Python, Java, or Scala for data processing (Python preferred) Knowledge of and experience with data-related Python packages Good understanding of SQL and analytical data warehouses Share and work in accordance with our values Constantly improve product quality, security, and performance Desire to continually keep up with advancements in data engineering practices Collaborate with team members to identify requirements, define successful outcomes, and deliver trusted results Catch bugs and style issues in code reviews Ship small features independently Ability to use GitLab Also, we know it’s tough, but please try to avoid the ​​confidence gap​.​​ You don’t have to match all the listed requirements exactly to be considered for this role. Hiring Process To view the full job description and hiring process, please view our​ ​handbook​ . Additional details about our process can also be found on our ​hiring page​. #LI-MG1 Country Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process."
Data Engineer,Dispatch,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=6676ed4620f2fdbf&fccid=46293e53c03acd75&vjs=3,"The Role (Remote) Dispatch is seeking inventive and motivated data engineers at all levels of experience to join the Data Engineering group. In this role, you will build critical data infrastructure that surfaces data and insights across the company. Our data team is at the intersection of business analytics, data warehousing, and software engineering. As a Data Engineer you will focus on the software engineering related to data replication, storage, centralized computation, and data APIs. You will help reduce data redundancy by creating systems and datasets that serve as sources of record, enable discovery and governance of our data, and support key business goals. This is a full-time exempt role (learned professional exemption) that reports to the Manager of Data Science. What You’ll Do Executes all job duties in alignment with Dispatch’s core values, mission, and purpose Acts ethically, with integrity and complies with legal standards to deliver an environment that promotes respect, innovation, and creativity Encourages and fosters an inclusive environment. An environment where the strengths and expertise of our workforce are welcomed, amplified and exhibited in the work at Dispatch Develops an in-depth understanding of Dispatch, industry trends, and competition Run and support a production enterprise data platform Design, develop, and test data models using dbt Work with languages like Python, Go, Bash, LookML, and SQL Build batch and streaming data pipelines with cloud-based data tools like dbt, AWS Aurora, AWS Athena, and AWS Kinesis Firehose Create, maintain, and test the data pipelines that power our business intelligence tools (Looker) Analyze and test changes to our data architectures and processes, and determine the possible downstream effects and potential impacts to data consumers Perform other duties as assigned (to be less than 10% of your responsibilities) What We’re Looking For You are excited about data and motivated to learn new technologies You have the ability to quickly pivot as needed while consistently delivering results on time You courageously identify opportunities and the determination to create solutions to meet the needs of the business You are comfortable collaborating with engineers from other teams, product owners, business teams, and data analysts and data scientists. You are eager to resolve upstream data issues at the source instead of applying workarounds Must be a positive, self-driven team-member with a desire to learn What You’ll Need Bachelor’s degree or equivalent experience required 3+ years experience in a data or software engineering role Experience with python required Professionalism; being both resolute and diligent Even if you don’t match 100% of the requirements, we still encourage you to apply so that we may possibly talk and see how you could still contribute to Dispatch in meaningful ways! ABOUT US Dispatch is a technology-based company that redefines the way same-day deliveries are made in the B2B space. With our network of independent contractor drivers, Dispatch puts suppliers, businesses, and technicians in control of local deliveries with real-time tracking and transparency. We strive to deliver the best value and service to our customers every day. Dispatch started in the Twin Cities, but is now in dozens of markets across the country. With all of this growth, we maintain a strong focus on our company culture. Dispatch operates on five core values: People First, Belief, Speed to Value, Driven to Deliver, and Transparency. If you connect with these values, we’d love to learn more about you!"
Data Engineer,NIC MAP Vision,Remote,https://www.indeed.com/company/NIC-MAP-Vision/jobs/Data-Engineer-25218c3df4e4ae74?fccid=67ac721cf5e7700d&vjs=3,"NIC MAP Vision is hiring a Data Engineer to join our team. This is a junior level position. We offer competitive salary, full-range of benefits, generous PTO, and a remote-working environment with equipment provided. NIC MAP Vision is dedicated to serving the senior housing and care industry through our software products. The Data Engineer position is an individual contributor role that helps to design, develop, automate, and support complex applications to extract, transform, and load data. Strong skills in MS SQL Server and TSQL are expected. Experience with other database technologies is a plus. The Data Engineer will collaborate with internal teams to ensure we are providing high quality data from an ever-growing variety of sources. ESSENTIAL DUTIES AND RESPONSIBILITIES: Work with data from various sources and formats (Excel, CSV, PDF, etc.) Build high quality, efficient ETL processes to ingest data from those sources Build datasets to support Product Engineering, Data Scientists, Client Delivery, etc. Maintain, support, and upgrade existing processes as needed Document processes and other relevant information **May perform other duties and responsibilities that management may deem necessary from time to time. REQUIRED SKILLS AND ABILITIES: Ability to communicate effectively through excellent interpersonal, verbal, written, and presentation skills. Attention to detail, with a special focus on data within the commercial real estate, banking, information services, or other technology-based companies. NIC MAP VISION is a collaborative environment that values discussion and debate to achieve the best result for the Seniors Housing sector. The successful candidate will be naturally inquisitive and self-motivated to dig into problems and provide solutions. Ability to collaborate with other team members to accomplish tasks in a team dynamic Ability to work autonomously Strong skill using MS SQL Server and T-SQL EDUCATION and/or EXPERIENCE: Bachelor’s Degree required Prior experience manipulating data to produce output Prior experience creating ETL processes In-depth experience using MS SQL Server and T-SQL TRAVEL REQUIREMENTS:Limited, at most 1-2 times/year. Job Type: Full-time Pay: $80,000.00 - $100,000.00 per year Benefits: 401(k) 401(k) matching Dental insurance Flexible spending account Health insurance Health savings account Paid time off Referral program Vision insurance Schedule: Monday to Friday COVID-19 considerations:Our entire team currently works entirely remotely. Experience: SQL: 1 year (Required) T-SQL: 1 year (Required) Work Location: Remote"
"Front End Engineer II, Shopping Data Foundations",Amazon.com Services LLC,+6 locationsRemote,https://www.indeed.com/rc/clk?jk=8d3b875f16cff983&fccid=fe2d21eef233e94a&vjs=3,"2+ years of professional non-internship experience with front end, web or mobile software development using JavaScript, HTML and CSS Job summary As a Front End Engineer on the Shopping Data Foundations team, your work will directly impact the look and feel of the Amazon.com customer experience world wide. You will have the opportunity to work alongside a team of experts to deliver technologies that help accelerate CX innovation at Amazon. Key job responsibilities As a Front End Engineer you will use work with TypeScript, HTML, CSS, a combination of industry popular and amazon proprietary software to build CX features and continuously experiment with new ideas on Amazon website and application. You will also help launch novel build tooling to help modernize and accelerate front end development at Amazon. Our products are used widely across Amazon. You will have the opportunity to leverage this to effect worldwide and Amazon-wide impact like latency optimization to speed up the shopping experience for our customers. You will use Git to manage continuous deployments while focusing on testability, scalability, maintainability, code quality, and cogent design. Our products include reusable component framework for Amazon, asset build/deploy system used by thousands of engineers, and a in-house templating language which compiles to Java, Perl, JavaScript, that enables engineers across the world to create features for shoppers. About the team At Shopping Data Foundations, we own the data plus look and feel of the the Amazon shopping experience. Our visual building blocks (a.k.a Product UI components), styling/interactivity libraries and build and build/deploy tools will power the Amazon.com front end development ecosystem. Thousands of amazon engineers will use our service and tools on a daily basis to build innovative experiences for shoppers on Amazon app and website. As a team, we value testability, maintainability, code quality, and cogent design. Understanding of UX design patterns and approaches to implement them. Familiarity with JavaScript frameworks such as React, Redux, Vue, Ember, or Angular Understanding of cross-browser/device support and testing Experience building scalable, highly available web services or applications. The pay range for this position in Colorado is $143,700-194,400/yr. Our range of benefits may include health care, employee discounts, 401(k) savings plans, paid time off, and more. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. Applicants should apply via Amazon's internal or external careers site. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Data Engineer,Evaya Data Systems,"Allen, TX",https://www.indeed.com/rc/clk?jk=762dcef94f0ba06f&fccid=d3963513239ea6de&vjs=3,"The engineering team consists of talented, team-oriented individuals who are empowered to take advantage of the latest cloud and distributed technologies to deliver reliable, high-throughput applications. As a Data Engineer, you’ll employ your skills on a daily basis to design and build data processing and storage applications to handle millions of transactions per day. You will analyze business requirements and consult with the broader team to ensure successful processing, storage and reporting of our Big Data. You’ll have a wide variety of languages and technologies at your disposal that you can use to solve problems. Your work will directly shape and create our data architecture to ultimately deliver systems that stand up to unpredictable environments at massive scale. Technical Skills Needed: 5 years of working with following technology stack: Core languages are Java and C#; RESTful services, jQuery, SQL Server, Hadoop, Hive, HBase, Storm, Spark, and AWS Services such as Kinesis, DynamoDB, Redshift, Lamda, and SQS. Growing track record of success or the groundwork to be an impactful member of the team. We’re looking for candidates that exhibit many of the following skills/attributes: Strong Educational Background Hands-on Engineering experience in Problem solving and debugging skills Writing and deploying code the Linux, Windows, or cloud environments Familiarity with algorithms and performance analysis Willingness to contribute to the operational responsibility of the team’s applications Some experience with one or more of the following: Relational Databases & SQL NoSQL databases (Cassandra, Redis, DynamoDB, MongoDB) Big Data tools such as Hadoop, Hive, EMR, Storm, Spark, DynamoDB, HBase"
Senior Data Engineer,Talkiatry,Remote,https://www.indeed.com/company/Talkiatry/jobs/Senior-Data-Engineer-a27aa496c696b4bd?fccid=9a056f5424e42051&vjs=3,"At Talkiatry, we believe mental health is health. We’re a successful, high-growth organization creating the gold standard in mental healthcare and helping people live their best lives. More specifically, we’re solving the behavioral health crisis in America by focusing on high-quality in-network care and proprietary technology that redefines how patients access and receive psychiatric care. The result? Through a personalized approach, we meet the needs of patients, physicians, and insurance partners while driving down costs and improving care. As a Senior Data Engineer, your main goal is to work closely with our data scientists and analysts. You will support them by providing infrastructure and tools they can use to deliver end-to-end solutions to business problems that can be developed rapidly and maintained easily. Essential Functions: Partner with business, analytics, and engineering teams to design and build data pipelines, and define the overall ETL strategy Institute data quality checks and implement monitoring in the pipelines to ensure confidence in the data Be a key contributor to the data modeling of the data warehouse Perform SQL tuning as necessary Carry out ad-hoc analysis as necessary Qualifications: 5+ years of experience working as a Data Engineer 3+ years of experience working with Python 2+ years of experience working with an orchestration tool like Airflow 2+ years of experience working with cloud data warehouses (Snowflake, Redshift, etc.) Proficient in SQL and Data Modeling (experience with dbt is a plus, but not required) Experience working within cloud computing environments such as AWS, Azure, Google Cloud Experience working with streaming data is a plus, but not required Comfort working in a dynamic environment with several ongoing concurrent projects Ability to work independently and cross-functionally with team members of all levels At Talkiatry, we are an equal opportunity employer committed to a diverse, inclusive, and equitable workplace and candidate experience. We strive to create an environment where everyone has a sense of belonging and purpose, and where we learn from the unique experiences of those around us. We encourage all qualified candidates to apply regardless of race, color, ancestry, religion, national origin, sexual orientation, age, citizenship, marital or family status, disability, gender, gender identity or expression, pregnancy or caregiver status, veteran status, or any other legally protected status. Job Type: Full-time Benefits: 401(k) 401(k) matching Dental insurance Health insurance Health savings account Life insurance Paid time off Parental leave Vision insurance Schedule: Monday to Friday Work Location: Remote"
"SENIOR SOFTWARE ENGINEER, SPORTS DATA",DraftKings,Remote,https://www.indeed.com/rc/clk?jk=1c4fab3d6a4f72cf&fccid=2b2d6f212948082d&vjs=3,"REMOTE - US ENGINEERING JR3006 FULL TIME BUILDING THE POSSIBILITIES. As a Senior Software Engineer, you’ll be part of one of our multidisciplinary teams where you’ll work closely with designers, product managers, and data analysts. You’ll be a creative contributor to our processes and decision-making so when we build new features, we can ensure scalability and availability of the entire platform. Sounds good to you? Join us. WHAT YOU’LL DO AS A SENIOR DATA SOFTWARE ENGINEER: As a full stack developer, you will be developing systems and APIs that power a rich set of applications used by a large and passionate group of users every day. Care about agility as much as you care about scalability. We roll out products very quickly and are looking for a team that can pivot at a moment’s notice. We’re constantly growing and forming new teams; you will be able to lead either as an engineer or transition into a manager role. WHAT YOU’LL BRING: Ideally, you have 3+ years of development experience in object-oriented programming using languages such as C# or Java. You have a strong knowledge of OOP and REST design principles. 2+ years of relational database experience including schema design and SQL Experience with data streaming technologies and distributed systems as well as using Kafka. Experience with modern client JS libraries, like React, Redux and runtime. You also have experience writing and maintaining a comprehensive suite of unit and integration tests. Experience writing distributed systems in a Cloud Computing environment such as AWS strongly preferred. Ability to grow other engineers through code reviews, design reviews, and over-the-shoulder debugging. #LI-DP2 WHO ARE WE A GOOD FIT FOR? We love working with talented people but more than that, we seek out compassionate co-workers with a collaborative spirit. Our work moves quickly and we’re great at coming together to find creative solutions to some of tech’s most interesting problems. If that sounds good to you, join us. WE ARE DRAFTKINGS. We’re inspired by our shared passion for developing creative solutions to complex challenges and empowering the people around us to do their best work. We are industry leaders in the digital entertainment and technology space propelled by constant curiosity and diverse perspectives. Our teams are fueled by innovation. We are looking ahead, building what’s next, and continuously reinventing the industry. We’re a publicly traded (NASDAQ: DKNG) technology company headquartered in Boston, with teams around the world and an expanding global presence. JOIN US! We strive to create a place where all feel safe, empowered, engaged, championed, and inspired. DraftKings is proud to be an equal opportunity employer. This means we do not tolerate discrimination of any kind and are committed to providing equal employment opportunities regardless of your gender identity, race, nationality, religion, sexual orientation, status as a protected veteran, or status as an individual with a disability. READY TO BUILD WHAT’S NEXT? APPLY NOW. As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment."
Senior ETL Data Engineer,Mantek Solutions,Remote in California+1 location,https://www.indeed.com/rc/clk?jk=7a7c4bf06f095986&fccid=d14958d1be855859&vjs=3,"Location California Date Posted June 19, 2022 Job ID 6703 Employment Type Contract Pay rate $75 /hour #6703 Seeking a Senior ETL Data Engineer for a one year contract that may extend or convert. This is a remote position in the preferred area of PST. Please note this position requires the successful completion of a background check, drug screen, and employment and education verification prior to starting work. Senior ETL Data Engineer is responsible for supporting Data Engineering activities in AWS cloud environment Design, develop, and maintain scaled ETL process to deliver meaningful insights from large and complicated data sets. Work as part of a team to build out and support Data Lake, implement solutions using Python to process structured and unstructured data. Partner with business users, architects and cloud engineers to develop, implement, and automated data pipelines. Collaborate with Engineering teams to discovery and leverage new data being introduced into the environment. Support existing ETL processes written in SQL, troubleshoot and resolve production issues. Create and maintain report specifications and process documentations as part of the required data deliverables. Serve as liaison with business and technical teams to achieve project objectives, delivering cross functional reporting solutions. Communicating with business partners, other technical teams and management to collect requirements, articulate data deliverables, and provide technical designs. Ability to multitask and prioritize an evolving workload in a fast-paced environment. Education & Experience: Bachelor’s degree W2 Only No Corp to Corp No Sponsorship No third-party candidates considered for this position Remote work to be done in PST If you are interested in this position and feel you are qualified, please apply to JO#6703 along with your updated resume. #MantekPriority"
Azure Data Engineer,Kaizen Technologies,"Las Vegas, NV",https://www.indeed.com/rc/clk?jk=fb13f61f95030ccf&fccid=c1edd7669511bab9&vjs=3,"Required Skills : Azure Databricks, Azure Data factory Job Description : Position: Azure Data Engineer Location: Las Vegas - NV Duration: Contract Job Description: Primary skill as Azure Databricks, Azure Data factory. Required Experience: Data Engineering/Data Warehousing development/operations experience of at least 12 years Design and develop Azure cloud-native enterprise data solution with emphasis on data integration, transformation, and governance Build solution designs and technical designs for data pipelines based on requirements Design plug-n-play components that can be orchestrated into data flows Required Skills Technical Skills- Databricks Nice to have skills Technical Skills- Azure Data Factory, Azure Databricks Roles & Responsibilities Required Experience: Data Engineering/Data Warehousing development/operations experience of at least 12 years Design and develop Azure cloud-native enterprise data solution with emphasis on data integration, transformation and governance Build solution designs and technical designs for data pipelines based on requirements Design plug-n-play components that can be orchestrated into data flows, data ingestion patterns based on source systems and data formats, data quality frameworks etc. Identify opportunities to enhance, streamline, improve existing codebase for automation, performance, scalability, reliability, operational efficiency Help prioritize data pipeline development backlog and create implementation roadmaps Lead team of data engineers to design and develop new features and enhance existing data pipelines, provide QA, UAT and Implementation Support. Preferred Experience: ADF source code version control using Azure DevOps or Git • Experience with Snowflake • Collaboration with business teams Experience in fast paced & complex environments, including large enterprise settings"
Data Engineer,Expect Engineering Solutions,"Denver, CO 80203 (Speer area)",https://www.indeed.com/rc/clk?jk=6011a4b35814fb70&fccid=4a201efff3e357f0&vjs=3,"Employment Type Full-time Industry Back-End ETL & Automation Developer Job Location 232 N Broadway, Denver, Colorado, 80203, USA Base Salary $120,000-$130,000 Per year Valid through July 29, 2023 Description Seeking an experienced Data Engineer for a full-time/perm position located in Denver Colorado. This is an onsite/in-office position. This position works closely with the executive team on projects like maintaining data pipelines, creating dashboards, and building tools for various departments. Responsibilities Maintain and build back-end ETL systems. Build data extractors and maintain the current ones to make sure the data is being correctly routed from a variety of sources (APIs, FTP/SFTP, csv, Google Drive). Create new tables as needed (GCP – BigQuery). Build reports with BI tools and use business logic to turn the raw data into meaningful measures. Maintain SharePoint websites and build new additions as needed. Maintain security for internal file structure (Egnyte). Be able to creatively build new automation solutions as the needs arise. Work closely with our outsourced IT company. Qualifications Bachelor’s degree required. 3-5+ years of experience working with big data sets, ETL systems and automation. Strategic thinker with strong research and problem-solving skills. Strong analytical, organizational and time management skills. Experience leading and growing a team in a fast-growing company. Skills Python (data manipulation, automation, and ETL processes) SQL Excel Database management Google Cloud Platform Microsoft 365 (administration) Microsoft SharePoint Development BI Development (Sigma, Power Bi) - nice to have, but not necessary"
Data Engineer,Deck,Remote,https://www.indeed.com/rc/clk?jk=900b81d5fec46e2c&fccid=db68c933135c168b&vjs=3,"Deck is hiring a Data Engineer to build and maintain the data graph that powers our predictive models so the progressive movement can make better decisions on targeting and resource allocation. OUR MISSION We’re working to move the country in a more progressive direction by empowering the best candidates and organizations to run their best campaigns — even on a tight budget. With the 2022 midterm elections coming up, we're looking to grow our team. WHAT IS DECK? Deck gives Democratic campaigns and progressive organizations of all sizes access to personalized targeting and planning tools so they can run more effective outreach and advertising programs. We have a suite of products that help our users reach the right voters, fundraise more efficiently, launch targeted digital ads, and make better resource allocation decisions. OUR PRINCIPLES We have an opinion. Our product is strictly for Democratic campaigns and progressive organizations. We are transparent. The world of political analysis and tech is rife with overblown promises, opaque pricing, and lack of accountability. We hold ourselves to a high standard. We value diversity. We'll need to collectively bring a range of lived experiences and backgrounds to meet the needs of the candidates and advocacy organizations we intend to serve. We run a disciplined and focused business. We aim to establish a business that is financially sustainable and whose products and roadmap are fully aligned with our mission. Our investors share our mission and understand that it takes precedence over the more typical business metrics. We believe in the power of a small but mighty team. A team of passionate, independent, multi-talented builders can have more impact than much larger teams. THE ROLE The person in this role will: Build and maintain predictive models that will help our users reach the right voters and make better resource allocation decisions. Manage data pipelines to ensure that your models' training data and predictions are up-to-date and accurate. Develop systems to make your models and data pipelines visible across our team. Maintain systems to QA models and predictions so we can spot (and fix) problems quickly. Brainstorm and prototype ideas for new predictive models and data products. Develop documentation and visualizations to help our users (and your teammates) understand where our predictions are coming from. Our data stack is currently based around R, TensorFlow, Keras, BigQuery, Drake, Prefect, and the Tidyverse. Familiarity with some of these is a big plus. A track record of learning new tech quickly is a must! REMOTE ENVIRONMENT Deck is a remote organization. We will hire the best people from anywhere in the country and support a remote working environment that is flexible, transparent, and trusting. Occasional travel to conferences and in-person meetings will be required. COMPENSATION The salary for this role will be $125,000 per year. Deck offers a 401k, full health and dental coverage (including for family members), 20 days of annual PTO, 10 days of annual sick leave, 30 days of annual medical leave, and 20 weeks of fully paid parental leave. While we have no strict requirements for this role, we're generally looking for candidates with: At least several years experience doing technical work to support a live product. Demonstrated interest in progressive politics. Proficiency with SQL, R (including the Tidyverse), and machine learning. Comfort working with deep learning models. An ability to explain technical ideas to nontechnical audiences. A patient and collaborative attitude."
Data Engineer,Ortho Molecular Products,"Stevens Point, WI 54482",https://www.indeed.com/rc/clk?jk=5bbcf974dd7c2c66&fccid=77ad0679852a2124&vjs=3,"Overview Why Work at Ortho Molecular Products : The position is on-site at our Stevens Point, Wisconsin facility. The schedule is Monday through Friday from 8:00am to 5:00pm - this is not a remote opportunity. Responsible for providing analytic and technical skills to innovate, build, and maintain well-managed data solutions through Power BI. Will provide capabilities to solve business problems by providing dashboards and or data solutions to assist business units in monitoring performance metrics/insights. They maintain the Power BI data model and adjust the data model for new reporting needs. They are also responsible for providing training and leadership to data analyst. What to Expect : Responsible for providing data and metrics (including dashboards) in Power BI to the business units as requested Responsible for managing the Power BI data model, modifying the data model to accommodate new reporting requirements and investigating data issues with Power BI reporting Responsible for writing specs for new/revision to existing reports; documentation and testing prior to release to the business units Continually work with the user to collect reporting requirements, establish appropriate test criteria and work with manager to develop a solution if one does not exist Identify problem areas in the organization and develop a data solution through process improvement Analyze large amounts of data and report on trends/forecasts, assist with the design, development, and maintenance of the Analytic Datamarts including quality checks, identifying issues and working with partners to create solutions Create Key Performance Indicators for departments, develops advanced analytics solutions, test and design of historical and predictive analytics solutions to solve business problems What You Will Contribute : Bachelor’s degree or higher education 3 to 4 years Data Analyst experience preferred in a related field Advanced experience using Microsoft Excel, SQL, Data Warehouse with a strong understanding of Power BI and or dashboarding tools Demonstrated knowledge of how to create/improve business processes with ability to understand/perform business and functional requirement analysis Strong ability to write Excel formulas, apply statistical/analytical mathematical concepts to solve problems Experience with Power BI, Tableau or other data visualization software, SQL, DataMarts and ability to process data via PowerQuery and PowerAutomate CHARACTER QUALITIES: Thoroughness, Dependability, Orderliness, Persistence, Responsibility and Wisdom. Must be authorized to work in the U.S. as Sponsorship is not provided What You Will Receive : Competitive Compensation with Bonus Program Medical, Dental, Vision, Company Paid Life Insurance, and 401(k) with Employer Match Voluntary Benefits: Short Term Disability, Life, Critical Illness, Accident, & Hospital Indemnity Paid Time Off and Holiday Job Specific Training & Tuition Reimbursement Program Wellness & Employee Assistance Program, Gym Reimbursements, and Healthy, Company Paid Meals Free Monthly Products, Employee Discounts, and Employee Referral Incentives Simply put, our healthcare system is broken. It is expensive, complicated, and dysfunctional. At Ortho Molecular Products, our vision is to transform the practice of medicine. Every day, across America and the world, we help health care providers implement better solutions for health challenges that include lifestyle medicine and nutritional therapies proven to improve patient outcomes. We do this by manufacturing science-based products and developing innovative clinical programs for doctors that help their patients get better faster. We are looking for people who align with our mission and want to invest their lifework and passion into transforming the practice of medicine. Our team is purpose-driven, values-based, and service-focused. We are looking for likeminded people who want to join the movement that is changing the way healthcare is being delivered. Ortho Molecular Products honors the service of our military veterans and understands how that service translates to a successful career. We invite you to explore the Ortho website to learn about our career opportunities and apply. Ortho Molecular Products is an Equal Opportunity Employer."
AWS Data Engineer-Reporting,"Orpine, Inc. Internal",Remote in United States+6 locations,https://www.indeed.com/rc/clk?jk=125db4f0bbdc0587&fccid=7df81f4c05f8d55a&vjs=3,"Manager-Vani Location-Remote Proficient with AWS Data warehousing tools Proficient with Quicksight, Tableau or similar data visualization tools Comfort with data munging techniques and ETL platforms Strong SQL programming skills AWS Native Apps - S3, EC2, EMR, Lambdas etc. -Cloud Datawarehouse- Snowflake( Must) or AWS redshift. Atleast one Cloud DW project is must with Snowflake. Strong applied knowledge of basic statistical concepts and data best practices Demonstrated ability to produce scalable and repeatable analytic processes Demonstrated ability to partner with peers and leaders using strong written and verbal communication"
Junior Data Engineer,Tupl,"Dallas, TX",https://www.indeed.com/rc/clk?jk=4f4aabca81cc0df0&fccid=61920b3cc7c67747&vjs=3,"You will join our data engineering team and help Tupl to expand our big data automation platform within specific customer projects. Dallas/USA Full time Tupl is a tech company that develops market leading solutions that bring innovation to the backend system of cellular networks and many other verticals. We have a strong knowledge on Wireless communications and IT technologies, especially AI and Machine Learning. As part of our team, distributed between USA, Spain and Japan, you will have a unique opportunity to grow your professional career by helping us in the continued success of our business transformation software! Your main responsibilities Right now, Tupl is focused on creating use cases in the telecom segment, so telecom experience is always a plus. Below are the basic job duties for you: Design and implement data collection components to ingest different data sources into big data systems Design and implement ETL pipelines Identify ways to improve data reliability, efficiency and quality Collaborate effectively in cross-functional teams Develop, integrate, deploy and test any Big Data tools and frameworks required by the customer projects Contribute to team effort by accomplishing related results as needed Close interaction with customer in order to identify project scope, functional requirements, and timelines Required Technical Skills and Qualifications Bachelor’s degree in Computer Science, Applied Mathematics, Engineering, or any other technology related field. Understanding of data modelling, algorithms, and data transformation techniques are the basics to work with data platforms. Understanding of data science concepts. Hands-on experience with ETL tools. BI tools knowledge Big data technologies: Hadoop and Kafka. ML frameworks and libraries: TensorFlow, Spark, PyTorch, mlpack. Experience with Java, Python, R, C/C#, Golang. Teamwork and collaboration skills. Upper English Level What you will love about Tupl! A competitive salary and benefits 24 days of paid Time Off IRA with 3% matching Open and sharing environment where you will be exposed to bleeding edge technologies Remote work with international exposure and support to grow in your career Modern hardware like MacBook Pro and peripherals Disclaimer Tupl is committed to a diverse and inclusive workplace. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Data Engineer,Uplight,+1 locationRemote,https://www.indeed.com/rc/clk?jk=649cb0a1c70d7ed9&fccid=76670ee1307f6d9c&vjs=3,"The Position Do you dream about creating a more sustainable future? At Uplight, we are motivating energy users and providers to accelerate the clean energy ecosystem. We’re working with over 90 of the world’s leading electric and gas utilities to build the future platform for grid and energy management. Uplight delivers personalized experiences that customers have now come to expect – improving satisfaction, increasing revenue, reducing the cost to serve, and contributing to carbon reduction goals. We are a certified B Corp, enabling us to put our values into action by not only making decisions for the benefit of our shareholders, but also for our customers, environment, employees, and community. We are seeking a Data Operations Engineer to join our team and help us achieve our ambitious goals for our business and for the planet. We will consider this role for continued remote work with some work/travel to our offices in Denver, Boulder, Boston, Chicago or Vancouver. What you get to do: We are searching for a Data Operations Engineer with expertise in building and supporting big data systems that help utility companies and people reduce their energy usage and carbon footprint. You’ll work with our data ingestion team, platform team SRE and other stakeholders to ensure that our systems operate efficiently by resolving issues and proactively implementing stability and automation improvements. A focus for this position will be hands-on usage of a data mocking or masking tool to ensure that private customer data remains secure. Skills and experience are necessary, but we hire on value alignment first, so if you feel you would be a good fit with us, still consider applying. You should: Be excited to work with talented, committed people in a fast-paced environment. Be passionate about energy consumption and making a difference in the world. Be capable of prioritizing your work to adhere to a deliverable schedule and ensure successful delivery that exceeds expectations. Be ready, able and willing to collaborate with a partner or colleague to help solve problems. Have a strong eye for detail and quality of your code. Not be afraid to dig into hard problems, and enjoy experimenting to come up with simple, pragmatic solutions to solve them. What you bring to Uplight: You are an accomplished developer with 2-5+ years of professional experience. Google Cloud Platform (Preferred), AWS or other cloud service provider experience. Understanding of the agile software development lifecycle including: scoping, detailed design, effort estimation, implementation, debugging, maintenance and support. Demonstrable knowledge of how to write effective unit and functional tests. BS in Computer Science / Engineering or demonstrable industry experience. Bonus Points: Experience using a data masking or mocking tool such as Tonic or Mockaroo. Experience with Apache Airflow, Matillion, Python, Spark or other data engineering tools. Experience building data pipelines or ETL/ELT processes. Experience with cloud infrastructure and SaaS environments. What makes working at Uplight amazing: In addition to all the standard medical and dental benefits, that kick in Day 1, we are: Proud to be over 500+ rebels with an important cause by helping to create a more sustainable planet. Committed to the environment, our employees, and our communities Focused on career growth by following defined career ladders Committed to taking our work and mission seriously and.... we love to laugh! We also provide: 401k program with company matching Medical, vision, and dental insurance Monthly wellness stipend Peer to peer recognition program Management by objectives bonus program Innovative flexible time off policy Exceptionally collaborative and cool office spaces (once we reopen them) Salary Range: $115,000 to $135,000 In accordance with the Colorado Equal Pay for Equal Work Act, the approximate annual base compensation range is listed above. The actual offer, reflecting the total compensation package and benefits, will be determined by a number of factors including the applicant's experience, knowledge, skills, and abilities, as well as internal equity among our team. Uplight provides equal employment opportunities to all employees and applicants and prohibits discrimination and harassment of any type without regard to race (including hair texture and hairstyles), color, religion (including head coverings), age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws."
Data Engineer,Microsoft,"Bellevue, WA+5 locations",https://www.indeed.com/rc/clk?jk=8cf96fb6cdc14702&fccid=734cb5a01ee60f80&vjs=3,"Microsoft is a company where passionate innovators come to collaborate, envision what can be and take their careers to levels they cannot achieve anywhere else. This is a world of more possibilities, more innovation, more openness, and the sky is the limit thinking a cloud-enabled world. Microsoft’s Intelligence Platform engineering team is leading the transformation of analytics in the world of data with products like Power BI, Synapse Analytics, Azure Data Factory, Azure Data Explorer. We will bring the world’s data to the Microsoft Cloud, power a new class of data first applications, and empower everyone on the planet to make better decisions with data. We do not just value differences or different perspectives. We seek them out and invite them in so we can tap into the collective power of everyone in the company. As a result, our ideas are better, our products are better, and our customers are better served. The Data and Telemetry Platform team is building the infrastructure and tools to create, pipeline and consume the data that drives our services and business; from near real time monitoring to big-data solutions that support our internal and external customers. Responsibilities We are looking for data engineers that are also passionate about software and cloud engineering, to build the next-gen data service - based on the latest Azure data technologies, to enable quick insights from a rapidly growing volume of data. As a data engineer in the Data and Telemetry Platform Team you will be working on the infrastructure of the service. You will communicate and collaborate with architects, product managers and feature teams to provide core-platform components that support the creation, pipelining and consumption of data and telemetry. You will be designing, coding and testing data pipelines and models, as well as the production processes around them, such as deployment and health-monitoring. You will be using Microsoft and Azure technologies and will be responsible for the proper integration of these with our platform. Responsibilities include: Engaging with stakeholders, defining, and validating requirements Designing, developing and maintaining data pipelines and data models. Driving service improvements around ownership areas Reviewing and improving designs/code quality, security, compliance and other production requirements such as performance and scale. Investigating and integrating new workloads, technologies, etc., and working with stakeholders to apply the required changes. Participating in team’s live-site activities Qualifications Required Qualifications Bachelor’s degree in Computer Science or Engineering 1+ years working with big-data technologies such as – Azure Data Lake, Azure Databricks, SQL Data Warehouse Preferred Qualifications 1+ years of BI experience, working on data analysis and visualization with tools such as Power BI or Tableau Master’s degree in Computer Science or Engineering 1+ years of software development engineering, working with Java, C# or similar 1+ years of BI experience in an enterprise setting #azdat #msftintelplat Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form. Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work."
Data Engineer,FloSports,Remote,https://www.indeed.com/rc/clk?jk=3cc6a3aaa6119b4c&fccid=3e5db2de424b29e6&vjs=3,"FloSports has led the way in establishing a world-class digital streaming experience for millions of fans, families and athletes of over 25 different underserved sports. Imagine creating a digital platform that unites the casual fan with the most dedicated spectator, both experiencing thrilling live events from around the world with interactive features, real time analytics, powerful broadcast technology and more. Combine that with our unique original sports content ranging from breaking news and expert commentary to feature films, documentaries and multi-episodic series. That’s what FloSports is all about. We have successfully revolutionized the global sports media industry- the result of creating a diverse team of technologists and die-hard wrestlers, creators and devoted cheerleading experts, designers and hockey enthusiasts, communicators and motorsport fanatics, producers and casual sports fans… united by a shared passion to delight the underrepresented communities we serve. We are creating a home for underserved sports and we’re looking for people like you to help us! THE ROLE: FloSports is seeking an extraordinary Data Engineer to evolve our Content Management System into a system that can help FloSports meet our mission of being the essential destination for the sports that we serve. This position will work on a team to develop our database and API’s, create our CMS front-end ,and help establish our metadata patterns to both allow our fans to quickly access the information most important to them and to enable our content producers a first-class experience. To be successful in the position, the selected engineer will need to be highly collaborative, logical, and have an expert skill level in relevant technologies. RESPONSIBILITIES: Develop technical roadmap for evolving our CMS database. Work with team to establish metadata structures to fit all of the sports we serve. Coordinate with product, design, and other development teams to deliver the CMS front-end. Convert well defined product user stories into technical execution plans. KNOWLEDGE, SKILLS AND ABILITIES: BS or MS in Computer Science, Engineering, or a related technical discipline or equivalent experience (5+ years). Strong communication and collaboration skills. Ability to clearly identify the pros/cons of various database technologies. Deep expertise in at least one database technology (preferably strong in more than one technology). Experience developing RESTful API’s. Experience with unit and integration testing. Experience with PHP and/or Typescript. Experience working with cross-functional teams including web, mobile & other back-end teams. Preferred: Experience with Google PubSub or similar technology. Preferred: Experience implementing or refining an enterprise search platform. OUR COMMITMENT TO DIVERSITY: At FloSports, we are bonded by our passion for sports and our purpose to unite communities around experiences that finally give underserved sports the love they deserve. We recognize the need to build a company that seeks out, embraces, and celebrates our individual differences, ideas, and talent. FloSports is committed to the pursuit of a fair, equal and inclusive workplace where everyone is given the opportunity to grow to their fullest potential. As such, we are intentional in our hiring practices in an effort to overcome systemic biases we may be blind to. FloSports has adopted the “blind recruiting” process, which aims to open our opportunities up to more candidates, help us be more objective in how we review applicants and mitigate bias in our decision making processes. OUR BENEFITS: Recognized two years in a row as a Top Workplace by the Austin-American Statesman Flexibility at work - you can take control of your profession and personal schedule Strong remote work culture All-hands events hosted twice a year in beautiful Austin, Texas Annual equity awards for all top performers Competitive and comprehensive medical, dental and vision plans Peace of mind through company-paid short-term disability, long-term disability and life insurance Generous 401(K) company match vested immediately Progressive parental leave policies Unlimited paid time off Hack-a-thons and a full calendar of team-building and social events Free laundry service for all positions that require travel Company donation to youth teams and leagues that our employees coach Stocked snack bar, catered lunch and breakfast tacos every week"
Data Analytics Engineer (contract),Noodle,"Remote in New York, NY 10003",https://www.indeed.com/rc/clk?jk=5326265ce0d8ef9d&fccid=db056ec58d565514&vjs=3,"Data Analytics Engineer (contract) Online education is no longer a novel or niche idea. It is the fastest-growing segment in higher education, accounting for 20% of all enrollees and 35% of graduate-level certificates and degrees. It's also getting increasingly competitive, as more and better programs are launched each semester. Universities need to go online quickly, economically, and elegantly, creating programs that students can't wait to tell their friends about and that their professors want to teach. Noodle helps universities bring programs online with flexibility, transparency, alignment, efficiency, and joy. That's why more top universities chose us last year than all other online program managers combined. We are a passionate team of technologists, educators, and experts. Online learning has the potential to transform higher education; if you’re interested in being part of that journey, keep reading! About the Role: As a Data Analytics Engineer at Noodle, you would build analytics products to inform strategic decision making, both internally and for our university partners. Our products help senior leaders understand successes and opportunities across all parts of the student journey, from engagement with our online marketing materials through enrollment, all the way to graduation. As a Data Analytics Engineer (contract) at Noodle you will: Be responsible for collaboratively building data analytics pipelines and dashboards for multiple stakeholders. This includes… Translating high-level product requirements into technical requirements Identifying new data we need and developing ingestion processes Clarifying business rules and implementing them in code Transforming data using SQL to power our analytics products Writing automated tests, documenting your work, and reviewing others’ work Building Tableau visualizations to make data actionable Teaching stakeholders how to use your products and incorporating their feedback You have: Experience using git, complex SQL, and AWS to build and deploy data products Experience creating visualizations in Tableau Ability to work cross-functionally to iteratively develop data products and processes Experience analyzing data from digital marketing, CRM, SIS or LMS tools Experience using Python, dbt, AWS Athena, or CircleCI (Bonus) At Noodle, we hire people who will help us change the future of online education. Even if you don't think you check off every bullet point on this list, we still encourage you to apply! We value both current experience and future potential Noodle benefits: Work from our beautiful New York office! OR Work from the comfort of your home office! Competitive salary 401K + match, bonus potential, and equity opportunities Tools you need on us! Mac is our computer of choice Our insurance plan offers medical, dental, vision, short- and long-term disability coverage, plus supplementals for all employees and dependents 12 weeks paid Parental Leave Pre-tax commuter benefits 3 weeks paid vacation + paid holidays + paid sick leave Monthly Gym Reimbursement and Membership to premium medical services like One Medical and Eden Health Monthly cell phone reimbursement Annual education stipend for lifelong learning Growth - we pride ourselves on creating environments where employees can be themselves and grow within and around the company Noodle is committed to creating a welcoming and inclusive workplace for everyone. We value and celebrate our differences because those differences are what make our team shine. We hire great people from different backgrounds, not just because it's the right thing to do, but because it makes us stronger as a whole. Women, people of color, LGBTQIA2S+ individuals, and members of other underrepresented groups are strongly encouraged to apply. Noodle is an equal opportunity employer and does not discriminate against candidates on the basis of race, ethnicity, religion, sex, gender, sexual orientation, gender identity, disability status, or veteran status. Noodle won Built In NYC’s 100 Best Places to Work, Best Midsize Companies, and Best Perks & Benefits 2021, and 2022 and was named one of Crain’s 100 best places to work in NYC in 2021. #LI-Remote"
Data Engineer,Integral Ad Science,"Hybrid remote in New York, NY 10003+10 locations",https://www.indeed.com/rc/clk?jk=e6ff5a56fb00be97&fccid=1dc32badf02d6835&vjs=3,"Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry and we're looking for a Data Engineer to join our Data Engineering team. If you are excited by technology that has the power to handle hundreds of thousands of transactions per second; collect tens of billions of events each day; and evaluate thousands of data-points in real-time all while responding in just a few milliseconds, then IAS is the place for you! As a Data Engineer you will build and expand upon the testing framework and testing infrastructure of IAS' core ad verification, analytics and anti ad fraud software products. The ideal candidate is naturally curious, dedicated, detailed-oriented with a strong desire to work with awesome people in a highly collaborative environment. You should be able to not take yourself too seriously as well. What you'll do: Working on Big Data technologies such as Hadoop, MapReduce, Kafka, and/or Spark in columnar databases Architect, design, code and maintain components for aggregating tens of billions of daily transactions Lead the entire software lifecycle including hands-on development, code reviews, testing, deployment, and documentation for streaming and batch ETL's and RESTful API's Mentor junior team members Who you are and what you have: 5+ years of recent hands-on in object oriented language (Java, Scala, Python) Experience with Hadoop MapReduce, Spark, Pig Experience developing data pipelines in AWS or Google Cloud Strong knowledge of collections, multi-threading, JVM memory model, etc. Understanding of full software development life cycle, agile development and continuous integration Good knowledge of Linux command line tools What puts you over the top: Exposure to messaging frameworks like Kafka or RabbitMQ In-depth understanding of object oriented programming concepts and functional programming concepts Excellent interpersonal and communication skills Superb understanding of algorithms and data structures Experience of designing for performance, scalability, and reliability Good understanding of database fundamentals, good knowledge of SQL IAS strives to maintain a COVID-free workplace and the health and safety of our employees is a priority. IAS implemented a policy that requires all employees (with limited exceptions) to be fully vaccinated and provide proof of vaccination prior to employment, to the fullest extent permitted by applicable law. About Integral Ad Science Integral Ad Science (IAS) is a global leader in digital media quality. IAS makes every impression count, ensuring that ads are viewable by real people, in safe and suitable environments, activating contextual targeting, and driving supply path optimization. Our mission is to be the global benchmark for trust and transparency in digital media quality for the world's leading brands, publishers, and platforms. We do this through data-driven technologies with actionable real-time signals and insight. Founded in 2009 and headquartered in New York, IAS works with thousands of top advertisers and premium publishers worldwide. For more information, visit integralads.com or email us at careers@integralads.com. Equal Opportunity Employer: IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply. California Applicant Pre-Collection Notice: We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com. To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership. #LI-Hybrid"
Data Engineer,Instec Corp,Remote,https://www.indeed.com/rc/clk?jk=77625ede0d52469a&fccid=8232d107052198ba&vjs=3,"Description Who We Are Insurity is a leading property and casualty insurance software and data analytics provider, working with some of the world’s largest insurers, brokers, and MGAs, including 15 of the top 25 P&C carriers in the US. With 1400+ team members globally, 7 office locations, and 300+ customers, we have a deep understanding of the insurance business, unparalleled technology expertise, and a singular focus of delivering a simplified insurance experience to our customers. Insurity’s next Data Engineer This position will be part of a team whose primary responsibilities are working with data from our customers. Responsibilities include identifying, acquiring, validating, cleansing, and producing data and datasets to be used in advanced analytics and predictive modeling initiatives by our internal teams. This is accomplished by combining data processing experience with software engineering concepts into solutions that are hosted in our cloud-based platforms. This role will report into the Director of Data Development What You’ll Do Data imports/extraction, transformation, and cleansing Collaborating with data scientists, software engineers, product managers, subject matter experts and customers Managing and maintaining metadata Performance optimization: e.g. approaches to speed up lookups on extra-large datasets Identify opportunities for efficiencies by automating repetitive tasks and process workflows Documentation of processes and requirements Manage and facilitate projects from start to finish Who You Are 2+ years Data Engineering experience with TSQL, Python, or functional programming Bachelor’s degree in Computer Science, Programming, or related technical areas Experience with AWS services including S3 and Lambda Reporting/data warehousing experience Experience with Snowflake a plus JSON, XML and CSV and varying file format data experience Knowledge of insurance concepts is an advantage in understanding our business requirements Self-starter and ability to grasp concepts quickly Ability to work well in a team environment, while also having the ability to work autonomously Passion for continuous learning and digging into the fine details Our Benefits Collaborative Culture | Flexible Hours | Growth Opportunities Day 1 Health Insurance Coverage | Open PTO Does Insurity sound like the right place for you? Send us your application and a cover letter highlighting what sets you apart from the nice-to-haves and makes you a must-have for our team! Thank you for your interest in Insurity! Please understand that due to the volume of applicants we receive, only selected candidates will be contacted. Insurity is proud to be an Equal Opportunity Employer We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. #LI-REMOTE"
Assoc Data Engineer,"The Travelers Companies, Inc.","Hartford, CT+23 locations",https://www.indeed.com/rc/clk?jk=cbe437d1e32bde06&fccid=614604a6208fa23b&vjs=3,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $77,000.00 - $127,100.00 Target Openings 1 What Is the Opportunity? The Bond & Specialty Insurance Finance Department is looking for a self-motivated Assoc Data Engineer to provide support for our Financial Data Management group. Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As an Associate Data Engineer you will aid in growing and transforming our analytics landscape. You will leverage your ability to rapidly grasp and design new technologies, as well as your creativity and curiosity to capture, explore and transform data to support Artificial Intelligence, Machine Learning and business intelligence/insights. This also includes supporting business and financial applications, as well as downstream system feeds and external reporting. This position requires working closely with IT teams in an Agile environment as well as with various business partners. This individual will be expected to become an expert in transactional financial data for Bond & Specialty Insurance front-end systems, financial applications, and system feeds. What Will You Do? Build rudimentary data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions. Assist in the operationalization and automation of data products. Analyze common sources to determine value and recommend data to include in analytical processes. Interact and collaborate with team and business users to support delivery and educate end users on data products/analytic environment. Perform data and systems analysis, assessment and resolution for defects and incidents. Test data movement, transformation code and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Two years of related experience Developing knowledge of tools, techniques, and manipulation including Cloud platforms, programming languages, and software engineering practices. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. One year of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/ ."
Data Engineer II,Spiceworks,+12 locationsRemote,https://www.indeed.com/rc/clk?jk=05733e17403b740e&fccid=1d28766f4d0bf6ff&vjs=3,"Who You Are: We are looking to hire a mid-level data engineer to join our dynamic engineering team. You will be a part of a global data engineering team, spread across the various United States and India based SWZD offices, and will play a key role in enabling our data-driven strategy. As a Data Engineer, you’ll work closely with Product Managers, Finance and Business Analysts, Data Scientists, and Software Engineers as you help define our data development roadmap. Eager to jump into a pivotal role that's essential in enabling data-informed decisions? It’s time to apply! Who We Are: Spiceworks Ziff Davis is a global organization with a work from anywhere approach to getting the job done. We help the world’s businesses find, adopt, and manage the latest technologies. We also help technology brands build, market, and sell better products and services. Millions of technology buyers and hundreds of brands later, we’ve built the platforms they use to get their jobs done and make them better at what they do, every day. the SWZD ecosystem to touch over 90% of all technology spending...Think about the impact of that! We are uniquely positioned to offer our clients (top international companies such as HPE, IBM, Adobe, and SAP) unmatched visibility into in-market accounts by leveraging our scale, quality, and broad spectrum of B2B data. Unparalleled access to the world’s most influential technology buyers combined with proprietary algorithms and cutting-edge analytics enables SWZD the leader in intent-backed, intelligent, omnichannel marketing. What You’ll Do: Collaborate with product team and contribute to software design Partner or lead in the development of self-monitoring, robust, scalable, batch and streaming ETL processes Develop and improve the continuous integration and testing processes Perform root cause analysis on external and internal processes and data to identify opportunities for improvement and answer questions Contribute to the consolidation of our data and empower other teams to derive value from our warehouse ecosystem Work closely with stakeholders on the data supply side (e.g. application engineers) and data demand side (e.g., BI analysts, data scientists, product managers, and other engineering teams) Ensure data privacy and compliance (GDPR), as well as maintaining data dictionaries for governance purposes What You Need: Bachelor’s or master's in engineering, computer science, or related field preferred 3+ years of experience delivering data pipelines and managing resulting data stores (experience with Snowflake Data Warehouse, Redshift a plus) Academic or work Experience applying analytic skillsets Working on structured and unstructured datasets Hands on experience in Python Understanding of building data models, SQL and query optimization Experience using managed cloud services (AWS preferred) Experience with one or more orchestration technologies (Matillion, Snowflake, Pyspark, Redshift, Athena, Airflow, Talend, Kinesis, Hive, Firehose, Kafka ..) Experience identifying and resolving performance and data quality issues Experience in data gathering, technical project planning and communicating with stakeholders Experience working in agile/scrum development environments Perks and Benefits Unlimited flexible time off Volunteer paid time off Generous holidays Recognition Programs - yes there are multiple, AND prizes! Remote-first work experience and a work from anywhere culture Weekly coffee chats with leaders Wellness and mindfulness programs Career advancement opportunities Sick days Generous Paid Parental Leave Bi-weekly Townhalls Regional holiday celebrations Community give-back celebrations Transportation Assistance for night-shift employees Unwavering commitment to diversity and inclusion Employee stock purchase program ...and more!"
Data Engineer,Cygnet Global Resources,"Union, NJ",https://www.indeed.com/rc/clk?jk=b88490344f9c4baf&fccid=dd616958bd9ddc12&vjs=3,"Job Description Job Description At Bed Bath & Beyond, we are working to transform the company to make it a data driven organization. To get there we need exceptionally talented, bright and driven people. We are looking for passionate Data Engineers to join our Data & Analytics team to create and own data pipelines and develop innovative data solutions in Google Cloud Platform. Key Responsibilities: Develop end to end scalable data applications and data pipelines. Automate the data ingress, data quality checks and final table builds. Develop optimal SQL queries and scripts for business logic implementation. Basic Qualifications: 3+ years of experience in Java or Python for Data Processing. 3+ years of SQL experience in building data transformations. 3+ years of experience with Unix / Linux including shell scripting. 1+ year of experience in Google Cloud Platform – Composer, BigQuery. Preferred Qualifications: Experience with Hadoop stack – Spark / Hive / Hbase. Experience developing cloud applications and understanding of design for scalability. Experice with requirements gathering and data modelling. Knowledge of relational database techniques, data warehouse concepts and architecture. Bachelor’s Degree in Information Systems, Computer Science or related field. Industry IT Services Salary 180000 City Union State/Province New Jersey Country United States Zip/Postal Code 07083"
Data Engineer,SimulStat,Remote,https://www.indeed.com/rc/clk?jk=f705683265de9b0c&fccid=8637215ace5fab49&vjs=3,"Apply Now Long-Term, Remote FSP role The Data Engineer is responsible for the development and implementation of optimal solutions to transform, integrate, store, secure, process and update large real-world healthcare data assets for use by statistical programmers, data scientists and other data analysts. Relevant database administration experience includes: Extensive knowledge of developing data pipelines using real-world healthcare data including claims and electronic medical records. Experience with one or more of the following commercial databases: MarketScan, Optum, DRG, Flatiron, JMDC, CPRD. Experience with the OMOP data model and optimization of healthcare data for observational research or epidemiology analysis use cases. Familiarity with medical coding, such as ICD-9, ICD-10, LOINC, NDC, CPT/HCPCS, SNOMED. Familiarity with big data processing platforms including Hadoop, AWS S3 and Databricks. Experience with enterprise support models for data management, security, database programming, service delivery, performance monitoring, and user support standards. Experience with conversion of raw data in ASCII or other formats into OMOP, Parquet or others, and storage in HDFS or S3. Troubleshooting data errors and developing mitigation plans. Strong communication and documentation skills for describing issues with data and potential remedies. Experience with database tuning techniques such as normalization, indexing, and parallel processing technologies is desirable as is experience with scripting languages such as Unix shell scripts and PERL. Additional responsibilities include the following: Ensuring data are consistent across the database Minimizing redundancy across the database Checking variable values for reasonableness Develop database tools to improve database efficiency and utility Building data pipelines for access to research data Managing vendor relations and communication Basic Qualifications: Bachelor’s degree in in Computer Science, Statistics, Mathematics, Life Sciences or other relevant scientific subject. Minimum 5 years relevant data asset curation experience (description above) Extensive experience using the OMOP common data model and ETLs Excellent SAS programming skills and the ability to implement complex data step logic and SQL. Experience with ETL software Experience with real world healthcare data, such as MarketScan, Optum, PharMetrics, Medicare and/or EMR databases Preferred Qualifications: Master’s degree in Epidemiology, Biostatistics, Computer Science, or other subject with high statistical content Eight (8) or more years relevant data asset curation experience (description above) Proficiency with Python is highly desired as well as ability to implement and troubleshoot complex ETL and QC programs. Experience in a regulated environment Vendor relations management Pharmaceutical industry experience Training or experience with the Hadoop database platform and Impala or Hive SQL Experience in software development & design life cycle, ideally using Agile methodology Experience using ODBC (Open Database Connectivity) Knowledge: Computer programming with SAS, R, Python or other procedural languages Database transformation, testing, cleaning and quality control using SQL Understanding of computer operating systems, including cloud-based Databricks and UNIX Software development and design Key Competencies: Technical excellence Innovation Teamwork Problem solving Attention to detail Oral and written communication Apply Now"
Data Engineer,Reliable Robotics,"Remote in Mountain View, CA 94043",https://www.indeed.com/rc/clk?jk=128725ea92b27c06&fccid=a14367aef85963f7&vjs=3,"We believe aircraft should fly themselves. Automated aviation systems will enable a future where air transportation is safer, more convenient and fundamentally transformative to the way goods — and eventually people — move around the planet. We are a team of mission-driven engineers with experience across aerospace, robotics and self-driving cars working to make this future a reality. As a Data Engineer at Reliable Robotics, you will be a part of the Production and Supply Chain team. The team is a small, but growing, team of smart, creative and highly driven individuals who help our engineering teams focus on the right work at the right time. As a key member of this team, you’ll play a critical role where you are responsible for gathering data and performing advanced analytics, creating infrastructure and data pipelines, developing predictive models, and making data applications that enable cross functional teams to leverage a wealth of construction productivity, scheduling strategy, and critical path data efficiently in multiple programs and initiatives. As Reliable Robotics continues to grow and scale, you’ll help ensure our continued success by providing accurate and actionable data in a way that is simple to consume with reliability to enable key business decisions. In this role, you will engage with various cross-functional teams to develop systems and tools for Executive Leadership, Engineering, Program Management, HR, and Production to visualize live metrics on progress while creating financial and productivity models to identify potential risks early on. You will also work with teams to continuously find improvements to minimize their time spent on data entry, enabling more productive time. You’ll help us uncover bottlenecks as well as highlight key successes that can be repeated. As a Data Engineer at Reliable, you’ll have the ability to positively impact a wide range of teams and stakeholders. Basic Success Criteria Bachelor’s degree in computer science, data science, physics, mathematics, or a STEM discipline 2+ years of professional, or educational/intern experience in analytics, data science, data engineering, or software engineering Development experience with SQL, Python, or other programming languages Data visualization veteran, familiar with tools and techniques such as Superset, Plotly, Tableau, Power BI Familiarity/understanding of REST APIs Strong collaboration and analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail, accuracy, and confidentiality Preferred Criteria Extensive experience writing software with Python Experience with multiple databases and pipeline tools (e.g., MySQL, MicrosoftSQL, Oracle, MongoDB, Kafka, Hadoop, HBase, Spark) Experience with data visualization techniques and tools (e.g. Superset, Tableau) and web application experience preferred Knowledge of various data communication protocols (e.g., REST API, gRPC, WebSockets) Experience using Git, Teamcenter, JIRA, Lever, or other program management solutions Experience working in a start-up environment, managing multiple competing priorities, and collaborating across multiple, cross-functional teams You’ll bring a consultative approach to soliciting requirements that answer the right questions and you’ll provide creative solutions when data is imperfect, or captured in disparate systems. You’ll leverage your expertise in data analytics and best practices to build solutions that are accurate, actionable, and scalable. Open to remote employment. Travel is minimal but could include occasional trips to the office in Mountain View, CA as needed. The estimated salary range for this position is $81,000 to $171,500. At Reliable Robotics, we strive to provide competitive and rewarding compensation based on experience and expertise, as well as market conditions, location, and pay equity. In addition to base compensation, Reliable Robotics offers stock options, employee medical, 401k contribution, great co-workers and a casual work environment. Reliable Robotics does not presently sponsor candidates for employment visas. In order to comply with export control regulations applicable to our technology and products, all candidates for this position must reside in the United States and be “U.S. persons” for purposes of the Export Administration Regulations (i.e., a U.S. citizen, a lawful permanent resident, or lawfully admitted into the U.S. as refugees or granted asylum in the U.S.) or otherwise eligible to access our technologies without an export license. At Reliable Robotics, our goal is to be a diverse and inclusive workforce. As an Equal Opportunity Employer, we do not discriminate on the basis of race, religion, color, creed, ancestry, sex, gender (including pregnancy, childbirth, breastfeeding, or related medical conditions), gender identity, gender expression, sexual orientation, age, non-disqualifying physical or mental disability or medical conditions, national origin, military or veteran status, genetic information, marital status, or any other basis covered by applicable law. All employment and promotion is decided on the basis of qualifications, merit, and business need. If you require reasonable accommodation in completing an application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to work@reliable.co"
Data Analytics Engineer,HealthVerity,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=5f011c0915f75fa7&fccid=6b1be984647e492b&vjs=3,"How you will help As a Software Engineer on the Discovery Team, you will be tasked with empowering our users to delve deep into the complexities of the data in our warehouse. Our team is uniquely charged with telling the full story of HealthVerity’s platform by highlighting the interoperability of data across hundreds of sources and showcasing the powerful insights that our data provides. You will work closely with Product and Engineering teams to build scalable data pipelines and design data analytics engines that empower deep insights for our customers. What you will do Work with a team of developers to execute strategies, implement solutions and produce peer reviewed quality software Build and optimize map-reduce pipelines to empower data discovery Design analytics engines that provide fast insights at-scale Mentor and train engineers on best practices in big data Leverage AWS serverless tooling to expose internal microservices via APIs and run asynchronous workflows Improve the software development process using Agile best-practices Our tech stack The Discovery team leverages the following technologies in our day-to-day development process: Spark, Python, Scala, Databricks, AWS Elastic Map-Reduce (EMR), Docker, PostgreSQL, Redis, ElasticSearch (AWS OpenSearch), AWS ECS, Serverless Framework, OpenAPI Specification, Datadog, Jenkins You are... An experienced technologist who has worked with large datasets Excited to create high quality products Knowledgeable in databases and can speak about uses cases for different types Knowledgeable in cloud services, especially AWS A team player who invests in interpersonal relationships and values shared goals Willing to work across the full software stack and learn new technologies Security conscious and understand the importance of data integrity and patient privacy Desired skills and experience 3+ years experience working with distributed data processing (Spark, Hadoop, Databricks, AWS EMR, AWS Glue/Athena) 3+ years experience writing code for data analytics/processing in a language such as Python, R, or Scala Strong command of SQL querying and optimizations Experience with programming Notebooks (ex Jupyter, Zeppelin, Databricks, R-Studio, Google Colab, or similar) AWS experience (serverless technologies, preferred) Comfortable with a UNIX-based command line environment 4+ years experience with version control system (Git, preferred) About HealthVerity At HealthVerity we are actively solving some of the greatest challenges in healthcare through innovative technology and data solutions. Our customers and partners including pharmaceutical manufacturers, payers and government organizations look to HealthVerity to partner on their most complicated use cases, leveraging our transformative technologies and real-world data infrastructure. The HealthVerity IPGE platform, based on the foundational elements of Identity, Privacy, Governance and Exchange, enables the discovery of RWD across the broadest healthcare data ecosystem, the building of more complete and accurate patient journeys and the ability to power best-in-class analytics and applications with flexibility and ease. To learn more about the HealthVerity IPGE platform, visit www.healthverity.com. Why you'll love working here We are making a difference – Our technology is at the forefront of some of the biggest healthcare challenges in the world. We are one team – Our people define our culture and always will. We take time out to celebrate each other at the end of every week through company-wide shout outs, and acknowledge the value that each of us adds towards our greater mission. Come share all you have to offer. We are learners – Every team member is continually learning, no matter if we've been in a role for one year or much longer. We are committed to learning and implementing what is best for our clients, partners, and each other. Benefits & Perks Compensation: competitive base salary & annual bonus opportunity (for non-commissioned roles) Benefits: comprehensive benefits with coverage on Day 1, medical, dental, vision, 401k, stock options Flexible location: our HQ is in Philadelphia with 50% of the team distributed across 25+ states Generous PTO: Take time off as needed, targeted at 4 weeks per year, including vacation, personal and sick time, plus paid maternity and paternity leave. Comprehensive and individualized onboarding: mentorship program, departmental talks, and a library of resources are available beginning day 1 for each new team member to minimize the stress of starting a new job Professional development: biweekly 1:1s, hands-on leadership that is goal-and growth-oriented for each team member, and an annual budget to support professional development pursuits HealthVerity is an equal opportunity employer devoted to inclusion in the workplace. We believe incorporating different ideas, perspectives and backgrounds make us stronger and encourages an environment where ageism, racism, sexism, ableism, homophobia, transphobia or any other form of discrimination are not tolerated. At HealthVerity, we’re working towards an innovative and connected future for healthcare data and believe the future is better together. We can only do that if everyone has a seat at the table. Read our Equity Inclusion and Diversity Statement. If you require a reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to careers@healthverity.com HealthVerity offers in-office and remote options, so you can work from anywhere within the US! #LI-Remote"
Data Engineer,Mercy Ships,"Garden Valley, TX 75771",https://www.indeed.com/company/Mercy-Ships/jobs/Data-Engineer-e9deb52b7c1d3a89?fccid=a9f382760ebf49b6&vjs=3,"Summary: Responsible for supporting Mercy Ships departments in their data modeling, warehousing, integration and business intelligence needs. Also assists in the execution of Mercy Ships' data architecture strategy. This includes: data analysis and/or integration product support and training, knowledge worker support, data source identification and classification, data inventory maintenance, supporting departments in data quality efforts, and application of data governance policy, process and procedures.Description:Essential Duties and Responsibilities (Include But Not Limited To)To perform this job successfully, an individual must be able to perform each essential duty satisfactorily: Supports departments in the use of their data and development of insights and interoperability by providing expert knowledge in data analytics and/or data integration. Work with data owners to determine, develop and support data goals and requirements. Develop models and processes for the management and leveraging of Mercy Ships data assets. Design, build, deploy and support data analysis or integration packages as assigned. Consult with the Data Architect and Data Services Manager on issues pertaining to the effectiveness of data architecture, integration and data management Prepare, administer and deliver training as required. Research and advise on emerging data management and analysis trends, products and methodologies Job Type: Full-time Pay: $70,000.00 - $75,000.00 per year Benefits: Dental insurance Health insurance Health savings account Life insurance Paid time off Referral program Vision insurance"
Junior Data Engineer,GitLab,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=85389079e52acab4&fccid=d8c987644cc029b0&vjs=3,"The GitLab DevOps platform empowers 100,000+ organizations to deliver software faster and more efficiently. We are one of the world’s largest all-remote companies with 1,600+ team members and values that guide a culture where people embrace the belief that everyone can contribute. Location - This position is 100% remote, based in APAC. The Data Engineer job family is focused on an analytical and business-oriented mindset with the ability to implement rigorous database solutions and best practices in order to produce and influence the adoption of strong quality data insights to drive business decisions in all areas of GitLab. The Data Engineer job family is essentially software engineers who have a particular focus on data movement and orchestration. Don’t have a ton of knowledge about GitLab yet? Don’t worry. We have an extensive onboarding and training program at GitLab and you will be provided with necessary DevOps and GitLab knowledge to fulfill your role. What you'll do in this role... Maintain our data platform with timely and quality data Build and maintain data pipelines from internal databases and SaaS applications Create and maintain systems documentation Write maintainable, performant code Implement the DataOps philosophy in everything you do Plan and execute system expansion as needed to support the company's growth and analytic needs Collaborate with Analytics Engineers and Data Analysts to drive efficiencies for their work Collaborate with other functions to ensure data needs are addressed This position is always central and reports to the Manager, Data We're looking for... Experience using Python, Java, or Scala for data processing (Python preferred) Knowledge of and experience with data-related Python packages Good understanding of SQL and analytical data warehouses Share and work in accordance with our values Constantly improve product quality, security, and performance Desire to continually keep up with advancements in data engineering practices Collaborate with team members to identify requirements, define successful outcomes, and deliver trusted results Catch bugs and style issues in code reviews Ship small features independently Ability to use GitLab Also, we know it’s tough, but please try to avoid the ​​confidence gap​.​​ You don’t have to match all the listed requirements exactly to be considered for this role. Hiring Process To view the full job description and hiring process, please view our​ ​handbook​ . Additional details about our process can also be found on our ​hiring page​. #LI-MG1 Country Hiring Guidelines: GitLab hires new team members in countries around the world. All of our roles are remote, however some roles may carry specific location-based eligibility requirements. Our Talent Acquisition team can help answer any questions about location after starting the recruiting process."
Data Engineer,Amazon.com Services LLC,+126 locationsRemote,https://www.indeed.com/rc/clk?jk=460cce461bec5669&fccid=fe2d21eef233e94a&vjs=3,"Bachelor’s/Masters degree in Computer Science or related technical field, or equivalent work experience. 4+ years of work experience with ETL, Data Modeling, and Data Architecture. 2+ years of work experience with Python, Scala or other scripting languages. Knowledge of AWS services including S3, Redshift, EMR, Kinesis and RDS. Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.) Knowledge of distributed systems as it pertains to data storage and computing Job summary AWS Support is one of the largest and fastest growing business units within AWS. We are a highly technical, innovative organization revolutionizing the customer engagement processes and offers topnotch technical support for the portfolio of products and features of AWS. We are determined to redefine the word “Support” and lead the industry with best in class technology. We are looking for an excellent Data Engineer who is passionate about data and the insights that large amounts of data sets can provide. You should possess both a data engineering background and a business acumen that enables you to think strategically. You will experience a wide range of problem solving situations requiring extensive use of data collection and analysis. The successful candidate will work in lock-step with BI Engineers, Data scientists, ML scientists, Business analysts, Product Managers and other stakeholders across organization. You will: Develop and improve the current data architecture, data quality, monitoring and data availability. Collaborate with Data Scientists to implement advanced analytics algorithms that exploit our rich data sets for statistical analysis, prediction, clustering and machine learning Partner with BAs across teams to build and verify hypothesis to improve the AWS Support business. Help continually improve ongoing reporting and analysis processes, simplifying self-service support for customers Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data sets of customer experience on AWS. Experience in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies. Experience with building data pipelines and applications to stream and process datasets at low latencies. Experience handling data - tracking data lineage, ensuring data quality, and improving discoverability of data. Knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures. Experience with native AWS technologies for data and analytics such as Redshift Spectrum, Athena, S3, Lambda, Glue, EMR, Kinesis, SNS, CloudWatch, etc. The base pay range for this position in Colorado is $132,090 - $178710/yr; however, base pay offered may vary depending on job-related knowledge, skills, and experience. A sign-on bonus and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. Applicants should apply via Amazon's internal or external careers site. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Associate Data Engineer,EAB,+3 locationsRemote,https://www.indeed.com/rc/clk?jk=1cee470797581f62&fccid=a168335bbdcce5e0&vjs=3,"#LI-Remote About EAB At EAB, our mission is to make education smarter and our communities stronger. We work with more than 2,500 institutions to drive transformative change through data-driven insights and best-in-class capabilities. From kindergarten to college to career, EAB partners with leaders and practitioners to accelerate progress and drive results across five major areas: enrollment, student success, institutional strategy, data & analytics, and diversity, equity, and inclusion (DE&I). We work with each partner differently, tailoring our portfolio of research, technology, and marketing and enrollment solutions to meet the unique needs of every leadership team, as well as the students and employees they serve. At EAB, we serve not only our partner institutions but each other—that's why we are always working to make sure our employees love their jobs and are invested in their communities. See how we've been recognized for this dedication to our employees by checking out our recent awards. For more information, visit our Careers page. The Role in Brief: Associate Data Engineer Are you a data enthusiast who seeks to tease out meaning from complex data flows and assets? Are you a talented problem solver who can transform abstract problems into elegant technical solutions? We are looking for a Data Engineer to join our team of engineers and data analysts focused on designing, creating, and delivering data solutions as part of our state-of-the-art cloud based products. The successful candidate will have the opportunity to build a world-class solution to help our higher education clients solve challenging problems through data Open to remote or can be based in one of our EAB locations; Washington, DC., Richmond, VA., or Birmingham, AL. Primary Responsibilities: Responsible for translating functional requirements and processes into scaled solutions through logical implementation of code (e.g., SQL, python) Responsible for data modeling and schema design that will range across multiple business domains within higher education Partner with multiple stakeholders including clients, new product development, BI engineers to develop scalable standard schemas Work with clients to research and conduct business information flow studies Codify high-performing SQL for efficient data transformation Coordinate work with external teams to ensure a smooth development process Support operations by identifying, researching and resolving performance and production issues Basic Qualifications: Experience working with relational or multi-dimensional databases, including statistical and business intelligence solutions. Demonstrated mastery in database concepts through technically accurate representation of functionally meaningful data Foundational knowledge and eagerness to expand skills in SQL Proven ability to work with stakeholders to define requirements and a clear understanding of data-generative processes Excellent analytic and troubleshooting skills Strong written and oral communication skills Ideal Qualifications: Experience working in an AGILE environment Experience developing commercial software products Proven ability to synthesize complex topics into intuitive and generalizable taxonomies Demonstrated mastery of large-scale database implementations and design patterns Experience developing ETL processes Demonstrated mastery in one or more SQL variants: PostgreSQL, MySQL, Oracle, SQL Server, or DB2 Experience developing logical data models within a data warehouse Experience with AWS infrastructure (Lambda, Python, Aurora DB) Familiar with Snowflake database Experience working with BI Platforms such as: Tableau, PowerBI, etc. etc. GIT expertise Commitment to valuing diversity, practicing inclusive behaviors, and contributing to an equitable working and continual learning environment in support of EAB’s DE&I Promise If you’ve reached this section of the job description and are unsure of whether to apply, please do! At EAB, we welcome diversity of background and experience. We would encourage you to submit an application if this is a role you would be passionate about doing every day. Benefits: Consistent with our belief that our employees are our most valuable resource, EAB offers a competitive and inclusive benefits package. Generous PTO annually, in addition to paid firm holidays Daytime leave policy for community service or fitness activities (up to 10 hours a month each) Paid parental leave for birthing or non-birthing parents Phase Back to Work program for employees returning from parental leave Adoption or surrogacy assistance Dynamic growth opportunities with merit-based promotion philosophy ___________________________________________________________________________________________________________________________ At EAB, we believe that to fulfill our mission to “make education smarter and our communities stronger” we need team members who bring a diversity of perspectives to the table and are committed to fostering a workplace where each team member is valued, respected and heard. To that end, EAB is an Equal Opportunity Employer, and we make employment decisions on the basis of qualifications, merit and business need. We don’t discriminate on the basis of race, religion, color, sex, gender identity or expression, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law."
Data Control Engineer,Schneider Electric,"Cedar Rapids, IA 52404",https://www.indeed.com/rc/clk?jk=873101a19a8e2f3b&fccid=8dc4399ddb463d4a&vjs=3,"Job Description: Schneider Electric has an opportunity for a Data Control Engineer in our Cedar Rapids, IA location. The products supported in this role include circuit breakers but can be expanded into support of systems using other products also. What will you do? Designing, developing, and modifying data infrastructure to accelerate the process of data analysis and reporting Reviewing graphs, tables, and documents to ensure accuracy and quality Close collaboration with internal stakeholders as well as 3rd parties Evaluating and implementing database changes and updates as required by the business What qualifications will make you successful? Proven leadership and negotiation skills Solid understanding of test activities for electronic devices Excellent verbal and written communications Ability to collaborate with local and remote teams Ability to analyze, interpret, and organize large amounts of data In-depth understanding of modern database and information technologies Thorough understanding of data management duties such as collection, analysis, and distribution Desired Skills: Experience and/or exposure to certain test standards Experience and/or exposure to achieving product certification Experience with MS Office Experience with test management software (External) English Qualifications: Who will you report to? Lab Technical Manager Let us learn about you! Apply today. (External) English Company Boiler Plate: Why us? Schneider Electric is leading the digital transformation of energy management and automation. Our technologies enable the world to use energy in a safe, efficient and sustainable manner. We strive to promote a global economy that is both ecologically viable and highly productive. €25.7bn global revenue 137 000+ employees in 100+ countries 45% of revenue from IoT 5% of revenue devoted for R&D You must submit an online application to be considered for any position with us. This position will be posted until filled It is the policy of Schneider Electric to provide equal employment and advancement opportunities in the areas of recruiting, hiring, training, transferring, and promoting all qualified individuals regardless of race, religion, color, gender, disability, national origin, ancestry, age, military status, sexual orientation, marital status, or any other legally protected characteristic or conduct. Concerning agencies: Schneider Electric does not accept unsolicited resumes and will not be responsible for fees related to such."
Data Engineer,"JPMorgan Chase Bank, N.A.","Newark, DE 19713+27 locations",https://www.indeed.com/rc/clk?jk=9162b9978cceadb4&fccid=aaf3b433897ea465&vjs=3,"As a member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally. This role requires a wide variety of strengths and capabilities, including: BS/BA degree or equivalent experience Advanced knowledge of application, data, and infrastructure architecture disciplines Understanding of architecture and design across all systems Working proficiency in developmental toolsets Knowledge of industry-wide technology trends and best practices Ability to work in large, collaborative teams to achieve organizational goals Passionate about building an innovative culture Proficiency in one or more modern programming languages Understanding of software skills such as business analysis, development, maintenance, and software improvement Preferred Qualifications: Experience in working with/on data warehouses, data modelling, ETL/ ELT and SQL. Experience with Spark and Hadoop ecosystem. SQL performance tuning. Experience with reporting tools like Tableau, Cognos etc. JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management. We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs. The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment. As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law. Equal Opportunity Employer/Disability/Veterans"
Senior Data Engineer,ADT Security Services,"Irving, TX 75063 (Freeport/Hackberry area)+2 locations",https://www.indeed.com/rc/clk?jk=0d942ca21613855a&fccid=27a2140ddcca6697&vjs=3,"ADT LLC is seeking to employ one nonimmigrant worker (H-1B classification) in the position of a Senior Data Engineer in the occupational classification of Database Architect SOC code: 15-1199.06. The salary range for this position is from $114,234.00 to $140,000.00 per year. The period of employment shall be for approximately three years, beginning as soon as July 4, 2022, and the H-1B worker will be employed at ADT LLC, 8880 Esters Boulevard., Irving Texas 75063. The labor condition application is available for inspection at ADT LLC, 1501 Yamato Road, Boca Raton, Florida 33431. Complaints alleging misrepresentation of material facts in the labor condition application and/or failure to comply with the terms of the labor condition application may be filed with any office of the Wage and Hour Division of the United States Department of Labor. ADT LLC is seeking to employ one nonimmigrant worker (H-1B classification) in the position of a Senior Data Engineer in the occupational classification of Database Architect SOC code: 15-1199.06. The salary range for this position is from $114,234.00 to $140,000.00 per year. The period of employment shall be for approximately three years, beginning as soon as July 4, 2022, and the H-1B worker will be employed at ADT LLC, 8880 Esters Boulevard., Irving Texas 75063. The labor condition application is available for inspection at ADT LLC, 1501 Yamato Road, Boca Raton, Florida 33431. Complaints alleging misrepresentation of material facts in the labor condition application and/or failure to comply with the terms of the labor condition application may be filed with any office of the Wage and Hour Division of the United States Department of Labor."
Big Data Engineer,Apexon,"Remote in Menomonee Falls, WI+16 locations",https://www.indeed.com/rc/clk?jk=c3de10fd26e587c0&fccid=784ed0ea1f56bb8a&vjs=3,"Our Client is looking for a Big Data Engineer, this role will sit 100% Remote. Kindly go through the requirement and let me know your thoughts to move forward Job Title: Big Data Engineer Location: Remote Duration: Long Term contract Required Skills: Python, SQL Job Description: Responsible for: • Collaboration through frequent pair programming • Regular retrospectives to figure out what is being done wrong so it can be fixed, and what is being done right so the team can improve on it. • Test Driven Development. Requires: • Strong knowledge building development practices like CI/CD, Test Automation and cloud deployments • Knowledge of build management tools such as Jenkins or Maven • Demonstrated understanding of source control systems such as GIT • Database Design experience including either SQL, PL/SQL • Implementing ETL process with Big Data Technologies • Required: Spark, Python, Scala and Airflow • Preferred: MapReduce, Pig, Hive, Kafka, Sqoop, and Flume • Experience working with distributed caching technologies such as REDIS • Experience in designing and creating automation workflows and execution • Knowledge of Apache Airflow Developing DAG, Performance tuning of the DAGs and task implementation • Good understanding of MPP databases such as Teradata and Netezza • Experience and/or interest in Test Driven Development (TDD) and agile methodologies • Strong communication skills and interest in a pair-programming environment • Passion for growing your skills, tackling interesting work and complex problems • Experience deploying to cloud environments. GCP preferred (BigQuery, DataProc) • 3+ years of relevant work experience • BA/BS in Computer Science or related field, or equivalent experience Regards, Viduth | Mobile: +1 248 603 2674 | Desk: +1 248 313 4594 | Email: Viduth.Selvan@technosoftcorp.com Technosoft Corporation |One Towne Square, Suite 600 Southfield, MI 48076 |www.technosoftcorp.com |"
Data Engineer - Remote,Syngenta,"Remote in Downers Grove, IL",https://www.indeed.com/rc/clk?jk=5e029974070f682b&fccid=212d266bb52619f8&vjs=3,"About Syngenta Syngenta is a global leader in agriculture; rooted in science and dedicated to bringing plant potential to life. Each of our 28,000 employees in more than 90 countries work together to solve one of humanity’s most pressing challenges: growing more food with fewer resources. A diverse workforce and an inclusive workplace environment are enablers of our ambition to be the most collaborative and trusted team in agriculture. Our employees reflect the diversity of our customers, the markets where we operate and the communities which we serve. No matter what your position, you will have a vital role in safely feeding the world and taking care of our planet. Join us and help shape the future of agriculture. About Us Syngenta is changing the agriculture industry and we want you to be part of that. Digital innovations, data and new technologies will transform the way that crops are managed in the future and enable farmers and agronomists to enhance efficiency and sustainable food production. You will help to develop solutions that turns data into meaningful information and ultimately helps to grow more food with fewer resources. This is a Remote role but must be living in the US.. You will help meet the world’s most pressing needs by: Accountabilities Create and maintain optimal data pipeline architecture, assemble large, sophisticated data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Big Data technologies. Experience in developing data integration processes through any of the tools/techniques like Mulesoft Anypoint, Informatica, AWS Glue, Data Stage, Azure Data Factory. Build analytics tools that utilize the data pipeline to deliver impactful insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with partners including the Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Ensure the scalability and end-user friendliness of design decisions Perform testing at various levels including unit testing and end-to-end testing Guide customers through user acceptance testing of their data integration solution Communicating prompt and professional responses to requests from clients Work with product teams to understand the data needs and build integration to make sure the data flows between the applications seamlessly. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader Qualifications. Requirements 8+ years of hand on experience in as Data Engineer or Data Analyst or Data Specialist or Data Architect role who has attained a bachelor’s degree in computer science, Information Systems. 3+ years of experience with AWS Glue or Informatica or Data stage or Azure Data Factory. 3+ years of hands-on experience of Python programming, Spark programming with object-oriented/object function scripting languages. 3+ years of experience in any of the data warehousing platform like AWS redshift or Azure Synapse or Snowflake or Google Bigquery. Experience with data integrations for various applications with strong SQL skills. Preferred Requirements Experience in any of the Business Intelligence or analytics tools like Qlik Sense or Tableau or PowerBI will be a plus. What We Offer: A culture that celebrates diversity & inclusion, promotes professional development, and strives for a work-life balance that supports the team members. offers flexible work options to support your work and personal needs Full Benefit Package (Medical, Dental & Vision) that starts your first day 401k plan with company match, Profit Sharing & Retirement Savings Contribution Paid Vacation, 9 Paid Holidays, Maternity and Paternity Leave, Education Assistance, Wellness Programs, Corporate Discounts, among other benefits Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status. Family and Medical Leave Act (FMLA) (http://www.dol.gov/whd/regs/compliance/posters/fmla.htm) Equal Employment Opportunity Commission's (EEOC) (http://webapps.dol.gov/elaws/firststep/poster_direct.htm) Employee Polygraph Protection Act (EPPA) (http://www.dol.gov/whd/regs/compliance/posters/eppa.htm) #LI-SB2 #LI-Remote"
Associate Data Visualization Engineer,Cato Institute,Remote,https://www.indeed.com/company/Cato-Institute/jobs/Associate-Data-Visualization-Engineer-cf6ba215a2a4384d?fccid=d1e2d1178f64beb3&vjs=3,"Description: As an Associate Data Visualization Engineer, you will join our Digital Team and use your analytical skills to scrutinize and visualize diverse datasets. You will investigate datasets for findings, and more importantly create compelling and informative data visualizations. You will help the organization discover new data opportunities with diverse internal and external datasets, in diverse functions from donor outreach to policy analyses.In addition to your immediate colleagues on the digital team, you will work with a diverse group of policy research scholars, and various other teams in the production workflow such as publications and social media teams.You will clean, organize, and analyze datasets and use your programming skills to visualize data for external publications, web content, and social media content of the Cato Institute. Finally, you will learn and apply cutting edge methods in data visualizations for the web.Company Overview: The Cato Institute is a public policy research organization – a think tank – dedicated to the principles of individual liberty, limited government, free markets, and peace. Its scholars and analysts conduct independent, nonpartisan research on a wide range of policy issues.Founded in 1977, Cato owes its name to Cato’s Letters, a series of essays published in 18th-century England that presented a vision of a society free from excessive government power. Those essays inspired the architects of the American Revolution. And the simple, timeless principles of that revolution – individual liberty, limited government, and free markets – turn out to be even more powerful in today’s world of global markets and unprecedented access to information than Jefferson or Madison could have imagined. Social and economic freedom is not just the best policy for a free people, it is the indispensable framework for the future.Cato Institute is an Equal Opportunity Employer.Responsibilities Find, organize, and analyze policy data in diverse research areas, including economics, education, healthcare, and immigration. Come up with ways to visualize data: design data charts, graphs and maps to convey findings. Collaborate with fellow web programmers; web, UX and graphic designers. Collaborate with policy research scholars, publication, and social media teams. Create primarily web-based data visualization tools and dashboards. . Requirements: Experience in data analysis. Fluency in programming (in one of the major programming languages like Python, R, C++). Hands-on knowledge of Microsoft Excel/Google Sheets. Experience in data visualization with diverse charts and maps. Demonstrated enthusiasm to learn and collaborate. Preferred Qualifications Bachelor’s degree or equivalent in computer science, economics, statistics, data science, mathematics, or other fields that require strong quantitative skills. Fluency in Python. Fluency in web programming (HTML, CSS, JavaScript). Strong familiarity / fluency in diverse data formats (CSV, XML, JSON) and SQL. Familiarity / experience working with a CMS (such as Drupal or WordPress). Familiarity / experience with data-dashboarding platforms, BI tools (such as Tableau, Qlik, PowerBI, Plotly etc.). Familiarity / experience with version control software (Git). Experience with data visualization libraries designed for the web (such as D3). Familiarity with, and an appreciation for, libertarian principles. Keen attention to detail. Education and Prior Experience No prior work experience required. Job Type: Full-time"
Data / BI Engineer,TARGET,"Brooklyn Park, MN 55445 (Oak Grove area)",https://www.indeed.com/rc/clk?jk=894029e93456b2e9&fccid=15f43d82dc901ff2&vjs=3,"JOIN US AS A DATA / BI ENGINEER About us: As a Fortune 50 company with more than 350,000 team members worldwide, Target is an iconic brand and one of America's leading retailers. Target as a tech company? Absolutely. We’re the behind-the-scenes powerhouse that fuels Target’s passion and commitment to cutting-edge innovation. We anchor every facet of one of the world’s best-loved retailers with a strong technology framework that relies on the latest tools and technologies—and the brightest people—to deliver incredible value to guests online and in stores. Target Technology Services is on a mission to offer the systems, tools and support that guests and team members need and deserve. Our high-performing teams balance independence with collaboration, and we pride ourselves on being versatile, agile and creative. We drive industry-leading technologies in support of every angle of the business, and help ensure that Target operates smoothly, securely and reliably from the inside out. As an Engineer, you serve as a technical specialist delivering the engineering that powers the product. You develop keen insight into the technical architecture and design to deliver robust and scalable software components. You constantly demonstrate the depth of your expertise by solving engineering problems. You are passionate about the quality of software and balance between speed of delivering new features and robustness of the software components you implement. You can handle operational issues with little or no oversight. You actively review code to ensure the software quality and functional accuracy is maintained across the team. You are keen to learn the design and architecture of the product and participate in ceremonies that can influence both. Use your skills, experience and talents to be a part of groundbreaking thinking and visionary goals. As an engineer, you’ll take the lead as you… Use your technology acumen to provide input to assist with evaluation of new technologies and contribute to the design, lifecycle management, and total cost of ownership of services. Contribute to research and proof-of-concept initiatives for new technologies and assist with code review and design review, writes, organizes and maintains code based on designs. With guidance, delivers high-performance, scalable, repeatable, and secure deliverables. Participate in structured construction, automation, debugging, and implementation activities, ensuring architectural and operational requirements and best practices are met. Participate in disaster recovery planning and disaster recovery activities and participate in functional integration and regression testing and ability to automate test scripts. Resolve frequently encountered technical issues and monitors systems capacity with minimal assistance. Search and understand metadata about various data sources and metrics. Adhere to change and incident management standards and expectations. Core responsibilities are described within this job description. Job duties may change at any time due to business needs. About you: 4 year degree or equivalent experience 1+ years of software development experience Demonstrates familiarity with current and emerging technologies in own scope of responsibility, and develops ability to apply these technologies Understands concepts of package solutions and package specific programming language with knowledge of development objects Demonstrates and continuously builds upon domain-specific knowledge Demonstrates proficiency in at least one computer language Understands the concepts of distributed programming and applies it to their domain Possesses working knowledge of transaction codes/master data used within specific domain and participates in building custom solutions in the package Maintains technical knowledge within areas of expertise Stays current with new and evolving technologies via formal training and self-directed education Americans with Disabilities Act (ADA) Target will provide reasonable accommodations (such as a qualified sign language interpreter or other personal assistance) with the application process upon your request as required to comply with applicable laws. If you have a disability and require assistance in this application process, please visit your nearest Target store or Distribution Center or reach out to Guest Services at 1-800-440-0680 for additional information. Qualifications:"
Data Engineer,Maximo Global Tech,Remote,https://www.indeed.com/rc/clk?jk=6d21a0baa7f7814a&fccid=6cea0d277d8a065b&vjs=3,"Job Location Remote Type of Job Full Time Published Date April 25, 2021, 5:00:00 AM Job Description Requirements Experience with Python and packaging your code Familiarity with using Jupyter Notebooks for Exploratory Data Analysis Experience with web automation and scraping. Anything from bookmarklets to frameworks like Scrapy Ability to query data using SQL queries or using ORM libraries such as SQLAlchemy Basic knowledge of Git; Specifically using feature branches as part of your workflow Strong desire to pursue broadening and deepening technical knowledge Our Desired Skills and Experience: Able to share at least one project that demonstrates your technical expertise Familiarity with modeling data and writing database schemas Experience using JavaScript (ES6) and modern frameworks such as a React to build web applications along with build tools such as webpack Knowledge of either Bash or PowerShell scripting Experience writing configurable Dockerfiles"
Data Engineer,Virtusa,"Irving, TX 75061 (Plymouth Park area)+5 locations",https://www.indeed.com/rc/clk?jk=5fcf9164c8d240fc&fccid=146443e77d8c0778&vjs=3,"Detailed Job Description: 3-5 years of experience in IT Industry Extensive development using Java Spark, Big Data technologies. Hands on Experience in Big Data technologies Hadoop, Spark, NoSQL Understanding Business Requirements and Functional Requirements and Involved with implementation of end to end solutions, Design and build scalable infrastructure and platform to ingest, store and process very large amount of data, Collaborate with various data source teams on effective strategies for data ingestion, Experience in Agile SDLC, JIRA, Bitbucket or Git is a PLUS, SQL knowledge and fine query fine tuning capabilities are is a PLUS, Knowledge of database design techniques and experience working with extremely large data volumes is a PLUS Primary Location : US-TX-Irving Schedule : Full Time Employee Status : Executive Job Type : Experienced Travel : No Job Posting : 17/06/2022, 3:59:42 PM"
Project Engineer - Master Data Management,FedEx Logistics,"Remote in Miami, FL 33126+5 locations",https://www.indeed.com/rc/clk?jk=e48d42b12d3103e9&fccid=c10d511b96782b65&vjs=3,"Company: FedEx Logistics Job Title: Project Engineer - Master Data Management Job Requisition Number: RC528100 Time Type: Full Time Job Type: Regular Primary Job Posting Location: Remote United States Additional Locations: 170 Cooper Avenue Tonawanda, New York 14150 United States 15022 132nd Avenue New York, New York 11434 United States 701 Waterford Way Miami, Florida 33126 United States 1101 Busse Road Elk Grove Village, Illinois 60007 United States 17210 S Main St Gardena, California 90248 United States Posting Date: 2022-06-14 Job Posting End Date: 2022-06-21 Colorado Residents Only – Compensation: Monthly Salary $6510.8 - $12353.8 The estimate displayed represents the typical salary range or starting rate of candidates hired in Colorado. Factors that may be used to determine your actual salary may include your specific skills, your work location, how many years of experience you have, and comparison to other employees already in this role. This information is provided to applicants in accordance to the Colorado Equal Pay for Equal Work Act. This role will lead in maintaining data integrity and following MDM standards in our Freight Forwarding applications. Quality data management is at the heart of our ability to turn data into an asset. Only standardized, non-duplicated, accurate and complete data can effectively serve global operations. You’ll work with our internal IT teammates, as well as our Operations and Finance teams, to assist with application settings, reference data, reports, workflow engine and various other duties supporting users in more than 50 countries worldwide. Responsibilities: This role will lead in maintaining master data and settings within our freight forwarding system (Cargowise One). This role will provide standards, governance and stewardship, data processes, and will oversee application configuration settings. Maintenance and Management of the MDM in the freight forwarding system includes: Application configuration settings Ongoing maintenance of reference data and security settings. Responsible for developing standards, guidelines, processes and expertise to consistently address recurring master data issues. Engaging and collaborating with leaders and peers in evolving Master Data Management within the organization's applications and processes Assist with mass updates or downloads of data for special projects Customization of documents and reports Work with application Workflow configurations Participate in testing of new releases in the system Knowledge and Experience Bachelor’s Degree in Industrial Engineering or a related engineering discipline. Five (5) years professional or related experience. Experience in Logistics and familiarity with CargoWise One is required. Strong sense of urgency and quality awareness in a fast-paced business environment, with the ability to multi-task, problem solve, and prioritize Must be a strong self-starter able to work independently under limited supervision and meet deadlines. Ability to build a consensus and to work through others in achieving desired results and objectives. Ability to analyze varying stakeholder concerns, proactively working with diverse groups to address concerns SPECIAL SKILLS: Must speak English fluently Must be proficient in Excel. Experience with SQL and ability to perform queries preferred Very detail-oriented and able to look thoroughly through extensive data sets determining patterns and issues #LI-Remote This position will be remote. #LI-Remote FedEx Logistics provides freight forwarding, as well as import and export services that allow companies to reach markets throughout the world. They help customers of all sizes solve the intricacies of shipping goods globally by providing comprehensive international ocean and air freight forwarding, surface transportation and distribution, customs brokerage, trade and customs advisory services, and advanced e-commerce and trade facilitation solutions. We're glad you stopped by and hope your job search experience with FedEx Logistics, Inc. will be rewarding. We look forward to hearing from you! FedEx Logistics, Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to their protected veteran or disability status. FedEx Logistics, Inc. participates in the Department of Homeland Security U.S. Citizenship and Immigration Services' E-Verify program (For U.S. applicants and employees only). Please ready the E-Verify Notice available in English (https://e-verify.uscis.gov/emp/media/resourcesContents/E-Verify_Participation_Poster.pdf) and Spanish (https://e-verify.uscis.gov/emp/media/resourcesContents/E-Verify_Participation_Poster_ES.pdf) before proceeding with your job application. Click here to read the Right to Work Notice available in English (http://ftn.fedex.com/careers/OSC_Right_to_Work_Poster.pdf) and Spanish (http://ftn.fedex.com/careers/OSC_Right_to_Work_Poster_ES.pdf). Additional information about the E-Verify program can also be found at www.uscis.gov. The Company offers a comprehensive benefits package including health, dental, and vision care coverage, retirement savings, vacation pay, holiday pay, sick time, and life insurance to eligible employees. Pay Transparency Policy Statement: The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless required to do so by law or the FedEx Logistics Legal Department. Import Notice to All Applicants: FedEx Logistics is engaged in an industry regulated by federal law that prohibits it from employing convicted felons. Therefore, it must determine whether applicants have been convicted of felonies before a hiring decision is made. A criminal background check will be required of all selected applicants before a hiring decision is made. Equal Employment Opportunity: As a federal government contractor, we are committed to employ and promote qualified minorities, females, individuals with disabilities, and covered veterans (including, but not limited to, disabled veterans, recently separated veterans, Armed Forces service medal veterans, and other protected veterans. Our philosophy and commitment to equal employment opportunity and non-discrimination is the bedrock to job opportunities for all employees and applicants without regard to an individual's protected status (i.e. race/ethnicity, color, national origin, ancestry, sex/gender, gender identity/expression, sexual orientation, marital/parental status, pregnancy/childbirth, or related condition, religion, creed, age, disability, genetic information, veteran status, or any other protected status.) Click here and here to read more about ""Equal Employment Opportunity is the Law."" FedEx Logistics will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the FAIR Chance Initiative for Hiring Ordinance (FCIHOO) for the City of Los Angeles (LAMC 189.00) FedEx Logistics will not rely on the wage history of a prospective employee from any current or former employer when determining the wages for such individual at any stage in the employment process, including in the negotiation or drafting of any employment contract in accordance with Philadelphia Ordinance No. 160840."
Data Engineer,OSF HealthCare,"Peoria, IL 61603 (Downtown Peoria area)",https://www.indeed.com/rc/clk?jk=f17ada1d3216c7f7&fccid=9e81960f779f634e&vjs=3,"Overview: This position could offer work-from-home option that is open to those who reside in Illinois 65+ miles from Peoria, IL or for those that do not reside in the State of IL (dependant on location of candidate). POSITION SUMMARY: The Data Engineer maintains database architecture and metadata that support the Enterprise Data Ecosystem (EDE). Develops, tests and maintains data curation processes necessary to extract data from source systems and transform data according to business needs. Evaluates data reusability and works with Data Architect to review data usage to structure data for better management and quicker access. Supports project initiatives for process improvement and performance tracking. Qualifications: REQUIRED QUALIFICATIONS: Bachelors Degree computer science, math or engineering related. Epic Clarity data model fundamentals training is required within 90 days of employment and certification within 6 months of employment. Certification must be maintained as new version training is released. 1 year experience in Information Technology. 1 year progressively complex experience in ETL, SQL, and programming. Experience in data warehousing and/or business intelligence. PREFERRED QUALIFICATIONS: 1 year progressively complex experience in Informatica PowerCenter. 1 year Teradata experience. Experience with other technologies common to OSF Healthcare environment, Epic Systems preferred. Strong understanding of statistics and/or analytical methodologies. Experience with agile and rapid development processes. Working knowledge of ETL tools; preferrably Informatica PowerCenter. Working knowledge of datamart and multi-dimensional data structures. EOE/Minorities/Females/Vet/Disabled Job seekers will be afforded equal opportunity regardless of their race, ethnicity, veteran status or disability status."
NGS Data Quality Engineer,National Football League,"Remote in Inglewood, CA 90301",https://www.indeed.com/rc/clk?jk=1726d4c7158fb93a&fccid=85ac7fb3b19d15f1&vjs=3,"Whether you are looking to join our NFL League office in New York City, NFL Films office based in Mt. Laurel, New Jersey, the NFL Media offices in Inglewood, California or one of our international offices, on your journey you will be met with the excitement that comes with working for the NFL. We consider ourselves to be stewards of the game of football and most importantly, we consider working for the NFL to be fun. There is a fulfillment unlike any other that comes from working alongside like-minded individuals to achieve a common purpose. Whether you are working to deliver a memorable Super Bowl or play a hand in the process of delivering games to millions of fans on Sundays— we believe all of us play an important role in helping to fulfill the NFL’s mission of working to unite people and inspire communities. Summary The NFL's Next Gen Stats team is seeking associates for its player tracking project to help with game data review and verification. Candidate will work closely with Next Gen Stats engineering team by assisting the team in reviewing all plays during live games in preseason and on Sundays during regular season, ensuring data is correct and making necessary changes when it is not. The ideal candidate for this position loves football and enjoys immersing themselves in data and finding insights. Candidates must be self-motivated and available on Sundays for the entirety of the season (Aug-Jan). NOTE: This is a remote position on Sundays only during the NFL season. Essential Functions Review and verify data on all plays during live games Ensure all plays have data and video mapped properly Confirm player participation on a play-by-play basis Confirm all advanced statistics are created post play Make necessary changes to data when incorrect using in house developed web-based tools Required Education and Experience Strong football knowledge Must be computer savvy (Chrome, Slack, Google Docs/Sheets, Zoom, etc.) Detail-oriented and reliable Strong problem solving and analytical skills Preferred Education and Experience Hands on experience with data manipulation a plus Other Key Attributes / Characteristics This is a remote position. Must work game days during preseason (Thu-Sun) and Sundays during regular season. Candidates must be available for all 18 Sundays during regular season. A reliable internet connection is required, everything else will be supplied. All applicants must be eligible to work in the United States. No relocation or visa sponsorship is available for this position. Travel: None Expected Hours of Work 4 hours per game / 8 hours on Sundays The NFL maintains a Flexible Workplace Policy that provides members of our workforce with opportunities to periodically work from a location of their choice, while maintaining a priority on in-person work at an NFL office, which enables us to more effectively collaborate, connect and build a workplace culture that will drive our continued success. We also continue to prioritize the health and safety of our NFL workforce. Consistent with that commitment, considering the substantial and growing body of evidence that vaccinations remain the most effective protection against the spread the COVID-19, we require that members of our NFL workforce be fully vaccinated. Exceptions are available only for those who need an accommodation for a qualifying disability or sincerely held religious belief or practice. The NFL is committed to building a diverse, equitable and inclusive work environment that reflects our incredibly diverse fan base. We provide an environment of mutual respect where equal employment opportunities are available to all employees and applicants without regard to status as protected by applicable federal, state, or local law."
Scientific Data Engineer,Merck,"Boston, MA+1 location",https://www.indeed.com/rc/clk?jk=309030ee2a339573&fccid=c38b7d5e0419a6a7&vjs=3,"Job Description Our IT team operates as a business partner proposing ideas and innovative solutions that enable new organizational capabilities. We partner internationally to deliver the services and solutions that help everyone to be more productive and enable innovation. The Scientific Data Engineer is accountable for the design and development of software products in the Modeling and Simulation (M&S) Products Group of the Scientific Data Consumption Product Line. The M&S Products consist of the Modeling Platform, the Machine Learning Platform, and “experience” products delivering broad scientific modeling and machine learning capabilities. Tasks include gathering and reviewing technical requirements, design and development of code, and working with vendor partners to deliver products serving multiple business groups. This technical role requires knowledge and experience in both computer science and life sciences research to delivering solutions supporting pharmaceutical research. A thorough comprehension of data consumption approaches and platforms across a broad range of research activities is essential. The position will require a high level of familiarity and comfort working with the research organization. The Scientific Data Consumption Product Line (SDC) provides a combination of technology, infrastructure, software and personnel to support large scale scientific data consumption and computing comprising of the Scientific Data Platform, Modeling and Machine Learning Platforms, High Performance Computing (HPC) workflows, and “experience” products such as visualization, modeling workbenches, and analytics development environments. Primary job tasks include: Work with the Scientific Data Consumption Product Leads, Technical and Squad Leads to drive Business value through development and delivery of data and modeling software products Work with scientists to design scientific data and modeling products and integrations with commercial platforms such Databricks or Sagemaker We are seeking professionals with the following qualifications, skills and experience: Education Minimum: B.Sc. in computer sciences, engineering, or scientific disciplines Qualifications: Technical Skills: Expertise in developing, debugging and tuning software application built on traditional stacks (Java, Spring, Tomcat, etc.) and Cloud services in particular Amazon Web Services Experience in Database products (SQL Server, Oracle, Redshift) Expertise in building complex, highly available and scalable enterprise web applications Experience with Web Services and RESTful APIs Proficiency in LINUX operating systems Ability to architect, engineer, optimize and maintain software solutions to solve complex scientific problems Demonstrated ability to clearly convey technical and non-technical information verbally and in writing Demonstrated ability to work with a diverse group of professionals globally Required Experience: 3+ years in developing enterprise grade applications 2+ years in information technology support of the life sciences/pharmaceutical or other high technology industry Hands-on experience with cloud platforms (in particular AWS) Preferred: Knowledge of Machine Learning platforms and approaches (e.g. Databricks or Sagemaker) Thorough comprehension of technologies in support of data science Has used data driven methods to analyze and solve business problems Has worked with Agile methodologies and principles to drive development work Ability to present demos to users UI development experience with HTML, AJAX, Javascript/JQuery and similar technologies Knowledge of development on High Performance Computing systems Mindset Passionate in driving continuous improvement to improve delivery efficiency and practices Drive to deliver reusable and configurable solutions to enable the product line vision Keen interest in cloud and evolving technologies to help design, architect and build better solutions for our Company Passionate about modern data management, consumption and modelling capabilities and products Our Support Functions deliver services and make recommendations about ways to enhance our workplace and the culture of our organization. Our Support Functions include HR, Finance, Information Technology, Legal, Procurement, Administration, Facilities and Security. Who we are … We are known as Merck & Co., Inc., Rahway, New Jersey, USA in the United States and Canada and MSD everywhere else. For more than a century, we have been inventing for life, bringing forward medicines and vaccines for many of the world's most challenging diseases. Today, our company continues to be at the forefront of research to deliver innovative health solutions and advance the prevention and treatment of diseases that threaten people and animals around the world. What we look for … Imagine getting up in the morning for a job as important as helping to save and improve lives around the world. Here, you have that opportunity. You can put your empathy, creativity, digital mastery, or scientific genius to work in collaboration with a diverse group of colleagues who pursue and bring hope to countless people who are battling some of the most challenging diseases of our time. Our team is constantly evolving, so if you are among the intellectually curious, join us—and start making your impact today. NOTICE FOR INTERNAL APPLICANTS In accordance with Managers' Policy - Job Posting and Employee Placement, all employees subject to this policy are required to have a minimum of twelve (12) months of service in current position prior to applying for open positions. If you have been offered a separation benefits package, but have not yet reached your separation date and are offered a position within the salary and geographical parameters as set forth in the Summary Plan Description (SPD) of your separation package, then you are no longer eligible for your separation benefits package. To discuss in more detail, please contact your HRBP or Talent Acquisition Advisor. MRLITPM New hires in office-based roles in the US & Puerto Rico will be required, subject to applicable law, to demonstrate that they have been fully vaccinated for COVID-19 or qualify for a medical or religious exemption to this vaccination requirement that can be accommodated without an undue burden to the operation. However, subject to applicable law, employees working in roles that the Company determines require routine collaboration with external stakeholders, such as employees in health services, customer facing commercial, or research based roles, will be required to be fully vaccinated as a condition of employment. US and Puerto Rico Residents Only: Our company is committed to inclusion, ensuring that candidates can engage in a hiring process that exhibits their true capabilities. Please click here if you need an accommodation during the application or hiring process. Pay Transparency Nondiscrimination We are proud to be a company that embraces the value of bringing diverse, talented, and committed people together. The fastest way to breakthrough innovation is when diverse ideas come together in an inclusive environment. We encourage our colleagues to respectfully challenge one another’s thinking and approach problems collectively. We are an equal opportunity employer, committed to fostering an inclusive and diverse workplace. Search Firm Representatives Please Read Carefully Merck & Co., Inc., Rahway, NJ, USA, also known as Merck Sharp & Dohme LLC, Rahway, NJ, USA, does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position specific. Please, no phone calls or emails. Employee Status: Regular Relocation: No relocation VISA Sponsorship: No Travel Requirements: 10% Flexible Work Arrangements: Shift: Valid Driving License: Hazardous Material(s): Number of Openings: 1 Requisition ID:R186511"
Data Engineer,Thrive Causemetics,Remote,https://www.indeed.com/company/Thrive-Causemetics/jobs/Data-Engineer-f2f90acb959fb811?fccid=79f1ecf266761465&vjs=3,"Who We Are Thrive Causemetics is Bigger Than Beauty™: We are an independent, female-owned beauty brand that creates high-performance vegan cosmetics and supports a community of giving. All of Thrive Causemetics' products are free of parabens and sulfates, in addition to being 100 percent cruelty-free. Through its Bigger Than Beauty™ program, every product you purchase results in a donation to help a woman thrive. Thrive Causemetics is dedicated to fostering a collaborative and cross-functional workplace where everyone’s voice matters. We are committed to being pioneers in creating a culture of wellness. Together, we prioritize a strong work ethic while maintaining a positive, exciting environment where people are passionate about what they do. *Who We Are Looking For* We are looking for a Data Engineer who loves hands-on-keyboard work that has high impact and visibility. You have owned ETL and ELT pipelines in the past and are comfortable moving data from sources to sinks using automated tools like Airflow. Core Responsibilities: Develop and automate large scale, high-performance data processing systems (batch and/or streaming) to drive Thrive Causemetics business growth Evangelize high-quality software engineering practices toward building data infrastructure and pipelines at scale Lead data engineering projects to ensure pipelines are reliable, efficient, testable, and maintainable Design our data models for optimal storage and retrieval and to meet critical product and business requirements Understand and influence logging to support our data flow, architecting logging best practices where needed Contribute to shared Data Engineering tooling & standards to improve the productivity and quality of output for Data Engineers across the company Qualifications: Intermediate to Advanced level Python experience Fluency in SQL Comfortable writing DAGs in Airflow Comfortable working with AWS data stack: CRUD operations on S3 and Redshift Comfortable working with GCP data stack: CRUD operations with BigQuery and Google Storage Comfortable working with containerized environments: Docker and GHCR. Writing Docker images should be something you’ve done in your day to day Can write and utilize Github Actions Can create pipelines from API calls to data tables to BI tools and/or endpoints Nice to Haves: Experience creating data models for retail and/or ecommerce companies Fluency in at least one other open-source data engineering language (e.g. Scala or Go) End-to-experience deploying simple machine learning models Experience implementing a data mesh or working within a data mesh architecture Why Thrive Causemetics? Robust compensation package 401k & up to 4% company match Comprehensive medical, vision, and dental benefits Life Insurance Policy at no cost Employer paid Short-term disability & Long-term disability plans at no cost Employee Assistance Program Diversity, Equity, & Inclusion training Employee discount Health & Wellness Workshops Mental health resources; Calm app provided for free Remote team get togethers and opportunities to participate at company Giving events As required by C.R.S. 8-5-201(2): (Colorado only) The minimum pay for this role is $113,000. Actual compensation packages are based on a wide array of factors unique to each candidate, including but not limited to skill set, years & depth of experience, certifications and specific office location. This may differ in other locations due to cost of labor considerations. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire. Thrive Causemetics is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate with regards to race, color, religion, national origin, gender identity, gender expression, sex, sexual orientation, genetic information (including characteristics and testing), age, marital status, military and veteran status, status as an individual with a disability (physical and/or mental), and any other characteristic protected by applicable law. Job Type: Full-time"
Data Engineer,Consumer Edge,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=b9e1a72249a8c0c2&fccid=4119a53133fe0567&vjs=3,"Consumer Edge is the leading provider of consumer data for some of the largest hedge funds, venture capital and private equity firms, and corporations in the United States and Europe. We arm our clients with actionable consumer, competitive, and market insights that drive better investment and strategic decisions. Position Summary Consumer Edge is at its crux a data company. We deal with collecting, aggregating, wrangling, modeling, and then surfacing important data that our clients use to make business-driving decisions. That means that our Data Engineering team sits at the center of the business and plays a huge role in its success. Data Engineers at CE own and are responsible for the entire data lifecycle: ingestion, ETL, warehousing, and reporting. We are data pipeline builders and data wranglers who enjoy optimizing data systems and building them from the ground up. We are looking to add another person to our team that will own every single piece of a data stack and be able to plug and play at every single step of the way. We support CE's Developers, Product team, Data Analysts and Data Scientists on data initiatives and we ensure optimal data delivery architecture is consistent throughout ongoing projects. Responsibilities For Data Engineer Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using a combination of SQL, GCP, and open-source big data' technologies. Communicate insights and recommendations to key stakeholders, engineering, data science and product partners Work in a supportive team that offers engineers the flexibility to be creative and chase interesting ideas Work closely with the product manager, end-users and stakeholders to understand, document, troubleshoot and analyze requirements for complex data solutions Design and build data integration methods to guarantee accuracy as well as accessibility of all valuable data while understanding what data is important for the business and why. Provide technical assistance and cross training to other team members and help with operational data needs when required Participate in data architecture and engineering decision making/planning Qualifications For Data Engineer 1-5 years of experience as Data Engineer or a similar role Experiencing dealing with large volumes of data, preferably successfully managing multiple heterogenous datasets into a unified data warehouse Creating ELT or ETL production data pipelines using Python/SQL Working knowledge of containers and workflow orchestration/automation tools: Prefect or Airflow. Bonus: DBT (com) AWS, GCS and/or Azure cloud-based data stacks, specifically experience with large-scale databases such as BigQuery, Redshift, or Snowflake Expert knowledge in SQL (window functions, partitioned or clustered databases, MPP, etc). Python data analysis libraries, such as Pandas and NumPy Bonus points if you feel comfortable working with DevOps tooling What you will have at Consumer Edge: Competitive Salary Work-from-home flexibility. As of Q2 2022, CE is remote-first, with an office in Midtown Manhattan 401k with employer match Flexible vacation and unlimited sick days Paid family leave An incredible product & powerful data that ""wows"" clients Great people: surround yourself with a team of people with a shared vision & focus, drive, a passion for CE's customers, and camaraderie Career growth opportunities"
Data Engineer,eClinicalWorks,"Westborough, MA 01581",https://www.indeed.com/rc/clk?jk=2f91933427f33d8f&fccid=27a0ffd30391d406&vjs=3,"Description We are eClinicalWorks. We are a privately held leader in healthcare IT, providing comprehensive, cloud-based EHR/PRM solutions to medical professionals worldwide to improve workflows and reduce the risk of physician burnout. We care. We are committed to positive change. And that’s where you come in. Do you value creativity and innovation? Great, so do we. At eClinicalWorks, we share a passion for improving healthcare through dedication, education, and teamwork. Everyone has that one thing they’re really good at. We value your talent and want you to join our fast-paced, fun, and culturally diverse environment. Ready to make a difference? Apply today. Position Overview This position is responsible for transfer of information from client’s existing software to eClinicalWorks software. Responsibilities This position requires a demonstrated understanding of data quality, privacy and security issues. Responsible for extraction and mining of large volumes of data sets from a variety of data sources (Relational databases, XML, flat file formats etc.) and create complex data reports for analysis Work with clients to identify, define, collate, document, and communicate data migration requirements Responsible for data profiling, data cleansing, data transformation and the loading of data into eClinicalWorks software. Design and develop algorithms and visualization tools to help manage an efficient data migration process Write Java programs, T-SQL scripts and stored procedures for the data conversions and apply quality control processes to all output to ensure accuracy Create database objects such as tables, views, indexes, triggers, stored procedures, functions, and Integration Services packages to support new and existing applications Liaison with customers and Project Managers and provide regular updates to ensure a smooth data migration experience Deliver best practice, processes, and standards for effectively carrying out data migration activities Perform quality assurance and database validation on all test and live conversions Create, debug and execute JAVA programs to handle conversions of various sets of standard document formats (RTF, HTML, Word, Text, JPEG, TIFF, PNG, XML) and other custom format documents to PDF. Ensures data integrity, data security and performance of production databases. Requirements Bachelor degree in Computer Science, Data Analytics, Data Science, Business Analytics, or similar field 2+ years of proficiency in Java 2+ years of proficiency in Microsoft SQL server and MySQL Databases 1 - 2 years of experience with other database (Oracle/PostgreSQL/Sybase/MS Access/Informix/C-tree) Open to work into Night/EST shift (5:30 PM to 2:30 AM IST) Excellent Communication Skills Other Skills/Abilities Strong communication skills Strong project management skills with ability to work well under pressure with multiple priorities and deadlines Strong research, analytical, and creative problem-solving skills Ability to work in a fast-paced work environment Demonstrated success in working with cross-functional teams Ability to analyze data, identify trends and develop/optimize workflow hypothesis. Please know, current policy requires all eCW employees to be fully vaccinated against Covid-19 for business travel or attendance at any eCW location, event or customer, to the extent permitted by applicable law. eClinicalWorks is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills, and experiences that bring us together and help create a healthy world Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Engineer,Dutch Bros,Remote,https://www.indeed.com/rc/clk?jk=54db9dbdd2164f51&fccid=31f7ae01c9c13473&vjs=3,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time. Being part of the Dutch Family You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless! Dutch Bros mission statement We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time. Who we are Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities. We love people and we love OUR people! Here’s what we offer Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base: Medical/Dental/Vision/Short Term Disability/Life insurances Paid Sick Days 401(k) plan with employer match after one year of employment Education Benefit Program Vacation/Floating Holidays/Paid Time Off Paid Parental Leave Flexible Schedule Paid Volunteer Days Various employee discounts Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista Position Overview The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines and etc.) and deliver reliable and sustainable data products for internal use. Key Result Areas (KRAs) Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions: Design and develop new ETL solutions Improve the performance and effectiveness of current ETL processes Design and implement new data warehouses Monitor and improve the performance of the current data warehouses Perform ongoing preventive maintenance on data pipelines and related applications Develop and improve the data asset documentation: Build data catalog for the legacy and new data assets Develop data architecture diagram Develop data dictionaries for the legacy and new data assets Categorize and tag the data to democratize the data assets to a wider group Develop ETL and data warehouse description documentation Develop and support the data governance efforts: Develop data policies to manage the access and availability of data assets Develop data policies to support the privacy and security compliance efforts Monitor the permissions, access and availability of data for different internal and external users Apply the best practices to improve the data security for the data in motion or at rest Job Qualifications 3+ Years of work experience in data engineering roles, required 2 years of experience developing data warehouses on Snowflake platform, required Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred Experience with data warehousing concepts, SQL and SQL Analytical functions Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.) Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.) Experience in data modeling (dimensional, normalized, key-value pair) DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements Experience in management and maintenance of data pipelines in an enterprise setting Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making Preferred Qualifications Background and experience working in food and beverage industry Working knowledge of data programming languages/solutions (Python, Java or R) Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.) Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation) Familiar with real-time pipeline design and management principles and concepts Experience building RESTful APIs to enable data consumption Experience with Action Analytics (Microsoft D365 Analytics solution) Familiarity with Azure Logic Apps Preferred Certifications Azure platform (Developer/Architect/Data Engineer) Snowflake platform (SnowPro Core/Advanced) Competencies Adaptable Budgetary Responsibility Collaborative Communication Effective Prioritization Functional and Tech. Expertise Initiative Physical Requirements Occasional lifting up to ten pounds Must be able to work in a climate-controlled office environment Vision must be good, or corrected to normal, to perform normal job duties Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties Ability to read and write in English in order to process paperwork and follow up on any actions necessary Sitting for extended periods of time Manual dexterity needed for keyboarding and other repetitive tasks *This position is eligible for remote work within any state Dutch Bros currently resides in* Compensation: $84,079.75 - $117,940.49 If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!"
Sr. Data Engineer,Match,"Dallas, TX",https://www.indeed.com/rc/clk?jk=a4bb4ab4dc05b31f&fccid=41d3a70a35069f94&vjs=3,"As a Sr. Data Engineer, you will be implementing critical ETL pipelines and advancing best practices for the data engineering team, and the rest of the organization. You will work on delivering an actual big data architecture while concentrating on real-world problems such as privacy concerns. This role is key to the success of Match Group. Not only will you help power the love lives of millions of people, but you will play a critical part in the functioning of every brand at Match Group (Match, Tinder, Hinge, Okcupid, PlentyofFish, BLK, and others), with stakeholders ranging from customer experience to marketing to leadership. We're located in Dallas, TX, and seeking a DFW based engineer to join us. We work from the office 1 day per week (free catered lunches are provided). See you soon! How you’ll make an impact: Work with our Engineering teams to ensure data is flowing accurately through data creation to our presentation layers Become an advocate for the Data Engineering team by developing and championing Data Engineering practices with the team and with the company at large Improve our Data Engineering stack through containerization, data modeling, developing our ETL pipelines, and building scalable/reliable solutions Work with stakeholders and translate their needs and expectations into action items and deliverables Lead infrastructure initiatives, from design to implementation to delivery Support existing on-prem infrastructure and help expand our processes into the cloud (AWS) We could be a match if you bring: Prior Airflow and/or Python experience is required Expertise in SQL, Data Modeling, and Python Used Redshift, Airflow, Spectrum and relational database like SQL Server Capability to drive initiatives and articulate their value to Engineering and other stakeholders Experience delivering data products from conception to delivery Good communication skills (written/verbal) Passionate about designing elegant ETL pipelines 5+ years of professional/industry experience Our team culture: Authenticity: Share your genuine thoughts and opinions directly Courage: Invite and deeply consider challenges and criticism Empathy: Be empathetic, communitarian and trustworthy What's the team like? Our BI team is a service organization that delivers reporting solutions to the entire Match Group enterprise The BI team is responsible for architecting and engineering new data systems and reporting to help facilitate business decision-making We're located in Dallas, TX, and seeking a DFW based engineer to join us. We work from the office 1 day per week (free catered lunches are provided). See you soon! #LI-CENTRAL #LI-CH1 Why Match Group? Our mission is simple – to help people find love and happiness! We love our employees too – here are some examples how: Annual training budget for each employee 100% employer match on 401k contributions Specific COVID-19 allowance for home office set-up Matched giving to qualified organizations 100% paid Parental Leave for up to 20 weeks Happy Hours and Company events At Match Group, we represent a collection of unique brands - but we all focus together on the health and safety of all of our employees. That's why we require that employees are fully-vaccinated when in person at any US office or company-sponsored fun. If you need to talk through this in-person vaccine requirement, our People team can work with you through our accommodations review process. We are proud to be an equal opportunity employer and we value the rich dynamics that diversity brings to our company. We do not discriminate on the basis of race, religion, color, creed, national origin, ancestry, disability, marital status, age, sexual orientation, sex (including pregnancy and sexual harassment), gender identity or expression, uniformed service or veteran status, genetic information, or any other legally protected characteristic. Period."
Analytics Data Engineer,W. L. Gore & Associates,"Remote in Flagstaff, AZ 86004",https://www.indeed.com/rc/clk?jk=6ba3d724dd22cdce&fccid=d91ab1f015016afc&vjs=3,"Job : Business Execution Primary Location : Americas-US-AZ-Flagstaff Travel% : None Shift : Day Schedule : Full-time Analytics Data Engineer - 222297 About Us: Gore is a materials science company focused on improving lives through discovery, product innovation and rewarding careers for our Associates. About the Industry: Saving lives and improving the quality of life for patients is at the core of everything we do. This meaningful work gives purpose to our lives and inspires us to create solutions that make a difference in the lives of others. Learn more at gore.com/products/industries About the Role: We are looking for a Data Engineer to join our Medical Products Division Analytics team who will support a broad team in finding, activating, and systematizing data and tools to create actionable business insights. The Data Engineer is part of the team responsible for the integrity and quality of our data mart and a growing portfolio of data capabilities. More broadly, the Data Engineer has roles in our end-to-end delivery of analytics, from data management through an effective pipeline to partnering in creation of end-user tools, all to support our customers to derive new value from their information. This position offers multiple work arrangements, including on-site at our facility in Flagstaff, Arizona. Hybrid and fully remote work allowed in most locations within the United States, depending upon the responsibilities of the role and business needs. Responsibilities: Use a suite of database, data management and ETL tools to build and support functional infrastructure such as data pipelines between our data sources, data marts, and analytics applications Apply deep subject matter expertise to diagnose issues with data flows and sources, apply technical solutions and work with team members to make process improvements where needed Partner with analysts and other team members to understand stakeholder needs and then prototype and develop new data tools or visualizations Act as data product owner for one or more capabilities delivered by the team, to provide support and expertise, drive adoption, and maintain a high level of service Work with internal team and process owners to establish quality, confidence, and strong shared understanding of data resources; maintain high quality through process improvements, documentation and testing Promote best practices for data management, analysis, and insights communication Work with vendors to produce and manage data and/or tools for Gore use Prepare Gore data for use by partners such as vendors or other teams Collaborate with the Data and Capabilities Team to advance the sophistication of our tools, infrastructure and processes to take advantage of emerging technologies and methods Required Qualifications: Bachelor’s degree and a m inimum of 3 years work in analytics such as data analysis or data engineering, in business analysis or operations, or scientific computing Proven experience profiling data to determine its characteristics, find issues, and implement methods to clean and improve it Experience building data pipelines or integrations to provide data to applications, including systematization with ETL tools or applications Expertise with working with large data sets using SQL Server, Oracle, or other relational database platforms Expertise with a broad range of analytical methodologies including statistical analyses, data visualizations, predictive modeling, or operational dashboards Proficiency with a variety of tools for data manipulation, visualization, modeling and analysis, such as Tableau/Tableau Prep, R and Shiny, Power BI, python, Alteryx or Knime Proven project execution and communication skills: Ability to define projects, set expectations among stakeholders, organize work streams and deliver needed solutions Proven ability to support users of large production operations Demonstrated ability to collaborate with a variety of partners in complex projects Desired Qualifications: Master’s level education in a field related to analytics, business, or science a plus Familiarity with relevant industry data such as sales, marketing, operations, manufacturing, or health care Strong perspective on best practice approaches to effective data design, visualization and interpretation *Remote Working Arrangements are permitted for Associates in the continental United States (US) and Canada, with appropriate approval and compliance with Gore’s remote working policies, from the country in which they are employed. Locations not eligible for new remote work arrangements include: Alaska and Hawaii (for all roles), and Rhode Island (for wage/hourly roles only). What We Offer: At Gore, we offer comprehensive, competitive rewards in the form of compensation and benefits. Among these are work-life balance and sports programs, 401(k) Plan with a gift, Associate Stock Ownership Plan, health & well-being program with full health plan, and a flexible working program. Within Gore, you will find a unique culture, diversity, equity, and inclusion initiatives, and opportunities for growth and development. Learn more at gore.com/careers We believe in the strength of a diverse workforce and inclusive work environment. In support of our values and continued success we are proud of Associates around the world who support an inclusive work environment, strive to reflect the diversity of the communities where we operate, and ensure all Associates and external partners are treated with fairness, dignity and respect. Gore is committed to a drug-free workplace. All employment is contingent upon successful completion of drug and background screening. Gore requires all applicants to be eligible to work within the U.S. Gore generally will not sponsor visas unless otherwise noted on the position description. Gore is a M/F, Disabled and Vet EEO/AA employer. (Applies to all positions in the U.S.) Our Talent Acquisition Team welcomes your questions at gore.com/careers/contact"
Data Engineer,PepsiCo,"Plano, TX+11 locations",https://www.indeed.com/rc/clk?jk=d48545be0fac3259&fccid=2973259ddc967948&vjs=3,"Auto req ID: 279164BR Job Description PepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo’s global business scale to enable business insights, advanced analytics and new product development. PepsiCo’s Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation. What PepsiCo Data Management and Operations does: Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders Increase awareness about available data and democratize access to it across the company As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems. Key Accountabilities: Active contributor to code development in projects and services Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products Build and own the automation and monitoring frameworks that capture metrics and operational KPIs for data pipeline quality and performance Responsible for implementing best practices around systems integration, security, performance and data management Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions. Develop and optimize procedures to “productionalize” data science models Define and manage SLA’s for data products and processes running in production Support large-scale experimentation done by data scientists Prototype new approaches and build solutions at scale Research in state-of-the-art methodologies Create documentation for learnings and knowledge transfer Create and audit reusable packages or libraries COVID-19 vaccination is a condition of employment for this role. Please note that all such company vaccine requirements provide the opportunity to request an approved accommodation or exemption under applicable law Qualifications/Requirements 2+ years of overall technology experience that includes at least 2+ years of hands-on building data engineering pipelines 2+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.) 1+ years in cloud data engineering experience in Azure Azure Certification is a plus 1+ Years in building data engineering pipelines in Azure (ADF and databricks) Experience with version control systems like Github and deployment & CI tools Experience with Statistical/ML techniques is a plus Experience with building solutions in the retail or in the supply chain space is a plus Understanding of metadata management, data lineage, and data glossaries is a plus Working knowledge of agile development, including DevOps and DataOps concepts is a plus BA/BS in Computer Science, Math, Physics, or other technical fields Skills, Abilities, Knowledge: Excellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior-level management Ability to understand and translate business requirements into data and technical requirements Positive and flexible attitude to enable adjusting to different needs in an ever-changing environment Organizational and interpersonal skills Foster a team culture of accountability, communication, self-management, and self-motivated Proactively drives impact and engagement while bringing others along. Relocation Eligible: Not Eligible for Relocation Job Type: Regular All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status. PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity Our Company will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Credit Reporting Act, and all other applicable laws, including but not limited to, San Francisco Police Code Sections 4901 - 4919, commonly referred to as the San Francisco Fair Chance Ordinance; and Chapter XVII, Article 9 of the Los Angeles Municipal Code, commonly referred to as the Fair Chance Initiative for Hiring Ordinance. If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy Please view our Pay Transparency Statement"
Data Engineer,Texas Capital Bank,"Richardson, TX 75082+2 locations",https://www.indeed.com/rc/clk?jk=2079bd667492f7be&fccid=5a09f253b3171f0b&vjs=3,"Overview: Texas Capital Bank is built to help businesses and their leaders. Our depth of knowledge and expertise allows us to bring the best of the big banks at a scale that makes sense for our clients, with highly experienced bankers who truly invest in people’s success — today and tomorrow. While we are rooted in core financial products, we are differentiated by our approach. Our bankers are seasoned financial experts who possess deep experience across a multitude of industries. Equally important, they bring commitment — investing the time and resources to understand our clients’ immediate needs, identify market opportunities and meet long-term objectives. At Texas Capital Bank, we do more than build business success. We build long lasting relationships. Headquartered in Dallas with offices in Austin, Fort Worth, Houston, Richardson, Plano and San Antonio, Texas Capital Bank was recently named the #1 most trusted bank in the country on Newsweek’s inaugural list of America’s Most Trusted Companies. For more information about joining our team, please visit us at www.texascapitalbank.com. We’re looking for a Data Engineer to join our Data Operations team. The data platform is at the heart of Texas Capital Bank’s data strategy and its consumers expect the data to be accurate and accessible. We are looking for someone who is never satisfied with the data platforms reliability and is hungry to measure and optimize. The Data Engineering Team constantly supports services allowing colleagues to be more productive without being in the way. A Data Operations Engineer supports the implementation and integration of data warehouse solutions. Additionally, a Data Operations Engineer will support ETL Processes and perform daily tasks to ensure the data integrity and work with other teams identify and correct issues that arise. Responsibilities: Monitor, analyze and support Data Applications at Texas Capital Bank for stability and performance Document data flows and create Knowledge Base articles Support existing data applications Resolve incidents and ensure SLAs are met Communicate with Stakeholders on updates, incidents, outages, and vulnerabilities Work with Data Governance, Data Delivery teams to ensure platform is stable and compliant Eliminate toil for maintaining the Platform by adding automation, monitor the operations and validate the platform is performing as expected Review capacity and costs of the platform with stakeholders and scale the platforms accordingly while still meeting Service Level Objectives (SLO) Test different disaster scenarios with the team to ensure the platform is ready Regularly maintain Service Now CMDB and Knowledge Base as needed Participate in on-call rotation Triage, prioritize, and resolve support tickets Research and correction of data integrity issues Diagnose and correct performance issues Troubleshoot data load failures Create and maintain support documentation Partner with other support and development teams to provide feedback regarding health and process improvements Regularly perform with minimal supervision The duties listed above are the essential functions, or fundamental duties within the job classification. The essential functions of individual positions within the classification may differ. Texas Capital Bank may assign reasonably related additional duties to individual employees consistent with standard departmental policy. Qualifications: Passion to help business resolve issues in fast paced, complex, critical, and dynamic environment Understanding of ETL and ELT Processing desired Understanding of Software Development Life Cycle (SDLC) desired Curiosity to Reverse Engineer Undocumented Code Sets Knowledge and experience with SQL desired Experience documenting Process Flows Experience with Git and CI\CD (Continuous Integration and Continuous Delivery) Proactive Mind Set"
Data Engineer - DOF,Xcel Energy,"Denver, CO 80202 (Union Station area)+1 location",https://www.indeed.com/rc/clk?jk=be89aad535319020&fccid=0b3490f8005058ec&vjs=3,"The Digital Ops Factory Data Engineer will work closely with a multidisciplinary Agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from the factory's connected data, enabling the organization to advance the data-driven decision-making capabilities of the factory's enterprise. This role requires deep understanding of data architecture, data engineering, data analysis, and a general understanding of data science techniques and workflows. The ideal candidate is a skilled data engineer with experience creating data products supporting analytic solutions. They are an Agile learner, possess strong problem-solving skills, work as part of a technical, cross functional analytics team, and want to solve complex data problems and deliver the insights to enable analytics strategy. Essential Responsibilities Solution Delivery: Lead and support solution lifecycle technical activities. Ensure solutions are designed for great user experience and operational performance. Lead design, ensuring Enterprise Architecture, Security, Operations and Compliance aspects are continuously integrated into solutions. Provide input to cost and schedule estimation. Responsible for overall integrity of system design and operation. Oversee vendor activities. Operations: Review solution performance, and continually assess health of systems. Track and drive awareness to operational and technical debt risks. Provide escalated support to incident and problem management. Utilize analytics to improve availability, reliability, efficiency and capacity. Oversee vendor activities. Subject Matter Expertise: Continuously stay current on, and apply, technical industry knowledge pertaining to the respective domain. Relationship Management: Conduct peer reviews and approve system changes and technical solution design. Coach and mentor less experience team members. Partner cross-organizationally to drive minimal costs on optimal solutions. Provide in-depth technical information to stakeholders as needed. Minimum Requirements Seven years of related functional experience. Bachelor’s degree in Technology, Science, Business or related field, or 4 years of experience equivalent to the position. Excellent communication skills, effective with varying organizational levels and skill set, and able to translate between technical and non-technical concepts. Excellent Relationship Management and collaboration skills, with a track record of working as one team cross-organizationally to drive innovation and business results. Experience managing the lifecycle of technical solutions. Deep Subject Matter Expertise within the respective system domain products, platforms, processes and architecture. Broad general knowledge of technology architecture, infrastructure, network, security and software principles and models. Experience working in partnership with internal and external vendors. Proven analytical, problem-solving and troubleshooting skills. Extensive knowledge of future technology trends within area of expertise. Demonstrated leadership on technical aspects of large scale projects. Experience with delivery methodologies (Waterfall, Agile, Scrum) and operational models (ITIL). Experience and understanding of core IT Service Management functions, such as Change Management and Incident Management. Preferred Python and SQL Skills Knowledge of Spark, PySpark Experience with AWS in the data and analytics space Strong troubleshooting and problem solving Strong communication skills _______________________________________________________________________________________________ Xcel Energy is committed to the safety of its employees and customers, and promotes a Safety Always culture. Because of this, we strongly encourage all employees to be fully vaccinated against COVID-19; however, vaccination is not mandatory. After being hired, you will asked to report your vaccination status and dates of vaccination. This information will be maintained confidentially and disclosed only on a need-to-know basis. If you are not fully vaccinated or choose not to disclose your vaccination status you will be required to follow any health-and-safety rules applicable to unvaccinated employees. As a leading combination electricity and natural gas energy company, Xcel Energy offers a comprehensive portfolio of energy-related products and services to 3.4 million electricity and 1.9 million natural gas customers across eight Western and Midwestern states. At Xcel Energy, we strive to be the preferred and trusted provider of the energy our customers need. If you’re ready to be a part of something big, we invite you to join our team. Posting Notes: CO - Denver || CO - Denver; MN - Minneapolis || United States (US) || Customer And Innovation || 56200:IT-Digital Ops Factory || Full-Time || Non-Bargaining || The anticipated starting base pay for this position is: $87,000 to $123,666 per year This position may also be eligible for the following benefits and/or pay components: Pay - Annual Incentive Program, Medical/Pharmacy Plan, Dental, Vision, Life Insurance, Dependent Care Reimbursement Account, Health Care Reimbursement Account, Health Savings Account (HSA) (if enrolled in eligible health plan), Limited-Purpose FSA (if enrolled in eligible health plan and HSA), Transportation Reimbursement Account, Short-term disability (STD), Long-term disability (LTD), Employee Assistance Program (EAP), Fitness Center Reimbursement (if enrolled in eligible health plan), Tuition reimbursement, Transit programs, Employee recognition program, Pension, 401(k) plan, Paid time off (PTO), Holidays, Personal holidays, Volunteer Paid Time Off (VPTO) (full-time employees only), Parental Leave Click here to see our benefits Requisition Number: 43383 All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Individuals with a disability who need an accommodation to apply please contact us at recruiting@xcelenergy.com"
Data Engineer,The AES Corporation,Remote,https://www.indeed.com/rc/clk?jk=3ca64bc92873e2b2&fccid=a5147c03ec5618f8&vjs=3,"At AES, we raise the quality of life around the world by changing the way energy works. Everyone makes an impact every day in our small, global teams. Apply here to start an extraordinary career today. At AES we have an amazing opportunity to transform the world with renewable energy. By using the vast amounts of information available, we are designing Smart Maintenance, Smart Operations, Smart Grid and other Energy related solutions to improve our operations and be a global leader in renewable energy generation. Data Engineers work collaboratively with business and technology collaborators to establish and maintain the enterprise data architecture and data migration efforts. You will be responsible for building, operating and supporting the latest cloud-based data technologies from data ingestion to consumption. As part of a team, you help to optimally deploy large scale data solutions in the enterprise, using modern cloud based technologies. Your Role and Responsibilities Data Engineers are a part of AES's digital transformation. The focus of this role would be on the development side with main emphasis on the concepts of efficiently designing and implementation of our cloud-based Enterprise Data Lake. Work with Enterprise/Solution Architects to create/implement plans to improve existing data models and structure the tables with the design pattern that will help the system for improved performance. Generally, has in-depth knowledge and expertise of database technologies, along with solid programming, design and system analysis skills. Willingness to learn new technologies that can help improve the current system. The Work You May Do Build pipelines and processes for cleaning and organizing data as well as build tools to help make the data accessible by data scientists and the business. Leverage Google Cloud Platform and similar tools. Understand and support a corporate data model and overall data governance Connect with application, back-office and external customer teams regarding data requirements, standards, performance and access Define and perform unit testing of database code as appropriate. Perform code reviews and audits of application team’s database code to ensure compliance with established standard methodologies. Use data analytics tools and apply techniques for data retrieval, preparation and loading of data from a wide variety of data sources using various data engineering tools and methods. Build integrations (API, etc.) with on-premise and cloud databases You have a strong understanding of programming languages extensively used in Data Science applications (e.g., R, Python, Scala, Java, etc.) Debug, fix, design and implement solutions to sophisticated technical issues. Build capabilities with software tools (e.g. Google Cloud Platform) Work in an Agile, collaborative environment, partnering with other scientists, engineers, and database administrators of all backgrounds and fields to bring analytical rigor and statistical methods to the challenges of predicting behaviors. Designing and implementing data solutions for operational and secure integration across systems. Demonstrating solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code. Improving operations by conducting systems analysis to understand process and application bottlenecks; recommending changes in policies and procedures. Leverage Agile, CI/CD and DevOps methodologies to deliver high quality product on-time Who You Are You have a knack for redefining data and migrating data in cloud platforms using cloud native tools. You have built high-capacity data analytics systems using cloud platforms and services for storing, collecting, and analyzing data. (Google Cloud preferred.) You have a passion for creating scripts to move data and a prowess for data manipulation You have the ability to deal with ambiguity and the flexibility to change direction as additional information becomes available. Required Professional and Technical Expertise Bachelors degree in in computer science, software engineering or a closely related field; a Master's degree is preferred 2 + years of experience developing batch and streaming ETL processes (preferably Talend) 2 + years of experience with relational and NoSQL databases, including modeling and writing sophisticated queries 2 years of development experience using an Agile methodology with experience collaborating on coding projects in Google Cloud Platform 2+ years of industry experience with modern programming languages like Python (preferred), Java, etc. 1+ years of industry experience with graph databases like Neo4j or TigerGraph (preferred) Exposer to columnar cloud databases preferably BigQuery. Exposure to relational database platforms like Microsoft, Oracle, etc. Progressive attitude particularly around deployment models and emerging technologies 2 + years of experience in Cloud Engineering, experience in a similar role with proven relationship building skills resulting in traceable, measurable, impactful results Experience working in team environments and implementing organizational change. At AES, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists. You will also be surrounded by colleagues who are committed to helping each other grow through our outstanding Check-In approach where feedback flows freely. AES is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, religion, age, sexual orientation, gender identity, disability or veteran status. AES is an Equal Opportunity Employer who is committed to building strength and delivering long-term sustainability through diversity and inclusion. Respecting all backgrounds, differences and perspectives enables us to improve the lives of our people, customers, suppliers, contractors, and the communities in which we live and work. All qualified applicants will receive consideration for employment without regard to sex, sexual orientation, gender, gender identity and/or expression, race, national origin, ethnicity, age, religion, marital status, physical or mental disability, pregnancy, childbirth, or related medical condition, military or veteran status, or any other characteristic protected under applicable law. E-Verify Notice: AES will provide the Social Security Administration (SSA) and if necessary, the Department of Homeland Security (DHS) with information from each new employee's I-9 to confirm work authorization. Safety comes first at AES. To protect the health and safety of our people, customers, communities and partners, and to provide and maintain a workplace that is free of known hazards, AES requires all newly-hired people or current AES people applying for U.S.-based role(s), to be fully vaccinated against COVID-19 or be willing to be fully vaccinated against COVID-19 by their date of hire. Except where prohibited by law or not specifically covered in a collective bargaining agreement, new hires and transfers will be required to provide proof of vaccination during onboarding and periodically thereafter. This policy will comply with all applicable laws and is based on guidance from the Centers for Disease Control and Prevention and local health authorities, as applicable."
Data Engineer Trainee,Booz Allen Hamilton,"Arlington, VA+39 locations",https://www.indeed.com/rc/clk?jk=e1749587931efcb6&fccid=4e041af1d0af1bc8&vjs=3,"The Challenge: Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by cloud engineering and loosely coupled architectures? In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As an aspiring cloud data scientist, you know you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors — from fraud detection, to cancer research, to national intelligence — you see data scientists turning data into actions and you want to be part of the team. We have an opportunity for you to develop your analytical skills and establish your career in data science. You’ll join a rigorous training program that combines skills assessments, a comprehensive curriculum, functional mentorship, a capstone analytic challenge, and support to place you on your first data science project. You’ll learn how to write scripts to integrate data, conduct exploratory data analysis to discover hidden trends, apply machine learning in AWS to train predictive models, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers that inform decisions. Equipped with the foundational data science skills to accelerate your career, you’ll join a team and apply those skills to support our clients’ critical national security missions. Embrace the challenge and join us in driving change through data science. Empower change with us. You Have: Experience with data engineering, including querying or analyzing data to answer questions and solve problems Experience with python Knowledge of basic concepts in mathematics and statistics Knowledge of Cloud environments Ability to obtain a security clearance Scheduled to obtain a Bachelor's degree by Summer 2022 Nice If You Have: Experience with systems engineering or systems administration Experience with Amazon Web Services Experience with Azure Experience with Docker, Kubernetes, and Ansible Knowledge of SQL and GitHub Ability to learn a programming language Bachelor’s degree in Data Science, Mathematics, Engineering, Physics, Statistics, or CS Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. Build Your Career: At Booz Allen, we know the power of analytics and we’re dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you can expect: access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk a chance to change the world with the Data Science Bowl—the world’s premier data science for social good competition participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government You’ll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications? Take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We’ll help you develop the career you want, as you chart your own course for success. We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law."
Data Engineer (Junior),BDSA,"Remote in Louisville, CO",https://www.indeed.com/rc/clk?jk=4a0c63e0f246eb4f&fccid=1068f23bdc8cad68&vjs=3,"Job Summary: BDSA is seeking a self-driven professional to join our team as a junior data engineer. The ideal candidate will be hands-on, have a good understanding of data engineering technology and tools and be capable of functioning as an individual contributor. This is an ideal position for an up-and-coming data professional looking to apply their intellect, skills, and passion to hard problems. Day-to-day activities include implementing new solutions designed by senior staff, troubleshooting problems in existing workflows, and brainstorming ways to solve new challenges. If you enjoy working with disparate data types from a wide variety of sources (i.e., lots of data wrangling) this is the challenge you're looking for. If you're hoping to settle in for a nice easy (boring) ride than look elsewhere. The Data Engineering team is high intensity, deadline driven, and constantly working to overcome unexpected obstacles as the company integrates data from thousands of partner organizations. Expect to learn new skills weekly and leverage the latest technologies from Microsoft (ADF) and Snowflake, as well as numerous other data tools such as Python, R Studio, Power BI, and the old standby, MS Excel. Essential Functions and Responsibilities: Implement application specific logical and physical data models Implement ETL processes Implement QC processes Maintain and document operational environment Troubleshoot data-related workflows in support of the Analytics and Product teams Job-related Education, Experience, and/or Other Qualifications: Bachelor's degree or equivalent experience Experience in at least 2 of the following areas: Snowflake Azure Data Factory Python JSON Shell scripting Implementing database objects, tables, stored procedures, views and triggers in Snowflake or similar platform Building, testing, and executing ETL packages, including automation of jobs Data cleansing and data normalization processes and procedures Database administration experience in either Snowflake or a similar cloud data warehousing solution Pay Range: $70,000 – $90,000 Benefits: retirement plan, health insurance, flexible time off, remote work, and professional training NOTE: Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. BDSA is an equal opportunity employer. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate based on any pay inequities nor on race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. Applicants must be authorized to work for ANY employer in the US. We are unable to sponsor or take over sponsorship of employment visas at this time."
Data Engineer - Mid Level,USAA,"Hybrid remote in Plano, TX 75024+3 locations",https://www.indeed.com/rc/clk?jk=bcacca2c27739222&fccid=3a1edc2d763c4288&vjs=3,"Purpose of Job We are seeking a talented Data Engineer I for our Plano, TX facility. USAA values a culture that is highly collaborative, and we have found that a hybrid work type helps employees gain the best of both worlds – collaborating in-person in the office and working from home when needed to achieve focused results. The actual days' onsite are resolved between each employee and the employee’s manager. The candidate selected for this position is going to get work with the P&C Pricing Data and Analytics Team in USAA’s Enterprise Chief Information Office. They will work on various projects using Snowflake, DBT, Informatica and GitLab technologies. Data Engineers (DEs) are engaged in all phases of the data management lifecycle. This includes gathering and analyzing requirements, collecting, processing, storing, securing, and archiving data. Develop and maintain technical systems for data reporting and technical solutions utilizing emerging technologies. Partner with the business to ensure data management solutions aligned to business objectives. Job Requirements About USAA USAA knows what it means to serve. We facilitate the financial security of millions of U.S. military members and their families. This singular mission requires a dedication to innovative thinking at every level. About USAA IT Our most meaningful qualification isn't technical, it's human. Here, we don't just sit in front of a screen. We stand behind our 13 million members who rely on us every day. We're proud of USAA's strong history - and we're even more passionate about our future. That's why we have a team of supportive and collaborative hardworking technology professionals focused on doing more for our members. And why we're continuing to add innovative problem solvers to our team. With us, you'll find exciting challenges that inspire you to continue learning and growing. Tasks: Identifies and manages existing and emerging risks that stem from business activities and the job role. Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled. Follows written risk and compliance policies, standards, and procedures for business activities. Independently conducts work on the full life cycle of data engineering to include analysis, solution design, data pipeline engineering, testing, deployment, scheduling, and production support. Designs and implements complex technical solutions for data engineering and analytic systems. Identifies and solves significant technical problems and architecture deficiencies to include design, security, and performance. Collaborates on design reviews by providing feedback on trends and makes recommendations for solutions. Breaks down business features and into technical stories and approaches. Influences stakeholders in technical adoption for best solutions. Creates proof of concepts and prototypes that drive the vision and the outcome for complex initiatives to be delivered. Collaborates with the team and other engineers on new technologies and alternatives to plan and execute complex assignments and tasks. Helps on-board entry level engineers. May begin mentoring junior engineers. Acquires data from multiple data sources and maintains resulting databases, data warehouses, and/or data lakes. Assists to develop, maintain, and enforce the company’s data development tools and standards. Conducts code reviews on a regular basis to improve quality and ensure compliance. Minimum requirements: Bachelor’s degree; OR 4 years of related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree; OR Approved certification from CodeUp, Galvenize, VetFIT (Veterans for IT) or eFIT (Employees for IT) 4 years of data engineering, data analysis or software development experience implementing data solutions with at least 1 year of data engineering or data management experience. Extensive knowledge and working experience in SQL and Relational Databases. Strong analytical and problem-solving skills. When you apply for this position, you will be required to answer some initial questions. This will take approximately 5 minutes. Once you begin the questions you will not be able to finish them at a later time and you will not be able to change your responses. Preferred experience: 5+ years of hands-on experience with Informatica, SQL, databases, data warehousing Preferred hands on experience with Snowflake, DBT GitLab, AWS, Cloud to cloud integration The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job. Compensation: USAA has an effective method for assessing market data and establishing ranges to ensure we remain competitive. You are paid within the salary range based on your experience and market position. The salary range for this skill is: $88,200 - $158,900* Employees may be eligible for pay incentives based on overall corporate and individual performance or at the discretion of the USAA Board of Directors. Geographical Differential: Geographic pay differential is additional pay provided to eligible employees working in locations where market pay levels are above the national average. Shift premium: will be addressed on an individual-basis for applicable roles that are consistently scheduled for non-core hours. Benefits: At USAA our employees enjoy best-in-class benefits to support their physical, financial, and emotional wellness. These benefits include comprehensive medical, dental and vision plans, 401(k), pension, life insurance, parental benefits, adoption assistance, paid time off program with paid holidays plus 16 paid volunteer hours, and various wellness programs. Additionally, our career path planning and continuing education assists employees with their professional goals. Please click on the link below for more details. USAA Total Rewards Relocation assistance is Not Available for this position."
Data Engineer,Ready Responders,Remote,https://www.indeed.com/rc/clk?jk=9e27d82a764eefd8&fccid=01bbec249a563ae9&vjs=3,"About Us Ready is an on-demand mobile health service that delivers non-emergency care directly to patients. To accomplish this, Ready sends a trained health professional, which we call a “Responder,” to facilitate a telehealth visit between the patient and a licensed clinician. With Ready, patients now have access to quality care in their homes, 12 hours a day, 365 days a year, and talented individuals are provided the opportunity to work with a rapidly growing, mission-driven company. We hope you will join us. About The Opportunity The Ready Data team is a cornerstone of the medical care provided at Ready. Our team is responsible for ingesting, processing and leveraging internal data as well as medical data from large established healthcare providers to government agencies seeking to support underserved populations. We build custom data and ML-powered tools that enable Ready’s operational efficiency and improve the quality of care we deliver to our patients. We have an ambitious plan to improve and extend our batch and real-time systems that drive our internal data products and external reporting capabilities. We are looking for a Data Engineer to build this future with us. About the Role The Data team creates systems to centralize all of Ready Responder's internal and external data, and enables stakeholders to easily transform and access that data for analytics and machine learning through powerful APIs. As a Data Engineer, you will contribute to a number of our systems and deliverables, from scalable data pipelines to frameworks, tools and applications that make that data available to other teams and systems. What You'll Do Collaborate with data scientists, engineers, and stakeholders company-wide to solve high-impact healthcare problems by deploying solutions within production systems Work with broader Product organization to identify data, application, and reporting needed to support business initiatives and clinical service lines Develop, maintain and test architecture for data ingestion, processing and analysis Support existing processes running in production and implement optimized solutions What You’ll Need Bachelor’s degree (BA or BS) or equivalent Experience with SQL, ETL, data modeling and at least one programming language (preferably Python) Not afraid to wrangle messy data Excitement and dedication to working in an evolving healthcare industry Nice to Have Advanced degree in a STEM field Experience with Javascript/Typescript, Node.js, or Go Experience building data pipelines in workflow management platforms (e.g. Airflow, Luigi, etc) Experience with infrastructure as code (e.g. Terraform, Ansible, CloudFormation) Experience in healthcare or other highly regulated industry Ready is committed to meeting all Federal and State employment requirements including I-9 compliance. As part of that commitment, the company participates in the Department of Homeland Security's eVerify system."
AWS Data Engineer-Reporting,"Orpine, Inc. Internal",Remote in United States+6 locations,https://www.indeed.com/rc/clk?jk=125db4f0bbdc0587&fccid=7df81f4c05f8d55a&vjs=3,"Manager-Vani Location-Remote Proficient with AWS Data warehousing tools Proficient with Quicksight, Tableau or similar data visualization tools Comfort with data munging techniques and ETL platforms Strong SQL programming skills AWS Native Apps - S3, EC2, EMR, Lambdas etc. -Cloud Datawarehouse- Snowflake( Must) or AWS redshift. Atleast one Cloud DW project is must with Snowflake. Strong applied knowledge of basic statistical concepts and data best practices Demonstrated ability to produce scalable and repeatable analytic processes Demonstrated ability to partner with peers and leaders using strong written and verbal communication"
Data Analyst / Data Engineer,Kin + Carta,+1 locationRemote,https://www.indeed.com/rc/clk?jk=9f48ab1e78067705&fccid=a419cf85609f7c58&vjs=3,"The opportunity At Kin + Carta, we’ve got opportunities to offer you — for growth, for leadership, for big, world-changing impact and for, dare we say it, fun. We are a global workforce that is committed to building a world that works better for everyone. And that starts with our Kin. That’s why we’re proud of: The life we create within our virtual walls, every day Being B Corp certified Our honor as a “Best Large Firm to Work For” by Consulting Magazine The role Cascade Data Labs is a boutique consulting agency (operating as part of Kin + Carta) with end-to-end experience helping Fortune 500 companies form and execute their analytics strategy and infrastructure. We believe strongly that the difference between analytics success and failure comes down to practitioner-level understanding of the “details” presented across a variety of disciplines: data collection, organization, and engineering in a rapidly evolving technological landscape; analytical inference on multi-dimensional data sets; and the communication of findings to business stakeholders in visually compelling ways. As such, we seek a new breed of data professionals that can cut across these disciplines as project requirements dictate, blurring the lines between data analyst, scientist, and engineer, with the ability to work across a multitude of projects and contribute across various aspects of data product . While our culture promotes continual development and multidisciplinary growth, over time employees may gravitate towards a specific specialism and thrive in building a deep expertise in their domain of interest. Ideal candidates will have strong quantitative backgrounds and analytical discipline. While they will have some demonstrated ability to write code, they will not have learned programming languages for the sake of building their resume, but rather as a means to express their intellectual curiosity and analytical voice. Cascade Data Labs will provide a platform and training to help them reach their full potential. We are seeking candidates with all levels of experience; intern to senior-level. Core Responsibilities Analyze a collection of raw data sets to create meaningful impact to large enterprise clients while maintaining a high degree of scientific rigor and discipline. Engineer data pipelines and products to help stakeholders make and execute data driven decisions. Communicate analytical findings in an intuitive and visually compelling way. Potential Responsibilities (depending on aptitude, project, and seniority) Creating highly visual and interactive dashboards via Tableau, PowerBI, or custom web applications Conducting deep dive analysis and designing KPIs to help guide business decisions and measure success Engineering data infrastructure, software libraries, and APIs supporting BI and ML data pipelines Architecting cloud data platform components enabling the above Building and tracking project timelines, dependences, and risks Gathering stakeholder requirements and conducting technical due diligence toward designing pragmatic data-driven business solutions Minimum qualifications We want all new hires to succeed in their roles at Kin + Carta. That's why we've outlined the job requirements below. To be considered for this role, it's important that you meet all Minimum Qualifications. If you do not meet all of the Preferred Qualifications, we still encourage you to apply. Bachelors or Masters degree in quantitative studies including Engineering, Mathematics, Statistics, Computer Science or computation-intensive Sciences and Humanities. Recent graduates should include GPAs in their resumes from degrees obtained in the last 5 years. Proficiency (can execute data ingestion to insight) in programmatic languages such as SQL, Python, R Preferred qualifications Proficiency in visualization/reporting tools such as Tableau and PowerBI or programmatic visualization library such as R ggplot2, Python matplotlib/seaborn/bokeh, Javascript D3. Proficiency scripting in UNIX environment Proficiency in big data environments and tools such as Spark, Hive, Impala, Pig, etc. Proficiency with cloud architecture components (AWS, Azure, Google) Proficiency with data pipeline software such as Airflow, Luigi, or Prefect Ability to turn raw data and ambiguous business questions into distilled findings and recommendations for action Experience with statistical and machine learning libraries along with the ability to apply them appropriately to business problems Proficiency in front and back-end web application development stacks and frameworks (Javascript, HTML, CSS, React/Vue/AngularJS) including API design (REST/GraphQL) and library development Experience leading and managing technical data/analytics/machine learning projects Job Type: Full-time About Kin + Carta Kin + Carta is a global digital transformation consultancy committed to working alongside our clients to build a world that works better #ForEveryone. Our 1,700 curious minds make creative connections between people, data and technology to create connected outcomes across the full lifecycle of the product and platform ecosystems. We’re makers, builders and creators by nature, and we come to work every day to build experiences for some of the world’s most influential companies. We help businesses accelerate their digital roadmap, rapidly innovate, modernize their systems, enable their teams and optimize for continued growth. We are a technology business with trust and human connection at its heart. As a Certified B Corp, our triple bottom line focus on people, the planet and profit is at the core of everything we do. We welcome our Kin to show up as their full selves every day. Because this is so important to us, Kin + Carta is proud to be an equal opportunity employer. To read further about our commitment to Inclusion, Diversity, Equity and Awareness, check out the IDEA page on our website. If you need accommodations at any point in the application or interview process, please let us know. Apply for this role Whoever you are, wherever you’re from and whoever you love, you’ll find an open door at Kin + Carta. It’s yours to walk through if you’re passionate about building a better world for everyone, and you’re keen to be part of a diverse and inclusive culture that plays to people’s strengths and thrives on togetherness."
Data Control Engineer,Schneider Electric,"Cedar Rapids, IA 52404",https://www.indeed.com/rc/clk?jk=873101a19a8e2f3b&fccid=8dc4399ddb463d4a&vjs=3,"Job Description: Schneider Electric has an opportunity for a Data Control Engineer in our Cedar Rapids, IA location. The products supported in this role include circuit breakers but can be expanded into support of systems using other products also. What will you do? Designing, developing, and modifying data infrastructure to accelerate the process of data analysis and reporting Reviewing graphs, tables, and documents to ensure accuracy and quality Close collaboration with internal stakeholders as well as 3rd parties Evaluating and implementing database changes and updates as required by the business What qualifications will make you successful? Proven leadership and negotiation skills Solid understanding of test activities for electronic devices Excellent verbal and written communications Ability to collaborate with local and remote teams Ability to analyze, interpret, and organize large amounts of data In-depth understanding of modern database and information technologies Thorough understanding of data management duties such as collection, analysis, and distribution Desired Skills: Experience and/or exposure to certain test standards Experience and/or exposure to achieving product certification Experience with MS Office Experience with test management software (External) English Qualifications: Who will you report to? Lab Technical Manager Let us learn about you! Apply today. (External) English Company Boiler Plate: Why us? Schneider Electric is leading the digital transformation of energy management and automation. Our technologies enable the world to use energy in a safe, efficient and sustainable manner. We strive to promote a global economy that is both ecologically viable and highly productive. €25.7bn global revenue 137 000+ employees in 100+ countries 45% of revenue from IoT 5% of revenue devoted for R&D You must submit an online application to be considered for any position with us. This position will be posted until filled It is the policy of Schneider Electric to provide equal employment and advancement opportunities in the areas of recruiting, hiring, training, transferring, and promoting all qualified individuals regardless of race, religion, color, gender, disability, national origin, ancestry, age, military status, sexual orientation, marital status, or any other legally protected characteristic or conduct. Concerning agencies: Schneider Electric does not accept unsolicited resumes and will not be responsible for fees related to such."
Data Engineer,Banco Itau International- Miami,"Miami, FL 33131",https://www.indeed.com/rc/clk?jk=28fe64b3d746e3e9&fccid=dd616958bd9ddc12&vjs=3,"The Data Engineer will be responsible to develop an enterprise solution for the International Private Bank data-warehouse, data analytics and data visualization structure. Additionally, the Data Engineer is responsible to apply good software engineering and solution architecture practices to the design and construction of the data analysis self-service platform, and to propose decoupled and reusable solutions, as well as rationalization of tools and inner source culture. This position represents a key function for Itaú International Private Bank and US operations, requiring an individual with advanced knowledge with data structuring, as well as ability to collaborate and communicate with counterparties in other areas and offices Duties & Responsibilities Ø Access current data structure and connections in order to design the data models that support the bank's transactional and analytical systems Ø Work with IT team to restructure current DW set up, including new satellites systems, and set of data Ø Create patterns that facilitate the understanding of information Ø Generate optimized solutions for data consumption, looking for and specialized structures Ø Develop software and automate tasks Ø Draw architecture of business and data-oriented solutions Ø Build data pipelines for data lake Ø Define solution architecture Ø Compliance with BSA/AML laws, rules, regulations and the bank's BSA/AML policies and procedures Qualifications Ø Bachelor's degree in computer and information science, or related subject area required Ø Event-oriented architecture (Kafta) Ø Hadoo Ecosystem (Hive, Impala, Spark), SQL and NoSQL database (mongoDB, Cassandra) Ø Microservices and containers, Cloud computing (AWS) Ø Continuous integration and continuous delivery Ø Expertise in collaborative environment such as Git and Jira Ø Experience with design, construction, and documentation of APIs Ø Experience in Agile Methodologies Ø Clean Code Experience Ø Multi-tasker, strong ability to prioritize Ø Strong initiative and resourcefulness. Ø Cultural awareness to deal with people from different countries Ø Fluency in English, Portuguese is desirable"
data engineer,Capgemini,+20 locationsRemote,https://www.indeed.com/rc/clk?jk=22a84b2157430ca7&fccid=105ecfd0283f415f&vjs=3,"Contract length: 6+ months Job Description: Experience working with cloud technologies Knowledge of Spark, pySpark, Databricks, and Snowflake Ability to independently design / architect technical solutions Ability to quickly and independently learn new technologies Can be given high-level, large tasks to carry out, and can take ownership and handle the details Good communication skills Able to understand complex technologies at a deep level - not afraid of challenge The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job. A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion."
"Data Engineer, Remote",Guardian Life Insurance Company,+1 locationRemote,https://www.indeed.com/rc/clk?jk=17c670b5f0024a64&fccid=64294ff4323ee213&vjs=3,"Data Engineer As our Data Engineer you will be responsible for delivery of data solutions supporting analytic and reporting efforts. Specifically, the position will focus on the creation of data pipelines to optimize the architecture, design, governance, and movement to support self-service BI as well as performing statistical analysis, correlations, etc. Responsibilities include leading, defining, designing, building, testing and maintenance of the AWS data architecture, including ingestion of data from S3 (Hadoop) across various source types – Parquet, csv, text, etc. Responsible for the architecture of the transformation and integration layers utilizing various ETL tools and Redshift to create optimal structures to support centralized usage across BU and analytics. Responsible for helping propagate knowledge across this space to other team members and help to promote standards and best practice definition. You will: Focus on data architecture, design, and delivery of data solutions across the AWS environment Design, implement, and ensure data solutions are built, maintained, and updated based on established business requirements Collaborate with leadership to provide meaningful and credible feedback on data architecture, design, and delivery Work autonomously, in team settings and in partnership with management to review data design and solutions Identify information needed, sources, and use tools to deliver optimal solutions per the use case Partner with IT, Database Administrators, and business owners to ensure all data/data sources needed for reporting and analytics are defined and incorporated into the appropriate data solution Develop, implement, communicate, and maintain automated processes adhering to the deployment and support standards Develop data quality metrics that identify gaps and ensures compliance with standards across the enterprise Lead analysis, estimation, planning and implementation of data solutions Serve as a liaison with functional groups around data and BI. Lead planning and execution of multiple, simultaneous initiatives Conduct business data analysis and design to support effective report development and business decisions Leverage external best in class reporting solutions to support data needs Understand the data ecosystem to support placing data in the correct infrastructure Create the processes to show where and how data should be moved / aggregated once it is landed from source systems into the data lake environment (S3) Create the design and models for combing data across sources for efficient query patterns from BI and analytics Ensure governance standards are followed Review ongoing performance of existing assets and modify if needed Fast-track the use of Redshift and other AWS tools & services across the data lake environment We Offer: Meaningful and challenging work opportunities to accelerate technology and innovation in a secure and compliant way. Competitive compensation Excellent medical, dental, supplemental health, life and vision coverage for you and your dependents with no wait period Life and disability insurance A great 401(k) with match Tuition assistance, paid parental leave and backup family care. Dynamic, modern work environments that promote collaboration and creativity. Flexible time off, dress code, and work location policies to balance your work and life in the ways that suit you best. Social responsibility in all aspects of our work. We volunteer within our local communities, create educational alliances with colleges, drive a variety of initiatives in sustainability, and advocate for diversity & inclusion in all that we do. Primary Location: Remote - United States Other Locations: Job: IT Schedule: Full time Equal Employment Opportunity: Guardian is an equal opportunity employer. All qualified applicants will be considered for employment without regard to age, race, color, creed, religion, sex, affectional or sexual orientation, national origin, ancestry, marital status, disability, military or veteran status, or any other classification protected by applicable law."
USA - Data Engineer-Python Pyspark,Avestacs,Remote,https://www.indeed.com/rc/clk?jk=eb62262eec4672c8&fccid=029422091c50af35&vjs=3,"Job Title: Data Engineer-Python Pyspark Type: 6-12 months Contract to Hire Location: 100% Remote About Client: Our client, a Global Giant in the IT Networking Software & Product space as also Telecommunication hardware If you are: Seeking a work from home, long term contractual opportunity while being engaged with a challenging role and a highly bright and high energy team building out a state of art data solution - please reach out at the earliest. The role offers for a Contract-To-Hire mode of engagement at the Customers sole discretion. Overview: In the role of a Data Software Engineer you would be working as part of a niche team focusing on Data Engineering and Data Processing. Core Expertise: 3 to 5 years of experience - Data Engineering involving Large Complex Diverse data sets AWS Python Pyspark Golang (Nice to have) Spark &/or Hadoop Github/Git"
Data Engineer,Integral Ad Science,"Hybrid remote in New York, NY 10003+10 locations",https://www.indeed.com/rc/clk?jk=e6ff5a56fb00be97&fccid=1dc32badf02d6835&vjs=3,"Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry and we're looking for a Data Engineer to join our Data Engineering team. If you are excited by technology that has the power to handle hundreds of thousands of transactions per second; collect tens of billions of events each day; and evaluate thousands of data-points in real-time all while responding in just a few milliseconds, then IAS is the place for you! As a Data Engineer you will build and expand upon the testing framework and testing infrastructure of IAS' core ad verification, analytics and anti ad fraud software products. The ideal candidate is naturally curious, dedicated, detailed-oriented with a strong desire to work with awesome people in a highly collaborative environment. You should be able to not take yourself too seriously as well. What you'll do: Working on Big Data technologies such as Hadoop, MapReduce, Kafka, and/or Spark in columnar databases Architect, design, code and maintain components for aggregating tens of billions of daily transactions Lead the entire software lifecycle including hands-on development, code reviews, testing, deployment, and documentation for streaming and batch ETL's and RESTful API's Mentor junior team members Who you are and what you have: 5+ years of recent hands-on in object oriented language (Java, Scala, Python) Experience with Hadoop MapReduce, Spark, Pig Experience developing data pipelines in AWS or Google Cloud Strong knowledge of collections, multi-threading, JVM memory model, etc. Understanding of full software development life cycle, agile development and continuous integration Good knowledge of Linux command line tools What puts you over the top: Exposure to messaging frameworks like Kafka or RabbitMQ In-depth understanding of object oriented programming concepts and functional programming concepts Excellent interpersonal and communication skills Superb understanding of algorithms and data structures Experience of designing for performance, scalability, and reliability Good understanding of database fundamentals, good knowledge of SQL IAS strives to maintain a COVID-free workplace and the health and safety of our employees is a priority. IAS implemented a policy that requires all employees (with limited exceptions) to be fully vaccinated and provide proof of vaccination prior to employment, to the fullest extent permitted by applicable law. About Integral Ad Science Integral Ad Science (IAS) is a global leader in digital media quality. IAS makes every impression count, ensuring that ads are viewable by real people, in safe and suitable environments, activating contextual targeting, and driving supply path optimization. Our mission is to be the global benchmark for trust and transparency in digital media quality for the world's leading brands, publishers, and platforms. We do this through data-driven technologies with actionable real-time signals and insight. Founded in 2009 and headquartered in New York, IAS works with thousands of top advertisers and premium publishers worldwide. For more information, visit integralads.com or email us at careers@integralads.com. Equal Opportunity Employer: IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply. California Applicant Pre-Collection Notice: We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com. To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership. #LI-Hybrid"
Data Engineer,RISIRISA,"New York, NY",https://www.indeed.com/rc/clk?jk=cb6316daece026d4&fccid=570de3d15b9bbb97&vjs=3,"Location: New York, NY Department: Engineering Type: Full Time Min. Experience: Mid Level RISIRISA is looking to hire a Data Engineer to join its team in New York. You will collaborate with Data Scientists and Design Technologists to build custom, data-driven tools to help our clients in the commercial, public, and social sectors solve a wide range of complex human-scale problems spanning global development, music, health, cybersecurity, etc. Requirements Ability to wrangle and process large data files into usable formats and databases Experience designing algorithms to perform analysis and aggregation on data Experience building and deploying production-level web services Enthusiasm for learning new techniques and technologies to solve hard problems Technical skills we look for: Python SQL Java Hadoop Ecosystem (Hive, Pig, etc.) Web/API building Familiarity with Javascript and NodeJS Familiarity with Git for version control Bonus: PHP Familiarity with production deployment and administration in Linux, Amazon AWS, Heroku, etc. Django NoSQL (Mongo, etc.) PostGRES Redis C++ iOS/Android development Apply to ris@risirisa.com"
Requirements Engineer- Data Induction,iptiQ,"Armonk, NY+1 location",https://www.indeed.com/rc/clk?jk=ddd250e21158c6aa&fccid=3d77e47fb96f2034&vjs=3,"About Swiss Re Corporate Solutions Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer. We anticipate and manage risks, from natural catastrophes and climate change to cybercrime. Swiss Re Corporate Solutions is the commercial insurance arm of the Swiss Re Group. We offer innovative insurance solutions to large and midsized multinational corporations from our approximately 50 locations worldwide. We help clients mitigate their risk exposure, whilst our industry-leading claims service provides them with additional peace of mind. Our success depends on our ability to build an inclusive culture encouraging fresh perspectives and innovative thinking. Swiss Re Corporate Solutions embraces a workplace where everyone has equal opportunities to thrive and develop professionally regardless of their age, gender, race, ethnicity, gender identity and/or expression, sexual orientation, physical or mental ability, skillset, thought or other characteristics. In our inclusive and flexible environment everyone can bring their authentic selves to work. About the Team In this position, you are part of a team supporting the Data Induction into the policy administration system used by several types of Commercial P&C insurance products of Swiss Re Corporate Solutions North America. The team's main focus is to consistently provide superior customer service to our underwriting business partners. We respond to issues and requests for change to the functionality as well as continue to find ways to deliver operational efficiencies. To ensure consistent customer focus, strong relationships have been built with our business partners and vendors. The Requirements Engineer serves as the principal conduit between the business and the software development team throughout the lifecycle of an issue or change request. Job Description In this position, you are responsible for supporting the Product Owner in defining user stories and detailing out mapping requirements with business support for the use of integration into the policy administration system. In supporting the business, you will be responsible for collaborating with the business team members, internal IT team members, and vendor team members. Main tasks will include: Gather and understand requirements; work with clients, users, business/product owners & SMEs to understand their requests and be able to translate and breakdown requests into user stories; authoring additional requirements artifacts and project documentation as needed. Understand the overall Landscape architect from an End-to-end perspective; work with developers in finding best solutions from a user perspective Support systems ensuring all changes are adequately tested, coordinating changes to production with our vendor partner, and handle notification of system outage. Ensure that system changes are in line with business requirements by creating test plans & expected results, conducting some testing, and coordinating with the testing team to review test results. Provide support to end users when they identify issues – attempt to resolve the issues or ensure issues are reported/logged with developers, the correct priority is set, and workarounds are identified. Review & update knowledge-based articles used for production support as needed. Support/Coordinate testing of infrastructure changes. Be an integral part of the team by supporting our need for continuous improvement of our processes and operational efficiency. About You Bachelor's Degree or equivalent preferred Solid understanding of the fundamentals of system analysis & design Familiarity with the Software Development Life Cycle and Agile concepts Experience with Agile methodology, writing user stories, open collaboration, etc Strong verbal and written communication skills with proven ability working in globally located team situations, understanding and demonstrating sensitivity toward cultural differences Ability to cultivate networks throughout an organization to gather support and create a foundation for future influence Sound decision-making skills and ability to take decisive action Ability to align priorities of own area with the direction and priorities of the broader organization Flexibility with changes in tasks and priorities Demonstrate a willingness to adapt to shifting or competing priorities and try new things, even at the risk of failure. Solid understanding of Commercial Insurance Knowledge of insurance policy transactions and lifecycles Solid understanding of data models / table structures with demonstrable ability to create / implement SQL, conduct data analysis and provide conclusions Ability to map/conform data to support policy administration system Familiarity with Webservices, XML, JSON and API a plus Swiss Re is an equal opportunity employer. It is our practice to recruit, hire and promote without regard to race, religion, color, national origin, sex, disability, age, pregnancy, sexual orientations, marital status, military status, or any other characteristic protected by law. Decisions on employment are solely based on an individual's qualifications for the position being filled. During the recruitment process, reasonable accommodations for disabilities are available upon request. If contacted for an interview, please inform the Recruiter/HR Professional of the accommodation needed. As the COVID-19 pandemic continues to impact the world, it is our responsibility to help keep our employees, customers, partners and communities healthy and safe. SwissRe will require all candidates interviewing in person in Canada to provide evidence of vaccination when arriving at our offices."
Data Center Engineer,Sauce Labs Inc.,"Santa Clara, CA",https://www.indeed.com/company/Sauce-Labs/jobs/Data-Center-Engineer-8f8d1c7f9780be42?fccid=d17f420cd4ceec5e&vjs=3,"Sauce Labs is the leading provider of continuous testing solutions that deliver digital confidence. The Sauce Labs Continuous Testing Cloud delivers a 360-degree view of a customer's application experience, ensuring that web and mobile applications look, function, and perform exactly as they should on every browser, OS, and device, every single time. We're already transforming the way companies approach testing at organizations like Walmart, Verizon Media, and Charles Schwab.The role: On a daily basis, you will be working directly with our highly available systems which are the foundation of Sauce Labs. Becoming part of our growing multi-national team of DevOps professionals means you will have a direct, daily impact on improving our users' experience. You will be contributing to the successful operation and scaling of the Data Center infrastructure that powers Sauce Labs. We launch over 10 million virtual machines a month and supply our customers with remote access to thousands of real mobile devices; one of the biggest public cloud of real mobile devices on the market.Responsibilities Work alongside an international and geographically distributed team of engineers/technicians Apply best-practice methodology for maintaining a Data Center environment Help to plan, manage, and execute our data center build-outs Create rack elevations Calculate power consumption Plan and execute clean, and extendable cabling Hands-on with infrastructure provisioning and server/network equipment deployments Handle shipping and receiving with various vendors Document and maintain an up-to-date inventory list of all equipment, and device and network connections Assist with automated provisioning processes for streamlining hardware deployments Assure sufficient supplies and hardware such as PDUs, cables, optics, storage drives, etc. Troubleshoot and remedy dc hardware issues; document findings in tickets Manage the real mobile devices in our cloud Handle the purchase, configuration and maintenance of mobile devices (iPhone, Android) in a Data Center environment Handle tickets autonomously, as well as, in cooperation with Support and to troubleshoot our real devices Work with the Operations team and Developers to improve the stability of consumer electronics in a Data Center environment Help to grow the real device cloud setup in line with increasing demands, and constant technology adaptations in consumer electronics On-Call Rotation 24x7 Periodic trips to other company sites in the US Requirements 1+ years recent experience working as a Data Center Engineer or Equivalent Familiarity with Linux/Unix based systems Knowledge of Layer 1 network technologies (optics, network cable types, etc.) Familiarity with Data Center power delivery and power standards Basic knowledge of enterprise and consumer hardware and their similarities/differences (CPU, RAM, SSD, etc.) Basic understanding of the following technologies: TCP/IP, Routing, Linux, SAN, RAID, host configurations Physical work ability to lift at least 25-75 lbs on a regular basis Please find a link to our amazing benefits and perks hereSecurity responsibilities at Sauce: At Sauce, we will commit to supporting the health and safety of employees and properties, partnering with internal stakeholders to learn and act on ever-evolving security protocols and procedures. You'll be expected to fully comply with all policies and procedures related to security at the department and org wide level and exercise a 'security first' approach to how we design, build & run our products and services.Sauce Labs is proud to be an Equal Opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender identity/expression/status, sexual orientation, age, marital status, veteran status or disability status.#LI-CS2 Job Type: Full-time"
Senior Software Engineer: Data Team,Codecademy,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=ee9a8abb2e1b3b9c&fccid=b9d4e9eceb3ff4c0&vjs=3,"We are NYC based, but remote friendly unless specified. (US & Canada based candidates only) Hello, World! Codecademy is on a mission to build inspiring careers in technology through engaging, accessible, and interactive online coding education. Our learners have gone on to start new jobs, launch new companies, and lead new lives thanks to their work with Codecademy, and our platform has transformed the way businesses develop and retain their teams. Since 2011, our team has grown to over 200 employees serving 50+ million learners from 190+ countries. We've raised over $82M in venture capital funding from top investors including Prosus, Owl Ventures, Union Square Ventures, Y Combinator, and more-which gives us the capital to get stuff done in an impactful way. Join us to help build a business that empowers tens of millions of people to lead better lives! We are NYC based but remote friendly! A company's ability to track events is the key to improving and optimizing its business model. An event provides information about how users interact with the company website and its product. Determining what events to track is foundational in this context, as there are hundreds or thousands of possibilities. As a result, Codecademy is looking for a Senior Software Engineer to join our data team and partner with Product, Engineering, Marketing and Design to devise a strategy to track events in our platform. Our application continues to collect and process thousands of data points each day, we use this data to provide more intelligent recommendations and learning solutions for our millions of learners. We believe that everyone's learning journey is unique and we can leverage data to personalize learning for each user. Our data team works on three key areas: building a data platform, building and supporting ML models, and building and supporting analytics (internal and external). In this role you work with engineering and design teams to implement event tracking across our products so we can better understand all of our different learners. WHAT YOU'LL DO Assess our current client-side, server side events, corresponding metadata, and tracking specs. Partner closely with the Product, Engineering, Marketing and Design teams and other key stakeholders to formulate questions for analysis. Translate questions into related events and processes. Determine what events to track. Build and maintain the event tracking system for both internal and external use cases. Design, define, implement, optimize and maintain new and existing events and their properties, entities, naming conventions and data tracking plans. Collaborate with a cross-functional team of product managers, software/data/analytics engineers and data scientists. WHAT YOU'LL NEED Ability to think critically about Codecademy's business model and how it can be improved. The ability to break down real-world situations into stages that can be described by event data. Fluency in these languages: JavaScript/TypeScript, Ruby. A plus if you are familiar with Ruby on Rails, React, and NextJS (or similar frameworks). Familiarity with the database technologies we use in production: MongoDB, Redis, PostgreSQL. Ability to make pragmatic engineering decisions, write extensive tests and create documentation. Strong project management skills; a proven ability to gather and translate requirements from stakeholders across functions and teams into tangible results. WHAT WILL MAKE YOU STAND OUT Experience working with Customer Data Platform (we use Segment) and Object-action framework. Experience with tools in our current warehousing stack: Apache Airflow, Snowflake, Segment, Apache Kafka/Confluent, dbt, Looker. Experience with Segment ecosystem - Protocols, Personas, Journeys, Functions. Experience in protecting users' privacy and familiarity with GDPR & CCPA. Comfort with containerization technologies: Docker, Kubernetes, etc. At Codecademy, we are committed to teaching people the skills they need to upgrade their careers. Codecademy aims to educate a richly diverse demographic of users with our product and in order to accomplish this, we believe our team should reflect that rich diversity. Our company celebrates diversity in all of its forms- race, gender, color, national origin, marital status, sexuality, religion, veteran status, age, ability, disability status- and works to create an inclusive workplace where people of all backgrounds and beliefs are empowered to better their futures. #LI-Remote Equal Employment Opportunity At Codecademy, we are committed to teaching people the skills they need to upgrade their careers. Codecademy aims to educate a richly diverse demographic of learners with our product and in order to accomplish this, we believe our team should reflect that rich diversity. Our company celebrates diversity in all of its forms- race, gender, color, national origin, marital status, sexuality, religion, veteran status, age, ability, disability status- and works to create an inclusive workplace where people of all backgrounds and beliefs are empowered to better their futures. #LI-Remote"
Data Engineer,Advia Credit Union,"Hybrid remote in Elkhorn, WI 53121+5 locations",https://www.indeed.com/rc/clk?jk=596b6e57e1c2c630&fccid=6c941f895fa91c04&vjs=3,"Employment Type: Full-Time, Hybrid #LI-HYBRID What you should know about the role The Data Engineer will be the steward for structured data for Advia Credit Union. They will collaborate with the Infrastructure Team and third-party vendors to design, manage, build, and maintain the structured data solutions for Advia Credit Union. This is accomplished by providing outstanding service to both internal and external members as defined by living and demonstrating the core values of the credit union, Act with Integrity, Drive Progress, Build and Strengthen Relationships and Keep People at the Core. What you should know about Advia Advia is a fast-growing Credit Union that is positioned in the top 3% of credit unions across the United States with over 2 billion in assets. We offer very similar product and services as the big banks with a focus on saving our members money while providing financial advantages. We are rooted in our communities and believe we have a responsibility to give back outside of our four branch walls through volunteering and charitable donations. The work environment at Advia is fast-paced, performance based and fun infused. We certainly live by the saying “work hard, play hard.” As an employee of Advia, you can expect regular and constructive feedback, development opportunities, great benefits, excellent co-workers and engaged managers. As a Data Engineer, you will have opportunities to: Create, and ensure updating of, information and data ow diagrams in conjunction with Technical Architect. Collaborate with Infrastructure Team to ensure data warehouse servers are patched and updated as necessary. Responsible for the designation of authoritative data, and documentation of the sources. Key contributor to the Data Governance, Data Classification, and Data Management programs. Build required infrastructure for optimal extraction, transformation and loading of data from various data sources using SQL and Python scripting languages. Identifying, designing, and implementing internal process improvements including redesigning infrastructure for greater scalability, optimizing data delivery, and automating manual processes. Assembling large, complex sets of data that meet non-functional and functional business requirements. Responsible for managing internal relationships, and providing guidance to data usage for, reporting specialists throughout Advia Credit Union. Additionally responsible for managing relationships with third party managed service providers. Responsible for designing policies for structured data management within the guidelines provided by regulatory boundaries as well as the retention schedule set forth by the Advia Risk department. Must comply with applicable laws and regulations, including but not limited to, the Bank Secrecy Act, the Patriot Act, and the Office of Foreign Assets Control. Additionally, all employees must follow policies and procedures to minimize risk by exercising judgment, raising questions to management, and adhering to policy guidelines. Experience Five years to eight years of similar or related experience, including preparatory experience. Education/Certifications/Licenses A college degree. Interpersonal Skills The ability to motivate or influence internal or external senior level professionals is a critical part of the job, requiring a significant level of influence and trust. Obtaining cooperation and agreement on important outcomes via frequently complex, senior level dialogues, as well as a professional level of written communication skills are essential to the position. Physical Requirements Is able to bend, sit, and stand in order to perform primarily sedentary work with limited physical exertion and occasional lifting of up to 10 lbs. Must be capable of climbing / descending stairs in an emergency situation. Must be able to operate routine office equipment including computer terminals and keyboards, telephones, copiers, facsimiles, and calculators. Must be able to routinely perform work on computer for an average of 6-8 hours per day, when necessary. Must be able to work extended hours or travel off site whenever required or requested by management. Must be capable of regular, reliable and timely attendance. Working Conditions Must be able to routinely perform work indoors in climate-controlled shared work area with minimal noise. Mental and/or Emotional Requirements Must be able to perform job functions independently or with limited supervision and work effectively either on own or as part of a team. Must be able to read and carry out various written instructions and follow oral instructions. Must be able to complete basic mathematical calculations, spell accurately, and understand computer basics. Must be able to speak clearly and deliver information in a logical and understandable sequence. Must be capable of dealing calmly and professionally with numerous different personalities from diverse cultures at various levels within and outside of the organization and demonstrate highest levels of customer service and discretion when dealing with the public. Must be able to perform responsibilities with composure under the stress of deadlines / requirements for extreme accuracy and quality and/or fast pace. Must be able to effectively handle multiple, simultaneous, and changing priorities. Must be capable of exercising highest level of discretion on both internal and external confidential matters."
"Software Engineer 2, Big Data",Intuit,"Mountain View, CA 94043+5 locations",https://www.indeed.com/rc/clk?jk=2f08c929abfa99c3&fccid=9784ae78e9834539&vjs=3,"Overview Our formula for innovation begins with agile, cross-functional teams that welcome diverse perspectives and embrace collaboration. Inspirational working environments help spark fresh ideas, with state-of-the-art technology and creative workspaces that allow our team to decide how they want to work. And our shared commitment to make a meaningful impact for our customers helps us push the boundaries of technology to uncover new possibilities. If you have a commitment to excellence and a passion for innovation, come join our team. What you'll bring How you will lead"
Senior Data Engineer,Discord,"Hybrid remote in San Francisco, CA 94107",https://www.indeed.com/rc/clk?jk=386968bf9bffd7f3&fccid=f2ab4689def17626&vjs=3,"Discord is looking for experienced and passionate data engineers to join our Data team! As one of the early data engineers at Discord, you’ll have an outsized impact on our data foundations. Data Engineers at Discord collaborate with data science and engineering teams to design, build, and scale high-leverage datasets that enable analytics, modeling, and experimentation. These critical datasets directly inform how we identify opportunities, measure success, and drive decision making. If this sounds exciting to you and you’re passionate about data, impact, and working on an amazing team, read on! Check out our blog here! What you'll be doing Create and maintain data pipelines and foundational datasets to support analytics, modeling, experimentation, and product/business needs Design and build database architectures with massive and complex data, balancing ergonomic benefits with computational load and cost Collaborate closely with data science and engineering teams to improve the coverage, accuracy, and reliability of instrumentation Develop audits for data quality at scale, implementing alerting and anomaly detection as necessary Create scalable dashboards and reports to support business objectives and enable data-driven decision making Partner with data scientists, engineers, and product teams to accomplish all of the above!&nbsp; You'll Thrive In This Role If (not hard qualifications - if you're not sure, please apply!) 4+ years of experience building data pipelines in production with deep knowledge of performant scalable patterns 4+ years of experience in designing, developing, and maintaining robust data models from structured and unstructured sources &nbsp; 4+ years of experience writing accurate and effective code in SQL and Python Experience implementing and monitoring audits for data quality with massive data sets (e.g. billions of rows)&nbsp; Experience proactively identifying opportunities to improve ETL &amp; dashboard performance and cost Experience leveraging your excellent communication skills to thrive in ambiguous environments where problems are not well-defined and evolve quickly&nbsp; A desire to work with amazing, passionate people who care deeply about solving challenging problems to improve Discord. Last but not least - a collaborative attitude and a healthy dose of natural curiosity!&nbsp; Bonus Points Passion for Discord or online communities Experience owning and proactively improving the data models for a functional area&nbsp; Experience collaborating directly with data science and product engineering teams Experience with modern data storage and processing technologies (i.e. BigQuery SQL, Looker, Airflow, and DBT or similar) Experience with designing data architecture to power a variety of use cases, including experimentation&nbsp; New York City residents only: Minimum salary of $205,300 year + equity and benefits*Note: Disclosure as required by NYC Pay Transparency LawColorado residents only: Minimum salary of $164,800 year + equity and benefits*Note: Disclosure as required by sb19-085(8-5-20). #buildbelonging #LI-JF1Benefits and Perks Comprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures) Mental health resources and quarterly wellness stipends 16+ paid holidays, 4 weeks of PTO + use-what-you-need sick days&nbsp; Paid parental leave (plus fertility, adoption and other family planning benefits) Flexible long-term work options (remote and hybrid) Volunteer time off A diverse slate of Employee Resource Groups&nbsp; Plus commuter contributions and other perks for office-based employees About Us Discord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests — from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations. We’re working toward an inclusive world where no one feels like an outsider, where genuine human connection is a click, text chat, or voice call away. A place where everyone can find belonging. Challenging? Heck yes. Rewarding? Double heck yes. It’s a mission that gives us the chance to positively impact millions of people all over the world. So if this strikes a chord with you, come build belonging with us!"
Data Engineer I,American Civil Liberties Union,"Remote in New York, NY 10004+1 location",https://www.indeed.com/rc/clk?jk=9fc795ac60204836&fccid=b386980fa584d9b2&vjs=3,"ABOUT THE JOB The ACLU seeks applicants for the full-time position of Data Engineer I in the Analytics Department of the ACLU's National office in New York, NY/ Remote*. ACLU Analytics partners with teams across the organization to enable the ACLU to make smart, evidence-based decisions and bring quantitative insights on our issues to the courtroom and the public. Our team's work ranges from social science research for litigation & advocacy, to analysis & reporting for fundraising and engagement, to building and maintaining our data infrastructure. We strive to ensure the ACLU leads by example in the ethical use of data and technology. This includes maintaining our privacy and security standards, pushing for transparent data practices from government and corporate actors, and helping to steward high standards for algorithmic fairness, accountability, and transparency. Reporting to the Director of Data Infrastructure, the Data Engineer will be focused on reliably transforming data in the ACLU's internal systems into analysis-ready forms, extracting data from public datasets (e.g. court dockets) and working to improve our overall data and analysis pipeline. Data engineers will work in teams alongside data scientists, data analysts, and business users, to enable the use of innovative data-driven methods and advanced analytics to transform the way the ACLU approaches fundraising, digital communications, and supporter engagement, as well as program work in litigation and advocacy. Note: this position may be approved for remote work from a different U.S. location RESPONSIBILITIES Use transformation tools like Python, DBT, and Looker to maintain a well-tested analytical layer (e.g., modeling donor data from multiple sources into an event stream) Work directly with the Engagement Analytics team to build business logic into our fundraising data warehouse Use and mentor others on the team use data warehousing and SQL best practices to keep our analytics swift and reliable Advise other ACLU engineering teams such as Web and CRM on architecture decisions that impact data quality Support our Legal Analytics team to provide data support for fast developing legal crises Collaborate with leadership of the ACLU Data Infrastructure team to architect complex data pipelines, plan work, and set team policy Communicate complicated technical solutions to members of the ACLU in a friendly and easy to understand way Engage in special projects and other duties as assigned Center principles of equity, inclusion, and belonging in all work, embedding the values in program development, policy application, and organizational practices and processes Commitment to the mission of the ACLU Demonstrate a commitment to diversity within the office using a personal approach that values all individuals and respects differences in regards to race, ethnicity, age, gender identity and expression, sexual orientation, religion, disability and socio-economic circumstance Commitment to work collaboratively and respectfully toward resolving obstacles and/or conflicts PREFERRED QUALIFICATIONS Knowledge of latest trends and technologies in data infrastructure and data warehousing Knowledge of common software engineering best practices (e.g. interacting with file system, using version control) Familiarity with AWS services such as S3, IAM, EC2 Knowledge of Looker and Lookml Knowledge of CRM technologies such as Salesforce COMPENSATION The annual salary for this position is $91,237 (Level H). This salary is reflective of a position based in New York, NY. This salary will be subject to a locality adjustment (according to a specific city and state), if an authorization is granted to work outside of the location listed in this posting. Note that most of the salaries listed on our job postings reflect New York, NY salaries, where our National offices are headquartered. ABOUT THE ACLU The ACLU dares to create a more perfect union – beyond one person, party, or side. Our mission is to realize this promise of the United States Constitution for all and expand the reach of its guarantees. For over 100 years, the ACLU has worked to defend and preserve the individual rights and liberties guaranteed by the Constitution and laws of the United States. Whether it's ending mass incarceration, achieving full equality for the LGBTQ+ community, establishing new privacy protections for our digital age, or preserving the right to vote or the right to have an abortion, the ACLU takes up the toughest civil liberties cases and issues to defend all people from government abuse and overreach. Equity, diversity, and inclusion are core values of the ACLU and central to our work to advance liberty, equality, and justice for all. We are a community committed to learning and growth, humility and grace, transparency and accountability. We believe in a collective responsibility to create a culture of belonging for all people within our organization – one that respects and embraces difference; treats everyone equitably; and empowers our colleagues to do the best work possible. We are as committed to anti-oppression and anti-racism internally as we are externally. Because whether we're in the courts or in the office, we believe 'We the People' means all of us. The ACLU is an equal opportunity employer. We value a diverse workforce and an inclusive culture. The ACLU encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, national origin, marital status, citizenship, disability, veteran status and record of arrest or conviction, or any other characteristic protected by applicable law. Black people, Indigenous people, people of color; lesbian, gay, bisexual, transgender, queer, and intersex people; women; people with disabilities, protected veterans, and formerly incarcerated individuals are all strongly encouraged to apply. The ACLU makes every effort to assure that its recruitment and employment provide all qualified persons, including persons with disabilities, with full opportunities for employment in all positions. The ACLU is committed to providing reasonable accommodation to individuals with disabilities. If you are a qualified individual with a disability and need assistance applying online, please email benefits.hrdept@aclu.org. If you are selected for an interview, you will receive additional information regarding how to request an accommodation for the interview process. The Department of Education has determined that employment in this position at the ACLU does not qualify for the Public Service Loan Forgiveness Program."
Senior Data Engineer,Spring Health,"Remote in New York, NY 10003",https://www.indeed.com/rc/clk?jk=8152c54e0ad56b75&fccid=675ee465d3812bad&vjs=3,"Our mission: to eliminate every barrier to behavioral health. Spring Health is a comprehensive mental health solution for employers and health plans. Unlike any other solution, we use clinically validated technology called Precision Mental Healthcare to pinpoint and deliver exactly what will work for each person — whether that’s meditation, coaching, therapy, medication, and beyond. Today, Spring Health serves more than 200 companies, from start-ups to multinational Fortune 500 corporations, and is a preferred mental health provider to companies like General Mills, Guardian, Bain, and Instacart. We have raised over $300 million from prominent investors including Kinnevik, Tiger Global, Northzone, RRE Ventures, Rethink Impact, Work-Bench, William K Warren Foundation, SemperVirens, Able Partners, True Capital Ventures, and a strategic investor, Guardian Life Insurance. Thanks to their partnership, our current valuation has reached $2 billion. Our mission: to eliminate every barrier to mental health. Spring Health is a comprehensive mental health solution for employers and health plans. Unlike any other solution, we use clinically validated technology called Precision Mental Healthcare to pinpoint and deliver exactly what will work for each person — whether that’s meditation, coaching, therapy, medication, and beyond. Today, Spring Health serves more than 200 companies, from start-ups to multinational Fortune 500 corporations, and is a preferred mental health provider to companies like General Mills, Guardian, Bain, and Instacart. We have raised over $300 million from prominent investors including Kinnevik, Tiger Global, Northzone, RRE Ventures, Rethink Impact, Work-Bench, William K Warren Foundation, SemperVirens, Able Partners, True Capital Ventures, and a strategic investor, Guardian Life Insurance. Thanks to their partnership, our current valuation has reached $2 billion. We are looking for a Senior Data Engineer to join our team. You will help to define our product and engineering roadmaps and work as a part of a cross-functional product team to find elegant solutions to mental healthcare’s many problems. We are an award-winning, passionate, and mission-driven team with the support of leaders in psychiatry, and backed by prominent VCs including Rethink, RRE, and General Catalyst. About the Role At Spring Health we believe that data-driven technology and decision making is a critical part of solving the thorny, complex challenges of provider quality and accessibility in a broken system. We are looking for an experienced Sr Data Engineer who cares about impact, ownership, cross-functional projects, and mentorship. What you’ll be doing: Be part of a team of innovative engineers working on core pieces of our data infrastructure, pipelines, and data services underlying our product Lead and contribute to the code, systems and integrations Work on implementing and designing a data warehouse for all data use cases Work with stakeholders on requirements and solutions for data pipelines and data views Partner with Data Engineering and other stakeholders to improve our data platform Work with data scientists on the team when you discover game-changing opportunities for larger modeling and machine learning projects What we expect from you: Ability to write high-quality code in Python (or related languages) and a track record of shipping impactful data projects Experience in building fault-tolerant data pipelines with logging, alerting and data validation that goes beyond simple scripting Experience implementing and designing data warehouses using MPP databases such as AWS Redshift, Snowflake or BigQuery Ability to build data models using SQL for business analysts to consume with a data governance focus Data visualization experience a plus such as Tableau, Looker Experience working with highly sensitive data in a healthcare environment A track record of making quality vs. deadline tradeoffs in fast paced environments Strong communication skills and ability to generate consensus and buy-in within the team Organizational skills and the ability to simplify complex problems and prioritize what matters most for the sake of the team and the business Experience applying data and analytics concepts to business problems cross-functionally Proven success in partnering with and explaining data and analytics concepts to non-technical team members at any level of seniority Humble, scrappy, highly motivated, and thrive in fast-paced environments Benefits of working at Spring Health: Focus on total health including: Generous medical, dental, vision coverage available day 1 + access to One Medical Access to Spring Health’s platform which includes (10) free therapy sessions Unlimited time off in addition to (12) paid holidays 16-18 weeks paid parental leave $500 per year Wellness Reimbursement Creating a culture you can thrive in: Flexible remote and hybrid work style arrangements Calm Fridays to encourage meeting & distraction free days Donation matching to support your favorite causes Employee resource groups Supporting you financially through: Competitive mix of salary and stock options Employer sponsored 401(k) match In addition to finding people who are truly excellent at what they do, we take our values at Spring Health seriously: Members Come First We are genuine member advocates. Move Fast to Change Lives We build with urgency and intention. Take Ownership We extend trust and hold ourselves accountable. Embrace Diverse Teams & Perspectives We find strength in the diversity of cultural backgrounds, ideas, and experiences. Science Will Win We will achieve impact by innovation and evidence based frameworks. Candor with Care We are open, honest and empathetic. Spring Health is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex, marital status, ancestry, disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. We also consider qualified applicants regardless of criminal histories, consistent with applicable legal requirements. Spring Health is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans. If you have a disability or special need that requires accommodation, please let us know. #LI-remote #LI-OK1 Benefits of working at Spring Health: Focus on total health including: Generous medical, dental, vision coverage available day 1 + access to One Medical Access to Spring Health’s platform which includes (10) free therapy sessions Unlimited time off in addition to (12) paid holidays 16-18 weeks paid parental leave $500 per year Wellness Reimbursement Creating a culture you can thrive in: Flexible remote and hybrid work style arrangements Calm Fridays to encourage meeting & distraction free days Donation matching to support your favorite causes Employee resource groups Supporting you financially through: Competitive mix of salary and stock options Employer sponsored 401(k) match In addition to finding people who are truly excellent at what they do, we take our values at Spring Health seriously: Members Come First: We are genuine member advocates. Move Fast to Change Lives: We build with urgency and intention. Take Ownership: We extend trust and hold ourselves accountable. Embrace Diverse Teams & Perspectives: We find strength in the diversity of cultural backgrounds, ideas, and experiences. Science Will Win: We will achieve impact by innovation and evidence based frameworks. Candor with Care: We are open, honest and empathetic. Spring Health is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex, marital status, ancestry, disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. We also consider qualified applicants regardless of criminal histories, consistent with applicable legal requirements. Spring Health is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans. If you have a disability or special need that requires accommodation, please let us know. #LI-remote"
Data Scientist / Data Engineer,SEVEN,"Marshall, TX 75672",https://www.indeed.com/rc/clk?jk=ae2fad598ffe3650&fccid=3cde71f7f4b78fd8&vjs=3,"Job Description SEVEN Networks develops innovative mobile software solutions that help wireless carriers, mobile device manufacturers, application developers, and end users understand, analyze and optimize the wireless traffic between mobile devices and the cloud. We are looking for a team-oriented Data Scientist or Data Engineer to turn the vast amounts of data collected by SEVEN mobile applications and external data sources into actionable insights for customers of the analytics services, ecosystem partners, and for internal use. This job will be based at our Marshall, Texas headquarters. Responsibilities: Overall responsibility for creating insights from internal and external data sources Provide insight into SEVEN product management and executive team on key performance indicators and improvement opportunities of SEVEN products and users at the marketplace Provide analytics and insights on user behavior, network performance, and mobile application performance to respective customers and ecosystem partners Drive and design improvements to SEVEN mobile products to incorporate data collection that allows continuously better insights Drive and design improvements to SEVEN analytics products from data collection to data frameworks, processing, dashboards and presentation Work with customers and customer support in troubleshooting as a subject matter expert in mobile analytics Qualifications: 2+ years of relevant experience in analysis and statistics, and corresponding analytics engineering skills Technical or Scientific Master’s degree is required with strong background in mathematics. Ph.D. or other advanced degrees are desirable Experience in SQL, R, Python for analytics, combining data from multiple sources, experience in cleaning up data before jumping to conclusions Excellent verbal, written and visual presentation skills Demonstrated ability and curiosity to find and explain stories and insights from the granular data, connecting the data to real-world benefits Experience in business intelligence packages is preferred Experience in Hadoop is preferred Passion for mobile applications and smartphones Job Information Industry Technology City Marshall State/Province Texas Country United States Zip/Postal Code 75672"
Data Engineer (14579),Baer Group,"Remote in Seattle, WA",https://www.indeed.com/rc/clk?jk=7b495cc09699e796&fccid=0596141d02f55160&vjs=3,"**Federal Projects - Applicant must be a United States Citizen with Active Secret Clearance** The Baer Group is looking for Data Engineer for a 12+ month Remote Federal project. Title: Data Engineer Location: Remote (Must be based in US) Duration: 12 months Rate: All-Inclusive *W2 Required for this project (C2C Not Permitted) Opportunity: Our client has recently been awarded a 5-year contract to execute a series of IT modernization programs to improve system and Cybersecurity infrastructure performance, extend key applications, and enable advanced analytics. Consultants engaging on this program will have long term opportunities to leverage a range of leading-edge Cloud, Data and Cyber Security tools to drive unique innovation solutions. Description: Support the Data Architect and Data Modeler roles on the team. Conduct data mining using state-of-the-art methods. Enhance data collection procedures and develop data migration and wrangling scripts. Process, cleanse, and verify the integrity of data used for analysis. Conduct ad-hoc analysis and use visualization tools to develop dashboards, user-friendly reports. Create automated anomaly detection systems and constant tracking of its performance Requirements: Experience with data wrangling and Extract-Transform-Load (ETL) of large volumes of data Experience with data modeling and building data pipelines Experience using open-source and COTS middleware solutions for data integration e.g., Alteryx, R, Python. Alteryx, Python, Apache Hadoop, Data Engineering, Data Wrangling, ETL Architecture & Development Company Overview: The Baer Group is an Enterprise Technology Consulting firm providing job opportunities with several 1st Tier Global Systems Integrators and a wide array of Fortune 1000 clients. Consultants and Employees of TBG enjoy access to the highest profile job opportunities across leading Enterprise Technology Solutions ranging from Digital Transformation programs utilizing the latest technologies from SAP and Oracle to a wide range of emerging Cloud based infrastructure, application and AI related solutions. The Baer Group prides itself on our ability to work directly with key stakeholders to create the most optimized service experience possible for our consultants and our clients. TBG’s job requirements are carefully vetted and are typically associated with mission critical programs offering tremendous opportunities to expand your skills leveraging the latest solutions. TBG focuses on representing jobs that provide streamlined response to our proposed candidates and a best in class engagement experience. refMONa The Baer Group is an equal opportunity employer including disability/veteran."
Data Engineer,LendingTree,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=1b11592f4f22c2fc&fccid=e9e15932789966e0&vjs=3,"Position: QuoteWizard by LendingTree is seeking a Data Engineer to join our Data Engineering team. We have an exciting opportunity to deliver a near real-time data lake and low-latency data warehouse using world class cloud data tools and platforms including Snowflake, DBT, and FiveTran. Data Engineering provides a solid data foundation for analytics and machine learning teams that drive business decisions and strategy that power customer journeys across multiple CRM platforms. This individual will partner with architecture, technology operations, software engineering, analytic teams, and other senior leaders to develop and implement solutions to meet critical data/analytic related business needs and capabilities, while implementing technologies, platforms, and tools aligned to the LendingTree’s data strategy. We are seeking a data engineer who will be passionate about data engineering and building steaming data pipelines and will work with partners across Marketing, Product, Data Science, Analytics, Contact Center, and Technology teams to deliver on enterprise data initiatives. RESPONSIBILITIES Create real-time streaming data solutions Implement large scale, high-performance data analytics, and data integration platforms Design and develop ETL solutions Design, develop, and support database applications spanning multiple lines of business Evaluate performance and cost of data applications/environments and perform appropriate troubleshooting as necessary Collaborate effectively across various departments and teams to implement solutions Work with business users to understand project requirements and resolve issues Craft and maintain technical documents including educational materials, standards, and best practices Participate in on-call rotation for off-hours support Design and develop frameworks and other approaches for rapid development of high-quality data and reporting solutions Collaborate on product roadmap for data engineering to define the capabilities of the platforms and services and delivery timelines Perform complex data analysis to identify trends, patterns, and opportunities QUALIFICATIONS 5+ years of experience doing data warehousing, ETL development, analytics, and writing and debugging complex SQL queries. You have experience with highly scalable, distributed platforms. Experience designing and implementing data lakes and data warehouses. You have knowledge of data warehousing industry standards and standard methodologies. You understand dimensional database modeling. You have excellent data presentation skills, utilizing dashboards and other technologies. You have excellent verbal and written communication skills. You have the ability to design and implement projects with minimal guidance. You have experience with Agile methodologies. You have a dedication to being a phenomenal teammate - sharing success and struggles equally. You have real passion for learning and implementing new tools and supporting standard methodologies. PREFERRED EXPERIENCE B.S. in Computer Science, Mathematics or equivalent Experience working with Snowflake Experience working with SQL Server Experience with data visualization tools, such as Power BI Experience working with Azure Data Factory, DBT, and FiveTran Experience with scripting languages like PowerShell Experience with programming languages such as Python, C# Experience with Git SCM COMPANY QuoteWizard, a LendingTree company, is a dynamic insurance lead generation agency based in Seattle. We have been ranked by the INC 500 as one of the fastest growing private companies in the nation. We have also been listed by the Puget Sound Business Journal as a top company in Seattle. What you should know about LendingTree, our parent company: We’re a publicly-traded company (TREE). We’ve welcomed several other companies into the LendingTree family to augment our efforts at helping borrowers make their most sensible financial choices. We’ve built the LendingTree app and My LendingTree dashboard to give consumers tools to manage and monitor their financial health. CULTURE We’re a fast-paced company with an entrepreneurial bend. We work hard and test our products often. We’re collaborative, ambitious, candid and high-energy. Our teammates are some of the brightest, most talented people you’ll ever work with. We care more about your smarts than we do about the kinds of clothes you wear (but please, do wear clothes to work!), and we’re pretty good about rewarding innovation, creativity and the knack for just getting stuff done (we even have an award for employees called the GSD, “Get Stuff Done”). Come work with us! QuoteWizard by LendingTree is the kind of company that not only promotes diversity and inclusion; we thrive because of these values. We do not discriminate based on race, color, religion (or creed), gender, gender expression, age, national origin, disability, marital status, sexual orientation or military status. Compensation: $50,000-$175,000 DOE Incentive Compensation: Eligible for annual performance bonus Benefits: Medical, dental, vision insurance and 401(k) matching"
Staff Data Infrastructure Engineer,Databricks,"Remote in San Francisco, CA 94105+1 location",https://www.indeed.com/rc/clk?jk=d85d5d3e9ca1308d&fccid=3d0f7ba22a49432f&vjs=3,"While candidates in the listed locations are encouraged for this role, we are open to remote candidates in other locations. As a Senior Data Infrastructure Engineer on the security data infrastructure team you will help build data infrastructure for the security team. You will build reliable, large-scale, multi-geo data pipelines to support detecting threats (internal and external threats) in Databricks systems, incident response forensics analysis and periodic compliance audits. You will build and deploy data pipelines in multi cloud (AWS, Azure and GCP) environments to process data and logs from external SaaS systems The impact you will have: Architect and build data pipelines to collect telemetry and logs from millions of virtual machines running in the cloud (AWS, Azure and GCP). Design the base ETL framework that can be used by all pipelines developed in the security team. Partner with security engineers, detection engineers and incident response engineers to build bronze, silver, gold quality data sets to meet detection, forensics and compliance needs. Develop best practices and standards that can be used by data engineers in the security team to build, optimize and maintain data pipelines. Build tools to detect, improve data quality and monitor data pipeline performance. Perform on-call rotation to support any production issues or troubleshooting production jobs. What we look for: 5+ years of experience in software or data engineering. 3+ years of experience in programming with python, scala or SQL. (preference for python) 3+ years of experience in building data pipelines using Spark or dataframes. 2+ years of experience in AWS, Azure or GCP. Comfortable in exploring new tech or finding creative ways to solve problems. Experience in security engineering or detection engineering. BS in Computer Science/Engineering/Information Systems or equivalent experience Benefits Comprehensive health coverage including medical, dental, and vision 401(k) Plan Equity awards Flexible time off Paid parental leave Family Planning Gym reimbursement Annual personal development fund Work headphones reimbursement Employee Assistance Program (EAP) Business travel accident insurance Mental wellness resources About Databricks Databricks is the data and AI company. More than 7,000 organizations worldwide — including Comcast, Condé Nast, H&M, and over 40% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems."
Satellite Imagery Data Engineer,Google,"Mountain View, CA+4 locations",https://www.indeed.com/rc/clk?jk=516b66ec6ef5fe70&fccid=a5b4499d9e91a5c6&vjs=3,"Minimum qualifications: Bachelor's degree in Computer Science, Engineering, a related field, or equivalent practical experience. 3 years of experience in technical project management, stakeholder management, professional services, solution engineering, or technical consulting. 1 year of experience in technical troubleshooting and writing code in one or more programming languages. Preferred qualifications: Master’s degree in Engineering, Computer Science, Business, or a related field. 5 years of experience developing large scale Information storage and retrieval, mapping technologies, or Geographic Information System (GIS) data visualization tools or GIS oriented web applications. 1 year of experience working with customer-side web technologies (e.g., HTTP, HTML, JavaScript, XML, TypeScript) and database technologies (e.g., SQL, NoSQL). 1 year of experience using Machine Learning and building solutions. About the job As a Satelite Imagery Data Engineer you will strategize, acquire, process, and publish images from various overhead sources, including drones, planes, and satellites. As a part of the Overhead Imagery Operations Team you will help manage the overhead imagery database that's directly used by Users in Maps/Earth and is also used by internal teams to build and maintain our basemap. You will also get to work on projects like Flood Forecasting, Current Events, and AI for Social Good. Responsibilities Design, develop, optimize, and maintain data storage and reporting. Work closely with engineering teams to design and acquire log level data. Create and optimize dashboards. Write and review technical documents, including requirements and design documents for existing and future data systems, and data standards and policies. Coordinate cross-functionally to enable a seamless communication of risks, dependencies and schedules across hardware and software teams. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form."
Network Engineer III Data Center,University of Utah Health,"Salt Lake City, UT 84190",https://www.indeed.com/rc/clk?jk=41e9d213e11bfe46&fccid=c33e93641780afa2&vjs=3,"Overview As a patient-focused organization, University of Utah Health exists to enhance the health and well-being of people through patient care, research and education. Success in this mission requires a culture of collaboration, excellence, leadership, and respect. University of Utah Health seeks staff that are committed to the values of compassion, collaboration, innovation, responsibility, diversity, integrity, quality and trust that are integral to our mission. EO/AA This position will have emphasis in data center network functions. The incumbent is responsible for the design, deployment, maintenance and support of the computer networks, telecommunications networks and related security devices. This position has no responsibility for providing care to patients. Corporate Overview: The University of Utah is a Level 1 Trauma Center and is nationally ranked and recognized for our academic research, quality standards and overall patient experience. Our four hospitals and seventeen clinics provide excellence in our comprehensive services, medical advancement, and overall patient outcomes. Responsibilities Designs and plans network communications systems. Provides specifications and detailed diagrams for network architecture. Provides specific detailed information for hardware and software selection, implementation techniques and tools for the most efficient solution to meet business needs, including present and future capacity requirements. Conducts testing of network design. Maintains technical expertise in all areas of network and computer hardware and software interconnection and interfacing, such as routers, firewalls, gateways, etc. Evaluates and reports on new communications technologies to enhance capabilities of the network. Performs a full range of complex network designs encompassing multiple technologies within a single network. Evaluates new network technologies and makes recommendations to project managers regarding the integration of these technologies into the existing network. Plans new configuration for integration into the network, using knowledge of the performance characteristics of the systems being added to the network and the specifications for network interfaces to insure effective integration and optimal network performance. Prepares technical proposals for presentation to the Sponsor's engineering review boards for adding new technologies to the network. Performs a full range of upgrades to the existing network architecture. Reviews user requests for upgrades or additions to the network to assess impact on network performance and provides advice and guidance on the most practical technical approach to meeting user requirements. Proposes upgrades to existing network configurations, using knowledge of the performance characteristics of the systems being upgraded and the specifications for network interfaces to insure effective integration and optimal network performance. Utilizes complex network analysis tools to identify and correct problems in the network. Prepares troubleshooting procedures for restoring the network to optimal performance levels. Knowledge / Skills / Abilities Knowledge of theory and practice underlying satellite and LAN/WAN network operations. Ability to assess the technical characteristics of new operating capabilities proposed for inclusion in the network to determine potential impact on network performance. Ability to utilize complex network analysis tools to resolve complex network performance problems. Ability to provide explanations of complex technical procedures and processes clearly and accurately to both technical and non-technical audiences. Excellent IP networking fundamentals and extensive experience in the application of IP protocols. In-depth knowledge of and experience with major internet routing protocols; specifically BGP and OSPF. In-depth knowledge of and experience with major router platforms; specifically with Cisco 96xx, 95xx, 94xx, 45xx, 36xx platforms including all compatible supervisory and line cards for these platforms. Excellent network analysis fundamentals and robust troubleshooting skills. Configuring load balancers, troubleshooting traffic engineering using BGP and large scale network design and maintenance is critical. Candidates should also have had significant past experience with, and expertise in many of the following protocols & technologies: DWDM, 802.2/3, 802.1d VLANs/STP, IPv4 & IPv6, TCP (internals & flow control), BGP, OSPF, HSRP/GLBP, PIMv2, IGMP, LDP, TACACS, IPSEC & VPNs, netflow, DNS, HTTP. Experience with mission critical multicast systems is highly desired. Experience designing network and datacenter installations utilizing L2 and L3 protocols is highly desired. Strong Unix skills and the ability to script in Perl, shell, C or C++ is desirable. CCIE Lab and Written a huge plus. Qualifications Qualifications Required Bachelor's Degree in technical discipline such as Electrical Engineer, Computer Science, Information Technology, Systems or Software Engineering or equivalent. Three years industry experience in a similar environment. Qualifications (Preferred) Working Conditions and Physical Demands Employee must be able to meet the following requirements with or without an accommodation. This is a sedentary position that may exert up to 10 pounds and may lift, carry, push, pull or otherwise move objects. This position involves sitting most of the time and is not exposed to adverse environmental conditions. We are University of Utah Health. Employment.utah.edu Immediately Hiring Physical Requirements Carrying, Climbing, Color Determination, Crawling, Far Vision, Lifting, Listening, Manual Dexterity, Near Vision, Non Indicated, Pulling and/or Pushing, Reaching, Sitting, Speaking, Standing, Stooping and Crouching, Tasting or Smelling, Walking EEO Statement University of Utah Health Hospitals and Clinics, a part of The University of Utah, values candidates who have experience working in settings with students from diverse backgrounds and possess a strong commitment to improving access to higher education for historically underrepresented students. Individuals from historically underrepresented groups, such as minorities, women, qualified persons with disabilities and protected veterans are encouraged to apply. Veterans’ preference is extended to qualified applicants, upon request and consistent with University policy and Utah state law. Upon request, reasonable accommodations in the application process will be provided to individuals with disabilities. University of Utah Heath Hospitals and Clinics, a part of The University of Utah, is an Affirmative Action/Equal Opportunity employer and does not discriminate based upon race, ethnicity, color, religion, national origin, age, disability, sex, sexual orientation, gender, gender identity, gender expression, pregnancy, pregnancy-related conditions, genetic information, or protected veteran's status. The University does not discriminate on the basis of sex in the education program or activity that it operates, as required by Title IX and 34 CFR part 106. The requirement not to discriminate in education programs or activities extends to admission and employment. Inquiries about the application of Title IX and its regulations may be referred to the Title IX Coordinator, to the Department of Education, Office for Civil Rights, or both. To request a reasonable accommodation for a disability, please contact the University of Utah Health Hospitals and Clinics Human Resources office at 801-581-6500.If you or someone you know has experienced discrimination or sexual misconduct including sexual harassment, you may contact the Director/Title IX Coordinator in the Office of Equal Opportunity and Affirmative Action: Sherrie Hayashi Director/ Title IX Coordinator Office of Equal Opportunity and Affirmative Action (OEO/AA) 135 Park Building Salt Lake City, UT 84112 801-581-8365 oeo@utah.edu Online reports may be submitted atoeo.utah.edu/ For more information: https://www.utah.edu/nondiscrimination/ To inquire about this posting, email: careers@hsc.utah.edu The University is a participating employer with Utah Retirement Systems (“URS”). Eligible new hires with prior URS service, may elect to enroll in URS if they make the election before they become eligible for retirement (usually the first day of work). Contact Hospitals and Clinics Human Resources at (801) 581-6500 for information. Individuals who previously retired and are receiving monthly retirement benefits from URS are subject to URS’ post-retirement rules and restrictions. Please contact Utah Retirement Systems at (801) 366-7770 or (800) 695-4877 or Hospitals and Clinics Human Resources at (801) 581-6500 if you have questions regarding the post-retirement rules. This position may require the successful completion of a criminal background check and/or drug screen. Requisition Number 51607 Reg/Temp Regular Employment Type Full-Time Shift Day Work Schedule 8-5 Location Name Information Technology Services Patient Care? No City SALT LAKE CITY State UT Department COR ISC 17A INFRASTRUCTURE OPS Category Information Technology"
Assoc Data Engineer,"The Travelers Companies, Inc.","Hartford, CT+23 locations",https://www.indeed.com/rc/clk?jk=cbe437d1e32bde06&fccid=614604a6208fa23b&vjs=3,"Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $77,000.00 - $127,100.00 Target Openings 1 What Is the Opportunity? The Bond & Specialty Insurance Finance Department is looking for a self-motivated Assoc Data Engineer to provide support for our Financial Data Management group. Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As an Associate Data Engineer you will aid in growing and transforming our analytics landscape. You will leverage your ability to rapidly grasp and design new technologies, as well as your creativity and curiosity to capture, explore and transform data to support Artificial Intelligence, Machine Learning and business intelligence/insights. This also includes supporting business and financial applications, as well as downstream system feeds and external reporting. This position requires working closely with IT teams in an Agile environment as well as with various business partners. This individual will be expected to become an expert in transactional financial data for Bond & Specialty Insurance front-end systems, financial applications, and system feeds. What Will You Do? Build rudimentary data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions. Assist in the operationalization and automation of data products. Analyze common sources to determine value and recommend data to include in analytical processes. Interact and collaborate with team and business users to support delivery and educate end users on data products/analytic environment. Perform data and systems analysis, assessment and resolution for defects and incidents. Test data movement, transformation code and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Two years of related experience Developing knowledge of tools, techniques, and manipulation including Cloud platforms, programming languages, and software engineering practices. What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. One year of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We value the unique abilities and talents each individual brings to our organization and recognize that we benefit in numerous ways from our differences. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/ ."
Data / BI Engineer,TARGET,"Brooklyn Park, MN 55445 (Oak Grove area)",https://www.indeed.com/rc/clk?jk=894029e93456b2e9&fccid=15f43d82dc901ff2&vjs=3,"JOIN US AS A DATA / BI ENGINEER About us: As a Fortune 50 company with more than 350,000 team members worldwide, Target is an iconic brand and one of America's leading retailers. Target as a tech company? Absolutely. We’re the behind-the-scenes powerhouse that fuels Target’s passion and commitment to cutting-edge innovation. We anchor every facet of one of the world’s best-loved retailers with a strong technology framework that relies on the latest tools and technologies—and the brightest people—to deliver incredible value to guests online and in stores. Target Technology Services is on a mission to offer the systems, tools and support that guests and team members need and deserve. Our high-performing teams balance independence with collaboration, and we pride ourselves on being versatile, agile and creative. We drive industry-leading technologies in support of every angle of the business, and help ensure that Target operates smoothly, securely and reliably from the inside out. As an Engineer, you serve as a technical specialist delivering the engineering that powers the product. You develop keen insight into the technical architecture and design to deliver robust and scalable software components. You constantly demonstrate the depth of your expertise by solving engineering problems. You are passionate about the quality of software and balance between speed of delivering new features and robustness of the software components you implement. You can handle operational issues with little or no oversight. You actively review code to ensure the software quality and functional accuracy is maintained across the team. You are keen to learn the design and architecture of the product and participate in ceremonies that can influence both. Use your skills, experience and talents to be a part of groundbreaking thinking and visionary goals. As an engineer, you’ll take the lead as you… Use your technology acumen to provide input to assist with evaluation of new technologies and contribute to the design, lifecycle management, and total cost of ownership of services. Contribute to research and proof-of-concept initiatives for new technologies and assist with code review and design review, writes, organizes and maintains code based on designs. With guidance, delivers high-performance, scalable, repeatable, and secure deliverables. Participate in structured construction, automation, debugging, and implementation activities, ensuring architectural and operational requirements and best practices are met. Participate in disaster recovery planning and disaster recovery activities and participate in functional integration and regression testing and ability to automate test scripts. Resolve frequently encountered technical issues and monitors systems capacity with minimal assistance. Search and understand metadata about various data sources and metrics. Adhere to change and incident management standards and expectations. Core responsibilities are described within this job description. Job duties may change at any time due to business needs. About you: 4 year degree or equivalent experience 1+ years of software development experience Demonstrates familiarity with current and emerging technologies in own scope of responsibility, and develops ability to apply these technologies Understands concepts of package solutions and package specific programming language with knowledge of development objects Demonstrates and continuously builds upon domain-specific knowledge Demonstrates proficiency in at least one computer language Understands the concepts of distributed programming and applies it to their domain Possesses working knowledge of transaction codes/master data used within specific domain and participates in building custom solutions in the package Maintains technical knowledge within areas of expertise Stays current with new and evolving technologies via formal training and self-directed education Americans with Disabilities Act (ADA) Target will provide reasonable accommodations (such as a qualified sign language interpreter or other personal assistance) with the application process upon your request as required to comply with applicable laws. If you have a disability and require assistance in this application process, please visit your nearest Target store or Distribution Center or reach out to Guest Services at 1-800-440-0680 for additional information. Qualifications:"
NGS Data Quality Engineer,National Football League,"Remote in Inglewood, CA 90301",https://www.indeed.com/rc/clk?jk=1726d4c7158fb93a&fccid=85ac7fb3b19d15f1&vjs=3,"Whether you are looking to join our NFL League office in New York City, NFL Films office based in Mt. Laurel, New Jersey, the NFL Media offices in Inglewood, California or one of our international offices, on your journey you will be met with the excitement that comes with working for the NFL. We consider ourselves to be stewards of the game of football and most importantly, we consider working for the NFL to be fun. There is a fulfillment unlike any other that comes from working alongside like-minded individuals to achieve a common purpose. Whether you are working to deliver a memorable Super Bowl or play a hand in the process of delivering games to millions of fans on Sundays— we believe all of us play an important role in helping to fulfill the NFL’s mission of working to unite people and inspire communities. Summary The NFL's Next Gen Stats team is seeking associates for its player tracking project to help with game data review and verification. Candidate will work closely with Next Gen Stats engineering team by assisting the team in reviewing all plays during live games in preseason and on Sundays during regular season, ensuring data is correct and making necessary changes when it is not. The ideal candidate for this position loves football and enjoys immersing themselves in data and finding insights. Candidates must be self-motivated and available on Sundays for the entirety of the season (Aug-Jan). NOTE: This is a remote position on Sundays only during the NFL season. Essential Functions Review and verify data on all plays during live games Ensure all plays have data and video mapped properly Confirm player participation on a play-by-play basis Confirm all advanced statistics are created post play Make necessary changes to data when incorrect using in house developed web-based tools Required Education and Experience Strong football knowledge Must be computer savvy (Chrome, Slack, Google Docs/Sheets, Zoom, etc.) Detail-oriented and reliable Strong problem solving and analytical skills Preferred Education and Experience Hands on experience with data manipulation a plus Other Key Attributes / Characteristics This is a remote position. Must work game days during preseason (Thu-Sun) and Sundays during regular season. Candidates must be available for all 18 Sundays during regular season. A reliable internet connection is required, everything else will be supplied. All applicants must be eligible to work in the United States. No relocation or visa sponsorship is available for this position. Travel: None Expected Hours of Work 4 hours per game / 8 hours on Sundays The NFL maintains a Flexible Workplace Policy that provides members of our workforce with opportunities to periodically work from a location of their choice, while maintaining a priority on in-person work at an NFL office, which enables us to more effectively collaborate, connect and build a workplace culture that will drive our continued success. We also continue to prioritize the health and safety of our NFL workforce. Consistent with that commitment, considering the substantial and growing body of evidence that vaccinations remain the most effective protection against the spread the COVID-19, we require that members of our NFL workforce be fully vaccinated. Exceptions are available only for those who need an accommodation for a qualifying disability or sincerely held religious belief or practice. The NFL is committed to building a diverse, equitable and inclusive work environment that reflects our incredibly diverse fan base. We provide an environment of mutual respect where equal employment opportunities are available to all employees and applicants without regard to status as protected by applicable federal, state, or local law."
Data Science Engineer,Triangulate Labs,"Remote in Cincinnati, OH",https://www.indeed.com/rc/clk?jk=981acc88e8b53811&fccid=f1678279740a4c2b&vjs=3,"Triangulate Labs is looking for a Data Science Engineer who will work closely with our technically minded founders to build and validate predictive analytics models using machine learning. You can expect to work on internal research and development as well as specific client engagements. What we’re looking for: Strong probability and statistics background Proficient in predictive analytics Proficient with Python and/or R and current high-performance machine learning libraries Degree in Computer Science, Engineering, Mathematics, or similar field– Advanced degree is a plus Collaborative attitude Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future This is a full-time position based in Cincinnati, Ohio. Telecommuting may be considered for experienced candidates. Interested in joining our team? If you are ready to work in a dynamic, fast-paced environment, apply by sending your resume and cover letter to contact@triangulatelabs.com."
BI Data Engineer,GoTo,Remote,https://www.indeed.com/rc/clk?jk=303d497cbf79f54d&fccid=75d8817dffc3069a&vjs=3,"Job Description Engineering at GoTo We’re the trailblazers of remote work technology. We build powerful, flexible work software that empowers everyone to live their best life, at work and beyond. And blaze even more trails along the way. There’s ample room for growth – so you can blaze your own trail here too. When you join a GoTo product team, you’ll take on a key role in this process and see your work be used by millions of users worldwide. The Corporate BI (CBI) Team is looking for a BI Data Engineer to help build and maintain standardized, actionable data sets to provide reporting for our executive and functional leaders. The BI Data Engineer will work closely with the team’s reporting analysts as well as a wide range of stakeholders to continue to build out and support our corporate metrics program. As the providers of standardized definitions and centralized reporting data sets, the CBI Team enables GoTo stakeholders, from analyst to sales rep to executive, to better understand and trust the KPIs used to measure the health of the company. Your Day to Day: As a BI Data Engineer you will: Collaborate with CBI Tableau reporting team and downstream stakeholders to build data sets supporting our enterprise reporting and analytics workbooks Design and document data models for use by our GoTo analytics teams Share ownership with other CBI Team members to maintain and grow our existing catalog of certified data sources Assist with establishing and upholding best data practices for ETL pipelines Support GoTo analytics teams by acting as a technical resource for solving complex problems with data Partner with the GoTo Data Engineering team to understand company data flows from source to target to reporting layers What We're Looking For: As a BI Data Engineer your background will look like: 2+ years’ experience in a business intelligence or data analytics role Proficient in SQL, data visualization tools a plus (Tableau), Python/PySpark a plus, Databricks a plus Experience with Salesforce/Sales reporting a plus Experience gathering requirements from business stakeholders and transitioning these to data sets for reporting and analytics Familiarity with traditional data engineering concepts a plus: Agile, data warehousing, big data optimization, git versioning control (Github/Bitbucket) Self-starter, detail-oriented, and excellent communication skills Demonstrated ability to troubleshoot code/queries You’ll be working towards a shared goal with an open-minded and cohesive team greater than the sum of its parts. At GoTo, we’re passionate about growing a diverse and inclusive work ecosystem because unique takes make us a stronger company, and Stronger Together. We’re committed to creating an inclusive space for everyone, no matter what. That’s how we’ll Be Real, Think Big, Move Fast, and Keep Growing along the way."
Data Engineer,"The Leading Hotels of the World, Ltd.","New York, NY 10017 (Midtown area)","https://www.indeed.com/company/The-Leading-Hotels-of-the-World,-Ltd./jobs/Data-Engineer-33d3c34d234e590f?fccid=aefa31d2c62f8d95&vjs=3","Position SummaryAs a Data Engineer, you will work in a cross-functional Agile team environment to comprehensively architect, develop, and maintain databases, data pipelines, and a data warehouse. You will participate in a Data Governance committee and drive discussion about KPIs, data governance, data quality, and data lineage. You will develop and implement strategies for improving analytics capabilities data cleanliness, and machine learning. You will work closely and communicate clearly with Product Owners, developers, architects, and ScrumMasters daily. About you: You can work collaboratively with all team members despite department or position You are able to work independently You have strong problem-solving skills and clearly articulated complexity You can effectively communicate with stakeholders in business terms and high-level technical terms You are able to lead technical discussions using the voice of the business with technical and business stakeholders You are able to reframe and respond to requests in writing You listen and internalize complex business processes and help stakeholders flush out business processes when required You can understand and tell a story to stakeholders about patterns and anomalies in the data On a day to day you will: Architect and implement data pipelines, design data schemas, and maintain transactional databases, data warehouses, and data lakes Collaborate with the Analytics team to provide curated data sets, perform data analysis, and develop data services to make data more accessible Build reports and dashboards to help detect data quality issues Troubleshoot data quality issues and develop solutions to fix immediate data qualities issues and execute long term strategic business and technical initiates Write and maintain documentation: data dictionary, business glossary, and data linage Optimize performance of Redshift data warehouse Evaluate, test, and implement different data engineering tools (mostly AWS resources) Develop and execute plans for increasing data quality Work on and develop strategies for building a data lake Experiment with different products for the implementation of a data lake (mostly AWS resources) Technical Skills and Responsibilities: Design, implement, and QA data pipelines (any language and toolset) Understands APIs and has code development skills (any language), must be able to write code (any language) Understand the concepts and implementation practices of ETL, must be able to use different toolsets Designing databases and data warehouses (Redshift, Dremio, or similar technology), Data strategies for processing med-high data volumes for pushing out to the data warehouse Building SQL (Stored Procedures, Functions, advanced select statements) Excellent debugging and code-reading skills Optimization and monitor database and data warehouse performance Help develop data standards and implement and apply data governance strategies Knowledge and implementation of some reporting technology Knowledge of handling systems with med-high data volume Usage or knowledge of data blending tools Knowledge of machine learning implementation or training Knowledge of NoSQL is a plus As part of the LHW team you will be able to: Able to work with a mid-sized progressive company that is looking to grow their technical abilities Must be able to understand complex business scenarios and learn to speak in the voice of the business Able to work closely with stakeholders and participate and make recommendations in large collaborative groups Work in an agile methodology on all projects (does not require you to know agile methodology) About The Leading Hotels of the World, Ltd. (LHW)Comprised of more than 400 hotels in over 80 countries, LHW is the largest collection of independent luxury hotels. In 1928, 38 independent hoteliers came together to create LHW. Since then, the Company has carefully curated distinctive hotels, resorts, inns, chalets, villas, and safari camps from the snow-capped Alps of Europe to the African veldt, to share them with adventurous souls who seek the remarkably uncommon. The LHW community is filled with exceptional individuals, united by a passion for the surprising discoveries and details that come with every experience. LHW’s collection covers the globe and promises a broad range of destinations and uncommon experiences, enhanced by LHW’s tiered guest loyalty program Leaders Club. From converted former palaces, and countryside retreats run by the same families for generations, to gleaming skyscrapers in dynamic urban centers, serene private island escapes, and glamorous tented camps – and beyond – explore, find inspiration, and experience unforgettable travel moments. For more information visit: www.lhw.com, Facebook at @LeadingHotels, Twitter at @LeadingHotels, and Instagram @leadinghotelsoftheworld LHW is proud to be an equal-opportunity employer. LHW does not discriminate on the basis of religion, race, creed, color, national origin, sex, age, disability, handicap, veteran status, sexual orientation, genetic information, or any other applicable legally protected category. Job Type: Full-time"
Downhole Data Engineer - Sr. to Principal,Halliburton,"Conroe, TX 77385",https://www.indeed.com/rc/clk?jk=5398273c39dca261&fccid=0e4554ac6dcff427&vjs=3,"Downhole Data Engineer - Sr. to Principal Date: Jun 17, 2022 Location: Conroe, TX, US, 77385 We are looking for the right people — people who want to innovate, achieve, grow and lead. We attract and retain the best talent by investing in our employees and empowering them to develop themselves and their careers. Experience the challenges, rewards and opportunity of working for one of the world’s largest providers of products and services to the global energy industry. Roles & Responsibilities: Provide ultra-deep technical support for the in-bit data sensing product line to field operations. Provide expert-level analysis of downhole & surface data, combined with information from other data sources, e.g., bit dull condition, bit run information, lithology, surface operating parameters, and other application information to make best-in-class recommendations for optimizing drilling operations. Develop methods and algorithms for processing and interpreting high and low frequency downhole data. Utilize latest data analytical methods to derive new insights from the available data streams. Qualifications : Experienced with programming and data analysis software, especially MATLAB, Spotfire, Python, etc. Experience with drilling and/or bits preferred Experience with advanced data analysis techniques a plus, e.g., Machine Learning Excellent verbal and written communication skills Skills acquired through the completion of a degree in Mechanical Engineering or similar discipline. Minimum educational requirement of a master’s degree and zero years’ experience or bachelor’s degree and two or more years’ related experience. Mechanical Engineering degree with a preferred 5-10 years' experience in the Oil & Gas Drilling industry. Candidates having qualifications that exceed the minimum job requirements will receive consideration for higher level roles given (1) their experience, (2) additional job requirements, and/or (3) business needs. Depending on education, experience, and skill level, a variety of job opportunities might be available, including RD Mechanical Engineer, RD Senior Mechanical Engineer up to the RD Principal Mechanical Engineer. Halliburton is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, disability, genetic information, pregnancy, citizenship, marital status, sex/gender, sexual preference/ orientation, gender identity, age, veteran status, national origin, or any other status protected by law or regulation. Location 16548 Donwick Drive, Conroe, Texas, 77385, United States Job Details Requisition Number: 151028 Experience Level: Experienced Hire Job Family: Engineering/Science/Technology Product Service Line: Drill Bits and Service Full Time / Part Time: Full Time Additional Locations for this position: Nearest Major Market: Houston Job Segment: Data Analyst, Database, Technical Support, Data, Technology"
Big Data Engineer,harbinger-systems,United States+1 location,https://www.indeed.com/rc/clk?jk=d3fbf3de634dc3eb&fccid=030ece1ae7a221a1&vjs=3,"Date: 14-Jun-2022 Location: US Company: harbinger Position: Data Engineer Experience: 4-6 years Mode: Full Time Mode: Full Time/Permannet Job Description: a. Skill set: Java Spring Batch / SQL / Amazon RedShift / Processing of large data set 1. 4+ years of overall experience 2. 2+ years of experience in ETL and Data Warehousing / Big Data. 3. 2+ years of experience in Java (Nice to have) 4. 2+ years of experience in SQL a. Project: 1. Build and maintain ETL jobs 2. Maintain data lake built on Amazon RedShift. About Harbinger Harbinger is a three-decade young Global Software Services and Product company, headquartered in Pune, India. We build software products for our customers in the domains of HR Tech, Health Tech, Content and Learning Tech. These are exciting times at Harbinger! Powered by an ambitious growth plan built on Innovation, Engineering Excellence and Customer centricity, Harbinger is on a journey of constant reinvention, making the most of upcoming technology and business trends. Agility, Professionalism, People Development, and Meritocracy are the foundation of our culture that pivots on trust, transparency, and continuous learning. We are proud to be a diverse and inclusive organization and an equal opportunity employer. We thrive on an employee-centric work environment, that is not only dynamic and fast-paced, but also focuses on personal and professional development. An open culture, a friendly environment, opportunities to grow under the mentorship of talented seniors and technically sound colleagues, flexible work from home options, a host of employee benefits, and an opportunity to work on cutting edge technologies are some of the things you can expect to experience in Harbinger."
Data Engineer,Melissa Global Intelligence,"Braintree, MA",https://www.indeed.com/rc/clk?jk=ab78dede1acdc089&fccid=a16950eb8ed4ad91&vjs=3,"Braintree, MA × Melissa is seeking a Data Engineer to join our Braintree office. The successful candidate will be responsible for growing our Big Data solutions. You will work on collecting, storing, processing and analyzing large data sets. Primary focus will be on developing processes, consolidating data, and improving data accuracy. Requirements for this position include: BS degree in computer science, software engineering or closely related field. 3+ years of experience in software/database development. A mastery of SQL Server, T-SQL, Stored Procedures and User-Defined Functions. Proficiency in C#, particularly in database access operations. Team player with good communication, interpersonal and organizational skills. Benefits: 401(k). Medical, dental and vision insurance. Paid holidays and personal time off. Within walking distance of T and Commuter Rail. Melissa is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status. THIS CONTRACTOR AND SUBCONTRACTOR SHALL ABIDE BY THE REQUIREMENTS OF 41 CFR 60-300.5(A). THIS REGULATION PROHIBITS DISCRIMINATION AGAINST QUALIFIED PROTECTED VETERANS, AND REQUIRES AFFIRMATIVE ACTION BY COVERED PRIME CONTRACTORS AND SUBCONTRACTORS TO EMPLOY AND ADVANCE IN EMPLOYMENT QUALIFIED PROTECTED VETERANS. WE ARE A GOVERNMENT CONTRACTOR To Apply: Email your resume in PDF or Microsoft Word format to jobs@melissadata.com or apply at : https://www.melissa.com/jobs/jobapply.aspx No phone calls or recruiters please. Founded in 1985, Melissa (www.melissa.com) provides powerful and affordable Data Quality and Address Management solutions to customers in a wide range of industries. A powerful line of software, databases, programming tools, and hygiene services has made Melissa a recognized leader in the data quality industry. Our corporate headquarters are located in southern California, with development offices in Washington, Oregon and Massachusetts."
Data Engineer,Wondr Health,"Remote in Dallas, TX 75251",https://www.indeed.com/rc/clk?jk=2809648c59ccea41&fccid=342866836c92a7e5&vjs=3,"Overview: Wondr HealthTM is a digital behavioral change program focused on weight management, that helps participants improve their physical and mental wellbeing through simple, interactive, and clinically proven skills and tools. By treating the root cause of obesity through behavioral science, Wondr reduces risk factors to prevent chronic diseases like diabetes and hypertension, helps enhance employee productivity and engagement, decreases claims costs, and improves overall physical and mental wellbeing. A master class of sorts, Wondr Health’s team of renowned doctors and scientists teaches practical, data-backed skills that empower participants to stress less, sleep better, and feel better. The highly personalized program has helped hundreds of thousands of people by flipping diet culture upside down and teaching employees the science of eating the foods they love so they can still lose weight. Through the app, online community, certified coaches, and series of weekly videos that offer a new perspective on better health, participants enter a world where weight loss is a science, small steps lead to big changes, perspectives are flipped, possibilities are infinite, and good habits last. Learn more at www.wondrhealth.com. Purpose/Essential Functions: Build and operationalize enterprise data solutions. Collaborating with a team to create an event driven architecture. Utilizing AWS tools to implement real time data pipelines Will work to implement and abide by best software and data engineering processes to create scalable and maintainable solutions. ESSENTIAL FUNCTIONS: Collaborate with key stakeholders including the Executive, Product, Analytics and Design teams to assist with data-related technical issues and support their data infrastructure needs. Create and maintain optimal data pipeline architecture for the organization. Build out AWS data lake and warehouse for analytic and data science use Implement data and unit test to deliver the highest quality data throughout the organization Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python, SQL, and AWS ‘big data’ technologies. Build processes supporting data transformation, data structures, metadata, dependency, and workload management. Construct and optimize data pipelines, architectures, and data sets. Work with data and analytics experts to strive for greater functionality in our data systems. Write policies, procedures, and technical documents. Interacts daily with assigned business units and IT staff. Other tasks as assigned by stakeholders in assigned business unit and IT Operations Manager. Job Attributes and Abilities/Qualifications: KNOWLEDGE, SKILLS AND ABILITIES: Self-starter who can handle several work items independently Eagerness to learn new technologies and technology tools Results-driven/detail-oriented Strong analytical, quantitative, and problem-solving abilities Thorough knowledge of relational and NoSQL database theory and practice as well as familiarity with a variety of databases Ability to work both independently and collaboratively with cross-functional teams Ability to motivate and manage employees Excellent oral and written communication skills Basic knowledge of business practices Ability to solve practical problems and deal with a variety of concrete variables in situations where only limited standardization exists Able to interpret a variety of instructions furnished in written, oral, diagram or schedule form Must be knowledgeable of and comply with Wondr Health’s Client Privacy Policy, HIPAA regulations and E&O procedures and policies QUALIFICATIONS : Education: Bachelor’s degree in computer science, analytics, information systems or a related field preferred Experience: 3+ years of experience as a Data Engineer Experience with data pipelines, data lakes, data warehouses, and AWS cloud services. General Working Conditions/Disclaimer: General office working conditions can be remote work from home or in the office. Each department head determines if position is work from home or hybrid meaning works from home and in the office as needed. Work schedules vary. When working in the office pod workstation area has little or no privacy. Involves extended periods of sitting at a workstation performing computer duties. Constant flow of interruptions by personnel, visitors to area and telephone calls. Private workstations are available as needed. Certain positions are assigned an office. DISCLAIMER This description is intended to be sufficient merely to identify the classification and be illustrative of the duties that may be assigned. It should not be interpreted to describe all the duties an employee assigned to this classification may be required to perform"
Senior Data Engineer,Validere Technologies,+1 locationRemote,https://www.indeed.com/rc/clk?jk=aaf46c090078907f&fccid=e967e2adf60716db&vjs=3,"Who we are: Validere is the leading all-in-one commodity management platform for the energy industry. We believe the future of energy requires a modernized supply chain, so we’re reducing the barriers to actionable insights to make the energy landscape better for everyone. Through people and technology, we bring clarity to commercial, operational, and environmental challenges, provide ways to act on the learnings and facilitate predictions for the future state. Founded at Harvard University, Validere has since raised $70M+ from leading technology and energy investors, including Mercuria Energy America, BlackRock, Wing VC, Greylock Partners, and Y Combinator. With offices in Houston, Calgary, and Toronto, our 100+ employees focus every day on delivering the highest value, removing friction, and scaling results for every one of our customers. Who you are: To support our rapid growth, we are looking for a Senior Data Engineer with a passion for solving complex problems related to data infrastructures for large scale and fast-growing datasets, including data ingestion, data consumption, processing and automation. Above all, we’re looking for someone who is driven and excited about the positive impact technology can have on business. This is a remote first opportunity and we looking for candidates anywhere in Canada/USA. Let’s give you a purpose: Design and implement the data infrastructure platforms including the data ingestion, data consumption and stream processing on AWS Write code to automate ingestion and transformation of data from different sources (from conception to production) Design, build, and own highly resilient data processing jobs Build systems that represent real-world intricacies of physical commodities Collaborate with Services team to identify and map different data sources Participate in code reviews to push for high quality and coding standards Support the development and maintenance of data engineering guidelines, policies, standards and process narratives Mentor and guide other data engineers in the team Our tech stack: Platform: Python, AWS (Airflow, Lambda, EKS, etc), Postgres, Redis, Docker, GraphQL, Terraform, Prometheus What you'll bring along: Bachelor’s degree in Software Engineering, Computer Science or extensive practical experience with software development 5+ years of professional experience, preferably in a fast-paced environment such as a startup or rapidly growing company Strong foundation in algorithms and data structures Proficiency in Python (numpy, scipy, panda) and SQL Comfortable working in Linux and writing shell scripts Strong sense of ownership and accountability Nice to have Experience with CI/CD pipelines Experience with Docker We love it here, you will too: Competitive compensation Comprehensive health benefits Stock options (at Validere, we're all owners) RRSP/401(k) matching programs Flexible working arrangements Professional development budget to master your craft Generous time-off with parental/family leave Quarterly Employee Wellbeing Days and No Meeting Friday Afternoons An inclusive, ego-free environment where diversity of people and thought is valued Opportunity to impact the trajectory of a fast growing tech company Our shared values: Deliver (the highest) value Remove friction Everyday is more scalable Be well, fair & transparent Validere is an equal employment opportunity employer. We welcome and encourage applications from everyone regardless of race, colour, religion, gender, sexual orientation, age, or disability status. Accommodations are available on request for candidates taking part in all aspects of the interview process and beyond. We are committed to providing an inclusive, open, and diverse work environment."
Data Center Engineer,PacketFabric,"Remote in Los Angeles, CA",https://www.indeed.com/rc/clk?jk=e08ba8057be96e57&fccid=9be8328cb36fabdb&vjs=3,"Location: Los Angeles, California, United States Full-time Allows Remote THE ROLE: As a well-rounded Data Center Engineer, you will be part facilities engineer, part network engineer and part project manager. Your job is to get new hardware into the field and bring it online for customer use. You should definitely be the type that appreciates diversity in your day, and challenges outside of your comfort level! You will be organizing logistics for rapid domestic and international infrastructure deployments so you must come armed with well developed problem solving skills, be willing to take risks, and prepared to improve processes on the fly. WHAT YOU’LL BE DOING: Help determine which of PacketFabric’s 180+ data center sites need capacity upgrades. Ensure that spare capacity is always available to support customer growth and PacketFabric’s industry leading capacity on demand business model. Plan out which switches, routers, optical equipment, fiber distribution panels, and power circuits need to be upgraded and how best to upgrade them. Work with our vendors to procure which parts and services are needed. Generate instructions, MOPs, and maintenance procedures for our Data Center Engineers or outside contractors to execute. Supervise maintenance windows and procedures. Ensure new capacity passes quality control and hand over to network engineering. Work with our software developers to automate the most frequent, irritating, and cumbersome parts of your job. And of course, since this is a start-up, we aren’t just asking you to wear one hat. When you get a break, you can assist any of our other teams! WHAT YOU BRING: Expert Experience installing, testing, and troubleshooting optical fiber circuits, from 1 gig to 100 gig. Understanding of multi-tenant data center environments (carrier hotels and co-location facilities). Expert understanding of this ecosystem and which company is responsible for what. (Customer, Data Center Operator, Telecommunications Vendor or Customer) Understanding of large scale data center environments (power, cooling, physical hardware, cabling topologies. Ability to instruct contractors or remote hands technicians. Ability to operate independently in a small startup environment. Plan a job, send a material list to be purchased, book a flight and hotel, complete the job and come home - and deal with problems that come up during this process. (or supervise technicians and contractors in parts of this) Ability to learn new technologies, all of PacketFabric’s equipment is brand new and cutting edge. Knowledge of Microsoft Excel or Google Sheets - Ability to create complex documents, materials lists, MOPs. Experience estimating a job, both time and materials for at least two equipment racks of industry standard switches, routers, and servers. Ability to write technical documentation. Intermediate Experience racking and cabling servers, switches, routing and optical hardware. Knowledge of Microsoft Visio or CAD, ability to quickly draw a rack elevation or circuit diagram. Knowledge of command line operating systems (Cisco, Juniper, Linux), ability to console network equipment or servers, perform basic troubleshooting and configuration. Ability to support our network engineers over the phone as their hands and eyes. Entry Level Knowledge of command line operating systems (Cisco, Juniper, Linux), ability to perform basic troubleshooting and configuration (Check light levels on an interface, observe port up/down status, and very basic set commands like enable/disable port, set port speed and port description. Requirements Ability to lift at least 50 pounds. Ability to distinguish standard telecommunications color codes (Fiber and Copper) Valid driver’s license Travel appx 20%, 40% for the first few months. Must have valid passport & ability to travel internationally Ability to pass a background check Nice to Have (any not all) BICSI RCDD, DCDC, RTPM; Cisco CCNP, CCNA; Juniper JNCIA, JNCIS. Work Experience The right candidates will most likely have a strong background working in large scale data center or telecommunications environments, with a proven track record of completing projects on time in spite of obstacles. About PacketFabric PacketFabric is the connectivity cloud. We built a global, 50+Tbps carrier-class optical network that is completely automated and consumable on-demand like SaaS, so enterprises can connect the core of their hybrid and multi-cloud architectures and grow their digital business. We offer private and secure point-to-point, hybrid cloud, multi-cloud, and custom connectivity services that you can provision in minutes via our self-service portal or programmable API. We offer flexible consumption of our services, with month-to-month or longer terms, or even usage-based for bursting and disaster recovery. PacketFabric was recognized with the “2020 Fierce Telecom Innovation Award for Cloud Services,” named one of the “10 Hottest Networking Startups of 2020” by CRN, a Futuriom 40 Top Private Company, and a “2020 Cool Vendor in Enhanced Internet Services and Cloud Connectivity” by Gartner. PacketFabric is a distributed, fully remote team with people living and working all over the world. What PacketFabric Offers Remote first, globally distributed team. The chance to disrupt the entrenched telecommunications infrastructure industry. A supportive and optimistic team that likes to learn from each other. A product development pipeline that’s constantly pushing new features and enhancing the quality of existing products. The opportunity to work with many different industries and customer types. A small company culture. Great health, dental, and 401(k) for US residents. What PacketFabric Doesn’t Offer Lack of direction: we maintain a clear roadmap and product pipeline. A commute: no hours wasted in megaregion rush hour traffic. A dress code: a robe and slippers is acceptable attire any day of the week Here at PacketFabric, we want all of our employees to feel valued, appreciated, and free to be who they are. We provide equal opportunities to all employees and applicants for employment and follow employment lifecycle processes designed to prevent discrimination against our people, regardless of gender identity or expression or intersex, sexual orientation, religion, spiritual beliefs, ethnicity, age, neurodiversity, disability status, national origin, citizenship, generation, culture, or any protected category under federal, state and local law."
Data Engineer - DOF,Xcel Energy,"Denver, CO 80202 (Union Station area)+1 location",https://www.indeed.com/rc/clk?jk=be89aad535319020&fccid=0b3490f8005058ec&vjs=3,"The Digital Ops Factory Data Engineer will work closely with a multidisciplinary Agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from the factory's connected data, enabling the organization to advance the data-driven decision-making capabilities of the factory's enterprise. This role requires deep understanding of data architecture, data engineering, data analysis, and a general understanding of data science techniques and workflows. The ideal candidate is a skilled data engineer with experience creating data products supporting analytic solutions. They are an Agile learner, possess strong problem-solving skills, work as part of a technical, cross functional analytics team, and want to solve complex data problems and deliver the insights to enable analytics strategy. Essential Responsibilities Solution Delivery: Lead and support solution lifecycle technical activities. Ensure solutions are designed for great user experience and operational performance. Lead design, ensuring Enterprise Architecture, Security, Operations and Compliance aspects are continuously integrated into solutions. Provide input to cost and schedule estimation. Responsible for overall integrity of system design and operation. Oversee vendor activities. Operations: Review solution performance, and continually assess health of systems. Track and drive awareness to operational and technical debt risks. Provide escalated support to incident and problem management. Utilize analytics to improve availability, reliability, efficiency and capacity. Oversee vendor activities. Subject Matter Expertise: Continuously stay current on, and apply, technical industry knowledge pertaining to the respective domain. Relationship Management: Conduct peer reviews and approve system changes and technical solution design. Coach and mentor less experience team members. Partner cross-organizationally to drive minimal costs on optimal solutions. Provide in-depth technical information to stakeholders as needed. Minimum Requirements Seven years of related functional experience. Bachelor’s degree in Technology, Science, Business or related field, or 4 years of experience equivalent to the position. Excellent communication skills, effective with varying organizational levels and skill set, and able to translate between technical and non-technical concepts. Excellent Relationship Management and collaboration skills, with a track record of working as one team cross-organizationally to drive innovation and business results. Experience managing the lifecycle of technical solutions. Deep Subject Matter Expertise within the respective system domain products, platforms, processes and architecture. Broad general knowledge of technology architecture, infrastructure, network, security and software principles and models. Experience working in partnership with internal and external vendors. Proven analytical, problem-solving and troubleshooting skills. Extensive knowledge of future technology trends within area of expertise. Demonstrated leadership on technical aspects of large scale projects. Experience with delivery methodologies (Waterfall, Agile, Scrum) and operational models (ITIL). Experience and understanding of core IT Service Management functions, such as Change Management and Incident Management. Preferred Python and SQL Skills Knowledge of Spark, PySpark Experience with AWS in the data and analytics space Strong troubleshooting and problem solving Strong communication skills _______________________________________________________________________________________________ Xcel Energy is committed to the safety of its employees and customers, and promotes a Safety Always culture. Because of this, we strongly encourage all employees to be fully vaccinated against COVID-19; however, vaccination is not mandatory. After being hired, you will asked to report your vaccination status and dates of vaccination. This information will be maintained confidentially and disclosed only on a need-to-know basis. If you are not fully vaccinated or choose not to disclose your vaccination status you will be required to follow any health-and-safety rules applicable to unvaccinated employees. As a leading combination electricity and natural gas energy company, Xcel Energy offers a comprehensive portfolio of energy-related products and services to 3.4 million electricity and 1.9 million natural gas customers across eight Western and Midwestern states. At Xcel Energy, we strive to be the preferred and trusted provider of the energy our customers need. If you’re ready to be a part of something big, we invite you to join our team. Posting Notes: CO - Denver || CO - Denver; MN - Minneapolis || United States (US) || Customer And Innovation || 56200:IT-Digital Ops Factory || Full-Time || Non-Bargaining || The anticipated starting base pay for this position is: $87,000 to $123,666 per year This position may also be eligible for the following benefits and/or pay components: Pay - Annual Incentive Program, Medical/Pharmacy Plan, Dental, Vision, Life Insurance, Dependent Care Reimbursement Account, Health Care Reimbursement Account, Health Savings Account (HSA) (if enrolled in eligible health plan), Limited-Purpose FSA (if enrolled in eligible health plan and HSA), Transportation Reimbursement Account, Short-term disability (STD), Long-term disability (LTD), Employee Assistance Program (EAP), Fitness Center Reimbursement (if enrolled in eligible health plan), Tuition reimbursement, Transit programs, Employee recognition program, Pension, 401(k) plan, Paid time off (PTO), Holidays, Personal holidays, Volunteer Paid Time Off (VPTO) (full-time employees only), Parental Leave Click here to see our benefits Requisition Number: 43383 All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Individuals with a disability who need an accommodation to apply please contact us at recruiting@xcelenergy.com"
Data Engineer - Python,Nortal,Remote,https://www.indeed.com/rc/clk?jk=ae56a0a28222d3dd&fccid=2c763e7277b51398&vjs=3,"SOFTWARE DEVELOPMENT US REMOTE ENGINEERING A Nortal Data Engineer’s role is to lead and implement data engineering projects, support and maintain data pipelines, and provide expertise and best practices regarding data engineering for staff across the company. Typical data engineering projects focus on improving performance and adding features to existing data pipelines. As needed, the Data Engineer will design and develop new data engineering pipelines as part of the Data Engineering Team. Further, the Data Engineer will help decide how and implement improvements to pipelines, systems, and infrastructure. Data Engineers are expected to have an in-depth understanding of data engineering best practices as well as expertise with the tools needed to debug and diagnose issues. Data Engineers contribute as a team member to testing, QA, and documentation of data pipelines and systems. The Nortal Data Engineering Team is a small agile team of motivated individuals who welcome challenges, adapt quickly, strive to acquire new knowledge, learn new technologies, accept new responsibilities, and work well individually, as a team, and with other teams within the organization. You will work closely with the Data Engineering Lead, product managers, workflow developers and other software engineers to advance projects and meet objectives. We seek an experienced engineer who is interested in pursuing an advanced individual contributor technical career track over a technical management career track. Duties and Responsibilities Assembling large, complex sets of data that meet non-functional and functional business requirements Identifying, designing, and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies Building analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition Working with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues Working with stakeholders including the Executive, Product, Data and Design teams to support their data infrastructure needs while assisting with data-related technical issues Data Engineer Expectations Maintain an in-depth understanding of relevant data engineering best practices Display expertise with tools needed to debug and diagnose issues Given a medium to large understood problem, can design, implement, and deploy a solution Show initiative and help when needed without being asked Deliver feedback in a constructive manner Provide guidance to other engineers and workflow developers Work well with technical leads, incorporating feedback as needed Required Skills AWS: S3 Data Lake, Athena, Redshift, EMR, Glue, ECS, EKS Proficiency with Python in a data engineering context. Ex: Pandas, PySpark Source control using Git Proficiency with SQL Proficiency with workflow orchestration concepts Adaptable to Windows, Linux, and container-based deployment environments Workflow performance, scaling, and optimization. Big Data solutions in some cases. Security & privacy principals Desired Skill & Qualifications ETL productivity tools Spark EKS Terraform Helm Python3 APPLY FOR A JOB We like to say that Nortal is a right-sized company – big enough to undertake and impact influential projects yet small enough to care. At Nortal, your voice is heard, and everyone’s input matters. You solve critical problems for interesting customers from different domains. You work with experienced colleagues in a warm environment. You are able to execute your ideas in a reasonable time frame. And what you do and learn here are universally relevant and valuable. Last but not least, Nortal is an agile company with low hierarchy – meaning heavy on common sense, light on rules, and substance is more important than titles!"
Data Engineer,ApolloMed,+1 locationRemote,https://www.indeed.com/rc/clk?jk=c1f681a6a177e4f3&fccid=80f5616c7b308f10&vjs=3,"Data Engineer Job Description ApolloMed (NASDAQ: AMEH) is a physician-centric, technology-powered healthcare management company. We are building and operating a novel, integrated, value-based healthcare delivery platform to empower our physicians to provide the highest quality of end-to-end care for their patients in a cost-effective manner. Our mission is to combine our clinical experience, best-in-class delivery network, and technological expertise in order to improve patient outcomes, increase access to healthcare, and make the US healthcare system more efficient. With over a million managed lives across the country and terabytes of data generated, our teams need to be continuously equipped with the tools and insights to drive strategy and innovation to further our core values of improving patient outcomes and empowering our providers. We are currently seeking a highly motivated Data Engineer. This role will report to the Analytics Manager and work closely with data analysts and clinical leaders to produce deliverables for internal and external clients. You are: Comfortable with ambiguity and biased towards action.You can identify the 20% of the work that leads to 80% of the result, and mobilize and execute the high-impact work consistently. You enjoy thinking about complex and ambiguous problems and can execute consistently and add compounding value. Relentlessly resourceful.You enjoy taking ownership and can get things done without excuses. You are resilient, detail-oriented, and truly believe that no task is beneath you, even in the face of potential challenges. Growth-oriented.You are able to evaluate all perspectives, even if uncomfortable, and have the courage to adjust your views if necessary. You have the expertise and communication skills to balance a growth mindset with a bias towards action. Mission-driven.You are excited by the prospect of diving into complex problems that will drastically improve patient outcomes, while lowering the cost of a tremendously inefficient US healthcare system, where waste is over 40% and per-capita healthcare dollars spent is double that of other developed nations. What you’ll do: Design and develop a data reporting environment across organizational data systems. Identify and promote best practices and patterns for data modeling and provide oversight for activities to report migration and data consolidation Design, code, manage data & analytics product backlog Identify technical solutions that achieve efficiency and effectiveness and enable data usage as a strategic business asset Review team members’ codes for quality and correctness Collaborate with data analysts and other team members to architect data products and services. Integrate the data platform with analytical tools such as Tableau and PowerBI Analyze and document processes to create a large shared knowledge base. The opportunity: Join a team with extremely high visibility Startup-like mentality and career trajectory in a recently IPO’d company (>4B market cap) targeting 100%+ growth y/o/y in 2022 Work closely with highly collaborative leadership teams across multiple business units within managed care Minimum qualifications: Bachelor's degree required in healthcare, analytics, statistics, finance, or related field; Master’s degree (MBA, MPH) preferred 2+ years’ experience developing data pipelines or ETLs 2+ years’ experience in managed care or other healthcare data field Working knowledge with programming or scripting languages such as Python. Experience with SQL or similar relational databases Familiarity with business intelligence exploratory or visualization tools (e.g., Tableau, PowerBI) Strong written and oral communication skills Experience with Excel"
Big Data Engineer,Apexon,"Remote in Menomonee Falls, WI+16 locations",https://www.indeed.com/rc/clk?jk=c3de10fd26e587c0&fccid=784ed0ea1f56bb8a&vjs=3,"Our Client is looking for a Big Data Engineer, this role will sit 100% Remote. Kindly go through the requirement and let me know your thoughts to move forward Job Title: Big Data Engineer Location: Remote Duration: Long Term contract Required Skills: Python, SQL Job Description: Responsible for: • Collaboration through frequent pair programming • Regular retrospectives to figure out what is being done wrong so it can be fixed, and what is being done right so the team can improve on it. • Test Driven Development. Requires: • Strong knowledge building development practices like CI/CD, Test Automation and cloud deployments • Knowledge of build management tools such as Jenkins or Maven • Demonstrated understanding of source control systems such as GIT • Database Design experience including either SQL, PL/SQL • Implementing ETL process with Big Data Technologies • Required: Spark, Python, Scala and Airflow • Preferred: MapReduce, Pig, Hive, Kafka, Sqoop, and Flume • Experience working with distributed caching technologies such as REDIS • Experience in designing and creating automation workflows and execution • Knowledge of Apache Airflow Developing DAG, Performance tuning of the DAGs and task implementation • Good understanding of MPP databases such as Teradata and Netezza • Experience and/or interest in Test Driven Development (TDD) and agile methodologies • Strong communication skills and interest in a pair-programming environment • Passion for growing your skills, tackling interesting work and complex problems • Experience deploying to cloud environments. GCP preferred (BigQuery, DataProc) • 3+ years of relevant work experience • BA/BS in Computer Science or related field, or equivalent experience Regards, Viduth | Mobile: +1 248 603 2674 | Desk: +1 248 313 4594 | Email: Viduth.Selvan@technosoftcorp.com Technosoft Corporation |One Towne Square, Suite 600 Southfield, MI 48076 |www.technosoftcorp.com |"
Sr Data Center Engineer (Remote),CrowdStrike,+3 locationsRemote,https://www.indeed.com/rc/clk?jk=e137bb30d7133147&fccid=64e4cdd7435d8c42&vjs=3,"#WeAreCrowdStrike and our mission is to stop breaches. As a global leader in cybersecurity, our team changed the game. Since our inception, our market leading cloud-native platform has offered unparalleled protection against the most sophisticated cyberattacks. We’re looking for people with limitless passion, a relentless focus on innovation and a fanatical commitment to the customer to join us in shaping the future of cybersecurity. Consistently recognized as a top workplace, CrowdStrike is committed to cultivating an inclusive, remote-first culture that offers people the autonomy and flexibility to balance the needs of work and life while taking their career to the next level. Interested in working for a company that sets the standard and leads with integrity? Join us on a mission that matters - one team, one fight. About the Role: Provide efficiency improvements in existing DC locations Conduct site visits to ensure compliance with standards and best practices Participate in datacenter capacity and roadmap planning Participate in data center design. Including site selection, power, cooling, and infrastructure requirements decisions Participate in new and existing vendor contract renewal and negotiation Coordinate with contractors on all new cage and data center builds from start to finish Coordinate, schedule and lead all aspects of maintenance performed by vendors. Collaborate with remote teams such as network engineering, procurement/logistics and project management. Support and contribute thought leadership to the development and implementation of best practices which support the growth and ongoing management of our global data center footprint Ability to travel as needed What You'll Need: 10+ years experience supporting mission-critical data centers Experienced managing and coordinating the planning and implementation of data center services including, network connectivity, placement of equipment, racks, power circuits, heat containment, and ensuring they adhere to operational standards Experience with greenfield or brownfield data center construction Experienced with site selection, budget planning, RFP’s, space planning, power allocation, network infrastructure & hardware installations Experience working with auditors to meet all compliance requirements (SOX/SOC/FedRamp) Experience with vendor management (contracts, renewals and QBR’s) Experience with data center tools such as DCIM, and Power Monitoring Experience with electrical and mechanical equipment including generators, PDUs, UPS, switchgear, and DC Power Systems. Experienced in influencing and leading a diverse group of people, partners suppliers across multiple disciplines Leadership experience making decisions with minimal direction and prioritizing across multiple competing demands #LI-Remote #LI-LY1 Benefits of Working at CrowdStrike: Remote-first culture Market leader in compensation and equity awards Competitive vacation and flexible working arrangements Comprehensive and inclusive health benefits Physical and mental wellness programs Paid parental leave, including adoption A variety of professional development and mentorship opportunities Offices with stocked kitchens when you need to fuel innovation and collaboration We are committed to fostering a culture of belonging where everyone feels seen, heard, valued for who they are and empowered to succeed. Our approach to cultivating a diverse, equitable, and inclusive culture is rooted in listening, learning and collective action. By embracing the diversity of our people, we achieve our best work and fuel innovation - generating the best possible outcomes for our customers and the communities they serve. CrowdStrike is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. CrowdStrike, Inc. is committed to fair and equitable compensation practices. For applicants in Colorado the salary range is $133,770 - $222,950 + bonus + equity + benefits. A candidate’s salary is determined by various factors including, but not limited to, relevant work experience, skills, and certifications. The salary range may differ in other states. CrowdStrike participates in the E-Verify program. Notice of E-Verify Participation Right to Work"
SQL server Data Engineer,"Orpine, Inc. Internal",United States,https://www.indeed.com/rc/clk?jk=a83fbb791fa34c45&fccid=7df81f4c05f8d55a&vjs=3,SQL server SQL SSIS Python Azure APIs
Data Engineer,JACKSON HEALTH SYSTEM,"Miami, FL 33136 (Allapattah area)",https://www.indeed.com/rc/clk?jk=473f41d204915c6b&fccid=d65f7a458f65f781&vjs=3,"Jackson Memorial Hospital Days, FT Position Summary: The Data Engineer requires fluency and proficiency with data organization, preparation/cleansing/transformation, and structuring tools and tasks supporting analytical modeling, programming, and visualization. Work daily with database platforms and data-application development technologies such as Microsoft SQL Server and related tools (e.g., SSMS, SSIS, Visual Studio, Tableau Prep, etc.). Routinely apply expertise in developing data pipelines, APIs, and scripts that facilitate the creation of analytical models and support upstream application development. Prepare, integrate, and automate data movement and utilization by applying scripting and programming languages such as SQL/T-SQL/PL-SQL, Python, R, and scripting languages. Support the development of analytical and decision support applications. Duties & Responsibilities: Work daily with database platforms and data-application development technologies such as Microsoft SQL Server and related tools (e.g., SSMS, SSIS, Visual Studio, Tableau Prep, etc.) are required. Routinely apply expertise in developing data pipelines, APIs, and script that facilitate the creation and automation of analytical models and support upstream application development and maintenance. Prepares and integrates data using scripting and programming languages such as SQL/T-SQL/PL-SQL, python, and R. Support the development and maintenance of analytical and decision support applications bthrough business logic, automation engineering, structural data representation, and query optimization. Demonstrates behaviors of service excellence and CARE values (Compassion, Accountability, Respect and Expertise). Performs other related duties as assigned. Qualifications Experience: Generally requires 3 to 5 years of related experience. Education: Bachelor's degree in related field is required. Master's degree is preferred. License Certification: Valid license or certification is required as needed, based on the job or specialty. Knowledge Skill Abilities: Ability to analyze, organize and prioritize work accurately while meeting multiple deadlines. Ability to communicate effectively in both oral and written form. Ability to handle difficult and stressful situations with critical thinking and professional composure. Ability to understand and follow instructions. Ability to exercise sound and independent judgment. Knowledge and skill in use of job appropriate technology and software applications. Physical Demands: Job function is sedentary in nature and requires sitting for extended periods of time. Function may require frequent standing or walking. Must be able to lift or carry objects weighing up to 20 pounds. Jobs in this group are required to have close visual acuity to perform activities such as: extended use of computers, preparing and analyzing data and analytics, and other components of a typical office environment. Additional information and provision requests for reasonable accommodation will be provided by the home unit/department in collaboration with the Reasonable Accommodations Committee (RAC). Work Environment: Jobs in this group are required to function in a fast paced environment with occasional high pressure or emergent and stressful situations. Frequent interaction with a diverse population including team members, providers, patients, insurance companies and other members of the public. Function is subject to inside environmental conditions, with occasional outdoor exposures. Possible exposure to various environments such as: communicable diseases, toxic substances, medicinal preparations and other conditions common to a hospital and medical office environment. May wear Personal Protective Equipment (PPE) such as gloves or a mask when exposed to hospital environment outside of office. Reasonable accommodations can be made to enable people with disabilities to perform the described essential functions. Additional information and provision requests for reasonable accommodation will be provided by the home unit/department in collaboration with the Reasonable Accommodations Committee (RAC)."
Sr. Data Engineer,Match,"Dallas, TX",https://www.indeed.com/rc/clk?jk=a4bb4ab4dc05b31f&fccid=41d3a70a35069f94&vjs=3,"As a Sr. Data Engineer, you will be implementing critical ETL pipelines and advancing best practices for the data engineering team, and the rest of the organization. You will work on delivering an actual big data architecture while concentrating on real-world problems such as privacy concerns. This role is key to the success of Match Group. Not only will you help power the love lives of millions of people, but you will play a critical part in the functioning of every brand at Match Group (Match, Tinder, Hinge, Okcupid, PlentyofFish, BLK, and others), with stakeholders ranging from customer experience to marketing to leadership. We're located in Dallas, TX, and seeking a DFW based engineer to join us. We work from the office 1 day per week (free catered lunches are provided). See you soon! How you’ll make an impact: Work with our Engineering teams to ensure data is flowing accurately through data creation to our presentation layers Become an advocate for the Data Engineering team by developing and championing Data Engineering practices with the team and with the company at large Improve our Data Engineering stack through containerization, data modeling, developing our ETL pipelines, and building scalable/reliable solutions Work with stakeholders and translate their needs and expectations into action items and deliverables Lead infrastructure initiatives, from design to implementation to delivery Support existing on-prem infrastructure and help expand our processes into the cloud (AWS) We could be a match if you bring: Prior Airflow and/or Python experience is required Expertise in SQL, Data Modeling, and Python Used Redshift, Airflow, Spectrum and relational database like SQL Server Capability to drive initiatives and articulate their value to Engineering and other stakeholders Experience delivering data products from conception to delivery Good communication skills (written/verbal) Passionate about designing elegant ETL pipelines 5+ years of professional/industry experience Our team culture: Authenticity: Share your genuine thoughts and opinions directly Courage: Invite and deeply consider challenges and criticism Empathy: Be empathetic, communitarian and trustworthy What's the team like? Our BI team is a service organization that delivers reporting solutions to the entire Match Group enterprise The BI team is responsible for architecting and engineering new data systems and reporting to help facilitate business decision-making We're located in Dallas, TX, and seeking a DFW based engineer to join us. We work from the office 1 day per week (free catered lunches are provided). See you soon! #LI-CENTRAL #LI-CH1 Why Match Group? Our mission is simple – to help people find love and happiness! We love our employees too – here are some examples how: Annual training budget for each employee 100% employer match on 401k contributions Specific COVID-19 allowance for home office set-up Matched giving to qualified organizations 100% paid Parental Leave for up to 20 weeks Happy Hours and Company events At Match Group, we represent a collection of unique brands - but we all focus together on the health and safety of all of our employees. That's why we require that employees are fully-vaccinated when in person at any US office or company-sponsored fun. If you need to talk through this in-person vaccine requirement, our People team can work with you through our accommodations review process. We are proud to be an equal opportunity employer and we value the rich dynamics that diversity brings to our company. We do not discriminate on the basis of race, religion, color, creed, national origin, ancestry, disability, marital status, age, sexual orientation, sex (including pregnancy and sexual harassment), gender identity or expression, uniformed service or veteran status, genetic information, or any other legally protected characteristic. Period."
Data Engineer,Exodus Integrity Services,"Cleveland, OH",https://www.indeed.com/rc/clk?jk=e4f2d2483b6fa288&fccid=fefbcbf3019073c3&vjs=3,"Exodus Integrity Services, Inc is a rapidly expanding technology company headquartered in Northeast Ohio. EIS provides quality services to our clients by instilling honesty, commitment, and hard work to find the most qualified candidates to fill each opportunity. Currently, we are seeking individuals to fill an opportunity for our client in Cleveland, OH. This is a very exciting opportunity working with one of the top employers in the area. If you are interested in joining a vibrant organization where you are valued and rewarded for your contributions, and you possess the qualifications listed below, please forward your resume and salary requirements. Data Engineer Requirements SQL Data Warehousing Hadoop ETL Tools Python/R Exodus Integrity Services (EIS) is an equal opportunity employer. In accordance with anti-discrimination law, it is the purpose of this policy to effectuate these principles and mandates. EIS prohibits discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. EIS conforms to the spirit as well as to the letter of all applicable laws and regulations.”"
Data Engineer,SkySlope,Remote in Indiana,https://www.indeed.com/rc/clk?jk=8d5ca5c5bc1aac8b&fccid=b8b33880c81de810&vjs=3,"In 2011 SkySlope started as an idea born at the kitchen table of our CEO, with just him and two others. Headquartered in Sacramento, California, we have since grown out of our previous 3 offices and many of our close to 180 employees are spread all across the United States. Those 180 employees support close to 300,000 users across 5,000 offices nationwide and now in Canada as well. Included in that is 8 out of the 15 largest Real Estate Brokerages in the nation. But, despite being happy with what we’ve achieved we know that as industry leaders in our space there’s a lot of work left to be done. All of the growth and success that has happened is a result of us obsessing over building cutting edge software that makes the Real Estate world a better place. We know this only happens by hiring people who don’t just come up with out of the box ideas but hiring people who actually see those ideas through and bring them to life. As we’ve grown, we’ve been fortunate enough to hire plenty of people who possess that quality and realize it’s equally important to hire people who can pair that skill with empathy, collaboration, and a keen sense of urgency. If you’re looking to join a company where you can have real impact and surround yourself with an incredible team of people then look no further. Data engineers at SkySlope develop, test, and deploy new and improved software, while managing deliverables in a fast-paced, agile work environment. They are expected to continue promoting their talent via self-learning and collaboration with our senior/staff engineers to pursue advancing their own seniority in the company. Essential Functions Optimize MS SQL OLTP databases including schema, stored procs, and views to increase performance and reliability of connected applications - all with zero downtime Understand, design, and support complex data structures Logical and physical database design Develop SQL stored procedures and views and optimize SQL processes Design and develop processes to support large scale systems for data processing, transformation, data quality, reporting, and analytics. Develop and maintain software through its full lifecycle Continually expand your engineering skills and techniques Increase domain knowledge about SkySlope and our clients Commit to team success by being an effective collaborator Manage project priorities, deadlines, issues, and deliverables Actively participate in discussions around process and solutions Contribute to the overall architecture of systems Communicate honestly, respectfully, and candidly with everyone Required Qualifications 4+ years database development experience DBA experience required (configure/tune/troubleshoot) Experience designing and optimizing OLTP databases in MS SQL. Packaging and release management exposure Source control (Git, TFS, SVN, etc.) Experience in an Agile environment AWS EMR Spark and the Python plugin, pyspark Experience with file storage, such as parquet or ORC. Preferred Qualifications Cloud services (AWS Lambdas, RDS, S3, EC2, CloudFormation, etc.) AWS DMS NoSQL experience (DynamoDB, Redis, etc.) Continuous Integration (CI) (Jenkins, CodePipeline, etc.) C# (.NET Core and Framework) Unit and Integration Testing Data warehousing experience MPP database experience (Redshift, Snowflake, Vertica, etc.) Knowledge of new and emerging technologies Has an intermediate understanding of development best practices and proficient writing code. Uses and understands tools needed to debug and diagnose issues in a test and/or complex production environment. Understands the scope of large features. Has a good understanding of all their product components. Performs complex programming tasks. Participates in code reviews and can sign off on small features. Writes and executes test plans. Can write functional specifications for small features. Given a medium to large understood problem, can design and implement a solution. Shows initiative and offers assistance when needed without being asked. Delivers feedback in a constructive manner. Provides guidance to entry-level engineers. Works well with technical leads, incorporating feedback as needed. Help Perks & PTO $1000 referral bonuses 15 PTO days per year 16 paid holidays per year (5 floating to be used at any time) Paid day off on your birthday Insurance Offerings Medical, Dental and Vision Insurance Short and Long Term Disability Insurance Company paid Life Insurance Flexible Spending Account 4 Weeks Paid Parental Leave Retirement and Investment 401k + match Employee Stock Purchase Plan opportunities"
Data Engineer II,Federal Reserve Bank of Dallas,"Remote in Dallas, TX 75201",https://www.indeed.com/rc/clk?jk=2a0633c2f8e749fb&fccid=81aeb22fa799405c&vjs=3,"Company Federal Reserve Bank of Dallas A requirement of this position is that you must be fully vaccinated against COVID-19 or qualify for an accommodation from the Bank's vaccination policy; the Bank will provide accommodations as needed by law for individuals unable to be vaccinated because of medical condition or sincerely held religious belief. Location: #LI-Remote We are dedicated to serving the public by promoting a strong financial system and a healthy economy for all. These efforts take a team of dedicated individuals doing many different jobs. Together we’re creating a workplace where talented people can thrive, and we welcome your unique background and perspective to help present the best possible solutions for our partners. About the Role: The Federal Reserve Bank of Dallas is seeking a Data Engineer II who will serve as an integral member of a national team responsible for supporting the core functions of the Credit Risk Management business line. This person provides data and analytics development services and technical support. The Data Engineer II develops, tests and maintains data and analytics solutions (data warehouse/mart/stores/data lake/reporting/analytics) using tools and programming languages. The Data Engineer II works under the guidance of senior team members, operating under a clear framework of accountability with substantial autonomy. The successful candidate will develop a strong domain knowledge of the relevant business area/s, managing key responsibilities to include requirement analysis, code, test, debug, document, implement and maintain data and analytics solutions. You Will: Develop data and analytics solutions Perform analysis on data sets Monitor, maintain and enhance data processes Analyze and resolve customer requests and data issues Proactively identify and implement process improvements Participate in planning, conduct stakeholder meetings, requirements, design, development, testing and implementation Develop in-depth understanding of Credit Risk Management business function You Have: Working experience in data analytics, data integration and data science Experience building dashboards, and reports with BI tools Strong Experience with scripting languages (Unix/Windows/Python/R) Ability to develop data driven recommendations with actionable insights using predictive models Understanding of ETL (Extract Transform Load) Data Pipelines and relational databases Understanding of data warehouse concepts and frameworks Familiarity to work with AWS data technologies Experience with working within an Agile environment Strong customer focus and business acumen Extremely organized with strong time-management skills Capable of adapting to changing requirements and responsibilities Other skills: problem solving, analysis, excellent communication skills Equivalent education and/or experience may be substituted for any of the above Our Benefits: Our total rewards program offers benefits that are the best fit for you at every stage of your career: Comprehensive healthcare options (Medical, Dental, and Vision) 401K match, and a fully funded pension plan Paid vacation, holidays, and volunteer hours; flexible work environment Generously subsidized public transportation and free parking Annual tuition reimbursement Professional development programs, training and conferences And more… Notes: This position may be filled at various levels based on candidate's qualifications as determined by the department. This position requires access to confidential supervisory information and/or FOMC information, which is limited to ""Protected Individuals"" as defined in the U.S. federal immigration law. Protected Individuals include, but are not limited to, U.S. citizens, U.S. nationals, and U.S. permanent residents who either are not yet eligible to apply for naturalization or who have applied for naturalization within the requisite timeframe. Candidates who are not U.S. citizens or U.S. permanent residents may be eligible for the information access required for this position and sponsorship for a work visa, and subsequently for permanent residence, if they sign a declaration of intent to become a U.S. citizen and meet other eligibility requirements. In addition, all candidates must undergo an enhanced background check and comply with all applicable information handling rules, and all non-U.S. citizens must sign a declaration of intent to become a U.S. citizen and pursue a path to citizenship. The Federal Reserve Bank of Dallas is proud to be an Equal Opportunity Employer that believes in the diversity of our people, ideas and experiences, and we are committed to building an inclusive culture that represents the communities we serve. If you need assistance or an accommodation due to a disability, please notify your Talent Acquisition Consultant. Full Time / Part Time Full time Regular / Temporary Regular Job Exempt (Yes / No) Yes Job Category Work Shift First (United States of America) The Federal Reserve Banks believe that diversity and inclusion among our employees is critical to our success as an organization, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. The Federal Reserve Banks are committed to equal employment opportunity for employees and job applicants in compliance with applicable law and to an environment where employees are valued for their differences. Privacy Notice"
Jr Data Engineer,"The Wolff Company, LLC","Hybrid remote in Scottsdale, AZ 85251",https://www.indeed.com/company/The-Wolff-Company/jobs/Junior-Data-Engineer-0c3f284557e1ead1?fccid=81959575c463029a&vjs=3,"Description: The Wolff Company is looking for a data rock star to join our team of Business Intelligence Professionals. Our team is focused on managing application and analytical databases so business users can spend time doing what they are best at. We are actively looking to fill the role of a Junior Data Engineer. The person we are looking for is a self-starter, has a passion for learning a multitude of tools, and is first and foremost a people person.Responsibilities: Database administration: Microsoft SQL Server on Azure VMs. Azure SQL Databases. Azure Managed SQL Instances. Configuring database disaster recovery and high availability solutions. Managing permissions and security. Designing database structure for internal applications. Business intelligence: Creating data pipelines between organization applications and a data warehouse staging environment. Modeling and transforming data in the data warehouse (ELT). Creating stored procedures, tables, and views to enable end user reporting. Performing data analysis through both ad-hoc analysis and standardized reporting. General: Work collaboratively and effectively in our streamlined team. Seek out improvements with anything encountered related to the position. Document information (we document everything, so if you like good documentation and pride yourself in creating great documentation you will fit). Continually absorb and learn new technical skills. . Requirements: Bachelor’s degree in Computer Science, Data Analytics, Information Systems, or equivalent experience. Strong communication skills, demonstrating the ability to explain technical concepts to varying levels of end-users. Excellent communication skills over the phone while performing remote support. Friendly, kind, and seeks to solve root issue of end users. Loves to learn and find areas where they can bring improvements to the organization. Motivated by the feeling of satisfaction after a job well done. Must work well in a team environment, ready to share your experience; collectively and cooperatively deliver high-quality services to our clients. You are expected to have reliable transportation & ability to lift 40 lbs. The position is for a hybrid work environment. The job requires you to be in the office some days/weeks and can be remote as the position allows. Technical Skills (experience in or have an interest in learning): SQL – Microsoft SQL Server, Azure SQL Database administration (backups, restores, high-availability, security, etc.) Application database design Data warehouse design (Kimball Method, Star Schema) Analysis Services (Tabular) Potentially Snowflake ETL SSIS Azure Data Factory Python REST & Graph APIs Report Development & general programming Python, R Tableau Power BI Excel SSRS Agile Development Environment Azure DevOps Job Type: Full-time Pay: $70,000.00 - $80,000.00 per year"
Data Engineer entry level,Fisker Inc,"Manhattan Beach, CA 90266",https://www.indeed.com/rc/clk?jk=b25a9682949f26e1&fccid=38c354bb9b09f488&vjs=3,"About Fisker Inc. California-based Fisker Inc. is revolutionizing the automotive industry by developing the most emotionally desirable and eco-friendly electric vehicles on Earth. Passionately driven by a vision of a clean future for all, the company is on a mission to become the No. 1 e-mobility service provider with the world’s most sustainable vehicles. To learn more, visit www.FiskerInc.com – and enjoy exclusive content across Fisker’s social media channels: Facebook , Instagram , Twitter , YouTube and LinkedIn . Download the revolutionary new Fisker mobile app from the App Store or Google Play store. Job Responsibilities Be part of a team solving data and machine learning problems that constantly advance the state-of-the-art for electric vehicles. Work with software engineers, devops, ML engineers, and data scientists. Help in the development of data and training pipelines for supporting ML infrastructure. Build large scale training and inference pipelines Build metrics, dashboards to measure both ML and system performance Job Qualifications BS or Master’s Degree in Computer Science, Statistics or related field. Strong coding skills in Python, C/C++, or Go. Familiarity with large-scale data processing and distributed systems such as Hadoop, Kafka. Understanding of relational and columnar databases, SQL and data models. Mathematical knowledge; understanding of machine learning, statistics Expertise in crafting Data Models for high performance and scalability Preferred Experience working with IoT sensor data, ideally automotive. Experience with applied data analytics and predictive modelling Experience in distributed training and model deployment Related course work or experience with vehicle systems: Battery, powertrain, embedded, etc. Experience framework such as Airflow, MLflow, Kubeflow, etc Fisker Inc. is an Equal Opportunity Employer; employment at Fisker Inc. is governed based on merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status. Applicants wishing to view a copy of Fisker Inc.’s Affirmative Action Plan for veterans and individuals with disabilities, or applicants requiring reasonable accommodation to the application/interview process should notify the Human Resources Department"
Data Engineer,"JPMorgan Chase Bank, N.A.","Newark, DE 19713+27 locations",https://www.indeed.com/rc/clk?jk=9162b9978cceadb4&fccid=aaf3b433897ea465&vjs=3,"As a member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally. This role requires a wide variety of strengths and capabilities, including: BS/BA degree or equivalent experience Advanced knowledge of application, data, and infrastructure architecture disciplines Understanding of architecture and design across all systems Working proficiency in developmental toolsets Knowledge of industry-wide technology trends and best practices Ability to work in large, collaborative teams to achieve organizational goals Passionate about building an innovative culture Proficiency in one or more modern programming languages Understanding of software skills such as business analysis, development, maintenance, and software improvement Preferred Qualifications: Experience in working with/on data warehouses, data modelling, ETL/ ELT and SQL. Experience with Spark and Hadoop ecosystem. SQL performance tuning. Experience with reporting tools like Tableau, Cognos etc. JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management. We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs. The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment. As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law. Equal Opportunity Employer/Disability/Veterans"
GCP Data Engineer,The Data Sherpas,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=6890f162d6a7bf90&fccid=dd616958bd9ddc12&vjs=3,"Data Engineer - What you do: Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization. Design, implement and deploy new data models and data processes Experience in data processing using BQ, Dataplex, Data Catalog, Dataproc, Dataflow, Composer, etc... Experience designing data models and data warehouses and using SQL and NoSQL database management systems. Leverage API's to pull data from other applications Leverage API's to allow other applications to pull data Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity. Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it. Writes unit/integration tests, contributes to engineering wiki, and documents work. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Designs data integrations and data quality framework. Data Engineer - What you bring: BS in Computer Science or a related technical field 4+ years experience with Python 4+ years experience with SQL and NoSQL 2+ years of experience with schema design and dimensional data modeling 2+ years experience in GCP 2+ years experience with Looker Experience with Pulumi is a plus Ability in managing and communicating data warehouse plans to team members Experience designing, building, and maintaining data processing systems"
Data Engineer I,Ariel Investments,"Chicago, IL",https://www.indeed.com/rc/clk?jk=a298a7c00ce56c12&fccid=43a31a47b02448a2&vjs=3,"Ariel Investments is a premier, boutique, asset management firm. Our primary goal is to drive exceptional investment returns by bringing diverse perspectives together. The only way to beat a benchmark is to not look like one. As value investors, our thinking is deliberate and unconventional. We offer an independent, patient investing approach and aim to deliver excellence in any environment. We uphold our fiduciary responsibility to every shareholder, no matter how big or small. At Ariel, we strongly believe that teamwork yields results—which is why we have Co-CEOs. John Rogers and Mellody Hobson share a desire to cultivate leaders who are curious, focused and disciplined. We are nimble and efficient. Our drive is fanatical and intentional. Everyone plays their position and each contribution is critical to our firm's success. We seek subject matter experts who are unapologetically themselves. We encourage our employees to reach their full potential and we give them the runway to do so. After nearly four decades of active investing, we remain committed to our clients, our teammates and our community. We strive to be best-in-class investors and pioneer a path for those who entrust us with their financial future. Ariel Investments is looking for an entry level Data Engineer with experience in Microsoft technologies like Power BI, Power Apps and SQL. This role will need to own the development from end to end and the support and maintenance after. This individual will have an innovative approach to problem solving and a commitment to meeting deadlines. Create high quality code deliverables for a module, lead validation for all types of testing and support activities related to implementation, transition, and delivery. The role will involve working with all members of the IT team across different areas and understand the IT landscape and how it can evolve to help the business. Proof of vaccination is required as a condition of employment. Responsibilities will include: Building reporting models per best practices Develop visual reports, dashboards & apps using Power BI Connecting to data sources, importing and transforming data Working knowledge of ETL Good understanding of SQL Queries and logic Should have knowledge and experience in code design and requirements analysis Experience 2 years (ideally 2 years or less) of development using SQL, ETL tools and reporting tools Knowledge in any other reporting tools – SSRS, Tableau a plus Experience with at least one end-to-end implementation required Knowledge of data models, ETL, and data warehouse processes, preferred Python or R experience is a plus Knowledge of extracting data through API/web services a plus Education Bachelor in computer science or MIS - Required Certificates, Licenses, Registrations Any relevant Microsoft certifications – Preferred Computer Skills Needed to Perform this Job Working knowledge of Microsoft Office Suite Competencies Drive for Results: Can be counted on to exceed goals successfully; is constantly and consistently one of the top performers; very bottom-line oriented; steadfastly pushes self and others for results Customer Focus: Is dedicated to meeting the expectations and requirements of internal and external customers; gets firsthand customer information and uses it for improvements in products and services; acts with customers in mind; establishes and maintains effective relationships with customers and gains their trust and respect. Interpersonal Savvy: Relates well to all kinds of people, up, down, and sideways, inside and outside the organization; builds appropriate rapport; builds constructive and effective relationships; uses diplomacy and tact; can diffuse even high-tension situations comfortably. Priority Setting: Spends his/her time and the time of others on what's important; quickly zeros in on the critical few and puts the trivial many aside; can quickly sense what will help or hinder accomplishing a goal; eliminates roadblocks; creates focus. Business Acumen: Knows how businesses work; knowledgeable in current and possible future policies, practices, trends, and information affecting his/her business and organization; knows the competition; is aware of how strategies and tactics work in the marketplace. Ariel celebrates diversity and practices inclusion as a way to get work done – it's in our DNA. As an equal opportunity employer, our employment decisions are based on business needs, job requirements and individual qualifications without regard to race, color, religion, age, sex (including pregnancy), sexual orientation, gender identity, national origin, ancestry, marital status, parental status, mental or physical disability, military or veteran status, or any other basis protected by federal, state, or local law. Ariel is committed to recruiting and retaining talented applicants, and to providing all employees with a workplace free from discrimination and/or harassment."
Data Engineer,Peerspace,Remote,https://www.indeed.com/company/PeerSpace/jobs/Data-Engineer-0cd8fab03917fa45?fccid=2c273b3587669450&vjs=3,"Peerspace invites people to find, share, and book the most magical spaces in the world. Since 2014, our community has been opening the door to thousands of spaces - from lofts and mansions to storefronts and studios - helping people to create one-of-a-kind experiences that would not be possible elsewhere. In total, over 5 million people have been welcomed into a Peerspace location, and we're looking for people who want to help us reach the next 50 million. *The Role: * We are looking for a candidate that has a strong interest in developing data science and analytics solutions to address business problems, can interact effectively with both the technology teams, product and business units, and is passionate about new technologies. As a Data Engineer, you will help build our data infrastructure and further develop our analytics and data science capabilities. You will be involved with all stages of the data journey. The problems we routinely work on are devising new search and ranking algorithms, determining the potential worth of each of our hosts, calculating the ROI for each advertisement, and improving A/B testing when sessions span multiple days. Our stack includes Clojure, Python, NodeJS, MongoDB, Docker/Kubernetes, Postgres, Google Dataflow, Google BigQuery, DBT, Airflow and Javascript (React). For reporting, we use Periscope, Metabase, Jupyter notebooks, and Google Data Studio. *Responsibilities: * *Build and scale data ingestion and transformation processes Transform our data into models that help all units of the company understand our performance and opportunities Build datasets, tools and documentation to enable analysts in all parts of the company to build their own analytics and reports. At Peerspace everyone is an analyst! Run ad-hoc analyses to support high-priority projects from internal business units Provide input on new data-generating processes and help organize our data capture efforts Devise and implement new algorithms and data processes to improve the performance of our marketplace (i.e. recommendation systems, search ranking) *Qualifications: * *Working knowledge of Python, R, Clojure, Julia or similar data-oriented languages, including data frameworks like tidy-verse or pandas, scikit, etc. Prior experience in SQL analytics (i.e Postgres, Bigquery) (e.g. you know how to use window functions and the nuances of using date ranges) Experience working with data visualization tools Basic knowledge big data technologies, e.g. Hadoop, Airflow, Kafka, Spark or similar Displaying skills in strong oral and communication with the proven ability to teach complex information effectively Working knowledge of statistical analysis and / or machine learning A degree or equivalent experience in Computer Science, Math, Physics, Engineering, Life Sciences or Social Sciences. *Preferred Qualifications: * *Experience with customer data platforms like Segment et al, and working with marketing teams Experience working in an online marketplace Experience with building programmatic SEO *Perks: * *Competitive salary and equity compensation $500 annual professional development allowance Discount on all Peerspace bookings 100% employee coverage of medical, dental and vision insurance Peerspace is a remote first company with team members located in cities around the globe. We believe that access to flexible workspace makes us more productive. Flex work perks include: *Laptop, high res display, and stipend to setup home office Monthly cell phone and internet credit Coworking membership if needed (in lieu of home office) Access to the Peerspace network of inspiring spaces to do your best work Biannual in-person, all company offsites and team-building events (in Peerspace locations, of course) *Diversity* At Peerspace, we're dedicated to creating a team that's diverse, equitable and inclusive. Our workplace is a space where all team members are empowered to blaze their own trail, make things happen, and take pride in their work. We believe bringing people together from different backgrounds and identities makes us stronger and better serves the Peerspace community. We'd especially like to encourage applicants from different backgrounds, locations, and experiences. Job Type: Full-time"
Data Engineer,Toyota,"Remote in Ann Arbor, MI 48103+2 locations",https://www.indeed.com/rc/clk?jk=13da15fe5e4f0f39&fccid=90f0cbc4a30f8dba&vjs=3,"Who we’re looking for Toyota’s Digital Solutions Department is looking for a passionate and highly motivated Data Engineer. The primary responsibility of this role is to solve complex data problems which will be used to deliver insights to help solve organizational goals for R&D. The Data Engineer will create data products used to increase productivity and deliver data pipelines for analytically driven use cases. Reporting to the Senior Manager, the person in this role will support the Digital Solutions department's objective of delivering analytic insights through a defined model development lifecycle which utilizes vehicle data (CAN300 communication bus and other vehicle systems) along with other appropriate sources of data as defined by the business requirements. What you’ll be doing Partner with key business stakeholders to understand priorities, identify strategic initiatives, and develop effective and timely analytic solutions Statistical analysis as needed to support these of business initiatives, such as customer segmentation and behavioral models Presentation and communication of analytic results utilizing appropriate tool(s) (Power BI, Tableau, R, Python, other) Review existing analytic processes to identify best practices and opportunities for improvement Providing valuable input into business intelligence roadmaps and development plans Mentor team members regarding analytic best practices Stay abreast of data governance and data management best practices and continually recommend and implement process improvements Support Data Governance steward with initiatives related to data governance and the maturation of the data governance organization Project Owner on company-wide data analytics initiatives Travel 5% Overtime 20% What you bring Bachelor’s degree (or higher) Professional relevant work experience Demonstrated ability to communicate effectively with all levels of an organization, both technical and non-technical team members Knowledge of predictive analytics techniques and statistical diagnostics of models. Expert resource for tool development Demonstrated ability to exchange ideas and convey complex information clearly and concisely. Has a value-driven perspective with regard to understanding of work context and impact. Proficient in an object-oriented programming language (Python, R, SAS or other). Willingness to learn new languages and technologies is mandatory What you may bring Degree in Statistics, Math, Economics/Econometrics or other related fields of study Skill in creating mathematical models, experience in AI, machine learning, engineering design Proven expertise in delivering data driven applications in the form of APIs, dashboards, or software packages Healthy curiosity about the industry and trends in data analytics Toyota ECU Design experience including Deep knowledge of the CAN bus Progressive years of experience in a mathematically driven field of study or career Toyota work experience What we’ll bring During your interview process, our team can fill you in on all the details of our industry-leading benefits and career development opportunities. A few highlights include: A work environment built on teamwork, flexibility and respect Professional growth and development programs to help advance your career, as well as tuition reimbursement Vehicle purchase & lease programs Comprehensive health care and wellness plans for your entire family Flexible work options based on business needs Toyota 401(k) Savings Plan featuring a company match, as well as an annual retirement contribution from Toyota regardless of whether you contribute Paid holidays and paid time off Referral services related to prenatal services, adoption, child care, schools and more Flexible spending accounts Relocation assistance (if applicable) To save time applying, Toyota does not offer sponsorship of job applicants for employment-based visas or any other work authorization for this position at this time. This role is open to potential remote opportunities. #LI-REMOTE"
Data Engineer,AArete,"Denver, CO+5 locations",https://www.indeed.com/company/AArete/jobs/Data-Engineer-245008a137ccf0c3?fccid=24deae60a689525a&vjs=3,"Data EngineerAArete is one of a kind when it comes to consulting firm culture.You will be at the forefront of a development process to build a high-quality product using AI and machine learning in both cloud and on-premises environments. In this role, you will have the opportunity to assist organizations reduce costs and optimize organizational efficiency through real-time streaming analytics powered by Kafka and Kotlin. You will have an opportunity to foster a culture of collaboration and technical expertise with your team and AArete leadership as a subject matter expert.Work you’ll do *Understand product needs to define optimal system specifications Plan/ design the technology solution, build to scale and remain compliant to security standards Communicate system requirements to product engineering teams Provide information architecture, data engineering pipeline design, application software, API design and participate in development and production rollout of the solution Evaluate and select appropriate tech stack and suggest integration methods & business impact Ensure the implementation of agreed architecture and infrastructure Work closely with product managers, engineering, and data science teams to oversee product build/ release Resolve project challenges involving scope, design, and technical problems when they arise Address technical concerns, ideas, and suggestions Monitor systems to ensure they meet both user needs and business goals *Requirements* *Degree in Computer Science, Information Technology, or related field Minimum of 8 years of hands-on experience with data/system integration/analytics/software life cycle as a Data Engineer within a product development environment Experience in conceiving/designing/ architecting/developing data platforms using Big data and cloud technologies (AWS preferred, GCP a plus) Proficient in designing DWH/ ETL solutions and In-depth knowledge of data models/ structures Strong experience in Kafka and KStreams API Experience using Kotlin and Java Programming skills for data engineering Documentation of critical artifacts such as Logical/Conceptual design, Source to Target mapping, System architecture, etc. Problem-solving attitude, with a willingness to work in a fast-paced product development environment and a hands-on mentality to do whatever it takes to deliver a successful product Experience with working with an on-shore/off-shore model Understanding data standardization practices in the pharma domain, integrating Healthcare data, and security related to HIPAA is a plus Experience with data and system integration using RESTful APIs, web services, JSON, and XML will be a plus Familiarity with data visualization and BI tools is a plus *Why AArete?*We are an innovative strategy, operations, and technology consulting firm. In Greek, our name signifies “excellence” – due to this the bar is set high at AArete. We believe that any organization can succeed by enriching and empowering its people – starting with our own team members. Our distinctive Culture of Care compels us to collaboratively solve problems that effect purposeful change for our clients and community.We’re growing fast, and you will too. At AArete, we want you to realize your full potential by having direct impact delivering on our mission while prioritizing space for personal development and fulfillment.At AArete, you’ll collaborate with team members across the globe. While we have offices in the US, India, and the UK, based on your preference and client needs, AAretians may work on-premises and/or remotely.About AAreteAArete is a global management and technology consulting firm specializing in strategic profitability improvement, digital transformation, and advisory services. Our cross-industry solutions are powered through modern technology, market intelligence, and big data to drive purposeful change and actionable outcomes.AArete is guided by our deeply embedded principles: Excellence, Passion, Loyalty to Clients, Stewardship, Family, Community, Sustainability, and Inclusion.We are proud to have earned a Great Place to Work Certification™ and named as one of America’s Best Management Consulting Firms by Forbes, Vault’s Top 50 Firms to Work For, Crain's Chicago Business Fast 50, Inc 5000’s Fastest Growing Firms, Consulting Magazine's Fastest Growing Firms.Check out some of our AAwesome* Benefits* Flexible PTO, monthly half-day refuels, volunteer time off, 10 paid holidays Own Your Day flexible work policy Competitive majority employer paid benefits: Medical, Dental, Vision, 401K Match Employee Stock Ownership Plan Generous maternity / paternity leave options Completely employer paid Life Insurance, STD, LTD Charitable contribution matching program New client commission opportunities and referral bonus program Video free Fridays Bike share discount program All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Job Type: Full-time"
Jr. Data Applications Engineer,Tyler Technologies,+1 locationRemote,https://www.indeed.com/rc/clk?jk=3f19158913b3c8ef&fccid=35fa439a19059a40&vjs=3,"Tyler Technologies is currently seeking a Jr. Data Application Engineer to join their US Direct / NIC Division to support their Recreation Dynamics product. This is a remote position. As our Jr. Data Application Engineer, you will focus on supporting our government partners and ensuring support and satisfaction to our Outdoor products. Summary: The ideal candidate will be able to manage communications with our clientele as the primary point of contact for complex analytical, technical and administrative support in a SQL Server environment. You will be expected to quickly gain the knowledge of our software system and customer business areas in order to be effective at this role. The capability to handle multiple inquiries / projects with varying deadlines and in a fast-paced office environment is a must. Key Responsibilities: Will provide complex analytical, technical, and administrative support to facilitate the day to-day operations. Respond to complex inquiries from administrators. Perform analytical and technical tasks to complete special and ongoing projects requiring extensive research, data collection, and detailed analysis, following departmental guidelines, policies, and procedures. Exercise independent judgment to troubleshoot and resolve issues. Experience / Education: Degree in Computer Science is preferred SQL experience would be a plus 0-3 years of experience in a similar role Solid analytical and problem-solving skills involving sound decision making and effective resolutions Keen attention to detail. Strong planning and organizational skills involving the ability to manage multiple work streams effectively. Ability to work within a team to meet established project goals Ability to communicate professionally, concisely and effectively, both verbally and in writing, to internal and external stakeholders"
Data Engineer,Federal Reserve Bank of New York,"Hybrid remote in New York, NY",https://www.indeed.com/rc/clk?jk=497f7c28cc440455&fccid=2c6850e24c8a2811&vjs=3,"Company Federal Reserve Bank of New York Working at the Federal Reserve Bank of New York positions you at the center of the financial world with a unique perspective on national and international markets and economies. You will work in an environment with a diverse group of experienced professionals to foster and support the safety, soundness, and vitality of our economic and financial systems. The Bank believes in work flexibility to balance the demands of work and life while also connecting and collaborating with our colleagues in person. Employees can expect to be in the office a couple of days per week as needed for meetings and team collaboration and should live within a commutable distance. What we do: The Data and Analytics chapter in the Technology Group builds data products that provide the organization with analytical capabilities in support of its mission. Reporting to the chapter lead for Data and Analytics, you will be part of a diverse, dynamic, and agile squad that enables rapid, repeatable, and resilient self-service analytics capabilities for the enterprise. This includes Data Preparation, ETL, Data Integration, RESTful analytical apps, Visualization/BI, and Surveys. Your role as an Data Engineer (Alteryx, Cloudera, Tableau, AWS): Develop and maintain workflows using Alteryx with wide-ranging source and target configurations in a customer facing role Wireframe, design and build Tableau dashboards with advanced features in a customer facing role Migrate on-premise data management solutions to AWS cloud only as well as hybrid configuration. Advice, design, tune and optimize Alteryx flows build by customers and deploy to gallery Display strong understanding of Cloudera’s SQL processing solutions Research, troubleshoot and recommend solutions to complex data integration problems. Mature analytics self-service adoption through active contributions towards community of practices, center of excellence and other forums. Deep understanding of interoperability between current and future platforms. (Alteryx, Tableau, AWS, etc.) Ability to articulate where the strengths and weaknesses are for each of our platforms to the end users What we are looking for: Technologist with background in data engineering with hands on experience in Alteryx, Tableau, Hadoop, Hive, Impala, AWS Data services Experience with Python in data engineering or application development Expertise in data wrangling, data integration, and visualization Knowledge of data architecture and data management best practices Experience implementing and maturing an analytics self-service model Collaborative working style to support larger team goals and outcomes Experience with relational databases and SQL-based technologies such as Oracle, Microsoft SQL Server or MySQL Experience with data catalog tools like Collibra Touchstone Behaviors set clear expectations for leading with impact at every stage of our careers and aspire to achieve in our continued growth and development. Communicate Authentically: Empathetically engage one another with direct and transparent dialogue and listening. Actively discuss viewpoints with respect and compassion in a timely and candid manner, taking into account verbal and nonverbal cues. Ask questions, learn from each other, and share information widely to move the Bank's work forward. Collaborate Inclusively: Inspire a diverse and inclusive environment that empowers others to contribute meaningfully. Intentionally bring a diverse set of people together to achieve positive business results. Drive Progress: Grow and adapt to changing priorities in the Bank. Experiment with new concepts and take appropriate risk to drive innovation. Remain curious and action oriented, navigating through ambiguity and uncertainty to drive outcomes. Develop Others: Equitably champion, mentor, and develop others to grow professionally. Demonstrate vulnerability and empathy to create a trusted environment. Take Ownership: Establish an environment of action and excellence by holding self and others accountable to execute to the highest standard. Benefits: Our organization offers benefits that are the best fit for you at every stage of your career: Fully paid Pension plan and 401k with Generous Match Comprehensive Insurance Plans (Medical, Dental and Vision including Flexible Spending Accounts and HSA) Subsidized Public Transportation Program Tuition Assistance Program Onsite Fitness & Wellness Center And more Please note that the position requires access to confidential supervisory information and/or FOMC information, which is limited to ""Protected Individuals"" as defined in the U.S. federal immigration law. Protected Individuals include, but are not limited to, U.S. citizens, U.S. nationals, and U.S. permanent residents who either are not yet eligible to apply for naturalization or who have applied for naturalization within the requisite timeframe. Candidates who are permanent residents may be eligible for the information access required for this position if they sign a declaration of intent to become a U.S. citizen and pursue a path to citizenship and meet other eligibility requirements. In addition, all candidates must undergo an enhanced background check, comply with all applicable information handling rules, and will be tested for all controlled substances prohibited by federal law, to include marijuana. The Federal Reserve Bank of New York is committed to a diverse workforce and to providing equal employment opportunity to all persons without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, age, genetic information, disability, or military service. The successful candidate must be fully vaccinated against COVID-19, and receive a booster shot within 30 days of being eligible to do so, unless the Bank grants an exemption based on a medical condition or sincerely held religious belief. This is not necessarily an exhaustive list of all responsibilities, duties, performance standards or requirements, efforts, skills or working conditions associated with the job. While this is intended to be an accurate reflection of the current job, management reserves the right to revise the job or to require that other or different tasks be performed when circumstances change. Full Time / Part Time Full time Regular / Temporary Regular Job Exempt (Yes / No) Yes Job Category Information Technology Work Shift First (United States of America) The Federal Reserve Banks believe that diversity and inclusion among our employees is critical to our success as an organization, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. The Federal Reserve Banks are committed to equal employment opportunity for employees and job applicants in compliance with applicable law and to an environment where employees are valued for their differences. Privacy Notice"
Senior Data Engineer,Moonshot Brands,Remote,https://www.indeed.com/rc/clk?jk=45aa361239be63f9&fccid=034ebc94132db19a&vjs=3,"About Moonshot Brands We are Moonshot Brands, a Y-combinator-backed company (W21) with $160M in debt and equity funding from leading Silicon Valley VC firms, including Victory Park Capital, Liquid 2 Ventures (Joe Montana), and Garage Capital. Among our founding team of MIT Sloan and Wharton graduates, we have operated and sold five businesses and have come together as Moonshot Brands to acquire, operate, and grow profitable e-commerce brands. From our experience, we want to build the acquisition process that we wish we could have had and to provide the post-acquisition resources to grow your business to its fullest potential. As entrepreneurs ourselves, we believe in empowering our founders, giving them a stake in Moonshot’s continued success, and collaborating with an all-star team to change the e-commerce landscape. We connect our portfolio to growth capital, data, and expertise in operations, marketing, supply chain management, and product development to provide owner-operators with the infrastructure to grow and compete at scale. Moonshot is building a technology-centric ecosystem to provide our portfolio with cutting-edge tools and data-driven insights to succeed in global marketplaces. From inventory forecasting to performance marketing and automation, we are building the technology that allows brands to achieve peak performance and win in their markets. If you’d like to be part of this Moonshot which will be a fun fast-paced rocketship that will drive the future of e-commerce brands and you think you add significant value to our mission we’d love to hear from you. About The Role Moonshot Brands is seeking a Senior Data Engineer. In this role, you will work to shape the technology strategy and development of the Moonshot Brands Platform from a Data Engineering perspective. As Senior Data Engineer, you will: Build scalable data platforms and support the fast-growing data within the business. Implement API based integrations with external platforms and tools Develop, maintain and refactor data models & pipelines that allow the business to get maximum value from our data, with high quality, clean, maintainable code Curate, organize, and document data definitions, metrics, and reporting environments across raw datasets, dbt, and Looker to unlock value and drive efficiency Ensure data quality and integrity through well-defined acceptance criteria and testing. Manage monitoring and observability tooling of the data pipelines Helping define and improve our internal standards for architecture, style, maintainability, and best practices for a high-performance data organization Mentor and develop junior data engineers in adopting best practices Who we looking for: 4+ years working with ETL/ELT, and reporting and analytic tools. 2+ years working with Google Cloud data warehouse technical architectures and infrastructure components. 1+ years working with DBT analytics engineering workflow 5+ years working in eCommerce, Inventory, Finance, logistics, or SAAS Proficient in SQL and Data Analysis Moonshot Brands welcomes all and is proud to be an equal opportunity employer and values diversity at our company. We do not discriminate based on race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, disability status, or other applicable legally protected characteristics."
Health Data Engineer,Oak Ridge National Laboratory,"Oak Ridge, TN 37830+6 locations",https://www.indeed.com/rc/clk?jk=61ed1b10347ff069&fccid=64e028df9b3fd2c4&vjs=3,"Requisition Id 8179 Purpose: The Information Technology Services Division in the Business Services Directorate at the Oak Ridge National Laboratory is seeking qualified applicants for a Data Engineer position for an embedded research project. The research activities include HIPPA compliant research data that has been entrusted to ORNL. As such, you will have the opportunity to work on some of the most challenging and impactful research and development programs in healthcare informatics, bioinformatics, and computer science. This position will work directly within a medical research data project as part of the research team to deliver reporting workflows as well as data management and data lifecycles. As a Data Engineer, you should be comfortable around Linux, SQL, Python, Containers, Pandas, Spark, and source control in a high security environment. Major Duties and Responsibilities: As a Data Engineer you will be responsible for: Developing high-scale, robust data warehouses, and data lakes with special focus on the state-of-the-art solutions for healthcare, life sciences, and genomics. Interfacing with research teams to understand data needs, and providing subject matter expertise to research teams, and other team members about the data models, query optimizations, and schema interpretation. Designing, building and launching new data/study marts for the major national research programs. Designing, building and launching new data quality, data extraction, transformation and loading processes. Designing and developing architectures for intake, curation, organization, and dissemination of data in support of data science and related disciplines. Designing and development of high-performance database architectures. Researching and evaluating the state-of-the-art data and information management technologies. Working on a variety of data assignments; collaborate with scientists and engineers, and expect to produce reliable data products and systems. Experience working with Big Data processing frameworks such as Spark and Pandas Strong experience with relational SQL and python programming languages Basic Qualifications: B.S. in Computer Science, Information Systems, Engineering, or closely related field A minimum of 2 years of experience in database design and development. Preferred Qualifications: M.S or Ph.D. degree in Computer Science, Information Systems, Engineering, or closely related field. 5+ years of experience in basic and advanced SQL, database programming, and scripting languages (Python preferred). 5+ years of experience in data warehousing systems and database system administration. Expertise with SQL Server is strongly preferred. Experience in designing analytics data systems (OLTP, etc.). Familiarity with Big Data and NoSQL architectures. Demonstrated experience with collecting, organizing, storing, and preparing data analysis. Ability to conduct tasks independently and communicate effectively to team members and stakeholders. Experience with heath care informatics, and clinical data is highly desired. Special Requirement: This position requires the ability to obtain and maintain a clearance from the Department of Energy. As such, this position is a Workplace Substance Abuse (WSAP) testing designated position. WSAP positions require passing a pre-placement drug test and participation in an ongoing random drug testing program. Benefits at ORNL: UT Battelle offers an exceptional benefits package to include matching 401K, Pension Plan, Paid Vacation and Medical / Dental plan. Onsite amenities include Credit Union, Medical Clinic and free Fitness facilities. For more information about our benefits, working here, and living here, visit the “About” tab at jobs.ornl.gov. #LI-DC1 This position will remain open for a minimum of 5 days after which it will close when a qualified candidate is identified and/or hired. We accept Word (.doc, .docx), Adobe (unsecured .pdf), Rich Text Format (.rtf), and HTML (.htm, .html) up to 5MB in size. Resumes from third party vendors will not be accepted; these resumes will be deleted and the candidates submitted will not be considered for employment. If you have trouble applying for a position, please email ORNLRecruiting@ornl.gov. ORNL is an equal opportunity employer. All qualified applicants, including individuals with disabilities and protected veterans, are encouraged to apply. UT-Battelle is an E-Verify employer."
AWS Data Engineer,ValueBase Consulting,"Atlanta, GA+1 location",https://www.indeed.com/rc/clk?jk=b1a2456fd8823e9b&fccid=ffc8bb74d131df37&vjs=3,"AWS Data Engineer Atlanta, GA 12 Months Please send your resumes to hr@value-base.com for immediate consideration. Advanced knowledge of AWS Services/Architecture Experience in AWS Compute such as EC2, Lambda, Beanstalk, Batch or ECS Experience with AWS Storage services such as:S3, EFS, Glacier. Experience in AWS Management and Governance suite of products such asCloudTrail, CloudWatch Experience in AWS Analytics such as Athena,EMR, Glue, Redshift, Kinesis Strong knowledge in Python object-oriented programming Strong experience with AWS Database services such as: RDS, DynamoDB Experience using APIs for developing or programming software Experience using AWS Application Integration Services such as: Simple Notification Service (SNS), Simple Queue Service (SQS), Step Functions. Experience with AWS Developer tools such as: CodeDeploy, CodePipeline Experience with JSON Strong experience with SQL Experience with enterprise data lakes, data warehouses, data marts, and big data. Strong experience with data migration, cloud migration, and ETL processes. Experience determining causes of operating errors and taking corrective action"
Data Engineer,Sapient Industries,"Remote in Philadelphia, PA 19103",https://www.indeed.com/rc/clk?jk=45341abb4cf5e208&fccid=f72f53be78a80693&vjs=3,"Data Engineer Sapient is ushering in a new paradigm of building intelligence by building the first-ever building operating system. We ingest, analyze and convert billions of data points into meaningful insights through AI, machine learning, and always-on optimization. Insights that enable enterprises to fight climate change and transform the way their spaces are planned and run. From the tallest skyscrapers to the widest portfolio of buildings spanning the globe. From how space is used to how it is physically constructed. From driving enterprise sustainability goals to bottom-line profits. From creating engaged employees to satisfied shareholders. The world's largest enterprises are joining us on this journey because they, like us, care about making substantial, lasting positive changes to the built world and our planet. Join us, and together we will accomplish incredible, previously unimagined things. For a better future. Role Overview Sapient is looking for a Data Engineer. This role requires an experienced, highly intelligent, creative, and strategic person who can drive and manage positive change across the organization. The ideal candidate will be able to design, build, and deploy complex data pipelines in cloud environments given requirements from the business. You should be able to understand how to work with time-series data and how to apply functions to time-series data. You will be responsible for establishing metrics around data quality, reporting quality, and how to improve the speed of analysis. Understand complex SQL queries involving windowing functions and how to create chart points in SQL such as cumulative value over time. The ideal candidate will own the performance of our data pipelines. You'll work within a team focused on building cutting-edge data products, services, and APIs. Requirements 3+ years of hands-on data engineering in petabyte-scale data systems. Understand and balance the roles of Innovation, GSD, Security, and Automation. Ability to collaborate and debate ideas, with the outcome of finding the best solution we can quickly. You are fearless, aggressive, and creative in solving problems including automating human workflows and tasks. Take ownership and improve upon our project management process. Experience with big data systems including Spark, KubeFlow, BigQuery, Athena, Postgres, Cockroach, etc. Minor experience with systems automation and configuration systems such as Kubernetes, Lambdas, Cloud Functions, Airflow, Etc. Understanding of time-series data and how to report events and occurrences on that data correctly. Programming languages like Go, Python, or Scala You will want to work for us if you Help build a multi-billion dollar company while fighting climate change and building the next generation of intelligent buildings. Care about the planet and how to save it through completely novel ideas at scale. Like to move fast - you thrive in a fast-paced environment of innovation and cross-team collaboration. Love to roll up your sleeves and get things done. Want to deliver new products and delight customers. Benefits/Perks include, but are not limited to: Flexible, remote work arrangements Flexible Paid Time Off (PTO) 14 Paid Holidays Comprehensive and affordable health benefits 401k Plan Pet Insurance Generous Paid Parental Leave Team building and volunteering events Monthly internet stipend Employee Referral Bonus program Unlimited professional growth potential Disclaimer Sapient is an Equal Opportunity Employer and strictly prohibits discrimination of any kind. We believe that great ideas can come from anywhere. We are committed to building the best team possible and all employment decisions are based on business needs, job requirements, and individual potential and qualifications, without regard to race, color, age, religion, socioeconomic status, orientation, gender identity, national origin, or disability. The Sapient team is diverse — we welcome and learn from different individual experiences and points of view that our teammates bring to the table. We're excited to have you inspire us with yours!"
DATA ENGINEER,DraftKings,+5 locationsRemote,https://www.indeed.com/rc/clk?jk=b02da1a333c89e88&fccid=2b2d6f212948082d&vjs=3,"REMOTE - US ENGINEERING JR4289 FULL TIME WE’RE REIMAGINING SPORTS AND TECHNOLOGY. DraftKings is bringing sports fans closer to the games they love and becoming an essential part of their experience in the process. An industry pioneer since our founding in 2012, we believe we can continue to define what it means to be a technology company in sports entertainment. We love what we do and we think you will too. BUILDING THE POSSIBILITIES. DraftKings is growing quickly and we’re looking for a Data Engineer (Platform Operations) to help establish and lead a data team centered around the mission of providing a best-in-class experience for our products and customers. This position requires strong technical skills and a bias toward collaboration. You will be working across teams, informing business decisions, and helping to expand our software platform. WHAT YOU’LL DO AS A DATA ENGINEER (PLATFORM-OPS) AT DRAFTKINGS: Bring operational excellence with a focus on performance analysis, optimization, and tuning. Design scalable systems that support data transformation and structures, metadata, dependency and workload management. Improve expanding our systems through automation & documentation when architecting new or enhancing existing features. You will rapidly diagnose and fix problems while providing production support for business critical systems. Have the opportunity to see your personal work make an immediate impact on influential products. Care about agility as much as you care about scalability. We roll out products very quickly and are looking for a team that can pivot at a moment’s notice. Work with your team under fast deadlines to design, build, and deliver innovative solutions. WHAT YOU’LL BRING: Experience working with MPP platforms like Redshift, Snowflake, Vertica and/or Azure Data Warehouse A strong knowledge of a variety of AWS services like DMS, S3, EC2, ECS/ECR, IAM, CloudWatch, etc. Experience provisioning Infrastructure-As-Code (IAS) with either Terraform or CloudFormation. Experience working with CI/CD pipelines and deployment automation Experience with a variety of data logging/monitoring tools, such as DataDog. Experience writing software (preferably with Python) and scripting (Bash) Experience working as a database administrator is a plus. Advanced SQL experience Experience in all aspects of business intelligence and data engineering, including data warehousing, delivery, and operations. The ability to build and optimize data pipelines, transformations, architectures, and data sets. #LI-SD1 This position can sit in either Boston or remote; however, this work is to be performed entirely outside of Colorado. WHO ARE WE A GOOD FIT FOR? We love working with talented people but more than that, we seek out compassionate co-workers with a collaborative spirit. Our work moves quickly and we’re great at coming together to find creative solutions to some of tech’s most interesting problems. If that sounds good to you, join us. WE ARE DRAFTKINGS. We’re inspired by our shared passion for developing creative solutions to complex challenges and empowering the people around us to do their best work. We are industry leaders in the digital entertainment and technology space propelled by constant curiosity and diverse perspectives. Our teams are fueled by innovation. We are looking ahead, building what’s next, and continuously reinventing the industry. We’re a publicly traded (NASDAQ: DKNG) technology company headquartered in Boston, with teams around the world and an expanding global presence. JOIN US! We strive to create a place where all feel safe, empowered, engaged, championed, and inspired. DraftKings is proud to be an equal opportunity employer. This means we do not tolerate discrimination of any kind and are committed to providing equal employment opportunities regardless of your gender identity, race, nationality, religion, sexual orientation, status as a protected veteran, or status as an individual with a disability. READY TO BUILD WHAT’S NEXT? APPLY NOW. As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment."
Data Engineer,Foundation for California Community Colleges...,Remote,https://www.indeed.com/company/Foundation-for-California-Community-Colleges/jobs/Data-Engineer-4907acff91e687b4?fccid=792a38b0448ae235&vjs=3,"Data Engineer California College Guidance Initiative Remote/Virtual - All candidates must live in California. Full-Time The California College Guidance Initiative is looking for a data engineering expert to join the Infrastructure Team. As part of the Infrastructure Team, you will be a key strategic leader in the expansion, refinement, and continued development of CCGI’s infrastructure utilizing Amazon Web Services (AWS), as well as continuing to build out our data analytics and engineering tools. This role will be instrumental in helping us scale our work statewide and open the door for expanded use of California's official college and career planning platform for K-12th grade students, parents, and educators, CaliforniaColleges.edu. The ideal candidate for this team has extensive experience building out complex data architectures, including the testing, maintenance, and refinement of all data pipelines. They have also experience successfully scaling up an organization’s data intake to terabytes and petabytes of data, as well as optimizing data delivery and automating manual processes. This person is comfortable working with structured and unstructured data and can troubleshoot data loading and processing tools via SQL, Python, shell scripting, AWS, etc, and take on a leadership role in special projects when needed. Additionally, this person had extensive experience developing robust data documentation and data governance protocols. There are no direct supervisory responsibilities for this position, but you must be able to proactively and successfully partner and collaborate with other subject matter experts on a project management basis. Lastly, you must be comfortable leading and project managing work with many unknowns and ambiguous solutions, as well as carry a deep knowledge and/or curiosity about the needs and behaviors of students, educators, and parents, and a passion for educational equity. What Will You Be Doing? — Manage, refine, and enhance AWS cloud services infrastructure which include the following: EC2, VPC, RDS, ECS, CloudWatch, CloudFormation, CloudTrail, Transfer for sFTP, S3, Lambda, Secrets Manager, and Route 53. — Lead ETL/ELT processes which include the development, refinement, and implementation of data loading and processing tools, including Snowflake, Airflow, Python, SQL, dbt, and shell scripts. — Review, redesign, and expand existing analytics and data processing architecture to create an optimal data pipeline(s). — Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, designing infrastructure for greater scalability and automation. — Maintain and update documentation of data architecture from both the macro view (i.e. architectural diagrams) and the micro view (i.e. script level tasks in Airflow). — Lead meetings, research processes, collect data, analyze information and collaborate with the key stakeholders of your projects. — Develop and maintain expert knowledge of CaliforniaColleges.edu — Continuously improve data pipelines and architecture by staying updated on industry trends and best practices. — Model CCGI’s values both in action and in how decisions are made. What Technical Skills Do You Need? — Build processes supporting data transformation, data structures, metadata, dependency, and workload management. — Advanced proficiency with cloud analytical tools: Snowflake, Redshift, Hadoop, Spark, Kafka, etc. — Advanced proficiency with ETL tools like Matillion, dbt, Talend, etc. — Advanced proficiency with data pipeline and workflow management tools: Airflow, Azkaban, Luigi, etc. — Advanced proficiency building and optimizing data pipelines, cloud architectures, and data sets. — Advanced proficiency with scripting languages like Python, R, Scala, etc. — Advanced proficiency developing cloud infrastructure in AWS or currently has or is in the process of obtaining AWS Certification as a Solutions Architect - Associate — Expert SQL knowledge (SQL Server, PostgreSQL, MySQL, etc.) and understanding of relational databases, query authoring and optimization, as well as working familiarity with a variety of databases. — A successful history of manipulating, processing and extracting value from large structured and unstructured datasets. What Intangibles Do You Need? — Strong decision-making skills and collaborative spirit with the ability to take abstract brainstorming and generate concrete proposals for action. — Advance projects without detailed supervision, balancing multiple responsibilities, and providing colleagues with actionable proposals for advancing collective efforts. — Thrive in a fast-paced environment with changing priorities and deadlines. — Juggle multiple projects of various scopes with ease and grace. — Meticulous attention to detail. — Excellent verbal communication skills; ability to communicate with various levels of professionals. — Strong organizational, project, and time management skills. More about the Cloud Infrastructure Team The team oversees all of CCGI’s internal cloud-based data analytics and engineering infrastructure and technical strategy. This includes data analytics, data warehousing, and data engineering projects, ensuring alignment with the organization's mission and goals. This is a new role for the team. We are keen for you to bring your experience where you can thrive in an environment that allows for knowledge sharing and creates opportunities for you to take initiative to learn even more. This role reports to the Director, Cloud Infrastructure. More about CCGI CCGI works to ensure that all 6th-12th grade students in California have access to a systematic baseline of guidance and support as they plan, prepare, and pay for postsecondary education and training. This baseline is provided by CaliforniaColleges.edu, which provides California students and educators with a wide range of college and career planning information and tools. The site also houses, audits, and transmits student data to help ensure more accurate and efficient decisions regarding admissions, financial aid, and course placement. CCGI provides technical assistance, support, and training to K-12 school districts in order to support students, counselors, and parents with the systematic use of CaliforniaColleges.edu, including its transcript-informed tools. CCGI is a positive, diverse, and supportive culture. Everyone at CCGI works remotely. We are all located in various parts of California. We rarely meet in person. Instead, we make use of tools, such as ZOOM, Slack, and Salesforce, to communicate and document our work. CCGI is housed at the Foundation for California Community Colleges but is an autonomous initiative with its own mission, goals, and leadership team.Application Instructions— Go to https://www.cacollegeguidance.org/who-we-are/careers-opportunities/ — Find “Data Engineer” and follow the directions to apply. — Include both a cover letter and resume with your application. The application process will be open until the position is filled. The Foundation for California Community Colleges (Foundation) is committed to providing an environment of mutual respect where equal employment opportunities (EEO) are available to all employees and applicants without regard to race, color, ancestry, national origin, genetic characteristics, sex, gender identity, gender expression, sexual orientation, marital/parental status, political affiliation, religion, age, disability, pregnancy, childbirth, breastfeeding or veteran status. In addition to federal law requirements, the Foundation for California Community Colleges complies with applicable state and local laws governing nondiscrimination in employment. The Foundation for California Community Colleges is committed to workplace policies and hiring practices that comply with federal, state, and local law. During the hiring process, the Foundation is interested in hiring qualified candidates who are eligible and authorized to work in the United States. However, at this time, the Foundation is not able to sponsor visas. As a result, the Foundation cannot hire applicants that currently, or in the future, require immigration sponsorship for work authorization (i.e., H1B or F1 Student Visa). Job Type: Full-time Benefits: Dental insurance Employee assistance program Employee discount Flexible spending account Health insurance Health savings account Life insurance Paid time off Referral program Retirement plan Tuition reimbursement Vision insurance Schedule: Monday to Friday Work Location: Remote"
PySpark Data Engineer,Deloitte,"New York, NY+126 locations",https://www.indeed.com/rc/clk?jk=063d9ee03495cb78&fccid=9e215d88a6b33622&vjs=3,"The AI & Data Engineering team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-makin g. Together with the Strategy practice, our Strategy & Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets. AI & Data Engineering will work with our clients to: Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements Qualifications Required: 3+ years of relevant technology consulting or industry experience to include experience in Information delivery, Analytics and Business Intelligence based on data 3+ years experience in Python and/or R 3+ years experience in SQL 3+ years experience PySpark 2+ years of hands on experience with data core modernization and data ingestion 1+ years experience leading workstreams or small teams Bachelor's Degree or equivalent professional experience Limited immigration sponsorship may be available Ability to travel up to 50% on average, based on the work you do and the clients and industries/sec tors you serve Preferred: An advanced degree in the area of specialization is preferred. Experience with Cloud using Amazon Web Services (AWS), Microsoft Azure, and/or Google Cloud Platform (GCP) Experience with Spark, Scala Understanding of the benefits of data warehousing, data architecture, data quality processes, data warehousing design and i mplementation, table structure, fact and dimension tables, logical and physical database design, data modeling, reporting process metadata, and ETL processes. Experience designing and implementing reporting and visualization for unstructured and structured data sets Experience designing and developing data cleansing routines utilizing typical data quality functions involving standardizatio n, t ransformation, rationalizatio n, linking and matching Knowledge of data, master data and metadata related standards, processes and technology Experience working with multi-Terabyte data sets Experience with Data Integration on traditional and Hadoop environments Strong oral and written communication skills, including presentation skills (MS Visio, MS PowerPoint). AI&DE23"
Data Engineer,Mavrck,+2 locationsRemote,https://www.indeed.com/company/Mavrck/jobs/Data-Engineer-de35a6ecfb7f4f03?fccid=cec711a664fcfd7e&vjs=3,"Mavrck is the all-in-one, advanced influencer marketing platform enabling enterprise consumer brands to harness the power of social proof that consumers trust today. Marketers use Mavrck to discover and collaborate with influencers to create trusted content at scale. Mavrck is the #1 influencer marketing platform for the Enterprise on software review site G2, and was also named a “Leader” in Forrester’s evaluation, The Forrester New Wave™: Influencer Marketing Solutions, Q2 2020.In order to be the leading all-in-one advanced influencer marketing platform, Mavrck analyzes billions of assets to derive relevant information for our clients in a feasible time and cost. By being an early member of Mavrck’s Data Engineering team, you will have ample opportunity to work on many aspects of Mavrck’s Data Engineering platform.Day to day responsibilities include the architecture, execution, deployment and maintenance of: DataStores HBase, MySQL, Hadoop Search Technologies Solr, ElasticSearch Processing Pipelines YARN, Kafka, Spark API Provisioning & Deployments JVM ( Kotlin ) Kubernetes Data Analytics / Business Intelligence Roll Our Own ~ ad-hoc data request fulfillments Data Science ( Green Fields ) NLP Image Processing Modeling Machine Learning This role will offer the opportunity to work on the entire data stack! We don’t expect the candidate to have experience in all areas of our stack, but require a willingness and drive to learn. Curiosity and hustle is part of the DNA that makes up Mavrck’s squad and learning and building are natural consequences of that. Be a part of a creative group that solves challenging problems and has fun doing it!Mavrck is committed to building an inclusive, supportive place for you to do the best and most rewarding work of your career. If you identify with any of the following, we encourage you to apply! Required : Experience w/ JVM Technologies ( Java, Kotlin ) Experience w/ Web Technologies ( HTTP ) Experience w/ SQL & NoSQL Technologies ( ex: MySQL, HBase, Mongo, Redis) Experience w/ Search Technologies ( Solr / ElasticSearch ) Experience w/ Processing Pipelines ( YARN, Kafka, Spark ) Experience w/ Hadoop & YARN Required : An analytical mindset Some perks of being on our Squad include... Remote Work: We acknowledge (now more than ever) that you do not need to be in an office or at a desk to be successful! Unlimited PTO: To further support freedom and flexibility, we want you to take the time off when you want or need it to best recharge! Flex-Fridays: Summer Fridays are year long at Mavrck. Catch up on emails on Friday afternoons or start your weekend early - the time is yours! Paid Parental Leave: Take up to 12 weeks paid leave when a little one joins the family! Ongoing Learning: Growth is a big reason people join Mavrck and a core tenet of our culture, so we provide access to a variety of Learning and Development options, like online courses or coaching - and support you pursuing ones that you are passionate about! We Care: 401k, Health, Dental, Vision, Long Term and Short Term disability are part of a comprehensive benefits package Fun, Pet-Friendly Environment: When we’re in the office, music, jeans and t-shirts are the norm - and office dogs!! Yummy Food: Healthy snacks are always provided, and each Wednesday we enjoy catered lunches as a team. Mavrck is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires accommodation, please let us know by completing the form below. Job Type: Full-time"
Data ETL Engineer,Charles Schwab,"Lone Tree, CO 80124",https://www.indeed.com/rc/clk?jk=f8bdf8bf86c98326&fccid=3c74eafe288fc8ca&vjs=3,"Your Opportunity The Sales and Service Technology (SST) division supports client facing systems, sales support systems, and service systems. Salesforce.com is the foundation of the Customer Relationship Management (CRM) systems used by the Sales Technology team. The SST org, specifically the CRM Batch Integration teams have responsibility for all data moving in and out of the Salesforce Orgs in a batch technology manner and the quality of the data. As a member of the SST-CRM Batch Integration team, you will be immersed in a collaborative, innovative, and technically challenging environment. As a Data Engineer you will be responsible for design, development, and delivery of data integration solutions. What you are good at Collaborating with business partners: Analyzing business and systems requirements and providing technical solutions to meet their requirements Designing and developing solutions application platform integrating with backend systems and working closely with our development, QA, product teams and Architects Ensuring timely delivery of project deliverables using agile methodology delivering what the client needs in a timely manner Partnering with application and data developers on designs, models and best in class implementation Interacting with experts from across Schwab in different support organizations and business groups Providing Tier 2 support for production issues, including fixes across platforms and on-call responsibilities working with production support team to ensure 24x7 availability of production systems. Designing and implementing data integration ETL in Informatica Power Center and IICS utilizing Oracle DB or Google Cloud Platform Working closely with DBAs, data analysts, developers, and production support to identify and fix data issues that cross platforms What you have A data quality and performance focused mind. A strong foundational understanding of data engineering and integration of various data systems and related concepts and technologies Demonstratable problem solving and troubleshooting skills, coupled with a desire to take on responsibilities; solutions oriented Excellent written and verbal communication skills, including the ability to explain complex system issues in business terminology The ability to effectively handle multiple, competing, high-priority projects with varying deadlines Experience interfacing and working with business partners at various levels of the organization Demonstrated ability to understand the business functions that the team supports You are self-motivated and can work independently as a member of an Agile scrum team Track record of being detailed oriented; a self-starter having deliverables with minimal defects Must be able to quickly grasp complex concepts and learn new technologies Experience supporting production operations in a high-availability environment Experience interfacing with multiple technology domain partners, including offshore vendor teams and internal groups Must be able to coach and mentor junior members on the team As a developer you will have the following skills and experience: Required Skills: Expert in building and changing Informatica flows using PowerCenter 10.4 and IICS Extensive knowledge of Oracle and pl/sql Expert level of SQL knowledge Expert Data Analysis and profiling Unix Shell Scripting Experience with Cloud based data solutions: GCP (preferred) Expert knowledge of designing Data Warehousing and data integration Plus Skills: Salesforce Data Loader Jira for Agile story and work management Confluence Documentation Control – M Job scheduling software Colorado Compensation Target Total Compensation – $87,600 - $134,300 Your actual pay will be based on your skills and experience - talk with your recruiter to learn more. Why work for us? Own Your Tomorrow embodies everything we do! We are committed to helping our employees ignite their potential and achieve their dreams. Our employees get to play a central role in reinventing a multi-trillion-dollar industry, creating a better, more modern way to build and manage wealth. Benefits: A competitive and flexible package designed to empower you for today and tomorrow. We offer a competitive and flexible package designed to help you make the most of your life at work and at home—today and in the future. Explore further. Schwab is committed to building a diverse and inclusive workplace where everyone feels valued. As an Equal Opportunity Employer, our policy is to provide equal employment opportunities to all employees and applicants without regard to any status that is protected by law. Please click here to see the policy. Schwab is an affirmative action employer, focused on advancing women, racial and ethnic minorities, veterans, and individuals with disabilities in the workplace. If you have a disability and require reasonable accommodations in the application process, contact Human Resources at applicantaccessibility@schwab.com or call 800-275-1281. TD Ameritrade, a subsidiary of Charles Schwab, is an Equal Opportunity Employer. At TD Ameritrade we believe People Matter. We value diversity and believe that it goes beyond all protected classes, thoughts, ideas, and perspectives."
Data Engineer,Arcadia/Urjanet,"Remote in Washington, DC",https://www.indeed.com/rc/clk?jk=1e102a33b0b3b667&fccid=dd616958bd9ddc12&vjs=3,"Who we are Arcadia is the technology company empowering energy innovators and consumers to fight the climate crisis. Our software and APIs are revolutionizing an industry held back by outdated systems and institutions by creating unprecedented access to the data and clean energy needed to make a decarbonized energy grid possible. In 2014, Arcadia set out on its mission to break the fossil fuel monopoly and since then we have been knocking down the institutional barriers to unlock decarbonization. To date, we have connected hundreds of thousands of consumers and small businesses with high-quality clean energy options. Fast forward to today, and now, we're thinking even bigger. We have launched Arc, an industry-defining SaaS platform that empowers developers and energy innovators to deliver their own custom, personalized energy experiences, accelerating the transformation of the industry from an analog energy system into a digitized information network. Tackling one of the world's biggest challenges requires out-of-the-box thinking & diverse perspectives. We're building a team of individuals from different backgrounds, industries, & educational experiences. If you share our passion for ushering in the era of the clean electron, we look forward to learning what you would uniquely bring to Arcadia! What we're looking for We are seeking a Data Engineer to design, develop, and maintain large-scale data applications and pipelines, working closely with the Analytics & Data Science team to improve Arcadia's business through smarter use of data. The role will be hands-on and cross-functional, collaborating across the company to establish and execute the data engineering roadmap. This is an exceptional opportunity for someone who relishes the chance to engage with cutting-edge technology, influence how our team builds and stays relevant, and work in a fast-paced environment with engineers on a high-morale, tightly knit team. Our engineering values are deeply ingrained in our culture- you can read more about them here. Our core data stack makes heavy use of the AWS ecosystem, with pipelines built using both Lambdas and ECS tasks running Python on top of Snowflake or DynamoDB. We lean into modern data orchestration tools, including Prefect and Fivetran. Our customer-facing application stack also includes several Ruby on Rails apps, a GraphQL service layer, and a number of React clients. In your application, please include a link to GitHub or another place where your code is published, though we understand that not everyone has public code online. Arcadia is headquartered in Washington, DC, and open to fully remote candidates. #LI-REMOTE What you'll do: Manage data pipelines from disparate sources, standardizing and feeding them into our centralized data warehouse Work with both the Engineering and Analytics & Data Science teams to optimize data flow and queries for large data sets to improve scalability Sync data across internal and external systems, such as marketing and sales automation tools, to enable key stakeholders to build best-in-class experiences Support ongoing efforts to establish and enforce best practices on data quality, use, and security across the company What will help you succeed: Must-haves: 3+ years combined programming and/or DevOps experience Significant experience with and a strong understanding of languages/tools relevant to engineering & data teams' work Experience in one or more of the following languages: Python, Java, Ruby, Javascript Advanced knowledge of algorithms, data structures, and relational algebra Database management experience with PostgreSQL, RDS, Snowflake, or similar Data extraction experience with a strong understanding of thread-based and event-based paradigms Extensive experience in managing data pipelines, schemas, and storage for multiple systems and for multiple teams Strong communication skills Nice-to-haves: Undergraduate and/or graduate degree in math, statistics, engineering, computer science, or related technical field Experience in predictive modeling and statistical analysis Experience with enterprise database interfaces and messaging APIs Experience with Amazon Web Services (AWS) or other cloud infrastructure platforms Experience with entity resolution at scale Experience in the energy sector Benefits ""Remote first"" culture - work anywhere in the US as long as you have a reliable internet connection Flexible PTO - no accrued hours and no limit on the number of vacation days employees can take each year 15 annual company-wide holidays including a week long ""summer break"" 10 days sick leave Up to 4 weeks bereavement leave 2 volunteer days off 2 professional development days off 12 weeks paid parental leave for all parents Weekly ""flex time"" - no internal meetings on Tuesdays and Friday afternoons 80-95% employer cost coverage for medical, dental, and vision benefits for employees and dependents Annual budget to use on conferences, books, classes, workshops or anything that contributes to professional development Eliminating carbon footprints, eliminating carbon copies. Here at Arcadia, we cultivate diversity, celebrate individuality, and believe unique perspectives are key to our collective success in creating a clean energy future. Arcadia is committed to equal employment opportunity regardless of race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, protected veteran status, or any status protected by applicable federal, state, or local law. While we are currently unable to consider candidates who will require visa sponsorship, we welcome applications from all qualified candidates eligible to work in the United States. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation."
"Data Engineer, Remote",Guardian Life Insurance Company,+1 locationRemote,https://www.indeed.com/rc/clk?jk=17c670b5f0024a64&fccid=64294ff4323ee213&vjs=3,"Data Engineer As our Data Engineer you will be responsible for delivery of data solutions supporting analytic and reporting efforts. Specifically, the position will focus on the creation of data pipelines to optimize the architecture, design, governance, and movement to support self-service BI as well as performing statistical analysis, correlations, etc. Responsibilities include leading, defining, designing, building, testing and maintenance of the AWS data architecture, including ingestion of data from S3 (Hadoop) across various source types – Parquet, csv, text, etc. Responsible for the architecture of the transformation and integration layers utilizing various ETL tools and Redshift to create optimal structures to support centralized usage across BU and analytics. Responsible for helping propagate knowledge across this space to other team members and help to promote standards and best practice definition. You will: Focus on data architecture, design, and delivery of data solutions across the AWS environment Design, implement, and ensure data solutions are built, maintained, and updated based on established business requirements Collaborate with leadership to provide meaningful and credible feedback on data architecture, design, and delivery Work autonomously, in team settings and in partnership with management to review data design and solutions Identify information needed, sources, and use tools to deliver optimal solutions per the use case Partner with IT, Database Administrators, and business owners to ensure all data/data sources needed for reporting and analytics are defined and incorporated into the appropriate data solution Develop, implement, communicate, and maintain automated processes adhering to the deployment and support standards Develop data quality metrics that identify gaps and ensures compliance with standards across the enterprise Lead analysis, estimation, planning and implementation of data solutions Serve as a liaison with functional groups around data and BI. Lead planning and execution of multiple, simultaneous initiatives Conduct business data analysis and design to support effective report development and business decisions Leverage external best in class reporting solutions to support data needs Understand the data ecosystem to support placing data in the correct infrastructure Create the processes to show where and how data should be moved / aggregated once it is landed from source systems into the data lake environment (S3) Create the design and models for combing data across sources for efficient query patterns from BI and analytics Ensure governance standards are followed Review ongoing performance of existing assets and modify if needed Fast-track the use of Redshift and other AWS tools & services across the data lake environment We Offer: Meaningful and challenging work opportunities to accelerate technology and innovation in a secure and compliant way. Competitive compensation Excellent medical, dental, supplemental health, life and vision coverage for you and your dependents with no wait period Life and disability insurance A great 401(k) with match Tuition assistance, paid parental leave and backup family care. Dynamic, modern work environments that promote collaboration and creativity. Flexible time off, dress code, and work location policies to balance your work and life in the ways that suit you best. Social responsibility in all aspects of our work. We volunteer within our local communities, create educational alliances with colleges, drive a variety of initiatives in sustainability, and advocate for diversity & inclusion in all that we do. Primary Location: Remote - United States Other Locations: Job: IT Schedule: Full time Equal Employment Opportunity: Guardian is an equal opportunity employer. All qualified applicants will be considered for employment without regard to age, race, color, creed, religion, sex, affectional or sexual orientation, national origin, ancestry, marital status, disability, military or veteran status, or any other classification protected by applicable law."
Data Engineer | TS(SCI Eligible),Connect Talent Solutions,"Springfield, VA 22150",https://www.indeed.com/rc/clk?jk=373802758471a12b&fccid=78288b9f3d92642b&vjs=3,"Connect Talent Solutions is a fast growing, innovative staffing firm offering direct placement, contract and contract to hire solutions. We are uniquely positioned and experienced to support your requirements from IT and engineering to general labor and customer service positions. At Connect, people are the center of our universe and we go to great lengths to ensure that our customers and candidates have the most enjoyable and informational hiring experience that will encourage and foster fruitful, long term relationships and careers. Job Description: In your role as data engineer, you will be assigned to an agile scrum team that focuses on the development of extract, transform, and load (ETL) jobs currently using Microsoft SQL, Server, and SSIS. The environment currently supports hundreds of related ETL jobs that move data between 30 different source systems and between multiple classifications. Part of the challenge as a data engineer will be to find scalable and efficient coding solutions that plug into this extensible system in order to add more data to the Enterprise data store. The existing data warehouse is built on Microsoft SQL hosted on Amazon Web Services (AWS), so experience developing solutions that scale well in these environments is a plus. Experience with other data ingest pipelines such as NIFI is also desired as this contract is likely to evolve over the next 5 years to keep up with industry best practices. In this role you will work with product owners and data stewards to deliver high quality technical solutions in response to business requirements. You will be counted on to provide your peers with technical expertise that will offer solutions for difficult programming problems. Qualifications Desired Core Skills: SQL Server Integration Services (SSIS) including UI and custom code features. Ability to write or create stored procedures, SQL scripts, SSIS packages that can be used to: o Move data from source databases to target databases o Clean / Condition data o Convert or transform data o Reconcile and confirm converted data o Find data errors o Validate data to business rules o Ability to examine existing ETL scripts and track data back to source SQL Server administration, tuning, and workbench. Ability to work with business experts to understand data and complete data mappings. Preferable Secondary Skills: Data discovery techniques and data wrangling to pull data together from disparate sources. Data Modeling techniques Expertise in operating within an Agile based environment and breaking down large tasks into smaller story/point based tasks. AWS infrastructure functionality and configuration, installation as applies to databases and specifically. Experience in at least one scripting language desirable (PowerShell, Shell, PERL, Python). Expertise in the Design and Deployment of various components as part of SQL to include SQL Server Integration Services, SSIS - (both Scale- Out and non-Scale-Out) Understanding of SSIS ETL jobs including setting up and monitoring job length and performance. SQL Server Reporting Services (SSRS) – Decent to Solid understanding of monitoring the SSRS core database tables with regards to report run- time and slow reporting performance. Connect Talent Solutions is an Equal Opportunity Employer-Minorities/Females/Veterans/Individuals with Disabilities. Individuals with disabilities, including disabled veterans or veterans with service-connected disabilities, are encouraged to apply. Job Location: Springfield, VA"
Data Engineer,"3-GIS, LLC",Remote,https://www.indeed.com/rc/clk?jk=98e742cd48d53468&fccid=cc3ae8f09eb4559b&vjs=3,"Description: The purpose of the Data Engineer is to migrate and convert data from foreign data models into our proprietary 3-GIS data model. In addition to data conversion, the data engineer supports existing 3-GIS accounts with data changes for system corrections and upgrade requirements. Data maintenance tasks will require a good working knowledge of ArcGIS tools, SQL, ArcPy and an ability to navigate a relational data model to update data tables and associated relationships on large spatial tables to perform daily tasks. . Requirements: Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Job Duties: responsible for supporting data migrations and data conversions from disparate systems into the 3-GIS Data Model. oversee data mapping exercises and work closely with customers to understand their data models and to provide mapping between systems. employ a variety of tools including but not limited to Python Scripting, Database Scripting languages such as SQL, advanced knowledge of ESRI applications, FME workbenches and internally developed tools, as the assignment dictates. exhibit strong communication skills to ensure customer understanding of data migrations and conversions and must work with various team members such as Solutions Engineers, Data Technicians, Sales Executives and Project Managers to ensure project success. must be detail oriented and maintain proper time management as projects generally have specific timelines and milestones required for project success ability to provide references for users by writing and maintaining documentation design, develop, and test data transformation, extraction, and migration activities. prepare technical reports by collecting, analyzing, and summarizing information perform tasks efficiently while validating methodology. interact directly (face-to-face and remotely) with clients and project teams provide best practice recommendations during data mapping and project exercises. Collaborate with leadership to improve customer experience Other duties as assigned Qualifications Required Qualifications: You are someone who is motivated by helping other people solve problems. You thrive in a busy environment, and are passionate about providing an outstanding experience for our customers. Bachelor’s Degree in Information Technology or related field 2+ years of experience in data conversion, data mapping, and data analysis 2+ years of experience using ESRI, FME, or a combination of both Intermediate database experience including SQL relationship statements Intermediate Programming/Report Analysis experience Strong organizational skills and attention to detail Experience with issue tracking software (i.e. Jira) Communication skills, both oral and written Deadline driven, ability to work independently as well as a team player Preferred: 1+ year of experience with managed telecommunications databases Proficiency in ticketing support tools like Jira Database troubleshooting experience (including management tools such as SQL Developer, SQL Server Manager, PGAdmin) Experience with Python or similar scripting languages Experience with large databases containing millions of rows per table (Oracle experience prefered) Flexible to work across different US time zones Basic 3-GIS data model or application experience Working conditions This position can operate in a professional office environment or remotely. This role requires routine use of standard office equipment such as computers, phones, and copiers."
Scientific Data Engineer,BASF Corporation,"San Diego, CA 92121 (Torrey Pines area)",https://www.indeed.com/rc/clk?jk=42f186d555109b7f&fccid=38313780e9822361&vjs=3,"We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, age, citizenship, color, religion, sex, marital status, national origin, disability status, gender identity or expression, protected veteran status, or any other characteristic protected by law. Description At BASF, we create chemistry through the power of connected minds. By balancing economic success with environmental protection and social responsibility, we are building a more sustainable future through chemistry. As the world’s leading chemical company, we help our customers in nearly every industry meet the current and future needs of society through science and innovation. We provide a challenging and rewarding work environment with a strong emphasis on process safety, as well as the safety of our employees and the communities we operate in and are always working to form the best team—especially from within, through an emphasis on lifelong learning and development. And we are constantly striving to become an even better place to work. BASF has been recognized by Forbes Magazine as one of America’s Best Employers in 2021. Come join us on our journey to create solutions for a sustainable future! Scientific Data Engineer (2104039) - San Diego Where the Chemistry Happens We are seeking a professional like you to become a member of our interdisciplinary and agile team within our Digitalization unit RB/WIT of White Biotechnology Research. Our mission is to explore and improve enzyme function at molecular level to address real-world problems. Qualifications - BASF recognizes institutions of Higher Education which are accredited by the Council for Higher Education Accreditation or equivalent Formula for success Leveraging your education in Computer Science, Bioinformatics, Computational Biology or Biotechnology with your relevant industry experience, you will closely collaborate with scientists to understand end to end lab workflows and help to abstract these into data models and software processes. Your experience with biological lab processes, Python development, Unix based systems and standard development tooling like Git, CI/CD pipelines, will enable you to develop the scientific software needed by researchers in San Diego and other international sites to simplify their everyday workflow and foster their success. As a self-driven expert with excellent problem solving & communication skills, familiar with Scrum/Kanban teams and bi-weekly sprints, you will work in a full remote environment with international stakeholders, interacting with the scientific team to become an essential component of our in-house app development that you and the team will be leading. You will also be applying your experience with efficient data storage and retrieval in SQL / NoSQL databases. Create Your Own Chemistry: What We Offer You Adding value to our customers begins with adding value to you. You@BASF is the suite of benefits, perks, programs and unique opportunities we offer to support you—the whole you—in all stages of your life and career. With you@BASF, you create your own chemistry. The total rewards that you receive as a BASF employee go way beyond a paycheck. From competitive health and insurance plans, to robust retirement benefits that include company-matching contributions, to making sure you never stop learning, we believe investing in you is investing in our success. Working for a large, global organization, you’ll have a chance to grow professionally and personally, expand your network and build a rewarding and dynamic career. BASF provides interesting and challenging learning and development opportunities to help you make the most of your talents and your job."
Data Engineer,Cru,"Orlando, FL 32832+1 location",https://www.indeed.com/rc/clk?jk=a322d1f576c63527&fccid=cd411fa2d6591efd&vjs=3,"Job Description: Salary: Negotiable Full Time - Location, Orlando, FL -Hybrid (a combination of office and remote work) Cru has a long-standing history of being a pioneer in world Christian Missions. We are looking for the most talented individuals with a passion to see the Gospel of Jesus Christ proclaimed to the nations. Come use your God-given talents to help do this! Our teams are committed to praying for and with each other. Your faith isn’t just something apart from who you are, it's an integral part of you. Here at Cru we want you to use your gifts to further the Kingdom each day. Passion for Data: We're looking for a data engineer who is passionate about data and loves to empower analysts to efficiently create direction-setting dashboards. Are you more concerned with creating solutions instead of just fixing problems? Do you care deeply about things like data quality and data security? What You'll Be Doing: Supporting data analysts, data scientists, and other data consumers by providing them with large, complex, decision-making datasets Creating, scheduling, maintaining, and debugging ETL and ELT processes Data cleansing and data wrangling to prepare structured and unstructured data for various modes of consumption including AI, ML, statistical models, analysis, dashboards, etc. Gathering specific requirements and suggesting solutions Providing mentoring to less senior engineers in coding best practices and problem solving Troubleshooting and debugging Optimizing performance Staying up-to-date with new technology trends Getting Hands-on Training from Senior Team Members Getting Training through Conferences Required Experience: Skills Needed: Proven experience as a Data Engineer Extensive experience working with Enterprise databases and ETL tools Strong technical expertise with complex ETL/ELT flows and data pipelines In-depth knowledge of modern programming languages and platforms like Python, Oracle, BigQuery, Google Cloud Platform, R, SQL, Scala Comprehensive knowledge of Modern Data Warehouse design principles and architecture Proficiency in Data Modeling principles Ability to perform in a team environment and yet work independently Strong project management skills, including the ability to work independently and coordinate and prioritize multiple tasks Excellent oral and written communication Must have a high level of interpersonal skills to handle sensitive/confidential situations and information It is a plus if you also have experience with: Apache Airflow or GCP Composer Geospatial queries Snowplow Must Haves: Deep love for Jesus Christ Deep desire to share the Gospel with the world Willingness to receive and respond to feedback (it's not personal) Living in or willing to relocate to Orlando, Florida BS degree in Computer Science or relevant field High School Diploma From: Cru Benefits: We offer a comprehensive benefits package."
Data Engineer,DUOPEAK,"Menlo Park, CA",https://www.indeed.com/rc/clk?jk=88cc7d1f5293dc3a&fccid=302be7119a491f60&vjs=3,"At DuoPeak we’re a team of passionate and hard-working individuals with a real love for mobile games. We found ourselves enamored with understanding the process of what makes a game successful. Through our combined understanding, we found that the real essence of a successful game comes down to three things: Product, Marketing and Operations. What we’re looking for is the Data Engineer, who will thrive in an environment that is hands on and is always looking for ways to improve and further our business through big data and AI. We are offering a large opportunity for growth. Job Type: Full-time Key Responsibilities: Create and maintain optimal data pipeline architecture. Identify, design, and implement internal data process improvements for security, accuracy, stability and scalability purposes. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, GCS and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipelines to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools and deploy ML models for the analytics/data scientist team members, which will assist them in building and optimizing our product into an innovative industry leader. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. What We're Looking For: Highly analytical, data-driven individuals Detail-oriented and organized people Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience with data processing software (such as Hadoop, Spark, Pig, Hive) , data processing algorithms (MapReduce, Flume) and data pipeline & workflow management tools: Azkaban, Luigi, Airflow, etc. Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience building processes supporting data transformation, data structures, metadata, dependency and workload management. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. A Plus For: Strong project management and organizational skills is a plus Experience supporting and working with cross-functional teams in a dynamic environment. A Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools: Experience with Google or AWS cloud services Experience with stream-processing systems: Storm, Kafka, Spark-Streaming, etc. Benefits: Fully Covered Health insurance Unlimited DTO 401K Snacks (Food/Drinks) Cell Phone Reimbursement"
"Full Stack Engineer, Data Foundations",Spotify,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=193e338a48d0735d&fccid=fe404d18bb9eef1e&vjs=3,"Engineering Backend We are looking for Full Stack Engineers with an interest in Data/Infrastructure development to join one of our core data infrastructure teams that specialize in systems for data management, sharing, and storing of Spotify’s datasets and data resources. As a team we are also looking at data organization, monitoring, alerting, and reliability infrastructure for our data platform. Location New York or Remote Americas Job type Permanent What you'll do: Coordinate technical projects across teams within Spotify Be a valued member of an autonomous, multi-functional agile team Use your experience of full-stack engineering to craft intelligent solutions that include front-end, client, and back-end systems Work with data and backend engineers to architect stable, performant backend solutions Build, automate, maintain, scale, and monitor user-facing systems using best practices, with reliability and scalability in mind Work with the other specialists to debug and fix issues Implement high-quality release engineering practices to facilitate rapid development, safe changes, and engineer efficiency Maintain system architecture documentation and runbooks You’ll collaborate with other engineers, product managers, and designers to identify and tackle complicated problems, creating an awesome engineering experience within Spotify Use industry-standard, cloud-native tech, which means easily transferable skills and a focus on your professional development Take an active part in the operational responsibilities for our own infrastructure Work on what you want during regular hack days and bi-annual hack weeks Who you are: Have experience crafting and building distributed, well designed services in Java You know how to work with large scale data systems Experienced with modern JavaScript (TypeScript is a plus) coding, testing, debugging, and automation techniques Knowledgeable about data modeling, data access, and data storage techniques Are able to work across tech stacks, implementing features end-to-end You have a deep understanding of system design, data structures, and algorithms You care about quality and you know what it means to ship high quality code. Google Cloud Platform experience is a bonus Comfortable working both independently and collaboratively (pairing and mobbing) As a phenomenal influencer with great communication skills, you love sharing your knowledge with others and helping them grow Where you'll be: We are a distributed workforce enabling our band members to find a work mode that is best for them! Where in the world? For this role, it can be within the Americas region in which we have a work location and is within working hours. Working hours? We operate within the Eastern Standard time zone for collaboration and ask that all be located that time zone. Prefer an office to work from home instead? Not a problem! We have plenty of options for your working preferences. Find more information about our Work From Anywhere options here. Our global benefits Extensive learning opportunities, through our dedicated team, GreenHouse. Flexible share incentives letting you choose how you share in our success. Global parental leave, six months off - fully paid - for all new parents. All The Feels, our employee assistance program and self-care hub. Flexible public holidays, swap days off according to your values and beliefs. Spotify On Tour, join your colleagues on trips to industry festivals and events. Learn about life at Spotify Spotify is an equal opportunity employer. You are welcome at Spotify for who you are, no matter where you come from, what you look like, or what’s playing in your headphones. Our platform is for everyone, and so is our workplace. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be forward-thinking! So bring us your personal experience, your perspectives, and your background. It’s in our differences that we will find the power to keep revolutionizing the way the world listens. Spotify transformed music listening forever when we launched in 2008. Our mission is to unlock the potential of human creativity by giving a million creative artists the opportunity to live off their art and billions of fans the chance to enjoy and be passionate about these creators. Everything we do is driven by our love for music and podcasting. Today, we are the world’s most popular audio streaming subscription service with a community of more than 381 million users. Global COVID and Vaccination Disclosure Spotify is committed to safety and well-being of our employees, vendors and clients. We are following regional guidelines mandating vaccination and testing requirements, including those requiring vaccinations and testing for in-person roles and event attendance. For the US, we have mandated that all employees and contractors be fully vaccinated in order to work in our offices and externally with any third-parties. For all other locations, we strongly encourage our employees to get vaccinated and also follow local COVID and safety protocols. This role is not eligible for hire in Colorado, USA."
Data Engineer III,WW International,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=949c5e615c86b99c&fccid=dd616958bd9ddc12&vjs=3,"WW is looking for candidates to help change people’s lives. We are a global wellness technology company inspiring millions of people to adopt healthy habits for real life. We do this through engaging digital experiences, face-to-face workshops and sustainable programs that encourage people to move more, shift their mindset and eat healthier while enjoying the foods they love. By drawing on over five decades of experience and expertise in behavioral science, we build communities in order to deliver wellness for all. Department Overview: At WW, we are re-imagining engineering in and around our data infrastructure, architecture, pipeline, flow and security. We are building a modern data lake fed by batch and streaming pipelines creating incremental value from our data. We are implementing a data catalog, glossary and dictionary solution to make our data search and discoverable, propelling data democratization, enhancing data quality and data security. We are reimagining and replacing old data pipelines with modern architecture and technologies. It’s an exciting time for WW Data Org and Data Engineering is driving the excitement. If you would like to be part of this exciting journey, help build our modern data engineering solutions and set yourself up for an impressive learning and career growth potential, we have an opportunity for you. So if you feel passionate and excited to design and build data engineering solutions on Google Cloud Platform (GCP), we should connect Role Overview: Python/Java programing to implement data engineering solutions Data Engineering problem solving Opportunity to work on GCP, AWS cloud technologies + Kafka, Metadata Management tool, Data Quality (DQ) tool, Open Source tools, Cloud-Native solution, Dev/Ops and Data Science related work Work with high volume (100s TB), high velocity (real-time stream), high complexity (heterogeneous) data from hundreds of sources e.g. social media, click stream, e-commerce etc. Requirements: 3-4 years hands-on experience in application / data pipeline development with Java and Python programing language(s) Strong in SQL query, data manipulation language (DML) and data definition language (DDL) including hands-on experience of managing database tables and views Experienced in designing and implementing end-to-end data pipeline on at least one of top three cloud providers (AWS, Azure, GCP) Desired: Solid understanding of fundamental architecture and working principle of relational databases, NoSQL databases, massively parallel processing (MPP) databases, distributed processing frameworks (MapReduce/Spark/Beam etc.), messaging/streaming platforms (e.g. Kafka, Google Pub/Sub, Kinesis) Excellent work ethic, positive attitude to work and good verbal communication Possess excellent work ethic, positive attitude to work and good verbal communication Degree in Computer Science, IT, or similar field; a Master’s is a plus Data engineering certification (e.g Google Cloud Certified Data Engineer, AWS Certified Big Data Specialty) is a plus #LI-Remote At WW, it is our priority to cultivate a diverse and inclusive workplace. We are committed as individuals, as an organization, and as fellow humans, to advocate for and support our employees, our members, and our communities. We are proud to be an equal opportunity employer and we do not discriminate on the basis of sex, race, color, creed, national origin, marital status, age, religion, sexual orientation, gender identity, gender expression, veteran status, or disability."
GMD Data Analysis and Systems Engineer,Northrop Grumman,"Remote in Chandler, AZ 85286+2 locations",https://www.indeed.com/rc/clk?jk=59ed406e4ae01db0&fccid=11619ce0d3c2c733&vjs=3,"Requisition ID: R10047630 Category: Engineering Location: Chandler, Arizona, United States of America Citizenship Required: United States Citizenship Clearance Type: Secret Telecommute: Yes-May consider hybrid teleworking for this position Shift: Days (United States of America) Travel Required: Yes, 10% of the Time Positions Available: 1 At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history. Northrop Grumman Space Systems is currently seeking a Systems Engineer to join our Systems Engineering Integration & Test team to support the GMD (Ground-based Midcourse Defense) program within Launch Vehicles business unit in Chandler, AZ Role description & Responsibilities: The Data Analysis and Systems Engineer is part of the GMD Boost Vehicle team within SEIT. Tasking will include one or more of the following activities: perform review and analysis of rocket telemetry and simulation test data; identify and analyze anomalous data to determine root cause; support trend analysis of collected rocket data to determine aging and other environmental effects; support customer field site ground- and flight-testing operations, including test execution support and on-site data review. Additionally, this position may help update legacy analysis software to include feature enhancements and processing efficiency improvements. Additional tasking may include more traditional systems engineering efforts including requirements documentation and verification of requirements, using DOORS as the requirements management software. Required Experience: Bachelors Degree (BA/BS) in Engineering or related field with 2 years of related experience; Masters degree plus 0 years of experience Ability to obtain a Security clearance (SECRET or higher) which requires US Citizenship Ability to work in a team environment Strong written and verbal communication skills Ability to solve problems Ability to work in a fast paced environment and multi-task Ability to travel (approximately 10%) to test venues Preferred Experience: 4 years of systems engineering experience is preferred Current SECRET or higher clearance Working in a combined Linux/Window OS environment Coding experience in any of the following: MATLAB, Python, Visual Basic Familiarity with Telemetry Systems Systems Engineering experience Salary Range: $71,100 USD - $106,700 USD Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business. The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/. Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions."
Data Engineer,Virtusa,"Irving, TX 75061 (Plymouth Park area)+5 locations",https://www.indeed.com/rc/clk?jk=5fcf9164c8d240fc&fccid=146443e77d8c0778&vjs=3,"Detailed Job Description: 3-5 years of experience in IT Industry Extensive development using Java Spark, Big Data technologies. Hands on Experience in Big Data technologies Hadoop, Spark, NoSQL Understanding Business Requirements and Functional Requirements and Involved with implementation of end to end solutions, Design and build scalable infrastructure and platform to ingest, store and process very large amount of data, Collaborate with various data source teams on effective strategies for data ingestion, Experience in Agile SDLC, JIRA, Bitbucket or Git is a PLUS, SQL knowledge and fine query fine tuning capabilities are is a PLUS, Knowledge of database design techniques and experience working with extremely large data volumes is a PLUS Primary Location : US-TX-Irving Schedule : Full Time Employee Status : Executive Job Type : Experienced Travel : No Job Posting : 17/06/2022, 3:59:42 PM"
Data Engineer,LivCor,Remote in United States,https://www.indeed.com/rc/clk?jk=f1e0b4a5bc1ddc3f&fccid=3f1dd1e53506f3cf&vjs=3,"Overview: LivCor, a Blackstone portfolio company, is a real estate asset management business specializing in multi-family housing. Formed in 2013 and headquartered in Chicago, LivCor is currently responsible for a portfolio of over 400 Class A and B properties comprising more than 150,000 units in markets across the United States. Our business is focused on making real estate more valuable. But for us, it’s more than that. It’s people first, community always. It’s a life-filled career, not just a career-filled life. It’s doing good work, with good humans, and making a difference. It’s excellence in all its forms. Ultimately, we create great places to work, live, and grow. We do that by focusing on leaving people – and places – better than we found them. Whew! Still with us? Cool. Let’s talk about where you’d fit in: As a Data Engineer, you’re an artist. You will bring the business needs to life through beautifully crafted and well-thought-out solutions. You are a carpenter, building the scaffolding of the data workflows. You are a geek, always tinkering and making “cool” things. Above all, you are an engineer with the detail and precision often attributed to that title. You are an amazing, well-rounded individual and not “just a coder” who wants to be in a room being fed Mountain Dew and Twinkies under the door (not that we have anything against Mountain Dew or Twinkies, and we’d at least fully open the door to bring them to you). If this sounds like you and you want to be with amazing people, then we are looking for you. LivCor has a Data Engineer position who will design and develop data platforms, ingestions, and solutions for our ever-growing array of stakeholders. They will work across departments, ingesting raw data, integrating 3rd party systems, and expanding our data ecosystem. Only read further if you are: Kind Humble Honest Relentless Smart with Heart You should be: Authentic. You do you. Together, we’ll do something amazing. A passionate person with a love for real estate and investing; and believes that helping others win is a noble cause, essential to our success. An excellent team player who enjoys working with others and has strong interpersonal skills. Highly motivated, energetic, and organized Gumby. Things change. Responsibilities: What you will do: Responsible for delivering data warehouse and analytic solutions by ingesting, integrating, and curating data Builds analytical solutions and administers systems Create and maintain optimal data pipeline architecture. Our data must be woven into the fabric of our business Assemble large, complex data sets that meet functional…and sometimes non-functional business requirements Must believe that the health of a business is directly relatable to good, clean data; just like the health of the body is relatable to clean air and water Serve as a functional and content expert of the data warehouse to synthesize raw data into actionable information to be used in analytical solutions Communicating with stakeholders on project process and alignment. Must be as comfortable in a board room as you are in a data war room Developing integrated data solutions, modernizing, consolidating, and coordinating business needs across several applications Performance Tuning and Optimization of all Data Ingestion and Data Integration processes, including the Data Platform and databases Support Data Analyst and Business Stakeholder in analyzing and resolving any data issues as required. Make effective and decisive decisions when presented with multiple options for how to progress with any project Qualifications: What you should have: 3+ years hands-on with Python or related programming language. 3+ years hands-on experience as a Data Integration engineer or Software Developer 3+ years hands-on technical experience with ETL Tools BI Reports and Dashboards Understanding of data Schema modeling (Dimensions, Measures, Slowly Changing Dimension) 3+ years with SQL or NoSQL databases and data warehousing technologies. Understanding of cloud-based architecture. (AWS/Azure/GCP) Experience with Snowflake/Azure Databricks/Azure Data Factory is a big plus. Bachelor's degree or School of Hard Knocks Strong communication skills, with the ability to initiate and drive projects proactively and accurately with a large, diverse team An overwhelming desire to learn new things and to help people succeed What we offer: We know that if we take care of our team everything else will fall into place. We aren’t perfect, but we will try to set very clear expectations, always let you know where you stand, and do everything in our power to help you get where you want to go. Our culture and values matter to us. A lot. We’re definitely not serious but we take this stuff seriously, if you get what we mean. We want a place that is an ego-free zone. A place where good people do good things together and for the right reasons. It shouldn’t be rocket science in workplaces, but for some reason it still is? We’re absolutely determined to be different, and we think we’re doing a pretty good job at it. We have a CEO who makes fun of himself, and who will encourage you to tell him when he is wrong. In fact, he needs people to – we all do. Supportive challenge is good, it’s how we get better. We like getting better. We also love diversity, of all kinds. We need people who look, sound, speak, love, and exist differently from one another. This isn’t at the end of this paragraph because it’s an afterthought. It’s SO important to us we want it to stand out. Right. On to the technical stuff that we know matters to you. We offer competitive pay that is commensurate with the market and relevant experience, and a full slate of benefits that even includes things like paid parental leave. If any of this sounds interesting, then maybe we are a fit. Life is too short to work with people you don’t like. So whatever you do, don’t make that mistake. In compliance with the Colorado Equal Pay for Equal Work Act, the salary range for this position is $131,100 - $149,500 (for candidates that reside in CO). This role is bonus eligible. Benefits include generous health insurance and wellness benefits, 401(k), and paid time off. The LivCorian Values Be you. Be Real. Be Open. You do you. Together, we will do something amazing. Care, Always. We don’t want to let anyone down. Courageously Curious. We love to learn, even when it hurts. Help Others Win, Be A Good Neighbor. This is about ‘We, not Me.’ Relentless Hustle, Heart & Humility. Work hard. Be Kind. Make Better. A few of the people you will work with: Nathan Kimpel Elif Efeoglu Paul Hernacki Matt Lomas Deepa Rao Brian Chan Nick Fotopoulos Don Pochron Paul Stec LivCor is proud to be a US EPA ENERGY STAR® Partner EEO Statement Our company is proud to be an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. Our employment decisions are based on individual qualifications, job requirements and business needs without regard to race, color, marital status, sex, sexual orientation, gender identity and/or expression, age, religion, disability, citizenship status, national origin, pregnancy, veteran status and or any other legally protected characteristics. We are committed to providing reasonable accommodations, if you need an accommodation to complete the application process, please email talent@revantage.com. #LI-Remote #LI-DB1"
Senior Data Engineer,CPSI,Remote,https://www.indeed.com/company/CPSI/jobs/Senior-Data-Engineer-88fc7c5f70134086?fccid=b96ae80ac6a0c574&vjs=3,"As a Senior Data Engineer you will work on an Agile team that is digitally enabling the company by building data pipelines that drive analytic solutions. These solutions will generate insights from the connected data, enabling the organization to advance the data-driven decision-making capabilities of the enterprise. This role requires deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows. The ideal candidate is a skilled data and software engineer with experience creating data products supporting analytic solutions. What you'll do: Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals Solve complex data problems to deliver insights that helps the organization's business Create data products for analytics and data scientist team members to improve their productivity Advise, consult, mentor and coach other data and analytic professionals on data standards and practices Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering to improve the organization's productivity as a team Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives. Requirements What You Will Need to be Qualified: Bachelor's degree in a quantitative discipline such as Computer Science, MIS or related field with 5 years of related experience. 5 years' data engineering experience. 3 years' experience with cloud technology at the enterprise level for data and analytics. Experience using Azure Data Factory, Azure SQL, Azure Data Lake Storage, Azure Databricks & Azure Synapse Strong experience in SQL, including query tuning. Strong understanding of algorithms and data structures, and when to apply them. Demonstrated understanding of Business Intelligence and Report Modeling, with preference for PowerBI experience. Job Type: Full-time Benefits: 401(k) 401(k) matching Dental insurance Flexible spending account Health insurance Health savings account Life insurance Paid time off Parental leave Vision insurance Schedule: 8 hour shift Work Location: Remote"
Cloud Data Engineer,Formlabs,"Somerville, MA",https://www.indeed.com/rc/clk?jk=8fb380c13e31a9f9&fccid=8e0192a48bd27a99&vjs=3,"To reinvent an industry, you have to build the best team. Join Formlabs if you want to bring ground-breaking professional 3D printers to the desktop of every designer, engineer, researcher, and artist in the world. As one of our first dedicated cloud data engineers to help build our data team you will be architecting cloud infrastructure for data-intensive applications involving large scale 3D printing operations with tens of thousands of 3D printers. You will get to work closely with our Software and Data Analytics teams to develop, deploy and maintain large scale real-time data pipelines, infrastructure and tooling that make data accessible to our teams, tools and products. If you're excited to design data pipelines to help Formlabs make better printers, we want you to join the Software Engineering Team as a Cloud Data Engineer. The Job: Build and maintain scaleable, reliable data infrastructure and tooling to support our engineers, products and customers Architect and develop large scale data processing pipelines and ETL tools Protect data for us and our customers We value diversity at Formlabs, and work to remove unconscious and unnecessary barriers to build the best team possible. While we've outlined what an ideal candidate could look like, we know that you may bring something unanticipated and essential to the team. If you're reading this and can see yourself contributing, please apply! You: Ready to collaborate with a wide range of technical disciplines, including Software, Hardware, and Design teams Has developed and deployed large scale real-time data pipelines and ETL tooling in production for a variety of applications Expert in performant, scalable data warehousing, data modeling and database design Experience with observability / APM for tens of thousands of hosts Comfortable with web service providers like AWS or GCE Familiar with CI/CD pipelines, infrastructure as code and container orchestration Familiar with microservice architecture and REST API design Fluent in Python and/or golang Bonus Points: Experience doing data analysis Experience working with hardware sensor data Experience with predictive models Our Perks: Flexible vacation Premium healthcare coverage Paid parental leave Commuter benefits Unlimited 3D prints We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Data Warehouse Engineer (Remote worker opportunity),BAE Systems,"Remote in Charlotte, NC 28277+1 location",https://www.indeed.com/rc/clk?jk=c994dcfa0bbe104d&fccid=bae098e9666bd225&vjs=3,"The successful candidate will be a part of the team that is responsible for Enterprise Data Warehouse. This position requires the candidate understands and applies technical standards, principles, theories, concepts, techniques and provides solutions to a variety of technical problems of moderate to high scope and complexity. The candidate develops deep knowledge and understanding of the data warehouse and data management assets available within our data platforms and act as the subject matter expert on the data and its utility for operational use. The candidate will regularly interact with the customers, data management teammates, and product development partners, your expertise in large volume data in data lakes, data warehouses, or data marts using structured, semi-structured, and unstructured formats - will deliver on the BAE’s Data and Analytics organization’s mission to enable data-driven decisions within any action. The candidate will follow established procedures, and contribute to the completion of milestones associated with specific projects and keep up-to-date with the technology shifts through training and development. Required Education, Experience, & Skills Bachelor’s Degree in Computer Science, Information Systems or similar 6+ years of Data Warehousing and Data Modeling experience. 10+ years preferred. Strong understanding of Normalized/Dimensional model disciplines and similar data warehousing techniques. Strong experience working with ETL/ELT concepts of data integration, consolidation, enrichment, and aggregation in large volume data sets. Expert in SQL and/or SQL-based languages and performance tuning of SQL queries. Working knowledge of Data Pipelines, stream processing and highly scalable ‘big data’ data stores. Experience with various data storage technologies - e.g. RDBMS (Oracle, SQL Server, etc.), columnar, tabular, document store, NoSQL Experience with various ETL/ ETL tools – e.g. ODI, SSIS, Informatica Power Center, Talend, IICS, etc. Experience with cloud-based data warehouses - e.g. Snowflake, BigQuery, Azure Synapse, RedShift, etc Create supporting documentation, such as metadata and diagrams of entity relationships, business processes, and process flow. Collaborate with business users on normalizing and aggregating large data sets based on business needs and requirements. Data validation skills to verify data integrity, understand discrepancies, and resolve them with the highest sense of urgency. Demonstrated ability to share findings with non-technical or business stakeholders. Familiarity with Analytical/Reporting Solutions like Tableau, Power BI is a plus Virtual team collaboration tools such as WebEx, Zoom etc. Excellent written, verbal communication and Interpersonal skills Excellent problem solving skills Soft Skills: Work individually and in a matrix environment Work creatively and analytically in a problem-solving environment Communicate (written and oral) effectively and demonstrate professional interpersonal skills Interact professionally with clients and vendors Build positive working relationships with employees at all levels within the organization Meet deadlines as necessary Effectively work with minimal supervision “Can-do” attitude, pro-active and resourceful Preferred Education, Experience, & Skills 10+ years experience preferred. Knowledge of CI/CD pipeline. Experience with scripting languages – e.g. PowerShell, Python, etc. About BAE Systems, Inc. BAE Systems, Inc. is the U.S. subsidiary of BAE Systems plc, an international defense, aerospace and security company which delivers a full range of products and services for air, land and naval forces, as well as advanced electronics, security, information technology solutions and customer support services. Improving the future and protecting lives is an ambitious mission, but it’s what we do at BAE Systems. Working here means using your passion and ingenuity where it counts – defending national security with breakthrough technology, superior products, and intelligence solutions. As you develop the latest technology and defend national security, you will continually hone your skills on a team—making a big impact on a global scale. At BAE Systems, you’ll find a rewarding career that truly makes a difference. At BAE Systems, we celebrate the array of skills, experiences, and perspectives our employees bring to the table. For us, differences are a source of strength. We’re laser-focused on high performance, and we work hard every day to nurture an inclusive culture where all employees can innovate and thrive. Here, you will not only build your career, but you will also enjoy work-life balance, uncover new experiences, and collaborate with passionate colleagues."
Data Engineer,Palni,"McKinney, TX 75070",https://www.indeed.com/rc/clk?jk=0e94ecccb531e180&fccid=20c0d4a444a9e0b7&vjs=3,"Mckinney, Texas Palni, Inc. is currently seeking a Data Engineer. Responsibilities Work extensively on Power BI/associated tools to build reports and share across the organization. Migrate data from an enterprise data warehouse to Snowflake using Snowpipe and other ETL tools. Maintain existing EDW MDX and tabular cubes and create data modelling/architecture in Snowflake. Building custom apps using the Power Platform (other tools in the Power BI suite, including Report Builder ) Work on back-end SQL queries to pull data in to Power BI as sources. Desired Candidate Profile This position requires, at a minimum, Bachelor’s degree in Computer science, computer information systems, information technology, or a combination of education and experience equating to the U.S. the equivalent of a Bachelor’s degree in one of the aforementioned subjects. Note: Email resumes to 8951 Collin McKinney Pkwy, Unit 1101, McKinney, TX 75070 (or) or e-mail:jobs@palniinc.com"
Data Engineer,sharethrough,"Denver, CO+4 locations",https://www.indeed.com/rc/clk?jk=9d1453c834748bfa&fccid=420b591004b16413&vjs=3,"Sharethrough is disrupting the legacy digital advertising supply chain as the first ad exchange to auto-enhance every standard impression by rendering a higher-performing ad that dynamically fits into any placement on any site. Our technology and approach enables advertisers to see substantial campaign performance improvements and cost savings using the same standard video and display creative as well as the buying workflow they use with standard exchanges. The Sharethrough Exchange (STX) powers over 225 billion monthly impressions and is integrated with more than 30 of the world's largest demand side platforms, enabling buyers to efficiently achieve their marketing objectives at scale. We believe that access to an independent and open Internet is a critical human right. By building a sustainable advertising ecosystem for journalists, content creators, and app developers, we can help them and their users thrive. We are looking for Engineers to join our growing Data Engineering team who are thrilled by the complicated data challenges the advertising space offers. You’ll be using a very large database (petabytes of event data in Snowflake) that is clean, flexible, and fast. Our robust Airflow ETL system provides high levels of data integrity. Sharethrough operates in a quickly changing business environment, with plenty of challenges at the ground level. About the Role Ensure that our Looker implementation and Snowflake data warehouse work well together Use your master SQL skills to craft robust, accurate and sustainable data solutions Drive data modeling and data structure design Become a go-to expert around internal company data and SQL Although this position is not about keeping our data pipeline running, you will be writing Airflow ETLs About You 3-5 years in a data engineer or SQL-heavy data analyst role Expert level SQL and interpretation of query execution plans ETL and big data pipeline experience General understanding or interest in Looker architecture and its SQL generation Experience with data warehousing architecture and data modeling Experience and good understanding of AWS stack Python experience What's In It For You? Competitive compensation packages Generous group health insurance plan Access to the virtual healthcare platform Access to the company's stock option plan 16 days of vacation per year, which increases with seniority at the company 3 paid Caring days 1 paid volunteer day Offices closed during the holidays Wellness allocation of $840 per year (for gym memberships, sportswear, etc.) In-house training programs on our company and industry Encouragement and funding of continuing education and training Very active social committee and free online sports classes Access to a tool that measures your engagement and job satisfaction anonymously Pairing with a buddy for your first 6 months Advantageous referral program Inclusive, inspiring, and dynamic work environment Casual dress code Work from home and flexible hours And more!"
Data Engineer,Super73,Remote,https://www.indeed.com/rc/clk?jk=88f66357b95ae19c&fccid=6e3384591a3b1fb0&vjs=3,"Born from the desire to create adventure and community, SUPER73 is an American lifestyle adventure brand fusing motorcycle heritage and youth culture. We are a group of creators, adventurers, builders, thinkers, innovators, dreamers, and most importantly, doers who believe that the whole of our efforts far outweigh the sum of our parts. This is not for the faint of heart. We work hard, we move fast, and we are on a mission. For us, this is not a job, this is an opportunity to merge passion and career to compete in a new emerging global industry. ABOUT THE ROLE SUPER73 is hiring a Data Engineer to work remotely in the US (EST preferred) The purpose of this position is to integrate the various enterprise applications within the organization by creating and maintaining data pipelines, ETL workflows, and reports. You are passionate about all things data. The ideal candidate has a strong analytical and problem solving skills. Focused on developing high quality, robust, extendable and secure date. You are a highly motivated team player and are able to build partnerships with all the stakeholders. WHAT YOU’LL DO This role serves the critical function of integrating the data from our enterprise applications and other related systems and turning them into useful insights Build data pipelines to integrate enterprise apps/ ERP data and move it to our operational data store and data warehouse Integrate data flows between enterprise applications and build reports for data reconciliation and exception handling Support, maintain, and enhance our operational data models and ensure reliability and availability of the system Partner across business units and tech teams to understand business requirements and convert them into data solutions aligned with our enterprise architecture and business objectives Determine and communicate the technical design to the development team and be responsible for the timed and quality delivery of the data solutions Work with the enterprise application leadership to determine data strategy, document data engineering processes and align processes to industry best practices WHAT WE’RE LOOKING FOR 5+ years of software or data engineering experience Strong SQL skills High proficiency in python: ability to write scripts for ETL workflows, make API calls, create Lambda functions etc. Experience with the AWS ecosystem related to data ingestion, data storage, and reporting (Lambda, glue, kinesis, s3, redshift etc.) Knowledge of middleware solution like MuleSoft a plus Experienced in dash-boarding tools like Tableau etc. a plus SUPER73’S PERKS AND BENEFITS Full-time positions Employee bike and apparel discounts Fully stocked kitchen (free snacks, drinks, and coffee) Medical/Dental/Vision/Life Insurance Vacation/Sick Time off 401K Retirement Savings Program with a highly competitive company Match Amazing culture and a great place to work SUPER73 provides equal employment opportunities for all applicants and employees. All qualified applicants will be considered regardless of an individual’s race, color, sex, gender identity or expression, religion, age, national origin, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, military or veteran status, or any other basis protected by federal, state or local laws. All employment is decided on the basis of qualifications, merit, and business need. We're a fast growing company looking for progress-driven and forward thinking individuals that are all about shaking up industry standards. SUPER73 is proud to promote equity in all aspects of our hiring practice and company operation. For more information, we invite you to visit eeoc.gov."
Data Engineer,Instec Corp,Remote,https://www.indeed.com/rc/clk?jk=77625ede0d52469a&fccid=8232d107052198ba&vjs=3,"Description Who We Are Insurity is a leading property and casualty insurance software and data analytics provider, working with some of the world’s largest insurers, brokers, and MGAs, including 15 of the top 25 P&C carriers in the US. With 1400+ team members globally, 7 office locations, and 300+ customers, we have a deep understanding of the insurance business, unparalleled technology expertise, and a singular focus of delivering a simplified insurance experience to our customers. Insurity’s next Data Engineer This position will be part of a team whose primary responsibilities are working with data from our customers. Responsibilities include identifying, acquiring, validating, cleansing, and producing data and datasets to be used in advanced analytics and predictive modeling initiatives by our internal teams. This is accomplished by combining data processing experience with software engineering concepts into solutions that are hosted in our cloud-based platforms. This role will report into the Director of Data Development What You’ll Do Data imports/extraction, transformation, and cleansing Collaborating with data scientists, software engineers, product managers, subject matter experts and customers Managing and maintaining metadata Performance optimization: e.g. approaches to speed up lookups on extra-large datasets Identify opportunities for efficiencies by automating repetitive tasks and process workflows Documentation of processes and requirements Manage and facilitate projects from start to finish Who You Are 2+ years Data Engineering experience with TSQL, Python, or functional programming Bachelor’s degree in Computer Science, Programming, or related technical areas Experience with AWS services including S3 and Lambda Reporting/data warehousing experience Experience with Snowflake a plus JSON, XML and CSV and varying file format data experience Knowledge of insurance concepts is an advantage in understanding our business requirements Self-starter and ability to grasp concepts quickly Ability to work well in a team environment, while also having the ability to work autonomously Passion for continuous learning and digging into the fine details Our Benefits Collaborative Culture | Flexible Hours | Growth Opportunities Day 1 Health Insurance Coverage | Open PTO Does Insurity sound like the right place for you? Send us your application and a cover letter highlighting what sets you apart from the nice-to-haves and makes you a must-have for our team! Thank you for your interest in Insurity! Please understand that due to the volume of applicants we receive, only selected candidates will be contacted. Insurity is proud to be an Equal Opportunity Employer We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. #LI-REMOTE"
Senior Data Engineer,Capital One - US,"Plano, TX+57 locations",https://www.indeed.com/rc/clk?jk=22a9f12ee9648c4c&fccid=b85c5070c3d3d8c8&vjs=3,"Plano 6 (31066), United States of America, Plano, Texas Senior Data Engineer Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. What You’ll Do: Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake Utilize Kafka based frameworks to build resilient data pipelines Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance Partner with business teams to automate business processes, build visualizations and provide real time business insights to improve their business performance Basic Qualifications: Bachelor’s Degree At least 4 years of experience in application development (Internship experience does not apply) At least 1 year of experience in big data technologies Preferred Qualifications: 5+ years of experience in application development including Python, SQL, Scala, or Java 2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) 3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL) 2+ year experience working on real-time data and streaming applications 2+ years of experience with NoSQL implementation (Mongo, Cassandra) 2+ years of data warehousing experience (Redshift or Snowflake) 3+ years of experience with UNIX/Linux including basic commands and shell scripting 2+ years of experience with Agile engineering practices 2+ years of experience with visualization tools like Tableau, Quicksight, Thoughtspot etc. At this time, Capital One will not sponsor a new applicant for employment authorization for this position. No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC)."
Junior/Mid-level Software Engineer - Data Engineering,The Trade Desk,"Irvine, CA 92618 (Irvine Health and Science Complex area)",https://www.indeed.com/rc/clk?jk=f50102f65d8c7d73&fccid=4899a85209d20142&vjs=3,"The Trade Desk is a global technology company with a mission to create a better, more open Internet for everyone through principled, intelligent advertising. Handling over 600 billion queries per day (more than 100X the query volume of search globally), our platform operates at unprecedented scale. We have also built something even stronger and more valuable: an award-winning culture based on trust, empathy, collaboration, and ownership. By working together across typical dividing lines, we are better as a team than any of us could be apart. Do you have a passion for solving hard problems at scale? Are you eager to join a trust-based, globally-connected team, where your contributions will make a meaningful difference? Come and see why Fortune Magazine consistently ranks The Trade Desk among best small-medium sized workplaces globally. About the Role: Our Data Engineering Software Engineers are end-to-end owners. You will participate actively in all aspects of designing, building, and delivering data products for our clients. You will work with petabyte-scale data challenges, large-scale distributed systems coordinating thousands of servers in cloud and physical data centers around the world, machine learning, and advanced visualizations – to name a few. You will work with data processing pipelines, ML pipelines, data processing automation, data governance, data visualization, data quality, data privacy, data warehousing. Our Software Engineers work with a variety of platforms and technologies, such as Docker, Kubernetes, Gitlab, Bamboo, AWS, Azure, Scala, Spark, SQL Server, and Vertica. Who We Are Looking For: You understand engineering and computer science fundamentals. At our scale, many off-the-shelf techniques and existing technologies (open source and enterprise) simply don't work. You are able to work from first principles to evaluate solutions and adapt them to a unique environment. You are passionate about data engineering. You'll work at petabyte-scale with SQL, ETL, data modeling, and technologies similar to Spark, Scala, C#, Java, etc.. You are a creative thinker, not bound by ""the way things have always been done"". What you know is less important than how well you learn and innovate. We don't need engineers who know all the answers; we need engineers who can invent the answers no one has thought of yet, to the questions yet to be asked. What We Care About: What and how you can contribute is what’s important to us. Our consideration is not limited by the kind of education you have or the specific technologies you have experience with. Variety of technical challenge is one of the best things about working at The Trade Desk as an engineer, but we do not expect you to know every technology we use when you start. What we care about is that you can learn quickly and solve complex problems using the best tools for the job. Our culture runs much deeper than just having fun together (though, we do that well too...) – the people we want on our team are trust-builders, generous givers, scrappy problem solvers, and gritty pursuers of excellence. Does this sound like you? If so, we welcome your application and the chance to meet you. #LI-RE1 Our Compensation and Benefits (for Colorado residents only) Base Compensation Range: $95,800 - $191,600 In accordance with Colorado law, the range provided is The Trade Desk’s reasonable estimate of the base compensation for this role. The actual amount may be higher or lower, based on non-discriminatory factors such as experience, knowledge, skills and abilities. The Trade Desk also offers a competitive benefits package. Click here to learn more. The Trade Desk does not accept unsolicited resumes from search firm recruiters. Fees will not be paid in the event a candidate submitted by a recruiter without an agreement in place is hired; such resumes will be deemed the sole property of The Trade Desk. The Trade Desk is an equal opportunity employer. All aspects of employment will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law."
Data Engineer,Midcentral Management Resources Llc,"Oklahoma City, OK 73102 (Automobile Alley area)",https://www.indeed.com/rc/clk?jk=86131739402d2461&fccid=c4897298d2ad0d91&vjs=3,"Position Summary: The Data Engineer is responsible for building and maintaining databases, data pipelines and data warehouses. This position will construct data pipelines to transform raw, unstructured data into a functional format for the organization. Aligning data systems with organizational goals to further support MidCentral Energys mission and values. Essential Functions: Prepares big data, implements data models, and develops database Performs root cause analysis on external and internal processes and data to help identify opportunities for improvement Builds processes to support workload management, data transformation and data structures Optimizes data delivery and re-design infrastructure for greater scalability Conducts statistical analyses to develop strategies Builds predictive models and machine-learning algorithms Proposes solutions and strategies to organizational challenges Presents information and reports using data visualization techniques Documents all processes and research Collects data through analyzing business results or by implementing and managing new studies Create tools and processes to automate data collection Interprets results from multiple sources using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining independently Designs, develops, and implements the most valuable solutions for the organization Non-essential Functions: Other duties as assigned Knowledge, Skills, and Abilities (KSAs) for Position: An employee in this class must have the following knowledge, skills, and abilities upon application: Knowledge Policies, practices, and procedures of MidCentral Energy Adhere to Health, Safety, and Environmental (HSE) procedures and guidelines Principles of customer service Business and management principles involved in strategic planning, resource allocation, leadership technique, production methods, and coordination of people and resources Economic and accounting principles and practices, the financial markets, banking and the analysis and reporting of financial data Utilization of business intelligence tools and data frameworks Data analytics, clustering, architecture, cleansing, management, mining, visualization, and modeling Skills Excellent analytical skills with working on unstructured data Strong math skills Excellent interpersonal and communication skills Excellent management and supervisory skills Excellent organizational skills and time management Product Knowledge Attention to detail Leadership skills Problem solving aptitude Predictive analytics and modeling ETL (Extract, Transform, Load) Abilities Practice and foster safe work methods, identify workplace hazards, and use appropriate safety equipment Establish and maintain effective working relationships with staff, professional colleagues, and the public Handle multiple tasks simultaneously Find solutions to problems Work a flexible schedule which may include evenings and/or weekends and holidays and during emergency situations such as inclement weather Regular, timely attendance is a requirement for this position Respond to emergency situations Mentorship of employees Identify processes and streamline inefficiencies Physical Demands Required to walk, sit, and stand for long periods of time Push, lift, and carry up to 15 lbs Bend, stoop, kneel, and move intermittently throughout the day Minimum Education Requirements: Bachelors degree in computer Science, Statistics, Applied Math, or closely related field Minimum Experience: Five (5) years of experience in data mining and statistical analysis, at least two (2) of experience with SQL and statistical analysis OR equivalent combination of education and experience to successfully perform the duties of the job"
Data Warehouse Engineer,Mercari,"Remote in Palo Alto, CA",https://www.indeed.com/company/Mercari/jobs/Data-Warehouse-Engineer-3438f1f9dbd6f4b1?fccid=5398414faf66f195&vjs=3,"US RemoteMercari is your Marketplace. We make it super easy to sell (or buy) almost anything. We all have things we don't use, never used or simply outgrew. But that stuff still has value. Mercari gives you the power to simply sell it, ship it, and earn some cash for it. Fashion to toys. Sporting goods to electronics. All the brands you know and love. Our mission is simple: to make selling easier than buying. And with 50M+ downloads in the U.S. and 350k new listings every day, we're just getting started.The ideal candidate is eager to take responsibilities on developing curated data products with cloud data platforms technologies. This individual has a passion to make systems reliable, sustainable and engineered with scale and usability in mind. You will collaborate with cross functional teams (data analytics, product managers, business operations and engineering) to understand the requirements to deliver scalable business solutions. With your advanced knowledge of data warehousing concepts and experience working with Big Data, and ETL Transformation tools (eg. Dataform, DBT, DataProc, Dataflow), you will develop the best in class cloud data warehouse platform that delights the consumers of data at Mercari.What You'll Be Doing: Design, build and operate ETL pipelines at scale that are developed with quality, reliability, and availability as goals Review existing data warehouse usage and design and implement data products based on best practices in data warehousing to ensure quality, performance and reliability of data in the enterprise data warehouse Produce clear, well-documented code for product features Collaborate with internal teams to fix and improve data products and evaluate and implement new cloud technologies Automate tasks through appropriate tools and scripting What You'll Need: At least 8+ years of experience in building data pipelines on cloud data warehouses Industry experience building and productionalizing data pipelines Advanced knowledge of databases, real-time and batch data pipelines, SQL and data analysis Expert experience with RDBMS and SQL, Data Warehousing methodologies Prior experience with Google Cloud Platform or AWS or related cloud services specifically around ETL (DataProc (ApacheSpark), DataFlow (Apache Beam), Airflow and DBT or DataForm) Experience with Kafka or other streaming pipelines Ability and desire to take full ownership of projects, driving them forward to completion Nice-to-haves: Exposure to BI tools desired, but not required (eg. Looker preferred, Metabase & Tableau) Familiarity with Python/Java and willingness to learn to gain proficiency Experience with Apache Airflow or related workflow scheduling products Prior experience with Data Observability Tools (eg. Monte Carlo) Technologies We Use: ETL: Apache Airflow, DataFlow, DataProc, DataFusion, DataForm Cloud: Google Cloud(BigQuery/ML Engine, etc.) BI: Looker, Metabase Container: Docker/Kubernetes Database: Google Datastore/MySQL/Google Spanner/BigQuery Why Mercari: Small enough to make an impact but established enough to provide the stability you need to be successful, Mercari is the best of both worlds. At Mercari you are encouraged to take risks. And when you do, you can do it confidently, knowing you have a team and a company that supports you.As we grow, your career opportunities with Mercari grow. As our teams expand, your responsibilities expand. Our teams are supported with access to new tools, technologies, and learning opportunities. We will never stop growing.Total Rewards: Flexibility: Work remote from anywhere in the US and receive flexible time off Wellbeing: Top-notch insurance plans, best-in-class new parent offerings and access to mind and body wellness apps Growth: As we grow, your career opportunities grow, we provide access to new tools, technologies and learning opportunities Comprehensive and total rewards: We provide a strong financial foundation and rewards that go beyond the paycheck Teamwork: We are each other's biggest fans- we celebrate from virtual coffee breaks to recognition programs Additional Information (Colorado only*) Minimum salary of $113,500 + equity + benefits. More information about our benefits can be found here Note: Disclosure as required by sb19-085 (8-5-20) of the minimum salary compensation for this role when being hired into our offices in Colorado Mercari is proud to be an Equal Opportunity EmployerMercari prides itself on the diversity of its workforce. We do not discriminate on the basis of age, national origin, race, religion, marital status, veteran status, disability status, gender identity, sexual orientation, or any other class protected by applicable law. Job Type: Full-time Pay: $113,500.00 per year"
Data Engineer,BlocPower,Remote,https://www.indeed.com/rc/clk?jk=4a07291e8d11a786&fccid=5f7c8e9b696f11aa&vjs=3,"BlocPower is a clean energy leader creating smarter, greener, healthier buildings for all by reducing the barriers to money-saving, quality-of-life-improving green building upgrade. We provide engineering, financing and project implementation services for our clients, with a special focus in historically left out communities across the country. These communities, and their buildings, are underserved by traditional energy services companies because they are considered too small, too costly, or too risky. Our portfolio of projects include houses of worship, schools, non-profits, small businesses and multifamily buildings. Through our work, we save our clients money, reduce greenhouse gas emissions, improve health and create local employment opportunities. At BlocPower, we value our mission. We are trusted advisors that get things done for our customers by using data to make the right decisions. We support and expect excellence from our team members. We treat both our customers and ourselves with care and respect. As our work is centered around systematically disenfranchised communities – including people of color, people from working class backgrounds, women and LGBTQ people – we strongly encourage applications from people with these identities or who are members of other marginalized communities. About the Role To further this mission, BlocPower is looking for a friendly Data Engineer to join our growing team. This engineer will be responsible for expanding our data pipeline architecture. You should have a depth of experience building data pipelines,, and see yourself adding to as much as benefitting from a supportive team environment. This hire will help keep data consistent across projects and teams. This may look at times like helping our engineers to perform energy audits using our proprietary models, writing software that will help us analyze big data that comes into our platform via sensors installed across our projects, or optimizing the project pipelines of our construction and sales teams. The ideal candidate is someone who is self-directed, believes in our mission, and is an excellent written communicator. What You'll Do Assemble large, complex, structured/unstructured data sets from various public/non-public data sources into the raw-zone of our data lake. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Design and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data and associated architecture secure. Who You Are Ability to write good SQL, and work with a variety of databases (eg. AWS RDS, MySQL, PostgreSQL, and MongoDB) Autonomously stand up and maintain an ETL pipeline with little to no supervision, using tools such as AWS Glue, Informatica, or Talend Coherently organize a data lake, making it easy easy to collaborate on data Manipulate big data, including high-velocity streaming data using tools such as Spark, Kafka and Kinesis Strong project management and organizational skills Education/Experience BA/BS or equivalent combination of work experience and education preferably in degree/course work/experience in computer science/data engineering 2+ years of experience as a Data Engineer What You'll Get from Us Base salary between $120,000 and $130,000 Competitive equity in a growing, Series A startup Health, dental, vision benefits, plus perks like a One Medical membership Bonus Points Experience with AWS cloud services: EC2, EMR, RDS, Redshift, Glue, Sagemaker Microservice architectures Docker, Kubernetes, Docker-Compose Git and Jenkins Experience working with IoT/Sensors This job description is not intended to be a comprehensive list of the duties and responsibilities of the position. The duties and responsibilities may change without notice. BlocPower™ provides equal employment opportunities(EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, BlocPower™ complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. BlocPower™ expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of BlocPower™ employees to perform their job duties may result in discipline up to and including discharge."
Data Validation Engineer,Smarking,+1 locationRemote,https://www.indeed.com/rc/clk?jk=3c92e0af6d9365bf&fccid=2d3def7f59c7da5b&vjs=3,"Smarking is a leading provider of enterprise software and data technology solutions for the massively overlooked $655B global parking industry. Clean data is one of the keys to our business. This is an excellent opportunity for an engineer who is passionate about data and and loves digging in. In this cross functional role between our customer success and engineering, you'll be our go to engineer for diagnosing and fixing data accuracy and and data flow issues. You'll work with technologies such as Python, PostgreSQL, pandas, sellenium, Microsoft Excel, Docker, AWS and be a key contributor to the success of our customers. KEY RESPONSIBILITIES Work with customer success to identify and fix data issues Be the engineering liaison to customer success Dig into the data to insure accurate interpretation of its semantics Build tools to streamline the data accuracy process Occasionally interact with customers and vendors to facilitate accurate data ingestion QUALIFICATIONS (EXPERIENCE) 2+ years professional software engineering experience desire to learn new technologies demonstrated ability to work with data experience with relational databases and tools for analyzing relational data experience with Python, pandas, and PostgreSQL and AWS would be a plus QUALIFICATIONS (CHARACTER) Hungry for responsibility, impact, and growth Humble to learn, curious to learn, open-minded to learn Team first Strong sense of ownership Treat others with respect, empathy, and constructive candor COMPENSATION Competitive salary and equity. 100% coverage of medical, dental, and vision insurances. 401K plan with 3% company hard match. $100 monthly data plan. $60 per month gym membership (or other physical activity) Unlimited paid time off. Expenses for setting up home-office. About Smarking Smarking is a group of passionate MIT PhDs, data scientists, Silicon Valley engineers, and battle-tested business professionals, committed to enable highly efficient urban mobility by building the digital infrastructure for the massively overlooked $655B global parking industry ($131B in the US). Smarking is hired by organizations like Brookfield Properties, City of Miami, ABM Industry Groups, and many other enterprise industry leaders to turn their parking data into business results. Smarking's dynamic pricing engine has been creating 40%-400% revenue uplift for online parking sales at parking facilities in Chicago, NYC, Boston, and many other cities, without any manual involvement required from property managers, leveraging fully automatic algorithm-driven yield management technologies similar to the airline and hotel industries. By providing the very first business intelligence and yield management enterprise SaaS to the parking industry, Smarking is establishing itself as an emerging leader in the US parking market. Smarking currently works with 2,500+ parking locations cross North America, based in San Francisco, and backed by top investors like Khosla Ventures and Y Combinator."
Data Engineer,Tyler Technologies,"Olathe, KS 66061+7 locations",https://www.indeed.com/rc/clk?jk=a6431bcd38e40164&fccid=35fa439a19059a40&vjs=3,"The Mid-Level Data Engineer is responsible for analyzing data problems, designing and developing data pipeline and model solutions, and implementing those solutions. The data engineer will work closely with the data science team and product teams to analyze business problems and recommend solutions. The data engineer should have a background in development and data design and the know-how to move data between systems through automation. To develop the solutions, the data engineer will need to adhere to data best practices, including data security and data quality. The Data Engineer will be a member of the enterprise architecture team. Requirements Must have programming experience examples (Python, Julia, etc.) Development Experience in data pipelines AWS Glue, AWS DMS, Python, or other ETL Strong SQL Experience Data Analysis of relational and non-relational databases Development of Dimensional Data Models Computer Science, Computer Engineering, or similar BS degree or work experience equivalent. Knowledge of Data Warehousing best practices, including Data Cataloging, Data Security, and Data Quality Five years relevant experience Desired (not required) Skills Cloud and AWS Experience Experience with Data Visualization / D3 Experience with Enterprise Service Bus"
Data Engineer,"Stanley Consultants, Inc.","Centennial, CO+1 location",https://www.indeed.com/rc/clk?jk=fbc5f60a2548a34c&fccid=f299ff04559e660f&vjs=3,"The Data Engineer position will report to the Manager of the Enterprise Analytics Group (EAG) in Stanley Consultants’ Shared Services. The primary role of the Data Engineer will be to analyze the structured and unstructured data needs of the organization, then design, develop and support the data structures needed to support the business – databases, data warehouses, ELT processes, cubes, and whatever else is required to meet stakeholders needs. (Stakeholders will be both internal – other departments inside Stanley, and external – our clients and customers.) The Data Engineer will review the current databases used by the EAG, work with the enterprise applications experts in the company’s Technology Services Group (TSG, the company’s IT group), and will be required to fully review and document proposed changes and improvements to the current databases and applications used by the EAG. Working in concert with other members of EAG and key subject matter experts in TSG, the Data Engineer will then architect, develop, deploy and support Stanley’s next-generation data structures and warehouses. From there, the Data Engineer will act as a steward, caretaker, architect and developer for the systems in question, and any new systems that need to be re-architected or brought into production. EAG is a small and nimble team; the Data Engineer will need to be comfortable wearing multiple hats and working on a new and growing team that the wider organization is just learning to leverage. The environment is currently largely Microsoft-based (e.g. SQL Server, SSRS, SSIS, Power BI), but parts of the company are beginning to work with large and sometimes unstructured data sets – expectation is that EAG will work in standard enterprise technologies, but where required will deploy the technologies needed to support the business. The role will play a pivotal position in expanding the group into a more mature data team, and the ideal candidate will both have previous experience designing, implementing, and maintaining an enterprise level data warehouse, while also having the capability to flex and learn new approaches as the team and the company both grow. Primary Responsibilities Become the SME of the existing and future data systems at Stanley Consultants used by the EAG Work closely with the manager of EAG and SMEs in TSG to evaluate current data structure and understand data flows Document and fully understand the current data environment at Stanley Consultants Work with internal teams to design, build, test, and maintain a new data warehouse environment in SQL Server that will be exclusively used by the EAG Responsible for creating, updating, and maintaining all future reporting level changes required in the database Participate in a change management system to document changes to the database Create complex SQL queries per report or project requirements Optimize SQL queries to alleviate performance issue Create and maintain database documentation including entity-relationship models and changes to the database Work closely with the front-end Power BI developer to ensure the correct data is surfaced in the most efficient manner for reporting Research and suggest new database products, services, and protocols that could benefit the organization Develop SQL Server Reporting Services reports as needed for internal stakeholders Required skills, education, and experience: 5+ years working as a Data Engineer or similar role 3+ years SQL Server Reporting Services experience Prior experience designing, implementing, and maintaining an enterprise level data warehouse solution Prior experience owning Data Governance projects In-depth understanding of data management in SQL Server Prior experience with SSIS Expert level experience in creating and optimizing SQL queries Excellent analytical, organizational, and communication skills Ability to work on a small team on that takes ambiguous requests from multiple areas of the business and produces valuable outputs, reports, dashboards, and deliverables Strong understanding of data visualization concepts and best practices Ability to independently own issues and see them to completion Ability to work on multiple requests at one time and prioritize time effectively Prior experience with data visualization software (Power BI preferred) Prior DBA experience preferred but not required Certification in Database Engineering preferred but not required Bachelor’s Degree in Information Systems or related field Salary Range: Base Compensation: $108,000 - $120,000 In accordance with the Colorado Equal Pay for Equal Work Act actual compensation is subject to variation due to such factors as education, experience, skillset, and/or location. Are you ready to take your career to the next level with a company that is committed to innovative growth and improving lives in the communities where we live and work? Stanley Consultants is an award winning, interdisciplinary consulting firm providing program management, planning, design, permitting, engineering and environmental services. Recognized for its commitment to client service and a passion to make a difference, Stanley Consultants brings global knowledge, experience and capabilities to serve federal, municipal and industrial clients. Stanley Consultants solves complex challenges in power generation and delivery, transportation, water, energy and industrial plants, building services, and the environment. Since 1913, Stanley Consultants has successfully completed more than 50,000 projects globally in more than 100 countries, including all 50 of the United States and its territories. Throughout our history, Stanley Consultants has remained an employee-owned company, committed to a legacy of professional independence and objectivity. The commitment to private ownership, shared responsibility and reward has sustained us for more than 100 years. A Great Place to Work: Become a Member Once you are hired at Stanley Consultants, you become a member of our member-owned company. Our Core Values speak to the capabilities, initiative, integrity, creativity, and commitment that make you, as a member, our most important asset. As a member, you have the opportunity to chart your own career path and play a role in shaping our mutual future. Click Here: A Great Place to Work #LI-RH1 Qualifications Skills Behaviors : Motivations : Education Experience Licenses & Certifications Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Engineer ('22),84.51°,"Remote in Cincinnati, OH 45202+2 locations",https://www.indeed.com/rc/clk?jk=dffad87ddd5df7aa&fccid=d1ae41cea4bc9f6e&vjs=3,"84.51° Overview: 84.51° is a retail data science, insights and media company. We help the Kroger company, consumer packaged goods companies, agencies, publishers and affiliated partners create more personalized and valuable experiences for shoppers across the path to purchase. Powered by cutting edge science, we leverage 1st party retail data from nearly 1 of 2 US households and 2BN+ transactions to fuel a more customer-centric journey utilizing 84.51° Insights, 84.51° Loyalty Marketing and our retail media advertising solution, Kroger Precision Marketing. Join us at 84.51°! __________________________________________________________ Data Engineer We are a full-stack data science company and a wholly owned subsidiary of The Kroger Company. We own 10 Petabytes of data and collect 35+ Terabytes of new data each week sourced from 62 million households. As a member of our engineering team, you will use various cutting-edge technologies to develop applications that turn our data into actionable insights used to personalize the customer experience for shoppers at Kroger. We use agile development methodology bringing everyone into the planning process to build scalable enterprise applications. What you'll do As a Data Engineer, you will have the opportunity to build solutions that ingest, store and distribute our big data to be consumed by data scientists and our products. Our data engineers use Python, Hadoop, PySpark, Hive, and other data engineering technologies and visualization tools to deliver data capabilities and services to our scientists, products, and tools. Responsibilities Participate in the development of Hadoop and Cloud-based solutions Perform unit and integration testing Participate in implementation of BI visualizations Collaborate with architecture and lead engineers to ensure consistent development practices Participate in retrospective reviews Participate in the estimation process for new work and releases Collaborate with other engineers to solve and bring new perspectives to complex problems Drive improvements in people, practices, and procedures Embrace new technologies and an ever-changing environment Requirements Data Development experience Experience with Hadoop/HDFS and SQL (Oracle, SQL Server) Experience with PySpark/Spark Experience developing with either Python, Java, or Scala Understanding of ETL concepts and Data Warehousing concepts Exposure to VCS (Git, SVN) Understanding of Agile Principles (Scrum) Bachelor's Degree (Computer Science, Management Information Systems, Mathematics, Business Analytics, or STEM) Preferred Skills – Experience in the following Experience with Azure Exposure to NoSQL (Mongo, Cassandra) Experience with Databricks Exposure to Service Oriented Architecture Exposure to BI Tooling (Tableau, Power BI, Cognos, etc.) Proficient with Relational Data Modeling and/or Data Mesh principles Experience with CI/CD - Continuous Integration/Continuous Delivery #LI-DOLF #LI-REMOTE"
Data Engineer,CMS Energy,"Jackson, MI 49201",https://www.indeed.com/rc/clk?jk=55707c8b1aee519e&fccid=1b005486ecd42731&vjs=3,"Contract Assignment-June-December 2022 (W-2 Role) **Site Visits 1 to 2 times a month in Michigan*** Responsibilities: The Data Engineer provides development of useable data sources by acquiring, integrating, shaping, and automating data that can be used in predictive and prescriptive modeling. The Data Engineer must possess an intellectual curiosity to learn and apply new techniques and programming languages and must have the ability to cultivate and maintain relationships with others across the organization. At this level, individuals will have demonstrated the ability to streamline the process for acquiring, transforming, and delivering data to end users, in an efficient and timely manner. The engineer supports analytics projects of varying sizes and complexities which may result in altering or developing new company projects and standard operating procedures. The position will serve as support to other components of the data science process. Acts as the primary point of contact for understanding how to integrate and automate data from any platform. Create data pipelines from source systems to various databases. Clean and Wrangle data for future use. Collaborate with Data Scientists to provide data for prescriptive and predictive modeling. Effectively create data dictionaries for various sources. Skills: Python SQL (Oracle, SQL Server, MySQL) SAP Skill to set you apart: GIS Education: Bachelor’s degree in Information Systems, Computer Science, Data Science or related area. Three or more years of related exempt work experience in the Data Engineering field. Experience with Agile and or Scrum."
Big Data Engineer - Opportunity for Working Remotely Palo Al...,VMware,"Remote in Palo Alto, CA+126 locations",https://www.indeed.com/rc/clk?jk=6d105629661240f7&fccid=c762a27145bd166e&vjs=3,"The Elevator Pitch: Why will you enjoy this new opportunity? You want to be a part of an innovative company of 35000+ people working in 50+ locations worldwide and committed to building a community where great people want to work long term by living our values of passion, innovation, execution, teamwork, active learning and giving back. If you are ready to accelerate, innovate and lead, join us as we challenge constraints and problem solve for tomorrow today. You are highly motivated and would love to be part of VMware Data Engineering team working to solve complex business problems and bring digital transformations What is primary need, technical challenge, and/or problem you will be responsible for? VMware Data Engineering team is seeking a highly motivated, experienced Data Engineer within the IT Data Engineering and Analytics group. This position is responsible for hands on development work on all aspects of Data Engineer, data provisioning, modeling, performance tuning and optimization. The candidate will work closely with both Enterprise and Solution Architecture teams to translate the Business/Functional requirements into technical specifications that drive Hadoop/HANA/BI solutions to the meet functional requirements. Success in the Role: What are the performance goals over the first 6-12 months you will work toward completing? Within the first few months you will spend time learning VMware’s coding standards, products, and increasing you know how of the technology landscape around data. We want you to be curious, learning both from team members and individual study. You will collaborate with other team members and participate in architecture reviews. You will closely work with other data product owners/engineers towards taking ownership of few existing artifacts within the data landscape. You will be required to help in troubleshooting any upcoming production defects and perform production support. You will also work on delivering specific enhancements in an agile delivery model What type of work will you be doing? What assignments, requirements, or skills will you be performing on a regular basis? You will work in a fast paced and agile work environment. You will communicate and engage with a range of stakeholders. You will be responsible for hands on development work building scalable Data engineering pipelines and other data engineering/modelling work using one or more of Python, Kafka, Hadoop/Hive, Presto etc. You will have to query data using SQL or other techniques. Excellent SQL & Analytical SQL functions knowledge will be needed Understanding of SAP HANA and Knowledge of Data Integration Platforms - Informatica PowerCenter, SAP BODS, SDI, SLT (is desired but not mandatory) and will help you in understanding existing landscape You will be owner of specific modules. You will collaborate with other team members on improving dev practices, do peer code reviews and provide production support What is the leadership like for this role? What is the structure and culture of the team like? This role reports to a Senior Manager for IT Data Engineering and Analytics. IT Data Engineering and Analytics team is spread across VMware offices in Bangalore, Chennai, Palo Alto(USA) , Austin(USA) , Cork(Ireland), Beijing(China) and Costa Rica The team is headed by Director, IT Data Engineering and Analytics based in Palo Alto What are the benefits and perks of working at VMware? You and your loved ones will be supported with a competitive and comprehensive benefits package. Below are some highlights, or you can view the complete benefits package by visiting www.benefits.vmware.com. Employee Stock Purchase Plan Medical Coverage, Retirement, and Parental Leave Plans for All Family Types Generous Time Off Programs 40 hours of paid time to volunteer in your community Rethink's Neurodiversity program to support parents raising children with learning or behavior challenges, or developmental disabilities Financial contributions to your ongoing development (conference participation, trainings, course work, etc.) Healthy and local inspired snacks in all our on-site pantries ""This job opportunity is NOT eligible for employment-based immigration sponsorship by VMware"". The position is eligible for JoinCIO tag referral campaign This job may require the candidate to travel and/or work from a facility that requires full vaccination prior to entry. Category : Engineering and Technology Subcategory: Software Engineering Experience: Manager and Professional Full Time/ Part Time: Full Time Posted Date: 2022-05-23 VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape what’s possible today at http://careers.vmware.com. Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law."
Data Engineer,I5 TECH,"Edison, NJ 08817",https://www.indeed.com/rc/clk?jk=60878c4d7104968b&fccid=2212a3d841605eae&vjs=3,"Gathering the business requirements. Analyzing business requirements and defining functional specifications, Analyzing existing applications consisting of multiple batch programs in SAS and developing the code in Python and Spark, Designing rules and workflow processing using python and Spark frame work, Identifying and developing automated batch packages, Participating in the deployment of the applications into existing systems and databases, Documenting modifications and enhancements made to the applications, systems and databases as required by the project. Educational And Experience Requirements : Must require at least a bachelor’s degree in Electrical Engineering or related field of study. Location: Edison, NJ CV to I5Tech Address: 3 Ethel Rd, Suite#306, Edison, NJ -08817 or E-Mail: careers@i5techinc.com"
Data Engineer,Breezeline,"Remote in Quincy, MA",https://www.indeed.com/rc/clk?jk=8ae8a52f4ef41bf8&fccid=e11cd147f338a984&vjs=3,"Our culture lifts you up—there is no ego in the way. Our common purpose? We all want to win for our customers. We aim to always be evolving, dynamic, and ambitious. We believe in the power of genuine connections. Each employee is a part of what makes us unique on the market: agile and dedicated. Time Type: Regular Job Description : About Our Company Breezeline is a dynamic, innovative company providing the very best Internet, TV, and Voice service to the US markets we serve. We Are ‘ Above And Beyonders’, who consistently strive to surprise and delight our customers by doing the unexpected. We continually look for new and better ways to enrich our customers’ lives through connected and memorable experiences. As the 8th largest Internet provider in the United States, Breezeline provides Internet, TV, Voice, and enterprise business services to more than 450,000 business and residential customers across twelve states. Headquartered in Quincy, MA, Breezeline is a wholly-owned subsidiary of Cogeco Communications Inc. (TSX: CCA). Why Work At Breezeline? As one of the country’s fast-growing Internet service providers, Breezeline offers our colleagues a vibrant workplace culture and excellent career opportunities. As a proudly diverse and inclusive organization, we believe that every person’s unique individuality should be welcomed and celebrated, and their abilities and potential should be honored and recognized. It is a key part of our culture to actively promote opportunities internally to ensure that you are never static in your career with us. Internal Values – How we act We’re proud that Breezeline is unlike any other employer in the industry. We work hard, but we never lose sight of the big picture. We understand that our colleagues are looking for more than just a great job – they want an extraordinary life – and at Breezeline, we want to make that a reality. And here is how we do it. Fun: We laugh a lot. It makes every day brighter, and if you don’t love what you do, you’re not doing it right. Job flexibility: We think everything you do matters – at work and home. Discounted services: We offer our customers some fantastic services, and we think you deserve to enjoy them in your home, too. Total Rewards: Let’s be honest, everyone wants to make a good salary. We offer attractive total rewards and a great culture to go along with it. We’ve got you and your family covered with one of the best packages in the business. Career evolution: At Breezeline, you get more than just a job. You get all the tools you need to learn, grow, and achieve your career goals! Cutting-edge technology: Do you have a passion for technology? Great, we do, too. At Breezeline, you will get the opportunity to manage, influence, play, create, fix, and re-shape the industry. Position Description As a data engineer at Breezeline, you will participate in all steps of the data lifecycle, with the ultimate goal of adding value to the business. This role is responsible for a variety of tasks relating to data warehousing and business intelligence. For example, you may work one week on ingesting data from a new source, and work the next week on a visualization of this data for stakeholders to view. This position will be part of the Data & Analytics team. This is a remote position Responsibilities: Building Cloud Composer/Airflow pipelines for optimal extraction, transformation and loading of data from various data sources including MySQL, Oracle, JSON, CSV into our Big Query EDH Implementing tools and methodologies to improve data reliability and quality Creating dashboards in Google Data Studio for stakeholders to visualize activity and gain actionable insights Analyzing large, complex sets of data to deliver meaningful and accurate reporting Identifying and developing internal process improvements optimizing data delivery, and automating manual processes Skills: Ability to build and support data pipelines and other scheduled processes Ability to effectively communicate with business stakeholders Ability to learn complex data schemas and new technologies Experience with data visualization tools Excellent analytic skills and attention to detail Education & Knowledge: Bachelor's degree in Information Technology, Computer Science or equivalent combination of training and/or experience. Knowledge of relational databases and type 2 slowly changing dimensions Strong initiative to find ways to improve solutions, systems, and processes. Experience with UNIX/Linux environments Familiarity of APIs including knowledge of XML, JSON, REST, SOAP, etc. Scripting/programming: Python, SQL, Bash etc Familiarity with cloud technologies 3-5 years of experience Available Benefits: Competitive salary Medical coverage (including prescription and vision plans) Dental coverage Life Insurance (1x salary at no cost to employee) Long and short-term disability insurance (no cost to employee) Voluntary employee, spousal, and child life insurance Company recognized Holidays with additional Floating Holidays Paid Time Off (PTO) programs Comprehensive Flex Work Policy 401(k) plan eligibility (company match 50% up to 5% of eligible contributions) Participation in the Employee Bonus Plan Participation in the Cogeco Stock Purchase Plan Complimentary and discounted broadband services (for those in our service area) Tuition Reimbursement Headspace Membership Opportunities for LinkedIn Learning subscriptions for select colleagues #LI-Remote #LI-BR1 Location : Quincy, MA Company : Breezeline At Cogeco, we know that different backgrounds, perspectives, and beliefs can bring critical value to our business. The strength of this diversity enhances our ability to imagine, innovate, and grow as a company. So, we are committed to doing everything in our power to create a more diverse and inclusive world of belonging. By creating a culture where all our colleagues can bring their best selves to work, we’re doing our part to build a more equitable workplace and world. From professional development to personal safety, Cogeco constantly strives to create an environment that welcomes and nurtures all. We make the health and well-being of our colleagues one of our highest priorities, for we know engaged and appreciated employees equate to a better overall experience for our customers. If you need any accommodations to apply or as part of the recruitment process, please contact us confidentially at inclusiondiversite@cogeco.com"
Data Delivery Engineer,HealthVerity,Remote,https://www.indeed.com/rc/clk?jk=9e8ce1431d0839df&fccid=6b1be984647e492b&vjs=3,"How you will help You will assist the data delivery team with optimizing the data extraction and delivery process to ensure accurate and on-time data deliveries that meet client expectations. To achieve this, you will dive in to fix issues, optimize processes, and automate what you and the data delivery team do more than once. You will use the best tools for the job, whether modern and revolutionary or time tested and proven, to deliver elegant, scalable solutions that meet business and technical needs. What you will do Work with internal stakeholders to understand business needs for data deliveries Troubleshoot and resolve issues relating to data extraction and delivery Help establish procedures and best practices for extracting and delivering data Work with some of the most exciting open-source tools like Spark, Hadoop, Airflow, Zeppelin Leverage distributed computing and serverless architecture such as AWS EMR Enjoy the peace that comes with working in a mature software development environment Research and implement new technologies with a team of developers to execute strategies and implement solutions Produce peer reviewed quality routines Solve complex problems related to the real-time discovery of large data Continue to develop broader and deeper knowledge of data assets and analytic methodologies everyday About You You are... Experienced in writing scalable applications on distributed architectures Data driven, testing and measuring as much as you can Eager to both review peer code and have your code reviewed Confident in SQL, you know it, write smart queries, it’s no big deal Passionate about data and optimizing processes around it Excited about building and creating production processes that run on time, efficiently, and correctly A self-starter that enjoys working in a small, rapidly changing, fast paced environment Extremely comfortable working with large data sets Required skills and experience 5+ years of work experience 3+ years of experience with SQL 3+ years of experience with Python 3+ years of experience with Spark (writing, testing, debugging spark routines) 1+ years of experience with AWS EMR, AWS S3 service Comfortable using *nix command line (shell scripting, AWK, SED) Comfortable working in remote environments Able to gather requirements, test strategies, design deliverables Proven analytical, evaluative, and problem-solving abilities Extensive experience working in a team-oriented, collaborative environment Desired experience Experience with Apache Airflow Experience with Apache Zeppelin Knowledge of healthcare industry data utilized by manufacturers, payers, clearing houses, etc. About HealthVerity At HealthVerity we are actively solving some of the greatest challenges in healthcare through innovative technology and data solutions. Our customers and partners including pharmaceutical manufacturers, payers and government organizations look to HealthVerity to partner on their most complicated use cases, leveraging our transformative technologies and real-world data infrastructure. The HealthVerity IPGE platform, based on the foundational elements of Identity, Privacy, Governance and Exchange, enables the discovery of RWD across the broadest healthcare data ecosystem, the building of more complete and accurate patient journeys and the ability to power best-in-class analytics and applications with flexibility and ease. To learn more about the HealthVerity IPGE platform, visit www.healthverity.com. Why you'll love working here We are making a difference – Our technology is at the forefront of some of the biggest healthcare challenges in the world. We are one team – Our people define our culture and always will. We take time out to celebrate each other at the end of every week through company-wide shout outs, and acknowledge the value that each of us adds towards our greater mission. Come share all you have to offer. We are learners – Every team member is continually learning, no matter if we've been in a role for one year or much longer. We are committed to learning and implementing what is best for our clients, partners, and each other. Benefits & Perks Compensation: competitive base salary & annual bonus opportunity (for non-commissioned roles) Benefits: comprehensive benefits with coverage on Day 1, medical, dental, vision, 401k, stock options Flexible location: our HQ is in Philadelphia with 50% of the team distributed across 25+ states Generous PTO: Take time off as needed, targeted at 4 weeks per year, including vacation, personal and sick time, plus paid maternity and paternity leave. Comprehensive and individualized onboarding: mentorship program, departmental talks, and a library of resources are available beginning day 1 for each new team member to minimize the stress of starting a new job Professional development: biweekly 1:1s, hands-on leadership that is goal-and growth-oriented for each team member, and an annual budget to support professional development pursuits HealthVerity is an equal opportunity employer devoted to inclusion in the workplace. We believe incorporating different ideas, perspectives and backgrounds make us stronger and encourages an environment where ageism, racism, sexism, ableism, homophobia, transphobia or any other form of discrimination are not tolerated. At HealthVerity, we’re working towards an innovative and connected future for healthcare data and believe the future is better together. We can only do that if everyone has a seat at the table. Read our Equity Inclusion and Diversity Statement. If you require a reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to careers@healthverity.com HealthVerity offers in-office and remote options, so you can work from anywhere within the US! #LI-Remote"
Data Engineer,Blocknative Corporation,Remote in United States,https://www.indeed.com/rc/clk?jk=f15c0f0ff43e685f&fccid=3def73997cdde853&vjs=3,"Founded in 2018, Blocknative provides Web3 transaction orchestration infrastructure for the Ethereum, Polygon, Gnosis Chain, Fantom, BNB Chain, and Bitcoin ecosystems. Blocknative solutions are deployed by hundreds of Web3 builders and traders to enable dynamic user experiences and power real-time decisions via pre-chain data and insights. Blocknative’s mempool data platform is used by some of the leading projects in the category. Every day our infrastructure captures hundreds of millions of rows of data, enhancing and enriching the data set. The data engineering team designs, implements, and oversees all of Blocknative’s blockchain data pipelines/storage. As an engineer on the team, you will have ownership over the flow, storage, and access of data through Blocknative’s big data cloud infrastructure. This empowers internal teams and customers to access mempool data, build machine learning models, and conduct research. Responsibilities: Design, build, and maintain Blocknative’s data infrastructure Oversee the flow of data across all of Blocknative’s pipelines Coordinate with other teams to build blockchain data products Manage cross-functional stakeholders and help drive a data-driven culture company-wide #LI-Remote Preferred* Experience: Ethereum experienced — proficient with the core concepts in the space Big data (Databricks/Spark) experience Streaming data systems (Fluentd/Kinesis) Cloud infrastructure (AWS)ETL workflow management Data streaming systems Programming languages used for modern data engineering, such as Python. Go, Scala, as well as some Javascript We prioritize people above all else. If you think you’d add to the depth and diversity of our team but don’t fit these qualifications exactly, we want you to apply! We hope you apply! We are also open to exploring contract opportunities as we get to know each other. We strive to have you meet as much of the team as possible before extending an offer. Here’s what you can expect: Application review Schedule a call with the recruitment team Schedule a call with the hiring manager Schedule a group interview with the growth or technical team Reference calls/ background checks Offer If you want to dig deeper into Blocknative, please explore our YouTube channel and blog, and don't forget to create your free account. #LI-Remote"
Data Engineer,Becker Logistics LLC,Remote,https://www.indeed.com/rc/clk?jk=eedb6ae1cb24845e&fccid=d83042a77f0ed910&vjs=3,"Description: Summary of Role: Are you a technology enthusiast? Do you see opportunities around you to add value through technology? Do you enjoy being responsible for bringing information and people together to create and deliver value? Do you aspire to be a business leader and valuable teammate? Our Business Analyst opening is an opportunity to make a substantial impact by designing and delivering software development and implementation projects. You will be in the middle of the action, serving as a liaison between stakeholders, users, and developers. You will collaborate to define deliverables, set, and communicate goals, track progress, and evaluate and refine results. This is a very visible position at a company where you will have autonomy, work on a variety of self-driven tasks and have the opportunity for personal and career growth. Specific Responsibilities: Gathers business intelligence from a variety of sources including company data, industry and field reports, public information, or purchased sources. Compiles business intelligence or trends to support actionable recommendations. Summarizes financial and economic data reports for review by executives, managers, clients, and stakeholders . Requirements: Required Experience and Qualifications: 1-3 years of experience engineering BI / Reporting capabilities in business Excellent verbal and written communication skills Moderate presentation design capability creating smart visualizations that help people make decisions Moderate query design, data munging, mining ability. Exposure to ETL and ELT concepts. Exposure to structured and unstructured data technologies and concepts. Basic to advanced experience with source control systems. Ability to handle databases and understand technology-driven business intelligence tools Preferred Skills, Experience & Education: Associate’s, Bachelor’s and Master’s degrees in Information Technology, Engineering, Mathematics, or related fields. Familiarity with McLeod Power Broker Experience with project management and work tracking tools"
Data Engineer,Northrop Grumman,Remote in Maryland+6 locations,https://www.indeed.com/rc/clk?jk=b821ea2581c0d371&fccid=11619ce0d3c2c733&vjs=3,"Requisition ID: R10048406 Category: Information Technology Location: Unknown City, Maryland, United States of America Citizenship Required: United States Citizenship Clearance Type: None Telecommute: Yes- May Consider Full Time Teleworking for this position Shift: 1st Shift (United States of America) Travel Required: No Positions Available: 1 At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history. As a Data Engineer at Northrop Grumman, you will be supporting an exciting, cutting-edge data analytics program enabling Enterprise data analytics at Northrop Grumman. We are looking for a self-motivated, enthusiastic person who is excited about taking on a variety of engineering challenges as we continue to push our data analytics capabilities forward. This position can performed as a virtual telecommuter. The Chief Data Office - Data and Analytics organization is seeking a qualified Data Engineer to join our team. Individuals in this role are expected to be comfortable with a variety of database programming languages, techniques, and infrastructures. The Data Engineer is also expected to analyze data challenges and business opportunities and develop requirements and specifications for implementation. The ideal candidate will have a keen interest in the tools and processes around ETL and data visualization and a passion for identifying and answering questions that help us deliver the best service for our customers. Responsibilities include: Work closely with customers to understand and analyze data challenges and opportunities Work closely with customer to develop and implement data related architectures, designs, and solutions Drive the collection of new data and the refinement and aggregation of existing data sources Develop and manage ETL workflows using products/languages such as SSIS, Alteryx, and Python Have solid understanding of Data Warehouse and Data Warehouse development and optimization techniques Communication to various levels of management Basic Qualifications Bachelor’s or master’s degree in a STEM field with at least 2 years of experience. 0 with a Masters degree. Experience with SQL, ETL, and Databases Experience manipulating and analyzing complex, high-volume, high-dimensionality data from multiple sources / systems of record Experience with SQL Server Analysis Services, SQL Server Integration Services, and SQL Server Reporting Services Experience building and supporting multi-dimensional and tabular models Experience using Alteryx Proficient in one or more of the following Programming Languages: Pig, SQL, Python, Java, Perl, .NET, R Proficient in one or more of the following databases / data sources: Microsoft SQL Server, Sybase, MySQL Server, DB2, Oracle, Hadoop Preferred Qualifications: Experience building pipelines for Business Intelligence dashboards and Machine Learning models Experience automating processes Ability to work both independently and collaboratively on a team Competence and confidence working under pressure on requests with short turn-around times. Excellent attention to detail applied to complex data integration and analysis projects. Proficient in Atlassian tools (JIRA / Confluence). Experience using GitHub. Experience with Cloud native tools used for data and analytics delivery (AWS and Azure) Data Governance and Quality Experience Active DoD Secret security clearance. Salary Range: $83,800 USD - $155,900 USD Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business. The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/. Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions."
Data Engineer,Perry Street Software,Remote,https://www.indeed.com/rc/clk?jk=3c992d00e6ef4bd1&fccid=25f3406e935c590e&vjs=3,"About PSS Perry Street Software is Jack’d and SCRUFF. We are two of the world’s largest gay, bi, trans and queer social dating apps on iOS and Android. Our brands reach more than 30 million members worldwide so members can connect, meet and express themselves on a platform that prioritizes privacy, security, and community. Our company puts user privacy first, and doesn't use third-party ad networks or tracking software. A 100% remote, 100% global team Every day, the PSS product team comes together virtually from more than 18 cities in more than 12 countries. As a colleague at PSS, you can work from any timezone in North America, South America, or Europe (we start in Pacific Standard Time from the USA and conclude in Eastern European Time from Greece). Benefits include: 11 paid holidays One paid week off at mid-year (the PSS summer refresh week) Home office stipend - purchase furniture for your home setup Paid parental leave Paid travel around the world to meet and collaborate with colleagues (previous destinations include: New York City, Rio, and Berlin) Education and conference budget Healthy work-life balance and ability to be flexible in how you set your schedule United States-based employees additionally receive the following benefits: 401k plan with 6% match Comprehensive, nation-wide healthcare coverage Flexible time off policy Job Description We are hiring experienced Data engineers. This role will assist in building the next-generation version of Scruff and Jack’d. We are a small, Agile, nimble company, so the ability to make an impact is significant. The position is 40 hours per week and ongoing/full-time. You should be highly proficient in: Build and develop ETLs for our analytics pipeline, S3, and Redshift datasets. Maintaining, archiving and pruning this data. (We keep all our data in our cloud to ensure our customers' privacy) Knowledge of Python, Scala, Spark, Athena, Databricks, or AWS QuickSight You should be able to do one of the following: Server Engineering Maintain, code, and debug a complex Ruby/Sinatra backend which processes more than 350 million web server requests per day Keeps up-to-date with security and is able to proactively identify, diagnose, and solve complex security issues Site Reliability & DevOps Engineer Maintain and monitor deployment, orchestration of the servers, docker containers, databases, and general backend infrastructure Able to troubleshoot complicated issues across Linux, AWS, networking, and databases Architect and optimize AWS infrastructure balancing out reliability, resilience, scale, performance, security, and cost Be available for on-call support issues ensuring our currently extremely low on call rate Who you are: Good communicator with a remote distributed team Bachelor’s degree (or higher) in computer science, related field, or equivalent practical experience 3+ years of Server, Dev Ops, Infrastructure, or Data experience Strong sense of ownership, ability to work independently, and proven track record of driving products Shipped and maintained consumer software Nice to Have: Understand orchestration layers like Kubernetes, AWS Fargate, and AWS ECS Strong architectural knowledge in design patterns and object oriented/functional programming Understand CI/CD infrastructure specially AWS CodeDeploy and CodePipeline Has experience with some client facing Android, iOS or web in Kotlin, Swift, or React Additional Information Perry Street is proud to be an Equal Opportunity Employer. We do not discriminate based upon race, religion, color, gender, gender identity or expression, sexual orientation, genetic information, national origin, ancestry, medical condition, disability, marital status, caregiver status, pregnancy, citizenship, age, military or veteran status, or other applicable legally protected characteristics. All your information will be kept confidential according to EEO guidelines."
PySpark Data Engineer,Deloitte,"New York, NY+126 locations",https://www.indeed.com/rc/clk?jk=063d9ee03495cb78&fccid=9e215d88a6b33622&vjs=3,"The AI & Data Engineering team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-makin g. Together with the Strategy practice, our Strategy & Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets. AI & Data Engineering will work with our clients to: Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements Qualifications Required: 3+ years of relevant technology consulting or industry experience to include experience in Information delivery, Analytics and Business Intelligence based on data 3+ years experience in Python and/or R 3+ years experience in SQL 3+ years experience PySpark 2+ years of hands on experience with data core modernization and data ingestion 1+ years experience leading workstreams or small teams Bachelor's Degree or equivalent professional experience Limited immigration sponsorship may be available Ability to travel up to 50% on average, based on the work you do and the clients and industries/sec tors you serve Preferred: An advanced degree in the area of specialization is preferred. Experience with Cloud using Amazon Web Services (AWS), Microsoft Azure, and/or Google Cloud Platform (GCP) Experience with Spark, Scala Understanding of the benefits of data warehousing, data architecture, data quality processes, data warehousing design and i mplementation, table structure, fact and dimension tables, logical and physical database design, data modeling, reporting process metadata, and ETL processes. Experience designing and implementing reporting and visualization for unstructured and structured data sets Experience designing and developing data cleansing routines utilizing typical data quality functions involving standardizatio n, t ransformation, rationalizatio n, linking and matching Knowledge of data, master data and metadata related standards, processes and technology Experience working with multi-Terabyte data sets Experience with Data Integration on traditional and Hadoop environments Strong oral and written communication skills, including presentation skills (MS Visio, MS PowerPoint). AI&DE23"
Data Engineer,LawVu,Remote,https://www.indeed.com/rc/clk?jk=93b057909c4a9686&fccid=66b3d60fa6168010&vjs=3,"LawVu is transforming the legal industry by providing the world’s leading and most loved platform for in-house legal teams. Our aim is to make the lives of in-house legal teams and their business partners more productive and fulfilling. We are well on the way with some of the world’s leading global brands and best in-house legal teams already operating on LawVu. Growing super fast, LawVu is headquartered in Tauranga, New Zealand with teams in Australia, USA, Ireland, Philippines, UK and the EU. Our culture is strongly values aligned where we look for people to bring their whole selves and join a team doing the best work of their lives. We have offices in Tauranga and Wellington however, this role can be done remote from anywhere in New Zealand. What you’ll do.. As a Data Engineer at LawVu, you will be a key member of our expanding team, working to enable and build on our core data and analytics capability. You will be a technical data specialist applying software engineering best practices to the production and maintenance of our cloud based modern data platform. This is a position requiring an innovative problem solving approach to designing and building creative data solutions that provide valuable insights, drive performance and lead to the delivery of our strategic objectives. Your work will include the development and enhancement of our data platform with the aim of inspiring positive change for both our internal and external customers. Internally you will be part of a team that works directly with key stakeholders from our product, customer success, and sales teams to ensure the delivery of a first class data and analytics platform. Key Responsibilities Design and development of a cloud based modern data platform with metadata driven approaches Utilisation of extraction, loading and transformation (ELT) best practices and principles Creation and maintenance of testing and documentation artifacts Development and maintenance of automated system monitoring for critical components of the data platform to ensure we maintain our high SLA’s Bring in new tools/technologies as necessary to make our systems more efficient and cost effective Skills and Experience 5+ years experience in data architecture and engineering roles Strong SQL skills and experience Experience with Azure and Python would be an advantage Outstanding organisational skills and the ability to multitask Outstanding listening, negotiation and presentation skills Excellent verbal and written communications skills What sets us apart: Monthly wellness allowance to use on whatever enables you to bring your whole self to work – gym membership, massage, childcare.. the list goes on! Health insurance cover Extended paid parental leave Extra paid day off on your birthday Share options so you can have a piece of the pie Home office allowance set up for remote employees"
BI Data Engineer,GoTo,Remote,https://www.indeed.com/rc/clk?jk=303d497cbf79f54d&fccid=75d8817dffc3069a&vjs=3,"Job Description Engineering at GoTo We’re the trailblazers of remote work technology. We build powerful, flexible work software that empowers everyone to live their best life, at work and beyond. And blaze even more trails along the way. There’s ample room for growth – so you can blaze your own trail here too. When you join a GoTo product team, you’ll take on a key role in this process and see your work be used by millions of users worldwide. The Corporate BI (CBI) Team is looking for a BI Data Engineer to help build and maintain standardized, actionable data sets to provide reporting for our executive and functional leaders. The BI Data Engineer will work closely with the team’s reporting analysts as well as a wide range of stakeholders to continue to build out and support our corporate metrics program. As the providers of standardized definitions and centralized reporting data sets, the CBI Team enables GoTo stakeholders, from analyst to sales rep to executive, to better understand and trust the KPIs used to measure the health of the company. Your Day to Day: As a BI Data Engineer you will: Collaborate with CBI Tableau reporting team and downstream stakeholders to build data sets supporting our enterprise reporting and analytics workbooks Design and document data models for use by our GoTo analytics teams Share ownership with other CBI Team members to maintain and grow our existing catalog of certified data sources Assist with establishing and upholding best data practices for ETL pipelines Support GoTo analytics teams by acting as a technical resource for solving complex problems with data Partner with the GoTo Data Engineering team to understand company data flows from source to target to reporting layers What We're Looking For: As a BI Data Engineer your background will look like: 2+ years’ experience in a business intelligence or data analytics role Proficient in SQL, data visualization tools a plus (Tableau), Python/PySpark a plus, Databricks a plus Experience with Salesforce/Sales reporting a plus Experience gathering requirements from business stakeholders and transitioning these to data sets for reporting and analytics Familiarity with traditional data engineering concepts a plus: Agile, data warehousing, big data optimization, git versioning control (Github/Bitbucket) Self-starter, detail-oriented, and excellent communication skills Demonstrated ability to troubleshoot code/queries You’ll be working towards a shared goal with an open-minded and cohesive team greater than the sum of its parts. At GoTo, we’re passionate about growing a diverse and inclusive work ecosystem because unique takes make us a stronger company, and Stronger Together. We’re committed to creating an inclusive space for everyone, no matter what. That’s how we’ll Be Real, Think Big, Move Fast, and Keep Growing along the way."
Data Engineer,Toyota,"Remote in Ann Arbor, MI 48103+2 locations",https://www.indeed.com/rc/clk?jk=13da15fe5e4f0f39&fccid=90f0cbc4a30f8dba&vjs=3,"Who we’re looking for Toyota’s Digital Solutions Department is looking for a passionate and highly motivated Data Engineer. The primary responsibility of this role is to solve complex data problems which will be used to deliver insights to help solve organizational goals for R&D. The Data Engineer will create data products used to increase productivity and deliver data pipelines for analytically driven use cases. Reporting to the Senior Manager, the person in this role will support the Digital Solutions department's objective of delivering analytic insights through a defined model development lifecycle which utilizes vehicle data (CAN300 communication bus and other vehicle systems) along with other appropriate sources of data as defined by the business requirements. What you’ll be doing Partner with key business stakeholders to understand priorities, identify strategic initiatives, and develop effective and timely analytic solutions Statistical analysis as needed to support these of business initiatives, such as customer segmentation and behavioral models Presentation and communication of analytic results utilizing appropriate tool(s) (Power BI, Tableau, R, Python, other) Review existing analytic processes to identify best practices and opportunities for improvement Providing valuable input into business intelligence roadmaps and development plans Mentor team members regarding analytic best practices Stay abreast of data governance and data management best practices and continually recommend and implement process improvements Support Data Governance steward with initiatives related to data governance and the maturation of the data governance organization Project Owner on company-wide data analytics initiatives Travel 5% Overtime 20% What you bring Bachelor’s degree (or higher) Professional relevant work experience Demonstrated ability to communicate effectively with all levels of an organization, both technical and non-technical team members Knowledge of predictive analytics techniques and statistical diagnostics of models. Expert resource for tool development Demonstrated ability to exchange ideas and convey complex information clearly and concisely. Has a value-driven perspective with regard to understanding of work context and impact. Proficient in an object-oriented programming language (Python, R, SAS or other). Willingness to learn new languages and technologies is mandatory What you may bring Degree in Statistics, Math, Economics/Econometrics or other related fields of study Skill in creating mathematical models, experience in AI, machine learning, engineering design Proven expertise in delivering data driven applications in the form of APIs, dashboards, or software packages Healthy curiosity about the industry and trends in data analytics Toyota ECU Design experience including Deep knowledge of the CAN bus Progressive years of experience in a mathematically driven field of study or career Toyota work experience What we’ll bring During your interview process, our team can fill you in on all the details of our industry-leading benefits and career development opportunities. A few highlights include: A work environment built on teamwork, flexibility and respect Professional growth and development programs to help advance your career, as well as tuition reimbursement Vehicle purchase & lease programs Comprehensive health care and wellness plans for your entire family Flexible work options based on business needs Toyota 401(k) Savings Plan featuring a company match, as well as an annual retirement contribution from Toyota regardless of whether you contribute Paid holidays and paid time off Referral services related to prenatal services, adoption, child care, schools and more Flexible spending accounts Relocation assistance (if applicable) To save time applying, Toyota does not offer sponsorship of job applicants for employment-based visas or any other work authorization for this position at this time. This role is open to potential remote opportunities. #LI-REMOTE"
Data Analytics and Modeling Engineer,Electric Hydrogen,Remote,https://www.indeed.com/rc/clk?jk=bc976db0081b06b0&fccid=aaf79cebbf46296a&vjs=3,"Electric Hydrogen’s mission is to create an abundant and decarbonized material future. Our outstanding people are our most important asset and will allow us to deliver hydrogen from renewable electrolysis for heavy industry, at prices below fossil fuels. We are looking for a Data Analytics and Modeling Expert to develop and analyze aspects of electrolytic hydrogen production, storage, and transport with a focus on optimizing cost and performance. You will be a team player who loves learning, analyzing data, optimizing solutions with a deep passion for cleantech. You will be part of the Product Management team and be based in our offices in the greater Boston area (Natick MA), or the San Francisco Bay area (San Carlos CA). Remote options can also be considered. WHAT YOU'LL DO Contribute to EH2’s analytics toolkit development. Modeling electrolysis plants performance and cost. Learn and Develop optimization algorithms to determine lowest cost green hydrogen plant configuration. Extract insights from data and models output to guide product and plant development. Engage with customers to understand their analytics needs. Contribute to the delivery of feasibility studies to customers. Undertake research into new technologies to produce, transport, storage and use hydrogen-derived fuels and chemicals. Apply Data visualization skills to advance EH2’s dashboards. REQUIRED EXPERIENCE AND PROFESSIONAL QUALITIES Bachelor’s (an advanced degree preferred) in an engineering or quantitative discipline such as economics, mathematics, and statistics. Quantitative, rigorous person with experience in developing, documenting, and maintaining models energy system modeling experience is preferred. Techno-economic modeling skills. Experience working with large databases, data visualization and dashboarding tools (e.g.Tableau, PowerBI), and statistical analyses. Knowledge of python and/or Matlab to perform complex analyses and data visualization. Able to work well in a highly entrepreneurial environment with teams and with customers on a regular basis. A deep passion for renewable energy and combating climate change. PREFERRED EXPERIENCE Masters in a relevant engineering discipline (A degree in mechanical engineering with a thermal science focus or chemical & process engineering preferred) with 1 or 2 years of a first post-graduate professional experience. A detailed understanding of hydrogen production technologies. Experience at startups or early-stage companies. Employee Benefits Electric Hydrogen offers the best benefits possible. We pay 100% of all employees' health/dental/vision/disability insurance premiums and 100% of the premium for their immediate family. This is for all of our full-time employees. We feel strongly that our team should not have to worry about having quality healthcare. We also offer a generous 401k match and unlimited time-off. About Electric Hydrogen Electric Hydrogen is a team of the world's experts in scaling technologies for the post-carbon world, with a proven record in transforming the grid and transportation sectors. Backed by some of the world's top venture capital firms, we design and manufacture electrolytic hydrogen systems matched to renewable power sources to create green hydrogen by splitting water. We are building a cost-effective and transformative path between renewable energy and multiple large industrial sectors. Abundant and low-cost renewable energy sources will power the world, and Electric Hydrogen technology will use this energy to decarbonize industry through sustainable materials. We were founded in 2020 and is based in California and Massachusetts. Electric Hydrogen is proud to be an equal opportunity employer dedicated to building an inclusive and diverse workforce."
Data Engineer,Illumination Works LLC,"Remote in Cincinnati, OH+2 locations",https://www.indeed.com/rc/clk?jk=120cb8da6b1e7540&fccid=33ebdcb809a3b1a3&vjs=3,"Location and Travel Details: Remote The key responsibilities of the Data Engineer include: Work closely with data architects to ingest, integrate, and prepare database structures needed for reporting, analytics, and visualizations Heavily involved in the ETL process and must be motivated to be collaborative with the team members to understand and implement data requirements Do you have what it takes? Are you driven to implement creative solutions that unravel complex and ever-changing challenges? We value passion, curiosity, and perseverance with an ability to communicate ideas and results to diverse audiences. We look for people who thrive in collaborative and independent assignments, have the aptitude to learn new data quickly, and who are willing to mentor junior team members. Key skills for this position include: Database design and principles Data modeling, schema development, and data-centric documentation Experience integrating data from a variety of data source types Recommend and advise on optimal data models for data ingestion, integration, and visualization Develop and maintain ETL pipelines Strong SQL skill Experience improving code performance and query optimization to meet demanding data analytic and visualization needs Outstanding problem-solving skills Excellent verbal and written communication skills and ability to interact professionally with a diverse group, executives, managers, and subject matter experts Minimum education: Bachelor’s degree in Computer Science, Mathematics, or comparable academic discipline Minimum experience requirements: five years of experience required Must have or be willing to obtain Secret Clearance (this requires US Citizenship) Acceptable candidates must successfully pass a drug test and background screen Desired Experience: Experience with Analytics Cloud technologies – SAP Analytics Cloud, Oracle Analytics Cloud Insurance experience Experience with financial data Experience with ETL tools (SSIS or DataStage is preferred) Experience working with various Data Storage Technologies, Oracle, SQL Service A little more about us. At Illumination Works, we know data, and we should, we’ve been doing it since we started in 2006! We specialize in everything data from big data to data science, software engineering, data management, AR/IoT, and cloud development. Illumination Works is a trusted technology partner in user-centered digital transformation—delivering impactful business results to clients. We partner with customers to solve their unique technology and data challenges, and stay on top of modern technologies and advancements leveraging our Innovation Lab. Why choose us? We invest in our employees in all aspects of their life and we value family. We offer market competitive salary, a generous PTO package, and comprehensive medical, dental, vision and life insurance plans. We also offer 401K, short/long-term disability insurance, a fun and engaging culture, and training opportunities to keep you up to speed on the latest technologies. Illumination Works is committed to hiring and retaining a diverse workforce. We are an Equal Opportunity Employer, making decisions without regard to race, color, religion, sexual orientation, gender identity or national origin, age, veteran status, disability, or any other protected class. Acceptable candidates must successfully pass a drug test and background screen."
Data Analytics Engineer - Tealium,InfoTrust,"Remote in Cincinnati, OH+1 location",https://www.indeed.com/rc/clk?jk=66b9e58263a37f93&fccid=16a2f3e58cc251fd&vjs=3,"InfoTrust was started with one mission - to build the best place to work and all other things would fall into place. This mission has proven to be very successful, as shown by our multiple best places to work awards, our amazing eNPS (94), our significant impact to our community through the InfoTrust Foundation, and our happy clients with a NPS of 74 and strong employee retention rates. At InfoTrust, we are extremely proud of our core values, particularly our insistence on continuously innovating and growing our expertise within the analytics space. One of those innovations was the creation of our Consumer Data Governance team (CDG) just a few years ago. Due to the CDG team's expertise in the field today, we are now looking to expand the team with a Data Analytics Engineer with Tealium experience. The Data Analytics Engineer is equal parts technical and equal parts consulting. As an advocate for a strong tag management strategy, you will work with clients to strategize, complement, and support their data governance process. If you are unfamiliar with tag and data governance, check out this site. Responsibilities of the Data Analytics Engineer: Working with clients to support their marketing tagging needs to support their marketing initiatives Providing guidance internally and externally regarding the best practices in digital analytics as it relates to tag management (tools such as Google Tag Manager, Adobe Launch, Tealium, and more) Management of client's ticketing systems such as JIRA and working with different departments to gather all the technical requirements of a tagging request Implementation of tagging best practices and tag governance by working with the organization's Tag Governance team Advocating the usage of InfoTrust's proprietary tool, Tag Inspector, in making sure that the state of tag implementation is working as expected Working with the Product team to provide feedback about the product. Often collaborate within the internal Customer Data Governance, Product, and Delivery and Analytics teams Creation of documentation about processes, inventory of tags, and status updates regarding the client engagement Constantly provide open communication with the client, offering amazing support, thought leadership, and expertise in the cutting edge (and very important) space of data governance The successful Data Analytics Engineer will have the following background and skills: 2 years of experience with tag management systems, specifically Tealium. You can exemplify a strong grasp on how to implement, maintain, and use tag management systems to assist clients with their marketing strategies You are familiar with, or willing to learn more about, privacy and data protection laws and regulations. Additionally, you are familiar with how to apply data governance for the needs of large, multi-brand sites You have experience working with clients and exemplifying great communication and rapport with clients to ensure satisfaction, understanding, and collaboration When working with clients, you have exemplified project management and delivery skills You are driven, looking for ways to constantly learn You are resourceful and able to pivot quickly, as needed You are known for helping clients be more efficient and apply best practices for governance process You enjoy a collaborative environment where you're enabled to do your best work and make an impact Nice to have: Although it is not required, it would be nice if the Data Analytics Engineer has experience with tag governance, TagInspector.com, and building process and plans related to tag governance strategy It would be nice to be relocated close to our offices in Cincinnati, OH or Chicago, IL, but we are open to a fully remote position within the United States or Toronto, Ontario Location: Currently, returning to the office is optional for our Cincinnati and Chicago employees. We prefer candidates who live in one of those two metro areas, but we are open to someone working fully remote from the US or Toronto, Ontario, Canada. Must be authorized to work in US or Canada for any employer. Additional benefits: Other than an awesome culture and team mates we also offer: 100% employer paid medical, dental and vision insurance (seriously), Unlimited PTO, flexible work schedule, a generous parental leave policy, 401K with company match, tuition reimbursement, gym reimbursement and much, much more. Diversity is one of our 6 core values at InfoTrust: InfoTrust is committed to a diverse workforce and we are an equal opportunity employer. We want strong, diverse teams built from different backgrounds, experiences and identities. We are building an inclusive, supportive place for you to do the best work of your career."
Data Science Analyst/Engineer,NYU Langone,"New York, NY 10016 (Tudor City area)",https://www.indeed.com/rc/clk?jk=3a2e41ae97537f6c&fccid=848e72c84ce4a7a7&vjs=3,"NYU Grossman School of Medicine is one of the nation's top-ranked medical schools. For 175 years, NYU Grossman School of Medicine has trained thousands of physicians and scientists who have helped to shape the course of medical history and enrich the lives of countless people. An integral part of NYU Langone Health, the Grossman School of Medicine at its core is committed to improving the human condition through medical education, scientific research, and direct patient care. For more information, go to med.nyu.edu, and interact with us on LinkedIn, Glassdoor, Indeed, Facebook, Twitter and Instagram. Position Summary: We have an exciting opportunity to join our team as a Data Science Analyst/Engineer. In this role, the successful candidate is a part of the Medical Center IT (MCIT) department and the Center for Healthcare Innovation and Delivery Science. The mission of the unit is to apply the latest advances in machine learning and predictive analytics toward solving clinically and operationally significant prediction and classification problems across the medical center. We are both an operational and academic group that is interested in applying machine learning in healthcare settings and pushing the boundaries of academic research. This individual will be positioned to contribute to analytics efforts at NYU. By teaming up with clinicians, operations and administrative teams, the individual will develop innovative and impactful data, driven healthcare solutions. This position will be shared with Finance. The Data Scientist/Engineer will report to Dr. Aphinyanaphongs, while working closely with other members of the unit and NYU healthcare community at large. Job Responsibilities: Design and build data solutions using state of the art machine learning and informatics methods; deploy and integrate these products within the larger ecosystem of healthcare infrastructure at NYULMC Prepare and present results, reports, both oral and written, to a variety of audiences, concerning processes, models, evaluation, and impact (ROI) Collaborate with the overall NYULMC healthcare community and contribute to ongoing predictive modeling / analytics efforts Build and engineer workflows to collect, store, clean and process structured as well as unstructured data, verify their integrity and appropriateness for specific business processes and analytics systems Work with large, complex and noisy clinical datasets for solving challenging problems in the healthcare domain Minimum Qualifications: To qualify you must have a 1. Masters degree in a quantitative discipline (Biomedical Informatics, Computer Science, Machine Learning, Applied Statistics, Mathematics or similar field) 2. Proficiency in at least one programming language (Python, R) and machine learning tools (scikit learn, R) 3. Knowledge of predictive modeling and machine learning concepts, including design, development, evaluation, deployment and scaling to large datasets 4. Familiarity with computing models for big data Hadoop / MapReduce, Spark etc. 5. Knowledge of databases (Relational / SQL, NOSQL, MongoDB, etc.) 6. Good grasp of software engineering principles. Experience in integrating modern software architectures 7. Knowledge and some experience in operational aspects of software development and deployment, including automation, testing, virtualization and container technology 8. Knowledge of clinical and operational aspects of healthcare delivery 9. Excellent written and oral communication skills for a variety of audiences Preferred Qualifications: 1. PhD degree in a quantitative field (Biomedical Informatics, Computer Science, Machine Learning, Applied Statistics, Mathematics or similar field) + 2 years experience 2. Demonstrated skills in design and implementation of complex machine learning models 3. Demonstrated knowledge of software engineering and operational skills through prior projects. Qualified candidates must be able to effectively communicate with all levels of the organization. NYU Grossman School of Medicine provides its staff with far more than just a place to work. Rather, we are an institution you can be proud of, an institution where you'll feel good about devoting your time and your talents. NYU Grossman School of Medicine is an equal opportunity and affirmative action employer committed to diversity and inclusion in all aspects of recruiting and employment. All qualified individuals are encouraged to apply and will receive consideration without regard to race, color, gender, gender identity or expression, sex, sexual orientation, transgender status, gender dysphoria, national origin, age, religion, disability, military and veteran status, marital or parental status, citizenship status, genetic information or any other factor which cannot lawfully be used as a basis for an employment decision. We require applications to be completed online. If you wish to view NYU Grossman School of Medicine's EEO policies, please click here. Please click here to view the Federal ""EEO is the law"" poster or visit https://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm for more information. To view the Pay Transparency Notice, please click here. Required Skills Required Experience"
(Junior / Senior) Data Engineer - Sports Analytics,Zelus Analytics,"Remote in Austin, TX",https://www.indeed.com/rc/clk?jk=1b23ea790833098b&fccid=80816981c594885b&vjs=3,"We are seeking data engineers with a passion for sports to develop cloud-based data pipelines and automated data processing for our world-class sports intelligence platforms in baseball, basketball, cricket, football (American), hockey, soccer, and tennis. Through your work, you can support the professional teams in our exclusive partner network in their efforts to compete and win championships. We currently have both entry-level and senior positions available, allowing us to consider qualified candidates with a wide range of experience levels. Zelus Analytics unites a fast-growing startup environment with a research-focused culture that embraces our core values of integrity, innovation, and inclusion. We pride ourselves on providing meaningful mentorship that offers our team the opportunity to develop and expand their skill sets while also engaging with the broader analytics community. In doing so, we hope to create a new path for a more diverse group of highly talented people to push the cutting edge of sports analytics. We believe that a diverse team is vital to building the world's best sports intelligence platform. Thus, we strongly encourage you to apply if you identify with any marginalized community across race, ethnicity, gender, sexual orientation, veteran status, or disability. At Zelus, we are committed to creating an inclusive environment where all of our employees are enabled and empowered to succeed and thrive. As a Zelus Data Engineer, you will be expected to: Design, develop, document, and maintain the schemas and ETL pipelines for our internal sports databases and data warehouses Implement and test collection, mapping, and storage procedures for secure access to team, league, and third-party data sources Develop algorithms for quality assurance and imputation to prepare data for exploratory analysis and quantitative modeling Profile and optimize automated data processing tasks Coordinate with data providers around planned changes to raw data feeds Deploy and maintain system and database monitoring tools Collaborate and communicate effectively in a distributed work environment Fulfill other related duties and responsibilities, including rotating platform support In addition to the above, a Senior Data Engineer will be expected to: Break down complex data engineering projects into actionable work plans including proposed task assignments for one to four engineers Identify and recommend new ETL tools and novel data sources to push the cutting edge of our sports intelligence platforms Provide guidance and technical mentorship for junior engineers Assist with recruiting and outreach for the engineering team, including building a diverse network of future candidates A qualified entry-level candidate will be able to demonstrate several of the following and will be excited to learn the rest through the mentorship provided at Zelus: Academic and/or industry experience in back-end software design and development Experience with ETL architecture and development in a cloud-based environment Fluency in SQL development and an understanding of database and data warehousing technologies Proficiency with Python (preferred), Scala, and/or other data-oriented programming languages Experience with automated data quality validation across large data sets Familiarity working with Linux servers in a virtualized/distributed environment Strong software-engineering and problem-solving skills A qualified senior candidate will be able to demonstrate all of the above at a higher level of competency plus the following: Expertise developing complex databases and data warehouses for large-scale, cloud-based analytics systems Experience with task orchestration and workflow automation tools (Airflow preferred) Experience building and overseeing teamwide data quality initiatives Experience adapting, retraining, and retooling in a rapidly changing technology environment Desire and ability to successfully mentor junior engineers Zelus has a fully distributed workforce, spanning fifteen states and six countries. In addition to competitive salaries, our compensation packages include equity and benefits, such as an annual incentive bonus plan and flexible PTO, that allow us to attract and retain a world-class team. As an equal opportunity employer, Zelus does not discriminate on the basis of race, ethnicity, color, religion, creed, gender, gender expression or identification, sexual orientation, marital status, age, national origin, disability, genetic information, military status, or any other characteristic protected by law. It is our policy to provide reasonable accommodations for applicants and employees with disabilities. Please let us know if reasonable accommodation is needed to participate in the job application or interview process. Zelus is an at-will employer; employment at Zelus is for an indefinite period of time and is subject to termination by the employer or the employee at any time, with or without cause or notice. Pay: $75,000.00 - $150,000.00 per year"
Data Engineer,The Stable,"Remote in Bentonville, AR 72712",https://www.indeed.com/rc/clk?jk=d5c1d131804190a9&fccid=fa9a102fd393ce9d&vjs=3,"Data Engineer Bentonville, AR The Company: The Stable is a fully-integrated commerce agency that connects brands and consumers across all retail and digital channels. Leveraging a full suite of omnichannel capabilities, including retail representation, eCommerce services, in addition to creative and digital media, we generate revenue for brands across brick-and-mortar and direct-to-consumer (DTC) channels. Fueled by data and real-time insights, we create industry-leading strategies that drive sales and scale brands. Like what you hear? We invite you to get up out of your chair, walk to your boss’s office (or Zoom), quit your job and come work for us! We’re looking for a full-time Data Engineer to join our team ideally in Bentonville, AR but are open to remote candidates anywhere.. All About You: You’re a self-starter, who has a passion for using numbers to tell a compelling story. You get excited about building and optimizing data sets, pipelines and architectures. You love the idea of supporting a dynamic and growing organization and making your mark on a business process because you are driven to provide value to the business anyway you can! The Job: As a Data Engineer, you will be: Assembling large, complex sets of data that meet non-functional and functional business requirements Identifying, designing and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies Building analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition Working with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues Working with stakeholders including the SVP Platform Engineering, Product, Analytics & Insights and Business teams to support their data infrastructure needs while assisting with data-related technical issues The Qualifications: Experience with Sisense, Looker, Tableau, and PowerBI is a major plus Experience in Workflow orchestration tools such as Airflow etc. Experience with container management frameworks such as Docker, Kubernetes, ECR etc. Experience with Cloud based DW such as Redshift, Snowflake etc. Experience writing data transformations/logic via python The Stable strives to create a culture and environment that is inviting, encouraging and supportive of people from all backgrounds so that diverse voices, thoughts and perspectives may be heard and amplified. All are encouraged to apply. Thank you"
QA Engineer (Manual & Automation) - Data Feeds Testing/ETL,Haven Technologies,"Hybrid remote in New York, NY 10010",https://www.indeed.com/rc/clk?jk=2637e0840d37bfc5&fccid=3e5e72b4d1c6b869&vjs=3,"Haven Technologies has built deep capabilities in the life, annuity and disability insurance spaces. And now, our tech is your tech. The same purpose-built platform and expertise that have helped us delight customers, transform complex, advisor-driven businesses, and launch groundbreaking products with speed are available to everyone as a SaaS offering. Insurance carriers can use our advanced solutions for new business, in-force management and product development. But Haven Technologies is not just, well, all about technology. Our people and culture make our product. We believe magic happens when people have an opportunity to work with amazing colleagues and build things that matter. As a team made of over 300+ dreamers, possibility-seekers and difference-makers, we are focused on taking on challenging problems to create simple, more accessible, and more customer centric solutions. We're located in New York's Flatiron District and in case you're wondering, yes, we provide free snacks. Cold brew too. If you're creative, professional and kind, we'd love to hear from you. Curious about what it's like to work with us? Read about our culture and values here! Let's change the future of life insurance. Together. ABOUT THE ROLE You will be responsible for managing and executing the testing of our advanced insurance applications and platform. You will need to learn and understand our products at a detailed level and work with the team (primarily made up of developers, product managers, and other QA engineers) to ship high-quality products or features every two weeks. This role entails a mix of manual and automation work. We expect the automation component to grow over time, especially as driven by the person in this role once they understand the unique needs of the data team. Coding tests and automation questions are a part of the selection process for this role. Also, a Computer Science or related degree is strongly preferred. What you will do: Work with product owners and the developers to understand the requirements around data feeds and the required data mapping. As a part of feature testing, generate large feeds and review every data element to ensure compliance with the requirements. Perform regression testing to ensure that unintentional changes are not breaking data feeds. Contribute towards building and maintaining the automated regression testing suite Some of your testing responsibilities will include: Be accountable for highly complex products as the primary QA for the data team Lead or perform software test projects and tasks Review epics and stories, define the right test plan and criteria for them, and provide effort estimates Establish clear expectations of scope and timing of all testing deliverables with the team Define, execute, and document manual tests, test data, and test results with necessary detail Communicate test results to the team and help prioritize and resolve any issues Analyze and debug production defects and work with the team to prioritize and resolve them Deploy and troubleshoot local, sandbox, and/or CI/CD environments to enable testing Identify ways to make the testing process and surrounding processes more efficient and effective over time Document knowledge that will be useful for new team members looking to test your product and its dependencies Some of your automation responsibilities will include: Document and prioritize test cases for automation Automate some test cases and add them to the existing automation framework Run automated test cases during sprint testing, UAT testing, etc. Run and analyze reports for automated test results REQUIREMENTS These skills are essential for success in this position: Minimum 5 years of QA experience on web applications in multi-application production environments. Experience with multiple types of testing, for example, regression testing, ad hoc testing, feature testing, user acceptance testing, user interface testing, integration testing, performance testing, security testing, etc. Experience in creating, running and maintaining automated tests. Good knowledge of TypeScript. Hands-on experience working with Docker and setting up Docker dependencies between various applications. Good knowledge and hands-on experience of SQL and Excel/Google Sheets. Excellent communication skills, both oral and written. Strong problem solving and root cause analysis skills, including debugging and log analysis Authorized to work in the US without sponsorship now or in the future These skills are a plus: Bachelor's degree or equivalent work experience. Computer Science or related degree strongly preferred. Ability and willingness to look into code bases outside one's direct responsibility to identify potential failure points. Extensive experience with the Agile methodology and frequent releases. Experience in multi-platform testing (desktop, tablet, mobile) and multi-browser testing. Experience with quality assurance metrics and reporting. Intermediate coding skills. Ability to set up and troubleshoot local and sandbox environments. BENEFITS We have a stellar team of co-workers, a really cool office, a flexible hybrid work schedule, and lots of fun activities. Oh yeah, and we pay competitive base salaries and we reward performance. Our salary structure is commensurate with experience. In addition, you will be eligible to participate in our comprehensive benefits program including medical insurance and 401(K). We believe that one of the benefits to working here is our people and culture! We're proud to share that we've been consistently named a top workplace by Great Places to Work (#11 Best Workplaces in New York, #15 Best Workplaces in Financial Services and Insurance) and BuiltIn (Top 10 Best Midsize Company to Work For in NYC)! As part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. These requirements may include sharing information in our vaccine record tool, vaccination or regular testing, mask-wearing, social distancing, and daily health checks. Requirements may change in the future with evolving public health landscape. Haven Technologies will consider all legally required exemptions and accommodation requests."
Data Engineer,Workiva,"Remote in Denver, CO",https://www.indeed.com/rc/clk?jk=234411e471995ee5&fccid=c74820549fd8456b&vjs=3,"Summary The Data Engineer at Workiva will be an instrumental part of data workflows throughout the organization. You will build distributed services to support multiple data analytics teams and business intelligence engineers reliably and at scale using AWS cloud environments. Provide cutting edge, reliable, and easy to use systems for ingesting and processing data and help the teams that build data intensive applications be successful. This role will collaborate with many cross functional teams on the planning, execution, and successful completion of technical projects with the ultimate purpose of improving customer experience. The role will build and maintain batch and real-time data flows used for business intelligence, analytics, and machine learning within all organizations across Workiva. This also involves storing and exposing data via a Database, Data Lake, and other APIs. This role will work primarily with other Data Engineers, but also Data Scientists, ML Engineers, and business partners to ensure quality, reliability and performance at the highest level. What You'll Do Develop data extraction and integration code modules for batch and incremental data flow from various data sources using new and existing patterns. Use existing tools and processes to deploy to integration and production environments. Assist in maintaining the deploy processes. Maintain the health of the data ecosystem by configuring monitors, defining alerts on common failure points and giving feedback on data quality to data owners and business partners. Test software, validate data and write automated tests (unit, integration, functional, etc.). Review peer code and submit thorough and actionable feedback based on team standards and industry best practices. Triage and resolve production issues. Communicate with individual business partners on status. Escalate as needed. Design data lake storage and access patterns to match customer requirements and conform to naming standards. Understand the data at a deep level and apply security appropriately, escalate as needed. Tune processes and SQL to reduce cost and wait time. Implement systems to balance data volume, latency and customer requirements. Work with business partners to write requirements and test deployed code. Join rotation to support production workflows during off hours. What You'll Need Education Undergraduate Degree or equivalent combination of education and experience in a related field. Bachelor’s degree in Computer Science, Engineering, Math, Finance, Statistics or related discipline Skills Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams Strong planning and organizing skills to prioritize numerous projects and ensure data is delivered in an accurate and understandable manner to the end user Experience 2+ years of relevant experience in the data engineering role, including data warehousing and business intelligence tools, techniques and technology, or experience in analytics, business analysis or comparable consumer analytics solutions Statistics experience preferred Experience in big data processing and using databases in a business environment with large-scale, complex datasets. (SQL, Hadoop, Spark, Flink, Beam etc) Knowledge and direct experience using business intelligence reporting tools. (Quicksight, Tableau, Splunk etc.) Extensive knowledge of SQL query design and tuning for performance and accuracy Experience with Python, R, or other data relevant scripting languages preferred Experience with Data Lake design and philosophy Experience in an Agile/Sprint working environment preferred Proficient research skills to locate market information using numerous internal and external sources of data Travel Less than 10% Working Conditions & Physical Requirements Reliable internet access for any period of time working remotely, not in a Workiva office. How You'll Be Rewarded Base Pay Range in Colorado: $91,000 - $127,000 A discretionary bonus typically paid annually Restricted Stock Units granted at time of hire 401(k) match The base pay range represents the low and high end of the hiring range for this job. Actual pay will vary and may be above or below the range based on various factors including but not limited to relevant skills, experience, and capabilities. Where You’ll Work Our values drive how we work and who we hire. You will see these values ingrained in how we support our customers, work with team members, build our products and in the work environment we’ve created. Customer Success: Always delight our customers. Trust: Rely on each other. Integrity: Do the right thing, every time. Collaboration: Share resources and work together. Innovation: Keep creating solutions and finding better ways. Inclusion: Support a diverse community where we all belong. Accountability: Be responsible for your success and failure. We believe our people are our greatest asset, and our unique culture gives employees the opportunity to make an impact everyday. We give our employees the freedom and resources they need—backed by our culture of collaboration and diverse thought—to continue innovating and breaking new ground. We hire talented people with a wide range of skills and experiences who are eager to tackle some of today’s most challenging problems. At Workiva, you’ll enjoy: Fantastic Benefits: With coverage starting day one, choose from competitive health, dental, and vision plans on the largest physician networks available. Casual Dress: Workiva has a casual work environment, most people wear jeans to the office. Involvement: Ability to participate in Employee Resource Groups, (Women in Tech, Women in Sales, Ethnic Diversity, Veterans, Rainbow (LGBTQ), Remote Employees, Caregiving) Volunteering, Company wide celebrations, and more Work-life Balance: We have competitive PTO, VTO and Parental Leave. We encourage employees to spend time enjoying life outside of work. Learn more about life at Workiva: https://www.linkedin.com/company/workiva/ Learn more about benefits: https://www.workiva.com/careers/benefits Workiva is an Equal Employment Opportunity and Affirmative Action Employer. We believe that great minds think differently. We value diversity of backgrounds, beliefs, and interests, and we recognize diversity as an important source of intellectual thought, varied perspective, and innovation. Employment decisions are made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression genetic information, marital status, citizenship status or any other protected characteristic. Workiva is committed to working with and providing reasonable accommodations to applicants with disabilities. To request assistance with the application process, please email talentacquisition@workiva.com . Workiva supports employees in working where they work best - either from an office or remotely from any location within their country of employment. Effective October 18, 2021, proof of COVID-19 vaccination is required to visit any Workiva office, attend in-person meetings, or travel for business purposes."
Data Engineer - (Immediate Opening),IDEA Public Schools,"Weslaco, TX 78596",https://www.indeed.com/rc/clk?jk=8ddc024b32cb2554&fccid=4c58f1f52a144526&vjs=3,"Role Mission: The Data Engineer will be responsible for improving IDEA’s operational processes and supporting critical strategies by assisting in the new development and implementation related to our internal applications systems. The Engineer will deliver the testing, ongoing evaluation, and validation of organizational data structures and identify issues in current processes while providing proven strategies for ongoing database and data warehouse development relating to internal custom applications development and deployment. This position will provide recommendations and insight on IDEA’s IT operations and strategy from an applications development standpoint. This job requires the ability and desire to work and communicate well in a dynamic team environment as well as dependability and self-sufficiency. What You’ll Do – Accountabilities : On-time Product Delivery: Drive to and maintain on-time development and delivery of high-quality features for custom applications and business intelligence tools as defined by monthly sprint plans as measured by: % of Critical defects due to SQL code changes and ETL functioning should be limited to a max of 5% % of spilled over development tasks should be limited to a max of 5% Should acquire the complete ownership of at least 20% of the features developed % of reopened defects should be limited to a max of 2% Effective Requirements Analysis: New major product work and execution is detailed with full requirements analysis and effective preparation for sprint planning, with detailed task/effort estimates as measured by: Difference between estimated effort and actual effort should be limited to a max of 15% and decrease gradually Defects due a mis-match in understanding of the requirements should be limited to a max of 10% Efficient Object-Oriented Analysis and Design: Thorough object-oriented analysis and design of features with the documentation of necessary design artifacts as measured by: Refactoring time to enhance/improve SQL code changes and ETL development should be less than 15% of the original effort. At least 20% of the code developed should be reusable Reuse of code should be leveraged when possible. Duplication, if any, should be limited to a max of 5%. Adherence to Effective Scrum Practices: Adhering to all of the Scrum processes, with active and punctual participation in Scrum meetings as measured by: Absenteeism in scrum ceremonies including daily huddles, retrospectives, product reviews, and planning sessions should be limited to a max of 5% with prior intimation All planned leaves (both short and long duration) should be intimated in advance and documented so that sprint commitments are not affected. Deviation should be limited to 5%. Unplanned leaves (both short and long duration) should be intimated as soon as possible and documented so that sprint commitments are not affected. Deviation should be limited to 5%. Continuous Improvement of Domain, Technical, and Behavioral Skills: Continuously enhancing the Product domain knowledge, technical, and behavioral competencies to grow to the next level as measured by: Relevant trainings/actions need to be identified, planned and attended 3 times within the year (1 skill from each area – domain, technical, and behavioral) Development and demonstration of these skills for the purpose of the facilitation of team training and/or mentoring should be developed for each team member (1 opportunity per year) We look for Team and Family who embody the following values and characteristics: Believes and is committed to our mission and being an agent of change: that all students are capable of getting to and through college Has demonstrated effective outcomes and results, and wants to be held accountable for them Has a propensity for action, willing to make mistakes by doing in order to learn and improve quickly Works with urgency and purpose to drive student outcomes Thrives in an entrepreneurial, high-growth environment; is comfortable with ambiguity and change Seeks and responds well to feedback, which is shared often and freely across all levels of the organization Works through silos and forges strong cross-departmental relationships in order to achieve outcomes We believe in education as a profession and hold ourselves to high level of conduct, professionalism and behaviors as models for our colleagues and students Note: At IDEA, the Data Engineer role is a mid to high level role with a focus on building upon the IDEA data warehouse. The IDEA data warehouse is the central data store for all analytics and reporting. As a result, the Engineer is responsible for data extraction, transformation, and loading of data into the data warehouse and is the primary keeper of this system. These processes require strong skills with a variety of specialized tools and techniques for data cleansing, preparation, modeling, and integration. This role is also required to have a strong background in analytics and server-side processing. Supervisory Responsibilitie s : This role leads and oversees the work of others in a project capacity as a project technical lead: Planning and directing Data Integration/ETL Developer team member activities on projects Assigning work Overseeing proper maintenance and back-up of source code Participation in evaluating performance (for Data Integration/ETL Developers) Mediating conflict resolution Qualifications: Education: Bachelor's degree from four-year college or university in Information Technology, Computer Science, Computer Engineering, and Software Engineering Experience: 6+ years related work experience and/or training; or equivalent combination of education and experience. Certification/License: Microsoft Certified Solutions Associate (SQL 2016 BI Development), Certified Associate in Project Management (CAPM) preferred What We Offer Compensation: Salaries for people entering this role typically fall between $66,626 and $80,618, commensurate with relevant experience and qualifications and in alignment with internal equity. This role is also eligible for a performance bonus based on individual and organizational performance and goal attainment. Other Benefits: We offer a comprehensive benefits plan, covering the majority of the employee premium for the base medical plan and subsidizing the majority of costs for a spouse/domestic partner and children. Other benefits include dental and vision plans, disability, life insurance, parenting benefits, flexible spending account options, generous vacation time, com‐muter benefits, referral bonuses, professional development, and a 403(b) plan. We also offer an inclusive environment where staff are encouraged to bring their whole selves to work every day. IDEA may offer a relocation stipend to defray the cost of moving for this role, if applicable. To Apply : Please submit your application online through Jobvite. It’s in your best interest to apply as soon as possible. It is recommended that you include a cover letter in your application addressing why you are interested in IDEA and how your experience has prepared you for this position."
Data Engineer,New York Jets,"Florham Park, NJ 07932",https://www.indeed.com/rc/clk?jk=3bbe3a9fb54e8614&fccid=12977fdd42742d39&vjs=3,"Data Engineer Description: This position will be working to design, implement and maintain a Data Warehouse solution. Collaborating with key stakeholders across many departments to meet their needs for scalable analysis, modeling and automated reporting. It will oversee the migration of current practices to new ones that will scale with the expanding need for accurate and actionable data throughout the Jets organization. Essential Duties & Responsibilities: Develop and maintain a Data Warehouse to manage the company’s data and data needs Develop, implement, optimize, and continuously troubleshoot Extract / Transform / Load (ETL) processes Design data models and architecture to support reporting and analytical processes, working with Business Intelligence & Analytics and administrators of business systems to identify efficiencies Develop processes ensuring data standards, security, stewardship, lineage, and metadata management Create strategies to resolve, clean, enrich, and unify data of various types from disparate data sources and subsequently surface unified data to business applications Support analytics work done by team data analysts by translating requirements into scalable technical solutions Oversee all aspects of data warehouse operations, including defining and resolving database problems, tuning for performance, and managing storage Identify, obtain, and integrate new data sources useful for company problems Support business report creation across multiple departments from the Data Warehouse including metadata mapping, Business Intelligence technology use, and overall automation of standardized reporting and processes across the organization Collaborate with the Jets IT department to scope out and setup necessary infrastructure Collaborate with Jets IT department and other system administrators to implement vendor sourced software, configuring that software, customizing, and integrating it with internal systems, including the data warehouse Ensure data compliance as dictated by organizational Privacy and Security Policies Responsible for appropriate documentation development, including requirements, design, code documentation, test plans, and other related documents Qualifications: Bachelor’s degree or higher in Computer Science, Information Systems, Computer Engineering or related field Industry experience in Data warehousing design, Data Integration, and Business Intelligence Experience using APIs returning JSON, XML, CSV formatted data Knowledge of cloud computing platforms, Azure/AWS Experience with dbt, Databricks, Snowflake, Melissa Data services a plus Ability to prioritize needs, deal with ambiguity, and deliver results in an evolving data landscape Experience supporting or using statistical and/or data mining applications Enjoy learning new technologies, conducting unsupervised research, and sharing findings Required Skills: Expert knowledge of T-SQL; MS SQL server experience a plus Knowledgeable about software development life cycle best practices and long-term maintainability of code Ability to effectively diagnose, isolate, and resolve complex problems pertaining to data infrastructure, integrity, and incompatibilities Experience with some programming language, such as Python/C#/VB.NET/R GENERAL INFORMATION A background check will be conducted prior to the start of the position. The New York Jets are proud to be an equal opportunity employer. It is the policy of the Company to provide equal employment opportunities to all employees and applicants for employment without regard to race, creed, color, religion, sex, national origin, age, disability, marital status, military status, genetic information, sexual orientation, gender (including gender nonconformity, status as a transgender individual, gender identity or expression), pregnancy, childbirth or related medical conditions, sexual orientation, affectional orientation, marital status, civil union status, and domestic partnership status, age, physical or mental disability, genetic information, service in the uniformed services, or any other characteristic protected by federal, state or local law. The New York Jets are committed to providing reasonable accommodations for candidates with disabilities. Consistent with our commitment to maintain a safe workplace, all new hires are required to be fully vaccinated against COVID-19 and provide verification of vaccination prior to their start date, unless they receive an approved exemption under applicable law. “Fully vaccinated” refers to at least two (2) weeks after the final dose on a two-dose vaccination series (Pfizer or Moderna) or at least two (2) weeks after a single-dose COVID-19 vaccination series (Johnson and Johnson). In accordance with CDC recommendations, we recommend all new hires and employees stay up to date with their COVID-19 vaccination. “Up to Date” currently means that a person has completed their primary COVID-19 vaccine series, plus a booster vaccine, if eligible. For more information please refer to the below CDC page: https://www.cdc.gov/coronavirus/2019-ncov/vaccines/stay-up-to-date.html"
Associate Data Engineer - 100% Remote,Radian,Remote in Pennsylvania+3 locations,https://www.indeed.com/rc/clk?jk=e1deacf0db4c6b0c&fccid=49bacaf9ea5daa22&vjs=3,"See yourself at Radian? We see you here too. At Radian, we see you. For the person you are and the potential you hold. That’s why we’ve embraced a new way of working that lets our people across the country be themselves, be their best and be their boldest. Because when each of us is truly seen, each of us gives our best – and at Radian, we’ll give you our best right back. See Yourself as a Associate Data Engineer The Associate Data Engineer assists in developing database objects and structures for data storage, retrieval, and reporting according to project specification. Participates in small teams on assignments to accomplish project goals. The focus of this position will be on data warehouse and ETL activities. See Your Primary Duties and Responsibilities 1. Help ensure effectiveness of the current Information Technology systems. Participate/assist with the following: Prepares database loadable files for the data warehouse Applies pre-defined business transformation rules Designs and develops back-end databases for business intelligence applications Program, test, implement and maintain any data extraction programs necessary to extract the data Designs and develops ETL processes for delivery into the data warehouse Ensuring the correct application of the business rules through data query after the data is loaded into the Data Warehouse Monitor loads to ensure successful completion Perform Data conversion, Quality and Verification activities Perform SQL tuning for PL/SQL procedures, Views, Brio reports, etc Create and manage daily, weekly, and monthly data operations and schedule processes Identifies and Coordinates source data extraction from other operational systems Participation in design sessions chaired by data stewards and/or IT personnel where decisions are made involving the transformation from source to target Optimize ETL performance Design various data movement load processes Develop and implement the error handling strategy for ETL. 2. Provide support to database administrators and interfaces with business users to ensure the database is satisfying business requirements. Help to eavluate and modify existing technology to take into account changes in business requirements, equipment configurations, and software compliance 3. Assist with ensuring documentation is created and up to date on all projects and operational systems 4. Perform bug fixing, trouble shooting and assist in user support for existing applications See the Job Specifications Knowledge: 2+ years experience in database development (Microsoft SQL Server 2008+, Microsoft SQL Integration Services Understanding of database theory and practice (ETL, OLTP, OLAP, DataVault And Star Schema design patterns) Financial/Mortgage Industry Experience a plus Skills and Abilities: Proven ability to work autonomously, independent thinker with strong communication/interpersonal skills Proven ability to quickly understand client requirements and translate them into software developer requirements Strong technical estimating skills Takes ownership of actions and outcomes Strong customer orientation Strong team orientation Prior Work Experience Technical: 3 - 5 years Supervisory: None Education and Credentials Required: Bachelor’s Degree, Concentration in Computer Science, Information Systems Management See Your Location Radian is committed to a flexible work environment for many of our roles. This is a *Work From Anywhere* role meaning you have the flexibility to work from home (or another designated workspace that fits your needs). This role provides additional flexibility should you want to work on-site at a Radian office. Explore our office locations here and let your Talent Acquisition Partner know you would be interested in working on-site. Work From Anywhere is subject to Radian’s Alternative Work Policy and business needs. See Why You Should Work With Us Competitive Compensation: Competitive Compensation: anticipated base salary from $77,540 to $120,176 based on skills and experience. This position is eligible to participate in an annual incentive program. Our Company Makes an Impact. We’ve been recognized by multiple organizations like Bloomberg’s Gender-Equality Index, HousingWire’s Tech 100, and The Forum of Executive Women’s Champion of Board Diversity. Radian has also pledged to PwC’s CEO Action for Diversity & Inclusion commitment. Rest and Relaxation. Generous time off starting day one, 9 paid holidays + 1 floating holiday in support of our DEI culture. Health Benefits. Multiple medical plan choices, including HSA and FSA options, dental, and vision. Prepare for your Future. 401(k) with a top of market company match (did we mention the company match is immediately vested?!) Paid Parental Leave. An opportunity for all new parents to embrace this exciting change in their lives. Employee Assistance and Discount Programs. From helping you navigate the healthcare system, to providing resources and assistance to parents and caregivers of children with development disabilities, to scoring discounts with thousands of retailers. Pet Insurance. To help protect our furry family members. See More About Radian Radian is a fintech servicing the mortgage and real estate services industry. As a team, we pride ourselves on seeing the potential of every person, every idea and every day. Seeing each other at Radian goes far beyond our open, flexible culture. It means seeing our people’s potential – and creating inspiring career paths that help them get there. Or seeing new pathways and innovating for the future of our industry. It means seeing each other for all that we are. And it means seeing our purpose as one that extends beyond the bottom line – having an impact on communities across the country to help more people achieve the American Dream of homeownership. We hope you’ll see yourself at Radian. See more about us at Radian.com. Defining Roles for Radian's Future Understanding the qualities and characteristics that define a Leader and an Employee is important to building our future-fit workforce. Radian's future is only as bright as its people. For that reason, our People Plan includes profiles to support the qualities and characteristics that each Leader as well as each Employee should embody upon hire or via development. EEO Statement Radian complies with all applicable federal, state, and local laws prohibiting discrimination in employment. All qualified applicants will receive consideration for employment without regard to gender, age, race, color, religious creed, marital status, gender identity, sexual orientation, national origin, ethnicity, ancestry, citizenship, genetic information, disability, protected veteran status or any other characteristic protected by applicable federal, state, or local law. Equal Opportunity Employer Details Accommodation Whether you require an accommodation for the job application or interview process, Radian is dedicated to a barrier-free employment process and encourages a diverse workforce. If you have questions about the accommodation process, please e-mail careers@radian.com."
"Front End Engineer II, Shopping Data Foundations",Amazon.com Services LLC,+6 locationsRemote,https://www.indeed.com/rc/clk?jk=8d3b875f16cff983&fccid=fe2d21eef233e94a&vjs=3,"2+ years of professional non-internship experience with front end, web or mobile software development using JavaScript, HTML and CSS Job summary As a Front End Engineer on the Shopping Data Foundations team, your work will directly impact the look and feel of the Amazon.com customer experience world wide. You will have the opportunity to work alongside a team of experts to deliver technologies that help accelerate CX innovation at Amazon. Key job responsibilities As a Front End Engineer you will use work with TypeScript, HTML, CSS, a combination of industry popular and amazon proprietary software to build CX features and continuously experiment with new ideas on Amazon website and application. You will also help launch novel build tooling to help modernize and accelerate front end development at Amazon. Our products are used widely across Amazon. You will have the opportunity to leverage this to effect worldwide and Amazon-wide impact like latency optimization to speed up the shopping experience for our customers. You will use Git to manage continuous deployments while focusing on testability, scalability, maintainability, code quality, and cogent design. Our products include reusable component framework for Amazon, asset build/deploy system used by thousands of engineers, and a in-house templating language which compiles to Java, Perl, JavaScript, that enables engineers across the world to create features for shoppers. About the team At Shopping Data Foundations, we own the data plus look and feel of the the Amazon shopping experience. Our visual building blocks (a.k.a Product UI components), styling/interactivity libraries and build and build/deploy tools will power the Amazon.com front end development ecosystem. Thousands of amazon engineers will use our service and tools on a daily basis to build innovative experiences for shoppers on Amazon app and website. As a team, we value testability, maintainability, code quality, and cogent design. Understanding of UX design patterns and approaches to implement them. Familiarity with JavaScript frameworks such as React, Redux, Vue, Ember, or Angular Understanding of cross-browser/device support and testing Experience building scalable, highly available web services or applications. The pay range for this position in Colorado is $143,700-194,400/yr. Our range of benefits may include health care, employee discounts, 401(k) savings plans, paid time off, and more. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. Applicants should apply via Amazon's internal or external careers site. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Data Engineer,Molekule,Remote,https://www.indeed.com/company/Molekule/jobs/Data-Engineer-ebc6ef4fd65855ca?fccid=a96c1507862f6c0e&vjs=3,"""Best Places to Work 2021"" -SF Business Times Molekule products are helping to change the lives of thousands of people by delivering cleaner air. As a Data Engineer on our Analytics team, you will be responsible for wrangling disparate data sets, processing, and automating the exposed data such that business owners can take action and drive impact. Further, you'll have the opportunity to solve challenges around a multi-platform customer experience where data is captured at various levels of complexity and work directly with partners in all areas of Molekule. What you'll own: Partnerships with engineering teams and internal data consumers on new projects or enhancements. The building and maintenance of highly scalable data pipelines and clean datasets around key business metrics. The enhancement of our data architecture to balance scale and performance. Further, you'll support a team of data scientists, analysts, and stakeholders to meet their data requirements. Examples of our work: At least 4 years' experience driving impact in a similar capacity at companies creating cutting edge tech. Expertise building data pipelines on large complex data sets using Spark, Airflow, or other open source frameworks. Expertise in a scripting language like Python (or similar) and a query language like SQL. Experience with AWS services: EC2, S3, Redshift, Glue, Cloud formation etc. Knowledge of scheduling, logging, monitoring, alert frameworks like Airflow. Proven experience deploying machine learning algorithms to production. Demonstrated proficiency in writing high-quality and scalable code and integrating with version control systems. Experience leading successful data engineering projects and operationalizing machine learning algorithms. Bonus points: Experience leveraging vendor APIs - extractions and insertions. Experience working Tealium, Amplitude or equivalent (Segment, etc). Experience with Stitch/Singer and dbt or similar. Smart and humble with an ever learning attitude. We are Molekule and we’re changing air purification. Founded by a family trying to address the adverse impacts of polluted air, Molekule was created with a goal of using the power of science to eliminate indoor air pollution around the world. Our mission is to deliver clean air to everyone, everywhere. It’s a lofty goal, but that's why we need you! Molekule Values:Humility""Check your ego at the door.""Determination & Grit""We believe in what we're doing. That's why we persevere through problems.""Ownership""We roll up our sleeves, do the work, own the outcomes, and are proud of our contributions (no matter the size).""Community""We're all in this together.""Passion""We're devoted to changing the world for the better.""Growth Mindset""I know that I don't know everything, there's always more to learn. I learn from my mistakes.""Communication""My communications are candid, effective, respectful, and assuming good intentions."" Organizational Philosophy:Every great accomplishment is the result of a team working in harmony, not just of individuals. We believe teamwork and a sense of egalitarian responsibility is fundamental to building a great organization.The objective of all organizational processes is to turn our organization into something scalable, repeatable, and efficient that reflects our culture. Molekule is an Equal Opportunity/Affirmative Action Employer. We will consider employment for qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. The Company will also not discharge, or in any manner discriminate or retaliate against, any employee who discloses their own wages, discusses the wages of others, inquires about another employee’s wages, or aids or encourages any other employee to do the same. The Company is not obligated to disclose wages. Applicants with disabilities may e-mail peopleteam@molekule.com, to request and arrange for accommodations. If you need assistance to accommodate a disability, you may request an accommodation at any time. Job Type: Full-time"
Data Products Engineer,Biofire Technologies,"Broomfield, CO",https://www.indeed.com/rc/clk?jk=c68ef70d7624ae9a&fccid=cb974917a4e3752d&vjs=3,"WHO WE ARE Biofire Technologies is on a mission to give gun owners better tools for reducing preventable gun injuries and deaths, especially among children. We believe our technology, combined with a best-in-class customer experience, will define the future of firearms safety for the next generation. Our mission-driven approach has earned support from the firearm community, the tech world, and the media. Biofire employees are world-class engineers who have designed and tested firearms, medical devices, robots, cars, satellites, rockets, and supersonic jets. What unites our team is our commitment to safety and reliability that we bring to our work every day. OUR CULTURE Reducing accidental firearm injuries and deaths requires original thinking and authentic collaboration, so we’re deeply invested in building a team and culture that can achieve our mission together. Team members enjoy autonomy and flexibility from day one, so expect to be immediately tasked with solving challenging problems and building new systems that work. We’ll hold you accountable for executing on audacious goals, giving and receiving honest feedback, and helping your teammates succeed. You’ll receive respect, kindness, and support from every direction while you figure out how to get it all done. ABOUT THE ROLE As a Data Engineer at Biofire you will be responsible for building and maintaining scalable pipelines, structuring data and building tools that enable your teammates to succeed across the company. You will be a champion for bringing data into day to day operations, doing the technical heavy lifting to power the company’s work and supporting and training other members of the team to build on top of the foundation you create. To succeed you will need to be able to programmatically work with data at scale, spot opportunities where data could accelerate the team, and continuously improve Biofire’s overall data environment. You will need to be a curious problem-solver, rapidly learning Biofire’s business problems and determining how to help solve them with data. If you’re excited about advancing Biofire’s mission through data, we encourage you to apply. KEY RESPONSIBILITIES Day to day responsibilities of the role will include: Data pipeline development, management, and optimization; Centrally integrating and structuring data across the company, creating a common ontology on which the company can build; Partnering with stakeholders across the company to develop data-driven solutions for their use cases; Training teammates on data, workflows, and tools, to ensure every member of the team is equipped to utilize their data; Proactively identifying opportunities to bring data into day-to-day business operations and engaging the relevant stakeholders to build them. COMPENSATION, BENEFITS & PERKS We’ll need you to bring your very best, so we give you what you need to do a great job. You’ll enjoy flexible hours, teammates you will like, respect, and be inspired by, and all the technical resources you might need at our Broomfield office. In addition to our competitive pay and stock options, Biofire offers fully covered medical, dental, and vision benefits, a funded Health Spending Account, unlimited PTO (that team members actually use - we promise), a 401(k) with employer matching, and a 14 week parental leave policy. We deliver perks including noise-canceling headphones, the premium music streaming service of your choice, and anything else you’d need to succeed in your role (within reason). This is a full-time, salaried role with a flexible work-from-home policy. The compensation range for this role is $120K-$150K. QUALIFICATIONS If you think you will succeed in this role, and love the work you’ll do, we encourage you to apply regardless of your background. We evaluate candidates based on their unique talents and fit for our needs, not a rigid list of qualifications. LOCATION AND HOURS Our dog-friendly, state-of-the-art headquarters is located in beautiful Broomfield, Colorado, between Boulder and Denver. Most roles require team members to frequently collaborate in person, but you will enjoy the flexibility to work from home when you need to. We trust you to communicate with your team to make things work. DIVERSITY & INCLUSION We’re bringing innovation to a technological problem that has persisted for decades, so we depend on diverse, inclusive, and collaborative teams to break new ground and do great work. We welcome people from all qualified backgrounds, and we don’t discriminate on the basis of race, religion, color, political affiliation, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. ELIGIBILITY This role handles information subject to US Export Control Regulations. Applicants must be (a) a citizen of the United States; (b) a lawful permanent resident of the United States (“Green Card” holder); or (c) a person admitted into the United States as an asylee or refugee to be considered for the position."
Data Engineer,Geo Owl,"Fort Bragg, NC",https://www.indeed.com/rc/clk?jk=287784e5dc8f8cfc&fccid=be4bf56cd785b400&vjs=3,"Geo Owl is currently looking for a Data Engineer to support our USASOC contract opportunity. To be qualified, you need at least 5 years of relevant experience and meet the requirements listed below. If interested, apply now, or contact one of our recruiters. Location: Fort Bragg, NC Clearance: TS/SCI Requirements: Must meet all the requirements listed below. 5+ years of experience in one or more of the following: business analysis, army special operations intelligence, and/or information management/knowledge management. 5+ years of experience supporting the United States Military, preferably SOF elements. BA/BS degree from an accredited university or former officer, NCO, or warrant officer with military experience or intelligence/knowledge management background. 5+ years of experience with Single Page Application Development and client-side coding, including Jscript React, Angular, Aurelia, Vue, Ajax, JSON, or REST, such as OData, HTML, or CSS 5+ years of experience with two or more of the following: C#, Python, PHP, or Java. Knowledge of database architecture and data transformations. Benefits: Health Insurance (Geo Owl pays 80%+ of the premium). 401k matching. Dental, Vision, and other supplemental insurance plans available. Company-paid short-term and long-term disability and life insurance. Peer-to-Peer spot bonuses. 120 hours of PTO per year plus federal holidays. Joining the Geo Owl Team | What to Expect At Geo Owl, we highly value our team members. We offer challenging but rewarding opportunities for those who want to work hard to provide a great experience for the customer and strive to reach their professional goals. As a member of the Geo Owl family, you will be working alongside people who share this work ethic and are aiming to be the best partner for our customer. We are all proud to be a part of this company and we want you to be too. Our Mission · Provide high quality solutions to our mission partners in the United States through our expert analysts. · Be recognized as the best at what we do by our customers. · Be a team our team members are proud and excited to be a part of. · Continually strive for excellence and seek to tackle the most difficult challenges our industry has to offer. About Us Geo Owl is a premiere provider of Full-Motion Video (FMV), Geospatial, ISR, Intelligence and IT services to the Department of Defense and Intelligence Community. We are vitalized by our engaged team of professionals that truly value each other and the important missions we support. Equal Opportunities Geo Owl is an equal opportunity employer and does not discriminate on the basis of race, color, religion, creed, sex, age, sexual orientation, national origin, disability, marital status, military status, genetic predisposition, or any other basis protected by law. To stay up to date about new career opportunities: us on Instagram"
Senior Data Engineer,Ball Aerospace,"Hybrid remote in Westminster, CO 80021+1 location",https://www.indeed.com/rc/clk?jk=f29a52417adaa52e&fccid=82c5e27e77990fa2&vjs=3,"Ball Aerospace is powered by endlessly curious people with an unwavering mission focus. We pioneer discoveries that enable our customers to perform beyond expectation and protect what matters most. We create innovative space solutions, enable more accurate weather forecasts, drive insightful observations of our planet, deliver actionable data and intelligence, and ensure those who defend our freedom go forward bravely and return home safely. At our core, we're passionate, committed people who believe together we can achieve extraordinary things. We work collaboratively with each other, our customers and partners to solve the world's greatest challenges. That means listening to one another, providing feedback and partnering across all levels. We value our inclusive culture where everyone is heard equally and creativity thrives. Each team member is fully invested in our mission and we bring an energy to work every day that propels our business and motivates us all to Go Beyond.® The Operations Strategic Capabilities Unit plays a fundamental role in enabling efficient business and program execution – from technologies and investments to supply chain, manufacturing and test operations, facilities management, and information technology services. Senior Data Engineer Ball Aerospace is looking for a data engineer to join the Mission and Process Analytics (MPA) team. What You’ll Do: Be a member of the dynamic MPA team; a team tasked with being a champion for data-driven decisions throughout the enterprise while advancing Ball Aerospace’s data analytics and data governance strategies and goals. Collaborate with team members and business stakeholders on projects that answer key questions that enable informed decision-making. Use technical expertise and exercise wide latitude to discover, blend, transform and interpret data from disparate sources using database management, programming, and data visualization skills. Work with a variety of systems to integrate data and build out a data model/semantic layer for use in projects. Be open to general course correction and feedback from leadership regarding results. Coach, teach, instruct MPA team members on technical solutions and computer science concepts. Communicate complicated and/or advanced computer science ideas to non-technical audiences. Design, implement, and publish visualizations/dashboards and other reporting tools for consumption by the business community, working directly with leadership to fulfill MPA’s objectives. Operationalize and perform quality assessments of data models, business intelligence solutions, software algorithms, and re-usable components to mature the MPA toolkit. Work closely with the Information Technology organization in the development of data solutions. Partner with internal business stakeholders to gather requirements and develop solutions that provide access to information, independently and without appreciable direction from leadership. Bring new and innovative ideas to the MPA team and Ball Aerospace. Present technical and programmatic aspects of a project to the MPA team and to the stakeholder, independently and without appreciable direction from leadership. Interact appropriately with others to promote a positive and productive work environment. Maintain a regular and predictable work schedule. Establish and maintain effective working relationships within the department, the Strategic Business Units, Strategic Capabilities Units and the Company. Look for opportunities to build new working relationships with Stakeholders, in support of the mission of MPA. Perform other duties as necessary. What You’ll Need: BS degree or higher in Engineering or a related technical field is required plus 8 or more years related experience. Each higher-level degree, i.e., Master’s Degree or Ph.D., may substitute for two years of experience. Related technical experience may be considered in lieu of education. Degree must be from a university, college, or school which is accredited by an agency recognized by the US Secretary of Education, US Department of Education. Experience in software development, user interface/experience, design, testing, and database development and management is preferred. Ability to apply extensive technical expertise in data querying and integration tools, such as SSIS, SQL, or VQL. Extensive understanding and wide application of visualization tools and the development of dashboards and reporting solutions; tools like Tableau, Power BI, Business Objects Web Intelligence. Extensive and expert knowledge of software development fundamentals – data structures, methodologies, data warehousing concepts, and object-oriented coding concepts. Experience with JavaScript and API development/utilization highly preferred. Experience with C# is a plus. Experience configuring/customizing Product Lifecycle Management (PLM) solutions (Oracle Agile, WindChill, TeamCenter, ENOVIA, etc.) is a plus. Experience with Dassault Systèmes 3D Experience Platform and XPDM importer preferred. A passion for solving problems and finding answers to business questions where solutions may be highly technical in nature and require the regular use of ingenuity. Attention to detail, cost-conscious mindset, self-motivation, and go-getter attitude. Strong collaboration skills. Hybrid Work Environment: This position may be performed working from both the office and another location, while typically requiring working in the office less than 3 days per work week. Travel and local commute between Ball campuses and other possible non-Ball locations may be required. Working Conditions: Ball Aerospace is a drug-free workplace, which is imperative to the health and safety of all employees and is required as a condition of receiving contracts from federal agencies. Please remember that regardless of the legalization of marijuana in Colorado and other states, possession and use continues to be illegal under the federal Controlled Substances Act. This includes the use of some CBD products. A post-offer, pre-employment drug test is a condition of employment. Work is performed in an office, laboratory, production floor, or cleanroom, outdoors or remote environment. May occasionally work in production work centers where use of protective equipment and gear is required. May access other facilities in various weather conditions. #LI-LO1 Relocation for this position is available. Compensation & Benefits: HIRING SALARY RANGE: $129,500 - $163,500 (Salary to be determined by the education, experience, knowledge, skills, and abilities of the applicant, internal equity, and alignment with market data.) This position includes a competitive benefits package. For details, copy and paste https://bit.ly/3pNSnxv into your browser or visit our careers site. US CITIZENSHIP IS REQUIRED Ball Aerospace is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. #LI-LO1"
Data Engineer,Research Foundation of The City University of New...,"New York, NY",https://www.indeed.com/rc/clk?jk=f878c509c603ac1c&fccid=667ba717ce627077&vjs=3,"General Description The Data Collaborative for Justice (DCJ): The Data Collaborative for Justice is a research organization launched at John Jay College of Criminal Justice in 2013. The DCJ has partnered with state and local agencies in New York to publish reports on various criminal justice topics, and expanded portfolio of analyses, evaluation, and partnerships around the nation. The DCJ also provides technical assistance to the Mayor’s Office of Criminal Justice of New York City to process administrative data for criminal justice research, including data analysis, data engineering and data product development. This position is for the technical assistance project. The DCJ operates under the Research Foundation City University of New York (RF). The Mayor’s Office of Criminal Justice: The Mayor’s Office of Criminal Justice (MOCJ) advises the Mayor of the City of New York on criminal justice policy. MOCJ develops and implements strategies to reduce crime and incarceration and to promote fairness and legitimacy. MOCJ works with law enforcement, city agencies, non-profits, foundations and others to implement data-driven strategies that address current crime conditions, prevent offending, and build strong neighborhoods that ensure enduring safety. The office draws on various disciplines, such as, behavioral economics to “nudge” conduct and machine learning to develop reliable predictive analytics, to ensure effective results. Position: DCJ is seeking a Data Engineer to primarily assist with the technical assistance provided to MOCJ. The position will primarily work with the Data and Technology group and the Executive Director of Information Technology. The Data Engineer will assist in managing and supporting the agency’s data platform and data pipelines and addressing new needs as they arrive. The Data Engineer will also participate in the implementation of the City’s new data exchange platform. Work will include migrating existing data pipelines and development of new procedures. The candidate is expected to work independently, possess a variety of analytic and data management skills and be actively involved in the full life cycle of data management including acquisition, processing, quality assurance/quality control, documenting and cataloging. Other Duties Responsibilities: The Data Engineer’s responsibilities include, but are not limited to: Maintain and support the agency’s data platform and data pipelines; Develop new data pipelines in collaboration with agency business owners; Work with technologies and platforms including Redshift, Snowflake, Tableau, SnapLogic, Informatica Python, R and SQL. Ensure agency compliance with all relevant data security and privacy policies; Develop and oversee quality assurance/quality control procedures; Develop processes to automate testing and deployment of code, and Document all processes and procedures; Qualifications Core Competencies: Ability to secure any necessary security clearances; Ability to monitor and evaluate the work of others, consistent with RF policies and contracts; Ability to communicate effectively with technical and program staff about research techniques, applications, practices, etc. important to the field of inquiry; Knowledge of policies regarding intellectual property, use of facilities and equipment, allocation of time and materials to project costs, and utilization of IT resources, and Knowledge of protocols for safe conduct of research, including but not limited to the study of human subjects and establishment of safety reporting procedures. Qualifications: The successful candidate must be highly organized, pays close attention to detail, is results-driven, is flexible and is overall a problem-solver and self-starter. In addition, the preferred candidate should possess the following: Bachelor’s Degree and a minimum of 3 years of experience. Knowledge of the principles, practices, and methods of data management and curation. Knowledge of data structures, formats, metadata and cataloging standards, and database technologies. Programming proficiency in Python and an understanding of R. Demonstrated experience with the aforementioned tools. Experience managing data and automating data pipelines; Data visualization and presentation experience a plus; Experience with geospatial data and technologies is a plus. Ability to balance competing priorities, complex situations, and tight deadlines. Ability to work independently in a fast-paced environment. Ability works comfortably with a wide variety of people at different levels within and outside the organization. Well organized with strong communication skills. Salary: $80,000 - $120, 000, depends on experience. To Apply: Please go to www.rfcuny.org. Under “About RF” there is a link for “Careers.” Please choose John Jay College of Criminal Justice to find the position. For Additional Information, See: the DCJ website https://datacollaborativeforjustice.org/ and the MOCJ website http://www1.nyc.gov/site/criminaljustice/index.page"
Data Engineer *Remote Work*,Genentech,"Remote in New York, NY+4 locations",https://www.indeed.com/rc/clk?jk=bbe0b5a653e7c26e&fccid=2525cc4a9a704809&vjs=3,"THE POSITION This position may be based out of New York, USA, with remote work locations possible in The United States. The Position The Engineering group within Prescient Design seeks exceptional data engineers who have a demonstrated background in software engineering, a passion for technical problem-solving, and a proven ability to realize and deliver scalable data pipelines and infrastructure for modeling molecular data. The group provides a dynamic and challenging environment for cutting-edge, multidisciplinary research including access to heterogeneous data sources, close links to top academic institutions around the world, as well as internal Genentech Research and Early Development (gRED) partners and research units. Our mission is to develop and apply methods in designing novel macromolecules. The Data Engineer will work closely with teams in Structural & Computational Biology and Machine Learning to enable end-to-end data workflows for large-scale data ingestion, processing, analysis, and modeling, including our core machine learning framework. Fundamentally, our engineering and research goals will enable us to collaborate closely with and–contribute uniquely to–many different project teams across the company. The Role Enable cutting-edge research in machine learning and applications to drug discovery, design, and development through the collection, design, and management of data pipelines and infrastructure. You will collaborate closely with cross-functional teams across both Prescient Design and gRED to solve complex problems in the life sciences, including understanding and analyzing algorithm issues. You will interface with other teams at gRED in developing a common data architecture and model and in formalizing best practices. You will be expected to help develop, manage, and scale data pipelines and infrastructure for analysis and modeling in production. You will be expected to solve core engineering challenges including the design and implementation of stable data architecture and models. You will be expected to serve as an expert and resource for multiple, diverse groups at Prescient Design and gRED. Qualifications B.S., M.S., or Ph.D. in Computer Science, Statistics, Applied Mathematics, Computational Biology, Physics, related technical field, or equivalent practical experience. Strong programming skills in languages like C++, Python, Java, Scala, or SQL. Strong experience with data modeling and schema design, including databases and file systems for scientific data Experience with containerization and orchestration tools like Docker, Singularity, Airflow, and Kubernetes. Experience developing and maintaining codebases and software libraries, following industry best practices. Experience with CI/CD and automation tools like Terraform, CloudFormation, Jenkins, and Ansible. Experience with tools and platforms for MLOps like Weights & Biases. Intense curiosity about the biology of disease and eagerness to contribute to scientific and computational efforts. Who We Are Genentech, a member of the Roche group and founder of the biotechnology industry, is dedicated to pursuing groundbreaking science to discover and develop medicines for people with serious and life-threatening diseases. To solve the world's most complex health challenges, we ask bigger questions that challenge our industry and the boundaries of science to transform society. Our transformational discoveries include the first targeted antibody for cancer and the first medicine for primary progressive multiple sclerosis. Diversity and Inclusion (D&I) are critical to the success of our company and our impact on society. We believe that by championing diversity of background, thought and experience, we can foster a sense of belonging and provide an environment where every employee feels valued, included, and able to contribute their best for the patients we serve. We’re focused on attracting, retaining, developing and advancing our people to their full potential by rewarding bold ways of thinking and integrating inclusive behaviors into every aspect of our work. Genentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page. RAB-eligible employees For Colorado-based and New York-based applicants, the expected salary range for this position is $163,795.00 - $211,970.00. Actual pay will be determined based on experience, qualifications, and other job-related factors permitted by law. A discretionary annual bonus may be available based on individual and Company performance. This position also qualifies for the benefits listed below. Benefits Roche offers highly competitive benefit plans and programs, including: •Medical, dental and vision insurance •401(k) and 401(k) matching •Paid time off •Roche Long Term Incentive Plan (available at certain position levels) #LI-DC1 Genentech is an equal opportunity employer, and we embrace the increasingly diverse world around us. Genentech prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin or ancestry, age, disability, marital status and veteran status. Genentech requires all new hires to be fully vaccinated against COVID-19 as of their start date. This requirement is a condition of employment at Genentech, and it applies regardless of whether the position is located at a Genentech campus or is fully remote. If you are unable to receive the vaccine due to a disability or serious medical condition, or because it is prohibited as a result of your sincerely held religious beliefs, you will have an opportunity to request a reasonable accommodation. JOB FACTS Job Sub Category Computational Biology Schedule Full time Job Type Regular Posted Date Jun 10th 2022 Job ID 202206-123435"
Data Engineer,PACCAR,"Renton, WA 98055+2 locations",https://www.indeed.com/rc/clk?jk=136618b1cb426c77&fccid=c2c6a7536e4d9df3&vjs=3,"Requisition Summary The PACCAR Parts Advanced Analytics team has an immediate opening for a motivated and energetic Data Engineer who wants to challenge themselves by working on Best-in-Class business enterprise applications, cloud products, ETL tools, and data warehousing. In this position, you will work with multiple stakeholders to analyze requirements and develop innovative and sustainable data pipelines for internal and external business data. As a Data Engineer on this high profile team you will be responsible for the design, development, and testing of data pipelines and data warehouse designs used by PACCAR employees, dealers, customers, and shareholders. Additionally, you’ll work alongside a team of Data Scientists, Business Intelligence Analysts, and other Data Engineers who consistently work together to improve Data & Analytics in PACCAR Parts. Benefits at PACCAR Inc. Competitive salary, 401K with a 5% company match, AND a company paid Pension Plan Medical, dental, and vision insurance plans for you and your family Comprehensive Paid Time Off – Vacation, Paid Holidays, and Sick Leave Tuition Reimbursement for continued education Global Fortune 500 company with a wide array of growth and development opportunities Work alongside experienced goal-oriented colleagues recognized as experts in their field Job Functions / Responsibilities Responsibilities include but are not limited to: Solving highly technical and complex problems Developing and enhancing the PACCAR Snowflake Data Warehouse Understanding, applying, and executing sustainable ETL processes & tools Proficiency in cloud applications that support Business Intelligence and Data Science activities Contributing towards automation/configuration management using Docker, Terraform, and GitHub Identifying, troubleshooting, and resolving problems with the build, deployment, and continuous integration process Leveraging scripting languages and tools such as SQL, Python, Terraform, and AWS Services to build automated solutions and integrations On-call support of PACCAR’s data warehouse Education A Bachelor’s degree in Computer Science or related field. Qualifications and Skills The ideal candidate will have: 2+ years’ experience working with ETL tools such as Qlik, DBT, or SchemaChange 2+ years’ experience working in AWS cloud products, such as S3, API Gateway, Lambda, etc 3+ years’ experience in a programming language(s) (Python & SQL preferred) Experience with Snowflake or other cloud databases (preferred) CI/CD & Dev-Ops experience (preferred) Strong understanding of GitHub and automation through GitHub Actions Experience working in an Agile development environment Ability to understand business requirements and turn them into technical requirements/code Ability to work well independently, with stakeholders, and in a fast paced environment with other talented Data Engineers and Data Scientists A demonstrated passion for technology and innovation A successful candidate will have aggressive learning goals and may support business partners using critical solutions that would require on-call responsibilities Additional Job Board Information PACCAR Parts is an eVerify Employer. PACCAR is an Equal Opportunity Employer/Protected Veteran/Disability. PACCAR has success with diverse teams of employees working together to achieve excellent results. Having a diverse and inclusive work environment ensures PACCAR has the talent needed to conduct business today and in the future by leveraging different backgrounds, skills, and viewpoints. We believe diversity in the workplace increases innovation, results in better decisions and increases employee engagement. Division Information PACCAR Parts is the global provider of aftermarket parts and services to support Kenworth, Peterbilt, DAF and TRP dealers around the world. This includes 18 distribution centers globally that support 2,200 dealerships and over 1,000,000 customers. Aftermarket support includes world class customer centers that deliver industry leading uptime in conjunction with our outstanding supply chain that delivers record levels of inventory availability for dealers and customers. Company Information PACCAR is a Fortune 500 company established in 1905. PACCAR Inc is recognized as a global leader in the commercial vehicle, financial, and customer service fields with internationally recognized brands such as Kenworth, Peterbilt, and DAF trucks. PACCAR is a global technology leader in the design, manufacture and customer support of high-quality light-, medium- and heavy-duty trucks under the Kenworth, Peterbilt and DAF nameplates. PACCAR designs and manufactures advanced diesel engines and also provides customized financial services, information technology and truck parts related to its principal business. Whether you want to design the transportation technology of tomorrow, support the staff functions of a dynamic, international leader, or build our excellent products and services — you can develop the career you desire with PACCAR. Get started!"
Senior Data Engineer (Remote),pulseData,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=793cc61e331f02a7&fccid=2c23f29fcd5c78da&vjs=3,"Join us as we pursue our vision to eliminate preventable sickness and transform kidney care using AI and data! At pulseData, we provide value-based healthcare organizations and their care teams a patented data intelligence platform that helps deliver better care at less cost. As a company, we leverage data science and machine learning for Hospitals and Healthcare companies, to identify patients at risk of costly and avoidable medical outcomes. You will become a member of pulseData's engineering team in this role. You will be developing, deploying, and maintaining our product pipeline and working in an environment of growth and collaboration. The Role: You'll be developing, deploying, and maintaining our production pipeline. You'll be ensuring product deliverables are executed effectively on a regular basis. You'll be interacting with 3rd party client APIs to deliver outputs. You'll be growing your skillset in a diverse and challenging environment that offers the latest technologies. Your Background: A quantitative degree. 4-6 years of experience as a Data Engineer. Experience in SPARK and ideally python (pandas). A growth mindset with the ability to work autonomously and with teammates remotely. Experience working on healthcare data is a plus! The Perks: Competitive base + bonus + equity. A remote working environment - we work eastern working hours. Top tier benefits include medical, dental, and vision insurance - 85% of which is covered by pulseData. Unlimited PTO - so you can stay at your best year round! Fun gym discounts, a 401k, and a new laptop + equipment. Company offsite adventures throughout the US each year. Tons of room for growth and the ability to learn new things."
Data Center Operations Engineer,Meta,"Newton County, GA+42 locations",https://www.indeed.com/rc/clk?jk=bcb5b8770a794617&fccid=ba07516c418dda52&vjs=3,"Facebook is seeking an entry-level engineer with graduate level experience looking to apply their technical skills in a fast-paced and complex environment. A working knowledge of server hardware and the desire to participate in projects at a large-scale data center is central to this role. This position will work to resolve and diagnose compute issues at scale, escalate issues, and work with remote engineering teams. Additionally, this role will support rack lifecycle processes with a focus on helping build out and support cloud scale compute and storage environments. Solid communication skills are a requirement for this role. This person should enjoy working in a fast-paced environment where adaptability and flexibility will be key to their success.The candidate should also have working knowledge and experience in at least one of the following core areas: Networking, Programming/Scripting, Hardware, or OS repair. Data Center Operations Engineer Responsibilities: Work within Facebook's ticketing system First point of contact for break fix technicians Responsible for assisting with projects (retrofits, new process details, etc.) and repairs throughout the data center Understand and debug hardware and Linux OS related issues Identify and help create documentation for the global data center knowledge base Assist with process improvements and best practices in data center operations Participate in on-call rotation (once a month on call for a week, after hours, first point of contact) Minimum Qualifications: Must obtain work authorization in the country of employment at the time of hire and maintain ongoing work authorization during employment Experience modifying and developing in Python, SQL, and/or shell scripting Currently has, or is in the process of obtaining, a Bachelor's or Master's degree in technical field, or equivalent experience/certification Knowledge of Linux and server hardware support Preferred Qualifications: Working conceptual knowledge of technologies such as HTTP, DNS, RAID, and DHCP Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
Data Engineer,Consumer Edge,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=b9e1a72249a8c0c2&fccid=4119a53133fe0567&vjs=3,"Consumer Edge is the leading provider of consumer data for some of the largest hedge funds, venture capital and private equity firms, and corporations in the United States and Europe. We arm our clients with actionable consumer, competitive, and market insights that drive better investment and strategic decisions. Position Summary Consumer Edge is at its crux a data company. We deal with collecting, aggregating, wrangling, modeling, and then surfacing important data that our clients use to make business-driving decisions. That means that our Data Engineering team sits at the center of the business and plays a huge role in its success. Data Engineers at CE own and are responsible for the entire data lifecycle: ingestion, ETL, warehousing, and reporting. We are data pipeline builders and data wranglers who enjoy optimizing data systems and building them from the ground up. We are looking to add another person to our team that will own every single piece of a data stack and be able to plug and play at every single step of the way. We support CE's Developers, Product team, Data Analysts and Data Scientists on data initiatives and we ensure optimal data delivery architecture is consistent throughout ongoing projects. Responsibilities For Data Engineer Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using a combination of SQL, GCP, and open-source big data' technologies. Communicate insights and recommendations to key stakeholders, engineering, data science and product partners Work in a supportive team that offers engineers the flexibility to be creative and chase interesting ideas Work closely with the product manager, end-users and stakeholders to understand, document, troubleshoot and analyze requirements for complex data solutions Design and build data integration methods to guarantee accuracy as well as accessibility of all valuable data while understanding what data is important for the business and why. Provide technical assistance and cross training to other team members and help with operational data needs when required Participate in data architecture and engineering decision making/planning Qualifications For Data Engineer 1-5 years of experience as Data Engineer or a similar role Experiencing dealing with large volumes of data, preferably successfully managing multiple heterogenous datasets into a unified data warehouse Creating ELT or ETL production data pipelines using Python/SQL Working knowledge of containers and workflow orchestration/automation tools: Prefect or Airflow. Bonus: DBT (com) AWS, GCS and/or Azure cloud-based data stacks, specifically experience with large-scale databases such as BigQuery, Redshift, or Snowflake Expert knowledge in SQL (window functions, partitioned or clustered databases, MPP, etc). Python data analysis libraries, such as Pandas and NumPy Bonus points if you feel comfortable working with DevOps tooling What you will have at Consumer Edge: Competitive Salary Work-from-home flexibility. As of Q2 2022, CE is remote-first, with an office in Midtown Manhattan 401k with employer match Flexible vacation and unlimited sick days Paid family leave An incredible product & powerful data that ""wows"" clients Great people: surround yourself with a team of people with a shared vision & focus, drive, a passion for CE's customers, and camaraderie Career growth opportunities"
Data Engineer at Meetelise (with Turing Talent Leadership Pr...,Turing Talent,"New York, NY 10016 (Murray Hill area)+1 location",https://www.indeed.com/company/Turing-Talent/jobs/Data-Engineer-At-Meetelise-3ccf118dcf89f4c9?fccid=62ea0490eeb7ef2f&vjs=3,"About Turing Talent The Turing Talent Program is the first of its kind - it’s a job and a leadership program rolled into one. You not only work at some of the most cutting-edge companies, but also receive leadership training and mentorship, as well as be part of a high-calibre industry network. The program is designed to accelerate your trajectory in a technical career. www.turingtalent.org Position: Data Engineer at MeetElise About MeetElise MeetElise ses machine learning to address the underlying cause preventing significant advancements in affordable housing: operational costs, with an AI leasing agent named Elise. MeetElise’s courageous team is building the future we want to live in. A future where housing is affordable, powered by technology, and accessible to all. MeetElise is well-funded by VCs and strategic real estate investors, and was started by technical cofounders from MIT and the University of Cambridge. About the role You will work closely with the software development and automation teams, designing and building out the infrastructure for the first million apartments and beyond. You will have a huge impact on a product used by thousands of people a day. What you'll be working on Build, deploy, and maintain robust data pipelines and infrastructure around the core data infrastructure that powers MeetElise’s Analytics Collaborate with engineers, product managers and data scientists to understand data needs, representing key data sets that power decision-making across the business Organize and optimize data in the relational data store to be clean, accessible, and scalable Must-have skills 3+ years of relevant experience Industry experience building production-quality data pipelines using Python, Java, SQL, Spark, etc. Linux/Unix experience Is driven and excited to join a highly productive team composed of engineers and scientists at a fast-growing startup Willing to work in person at NYC headquarters. Your relocation is covered if needed Nice-to-have skills Experience in designing, building, and monitoring relational databases Experience in working with cloud provider (preferably AWS) Postgres and Databricks experience Experience working directly with data science/machine learning teams to build data products Why join Cutting-edge nature of the work and team Well-paid. Top of the market salary and stock options. Impact. You’ll be significantly changing how the housing industry works today with the ultimate goal of creating more housing opportunities. Growth. Automatic enrolment of the Turing Talent Leadership Programme, designed for technical individuals to accelerate your career and personal development 100% medical, dental, and vision coverage 401k benefits Unlimited vacation Monthly fitness stipend Flexible working hours MeetElise will cover relocation packages from outside of the Greater NYC metro area - they'll make the move exciting, not painful. Contract type: permanent employment Start Date: ASAP Work location: Greater NYC metro area About Turing Talent Leadership Program Founded by people from Google, Meta, Microsoft and McKinsey, Turing Talent is revolutionizing what a tech career looks like. Don’t settle just for any job! Find a platform to GROW! We pair jobs with a holistic leadership program specifically for tech professionals to accelerate your career and personal development.﻿ https://www.turingtalent.org/leadershipprogram Job Type: Full-time Salary: $96,453.00 - $212,925.00 per year Schedule: Monday to Friday Supplemental Pay: Bonus pay Ability to commute/relocate: New York, NY: Reliably commute or planning to relocate before starting work (Preferred) Experience: Informatica: 1 year (Preferred) SQL: 1 year (Preferred) Data warehouse: 1 year (Preferred) Work Location: One location"
Big Data Engineer,Lucid Motors,"Newark, CA 94560+8 locations",https://www.indeed.com/rc/clk?jk=39171460bbac22f0&fccid=16a37eddfee06e0f&vjs=3,"Leading the future in luxury electric and mobility At Lucid, we set out to introduce the most captivating, luxury electric vehicles that elevate the human experience and transcend the perceived limitations of space, performance, and intelligence. Vehicles that are intuitive, liberating, and designed for the future of mobility. We plan to lead in this new era of luxury electric by returning to the fundamentals of great design – where every decision we make is in service of the individual and environment. Because when you are no longer bound by convention, you are free to define your own experience. Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you. Put your education to work and take us to the next level. Lucid's Digital organization recently opened a number of jobs tailored specifically for recent MS graduates who are looking to learn, grow and get in on the ground floor of our rapidly accelerating start-up. Working alongside some of the most accomplished minds in the industry, you will use your graduate level experience to advance this decade's most exciting brand in automotive. Bring your fresh ideas and collaboration skill. Bring your compassion for the environment. Bring your thirst for creating something that actually matters. They will all be nurtured here. You pursued a MS degree for a reason. Let Lucid help you use it by driving to create a better, more sustainable future. Role The Data Connectivity team is currently seeking a Big Data Engineer who will build data streaming pipelines using your skill in Kafka, Spark, Scala and Python. You will be hands-on to design and develop streaming and IoT data pipelines. Our ideal candidate exhibits a can-do attitude and approaches his or her work with vigor and determination. Candidates will be expected to demonstrate excellence in their respective fields, to possess the ability to learn quickly and to strive for perfection within a fast-paced environment. In this role you will be responsible for, Hands-on design and development of streaming and IoT data pipelines using Kafka, Spark, Scala and Python Scripting with Apache Spark and data frame Designing ETL in Apache Airflow and other dependency enforcement and scheduling tool. Hands-on data modeling and data warehousing Collecting, consolidating, and securely storing data streamed real-time Writing scripts, macros, and programs to automate routine analyses and actions Identifying actionable insights, suggest recommendations and influence the direction of the business by communicating results to cross-functional groups Suggesting improvements in the tools and techniques to help scale the team Creating reports and presentations for upper management, finance partners and others Qualifications 1+ years of academic or industry experience in each the following areas: Solving analytical problems using quantitative approaches Building real-time streaming data pipelines using tools such as Spark, Kafka, S3, Hive, Data Lake SQL or other programming languages (Python, Java, and/or C++) Scripting languages (Python, Bash, etc.) Working with tools such as Apache Spark, Apache Airflow, Presto, and Kubeflow Working with libraries such as Pandas, NumPy, sci-kit-learn Working with large data sets and distributed computing tools on cloud is a plus (Spark, Map/Reduce, Hadoop, etc.) Education Requirements MS degree in Computer Engineering, SW Engineering or Computer Science, Applied Mathematics, Statistics, Economics, or related technical field . At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations. Notice regarding COVID-19 vaccination requirement as a condition of gainful employment within the United States At Lucid, we prioritize the health and wellbeing of our employees, families, and friends above all else. In response to the novel Coronavirus, and the increased transmissibility with recent variants, all new Lucid employees, whose job will be based in the United States, must provide original documentation confirming status as having received the prescribed inoculation (doses) based on the manufacturer's guidelines on their first day of employment. Individuals seeking a medical and/or religious exemption from this requirement may be granted such an accommodation after submitting a formal request to and the subsequent review and approval thereof by our dedicated Covid-19 Response team. To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes."
Data Engineer,Fingerpaint,"Conshohocken, PA 19428",https://www.indeed.com/rc/clk?jk=6f337e5f517b4323&fccid=a67acab8a7c09a56&vjs=3,"Reset your expectations of a health and wellness agency. Independent by design and built on a foundation of empathy, Fingerpaint celebrates what you bring as both a professional and an individual. With talent across the United States and Europe launching more than 200 brands, we are committed to creating and executing meaningful experiences. In 2021, Fingerpaint was named to Ad Age’s Best Places to Work and was awarded Agency of the Year by Med Ad News. Here, creativity happens naturally—we attract top talent and give them a space to grow and collaborate. Fingerpaint is looking for an inquisitive, analytical thinker to join our growing digital team in the Saratoga Springs, New York office. This person will utilize their analytical, statistical, and database skills to turn raw data into actionable insights. Core Responsibilities: Identify, analyze, and interpret trends or patterns in complex data sets Performing ad-hoc analysis and presenting results in a clear manner Validate, cleanse, and optimize campaign data Management of campaign data warehouses Advance our reporting and data visualization efforts What it Takes: Undergraduate degree in Computer Science, Mathematics, Statistics, or equivalent combination of training and experience required. 3-5 years of experience in data analysis or data engineering in a digital marketing setting Advanced query building skills in PostgreSQL, SQL Server, or similar Practical business experience using SQL, Python, and ETL tools & techniques for data analysis Versed in mainstream business intelligence tools (Tableau, Power BI, etc.) and/or data visualization platforms (Datorama, Google Data Studio, etc.) Working knowledge of statistics and common digital marketing principles and metrics An analytical mind capable of creative problem-solving Articulate, detail-oriented communication skills Ability to stay current on new technology advancements and analytical trends A sense of humor and collaborative approach Bonus Points: Agency or pharma experience Experience with popular data warehouse platforms –Snowflake, RedShift, or equivalent Experience managing data models and ERDs (e.g. Omnigraffle, Lucidchart) Exposure to machine learning concepts Experience managing and mentoring team members"
Data Engineer - Data Scientist,BOEING,"Remote in Hazelwood, MO",https://www.indeed.com/rc/clk?jk=ca166deec2ea0abf&fccid=edae4285faf6c2f0&vjs=3,"At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us. Would you enjoy building machine learning models to predict component failures on a fighter jet? Or using the latest analytics techniques to create solutions no one has ever built before? Here, the sky is no limit. The Government Services Analytics team in Boeing Global Services has an opening for a Data Engineer with an interest in data science in St. Louis, MO, Colorado Springs, CO, or Philadelphia, PA. In this position you will work with an industry-leading team to create innovative health management solutions for government aircraft platforms in a dynamic, fast-paced team setting. Are you up for the challenge? Interacting with customers to formulate their needs into specific requirements and then defining and building data frameworks to support solutions for them will be a key part of the job. Experience navigating data integration in a secure environment is important to success. Developing robust and scalable sets of data processing tools and platforms, database wrangling, and building and maintaining Extract-Transform-Load pipelines will all be key components of the position. In addition to data engineering opportunities, creating new analytics models to provide as aftermarket services for our military customers is at the heart of what this position will require. Designing and developing machine learning models using a wide-array of methods, you will create solutions that empower users of our aircraft with unique insight. Together with our larger team, you will work with cutting edge analytics tools to create solutions that help manage the health and operations of aircraft for users across the world. The successful candidate will have a strong data engineering and data science background, with proven experience implementing a wide variety of data infrastructures, along with experience in data science techniques and approaches in cloud environments. Robust knowledge of data formats, architectures, and security are all foundational to the position. Knowledge and experience using machine learning is key as well. Experience using Python and SQL is critical, however knowledge of other programming languages such as C++, Java and R is also desirable. Prior aviation and engineering knowledge are both helpful as well. Excellent communication and teamwork ability are critical for success. Position Responsibilities: Performs data analysis integral to the research, development, test and evaluation of company products or manufacturing processes Investigates and applies best fit methods and algorithms, validates results and performs necessary data preparation and enhancements to models This position allows telecommuting. The selected candidate will be required to perform some work onsite at one of the listed location options. This position requires the ability to obtain a U.S. Security Clearance for which the U.S. Government requires U.S. Citizenship. An interim and/or final U.S. Secret Clearance Post-Start is require. Basic Qualifications (Required Skills/Experience): Bachelor’s degree in Mathematics, Computer Science, Engineering, Physics or similar discipline 2+ years of relevant experience Proficiency using Python on data science applications Preferred Qualifications (Desired Skills/Experience): Advanced degree in Data Science, Engineering, Computer Science, Mathematics, or another similar technical background Proficiency using SQL Familiarity with tools such as Apache Spark, Apache Airflow, Amazon Redshift, Snowflake, noSQL storage technologies, and other data management tools is preferred Experience and familiarity with cloud-based tools is preferred. Advanced understanding of military aircraft systems Engineering domain knowledge relating to aircraft maintenance, design, or testing are desirable Understanding of software engineering development processes and tools, from inception to production Familiarity with Condition-based maintenance techniques Experience with project management, including with agile development techniques Typical Education & Experience: Education/experience typically acquired through advanced technical education from an accredited course of study in engineering, computer science, mathematics, physics or chemistry (e.g. Bachelor) and typically 2 or more years' related work experience or an equivalent combination of technical education and experience (e.g. Master). In the USA, ABET accreditation is the preferred, although not required, accreditation standard. Relocation: This position offers relocation based on candidate eligibility. Drug Free Workplace: Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies. Shift Work: This position is for 1st shift. At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities. The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work. The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements. Please note that the salary information shown below is a general guideline only. Salaries are based upon candidate experience and qualifications, as well as market and business considerations. Summary pay range: $90,950 – $125,190 Equal Opportunity Employer: Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law."
Data Engineer,NeoReach,Remote,https://www.indeed.com/company/NeoReach/jobs/Data-Engineer-96760b07e7735481?fccid=d51054e2faa7147e&vjs=3,"We are looking for an experienced data engineer to join our team. You will use various methods to transform raw data into useful data systems. For example, you’ll create algorithms and conduct statistical analysis. Overall, you’ll strive for efficiency by aligning data systems with business goals. To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources. Data engineer skills also include familiarity with several programming languages and knowledge of learning machine methods. If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you. Responsibilities Analyze and organize raw data Build data systems and pipelines Evaluate business needs and objectives Interpret trends and patterns Conduct complex data analysis and report on results Prepare data for prescriptive and predictive modeling Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality and reliability Identify opportunities for data acquisition Develop analytical tools and programs Collaborate with data scientists and architects on several projects Requirements Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming languages (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills Benefits Health Care Plan (Medical, Dental & Vision) Paid Time Off (Vacation, Sick & Public Holidays) Family Leave (Maternity, Paternity) Work From Home Stock Option Plan Job Type: Full-time"
AWS Data Engineer,Tekserv,+1 locationRemote,https://www.indeed.com/rc/clk?jk=9f535f059b0c624a&fccid=e30c23ebf8b00210&vjs=3,"Location: Remote (EST Work hours) Duration: 6-12 Months Interview: MS Team Video Interview Industry: Media Rate: Please advice AWS Data Engineer – 2 Opportunities (4 Positions) Opportunity 1: AWS Data Engineer with a heavy focus /experience with Data Science and Data Engineering. – 2 Positions Opportunity 2: AWS Data Engineer needs to be strong in writing and reading APIs. – 2 Positions Who You Are: A highly motivated back-end developer that can produce and maintain applications that drive media efficiencies for our clients A person who can collaborate on small team of developers tasked to develop products that set our agency apart through innovation. You have a solid foundation of technical skills including product design, coding, debugging, and implementation of web applications. A supporter of and advocate for diversity, equity, and inclusion. Required Skills & Experience 2+ years of development experience. Experience in Python, SQL, and JavaScript. Strong experience with data engineering and data science background. AWS experience Ability to work on and drive innovation of multiple products. Ability to articulate clearly and effectively in person and in writing. Excellent organizational skills and the ability to juggle multiple responsibilities. Bachelor’s degree. Preferred Skills & Experience Exposure to the following Python libraries: pandas, NumPy and openpyxl. Experience to data science and data engineering. Handling of APIs, databases, web scraping, data processing, and cloud platforms. Knowledge of Django framework. Familiarly with Windows OS and Linux OS. Experience with Jira, Confluence, Google Suite (Sheets, Docs, Slides)"
KDB Data Scientist / Engineer,Barclays,"New York, NY 10019 (Midtown area)",https://www.indeed.com/rc/clk?jk=31ee5bba30a34cfb&fccid=057abf3fd357e717&vjs=3,"KDB Data Scientist Engineer New York This role is regulated by FINRA. As a Barclays KDB Data Scientist/Engineer, you will be focused on developing database code and processes (q/kdb, mysql), visualization/scripting for Management Information, and analytics with the associated GUIs. The Quant Trading group in Equities builds systematic strategies and runs the equities Central Risk Book which aims to mininize hedging costs by netting flows and managing risk portfolios. This involves accumulating large datasets, developing trading models, and conducting trade operations. Barclays is one of the world's largest and most respected financial institutions, with 329 years of success, quality and innovation behind us. We've helped millions of individuals and businesses thrive, creating financial and digital solutions that the world now takes for granted. An important and growing presence in the USA, we offer careers providing endless opportunity. What will you be doing? You will have ownership of data processes and code You will have ownership of visualization tools and reports You will work with quants, traders, and developers and other teams You will support and maintain existing and new APIs and automated jobs What we’re looking for: A bachelors degree in computer science, information services, engineering or related field Experience in GUI development Strong software engineering backgrounds with interest in learning KDB Skills that will help you in the role: Knowledge in equity markets Knowledge in statistics Where will you be working? You will be working at our Americas Headquarters at 745 Seventh Avenue. This 37-story office tower is located in Times Square in the heart of Manhattan and features a cafeteria, fitness center and state-of-the-art LED signage on the facade of the building."
Associate Data Engineer,AlignTech,"Morrisville, NC 27560 (Perimeter Park area)+6 locations",https://www.indeed.com/rc/clk?jk=4507ed3d7e0e49b1&fccid=5d6a5521c3a684d6&vjs=3,"Join a team that is changing millions of lives. Transforming smiles, changing lives At Align Technology, we believe a great smile can transform a person’s life, so we create technology that gives people the confidence to take on whatever’s next. We revolutionized the orthodontic industry with the introduction of the Invisalign system, and we have never lost sight of that spirit of innovation. Our diverse and collaborative teams are constantly pushing the boundaries of what’s possible. Ready to join us? About this opportunity The Associate Data Engineer will help develop our products by using our existing repositories of medical data to help build systems and services that improve the experiences of our customers and patients. The candidate will work with machine learning researchers to help identify, extract, and analyze data that will be used to create new and improve existing products. In this role, you will… Design, implement, and maintain efficient and reliable data pipelines to collect data from multiple systems (on-premise and cloud-based sources) and structure those data into a consistent and useable format. Collaborate with multiple teams (database administrators, software engineers, machine learning researchers, dev-ops engineers, and SQA) to build and maintain pipelines and tools, and to collect the appropriate data for research. Design and develop custom tools to facilitate effective data usage Implement a data workflow to aggregate and structure data for high-performance analytics Monitor performance of the data platform and optimize as needed Evaluate, benchmark, and integrate the latest big data tools and technologies Help to ensure compliance with GDPR and other related privacy laws when working with medical data. Use data analytics to establish and certify accuracy of data pipelines In this role, you’ll need … 2+ years of software development experience Experience with SQL and databases B.S. in Computer Science or a related field, or equivalent experience 1+ years of experience with Python Interest in learning or experience in ETL processes Sound like a good fit? Great! Click the ""Apply"" link to let us know you are interested. Not the right fit? Don’t worry, Align is quickly growing so we are creating more opportunities to expand our Align family. Please consider joining our Talent Network to receive notifications about future jobs or sharing this opportunity with others in your network. About Align Align Technology is a publicly traded medical device company that is transforming smiles and changing lives. Our global team of talented employees develop innovative technology, tools and treatment options to help dental professionals worldwide achieve the clinical results they expect. Our digital ecosystem combines the power of technology to create beautiful smiles through the integration of AI and machine learning, digital imaging and visualization, biomechanics and material science to develop the Invisalign system, the most advanced clear aligner system in the world; iTero Intraoral Scanners and OrthoCAD digital services. Did you know? Align is the world’s largest manufacturer of custom 3D-printed materials. By joining Align, you will be part of a global, fast-growing company in one of the most dynamic industries. Great people, innovative technologies, and meaningful work – these are just some of the things employees say make Align Technology a great place to work. We respect your privacy. Please review our Applicant Privacy Policies for additional information. Global Diversity Statement: At Align, we believe in the power of a smile, and we know that every smile is as unique as our employees. As we grow, we will continue building a workforce of diverse cultural backgrounds and life experiences and fostering a culture of open-mindedness and compassion for all our employees. We live our company values by promoting healthy people and healthy communities. All with the intent of changing millions of lives, one unique smile at a time. Equal Opportunity Statement It is our policy to provide equal employment opportunity in all of our employment practices without regard to race, color, religion, sex, national origin, ancestry, marital status, protected veteran status, age, individuals with disabilities, sexual orientation or gender identity or expression or any other legally protected category. Applicants for positions with Align must be legally authorized to work in the country which they are applying for and verification of employment eligibility will be required as a condition of hire."
Data Engineer II (Regular Full-Time),Seattle Cancer Care Alliance,"Seattle, WA 98109 (South Lake Union area)+1 location",https://www.indeed.com/rc/clk?jk=4736f060763d91dc&fccid=bcb8a8917771192d&vjs=3,"Overview: Fred Hutchinson Cancer Center is an independent, nonprofit, unified adult cancer care and research center that is clinically integrated with UW Medicine, a world leader in clinical care, research and learning. The first National Cancer Institute-designated cancer center in the Pacific Northwest, Fred Hutch’s global leadership in bone marrow transplantation, HIV/AIDS prevention, immunotherapy, and COVID-19 vaccines has confirmed our reputation as one of the world’s leading cancer, infectious disease and biomedical research centers. Based in Seattle, Fred Hutch operates eight clinical care sites that provide medical oncology, infusion, radiation, proton therapy, and related services, and network affiliations with hospitals in five states. Together, our fully integrated research and clinical care teams seek to discover new cures for the world’s deadliest diseases and make life beyond cancer a reality. At Fred Hutch, we believe that the innovation, collaboration, and rigor that result from diversity and inclusion are critical to our mission of eliminating cancer and related diseases. We seek employees who bring different and innovative ways of seeing the world and solving problems. Fred Hutch is in pursuit of becoming an antiracist organization. We are committed to ensuring that all candidates hired share our commitment to diversity, antiracism, and inclusion. The Data Platform Team within SCCA's Information Technology Department is responsible for designing, developing, and supporting SCCA data systems and integration for both operational and analytical purposes. Under the guidance of the Data Warehouse Manager, the Data Engineer II is responsible for the development and implementation of scalable, stable, and secure solutions for data acquisition, data distribution, and workflow orchestration in SCCA's data warehouse. The role will also contribute to the maintenance and optimization of existing data pipelines from a wide variety of internal and external data sources, including partner data warehouses and repositories. They will work closely with other engineering team members, business analysts, and systems analysts to provide data solutions that support and empower internal business partners and drive enterprise analytics and data science objectives. Successful candidates will have strong engineering and communication skills as well as a strong knowledge in on-prem SQL Server data systems. Familiarity with common cloud data tools, best practices and migration strategies is a plus as well as agile development methodologies. Responsibilities: Design, develop, and support ETL/ELT processes sourcing data from various internal applications and external data repositories including our partner EPIC EMR implementations. Monitor and maintain build and release pipelines in Azure Devops using continuous development best practices. Develop and support data infrastructure primarily built with Microsoft technologies. Partner with Test Engineer in development of the QA & Test Plan, including the automated test framework Contribute to production support efforts, including the identification, resolution, and communication of bugs within our data platform. Contribute to a collaborative environment within the Data Engineering function and in partnership with stakeholders. Work on multiple projects in parallel. Qualifications: Required: High school diploma or equivalent Excellent knowledge and experience developing, performance tuning, and supporting on-prem data engineering systems including Microsoft SQL Server Strong knowledge and experience with ETL tools and various data processing techniques and best practices Some knowledge and experience with database architecture and design, coding, and administration Strong knowledge and experience with data warehousing design and concepts Some knowledge and experience in working with large and complex data sets Ability to work independently, manage competing priorities and to adapt to new and changing technologies Strong analytical, problem solving, and organizational skills Strong verbal/written communication skills, including an ability to effectively communicate using multiple methods with both technical and non-technical teams Preferred: B.Sc or M.Sc degree in quantitative field (Engineering, Computer Science, Information Systems, etc.), or commensurate professional experience Prior experience in scripting languages (Powershell, Python, or similar) Prior experience in AWS or Azure cloud data tools/technologies Experience with Cerner and/or Epic healthcare systems Familiarity with healthcare financial and/or clinical data Familiarity with HIPAA regulations and data warehousing security best practices Experience using AWS for data processing SQL Server indexing and performance tuning Familiarly with the Systems/Software Development Life Cycle Experience with Agile software development SCCA has a mandatory COVID-19 vaccination policy, and there are no exceptions for any employee who is patient-facing and/or requires access to SCCA facilities. Exceptions exist only for employees whose positions are fully remote, with no required access to campus. As a condition of employment, newly hired employees requiring access to campus must provide proof of vaccination before their first day of employment. A statement describing your commitment and contributions toward greater diversity, equity, inclusion, and antiracism in your career or that will be made through your work at Fred Hutch is requested of all finalists. Our Commitment to Diversity: We are proud to be an Equal Employment Opportunity (EEO) and Vietnam Era Veterans Readjustment Assistance Act (VEVRAA) Employer. We are committed to cultivating a workplace in which diverse perspectives and experiences are welcomed and respected. We do not discriminate on the basis of race, color, religion, creed, ancestry, national origin, sex, age, disability (physical or mental), marital or veteran status, genetic information, sexual orientation, gender identity, political ideology, or membership in any other legally protected class. We are an Affirmative Action employer. We encourage individuals with diverse backgrounds to apply and desire priority referrals of protected veterans. If due to a disability you need assistance/and or a reasonable accommodation during the application or recruiting process, please send a request to our Employee Services Center at hrops@fredhutch.org or by calling 206-667-4700."
Data Engineer,Peerspace,Remote,https://www.indeed.com/company/PeerSpace/jobs/Data-Engineer-0cd8fab03917fa45?fccid=2c273b3587669450&vjs=3,"Peerspace invites people to find, share, and book the most magical spaces in the world. Since 2014, our community has been opening the door to thousands of spaces - from lofts and mansions to storefronts and studios - helping people to create one-of-a-kind experiences that would not be possible elsewhere. In total, over 5 million people have been welcomed into a Peerspace location, and we're looking for people who want to help us reach the next 50 million. *The Role: * We are looking for a candidate that has a strong interest in developing data science and analytics solutions to address business problems, can interact effectively with both the technology teams, product and business units, and is passionate about new technologies. As a Data Engineer, you will help build our data infrastructure and further develop our analytics and data science capabilities. You will be involved with all stages of the data journey. The problems we routinely work on are devising new search and ranking algorithms, determining the potential worth of each of our hosts, calculating the ROI for each advertisement, and improving A/B testing when sessions span multiple days. Our stack includes Clojure, Python, NodeJS, MongoDB, Docker/Kubernetes, Postgres, Google Dataflow, Google BigQuery, DBT, Airflow and Javascript (React). For reporting, we use Periscope, Metabase, Jupyter notebooks, and Google Data Studio. *Responsibilities: * *Build and scale data ingestion and transformation processes Transform our data into models that help all units of the company understand our performance and opportunities Build datasets, tools and documentation to enable analysts in all parts of the company to build their own analytics and reports. At Peerspace everyone is an analyst! Run ad-hoc analyses to support high-priority projects from internal business units Provide input on new data-generating processes and help organize our data capture efforts Devise and implement new algorithms and data processes to improve the performance of our marketplace (i.e. recommendation systems, search ranking) *Qualifications: * *Working knowledge of Python, R, Clojure, Julia or similar data-oriented languages, including data frameworks like tidy-verse or pandas, scikit, etc. Prior experience in SQL analytics (i.e Postgres, Bigquery) (e.g. you know how to use window functions and the nuances of using date ranges) Experience working with data visualization tools Basic knowledge big data technologies, e.g. Hadoop, Airflow, Kafka, Spark or similar Displaying skills in strong oral and communication with the proven ability to teach complex information effectively Working knowledge of statistical analysis and / or machine learning A degree or equivalent experience in Computer Science, Math, Physics, Engineering, Life Sciences or Social Sciences. *Preferred Qualifications: * *Experience with customer data platforms like Segment et al, and working with marketing teams Experience working in an online marketplace Experience with building programmatic SEO *Perks: * *Competitive salary and equity compensation $500 annual professional development allowance Discount on all Peerspace bookings 100% employee coverage of medical, dental and vision insurance Peerspace is a remote first company with team members located in cities around the globe. We believe that access to flexible workspace makes us more productive. Flex work perks include: *Laptop, high res display, and stipend to setup home office Monthly cell phone and internet credit Coworking membership if needed (in lieu of home office) Access to the Peerspace network of inspiring spaces to do your best work Biannual in-person, all company offsites and team-building events (in Peerspace locations, of course) *Diversity* At Peerspace, we're dedicated to creating a team that's diverse, equitable and inclusive. Our workplace is a space where all team members are empowered to blaze their own trail, make things happen, and take pride in their work. We believe bringing people together from different backgrounds and identities makes us stronger and better serves the Peerspace community. We'd especially like to encourage applicants from different backgrounds, locations, and experiences. Job Type: Full-time"
"Data Center Facilities Engineering, Electrical Engineer",Facebook App,+10 locationsRemote,https://www.indeed.com/rc/clk?jk=afb4d07f4431fd58&fccid=ba07516c418dda52&vjs=3,"Meta is seeking an Electrical Engineer experienced in the operations support and design of critical facilities to become part of our Data Center Facilities Engineering team. Our data centers are the foundation upon which our rapidly growing infrastructure efficiently operates and our innovative services are delivered. The establishment of new regions in the US, Europe, and Asia are important next steps in the evolution of the Facebook's infrastructure expansion. The Facilities Engineering team designs retrofit and upgrade projects and ensures our highly reliable environment is guaranteed. The ideal candidate will be able to work broadly, both leading critical projects cross-functionally as well as work independently leading deep dives and expert analyses. Data Center Facilities Engineering, Electrical Engineer Responsibilities: Lead complex electrical engineering projects and initiatives including working cross-functionally with design teams, construction, field operations, vendors, and R&D. Conduct analyses and audits of electrical systems, and lead improvements. Prepare electrical specifications and design criteria for retrofits, and provide input on future data center design reviews. Develop comprehensive project plans and inform frequently on progress, risks, and schedule. Review and develop detailed scripts for change management request (CMR) activities. Travel to data center sites to lead or support engineering studies, electrical systems audits, startup testing, and full commissioning. Participate in equipment failure and power outage incidents and drive Root-Cause-Analysis (RCA). Implement solutions broadly across all regions. Evaluate data center commissioning scripts and participate in commissioning activities (Integrated System Test) for new and retrofitted data centers. Develop and review design standards, specs, and method of procedures (MOP) for consistency and maximum system reliability. Generate RFPs, ROMs and SOWs for projects. Review and update data center electrical ""as-built"" documentation as re-configurations occur. Respond to incidents and emergencies. Participate in vendor, supplier, and contractor management at each site. Review electrical mission critical system changes with local data center operations teams. Provide and analyze energy efficient solutions to minimize power losses. Develop innovative and efficient improvement through lessons learned and Design Change Management. Minimum Qualifications: Knowledge of short circuit coordination and arc flash studies Knowledge of high voltage (115kV, 12kV) substations, mission critical power distribution and generator power systems Bachelors or Masters degree in Electrical Engineering Experience in load management at the operations level within a critical facility Cross-discipline knowledge of critical facility systems Communication, presentation, project management, and reporting experience Troubleshooting and analytical experience Knowledge of industry standards, building codes and safety standards Preferred Qualifications: Electrical Professional Engineer (PE) registration Familiarity with SKM or ETAP Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
Data Engineer,Interactive One,"New York, NY 10004 (Financial District area)",https://www.indeed.com/rc/clk?jk=8306bc23ec04f090&fccid=6e3507ea79837459&vjs=3,"“Notice to California Residents of Collection of Personal Information. When you submit an application, we collect the personal information you provide and that you authorize us to collect on your behalf for the purpose of processing and evaluating your application, verifying the accuracy of information you provide, and communicating with you about your application. The information we may collect includes: personal identifiers like your name, address, and contact information; information about your professional abilities, skills, aptitudes and background (e.g., educational and professional experience, resumes, curricula vitae, writing samples, and information about your skills, training, and applicable licenses, permits, and certifications); information about your character, references, and credentials; information about your authorization to work for us; information obtained from references, educational institutions, and others you have authorized us to contact (including results of background checks you authorize us to perform if you are offered a position); and any other information you elect to provide or authorized us to obtain. We may collect additional information for the purposes of complying with legal obligations, including criminal background and licensure information that may affect your legal ability to work for us and status information required for the monitoring of equal employment opportunity compliance (e.g., race/ethnicity, disability status, and gender).” Mandatory Vaccination Requirement: Urban One, Inc. and its divisions (collectively “Urban One” or the “Company”) have implemented a mandatory vaccination policy pursuant to which all employees must be fully vaccinated as a condition of employment to safeguard their health and well-being, as well as that of their coworkers, families, and the community at large, from the risks associated with COVID-19. Candidates should be aware that new employees will be required to be vaccinated by their start date, meaning they have received all of the recommended doses for either a one dose or two dose COVID-19 vaccine, and provide proof of vaccination status (e.g. CDC COVID-19 Vaccination Record Card) , which will be kept confidential. Urban One is an equal opportunity employer, and will provide a reasonable accommodation to those who are unable to be vaccinated due to a sincerely-held religious belief or a medical disability where it does not pose an undue hardship on the Company to do so as provided under federal, state, and local law. Interactive One ( www.interactiveone.com) is powered by the mission to create an online community that provides rich content and digital products that engage, entertain and inspire the lives of African Americans. We are the #1 digital platform for the Multi-Cultural Millennials, reaching millions of users each month through a suite of content, social, and local radio offerings. iOne owns and operates a number of branded destinations, including HipHopWired (Hip Hop x Technology),GlobalGrind (Millennials), HelloBeautiful (Women), MadameNoire (Women’s Lifestyle), NewsOne (Affluent), Bossip (Celebrity News & Gossip) and TheUrbanDaily (Men), as well as social networking sites such as BlackPlanet, and more than 50 local radio sites. Interactive One was launched in 2008 by Radio One, Inc. [NASDAQ: ROIA and ROIAK, radio-one.com] to complement its existing portfolio of media companies targeting Black Americans. KEY RESPONSIBILITIES: The DE role is responsible for supporting the data infrastructure that drives analytical insights, data intelligence, and dashboards. The DE is responsible for writing scripts (Python, Java, SQL) and creating data pipelines for storing data within our Amazon Web Services (AWS) infrastructure (Redshift, S3, S2). Engineer efficient, adaptable, real-time and scalable data pipelines that power our reporting and modeling capabilities Design and build efficient ETL / ELT infrastructure for both structured and unstructured data sources Monitor and maintain existing data pipelines and infrastructure currently in production Help drive optimization, testing, and tooling to continuously improve data quality Research and implement multiple API connections for data extractions Academic or 1 year of work experience with Agile Development including daily scrum and weekly iteration reviews and planning Complies with Network and Urban One’s mandatory trainings and adheres to related course deadlines CRITICAL COMPETENCIES FOR SUCCESS: The ultimate result is to standardize, and organize data for advanced modeling and reporting across the organization. EDUCATION/QUALIFICATIONS: Undergraduate or graduate degree in Computer Science is a plus Excellent teamwork and collaboration skills Excellent verbal and written communication skills Excellent project management skills (can function highly independently) Basic understanding of statistics Authorization to work in the United States is a precondition of employment. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire. COMPANY CORE VALUES: We believe in ideas that matter. To our clients. To the audiences we serve. To us. We don't care about the size of the idea as long as it makes a meaningful difference. We challenge everything. No thought. No point of view. No industry convention. Nothing is off limits. No idea is too great to be challenged when it comes to exploring ways to make things better. We have high expectations. We require the most out of each other because we know that the highest levels of achievement cannot take place without the highest levels of expectations. We take risks. Not any risks, but smart risks. The type of risks that can propel us to new heights. We embrace failure as long as we are aiming for the mountaintops and finding new lessons in the instances where we happen to fall short. We are humble giants. We are the best at what we do without the cockiness to go along with it. We are nice people who sit confidently at the top of our craft. To us, actions will always speak louder than words. We take care. Of our responsibilities. Of the work. Of our reputation. And most of all, of each other. Beyond being accountable, we are committed to never let each other fail. We partner until the work tells us it’s done. No agenda is higher than the one uniting us all."
Data Engineer,Micron,"San Jose, CA+8 locations",https://www.indeed.com/rc/clk?jk=3f1e6fd69a7d9003&fccid=be240c643a8631c5&vjs=3,"Our vision is to transform how the world uses information to enrich life for all. Join an inclusive team passionate about one thing: using their expertise in the relentless pursuit of innovation for customers and partners. The solutions we build help make everything from virtual reality experiences to breakthroughs in neural networks possible. We do it all while committing to integrity, sustainability, and giving back to our communities. Because doing so can fuel the very innovation we are pursuing. You will be joining an existing high performance global business intelligence team responsible for the architecture, design, implementation, and support of new and existing BI data solutions used by People professionals and business leaders throughout the Micron enterprise. This will require a deep understanding of several People Data domains: Talent Acquisition (Recruiting), Organizational (Headcount, Transfers, Retention), Time Tracking & Attendance, Total Rewards (Compensation & Benefits), Performance Management & Succession, Learning & Development, Diversity & Inclusion, and more. This role will also ensure People custom solutions are continually evolving and represent the People Organization’s strategy while remaining aligned with Micron’s brand. This position will have a main focus of: Creating and maintaining Power BI reports and dashboards. Creating and maintaining Power BI data flows sourced form SQL server, Azure, Workday API and Visier API. Writing intermediate SQL queries against on-premise SQL server databases and Azure cloud databases. Creating and / or adapting Workday reports for use in Power BI dataflow. Crafting and modifying ETL Packages (SSIS) The successful candidate will have: Familiarity with Power BI. (Reporting / dashboarding / dataflow creation) Familiarity with SQL Server coding of views, functions, and stored procedures. Knowledge of data warehouse design methodologies. (Relational, Dimensional, etc.) Good working knowledge of Microsoft Office Suite. (Word, Excel, Power Point, SharePoint.) The following skills will be considered helpful: Familiarity with Workday Reporting and / or Visier Analytics. Familiarity with UI Path or other RPA Automation software. Education: Bachelor’s degree. Preferably in Computer Science, Information systems, or Data related field. Alternately, Other bachelor’s degree with 1+ years of business intelligence related experience. About Micron Technology, Inc. We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life for all . With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron® and Crucial® brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience. To learn more, please visit micron.com/careers Micron is proud to be an equal opportunity workplace and is an affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, age, national origin, disability, protected veteran status, gender identity or any other factor protected by applicable federal, state, or local laws. Please note that in order to assist in providing a safe and healthy workplace for all Micron team members, new employment offers for jobs based in India, Malaysia, Singapore, and the U.S., are contingent upon the applicant’s provision of a copy of their COVID-19 vaccination document to Micron on a confidential basis prior to their scheduled start date confirming that they have completed the COVID-19 vaccination process, subject to any written request for medical or religious accommodation and to the extent permitted by applicable law. For US Sites Only: To request assistance with the application process and/or for reasonable accommodations, please contact Micron’s People Organization at hrsupport_na@micron.com or 1-800-336-8918 Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards. Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron."
Data Engineer,Shell,"Houston, TX+1 location",https://www.indeed.com/rc/clk?jk=609e4d11e9d0cde6&fccid=167aa4ca2fe7d8e6&vjs=3,"The Role Where You Fit In You will be part of a community of experts in different capabilities in Information Digital Engineering driving ideas to reality embedding AI in every part of our organisation from making our existing businesses more effective and efficient and make us competitive as we accelerate the development of the next generation of clean energy solutions. The Information Data & Analytics (IDA) family is a family of Data experts who create business value every day with their cutting-edge knowledge. We maximize value from information & data, using our domain knowledge & deep technical expertise in market leading information & data tools, to deliver actionable data driven insights for Shell What’s The Role? As Data Engineer, You will design and build data foundations and end to end solutions for Shell to maximize value from data. You are a key person to convert Vision and Data Strategy for IT solutions and deliver them. With your knowledge you will help create data-driven thinking within the organization, not just within IT teams, but also in the wider Shell stakeholder community. In this role, you will: Communicate with both technical developers and business managers and gain respect and trust of leaders and staff. Actively deliver the roll-out and embedding of Data Foundation initiatives in support of the key business programs advising on the technology and using leading market standard tools. Coordinate the change management process, incident management and problem management process. Ensure traceability of requirements from Data through testing and scope changes, to training and transition. Drive implementation efficiency and effectiveness across the pilots and future projects to minimize cost, increase speed of implementation and maximize value delivery. Being Our Team Member, you will be an asset in our team bringing deep technical skills and capabilities to become a key part of projects defining the data journey in Shell, keen to engage, network and innovate in collaboration with companywide teams. What we Need from you University degree in any IT discipline. Minimum 5+ years of experience in the IT industry. Proven technology champion in working with relational, Data warehouses databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience/Knowledge in working with NoSQL databases and can create E2E pipelines. Experienced in building and optimizing complex queries. Good with manipulating, processing and extracting value from large, disconnected datasets. Proven Experience in working with any one of the data engineering technologies like ADLS, ADF, Azure Databricks, Azure SQL, Synapse, SAP HANA, AWS. Your experience in handling big data sets and big data technologies will be an asset. Proven champion with in-depth knowledge of any one of the scripting languages: Python, SQL, Spark-SQL/ PySpark. Very Good understanding in Data Foundation initiatives, like Modelling, Data Quality Management, Data Governance, Data Maturity Assessments and Data Strategy in support of the key business stakeholders. Experience in working with AGILE, KANBAN methodologies. Able to run a sprint. Communication Skills to engage both technical developers, Architects, and stakeholders. Good to haves: Previously created or enhanced CI/CD build and releases pipelines. Experience in working with scripting languages such as YAML, PowerShell, Terraform etc. Experience with big data tools: Kafka, Hadoop, Spark and similar technologies. Experience with stream-processing systems. Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow and more. Core Python skills like: Numpy, Panda, Django. Certification in Azure. COMPANY DESCRIPTION Shell is a global group of energy and petrochemicals companies with over 90,000 employees in more than 70 countries and territories. In the US, we have operated for over a century and are a major oil and gas producer onshore and in the Gulf of Mexico, a recognized innovator in exploration and production technology, and a leading manufacturer and marketer of fuels, natural gas and petrochemicals. We deliver energy responsibly; operate safely with respect to our neighbours and work to minimize our environmental impact. We are in search of remarkable people who will thrive in a diverse and inclusive work environment to deliver exciting projects locally and globally. People who are passionate about exploring new frontiers. Innovators and pioneers. People with the drive to help shape our future. Because remarkable people achieve remarkable things. An innovative place to work There’s never been a more exciting time to work at Shell. Everyone here is helping solve one of the biggest challenges facing the world today: bringing the benefits of energy to everyone on the planet, whilst managing the risks of climate change. Join us and you’ll add your talent and imagination to a business with the power to shape the future – whether by investing in renewables, exploring new ways to store energy or developing technology that helps the world to use energy more efficiently. An inclusive place to work To power progress together, we need to attract and develop the brightest minds and make sure every voice is heard. Here are just some of the ways we’re nurturing an inclusive environment – one where you can express your ideas, extend your skills and reach your potential… We’re creating a space where people with disabilities can excel through transparent recruitment process, workplace adjustments and ongoing support in their roles. Feel free to let us know about your circumstances when you apply and we’ll take it from there. We’re closing the gender gap – whether that’s through action on equal pay or by enabling more women to reach senior roles in engineering and technology. We’re striving to be a pioneer of an inclusive and diverse workplace, promoting equality for employees regardless of sexual orientation or gender identity. We consider ourselves a flexible employer and want to support you finding the right balance. We encourage you to discuss this with us in your application. A rewarding place to work Combine our creative, collaborative environment and global operations with an impressive range of benefits and joining Shell becomes an inspired career choice. We’re huge advocates for career development. We’ll encourage you to try new roles and experience new settings. By pushing people to reach their potential, we frequently help them find skills they never knew they had, or make career moves they never thought possible. Disclaimer Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date. Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Royal Dutch/Shell Group companies around the world. The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand. Shell participates in E-Verify. All qualified applicants will receive consideration for employment without regard to race, color, sex, national origin, age, religion, disability, sexual orientation, gender identity, protected veteran status, citizenship, genetic information or other protected status under federal, state or local laws. Shell is an Equal Opportunity Employer - Minorities/Females/Veterans/Disability. As a US Federal Contractor, hiring selections are subject to periodic audit review and documentation of your selections should be maintained for a period of three calendar years. It is the policy of Shell in the U.S. (“Shell”) to provide equal opportunity to all individuals, employees and all qualified applicants for employment consistent with employment requirements and qualifications. Shell prohibits discrimination based on race, color, sex, national origin, age, religion, disability, sexual orientation, gender identity, veteran status, citizenship, genetic information, or other protected status under federal, state or local laws. All employees are expected to support this policy and contribute to an environment of equal opportunity. If you need an accommodation for a disability during the resourcing process, please speak with an HR representative."
"Network Engineer, Data Center Management",Google,"Reston, VA (Sunset Hills area)",https://www.indeed.com/rc/clk?jk=6910e70da8c6a034&fccid=a5b4499d9e91a5c6&vjs=3,"Minimum qualifications: 1 year of IP networking experience. Experience in one or more of the following: C, C++, Go or Python. Operational experience with routers and switches. Experience in network routing protocol design and troubleshooting L2, VLANs, VRRP, RSTP, BGP, OSPF, IS-IS. Preferred qualifications: Experience with a service provider or hyperscale network in engineering or design roles. Experience developing networking products, technologies, software and protocols. Experience with ACLs, stateful firewalls and NAT. Interest in designing, analyzing and troubleshooting large-scale distributed systems. Ability to coordinate with various teams to understand partner teams requirements and deliver designs based on those. Systematic problem-solving approach, coupled with excellent communication skills and a sense of ownership and drive. About the job Google is proud to boast a network that provides service to millions of Internet users around the world. The Network Engineering team is responsible for operating that network reliably and at scale. As a member of the team, you have a direct impact on design and feature enhancements to keep our systems running smoothly. You also ensure that network operations are safe and efficient by monitoring network performance, coordinating planned maintenance, adjusting hardware components and responding to network connectivity issues. Google's complex network generates a constant stream of challenges which require you to continually be innovative with an evolving set of technologies. Keeping the network reliable ensures that our users stay connected with our suite of applications, products and services. Network Engineering provides comprehensive long-term development, automation and engineering of Google’s data center monitoring networks. New product introduction (NPI) is a development function responsible for introducing new hardware, topology and network designs to data center management networks. Our team's mission is to provide technology continuity which allows the network to continuously scale, constantly increase efficiency and satisfy new use cases demanded by the business. In this role you will focus on developing new networks related to industrial control systems monitoring in Google scale data centers. You will work closely with partner teams which manage industrial control systems. You will ingest the business requirements and convert those requirements into networking requirements, design network based on requirements, and understand the various product lifecycles. Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible. Responsibilities Engage in and improve the whole lifecycle of networks from inception and design, to qualification and validation, through deployment, operation and optimization. Scale systems sustainably through mechanisms like automation, and evolve systems by pushing for changes that improve reliability and velocity. Work with other team members and groups to analyze requirements or potential problems and proactively develop solutions and policy recommendations. Partner with Google’s internal application groups and design network infrastructure which meets their networking requirements. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form."
Data Engineer - Data & Analytics,Procter & Gamble,"Cincinnati, OH+3 locations",https://www.indeed.com/rc/clk?jk=2f8ec8ad54278156&fccid=2da0dedf6df97194&vjs=3,"With us you will: Build data & analytics solutions in Microsoft Azure – architect and design technical solutions to obtain, process, store and provide insights based on the processed data Develop within existing designs of various solutions in Microsoft Azure environment to help the business get valuable insights Suggest and implement architecture improvements Work on automation and optimization of internal processes in Azure Influence the future of these new technologies and the ways in which P&G uses them Have a possibility to work with multifunctional and multinational teams within and outside of P&G Focus on key business cases development within Data & Analytics + Azure Manage agile projects using cloud and hybrid solutions Responsibilities: We are currently looking for a Data Engineer to join our Data & Analytics team in Cincinnati focused on Business Units specific deliverables. In this role, you will be responsible for building systems and solutions leveraging various Azure components & tools. You will lead this architecture and actively code and adapt it to ensure it functions well. Qualifications Python and SQL programming skills Cloud Understanding Previous experience or understanding of Data Models English proficiency Bachelor's degree in Computer Science, Computer / Systems / Industrial Engineering, Business / Management Information Systems or Software Development. Job locations: Cincinnati, Ohio, United States Job Type: Full time Job categories: Information Technology Req No: R000004776"
Data Engineer.,Ardan Labs,Remote,https://www.indeed.com/rc/clk?jk=b8787a86d7cea92c&fccid=34508cd7f02c1bbb&vjs=3,"Ardan Labs is a consulting firm that helps our clients develop software solutions and applications. We work on software projects and teams of different sizes. We are currently looking for a Data Engineer with experience in technologies like AWS, Stitch, RedShift, and others. Requirements 3+ years of experience as a Software Engineer Strong SQL skills are required Experience with core AWS services Data processing tools like Stitch, DBT, Spark Data warehousing tools like Redshift, Snowflake Databases like MongoDB, Postgres, AWS Aurora Benefits As a W2 employee, we offer family medical coverage, life insurance, paid vacation, and technical training."
Data Engineer,Becker Logistics LLC,Remote,https://www.indeed.com/rc/clk?jk=eedb6ae1cb24845e&fccid=d83042a77f0ed910&vjs=3,"Description: Summary of Role: Are you a technology enthusiast? Do you see opportunities around you to add value through technology? Do you enjoy being responsible for bringing information and people together to create and deliver value? Do you aspire to be a business leader and valuable teammate? Our Business Analyst opening is an opportunity to make a substantial impact by designing and delivering software development and implementation projects. You will be in the middle of the action, serving as a liaison between stakeholders, users, and developers. You will collaborate to define deliverables, set, and communicate goals, track progress, and evaluate and refine results. This is a very visible position at a company where you will have autonomy, work on a variety of self-driven tasks and have the opportunity for personal and career growth. Specific Responsibilities: Gathers business intelligence from a variety of sources including company data, industry and field reports, public information, or purchased sources. Compiles business intelligence or trends to support actionable recommendations. Summarizes financial and economic data reports for review by executives, managers, clients, and stakeholders . Requirements: Required Experience and Qualifications: 1-3 years of experience engineering BI / Reporting capabilities in business Excellent verbal and written communication skills Moderate presentation design capability creating smart visualizations that help people make decisions Moderate query design, data munging, mining ability. Exposure to ETL and ELT concepts. Exposure to structured and unstructured data technologies and concepts. Basic to advanced experience with source control systems. Ability to handle databases and understand technology-driven business intelligence tools Preferred Skills, Experience & Education: Associate’s, Bachelor’s and Master’s degrees in Information Technology, Engineering, Mathematics, or related fields. Familiarity with McLeod Power Broker Experience with project management and work tracking tools"
Data Engineer,Nexstar Broadcasting,California+1 location,https://www.indeed.com/rc/clk?jk=da9099c17972cc97&fccid=fffb9c1ff9b4747b&vjs=3,"Job Summary: The Data Engineer is responsible for helping develop and maintain the company’s data platforms. This position works closely with other engineers and data scientists. Principal Duties & Responsibilities: Data collection Data transformation and cleanup Data importation into analysis and reporting databases Daily monitoring of data systems Analysis of data to find new insights Required Technical Skills and Abilities Python SQL BASH Scripting Recommended Technical Skills and Abilities: AWS knowledge AWS Redshift knowledge Knowledge about Docker containers Knowledge about NoSQL Systems Javascript knowledge HTML/CSS Education/Experience Needed: Bachelor’s degree in computing related field preferred Will consider work or internship experience that involves daily usage of Python and SQL Soft Skills: Takes initiative to solve problems Able to multi-task and manage multiple projects Seeks feedback Excellent interpersonal, written, and verbal communication skills Able to self-manage Quality oriented NOTE: This job description contains the basic requirements for the position and is NOT intended to be a complete list of responsibilities; other duties may be assigned."
Data Engineer,Groundspeed,Remote,https://www.indeed.com/rc/clk?jk=bde91c62de69fd62&fccid=d9670ef40693b560&vjs=3,"Who We Are Groundspeed is a fast-growing, fully-remote insurtech company funded by top venture firms like Insight Partners and Oak HC/FT. We’re helping the centuries-old, $800 billion commercial insurance industry transform inefficient processes. Our human-in-the-loop AI platform captures, structures, and delivers complete risk data to underwriters and business leaders — so they can make faster, smarter decisions. Top insurers like Travelers, Liberty Mutual, and Swiss Re trust Groundspeed to help them win more business and operate more efficiently. We are recognized by industry analysts as an insurtech leader, and were recently named one of the Best Places to Work by Purpose Jobs. Historically headquartered in Ann Arbor, the Groundspeed team is now distributed across the U.S. About the Role We are looking for a creative, enthusiastic, and collaborative Data Engineer who doesn't shy away from hard problems. This role will contribute towards the design and development of Groundspeed’s Data Platform, helping to define data practices and execute on complex data platform and data engineering initiatives. You will have the opportunity to work with various big data cloud technologies and build relationships across Engineering, Product, Data Science, BI/Analytics, and Operations. It’s an exciting time to join the team and play a big role in developing the future of data at Groundspeed! What You Will Do Data Infrastructure - Help design and implement our Data Platform from the ground up. Tooling and integrations for data ingestion, kappa or lambda architectures for stream and batch processing, monitoring, and more. Data Pipelines - build end-to-end ETL/LT pipelines to populate the Data Warehouse and empower downstream analytical data consumers Data Modeling - help model service and warehouse data stores, working with both SQL and noSQL databases as well as row-based and columnar engines. Cross-functional Collaboration - Interface with Product, Engineering, Data Science, Analytics/BI, and Operations to understand their data needs, providing both consultative and data engineering solutions for the various internal customers What We are Looking For BS degree in Computer Science or related technical field, or equivalent practical experience 1-3 years proven work experience as a Data Engineer, working with at least one programming language (e.g. Scala, Python/PySpak) plus SQL expertise 1-3 years experience developing data platform infrastructure Background working with distributed big data technologies such as Spark, Presto, Hive, Redshift etc. Experience with schema design, dimensional data modeling, and large-scale data warehousing architecture Experience in building data pipelines through efficient ETL design, implementation, and maintenance Knowledge of agile software development and continuous integration / deployment principles We are Committed to a Diverse Workforce Groundspeed is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, nativity, neurodiversity, genetics, disability, age, or veteran status. For more information about Groundspeed, please visit www.groundspeed.com. Groundspeed Analytics, Inc. is an E-Verify Employer. Groundspeed Analytics, Inc. respects the privacy of your data. *If you are a resident of the State of California, please take the time to read our Candidate Privacy Notice, available here."
Data Engineer,Resolution Life,"Remote in West Chester, PA+1 location",https://www.indeed.com/company/Resolution-Life/jobs/Data-Engineer-63e02c02502e4800?fccid=932de71456da6ef2&vjs=3,"As part of the application process, a candidate account is required to log in and view application(s). Please be sure to check email regularly for information regarding our employment process. Profile Summary:Data Engineer designs and develops scalable data solutions using data integration tools and technologies. Being Data Engineer utilizes big data computation, data platforms and storage tools to create prototype and data products. Conduct build and testing of data pipelines and solutions. Additionally, Data Engineer integrates, tests data pipelines with Advance Analytics and AI platforms. Must be proficient with multiple data engineering and integration tools such as Python, Informatica IICS, Spark, Dynamo DB etc. in the AWS environment. Profile Description:The data engineer builds high quality data pipelines driving analytic solutions. The role requires deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows. The ideal candidate is a skilled data / software engineer with experience creating data products supporting analytic solutions. Profile Responsibilities: Design, develop, optimize, and maintain data architecture and pipelines that adhere to data integration principles and business goals Solve complex data problems to deliver insights that helps our business to achieve their goals Create data products for analytics and data scientist team members to improve their productivity Code, test, and document new or modified data systems to create robust and scalable applications for data analytics Ensure that data pipelines are scalable, repeatable, and secure, and can serve multiple users within the company Enable big data and batch/real-time analytical solutions that leverage emerging technologies Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes Work with Data Science practitioners and developers to make sure that all data solutions are consistent Partner with Business Analysts and Solutions Architects to develop technical architectures for strategic enterprise projects and initiatives. Ensure all automated processes preserve data by managing the alignment of data availability and integration processes Interact with business clients, understand business requirements, propose and deliver data solutions to meet the business requirements. Knowledge & Experience: Bachelor of Science in Computer Science, Engineering, Mathematics, Statistics or related subject 3-5 years of experience in Data platforms and technologies in AWS Cloud environment such as Spark, Informatica IICS, Redshift, Postgres, Dynamo DB, Neptune DB, EMR, Glue, Kafka. Expertise in SQL and data analysis and experience with Python and other programming languages Experience developing and maintaining data warehouses in big data solutions Experience with BI tools such as Tableau, Power BI Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, etc. Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics Demonstrated experience with agile or other rapid development methods Excellent problem solving, critical thinking, quick learning and communication skills Passion for innovation and “can do” attitude to thrive in a fast-paced environment Additional Qualifications Expertise in AI, Advanced Analytics and Machine Learning technologies is a plus Life insurance industry domain experience is a plus. Front-end software development experience is a plus Location: West Chester, PA, Atlanta, GA, and open to remote #LI-Remote Critical SkillsAt Resolution Life, we have identified the following critical skills which are key to success in our culture: Customer Focused: Passionate drive to delight our customers and offer unique solutions that deliver on their expectations. Critical Thinking: Thoughtful process of analyzing data and problem solving data to reach a well-reasoned solution. Team Mentality: Partnering effectively to drive our culture and execute on our common goals. Business Acumen: Appreciation and understanding of the financial services industry in order to make sound business decisions. Learning Agility: Openness to new ways of thinking and acquiring new skills to retain a competitive advantage. Job Type: Full-time"
Data Engineer,"Kia America, Inc.","Irvine, CA 92606",https://www.indeed.com/rc/clk?jk=a55a584e99ee59ef&fccid=5fdf2415a4f9db15&vjs=3,"At Kia, we’re creating award-winning products and redefining what value means in the automotive industry. It takes a special group of individuals to do what we do, and we do it together. Our culture is fast-paced, collaborative, and innovative. Our people thrive on thinking differently and challenging the status quo. We are creating something special here, a culture of learning and opportunity, where you can help Kia achieve big things and most importantly, feel passionate and connected to your work every day. Kia provides team members with competitive benefits including premium paid medical, dental and vision coverage for you and your dependents, 401(k) plan matching of 100% up to 6% of the salary deferral, and time off starting at 14 days per year. Kia also offers company lease and purchase programs, company-wide holiday shutdown, paid volunteer hours, and premium lifestyle amenities at our corporate campus in Irvine, California. Status Exempt Summary As Kia North America’s Big Data Center continues to grow rapidly, we are looking to add a talented Data Engineer to our team. The position will be responsible for building ETL data pipelines for use in machine learning models and visualizations. This will require participating in the full development lifecycle (design, implementation, testing, documentation, delivery, support, and maintenance). Major Responsibilities 1st - Build robust and scalable data pipelines. (30%) 2nd - Maintain existing data pipelines especially on telematics data. (20%) 3rd - Dataset documentation. (20%) 4th - Solve database performance issues. (20%) 5th - Build APIs. (10%) Education/Certification Bachelor’s degree in computer science, statistics, engineering, informatics, information systems or similar technical discipline. Certifications in Data Engineering. Overall Experience N/A Directly Related Experience Advanced SQL knowledge and experience with relational databases. Experience with Hadoop ecosystem (Hadoop, Hive, Impala and Spark etc.). Experience with data modeling, data warehousing, and building ETL pipelines. Experience with shell scripting. Experience working in a UNIX/LINUX environment. Proficient in the use of Python and libraries used for parallel computing (e.g. Dask). 2+ years of experience working as a Data Engineer or in a similar role. Preferred Experience: Familiarity with machine learning concepts. Experience with Apache Airflow. Proficiency with Scala. Experience using visualization tools (e.g. Power BI, MicroStrategy, Tableau etc.). Master’s degree. Skills Ability to write high quality, maintainable, and robust code in SQL, Python, Scala. Demonstrated strength in data modeling. Understanding big data analysis techniques: MapReduce, Hadoop ecosystem, Spark etc. Strong problem solving skills based on data analysis Excellent written and verbal communication skills for coordinating across teams. Competencies CHALLENGE - Solving Complex Problems COLLABORATION - Building and Supporting Teams CUSTOMER - Serving Customers GLOBALITY - Showing Community and Social Responsibility PEOPLE - Interacting with People at Different Levels Adapting to Change Championing Customer Needs Communicating Effectively Delivering High Quality Work Entrepreneurial Thinking Managing Resources Equal Employment Opportunities KUS provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, ancestry, national origin, sex, including pregnancy and childbirth and related medical conditions, gender, gender identity, gender expression, age, legally protected physical disability or mental disability, legally protected medical condition, marital status, sexual orientation, family care or medical leave status, protected veteran or military status, genetic information or any other characteristic protected by applicable law. KUS complies with applicable law governing non-discrimination in employment in every location in which KUS has offices. The KUS EEO policy applies to all areas of employment, including recruitment, hiring, training, promotion, compensation, benefits, discipline, termination and all other privileges, terms and conditions of employment. Disclaimer: The above information on this job description has been designed to indicate the general nature and level of work performed by employees within this classification and for this position. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job."
Big Data Engineer,Avani Systems,"Seattle, WA",https://www.indeed.com/rc/clk?jk=af178c911ca9fb16&fccid=4e6bb1d1b2720186&vjs=3,"Job Description: Ensure high throughput of development teams by identifying potential issues, removing impediments or guiding the team to remove impediments by collaborating with the appropriate resource Manage sprint planning and execution which includes the management of project progress and provide status and visibility Facilitate release planning and scheduling by providing empirical Scrum team statistics, identifying project dependencies, and creating velocity forecasts Assist with internal and external communications to improve transparency and radiate information ensuring the team’s progress and successes are highly visible to all stakeholders including the team itself (e.g. backlogs, burn down/up charts, etc.) Develop pipelines using copy activity from different sources like FTP, Windows Blob Storage, SQL SERVER, COSMOS big data etc. and scheduling the pipelines as per requirement using azure data factory. Requirements: Required minimum Bachelor’s degree in Computer Science"
Data Warehouse Engineer,"Analysis Group, Inc.","Boston, MA 02199 (Back Bay area)",https://www.indeed.com/rc/clk?jk=48cd649f13710f8d&fccid=0fc0821efa996180&vjs=3,"Overview: Make an impact at Analysis Group, where we provide our clients with thoughtful, pragmatic solutions to their most challenging business and litigation problems. Analysis Group is one of the largest international economics consulting firms, with more than 1,000 professionals across 14 offices in North America, Europe, and Asia. Since 1981, we have provided expertise in economics, finance, health care analytics, and strategy to top law firms, Fortune Global 500 companies, and government agencies worldwide. Our internal experts, together with our network of affiliated experts from academia, industry, and government, offer our clients exceptional breadth and depth of expertise. The Data Warehouse Engineer will join the Business Intelligence team and will be responsible for optimizing Analysis Group’s data warehouse, ETL processes and tabular models using industry standard best practices. The Data Warehouse Engineer will ensure all warehouse data is accurate and resolve any data issues. This role requires a deep understanding of data modeling and integration practices to efficiently ingest, transform, and provision data across various sources into an organized and unified view. Essential Job Functions and Responsibilities: Design, code, test, and deploy new data warehouse and tabular model features. Design and implement ETL procedures for intake of data from both internal and external sources, using star schema and Kimball Design Methodology. Provide guidance on data modelling best practices for the warehouse and tabular models. Carry out monitoring, tuning, and database and SSAS performance analysis. Troubleshoot production support issues. Ensure that the established standards are followed for application architecture, development, documentation and deployment. Work with the team to evaluate business needs and priorities, liaise with key business partners and address team needs related to data systems and management. Provide guidance on best practices for Business Intelligence data architecture. Qualifications: Bachelor’s degree preferred. Concentration in computer science or related subjects preferred. Minimum 5 years of substantive relevant experience required. An ideal candidate will have 5-8 years of substantive relevant experience. Extensive experience in database management and data warehouse design required. Extensive experience with SQL Server and SSAS (Tabular) databases required Strong analytic skills related to working with complex datasets required Expertise in designing, validating, and implementing projects across the hybrid infrastructure (On-cloud to On-Premise and vice versa) preferred Experience with visualization tools like Power BI preferred C# experience for complex ETL processes (pulling data from web apis, etc.) preferred Experience with DAX preferred Experience with Thompson Reuters Elite 3E preferred Strong analytical and organizational skills. Strong interpersonal, oral, and written communication skills. Excellent attention to detail. Able to effectively work independently and as part of a team. An inclusive and growth-oriented mindset, strong interpersonal skills, and an ability to work across differences. Eligible candidates must be authorized to work in the United States without sponsorship or restriction, now and in the future. Analysis Group embraces diversity and equal opportunity in a deep and meaningful way. We are committed to building teams that represent a variety of backgrounds, perspectives, and skills. The more inclusive we are, the better our work will be. We provide equal opportunities across all sexual orientations, gender identities and expressions, races, colors, ethnicities, mental and physical abilities and characteristics, ages, socioeconomic statuses, and religions, and we encourage candidates of all backgrounds to apply. Other Information: Nothing in this Job Description restricts Analysis Group, Inc.’s right to assign or reassign duties and responsibilities to this position at any time. This position is at will, which means that it can be terminated by the employee holding the position or by Analysis Group, Inc. at any time, with or without cause or notice. Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities. The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. Â: Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities. Please view Equal Employment Opportunity Posters provided by OFCCP here. The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Engineer,Toyota Connected North America,"Hybrid remote in Plano, TX+1 location",https://www.indeed.com/rc/clk?jk=7149521c5bd685c8&fccid=dd616958bd9ddc12&vjs=3,"Data Engineer Toyota Connected's Mobility group is looking for a strong Data Engineer to join our talented team in the development of cutting edge data service and platform products! If you are results driven, would love to work with vehicle telemetry data, are deeply technical, highly innovative and long for the opportunity to build solutions for challenging problems that directly impact the company's bottom-line, we want to talk to you. Responsibilities: Work with a team of data and software engineers to deliver big data streaming platform and data management capabilities. Develop cutting edge software solutions by writing maintainable, extensible, tested code, while complying with coding standards Be hands-on and lead from the front in following best practices in development, microservices design and CI/CD methodologies Facilitate end to end user testing with customers. Troubleshoot, debug and upgrade existing systems. Help bridge gaps between Toyota Connected, other Toyota Entities, and 3rd party suppliers. Work closely with product owners to shape and deliver features to customers. Embrace emerging technology opportunities and contribute to our best practices, driving overall architecture, security, design. Write full-stack software and tooling, ensuring code is well-tested and performant. Develop tools and libraries that will enable rapid and scalable development in the future. Contribute to all aspects of the software development life cycle across multiple, interconnected software products. Qualifications: 3+ years of software and data engineering experience. Solid experience writing clean, concise, tested, maintainable code in Java. Experience building and deploying applications in a public cloud environment such as AWS, Azure, or GCP. Experience orchestrating config-driven deployments using modern CI/CD tooling. Experience in source-control practices such as Git and infrastructure as code such as Terraform or CloudFormation. Hands-on production experience working with Big Data platforms, building and optimizing data pipelines that involve data processing and streaming platforms including work serverless architecture and queuing systems. Experience in test automation frameworks, optimizing performance and security enabling delivery of robust and maintainable architecture. Experience in Agile practices and development techniques such as TDD, BDD and CI/CD. Ability to communicate effectively and work well in a collaborative team environment. Ability to learn and apply new technologies and programming practices. Experience with Spark or Amazon EMR is a plus. Hands-on experience building and delivering IOT, Telematics, or Connected Car products or solutions is a plus. We think the knowledge acquired earning a Bachelor's Degree in Computer Science would be of great value in this position, but if you're smart and have the experience that backs up your abilities, for us, talent trumps degree every time. What's in it for you? In addition to an excellent compensation and benefits package, you'll also receive: A Career Path that allows you to take your career to the next level. Annual $2,500 Training Budget to help you grow and develop your professional skills. Unlimited time off and flexibility for a great work life balance. At TC you'll be treated like the professional we know you are and left to manage your own time and workload. Hybrid work schedule to allow for a blend of in office and remote work OR fully remote work option from CA, CO, GA, IL, MA, MI, MO, NY, PA, TN, TX, UT, or WA Home office stipend of $1,000 to help furnish an ergonomic remote office. Four months of paid parental leave. We want new moms and dads to have an opportunity to bond with their new little bundles of joy. Adoption Assistance of $5,000 for regular adoptions or $6,000 for special needs. We know adoption costs can add up, and we want to help. 401(k) with generous company match that is fully vested day one. Toyota and Lexus vehicle discounts to allow you to drive in style. Generous vehicle allowance for new and leased Toyota and Lexus vehicles. Scratch that vehicle payment off your monthly bills! Annual Patent-a-thons and Hackathons to embrace your superior creative thinking ability. Annual fitness reimbursement to help you balance your overall health without breaking the bank. We also have a Toyota Connected fit club that loves plank competitions! Free catered lunches when working onsite. We try to keep it healthy, but Fridays are ""cheat"" days, so you can get your carbs on! Two fully stocked Nespresso bars for your coffee and tea fixes. Stocked kitchens with healthy snacks including fresh fruit, almonds, mixed nuts, pretzels, trail mix, and flavored waters. Nobody is hangry here! No dress code! Come as you are. We know the smart people we hire don't need to be told what to wear. Free covered garage parking to shield your vehicle from those sneaky storms and to protect your buns from the Texas sun. Who Are We? Toyota Connected is a new company created to infuse the power of big data and cloud intelligence into all aspects of the mobility experience so that driving a Toyota or Lexus is more personal, intuitive and safe. We create and enable technologies that delight, simplify and connect the lives of those who use our products. We believe this mobility revolution will empower our customers to use their vehicles in an array of exciting new ways. We support, celebrate and thrive on the opportunity to provide Mobility for All. Making a connected life a more human experience takes humans from all walks of life. Toyota Connected celebrates and is committed to a diverse and inclusive workplace that embraces you regardless of your race, gender, religion, sexual orientation, skin color, age, disability, military or veteran status, big shot relative, or Instagram fame. Different makes us awesome."
Senior Data Engineer,Cint,"Remote in New Orleans, LA 70130",https://www.indeed.com/rc/clk?jk=bcb4496f6b2b660e&fccid=e53557dfdd590825&vjs=3,"Lucid (a Cint Group company) is a research technology platform that provides programmatic access to first-party data. With respondents in more than 100 countries, Lucid enables anyone, in any industry, to survey online audiences and get the answers they need. These answers reveal the sentiments, motivations, and behaviors of target demographics – data that can be used to build business strategies, measure the impact of digital advertising, publish research, and more. Founded in 2010, Lucid is headquartered in New Orleans, LA with offices throughout the US, Europe, and Asia. Senior Data Engineer Location: New Orleans, LA Responsibilites: Build infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of structured and unstructured data sources using big data technologies preferably using AWS services. Build analytics tools that utilize data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders, including the Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure through multiple AWS regions. Create data tools for analytics and data science team members and assist them in building and optimizing our product into an innovative industry leader. Assemble large, complex data sets that meet functional / non-functional business requirements. Create and maintain optimal data pipeline architecture. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Work with data and analytics experts to strive for greater functionality in our data systems. Telecommuting (remote work) is permitted. Qualifications Requires a Master's degree in Computer Engineering, Computer Science, Statistics, Informatics, or a related field plus 5 years of related work experience. Requires 5 years of experience in the following: Advanced working SQL knowledge; working with relational databases, query authoring (SQL) and databases and CDC processes, including MSSQL and PgSQL, with Custom Code written in Python, Java, or Scala; Using Spark for large-scale distributed processing with custom code written in Java and Scala and messaging layer using Kinesis; AWS cloud services, including EC2, EMR, RDS, Redshift, Athena, and Lambda; Working in the languages of Python, Java, and Golang; and Spark-streaming that is specifically used with the ability to Code in Scala and Java, such as Storm or Spark-Streaming. Lucid's Hiring Commitment At Lucid we foster a collaborative and inspiring workplace. We pride ourselves in doing this by recruiting, hiring and retaining diverse, passionate, and forward-thinking talent. Lucid is committed to and encourages an inclusive environment and we are dedicated to providing equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please let us know."
Data Engineer- Remote,WESTAT,"Remote in Rockville, MD+1 location",https://www.indeed.com/rc/clk?jk=036ef6f6e9cbf877&fccid=1e7fef0b4511d646&vjs=3,"Westat is an employee-owned corporation providing research services to agencies of the U.S. Government, as well as businesses, foundations, and state and local governments. Westat's research, technical, and administrative staff of more than 2,000 is located at our headquarters in Rockville, Maryland, near Washington, DC. Job Summary: We are seeking a Data Engineer to be part of our DataOps team that includes solution architects, software engineers, data management specialists and data scientists. You will contribute to the design of scalable data solutions including the development of automated and batch ETL data pipelines to ingest and validate data to a modern data repository system. Job Responsibilities: Develop and manage high performing, flexible data pipelines and data processes. Work with domain experts to translate data requirements to processing specifications. Monitor performance and data quality using automated testing frameworks. Stay apprised of emerging methods, technologies and best practices related to data acquisition. Contribute to the design and optimization of SQL and NoSQL data repositories. Contribute to the development of data quality assurance plans and KPIs. Contribute to the management of risk and the design of system redundancies. Basic Qualifications: A Bachelor’s degree, preferably in computer science or related field. 2 or more years of relevant experience. Proficient with processing languages such as Java, Python, R or SQL. Proficient with relational databases, stored procedures and storage optimization techniques. Preferred Qualifications: Experience with business intelligence tools such as Power BI. Experience with developing data visualizations using open source libraries such as D3 and/or SaaS. Experience with developing APIs using languages such as C#. Familiarity with NIST 800-53 security controls. Familiarity with native cloud services such as AWS Lambda and AWS Glue. Familiarity working within a DevOps process driven environment and tools such as GitLab or Jenkins. Minimum Qualifications: Excellent communication and organizational skills. Able to manage multiple tasks simultaneously; be detail-oriented; and work well in a fast-paced team environment. Westat offers a well-rounded and comprehensive benefits program focused on wellness and work/life balance. Eligible employees may participate in: Employee Stock Ownership Plan 401(k) Retirement Plan Paid Parental Leave Vacation Leave Sick Leave Holiday Leave Professional Development Health Advocate Employee Assistance Program Travel Accident Insurance Medical Insurance Dental Insurance Vision Insurance Short Term Disability Insurance Long Term Disability Insurance Life and AD&D Insurance Critical Illness Insurance Supplemental Life Insurance Flexible Spending Account Health Savings Account Protecting the health and safety of our employees and survey participants is a top priority for Westat. As a federal government contractor, Westat will require Westat staff, regardless of work location, to provide proof that they are fully vaccinated against COVID-19 upon hire and to follow all safety protocols, subject to approved accommodations under applicable law. Westat is an Equal Opportunity Employer and does not discriminate on the basis of race, creed, color, religion, sex, national origin, age, veteran status, disability, marital status, sexual orientation, citizenship status, genetic information, gender identity or expression, or any other protected status under applicable law. Career Area Computer Systems and Applications Pay Range $65,000 - $86,700 Bonus Eligibility Yes"
Quality Data Solutions Engineer,"JPMorgan Chase Bank, N.A.","Columbus, OH",https://www.indeed.com/rc/clk?jk=54f47f16bd4bf5fe&fccid=aaf3b433897ea465&vjs=3,"Performance Consulting is a Center of Excellence (CoE) responsible for leading critical reengineering and diagnostic efforts throughout the business, with the ultimate goal of improving both operating and financial performance. Typical projects are commissioned by senior executives and leaders throughout CCB and focus on the business's most urgent process improvement, organizational change, and/or functional strategy development needs. Typical engagements (not exhaustive) include: Operations Strategy Organization Design & Governance Business/Function Transformation Operating Models Quality Program Implementation Process Design Operational Risk and Controls Performance Consulting follows a hypothesis-driven, fact-based approach to problem solving. The ability to solve critical business problems along with the diversity and backgrounds of individuals distinguish Performance Consulting from other areas of the Firm. Typical project teams are comprised of 2 to 4 members, many of whom are former management consultants (internal or external). Projects are usually 4 to 12 weeks long, depending on complexity and scope. We are currently seeking qualified individuals who can work with the senior management on the Performance Consulting team to identify opportunities to improve processes (e.g., drive efficiencies, improve the customer experience, reduce risks, etc.), conduct robust analysis to quantify the opportunities identified and present findings in a clear and concise manner to senior leadership. The candidate will own aspects of the engagement, but collaborate as part of a larger project team. Activities may include conducting interviews and side-by-sides with clients, analyzing various data sources, compiling presentations and syndicating results with partners across the firm. Responsibilities: Collaborate with businesses to identify populations and sub-set data for quality test sampling Creatively solve for data acquisition and migration Assess business processes and implement Quality Management Systems solutions to standardize processes and improve pass rates while reducing rework Support engagements that drive Quality, Cost, Productivity and Service Delivery projects to completion using formal process improvement methodologies such as Lean, Six Sigma and/or Capacity Planning. Gather, model and analyze data to test hypotheses and size opportunities of major change programs and process improvement projects Develop and refine recommended solutions to address issues and capture opportunities. Compile presentations to summarize findings/recommendations and take part in syndication process to senior management. Partner with stakeholders in all activities. Demonstrate a strong desire to learn new concepts, tools and business practices by taking direction from managers and senior consultants and following through on tasks and assignments. Drive end-to-end process redesign and performance improvement through the identification and elimination of waste (non-value added activities) Build organizational capability through strong relationships with internal clients and team members Use project management skills to break down work into process steps, develop schedules, and work within time constraints. Apply analytical / quantitative approach to problem solving; e.g., organize and analyze data through statistical concepts. Identify key metrics aligned with client initiatives to help establish baselines and estimate appropriate targets. Use strategic thinking and planning skills/abilities to drive innovation. Serve as a Change Agent and contribute to the Continuous Improvement Culture. Qualifications: Experience with data management and code development highly preferred; ACES software experience are a plus Experience with implementing or auditing Quality Management Systems, e.g. ISO 9000, AS 9000, TS 16949; lead assessor training a plus Bachelor's degree from a competitive school, demonstrating a strong academic and extracurricular track record Have experience in strategy, process improvement or reengineering efforts within an operations environment Experience in financial services operations strategy or consulting preferred, but not required Banking experience within Retail Operations, technology and other support functions preferred but not required Formal LEAN and Six Sigma training a plus, or demonstrated excellent problem solving and communication skills Proven ability to prioritize and efficiently complete assignments while maintaining the highest quality Exceptional organizational skills Exceptional facilitation skills with ability to bring teams to consensus Knowledge of change management principles, methodologies and tools (experience with Prosci/ADKAR methodology or similar formal change management methodologies is a plus) Experience in robotics/automation, quality or strategy Ability to travel as needed (e.g., ranges of 25% to 50%; will vary by project) Required Skills: Project management skills - Candidate must be able to scope projects, create workable project plans and execute on such plans. The Associate will be staffed on multiple projects simultaneously, so the ability to balance competing priorities and appropriately set expectations is key. Problem solving skills - Candidate must demonstrate end-to-end generalist problem solving skills, including the ability to define and deconstruct problems, identify and prioritize key issues Analytic skills - gather data, structure and execute quantitative and qualitative analyses, financial modeling, perform competitor/industry research, conduct interviews, synthesize findings, and develop actionable recommendations. Client management skills - Candidate must demonstrate the ability to closely partner with senior and line managers and other stakeholders on projects. Collaboration with business partners will be critical to ensuring successful project delivery. Communications and influencing skills - Candidate must possess excellent written and oral communications skills. Teamwork skills - Candidate must be flexible in his/her work style and be able to work with stakeholders and colleagues at all levels. Must have excellent skills with MS Excel, PowerPoint, Visio or iGrafx and other Microsoft Office applications. Personal traits - Candidate must be a results-focused, highly-motivated, self-starter. Chase is a leading financial services firm, helping nearly half of America's households and small businesses achieve their financial goals through a broad range of financial products. Our mission is to create engaged, lifelong relationships and put our customers at the heart of everything we do. We also help small businesses, nonprofits and cities grow, delivering solutions to solve all their financial needs. We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs. The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment. As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law. Equal Opportunity Employer/Disability/Veterans"
Data Engineer,Carnegie Mellon University,"Pittsburgh, PA 15213 (Squirrel Hill North area)",https://www.indeed.com/rc/clk?jk=b4cbbf1ebe0bd31e&fccid=7655fb7543c6cbbf&vjs=3,"The National Robotics Engineering Center (NREC) at Carnegie Mellon University is looking for data scientists to develop tools to support machine learning and data-intensive applications. We are people with a desire to make robust software using agile development processes. You will work on a variety of software for commercial and government organizations. You will bring together open-source, commercial, internal, and your own tools to support diverse data processing workflows. Some of our machine learning software keeps self-driving vehicles safe, automatically discovers new pharmaceuticals, and leads to less waste in agriculture. You will support programs in deep learning for agriculture, artificial intelligence for defense, and autonomous manipulation. Why NREC? You will have an impact in shaping the robotics revolution, collaborate with and learn from experts,and build your career in a very fast-growing field. As part of our team, you will develop solutions to solve industrial and government challenges, deploy your technology in real-world situations, work side-by-side with elite robotics experts, and develop a variety of cutting-edge technologies. Have an Impact! Remove waste from farming = more food ( link ) Make industrial processes environmentally friendly ( link ) Make hazardous jobs safer ( link ) Improve efficiency in industry & manufacturing ( link ) Accelerate screening of pharmaceuticals ( link ) Take Control of Your Career! Select the career pathway that interests you Influence the direction of projects Supportive of a non-standard schedule Maintain work/life balance Switch between part-time and full-time as life demands NREC is at the center of the robotics ecosystem in Pittsburgh, PA. With over 60 robotics companies, Pittsburgh has become the robotics capital of the world. Geek Wire calls it Robotics Row ; others call it Roboburgh . Join the leader in the most exciting time in robotics! Join the best robotics R&D group Join our talented team at NREC, an operating unit within the world-renowned Robotics Institute at Carnegie Mellon University. NREC has 20+ years of experience and is globally renowned for developing and deploying robots into many applications across multiple sectors, such as agriculture, mining, defense, energy, and manufacturing. We strive to provide solutions for real world challenges where automation and robots have greater impact on productivity and improve the safety and comfort of the labor force. Our unique expertise places us at the forefront of unmanned ground vehicle design, autonomy, sensing and perception, machine learning, machine vision, operator assistance, 3D mapping and position estimation. With over 120 robotics professionals, we can solve challenges that no other organization can. NREC also leads in educational outreach through its Robotics Academy, which builds robotics curricula and software for K-12 and college-level students. Your primary responsibilities include: Developing data pipeline for machine learning, computer vision, and robotic applications Adapting and integrating proprietary and open source software packages and APIs Data preparation, ingestion, integration, verification Participating in the software process: design, code reviews, etc. Developing, documenting, testing, and fixing software Supporting development and acquisition of storage and networking hardware Database deployment and administration Webserver deployment and maintain You must be willing to travel for up to 10% for field testing. Qualifications: B.S. in Computer Science, Engineering, Mathematics is required (Any more is a bonus) >=1 year relevant industry experience is required. Demonstrated understanding and use of software engineering concepts, practices, and procedures. Proficient development skills in Python Proficient in data infrastructure tools (SQL DB, NoSQL DB, data version control, etc.) Technical communication skills Ability to participate in a multi-disciplinary team We especially want to hear from you if you have experience or qualifications in ANY of the following areas: MLOps tools (airflow, mlflow, etc.) Deployment tools (docker, kubernetes.) Cloud, high performance, and distributed computing Ingestion and integration of disparate sources Data processing (pre-processing, augmentation, post-processing) Tools and protocols for reproducible research and data analysis Front end (Data visualization, exploration, labeling) Proficient C or C++ skills Professional software development processes Networking interfaces and applications CMake, Valgrind, and other development tools Computer vision, robotics, machine learning, scientific computing, simulation, or graphics At NREC, we value diversity, support it, and thrive on it for the benefits of our organization, our employees and our community. CMU’s COVID-19 Vaccination Requirements: As a condition of employment, Carnegie Mellon University requires all staff and faculty working in the United States to be fully vaccinated, including a booster when eligible, against COVID-19. Prior to commencement of employment, new hires in the United States must provide proof of vaccination or obtain an approved exemption. (Exemptions may be requested for medical reasons or for religious or strong moral or ethical conviction.) Those granted an exemption must comply with all applicable COVID-19 mitigation requirements. The most up-to-date information on CMU's COVID-19 mitigation requirements can be found here: Minimum Requirements to Return to Campus . Location Pittsburgh, PA Job Function Engineering, Research and Project Scientists Position Type Staff – Regular Full Time/Part time Full time Pay Basis Salary More Information: Please visit “ Why Carnegie Mellon ” to learn more about becoming part of an institution inspiring innovations that change the world. Click here to view a listing of employee benefits Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran . Statement of Assurance CMU’s COVID-19 Vaccination Requirements: As a condition of employment, Carnegie Mellon University requires all staff and faculty working in the United States to be fully vaccinated, including a booster when eligible, against COVID-19. Prior to commencement of employment, new hires in the United States must provide proof of vaccination or obtain an approved exemption. (Exemptions may be requested for medical reasons or for religious or strong moral or ethical conviction.) Those granted an exemption must comply with all applicable COVID-19 mitigation requirements. The most up-to-date information on CMU's COVID-19 mitigation requirements can be found here: Minimum Requirements to Return to Campus . Location Pittsburgh, PA Job Function Engineering, Research and Project Scientists Position Type Staff – Regular Full Time/Part time Full time Pay Basis Salary More Information: Please visit “ Why Carnegie Mellon ” to learn more about becoming part of an institution inspiring innovations that change the world. Click here to view a listing of employee benefits Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran . Statement of Assurance"
Data Engineer,Atlantix Careers,"Remote in Fort Lauderdale, FL+1 location",https://www.indeed.com/rc/clk?jk=18c66ca6c9428b07&fccid=dd616958bd9ddc12&vjs=3,"Atlantix Partners is On the Grow! We're hiring a Data Engineer to join our team. The ideal candidate is a hands-on leader with a real passion for solving problems, has ability to wear multiple hats, and can work with our onshore and offshore teams to deliver on client challenges through their data engineering talents. You'll collaborate across all lines of business with a high-caliber team of experienced professionals and will have the opportunity to gain a broad base of experience working with mid-market companies across a wide spectrum of industries. Your primary focus will be to help lead the team through your data engineering expertise by designing and optimizing the data and data pipeline architecture across our client-base; designing and implementing data models that align with data warehouse standards; and providing documentation, training and consulting with internal and external clients. Essential Duties & Responsibilities Provide technical expertise in data pipeline design and development in Python and PySpark Contribute technical expertise in data warehouse architecture and management Define and document processes related to data transformation, data structures, metadata, dependency and workload management Participate in solution architecture requirements gathering and evaluate business needs and objectives to inform architecture design Extend company's data with third party sources of information when needed Enhance data collection procedures to include information that is relevant for building analytic systems Process, cleanse, and verify the integrity of data used for analysis Effectively communicate complex issues and solutions Manage multiple projects with tight, sometimes overlapping deadlines Required Skills / Experience 3+ years as a Data Engineer with hands-on coding experience creating data pipelines in Python 2+ years experience creating data pipelines using PySpark in Databricks 2+ years of hands-on coding experience in SQL Experience with managing and scaling cloud data warehouse (Snowflake) Experience with AWS ecosystem – S3, Amazon RDS, Amazon ML ecosystem Excellent communication skills with the ability to effectively communicate complex issues and solutions at all levels Bachelor's degree in Computer Science or Software Engineering with master's degree a plus Work locations in Eastern or Central U.S major cities will be considered with the ability to travel to office and client locations About the Company Atlantix Partners delivers transformation, transaction, and compliance consulting services to middle-market companies. Our team focuses on increasing the return on investment and mitigating risk. Our professionals are knowledgeable and skilled leaders who focus on a singular goal: to deliver measurable, lasting results that create value for our clients. What differentiates us from our competitors is the combination of our technical knowledge, industry expertise, and prior leadership experience. Our professionals come from large national consulting or public accounting firms and have been business, finance, and technology leaders. This first-hand knowledge allows us to leverage our experience into practical, common-sense solutions for our clients. Our business is growing at a rapid rate. The ideal candidate will share the Atlantix passion for client service and delivering quality results. You must be hands-on and excited about working with integrated teams of IT, accounting, finance, and process professionals to find solutions for our clients. Atlantix Partners is headquartered in Ft. Lauderdale, Florida. Competitive base salary, annual bonus, flexibility, and excellent full benefits package including Health, Dental, Vision, Life, Disability, 401(k), and more. ALL INQUIRIES ARE KEPT CONFIDENTIAL. Equal Opportunity Employer."
Data Engineer,Exodus Integrity Services,"Cleveland, OH",https://www.indeed.com/rc/clk?jk=e4f2d2483b6fa288&fccid=fefbcbf3019073c3&vjs=3,"Exodus Integrity Services, Inc is a rapidly expanding technology company headquartered in Northeast Ohio. EIS provides quality services to our clients by instilling honesty, commitment, and hard work to find the most qualified candidates to fill each opportunity. Currently, we are seeking individuals to fill an opportunity for our client in Cleveland, OH. This is a very exciting opportunity working with one of the top employers in the area. If you are interested in joining a vibrant organization where you are valued and rewarded for your contributions, and you possess the qualifications listed below, please forward your resume and salary requirements. Data Engineer Requirements SQL Data Warehousing Hadoop ETL Tools Python/R Exodus Integrity Services (EIS) is an equal opportunity employer. In accordance with anti-discrimination law, it is the purpose of this policy to effectuate these principles and mandates. EIS prohibits discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. EIS conforms to the spirit as well as to the letter of all applicable laws and regulations.”"
Data Center Engineer II,Astreya,"Sunnyvale, CA+1 location",https://www.indeed.com/rc/clk?jk=3ad9015088da49bc&fccid=f7fcb231ff95ee5c&vjs=3,"Company Description Astreya is the leading IT solutions provider to deliver technology-enabled services and fuel digital transformation to some of the most exciting companies on the planet. We are at the cusp of a new way of working with our delivery model that helps our clients be positively productive by matching exceptional people to on-site teams delivering world-class IT service. With engineers in over 30 countries and 70 cities around the world, we are a global company working with the world's most recognizable and innovative organizations. Job Description What this Job Entails: The Data Center Engineer II will be heavily involved in the design of the datacenter collocations, infrastructure hardware, and provide technical consultations. The incumbent will build/create all drawings for datacenter POP’s and develop/write Scopes of Work (SOW) for new POP builds. The Data Center Engineer will create detailed installation MOP’s (Method of Procedure) for multiple types of optical transport and switching equipment, overheads (fiber raceway, ladder, basket) and power AC/DC. The incumbent will also communicate with all departments and provide tech support for Network Engineers. Scope: Resolves a wide range of issues in creative ways Seasoned, experienced professional with a full understanding of their speciality Works on problems of a diverse scope Receives little instruction on day to day work, general instruction on new assignments Your Roles and Responsibilities: Deploy, configure, and support a large-scale production and corporate network and server infrastructure in data centers and Point of Presence (POP) sites. Calculate and document equipment power requirements and work with Engineering, Facilities Operations, and/or collocation vendors to meet these requirements. Manage project timelines to support network turn-up within expected completion intervals. Responsible for asset management of networking gear in datacenter and POP sites. Contribute to documentation, automation and processes as they evolve. Create network and server rack face elevations, floor plans, wiring diagrams, and detailed port maps for new deployments and documentation. Create statements of work for vendors at the POP sites. Create cage and rack designs and understand the overall needs of POP infrastructure. Document and follow RMA processes and procedures for all relevant vendors. Assist in following, improving, and implementing data center and POP best practices. Work closely with Network Engineering, Logistics, and equipment vendors as new equipment and technologies are integrated into the production network. Other duties as required. This list is not meant to be a comprehensive inventory of all responsibilities assigned to this position Required Qualifications/Skills: Bachelor’s degree (B.S/B.A) from four-college or university and 2 to 5 years’ related experience and/or training; or equivalent combination of education and experience Builds productive internal and external working relationships Exercises judgment within defined procedures and practices to determine appropriate action Understanding of Data center practices (i.e. cable routing, calculating power usage and cooling). Familiarity with creating As-Built drawings for Datacenter POPs and creating the 3rd module on DC-CAD Knowledge of how to build/create SOW’s for new POP builds Understanding of field-based work in POPs, carrier hotels, or Central Office environments. Understanding of fiber-optic technology including cable types, connector types, optic types, patch panels, and optical transport technologies. Excellent communication skills, should be able to work with carriers/vendors Understanding of importance of dealing with service providers and colocation facilities Ability to work within a global team in a fast-paced and dynamic environment with limited supervision Strong attention to detail with excellent time management and organization skills Preferred Qualifications: Physical Demand & Work Environment: Must have the ability to perform office-related tasks which may include prolonged sitting or standing Must have the ability to move from place to place within an office environment Must be able to use a computer Must have the ability to communicate effectively Some positions may require occasional repetitive motion or movements of the wrists, hands, and/or fingers What can Astreya offer you? Employment in the fast-growing IT space providing you with a variety of career options Opportunity to work with some of the biggest firms in the world as part of the Astreya delivery network Introduction to new ways of working and awesome technologies Career paths to help you establish where you want to go Focus on internal promotion and internal mobility - we love to build teams from within Free 24/7 accessible Professional Development through LinkedIn Learning and other online courses to give you opportunities to upskill at your own pace Education Assistance Dedicated management to provide you with on point leadership and care Numerous on the job perks Market competitive compensation and insurance, health and wellness benefits Additional Information Astreya Partners is an equal employment and affirmative action employer. We evaluate qualified applicants on merit and business needs and not on race, color, religion, creed, gender, sexual orientation, national origin, ancestry, age, disability, genetic information, marital status, veteran status or any other factor protected by law. #INDG1 #LI-GN1"
Data Engineer,CommonSpirit Health,"Remote in Chicago, IL 60606",https://www.indeed.com/rc/clk?jk=48e78c56b9552ace&fccid=0496d9a56f91d03d&vjs=3,"Overview CommonSpirit Health was formed by the alignment of Catholic Health Initiatives (CHI) and Dignity Health. With more than 700 care sites across the U.S. & from clinics and hospitals to home-based care and virtual care services CommonSpirit is accessible to nearly one out of every four U.S. residents. Our world needs compassion like never before. Our communities need caring and our families need protection. With our combined resources CommonSpirit is committed to building healthy communities advocating for those who are poor and vulnerable and innovating how and where healing can happen both inside our hospitals and out in the community. Responsibilities Job Summary / Purpose Work from Home This Data Engineer will support payment integrity compass (PIC) which is a revenue cycle contract management application. They will monitor data as it passes from patient accounting systems to (PIC) payment integrirty compass. They will also assist with reporting, setup and maintaining security. Candidate must have experience with healthcare. Experience with SQL, SSAS, excel and a visualization work tool either Tableau or PowerBI are strongly preferred. The Data Engineer I develops data models and maintains foundational data architecture supporting Payer Strategy & Relationships (PSR) initiatives. This role manages information using relational databases, database management systems and tools. The Data Engineer I acts as a liaison between super users, data architects, programmers, and analysts to implement and enforce data integrity standards and procedures to ensure data is managed consistently and appropriately integrated within data marts and databases. Additionally, the Data Engineer I manipulates and integrates data from various sources to enlarge and enhance the data repository and is responsible for coding and documenting procedures, programming, testing and debugging. Essential Key Job Responsibilities Develop scripts to automate routine and repetitive database SQL tasks using standard integration processes. Interact regularly with team members and clients to improve data structure, ETL processes, and application performance. Provide production support as required to ensure the availability and performance of developed applications for both external and internal users. Develop stored procedures, triggers, functions and views to support PSR initiatives. Develop SQL queries in the creation of business applications and SQL reports from corporate data sources. Evaluate, design, develop, implement and maintain PSR repository using industry standard database tools. Create and support data integration process through database refreshes and SSIS. Maintain data integrity by working to eliminate redundancy. Support PSR to continuously improve upon the current work/business processes to achieve high levels of effectiveness and efficiency. #LI-remote Qualifications Required Skills and Education Bachelor of Science in Computer Science or related technical field. Education and experience may be considered in lieu of degree. Minimum of three (3) years of Information Technology (IT) experience in a fast-paced, complex business environment. Healthcare industry experience required. Experience with relational database management systems (RDBMS) such as SQL Server, Oracle, DB2, MySQL, PostgreSQL. Experience developing SQL queries in the creation of business applications and SQL reports from corporate data sources. Proven ETL development and data integration between multiple data source systems. Detailed analytic problem-solving skills, documentation, communication and flexibility with strong attention to detail in high pressure situations. Ability to manage time, work within a team environment to meet project goals/deadlines. Ability to work on multi (Technical/Business) environments and train end users. Familiar with SSIS/T-SQL troubleshooting and debugging skills. Preferred Skills Experience in payer contract analysis and payer process preferred Experience with healthcare claims and remit data preferred Experience in medical and billing data preferred A compensation range of $70,000 - $106,000 is the reasonable estimate that CommonSpirit in good faith believes it might pay for this particular job based on the circumstances at the time of posting. CommonSpirit may ultimately pay more or less than the posted range as permitted by law and according to geographic pay area. While you’re busy impacting the healthcare industry, we’ll take care of you with benefits that include health/dental/vision, FSA, matching retirement plans, paid vacation, adoption assistance, annual bonus eligibility and more!"
Data Engineer - 100% Remote,AAA Careers,"Remote in Coppell, TX 75019+1 location",https://www.indeed.com/rc/clk?jk=f529df07dfa1841a&fccid=a927cf5ed0a9812c&vjs=3,"Please Note: This position is 100% remote, however you must reside within driving distance of our offices in Coppell, TX to attend meetings and team collaboration. The Data Engineer is a member of the Insurance Data Team. They will play a critical role on the team developing data pipelines for ingestion and enablement in data warehouses, data lakes and public/private cloud platforms (AWS, GCP, CDP, etc) Responsibilities: Develop, manage, and maintain data pipelines for Insurance Data needs on Cloud (AWS and GCP) and Hadoop platforms Develop low friction APIs, highly responsive RESTful web UIs, and the backend to support them. Utilizing Team Foundation Server Git, Jenkins, Ansible, Nexus IQ/Repo and SonarQube to enable CI / CD. Develop automation using scripting languages such as Python, Shell, PowerShell, and Bash Support Hadoop Applications such as Sqoop, Hue, Impala, Hive, Hbase Implement and support streaming technologies such as Kafka, Spark & Kudu Partner with the infrastructure, network, marketing, application, and business intelligence teams to guarantee high data quality and availability. Work with enterprise and solution architects to develop a Big Data cloud architecture and implement. Working as part of DevOps teams to accelerate the delivery of business value. Job Requirements: 4+ years of experience as a Developer with at least 2 years in a Cloud Service environment Solid understanding of Cloud technology (preferably AWS- EC2, S3, Lambda, API Gateway, GLUE) and Big Data platforms (Hadoop) Demonstrated proficiency with at least one modern general-purpose programming languages (Java, C++, Python, etc.) Experience building low friction APIs, highly responsive RESTful web UIs, and the backend to support them. Experience with data modeling and business logic. Experience with Cloud security and Microservices. Familiarity with DevOps software development methods. Strong fundamentals in data structures, algorithm design, and complexity analysis. Ability to work with a variety of teams and be passionate about building cutting-edge solutions to solve problems with the right technologies. Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, testing, deployment and operations. Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs. Experience with automated deployments and source code/configuration management tools such as GitHub, AWS Cloudformation, Jenkins, Terraform, etc Ability to understand the big picture and drive the initiatives the lead to completion of the overall big picture Excellent time management skills, strong organizational skills and detail orientation required. Strong verbal and written communication skills and must also be a logical thinker with the ability to communicate clearly and effectively. #LI-SJ1 Remarkable benefits: Health coverage for medical, dental, vision 401(K) saving plan with company match AND Pension Tuition assistance PTO for community volunteer programs Wellness program Employee discounts AAA Texas is part of the largest federation of AAA clubs in the nation. We have 14,000 employees in 21 states helping 17 million members. The strength of our organization is our employees. Bringing together and supporting different cultures, backgrounds, personalities, and strengths creates a team capable of delivering legendary, lifetime service to our members. When we embrace our diversity – we win. All of Us! With our national brand recognition, long-standing reputation since 1902, and constantly growing membership, we are seeking career-minded, service-driven professionals to join our team ""Through dedicated employees we proudly deliver legendary service and beneficial products that provide members peace of mind and value.” AAA is an Equal Opportunity Employer"
Data Quality Engineer lll,AbleTo,"Remote in New York, NY 10018+1 location",https://www.indeed.com/rc/clk?jk=6034e830e21e5485&fccid=954e57501f6bca1f&vjs=3,"About AbleTo Join our mission-driven organization, where your work matters and a diversity of ideas and backgrounds are welcomed. AbleTo is the leading provider of high quality, technology-enabled behavioral health care. We believe that everyone deserves access to high-quality care and offer a suite of technology-enabled services to empower people to lead better lives through better mental health. A proprietary platform connects individuals with AbleTo highly trained licensed providers who deliver weekly sessions by phone or video supported by an integrated digital experience. Members also have access to mental health coaches, and digital support programs. Our outcomes-focused approach is proven to improve both behavioral and physical health and lower medical costs. Overview As a key member of AbleTo's data engineering team, you will be responsible for ensuring we get it right the first time by driving quality automation throughout our SDLC and participating as a peer engineer within our Lean-Agile product engineering group. You will work with our talented team of remote engineers, designers and product managers to ensure the highest quality of the systems that manage our member's care journey. We are a team committed to agile value delivery and solid engineering principles, as well as continuously improving our craft. If you love shipping software that delivers deep and meaningful impact to people's mental and behavioral health, join us! What You'll Do: Work as part of a fast paced and highly motivated Agile team to help design, build and test new features. Participate in sprint planning, backlog grooming, daily-standups, and retrospectives during a 2 week sprint cadence. Work closely with product managers and data engineers to identify test cases and devise efficient and repeatable testing processes. Review other team members' work and hold other team members accountable for high quality software. Coach, mentor and develop team members. Ability to complete high quality work with minimal supervision. Perform ETL testing and verify against requirement specifications for data correctness and data completeness of data. Define test automation strategy, lead the implementation & execution of automated test cases, and analyze test outputs. Catalog software defects and collaborate with peer engineers to ensure they are resolved and thoroughly retested. Work with Data Engineering management to identify and implement process improvements to continuously improve the team's productivity and efficiency. Who You Are: Bachelor's degree in Computer Science or equivalent practical experience. 10+ years experience in ETL/Data Integration Testing (e.g., Data Warehouse, Data Lake). Advanced to Expert SQL skills (inc. data profiling). Demonstrated experience of ETL tools (e.g., Informatica preferred). Knowledge of working with Big Data on a Cloud Platform (GCP preferred) Knowledge of at least one scripting language (eg., bash). Basic knowledge of Python. Experience using version control systems such as Git and an understanding of Data Pipelines and workflow management tool (eg., Airflow, Luigi) Experience testing reports and dashboards on visualization applications (eg., Looker, Tableau) Extensive experience setting up, running and maintaining scripted automation frameworks for data teams. Experience working with Unix/Linux operating systems. Demonstrated knowledge of test methodologies, test design and extensive QA workflow experience. Excellent verbal and written communication skills. Proven ability to build and maintain strong, productive working relationships with internal stakeholders and external customers. Clinical/Healthcare product experience is a plus Why You Should Join Our Team: We're proud to be a Great Place to Work-Certified™ company. We want you to show up and feel your best at work, and that means respecting your time outside of work. Our inclusive, flexible workspace prioritizes a work/life balance. We offer competitive salaries, comprehensive health benefits (for full-time employees), and professional perks such as 401K matching, fully funded HRA, and generous time off, including mental health days because your well-being is important to us. At AbleTo, we're empowering people to get better and stay better. Want to join us? Take the next step in your career by applying for this role today. #LI-Remote Follow AbleTo on LinkedIn, Twitter, and Instagram! Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice. AbleTo is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status. AbleTo is an E-Verify company."
Data Engineer,sharethrough,"Denver, CO+4 locations",https://www.indeed.com/rc/clk?jk=9d1453c834748bfa&fccid=420b591004b16413&vjs=3,"Sharethrough is disrupting the legacy digital advertising supply chain as the first ad exchange to auto-enhance every standard impression by rendering a higher-performing ad that dynamically fits into any placement on any site. Our technology and approach enables advertisers to see substantial campaign performance improvements and cost savings using the same standard video and display creative as well as the buying workflow they use with standard exchanges. The Sharethrough Exchange (STX) powers over 225 billion monthly impressions and is integrated with more than 30 of the world's largest demand side platforms, enabling buyers to efficiently achieve their marketing objectives at scale. We believe that access to an independent and open Internet is a critical human right. By building a sustainable advertising ecosystem for journalists, content creators, and app developers, we can help them and their users thrive. We are looking for Engineers to join our growing Data Engineering team who are thrilled by the complicated data challenges the advertising space offers. You’ll be using a very large database (petabytes of event data in Snowflake) that is clean, flexible, and fast. Our robust Airflow ETL system provides high levels of data integrity. Sharethrough operates in a quickly changing business environment, with plenty of challenges at the ground level. About the Role Ensure that our Looker implementation and Snowflake data warehouse work well together Use your master SQL skills to craft robust, accurate and sustainable data solutions Drive data modeling and data structure design Become a go-to expert around internal company data and SQL Although this position is not about keeping our data pipeline running, you will be writing Airflow ETLs About You 3-5 years in a data engineer or SQL-heavy data analyst role Expert level SQL and interpretation of query execution plans ETL and big data pipeline experience General understanding or interest in Looker architecture and its SQL generation Experience with data warehousing architecture and data modeling Experience and good understanding of AWS stack Python experience What's In It For You? Competitive compensation packages Generous group health insurance plan Access to the virtual healthcare platform Access to the company's stock option plan 16 days of vacation per year, which increases with seniority at the company 3 paid Caring days 1 paid volunteer day Offices closed during the holidays Wellness allocation of $840 per year (for gym memberships, sportswear, etc.) In-house training programs on our company and industry Encouragement and funding of continuing education and training Very active social committee and free online sports classes Access to a tool that measures your engagement and job satisfaction anonymously Pairing with a buddy for your first 6 months Advantageous referral program Inclusive, inspiring, and dynamic work environment Casual dress code Work from home and flexible hours And more!"
"DATA ENGINEER - SQL, .NET, AWS",InspiHER Tech,Remote,https://www.indeed.com/rc/clk?jk=982122e46c0ef064&fccid=f4d8d9827523c093&vjs=3,"Published December 13, 2021 Location 100% Remote, United States of America Job Type Full-time DESCRIPTION TITLE: Data Engineer- SQL, .Net, AWS #11004 JOB ID: 11004 LOCATION: 100% Remote SALARY: $85-110K + Bonus STATUS: Full-time, US Citizen About the Client: A leader in technology-enabled solutions for the Supply Chain Industry. Our client excels at helping their customers have real-time access and visibility to their data with comprehensive reporting for better decision making. About the SQL .Net Data Engineer Position: Database Engineers contribute to the management and design of large-scale database systems. While supporting the architectural vision of quality, scalability, function, and performance. About the SQL .Net Data Engineer Responsibilities: Code, install, optimize, and debug SQL database queries and store procedures using appropriate tools or editors. Develop ad-hoc scripts, including clean-up scripts as needed. Identify and correct performance bottlenecks related to SQL code. Perform code reviews, providing feedback in a timely manner. Collaborate with team to develop database structures that fit into the overall architecture of the systems under development Provide development expertise to team members through education and review present technical ideas and concepts in business-friendly language Proactively monitor database trends and act to improve database systems and processes. Provide recommendations, analysis, and evaluation of systems improvements, optimization, development, and/or maintenance efforts including, but not limited to capacity planning. Develop ad-hoc scripts, including clean-up scripts as needed. Contribute to selection and design of tools required for management of the database and transaction processing environments. Support and be accountable for timely product releases and adherence to release activities. Contributes to the development of database maintenance plans and data retention strategy. About the SQL .Net Data Engineer Requirements: 5 years managing enterprise-level database systems leveraging the following: Microsoft SQL Server T-SQL MS SQL Server Integration Services (SSIS) Adept at creating stored procedures, views, user-defined functions, table functions Clear understanding of (.Net core) Object-Oriented programming techniques Bachelor’s degree required, Masters preferred."
Data Engineer,Sotheby's,"Remote in New York, NY 10022+1 location",https://www.indeed.com/rc/clk?jk=5ddf130fd0e3169e&fccid=4cb910b4ed1e1683&vjs=3,"ABOUT SOTHEBY'S Established in 1744, Sotheby's is the world's premier destination for art and luxury. Synonymous with innovation, Sotheby's promotes access, connoisseurship and preservation of fine art and rare objects through auctions, private sales and retail locations. Our trusted global marketplace is supported by a network of specialists spanning 40 countries and 50 categories, which include Contemporary Art, Modern and Impressionist Art, Old Masters, Chinese Works of Art, Jewelry, Watches, Wine and Spirits, and Interiors, among many others. THE ROLE Sotheby's Data Engineering team is transforming a 200 year old business by using machine learning, cloud technologies, and real time analytics. Our platform processes multiple types of data including 10+ million images, 1+ billion transactions, and 10+ million objects. We work with data scientists, business analysts, and software engineers to store, process, and retrieve data. This role will be responsible for building data pipelines, developing new tools, and implementing access controls. RESPONSIBILITIES Develop new data ingestion pipelines from external and internal API's using python Create data processing, monitoring, and alerting tools for business analysts, data scientists, and software engineers Implement data access controls in GCP using terraform Improve system stability and code quality using version control, automated testing, and continuous integration Identify, resolve, and prevent failures IDEAL EXPERIENCE & COMPETENCIES Bachelor's degree in a quantitative field or equivalent experience Programming experience, preferably in Python and SQL Familiarity with cloud development environments such as AWS and GCP Understanding of Role Based Access Controls (RBAC) Able to use orchestration frameworks such as Airflow, Kubernetes, and Docker Swarm Working knowledge of containers Willing to learn new programming languages, tools, and frameworks Curiosity about problems and a desire to solve them To view our Candidate Privacy Notice for the US, please click here. To view our Candidate Privacy Notice for the UK, Hong Kong, France and Switzerland, please click here. The Company is an equal opportunity employer and considers all applicants for employment without regard to race (including, without limitation, traits historically associated with race, such as natural hair, hair texture, and protective and treated or untreated hairstyles), color, creed, religion, sex, sexual orientation, marital or civil partnership/union status, national origin, age, disability, pregnancy, genetic predisposition, genetic information, reproductive health decision, sexual orientation, gender identity or expression, alienage or citizenship status, domestic violence victim status, military or veteran status, or any other characteristic protected by federal, state/province or local law. The Company complies with applicable state and local laws prohibiting discrimination in employment in every jurisdiction in which it operates."
Data Engineer,"Kia America, Inc.","Irvine, CA 92606",https://www.indeed.com/rc/clk?jk=a55a584e99ee59ef&fccid=5fdf2415a4f9db15&vjs=3,"At Kia, we’re creating award-winning products and redefining what value means in the automotive industry. It takes a special group of individuals to do what we do, and we do it together. Our culture is fast-paced, collaborative, and innovative. Our people thrive on thinking differently and challenging the status quo. We are creating something special here, a culture of learning and opportunity, where you can help Kia achieve big things and most importantly, feel passionate and connected to your work every day. Kia provides team members with competitive benefits including premium paid medical, dental and vision coverage for you and your dependents, 401(k) plan matching of 100% up to 6% of the salary deferral, and time off starting at 14 days per year. Kia also offers company lease and purchase programs, company-wide holiday shutdown, paid volunteer hours, and premium lifestyle amenities at our corporate campus in Irvine, California. Status Exempt Summary As Kia North America’s Big Data Center continues to grow rapidly, we are looking to add a talented Data Engineer to our team. The position will be responsible for building ETL data pipelines for use in machine learning models and visualizations. This will require participating in the full development lifecycle (design, implementation, testing, documentation, delivery, support, and maintenance). Major Responsibilities 1st - Build robust and scalable data pipelines. (30%) 2nd - Maintain existing data pipelines especially on telematics data. (20%) 3rd - Dataset documentation. (20%) 4th - Solve database performance issues. (20%) 5th - Build APIs. (10%) Education/Certification Bachelor’s degree in computer science, statistics, engineering, informatics, information systems or similar technical discipline. Certifications in Data Engineering. Overall Experience N/A Directly Related Experience Advanced SQL knowledge and experience with relational databases. Experience with Hadoop ecosystem (Hadoop, Hive, Impala and Spark etc.). Experience with data modeling, data warehousing, and building ETL pipelines. Experience with shell scripting. Experience working in a UNIX/LINUX environment. Proficient in the use of Python and libraries used for parallel computing (e.g. Dask). 2+ years of experience working as a Data Engineer or in a similar role. Preferred Experience: Familiarity with machine learning concepts. Experience with Apache Airflow. Proficiency with Scala. Experience using visualization tools (e.g. Power BI, MicroStrategy, Tableau etc.). Master’s degree. Skills Ability to write high quality, maintainable, and robust code in SQL, Python, Scala. Demonstrated strength in data modeling. Understanding big data analysis techniques: MapReduce, Hadoop ecosystem, Spark etc. Strong problem solving skills based on data analysis Excellent written and verbal communication skills for coordinating across teams. Competencies CHALLENGE - Solving Complex Problems COLLABORATION - Building and Supporting Teams CUSTOMER - Serving Customers GLOBALITY - Showing Community and Social Responsibility PEOPLE - Interacting with People at Different Levels Adapting to Change Championing Customer Needs Communicating Effectively Delivering High Quality Work Entrepreneurial Thinking Managing Resources Equal Employment Opportunities KUS provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, ancestry, national origin, sex, including pregnancy and childbirth and related medical conditions, gender, gender identity, gender expression, age, legally protected physical disability or mental disability, legally protected medical condition, marital status, sexual orientation, family care or medical leave status, protected veteran or military status, genetic information or any other characteristic protected by applicable law. KUS complies with applicable law governing non-discrimination in employment in every location in which KUS has offices. The KUS EEO policy applies to all areas of employment, including recruitment, hiring, training, promotion, compensation, benefits, discipline, termination and all other privileges, terms and conditions of employment. Disclaimer: The above information on this job description has been designed to indicate the general nature and level of work performed by employees within this classification and for this position. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job."
Sr. Data Engineer / Analyst (Open to 100% Remote),Perrigo Company,"Remote in Allegan, MI 49010",https://www.indeed.com/rc/clk?jk=ef10b149a3a068b2&fccid=81c5aa94f4595406&vjs=3,"Perrigo Company is dedicated to making lives better by bringing high quality and affordable self-care products that consumers trust everywhere they are sold. Help us do it. *Open to 100% remote for this position* The Data Engineer / Analyst is tasked with data migration activities that include data analysis, reporting, conversions, harmonization and business process analysis, ensuring the accuracy and availability of Perrigo’s primary data. Identifying customer business requirements which are translated to data mappings for data migrations for integration projects or reporting purposes. This role will be directly in contact with projects or day to day support activities of the transformations developed. Responsibilities: Participate in all aspects of Data migration design, development, maintenance, and support; and establish standards and processes which ensure the reliability of Perrigo’s SAP data. Independently develop and maintain functional and technical requirement specifications documentation and issue resolution for Data Migration, Data Integration, SAP MDG & SAP BusinessObjects Data Services application. Work with Perrigo SAP Business Analysts and subject matter experts to gather and document process flows, requirements and business value drivers, and develop estimates for assigned projects. Develop solutions in coordination with other IT staff, including Data Migration Analysts, SAP Developers, Basis, Infrastructure, and project managers. Review, debug, test, and deploy customizations, ETL or enhancements supporting Data Migrations, SAP MDG, SAP BO Data Services and projects. Maintain project, validation & change control documentation to ensure compliance in Perrigo’s validated cGMP environment. Required Experience: The candidate must have good knowledge of Master Data Governance, Master Data Management and ETL. Experience with tools like SAP MDG, SAP BusinessObjects Data Services and familiarity with ETL developing techniques and development life cycles is preferred. Good familiarity with different type of databases connections and profiles. Strong analytical and communication skills, and the ability to translate business processes or concepts into technical requirements are essential. Comprehensive understanding of SAP master data elements from one or more of the following domains: Material, Customer, Vendor or Finance. As well as comprehensive understanding of data mapping and data conversion is necessary, with the ability to read and interpret process flow documentation and translate this into mapping, harmonization, cleansing packages. Ability to test programming and interfaces that align to data standards and business rules is preferred, and the ability to debug programs is also preferred, but not required. Must work independently on multiple concurrent projects, and in supporting problem tickets by working with end users, subject matter experts, and SAP Business Analysts to gather requirements, present solutions and participate in the selection of the best solutions. These skills are normally acquired through possession of a Bachelor degree in Business Information Systems, Computer Science, or a relevant business discipline, combined with 3 to 7 years experience as a Master Data Analyst. #DIV"
Data Center Engineer,MaineHealth - Corporate,"Westbrook, ME 04092",https://www.indeed.com/rc/clk?jk=6ee77ba9af1d71b0&fccid=4fe42e8b0963c14e&vjs=3,"Position Summary The Data Center Engineer role is the second level of a three level career path. Data Center Engineers provide technical maintenance and support of the equipment and systems contained in MaineHealth Data Centers and associated facilities. They deliver technical solutions per specified plans, deliverables, costs, and timelines. They gather business requirements and translate them into IT solutions. They maintain and support the core systems infrastructure, to include procurement, provisioning, configuration, ongoing maintenance, inventory, documentation, and decommissioning of servers, storage/archive/backup systems, racks/consoles/structured cabling systems, specialty appliances, UPS units, chillers, and related infrastructure. In partnership with other groups inside and outside of Information Services, they are attentive to requirements such as physical security, monitoring/alerting, 24x7 operations, environmental conditions and facilities cleanliness, system availability, and disaster recoverability. They act as liaison with vendor support resources for support and troubleshooting purposes. Required Minimum Knowledge, Skills, and Abilities (KSAs) Education: Bachelor's degree in Information Technology or a related field, or equivalent work experience. License/Certifications: N/A Experience: 4+ years of significant hands-on enterprise-level experience in the following disciplines. Lifecycle management for computer systems hardware, including capacity planning, procurement, deployment, maintenance, updates, upgrades, and decommissioning. Implementing, managing, and supporting structured cabling systems for electrical power, networking, fiber channel-based storage, out-of-band management, and keyboard-video-mouse (KVM) access in an enterprise environment. Troubleshooting systems for functionality, stability, performance, availability, security, etc. Documentation, inventory control, and as-built diagrams for racks, servers, power, and various forms of connectivity. Monitoring and alerting for availability and performance. Risk mitigation, systems planning, and change control. Configuring, supporting, and monitoring delivery of electrical power to equipment through the use of uninterruptible power systems (UPS). Strong interpersonal, verbal and written communication skills. Strong problem solving skills. Demonstrated ability to effectively train or present to small groups. Demonstrated ability to effectively convey and articulate concepts and ideas to both technical and non technical staff. Additional Information MaineHealth was ranked a Best-In-State Employer in 2021 and one of America’s Best Large Employers in 2022 by Forbes! MaineHealth is a not-for-profit integrated health system whose vision is, “Working together so our communities are the healthiest in America.” MaineHealth consists of nine local health systems, a comprehensive behavioral health care network, diagnostic services, home health agencies, and 1,700 employed clinicians working together through the MaineHealth Medical Group. With approximately 22,000 care team members, MaineHealth provides preventive care, diagnosis and treatment to 1.1 million residents in Maine and New Hampshire. Learn more about our system at mainehealth.org At MaineHealth, we offer benefits that support an individual's needs for today and flexibility to plan for tomorrow. Our packages include health and dental insurances, paid parental leave, retirement program, generous paid time off, and much more! Our comprehensive array of benefits are competitive, affordable, and include choices that meet specific, but ever changing, needs. With a career at any of the MaineHealth locations, you’ll be working with health care professionals that truly value the people around them – both within the walls of the organization and the neighborhoods that surround it. We are deeply invested in the well-being of our communities and care team members. We believe in fostering a work environment of strong commitment, compassionate caring and continuous improvement. Join us, and your abilities will be challenged and enhanced as you take your career to a new level. Location: MaineHealth · Integ IT - Platform Services Schedule: Full Time, Day Shift, 40"
Data Engineer : 22-03399,Akraya Inc.,"Sunnyvale, CA 94086+5 locations",https://www.indeed.com/rc/clk?jk=7860da9fb5c1e7d0&fccid=474b9602e1305593&vjs=3,"Primary Skills: Data Engineer, Hadoop, Hive, Spark, Presto, Pandas, Python Contract Type: W2/C2C Duration: 6+ months contract with possible extension Location: Sunnyvale, CA (Remote until office reopens) To follow up with any questions, please contact Dhaval at (408) 907-6913. Work for a Ecommerce Company! JOB RESPONSIBILITIES: Designs, develops, and implements Hadoop eco-system based applications to support International Search Team, follows approved life cycle methodologies, creates design documents, and performs program coding and testing. Resolves technical issues through debugging, research, and investigation. JOB REQUIREMENTS Bachelor's degree in Computer Science, Information Technology, or related field and 5 years experience in computer programming, software development, or related. 5+ years of solid hands-on experience in coding, designing and supporting of big data solutions in Hadoop using Hive, Spark, Presto, Pandas Hands-on experience with Python Strong communication and problem-solving skills An Advantage Experience supporting teams that build Client algorithms Some experience in building web services ABOUT AKRAYA Akraya is an award-winning IT staffing firm and the staffing partner of choice for many leading companies across the US. Akraya was recently voted as a 2021 Best Staffing Firm to Temp for by Staffing Industry Analysts and voted by our employees and consultants as a 2022 Glassdoor Best Places to Work."
Data Engineer,Ascent360,Remote,https://www.indeed.com/rc/clk?jk=e3f812e52ccfda7a&fccid=0b9605374f662bfa&vjs=3,"Ascent360 is seeking a Data Engineer to join our growing team of professionals. This individual will work with the Senior Database Architect and other developers to build core data systems to support the Ascent360 product and business. Essential Functions: Adapt existing data systems & processes to new technology solutions Develop scalable data pipelines and support data processes Learn new technologies to build the best solutions possible Take requirements created by the business teams to build Education & Experience: Bachelor’s Degree in Computer Science, or other related field or equivalent experience. 5+ years experience delivering real-world data solutions 2+ years experience with Python, Spark or PySpark Beneficial Experience: Cloud platforms like Azure or AWS Experience with Databricks or similar cloud-based products Relational database systems like SQL Server & PostgreSQL Azure Data Lake Storage, Delta Lake, or similar solutions Other open source NoSQL technologies *Critical features of this job are described herein. They may be subject to change at any time due to reasonable accommodation or other reasons. Compensation and Benefits: Competitive base salary and equity in our high growth SaaS company Benefits – Medical, dental, vision, retirement matching, flexible PTO + paid holidays, gym & gear discounts About Ascent360 and Why Us? At Ascent360, our mission is simple; to help B2C companies develop authentic, lifelong relationships with their customers. We are a cloud based data driven marketing platform that enables highly targeted, omni-channel marketing engagement direct to customers and prospects. We work with over 100 different brands, retailers, and resorts to integrate all relevant data sources, providing a real time, 360 degree view of their customer, allowing for needle moving marketing campaigns. Based in Denver, CO, Ascent360 supports work from home and hires locally as well as throughout the United States. With flexible PTO, flexible work hours and great benefits, we truly believe in a healthy work-life balance. We are privileged to work with clients you know and love from industries like retail, resort and outdoor & active lifestyle. At Ascent360 we work and function as a team and each day live and breath our core values. To apply: Data Engineer"
Data Warehouse Engineer,Piper Companies,Remote,https://www.indeed.com/rc/clk?jk=0768a212f9de43b2&fccid=fc68da685e8aa986&vjs=3,"Piper Companies is seeking a Data Warehouse Engineer to support the development, enhancement and maintenance of data processing services used for customer reporting and billing. The Data Warehouse Engineer will work in a Linux environment with multiple data stores and models (RDBMS, Redshift, Data Lake, etc), multiple data processing technologies, and multiple software languages running on Cloud infrastructure. Responsibilities of the Data Warehouse Engineer include: Develop Services and Products as part of an Agile (Scrum/Kanban) DevOps team responsible for end-to-end platform ownership from requirements, through the entire SDLC to production support Help develop/enhance/maintain large scale Data/Big Data platforms This includes: modeling, ingesting and processing billions of records daily across multiple Database platforms Help develop/enhance/maintain code (Go, Perl, Python) for complex ETL data pipelines Develop proper instrumentation to measure the health and performance of the services you help build, easily pinpoint and address deficiencies and strive for operational excellence through continuous improvement Automate everything – build, test and deploy software and infrastructure Qualifications for the Data Warehouse Engineer include: 5+ years’ experience developing enterprise data solutions Experience in data-modeling and data-architecture optimized for big data patterns, data warehousing, focusing efficient storage and query performance Strong ETL development skills Experience in Python or GoLang Experience with infrastructure and software automation and tools (Terraform, Ansible, Jenkins, etc) Experience with Cloud Platforms and services such as AWS (EC2, S3, RDS, Redshift, Lambda, etc) and/or GCP, Azure or other cloud equivalents Compensation for the Data Warehouse Engineer include: $160,000-180,000 base salary Benefits: Full Health, Dental, Vision, 401K, PTO, etc."
Data Engineer,Gravie,Remote,https://www.indeed.com/rc/clk?jk=a3614352edd3d270&fccid=e770573a89b37473&vjs=3,"Hi, we’re Gravie. Our mission is to improve the way people purchase and access healthcare through innovative, consumer-centric health benefit solutions that people can actually use. Our industry-changing products and services are developed and delivered by a diverse group of unique people. We encourage you to be your authentic self - we like you that way. If you’re dreaming about how you can use an awesome tech stack to disrupt an industry... Gravie could be the place for you. AWS native since we started, we’re using functional programming with autonomous, cross-functional teams to rapidly build and evolve our systems. Gravie is at that sweet spot, checking the boxes for both excellent technology and making a huge splash in the insurance industry. What does it take to thrive as a Data Engineer at Gravie? You need to have both deep and broad data engineering skills, be innovative, creative, responsible, and curious while moving quickly to deliver results for our customers. Data team builds the data infrastructure and platform for reporting, analytics, and data science. The Data team is part of the engineering organization and uses engineering fundamentals to build solutions that deliver excellent value for the Gravie business teams. You are likely to be self-driven, enjoy working in a fast-paced entrepreneurial environment, and want to get a great understanding of modern data engineering stack and implement them with a long-term vision to create a data driven organization. You will: Create and maintain optimal data pipeline architecture from various sources to Gravie’s reporting and analytics database. Architect, build, and launch efficient & reliable data models and pipelines that meet business requirements and IT standards. Build the modern data infrastructure for Gravie’s data warehouse by optimal extraction, transformation (dbt), and loading of data from a wide variety of data sources using SQL and AWS technologies (Redshift, Glue, Lamda). Act as a data architect to understand various source applications and how to integrate them with other source applications. Identify, design, and implement internal process improvements such as automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability. Passionate about data, data quality, and creating accurate and performant data solutions that are easy to consume. Excel at collaborating with end users to deeply understand questions they’re trying to answer and coming up with user friendly data models that provide actionable insights into operational efficiency, growth, underwriting and other key business performance KPIs. Demonstrate commitment to our core competencies of being authentic, curious, creative, empathetic and outcome oriented. You bring: Bachelor’s Degree or equivalent ? 2+ years of experience building and optimizing data pipelines, architectures and data sets using modern technologies such as AWS, dbt, Glue Airflow. 3+ years of hands on work on building data warehouses with Kimbell methodology 2+ years of data pipelines and orchestrating performant data models on cloud warehouse such as Redshift (preferably using dbt and data orchestration tools like Airflow) Experience supporting data transformation, data structures, metadata, dependency and workflow management. Evaluate emerging tech in the rapidly evolving field of data tooling and practices, and regularly make recommendations on opportunities to advance our capabilities. Analyze query performance and perform query tuning to assist development engineers in designing and optimizing queries. Experience using the command line and software engineering best practices like version control and using Git Overall 5+ years of experience in a Data Engineer role, who has attained an undergraduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. History of managing complex processes and multi-layered projects Excellent communication skills Demonstrated success getting results through collaboration Extra credit: Knowledge of Health Insurance Industry Knowledge of AWS Infrastructure and AWS services like Redshift, Glue, Lambda and Athena Experience creating reports and dashboards using data visualization or BI tools (Looker, Tableau, Power BI) Hands on experience with Airflow implementation Working knowledge of message queuing, stream processing, and highly scalable data stores. Experience with Tableau Previous start up company experience Competitive pay is standard. Our unique benefits program is the gravy, i.e., the special sauce that sets our compensation package apart. In addition to standard benefits, Gravie’s package includes alternative medicine coverage, flexible PTO, 16 weeks paid parental leave, paid holidays, cell phone reimbursement, education reimbursement, and 1 week of paid paw-ternity leave just to name a few. Where permitted by applicable law, candidates must be fully vaccinated or be willing to be fully vaccinated for COVID-19 by date of hire to be considered for a job at Gravie."
Data Engineer,First National Bank of Omaha,"Omaha, NE",https://www.indeed.com/rc/clk?jk=bcba580112650c85&fccid=93443b35b28eec93&vjs=3,"At FNBO, our employees are the heart of our story—and we’re committed to their success! Please see below the details of this career opportunity and how it fits into our organization’s success. The banking landscape and customer expectations continue to evolve. To enable us to respond to these changes we are focusing heavily on digital and data. Data Engineering and Data Products team is all about the Data. We are focused on simplifying and modernizing our data platform by shifting to real-time, intelligent data integration and technology including cloud that drive agility and stability with the customer at the center of everything we do. As a developer on the Data Engineering team, you will be focused on acquiring data into the data ecosystem along with support for the enterprise reporting tools that our team maintains. Although we look for you to be a strong contributing member of the team, it is also a learning role where you will gain an understanding of the tools we use, tool administration, learn the data and technology ecosystem, and understand compliance and governance standards. As part of the career path for this role, you will have the opportunity to learn about data modeling and presentation, data management tools and support, reporting and visualization tools and more. You will be working as part of a matrixed and self-directed team, leveraging Agile methodologies to deliver production support, enhancement and project tasks and report into the Director of Delivery Management. Key Responsibilities: Data Movement (ETL/ELT): Ability to independently perform data movement development work Production Support and Tool administration: Learn business intelligence tools for tool administration Monitor and mitigate issues with scheduled jobs; identify opportunities and optimize data jobs Triage, analyze and support end users with technical issues with reporting tools and outputs Work with business partners to ensure appropriate access is maintained Drive the creation and use of a service catalog and encourage self-service resolution for non-technical issues; ensure documentation is kept current Be available for on-call support and critical issue resolution Job Qualifications: Bachelor's degree in Computer Sciences, Math, Finance or Business Admin 1-2 years of internship and 2-3 years full-time work experience within IT or minimum of 3 – 5 years full-time work experience within IT; successful fnbo internship experience and Business Intelligence or Database experience preferred 2 – 3 years Informatica iiCS experience highly preferred Experience with Structured Query Language, T-SQL or Dynamic SQL Experience with the development and maintenance of data warehouses Ability to interpret business requirements An analytical mind with strong data analysis skills 1 – 2 years of snowflake experience is a plus AWS or similar cloud experience is a plus Additional Qualifications: Emerging relationship management skills Good written and verbal communication skills Ability to work in a collaborative, self-directed environment Ability to communicate and work effectively with peers, team, business analysts, management and third-party service providers Ability to think outside the box to solve problems Equity, Diversity, & Inclusion: FNBO is committed to belonging, inclusion, diversity and equity. We are committed to intentionally and proactively creating pathways to success for historically underrepresented populations. To accomplish this, we foster a culture of belonging and inclusion so that every employee is valued, and has opportunity and the ability to make an impact. FNBO strives to reflect the diversity of the communities we serve in the makeup of our workforce. See the full FNBO Equity, Diversity, & Inclusion Statement here All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status."
Data Engineer,Massachusetts General Hospital(MGH),"Hybrid remote in Charlestown, MA",https://www.indeed.com/rc/clk?jk=3c1afbb63d43aaab&fccid=3aaabf5c54e51db9&vjs=3,"Data Engineer - (3193040) Home Base, a Red Sox Foundation and Massachusetts General Hospital program, is an innovative public/private partnership dedicated to improving the lives of service members, Veterans, and their Family Members living with invisible wounds such as post-traumatic stress disorder (PTSD), traumatic brain injury (TBI), anxiety, depression, military sexual trauma, and family/relationship challenges. Our program provides intensive outpatient care, traditional outpatient care, couples therapy, wellness, and fitness programs, as well as community outreach and education. Home Base also serves as a leader in research, identifying and implementing new treatments for the invisible wounds. Central to our mission is a value of inclusivity and equity. We strive to create an environment in which colleagues and patients are seen, heard, and treated with dignity and respect. Since its inception in 2009, Home Base has served more than 25,000 Veterans and their family members, trained more than 85,000 clinicians nationally, and remains at the forefront of discovering new treatments, ensuring a brighter future for 21st century warriors and their families. Home Base seeks to hire a data engineer to start April 2022, who will support a variety of database/warehouse management, ETL scripting, and data validation tasks that include but are not limited to querying databases, restructuring data, cleaning, and validating data, performing manual ETL tasks, automating ETL tasks using tools and custom scripting, full pipeline management/monitoring, improving systems and processes, and documenting data systems. The qualified candidate will be highly detail-oriented and have a strong interest in and aptitude for data management and engineering. Some specific focus areas would be determined based on the candidate's skills and interests. The successful candidate must be highly organized, motivated, and able to thrive in a fast-paced team environment and must enjoy the challenge of a dynamic environment with evolving needs. It is extremely important that the candidate possess the ability to carefully keep track of multiple work streams. PRINCIPAL DUTIES AND RESPONSIBILITIES: Relevant activities include, but are not limited to the following: Achieving an extremely detailed understanding of our current data ecosystem, including its structure, data meaning, history, flow/processing, and challenges Utilizing, improving, and constructing and ETL tools and data warehousing solutions Running current SQL, Python, PHP, and/or Tableau Prep ETL scripts Using various monitoring and evaluation methods to validate that data flowing through these pipelines is accurate and troubleshooting/addressing issues when they are discovered Data warehouse maintenance and support Improving and better integrating scripts (ETL and validation) and warehouse elements into various data pipelines to achieve greater efficiency, reliability, and functionality Constructing new ETL tools and warehouse components as necessary, specifically including a dedicated-use pipeline for a new collaborative research project Data Cleaning Writing queries (SQL) and scripts (Python) to identify data quality problems Investigating the root cause of data quality problems Working with appropriate team members to determine appropriate data remediation and process improvement plans Developing queries and scripts as needed to repair data in bulk Developing and managing data quality and infrastructure monitoring dashboards Additional Responsibilities Supporting the team as needed with data querying (particularly of the data warehouse), processing, analysis and reporting for both regular and ad-hoc requests from clinical, executive, and external audiences Researching potential new data engineering solutions, analyze feasibility, and assist technical leadership in road-mapping and designing the evolution of our data infrastructure Creating and maintain documentation across our data ecosystem SKILLS & COMPETENCIES REQUIRED: Background Degree in Health Informatics, Computer Science, Statistics, Mathematics, Engineering, or a similar field Familiarity with behavioral health clinical practice and/or research preferred Technical Procedural programming for data manipulation using Python, NumPy, and Pandas PHP, Java, or other languages are a plus Knowledge of relational database platforms, data modeling, and warehousing Comfortable extracting data from and loading data into sources ranging from an Enterprise Data Warehouse to an Excel or text file, using built-in tools or custom-written ETL scripts Knowledge of data aggregation and transformation processes (e.g., pivot, merge, union, hierarchical grouping, aggregation functions) Above average SQL skills (e.g., familiar with subqueries, multiple joins, and grouping), specifically MySQL. SQL Server experience a plus Comfortable with complex multi-stage, multi-technology ETL pipelines Comfortable using APIs to transmit data in both an ad-hoc and automated manner Familiar with concepts/tools of Data Quality Management as well as Data Governance practices Professional Ability to interpret and follow-through on data requirements and with strong attention to detail Strength in independently validating and debugging code and analyses, including consulting documentation, Stack Exchange, etc. Demonstrates personal initiative and time management skills, as well as the ability to work effectively and kindly as part of a team Excellent verbal and written communication skills Familiar with agile software development methodologies Interest in identifying process improvement opportunities is a plus LICENSES, CERTIFICATIONS, and/or REGISTRATIONS: Required: Undergraduate degree in Health Informatics, Computer Science, Statistics, Mathematics, Engineering, or a related subject. Preferred: Graduate degree in one of the above. Preferred coursework would include most of the following: Intermediate Databases and SQL Intermediate Programming (Procedural and/or OO) Data Structures and Algorithms Data Quality Management Data Flow and Automation Agile Project Management Equivalent Experience – Equivalent time and aptitude achieved through work experience may substitute for some of the preferred courses listed above. EXPERIENCE: Preferred: 2+ years of experience in data management in a healthcare/clinical setting, however recent or anticipated college graduates will be considered. WORKING CONDITIONS: Shared spaces; Open work setting model. Hybrid remote schedule EEO Statement Massachusetts General Hospital is an Equal Opportunity Employer. By embracing diverse skills, perspectives and ideas, we choose to lead. Applications from protected veterans and individuals with disabilities are strongly encouraged. Primary Location MA-Charlestown-MGH OCC Work Locations MGH OCC One Constitution Center Charlestown 02129 Job IT/Health IT/Informatics-Engineer Organization Massachusetts General Hospital(MGH) Schedule Full-time Standard Hours 40 Shift Day Job Employee Status Regular Recruiting Department MGH Psychiatry Job Posting Mar 28, 2022"
Data Engineer,Riiid Labs,"Hybrid remote in Mountain View, CA+2 locations",https://www.indeed.com/rc/clk?jk=7fc542aa83eaca26&fccid=933989f3b0ffe928&vjs=3,"Location: Mountain View, CA Here at Riiid Labs, as an AI SaaS organization, we partner with many global leaders in numerous industries to tailor our verified AI technology to the needs of students, educators, organizations and their employees, and many more throughout the world because we believe that there should be no limit in learning! Riiid Labs’ believes that everyone should have access to personalized education & learning platforms regardless of socio-economic status, age, race, gender, identity, or educational history. We help learners realize their goals in the fastest, most efficient way! Check out “Our Story” to learn more about what it means to be a part of our organization and what Riiid Labs hopes to accomplish! Riiid Labs is growing! - Join us as we continue to expand Riiid Labs and its products/solutions further into the US and Global educational & workforce/training development industries! To date, we have received $175M in funding from Softbank's Vision Fund 2, with over $250M in total funding. The Role/What you’ll do: We are looking for a Data Engineer to join our new project that requires large scale data analysis. You will be responsible for developing our data acquisition pipeline, optimizing multimodal data collection framework, and implementing APIs for accessing data storage. You will integrate unstructured data from different sources and create a stable data transformation pipeline. The ideal candidate is an experienced data pipeline builder who is enthusiastic on optimizing data especially in the education domain. They must be self-directed and comfortable supporting the data needs of multiple teams and products. Create and maintain an optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Collaborate with other teams across national boundaries to build centralized data storage solutions. Keep our data separated and secure across national boundaries through multiple data sources Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader Work with data and analytics experts to strive for greater functionality in our data systems What you’ll work on: Phone/Web Based AI powered tutor applications that support and enhance a student’s education. AI SaaS platforms supporting educators' efforts to enhance education for students in and out of the classroom. AI API integration projects to assist organizations with optimizing their workforce development, corporate training, and online learning systems. What you bring to Riiid Labs: At least 2 years of professional development experience. Demonstrated expertise in at least one of the following: Spring, Spring Boot, Node.js, Nest.js. Hands-on experience with at least one of the following programming languages: Kotlin, Java, JavaScript, TypeScript. Knowledge of RESTful web services. Experience with relational databases (PostgreSQL, MySQL).Experience with at least one of the following cloud platforms: AWS, Azure, GCP. Desire to refine your craft by proactively seeking out ways to hone your skill sets. Strong communication skills to effectively communicate with stakeholders and team. What Riiid Labs is offering to you! Hybrid Schedule (remote and in-person). Career Growth - opportunity to professionally grow within a rapidly expanding company. Competitive Salaries and Compensation Packages. Flexible Time Off Policy - allows you to take time off as you need it, without having to accrue a capped number of hours per year 100% paid benefit premiums (medical, dental, vision) for individual and family. 401K with 4% Match. Opportunity to travel and work with our Engineering Team at Riiid, in Seoul, Korea. Ability to have your voice & opinions heard within a small organization that is growing!Family oriented and friendly environment. Even if you don’t meet all of the qualifications, we still encourage you to apply! Riiid Labs, Inc. is an equal opportunity employer. In accordance with anti-discrimination law, it is the purpose of this policy to effectuate these principles and mandates. Riiid Labs, Inc. prohibits discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law. Riiid Labs, Inc. conforms to the spirit as well as to the letter of all applicable laws and regulations."
Data Quality Engineer lll,AbleTo,"Remote in New York, NY 10018+1 location",https://www.indeed.com/rc/clk?jk=6034e830e21e5485&fccid=954e57501f6bca1f&vjs=3,"About AbleTo Join our mission-driven organization, where your work matters and a diversity of ideas and backgrounds are welcomed. AbleTo is the leading provider of high quality, technology-enabled behavioral health care. We believe that everyone deserves access to high-quality care and offer a suite of technology-enabled services to empower people to lead better lives through better mental health. A proprietary platform connects individuals with AbleTo highly trained licensed providers who deliver weekly sessions by phone or video supported by an integrated digital experience. Members also have access to mental health coaches, and digital support programs. Our outcomes-focused approach is proven to improve both behavioral and physical health and lower medical costs. Overview As a key member of AbleTo's data engineering team, you will be responsible for ensuring we get it right the first time by driving quality automation throughout our SDLC and participating as a peer engineer within our Lean-Agile product engineering group. You will work with our talented team of remote engineers, designers and product managers to ensure the highest quality of the systems that manage our member's care journey. We are a team committed to agile value delivery and solid engineering principles, as well as continuously improving our craft. If you love shipping software that delivers deep and meaningful impact to people's mental and behavioral health, join us! What You'll Do: Work as part of a fast paced and highly motivated Agile team to help design, build and test new features. Participate in sprint planning, backlog grooming, daily-standups, and retrospectives during a 2 week sprint cadence. Work closely with product managers and data engineers to identify test cases and devise efficient and repeatable testing processes. Review other team members' work and hold other team members accountable for high quality software. Coach, mentor and develop team members. Ability to complete high quality work with minimal supervision. Perform ETL testing and verify against requirement specifications for data correctness and data completeness of data. Define test automation strategy, lead the implementation & execution of automated test cases, and analyze test outputs. Catalog software defects and collaborate with peer engineers to ensure they are resolved and thoroughly retested. Work with Data Engineering management to identify and implement process improvements to continuously improve the team's productivity and efficiency. Who You Are: Bachelor's degree in Computer Science or equivalent practical experience. 10+ years experience in ETL/Data Integration Testing (e.g., Data Warehouse, Data Lake). Advanced to Expert SQL skills (inc. data profiling). Demonstrated experience of ETL tools (e.g., Informatica preferred). Knowledge of working with Big Data on a Cloud Platform (GCP preferred) Knowledge of at least one scripting language (eg., bash). Basic knowledge of Python. Experience using version control systems such as Git and an understanding of Data Pipelines and workflow management tool (eg., Airflow, Luigi) Experience testing reports and dashboards on visualization applications (eg., Looker, Tableau) Extensive experience setting up, running and maintaining scripted automation frameworks for data teams. Experience working with Unix/Linux operating systems. Demonstrated knowledge of test methodologies, test design and extensive QA workflow experience. Excellent verbal and written communication skills. Proven ability to build and maintain strong, productive working relationships with internal stakeholders and external customers. Clinical/Healthcare product experience is a plus Why You Should Join Our Team: We're proud to be a Great Place to Work-Certified™ company. We want you to show up and feel your best at work, and that means respecting your time outside of work. Our inclusive, flexible workspace prioritizes a work/life balance. We offer competitive salaries, comprehensive health benefits (for full-time employees), and professional perks such as 401K matching, fully funded HRA, and generous time off, including mental health days because your well-being is important to us. At AbleTo, we're empowering people to get better and stay better. Want to join us? Take the next step in your career by applying for this role today. #LI-Remote Follow AbleTo on LinkedIn, Twitter, and Instagram! Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice. AbleTo is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status. AbleTo is an E-Verify company."
Data Warehouse Engineer 3 - Remote,"TrueCar, Inc.",Remote in California,https://www.indeed.com/rc/clk?jk=a0dd42522762cfc4&fccid=028921740570b632&vjs=3,"Job Description: TrueCar is on a mission to revolutionize the way that consumers engage in the vehicle purchase and ownership experience. We’re building an end-to-end consumer journey that’s uplifting, empowering, and unrivaled in the marketplace, and we’re looking for the best and brightest to help us achieve our goals. We’re on the hunt for teammates who embrace challenge, relentlessly innovate, and reject the notion that ‘it can’t be done.’ TrueCar maintains a Dynamic Workplace, allowing employees to have their primary workstations at home, with office space in Santa Monica, CA and Austin, TX to be made available to individuals and teams to use as needed. Employees enjoy excellent benefits (100% employer-paid health/vision/dental premium, 401k with contribution matching, equity for eligible roles, etc.) as well as perks like monthly credits for at-home food delivery, internet/mobile phone service coverage, and fitness expenses.cIn short, we care deeply about our teammates and build employee-centric programs that prove it. About the job: The Data Warehouse Engineer serves as an expert in Microstrategy and SQL. Key responsibilities include developing reports and dashboards on TrueCar’s BI Platforms (Microstrategy & Tableau) and Microstrategy maintenance and administration. The Engineer will also coordinate and perform tasks in support of data quality efforts, tune queries for optimal performance, and provide platform support for various AWS components like Redshift, RDS & AWS S3 bucket and manage platforms for monitoring of jobs and admin consoles. What you In this role, you will support business leaders with visual reporting based on stakeholder needs and company priorities. You will also be creating and maintaining new attributes and metrics in Microstrategy. Collaborate with data operations and analysts to ensure correct data sources and dataset development Work with end users to define visual reporting needs for intended audiences and delivery formats. Develop or modify datasets, or specify additions or modifications necessary to meet reporting requirements. Conduct analyses to identify new insights and visualization possibilities. Perform ad hoc analytical requests and report prototyping for internal and external parties. Participate in application validation and QA efforts as they pertain to reporting, data and metrics. Be involved in Microstrategy server administration and maintenance tasks. What you'll need: Business Intelligence experience developing reports and dashboards. Experience with visualization creation on different BI solutions including Microstrategy and Tableau. Strong SQL skills and experience with AWS Redshift is a plus Solid design aesthetic with ability to tailor/specify correct visualization types and styling for intended communication and audience. Proven work ethic with ability to work within set timelines and update management on deviation to these estimates. Strong interpersonal communication skills, effectively communicates in verbal and written form. Nice to have: Familiarity with AWS technologies such as Redshift, Lambda and S3 Experience with Python Experience using GIT BS/MS in computer science or equivalent work experience Automotive industry experience *** While this position is open to remote work through TrueCar's Dynamic Workplace initiative, applicants may not reside in Colorado. Colorado candidates will be required to relocate. *** #LI-Remote Location(s): Field-California"
Data Center Support Engineer,Sentinel,"Remote in Livonia, MI 48150",https://www.indeed.com/rc/clk?jk=8dca465939f53edd&fccid=c2ac3734cc3a01c6&vjs=3,"Responsibilities: The Data Center Support Engineer will support, administer, and consult the core infrastructure of the business. In this position, you will need to identify, troubleshoot, escalate and communicate customer issues and resolutions as a member of our support services team. This position can be remote but must provide occassional travel to our Livonia, MI location. Qualifications: Experience working with and supporting Microsoft technologies Strong experience working with Windows Server Experience supporting Servers and Storage Devices Strong experience with Virtualization Technologies (VMware, Hyper-V) Strong experience supporting and configuring ESX Excellent knowledge of Active Directory The candidate must have a car, as this position requires travel between location and the transportation of equipment A valid driver’s license and proof of vehicle insurance will be required Legally authorized to work in the US without sponsorship Must demonstrate a “can-do” attitude We focus on candidates that display our “ACE” factor – Attitude, Compassion, and Enthusiasm to deliver quality solutions with exceptional customer service. What you get: We offer an energetic work environment with many corporate culture amenities, competitive salary, and rich benefit plan including: Medical, Dental, Vision, 401K, 529, Life Insurance, Income Protection Short and Long-Term Disability, Medical and Child/Elder Care, Flexible Spending Account Plans, Employee Assistance Program, Two weeks vacation, additional paid time-off for Personal and Sick, certification and hands-on training, and discounts for local event entertainment and health clubs. Overview: MOTIVATED…..make IT happen! Sentinel Technologies, Inc. has been rated a top workplace every year since 2012! About Us: Sentinel delivers solutions that can efficiently address a range of IT needs – from security, to communications, to systems & networks, to software applications, to cloud and managed services; all of which include our staffing solutions for our clients. Since 1982, Sentinel has grown from providing technology maintenance services to our current standing as one of the leading IT services and solutions provider in the US. We have aligned with many of today’s global technology leaders including Cisco, Dell, VMware and Microsoft. Sentinel services customers both nationally and internationally with primary support operating centers in Downers Grove (HQ), Chicago, and Springfield, IL; Phoenix, AZ.; Detroit, Lansing, and Grand Rapids, MI; Milwaukee, WI; Denver, CO; and Fort Lauderdale, FL. If you are MOTIVATED… you can make IT happen at Sentinel. Our commitment to our employees is to create a work environment that encourages creativity, an entrepreneurial spirit, fosters growth through certification and hands-on training, and values a team-oriented culture with rewards based on impact! If you share our passion about what technology can do and want to be part of a top workplace environment – we’d like to have you join our team. Learn more at www.sentinel.com/careers. As part of Sentinel's employment process, candidates will be required to complete a background check. Only those who meet the minimum requirements will be contacted. No phone calls please. Sentinel is proud to be an equal opportunity/affirmative action employer committed to a diverse and inclusive work environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, marital status, genetics, disability, pregnancy, veteran status or any other basis protected by law. If you are an individual with a disability and need assistance in applying for a position, please contact SentinelHR1@sentinel.com."
Data Integration Engineer,Doximity,"Remote in Tulsa, OK+1 location",https://www.indeed.com/rc/clk?jk=56d6500f5377d5d0&fccid=cc9f04eed69b86b2&vjs=3,"Doximity is transforming the healthcare industry. Join our mission to help every physician be more productive and provide better care for their patients. As medicine's largest network in the United States, there's an elevated level of responsibility in everything we do. We don't take that responsibility lightly and are committed to building diverse teams with an inclusive culture that can make a direct impact on the healthcare system. One of Doximity's core values is stretching ourselves. Even if you don't check off all the boxes below we encourage you to apply. Doximity is full of exceptional people who bring their own unique experiences to work everyday and make us all better for it! Data engineers on our data integration team are responsible for many of our foundational datasets powering our user-facing products. They collaborate with a variety of teams across the organization to shepherd data products in the right direction. Ultimately, data engineers on the data integration team take great interest in understanding how our data impacts our products - to drive the team's data endeavors in directions that directly improve our products. This role can be filled in our San Francisco headquarters OR remotely in the U.S. How you'll make an impact Collaborate with product managers and data engineers to develop data pipelines with the goal of creating or improving products through the use of our data Gain an understanding of Doximity's data and proactively identify places where unused data can be integrated to add value Define how data should be structured to provide maximum value to downstream consumers Build, maintain, and scale data pipelines that empower Doximity's products Establish data architecture processes and practices that can be scheduled, automated, replicated and serve as standards for other teams to leverage Work alongside others in planning and carrying out the implementation of solutions that are focused on enhancing products, leading one or two projects at any given time What we're looking for You have professional data engineering or operations experience with a focus on data pipelines and the data within those pipelines. You are fluent in Python and SQL. You have an interest in spending time understanding how our user-facing products operate to help find novel ways to create value from our data. You are no stranger to data warehousing (we use Snowflake) and designing data models. You are familiar with different types of data structures and what they mean for the data stored within them. You are foremost an engineer, making you passionate about high code quality, automated testing, and engineering best practices. You have the ability to self-manage, prioritize, and deliver functional solutions. You agree that concise and effective written and verbal communication is a must for a successful team. Why you want to work here/Benefits/Perks Doximity is proud to offer industry-leading benefits. Some of our offerings include: Medical, dental, vision offerings for you and your family 401k with matching program Stock Incentives Family building support, Childcare FSA, and parental leave Life, AD&D, and Disability Generous time off, holidays and paid company trips Plus many more! More About Doximity… For the past decade, it's been our mission to help every physician be more productive so they can provide better care for their patients. We believe that when doctors are connected, the healthcare system works better and patients benefit. Doximity enables our verified clinician members to collaborate with colleagues, stay up-to-date with the latest medical news and research, manage their careers, and conduct virtual patient visits. Today, Doximity is the leading digital platform for U.S. medical professionals, with over 80% of physicians, 50% of all nurse practitioners and physician assistants, and 90% of graduating medical students as members. Joining Doximity means being part of an incredibly talented and humble team passionate about improving inefficiencies in our $4.3 trillion U.S. healthcare system. We are a team of doers who solve problems everyday by treating obstacles like an adventure, and we love creating technology that has a real, meaningful impact on people's lives. Doxers are committed to working towards a more equitable world both within and beyond our office walls. This starts by fostering an inclusive and diverse work environment where differences are valued and all employees are encouraged to bring their full, authentic selves to work daily. To learn more about our team, culture, and users, check out our careers page, company blog, and engineering blog. We're growing fast, and there's plenty of opportunity for you to make an impact—join us! For more information, visit Doximity.com. ____________________________________________ EEOC Statement Doximity is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law."
Data Engineer,FCA,"Auburn Hills, MI 48326+6 locations",https://www.indeed.com/rc/clk?jk=676ccca23367b228&fccid=347529ce49ee92b3&vjs=3,"Build your brand. Tell your story. Take advantage of a rare opportunity to create something new and original. At Stellantis, we're breaking with the past and launching a new software organization built from the ground up. The Stellantis Software organization (SWX) was established in 2021 and brings an entirely new vision to the driving experience. Our mission is to design the most captivating experiences in Mobility, bringing ""tomorrow's"" tech innovations closer to today, everyday. If you're ready to help lead this automotive technology transformation, we want to hear from you. Visit https://careers.fcagroup.com/nextgen/ to learn more. The Global Analytics & Data Products Team is looking for a Data Engineer to join our team. Your mission is to establish the organization's data infrastructure, promoting engineering best practices on data management, and keeping the high bar for data quality. Priorities can change in a fast-paced environment like ours, so this role includes, but is not limited to the following responsibilities: Design and implement secure, scalable, high-performance and robust data services for connected vehicle data in distributed data processing platforms using modern Big Data technologies Design, extend, and review data architecture, model, flow, and integration -- be hands on and involved with every stage of the software development life cycle Partner with software engineers and data scientists to meet the need of upstream and downstream dependencies Work with external carrier stakeholders and internal partner teams to ingest connectivity data for data processing Develop state of the art code -- influence/establish the software development culture of the team Establish standards and best practice for instrumentation within software engineering Keep up to date with the evolving Big Data technology, share the knowledge across the organization by enabling best practices, standards, governed processes and relevant technologies Top Performers will be able to demonstrate: Comprehensive knowledge of relational database concepts, including; data architecture, operational data stores, Interface processes, Multidimensional modeling, master data management, and data manipulation Expert knowledge and experience with custom ETL design, implementation and maintenance Comprehensive experience designing, implementing, and iterating data pipelines using Big Data technologies Experience working on cross-functional teams and leading efforts to build data services from ground up Excellent communication skills with the ability to understand complex business problems and provide solutions Basic Qualifications : BA/BSc in Computer Science, Engineering, Mathematics, or a related technical discipline preferred A minimum of 5 years of experience in the data engineering and software development life cycle A minimum of 2 years of hands-on experience in building and maintaining production data applications, current experience in both relational and columnar data stores Experience with more than one coding language Experience with one or more functional languages such as F#, Scala or Haskell Experience working with cloud Big Data platforms (i.e. Spark, Google BigQuery, Azure Data Warehouse, etc.) Familiarity with time series database, data streaming applications, Kafka, Flink, and more Experience with workflow management engines (i.e. Airflow, Luigi, Azure Data Factory, etc.) Familiarity with modern data science and product analytics tools and techniques such as R, Machine Learning, and advanced statistics Understand how to work with Hive metastores Experience with continuous integration tools like Jenkins Experience with creating containerized applications using Docker running them on Kubernetes Preferred Qualifications : Experience with designing and implementing real-time pipelines Experience with data quality and validation Experience with SQL performance tuning and E2E process optimization Experience with notebook-based Data Science workflow Experience with Airflow Experience using Spark, Presto, Hive, etc. Experience using Cats or ZIO Our benefits reflects the FCA commitment to helping you reach your personal and professional goals. In addition to an environment that promotes career development, we offer benefits for a healthy lifestyle and a rewarding future, designed to take care of you and your family, in various stages of life. As a global company, our employee packages will vary by country, customary norms and the legal entity into which you are hired."
Data Engineer,JACKSON HEALTH SYSTEM,"Miami, FL 33136 (Allapattah area)",https://www.indeed.com/rc/clk?jk=473f41d204915c6b&fccid=d65f7a458f65f781&vjs=3,"Jackson Memorial Hospital Days, FT Position Summary: The Data Engineer requires fluency and proficiency with data organization, preparation/cleansing/transformation, and structuring tools and tasks supporting analytical modeling, programming, and visualization. Work daily with database platforms and data-application development technologies such as Microsoft SQL Server and related tools (e.g., SSMS, SSIS, Visual Studio, Tableau Prep, etc.). Routinely apply expertise in developing data pipelines, APIs, and scripts that facilitate the creation of analytical models and support upstream application development. Prepare, integrate, and automate data movement and utilization by applying scripting and programming languages such as SQL/T-SQL/PL-SQL, Python, R, and scripting languages. Support the development of analytical and decision support applications. Duties & Responsibilities: Work daily with database platforms and data-application development technologies such as Microsoft SQL Server and related tools (e.g., SSMS, SSIS, Visual Studio, Tableau Prep, etc.) are required. Routinely apply expertise in developing data pipelines, APIs, and script that facilitate the creation and automation of analytical models and support upstream application development and maintenance. Prepares and integrates data using scripting and programming languages such as SQL/T-SQL/PL-SQL, python, and R. Support the development and maintenance of analytical and decision support applications bthrough business logic, automation engineering, structural data representation, and query optimization. Demonstrates behaviors of service excellence and CARE values (Compassion, Accountability, Respect and Expertise). Performs other related duties as assigned. Qualifications Experience: Generally requires 3 to 5 years of related experience. Education: Bachelor's degree in related field is required. Master's degree is preferred. License Certification: Valid license or certification is required as needed, based on the job or specialty. Knowledge Skill Abilities: Ability to analyze, organize and prioritize work accurately while meeting multiple deadlines. Ability to communicate effectively in both oral and written form. Ability to handle difficult and stressful situations with critical thinking and professional composure. Ability to understand and follow instructions. Ability to exercise sound and independent judgment. Knowledge and skill in use of job appropriate technology and software applications. Physical Demands: Job function is sedentary in nature and requires sitting for extended periods of time. Function may require frequent standing or walking. Must be able to lift or carry objects weighing up to 20 pounds. Jobs in this group are required to have close visual acuity to perform activities such as: extended use of computers, preparing and analyzing data and analytics, and other components of a typical office environment. Additional information and provision requests for reasonable accommodation will be provided by the home unit/department in collaboration with the Reasonable Accommodations Committee (RAC). Work Environment: Jobs in this group are required to function in a fast paced environment with occasional high pressure or emergent and stressful situations. Frequent interaction with a diverse population including team members, providers, patients, insurance companies and other members of the public. Function is subject to inside environmental conditions, with occasional outdoor exposures. Possible exposure to various environments such as: communicable diseases, toxic substances, medicinal preparations and other conditions common to a hospital and medical office environment. May wear Personal Protective Equipment (PPE) such as gloves or a mask when exposed to hospital environment outside of office. Reasonable accommodations can be made to enable people with disabilities to perform the described essential functions. Additional information and provision requests for reasonable accommodation will be provided by the home unit/department in collaboration with the Reasonable Accommodations Committee (RAC)."
Data Engineer,Blocknative Corporation,Remote in United States,https://www.indeed.com/rc/clk?jk=f15c0f0ff43e685f&fccid=3def73997cdde853&vjs=3,"Founded in 2018, Blocknative provides Web3 transaction orchestration infrastructure for the Ethereum, Polygon, Gnosis Chain, Fantom, BNB Chain, and Bitcoin ecosystems. Blocknative solutions are deployed by hundreds of Web3 builders and traders to enable dynamic user experiences and power real-time decisions via pre-chain data and insights. Blocknative’s mempool data platform is used by some of the leading projects in the category. Every day our infrastructure captures hundreds of millions of rows of data, enhancing and enriching the data set. The data engineering team designs, implements, and oversees all of Blocknative’s blockchain data pipelines/storage. As an engineer on the team, you will have ownership over the flow, storage, and access of data through Blocknative’s big data cloud infrastructure. This empowers internal teams and customers to access mempool data, build machine learning models, and conduct research. Responsibilities: Design, build, and maintain Blocknative’s data infrastructure Oversee the flow of data across all of Blocknative’s pipelines Coordinate with other teams to build blockchain data products Manage cross-functional stakeholders and help drive a data-driven culture company-wide #LI-Remote Preferred* Experience: Ethereum experienced — proficient with the core concepts in the space Big data (Databricks/Spark) experience Streaming data systems (Fluentd/Kinesis) Cloud infrastructure (AWS)ETL workflow management Data streaming systems Programming languages used for modern data engineering, such as Python. Go, Scala, as well as some Javascript We prioritize people above all else. If you think you’d add to the depth and diversity of our team but don’t fit these qualifications exactly, we want you to apply! We hope you apply! We are also open to exploring contract opportunities as we get to know each other. We strive to have you meet as much of the team as possible before extending an offer. Here’s what you can expect: Application review Schedule a call with the recruitment team Schedule a call with the hiring manager Schedule a group interview with the growth or technical team Reference calls/ background checks Offer If you want to dig deeper into Blocknative, please explore our YouTube channel and blog, and don't forget to create your free account. #LI-Remote"
Data Engineer II,AMC Networks Inc.,"New York, NY 10001 (Garment District area)",https://www.indeed.com/rc/clk?jk=c1dfb1c6a735289a&fccid=490d2f31522bb345&vjs=3,"Job Description AMC Networks is looking for a Data Engineer to play a key role in development and maintenance of the company’s highly visible consumer facing SVOD and AVOD products. The engineer will join the product development team and help enable analytics on our digital platforms. Candidates will do so by working on initiatives including ensuring the quality of data, supporting integrations across various tools and platforms, and democratization of data via training, productized solutions, and documentation. The ideal candidate must show proficiency in building cost effective high performing systems in the AWS stack using Python and Pandas. The Data Engineer will also be expected to learn new and emerging technologies in order to adapt to a dynamic technological landscape. Responsibilities include the following: Building out data pipelines using AWS infrastructure (lambdas, batch, steps, etc) Defining standardized tracking requirements for development teams based on requirements from different departments such as marketing, product, BI, research. Creating and supporting validation pipelines for continuous monitoring of the quality of data Helping pinpoint and fix issues in data quality Support data input and output configurations via CDP (mParticle) Guide different product development teams on experimentation initiatives Enhance AMCN’s data culture by increasing the knowledge base via documentation and training for different departments Skills & Experience: Strong combined experience (3-5+ years) in working with python and libraries (pandas, scikit-learn, numpy) for analytics and/or data pipelines 1+ year experience in working with AWS or similar Cloud solutions. GIT experience Ability to document technical solutions and define development tasks accurately Familiarity with various third party analytics tools (such as mParticle, Braze, Amplitude) a plus The Company is committed to policy of nondiscrimination in its employment and personnel practices. Applicants are considered for all employment without regard to race, color, religious creed, religion, alienage, citizenship, gender, gender identity, national origin, ancestry, genetic predisposition or carrier status, age, marital status, familial status, military or veteran status, status as a victim of domestic violence, stalking or sexual assault, sexual orientation, disability or any other characteristic protected by federal, state or local law."
"Specialist, Data Engineer (ETL)",Nationwide,"Remote in Columbus, OH 43215+2 locations",https://www.indeed.com/rc/clk?jk=6dbb6083078515c1&fccid=312920717c3edd0d&vjs=3,"If you’re passionate about innovation and love working in an environment where you can constantly improve and adopt new technologies to drive business results, then Nationwide’s Information Technology team could be the place for you! Nationwide Technology is seeking to fill a Data Engineer – ETL Developer role for Customer Analytics. This role within Marketing, Analytics, and Customer Business Solution Area in the Data and Analytics department will be a lead developer on a software engineering team along with the responsibility to address technical issues and challenges. This Data Engineer role will be responsible for acquiring, curating, and publishing data for analytics along with supporting the Customer Analytic Data Store. The ideal candidate will have the following characteristics: Solid communication, people interaction, and leadership skills Thought leadership with a strong ability to analyze and troubleshoot Work closely with development teams to ensure that design specifications are implemented Well versed in data engineering, data warehousing, data integration, and analytics Knowledge of modern integration patterns (streaming/APIs) and containerized solutions (Docker / Kubernetes) Technical skills: Strong SQL skills Teradata/Snowflake/Oracle ETL/Informatica, PERL/Python (or similar) Cloud Native applications in AWS or Azure CI/CD pipeline enablement Agile software development methodology For the right candidate, we would consider WFT(remote work). Compensation Grade: F5 Colorado Residents: Email taproces@nationwide.com for salary information. Job Description Summary Nationwide’s industry leading workforce is passionate about creating data solutions that are secure, reliable and efficient in support of our mission to provide extraordinary care. Nationwide embraces an agile work environment and collaborative culture through the understanding of business processes, relationship entities and requirements using data analysis, quality, visualization, governance, engineering, robotic process automation, and machine learning to produce targeted data solutions. If you have the drive and desire to be part of a future forward data enabled culture, we want to hear from you. As a Data Engineer you’ll be responsible for acquiring, curating, and publishing data for analytical or operational uses. Data should be in a ready-to-use form that creates a single version of the truth across all data consumers, including business users, data scientists, and Technology. Ready-to-use data can be for both real time and batch data processes and may include unstructured data. Successful data engineers have the skills typically required for the full lifecycle software engineering development from translating requirements into design, development, testing, deployment, and production maintenance tasks. You’ll have the opportunity to work with various technologies from big data, relational and SQL databases, unstructured data technology, and programming languages. Job Description Key Responsibilities: Provides basic to moderate technical consultation on data product projects by analyzing end to end data product requirements and existing business processes to lead in the design, development and implementation of data products. Produces data building blocks, data models, and data flows for varying client demands such as dimensional data, standard and ad hoc reporting, data feeds, dashboard reporting, and data science research & exploration Translates business data stories into a technical story breakdown structure and work estimate so value and fit for a schedule or sprint is determined. Creates simple to moderate business user access methods to structured and unstructured data by such techniques such as mapping data to a common data model, NLP, transforming data as necessary to satisfy business rules, AI, statistical computations and validation of data content. Assists the enterprise DevSecOps team and other internal organizations on CI/CD best practices experience using JIRA, Jenkins, Confluence etc. Implements production processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it. Develops and maintains scalable data pipelines for both streaming and batch requirements and builds out new API integrations to support continuing increases in data volume and complexity. Writes and performs data unit/integration tests for data quality With input from a business requirements/story, creates and executes testing data and scripts to validate that quality and completeness criteria are satisfied. Can create automated testing programs and data that are re-usable for future code changes. Practices code management and integration with engineering Git principle and practice repositories. May perform other responsibilities as assigned. Reporting Relationships: Reports to Manager/Director Data Leader. Typical Skills and Experiences: Education: Undergraduate studies in computer science, management information systems, business, statistics, math, a related field or comparable experience and education strongly preferred. Graduate studies in business, statistics, math, computer science or a related field are a plus. License/Certification/Designation: Certifications are not required but encouraged. Experience: Three to five years of relevant experience with data quality rules, data management organization/standards, practices and software development. Experience in data warehousing, statistical analysis, data models, and queries. One to three years’ experience with Cloud technology and infrastructure including security and access management. Insurance/financial services industry knowledge a plus. Knowledge, Abilities and Skills: Data application and practices knowledge. Moderate to advanced skills with modern programming and scripting languages (e.g., SQL, R, Python, Spark, UNIX Shell scripting, Perl, or Ruby). Good problem solving, oral and written communication skills. Other criteria, including leadership skills, competencies and experiences may take precedence. Staffing exceptions to the above must be approved by the hiring manager’s leader and HR Business Partner. Values: Regularly and consistently demonstrates the Nationwide Values. Job Conditions: Overtime Eligibility: Exempt (Not Eligible) Working Conditions: Normal office environment. ADA: The above statements cover what are generally believed to be principal and essential functions of this job. Specific circumstances may allow or require some people assigned to the job to perform a somewhat different combination of duties. For NY residents please review the following state law information: Notice of Employee Rights, Protections, and Obligations LS740 (ny.gov) Nationwide utilizes a geographic-specific salary structure. For the salary range in Colorado, email taproces@nationwide.com."
Junior Quantitative Data Engineer,BMO Harris Bank,"Charlotte, NC 28277 (Ballantyne West area)+1 location",https://www.indeed.com/rc/clk?jk=691f08e6e392e84a&fccid=c9b51b880e5f15f6&vjs=3,"Address: 15720 Brixham Hill Ave Job Family Group: Technology DESCRIPTION: As a Junior Quantitative Data Engineer at BMO, you will participate in the design, development, and testing of quantitative abstraction frameworks for Credit Risk Forecasting Models. The successful candidate will contribute to a culture of innovation, collaboration, and continuous improvement while supporting and enhancing business-critical systems for the Bank's Credit Risk Reporting Disclosures.As an entry- level engineer, you will receive significant ongoing technical and business context training in order to fast-track their development as a Data Engineer. Further responsibilities include: Experimenting with new technologies and assess their viability for existing or future use cases Collaborating with other developers to improve processes and project deliverables Establishing partnerships with business partners in the Risk and Model Development teams Automating existing manual processes Establishing reliable DevOps and CI/CD Pipelines Supporting System Integration and User Acceptance Testing activities through defect triage and remediation Producing process and design documentation, where needed QUALIFICATIONS: Willingness to take calculated risks to improve team outcomes Willingness to disrupt the status quo Track record of self-motivation Curious, detail-oriented disposition Commitment to team success Excellent Written/Verbal Communication skills PREFERRED QUALIFICATIONS: Degree in Mathematics, Computer Science, Economics, or related field - 0 - 2 Years experience in a Data Engineering, Data Analyst, or Software Engineering role Experience programming with a modern programming language such as C++, Python, Java, Scala, R, Matlab, or similar We are strong believers in the benefit of co-located teams to foster great working relationships and help solve complex business problems, but we are also effective working remotely. As such, the goal for our team is to work in a hybrid environment, 2-3 days a week in the office. We’re here to help At BMO Harris Bank we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world. As a member of the BMO Harris Bank team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one – for yourself and our customers. We’ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we’ll help you gain valuable experience, and broaden your skillset. To find out more visit us at https://jobs.bmoharris.com . BMO Harris Bank is committed to an inclusive, equitable and accessible workplace. By learning from each other’s differences, we gain strength through our people and our perspectives. BMO Harris Bank N.A. is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter."
Data Engineer I,Ariel Investments,"Chicago, IL",https://www.indeed.com/rc/clk?jk=a298a7c00ce56c12&fccid=43a31a47b02448a2&vjs=3,"Ariel Investments is a premier, boutique, asset management firm. Our primary goal is to drive exceptional investment returns by bringing diverse perspectives together. The only way to beat a benchmark is to not look like one. As value investors, our thinking is deliberate and unconventional. We offer an independent, patient investing approach and aim to deliver excellence in any environment. We uphold our fiduciary responsibility to every shareholder, no matter how big or small. At Ariel, we strongly believe that teamwork yields results—which is why we have Co-CEOs. John Rogers and Mellody Hobson share a desire to cultivate leaders who are curious, focused and disciplined. We are nimble and efficient. Our drive is fanatical and intentional. Everyone plays their position and each contribution is critical to our firm's success. We seek subject matter experts who are unapologetically themselves. We encourage our employees to reach their full potential and we give them the runway to do so. After nearly four decades of active investing, we remain committed to our clients, our teammates and our community. We strive to be best-in-class investors and pioneer a path for those who entrust us with their financial future. Ariel Investments is looking for an entry level Data Engineer with experience in Microsoft technologies like Power BI, Power Apps and SQL. This role will need to own the development from end to end and the support and maintenance after. This individual will have an innovative approach to problem solving and a commitment to meeting deadlines. Create high quality code deliverables for a module, lead validation for all types of testing and support activities related to implementation, transition, and delivery. The role will involve working with all members of the IT team across different areas and understand the IT landscape and how it can evolve to help the business. Proof of vaccination is required as a condition of employment. Responsibilities will include: Building reporting models per best practices Develop visual reports, dashboards & apps using Power BI Connecting to data sources, importing and transforming data Working knowledge of ETL Good understanding of SQL Queries and logic Should have knowledge and experience in code design and requirements analysis Experience 2 years (ideally 2 years or less) of development using SQL, ETL tools and reporting tools Knowledge in any other reporting tools – SSRS, Tableau a plus Experience with at least one end-to-end implementation required Knowledge of data models, ETL, and data warehouse processes, preferred Python or R experience is a plus Knowledge of extracting data through API/web services a plus Education Bachelor in computer science or MIS - Required Certificates, Licenses, Registrations Any relevant Microsoft certifications – Preferred Computer Skills Needed to Perform this Job Working knowledge of Microsoft Office Suite Competencies Drive for Results: Can be counted on to exceed goals successfully; is constantly and consistently one of the top performers; very bottom-line oriented; steadfastly pushes self and others for results Customer Focus: Is dedicated to meeting the expectations and requirements of internal and external customers; gets firsthand customer information and uses it for improvements in products and services; acts with customers in mind; establishes and maintains effective relationships with customers and gains their trust and respect. Interpersonal Savvy: Relates well to all kinds of people, up, down, and sideways, inside and outside the organization; builds appropriate rapport; builds constructive and effective relationships; uses diplomacy and tact; can diffuse even high-tension situations comfortably. Priority Setting: Spends his/her time and the time of others on what's important; quickly zeros in on the critical few and puts the trivial many aside; can quickly sense what will help or hinder accomplishing a goal; eliminates roadblocks; creates focus. Business Acumen: Knows how businesses work; knowledgeable in current and possible future policies, practices, trends, and information affecting his/her business and organization; knows the competition; is aware of how strategies and tactics work in the marketplace. Ariel celebrates diversity and practices inclusion as a way to get work done – it's in our DNA. As an equal opportunity employer, our employment decisions are based on business needs, job requirements and individual qualifications without regard to race, color, religion, age, sex (including pregnancy), sexual orientation, gender identity, national origin, ancestry, marital status, parental status, mental or physical disability, military or veteran status, or any other basis protected by federal, state, or local law. Ariel is committed to recruiting and retaining talented applicants, and to providing all employees with a workplace free from discrimination and/or harassment."
Data Engineer (Mid-level),BlueHalo,"Colorado Springs, CO 80912",https://www.indeed.com/rc/clk?jk=6dbf0a9b1349c72a&fccid=2edd6db80ce3aa8d&vjs=3,"Overview: Being on the BlueHalo team means working alongside the brightest minds in technology on the toughest challenges facing our nation – not just every once in a while, but every single day. Together, we are leading the transformation of modern warfare and each BlueHalo employee plays a key role. That’s why our investment in you goes beyond a rewarding salary and benefits package. We’re committed to providing our people with the best opportunities to develop their skills, share their knowledge, and push their innovative ideas to the cutting-edge. Having fun doing it with a team that feels like family all across BlueHalo Nation is the ultimate perk. From Space and Directed Energy to Cyber and Intelligence to C4ISR and Air & Missile Defense, there is no limit to where you can take your career with us. Are you ready to launch a career at BlueHalo? BluHalo is looking for a Data Engineer for an integrated contractor team, supporting high-fidelity/high-resolution modeling of the Ballistic Missile Defense System (BMDS) in a virtualized, high-performance, high-capacity environment to provide Modeling and Simulation as a Service (MSaaS). The qualified candidate will be responsible for supporting the Integration, Test and Verification of large-scale data storage environments to support the Missile Defense Agency’s digital modeling/simulation programs. This includes working with many of the following technologies: data pipelines, data services, operational data stores, data warehouses, data marts, big data stores, data mining, big data visualization and experiment designs. The right individual will display both a passion for data science and leading a cultural change in how data is used throughout the organization regarding these efforts. Some travel is required.This position is located at Schriever AFB. Responsibilities: Design, create, build & maintain ETL data pipelines Automate processes, optimize data delivery & re-design the complete architecture to improve performance. Handle, transform & manage Big Data using Big Data Frameworks & NoSQL databases. Build complete infrastructure to ingest, transform & store data for further analysis & business requirement. Stand up and operate integrated data capabilities, including both databases and flat file structures. Integrate hardware, software and network components to facilitate delivery of data management and transformation capabilities. Implement monitoring and metrics Qualifications: Required Qualifications: A Bachelor of Science degree in Science or Engineering discipline plus two (2) years directly related experience in data This position requires the selected candidate have an active DoD Secret clearance with the ability to obtain a TS/SCI clearance Desired Qualifications: Proficiency using a data ETL tools like Apache NiFi and Apache Kafka. High level data literacy Python developer Bash script writer Working knowledge of the Linux operating system Proficient in data security management Experience with data systems RDBMS (MySQL, MariaDB, Postgres), NoSQL (MongoDB), and the Hadoop Ecosystem Experience with file, object (ECS), and block storage Expertise in high availability, backup/recovery, performance tuning and install/upgrade in data system technologies Security+ certified Salary range from $70,000 to $113,800 BlueHalo offers 4 weeks of PTO, comp. time, flex time, medical, dental, vision insurance, tuition reimbursement but other benefits as well. We provide employees with a comprehensive set of health care and very generous retirement benefits; one we consider superior to those offered by other companies in the industry. Leading the Transformation: The BlueHalo Effect It speaks to who we are as a company, a global protective ring that shields everything we most want to safeguard, an unbroken line that ensures our customers retain the advantage in any battlespace, from high above the Earth to deep in cyberspace. It’s who we are, a halo, a protector, the light of inspired engineering keeping our Nation safe. Our vision is a world where national security is certain because technical superiority is assured. Join us and become a vital element of The BlueHalo Effect! EEO Statement BlueHalo is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. U.S. Citizenship is required for most positions. If you are an individual with a disability and would like to request a reasonable workplace accommodation for any part of the employment process, please send an email to Recruiting@bluehalo.com. Please indicate the specifics of the assistance needed. This option is reserved only for individuals who are requesting a reasonable workplace accommodation. It is not intended for other purposes or inquiries."
data engineer sr,Starbucks,"Remote in Seattle, WA",https://www.indeed.com/rc/clk?jk=6e2b01a98b241f28&fccid=a88e611ddef97571&vjs=3,"Job Posting : Mar 21, 2022 Job Posting End Date : Ongoing Location : US-WA-Seattle-Starbucks Support Center United States Is this role eligible for remote or hybrid work? : Yes-Remote Starbucks - Technology Schedule : Full-time Senior data engineer Job Summary and Mission This position contributes to Starbuck's success by building enterprise data services for analytic solutions. This position is responsible for design, development, testing, and support for data pipelines and data products to enable continuous data processing for data exploration, data preparation, and real-time business analytics. Summary of Key Responsibilities Responsibilities and essential job functions include but are not limited to the following: Demonstrate deep knowledge of the data engineering domain, including non-interactive (batch, distributed) & real-time, highly available data, data pipelines Deep knowledge of data as a concept and the development of domain driven data products. Optimization of data products to service customer personas, Data science, AI/ML and data visualization. Knowledge of semantic data concepts. Build fault-tolerant , self-healing, adaptive , and highly accurate data computational pipelines Provide consultation and lead the implementation of complex programs Develop and maintain documentation relating to all assigned systems and projects Perform root cause analysis to identify permanent resolutions to software or business process issues Basic Qualifications Bachelor’s degree in computer science, management information systems, or related discipline, or equivalent work experience MUST HAVE Technology skills (7/10 or higher): Strong/expert Spark (PySpark) Using Jupyter Notebooks, Colab or DataBricks Hands-on data pipeline development, ingest patterns in Azure Orchestration tools , ADF or Airflow SQL Denormalized Data modeling for big data systems MUST HAVE competencies: Collaborative, able to work remotely , and still be an engaging team member. Strong analytical and design skills. Years Architect and design large scale high performance distributed systems 7-10 SQL Platform 7-10 No-SQL Platform 3+ Spark 3+ Data platform implementation on Azure or AWS 3+ CI/CD experience 2+ Exposure to SOA architecture 2+ Starbucks and its brands are an equal opportunity employer of all qualified individuals. We are committed to creating a diverse and welcoming workplace that includes partners with diverse backgrounds and experiences. We believe that enables us to better meet our mission and values while serving customers throughout our global communities. People of color, women, LGBTQIA+, veterans and persons with disabilities are encouraged to apply. Qualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Starbucks Corporation is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at 206-318-0660 or via email at applicantaccommodation@starbucks.com"
Data Integration Engineer,Readerlink Distribution Services,"Oak Brook, IL 60523",https://www.indeed.com/rc/clk?jk=aad88331ebea8a41&fccid=42d9053e3b5c3114&vjs=3,"If you love books and want to play an active role in the continued expansion of one of the book industry’s most important and fastest growing organizations, then you must be part of the ReaderLink Distribution Service’s dynamic team. ReaderLink sells one of every three trade print books sold in the United States to a blue-chip customer base including the biggest names across multiple retail channels. In the past few years, ReaderLink has become the #1 book distributor in the U.S. by doubling its annual sales to over $1 billion through the distribution of 300 million books per year to over 70,000 store locations nationwide. ReaderLink ships via its extensive logistics network of 6 national distribution facilities totaling 50 acres of building capacity. ReaderLink also publishes under the name Printers Row Publishing Group (PRPG) with four unique imprints: Canterbury Classics, Portable Press, Silver Dolphin Books, Thunder Bay Press and Dreamtivity. The diversity of these imprints allows PRPG to develop and expand on book industry trends in both the juvenile and adult book genres. ReaderLink headquarters is in Oak Brook, Illinois with its publishing headquarters in San Diego, California. We are currently seeking a Data Integration Engineer. The Data Integration Engineer position will be a member of the ReaderLink Data Administration and Integration Team. The opportunities for the team and this position include new development and enhancement of existing business applications for future growth and implementation of industry best practices. What You Will Be Doing: Work closely and effectively with database administrators, business analysts, subject matter experts, and other team members to determine data extraction and transformation requirements. Develop and support new/updated data flows between internal applications and 3rd party solutions, ensuring data meets business needs. Identify and resolve problems in a timely manner. Tune and optimize performance of processes, while ensuring the highest security standards. Create, document, and execute test plans, including white-box testing, black-box testing, positive and negative testing. Maintain systems in accordance with best practices to improve security, reliability and resilience of the systems in production. Be a champion of data security and a steward of data quality. Provide post-implementation support by performing problem analysis and resolution as needed. Work using an Agile/Waterfall hybrid development life cycle methodology using version control (TFS). Document, review and ensure that all quality and change control standards are met. Take ownership and support of assigned deliverables, and adjust well to changes in priority. Develop accurate estimates of effort and timelines, ensuring that all assignments are completed accurately and within approved delivery schedules. Ensure efficient and effective IT Department operations by providing back-up support to department personnel in performing daily tasks as needed. Provide after-hours support as needed. Be flexible to manage other tasks as assigned. What You Will Need: Possess high-level skills with MSSQL Server 2008 R2 or higher. .NET skills with C#, Windows Services and Web Services Object-oriented programming and XML Willingness and commitment to learn Consistently at work and on time, follows instructions, responds to management direction and solicits feedback to improve. Strong teamwork and customer service skills Good verbal and written English communications skills. Be able to effectively present technical concepts and technical information to a non-technical audience Prepare concise, yet detailed written communication (e.g. status reports and meeting notes) that may be shared and understood by a cross-functional audience (i.e. technical and non-technical) Bachelor’s degree (Information Technology or related field) or equivalent development experience required Competency in using Microsoft Office tools (i.e., Word, Excel, Visio, PowerPoint, and Project) is required Nice-to-Haves: Logic Apps DB2 (iSeries AS400) and/or SQLCLR Oracle PL/SQL MS Azure Cloud PowerShell ReaderLink is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, protected veteran status, or status as an individual with a disability. EOE/Minority/Female/Disabled/Veteran."
ML Ops / Data Engineer,Praetorian,"Remote in Austin, TX",https://www.indeed.com/rc/clk?jk=cb0bef9b7aeae077&fccid=d01f017a3e58dbe1&vjs=3,"Company Overview: At Praetorian, we are bringing together the world's brightest minds in pursuit of solving the cybersecurity problem by reducing the friction of security and enabling the next wave of technological innovation. From projects that range from cryptocurrency exchanges to autonomous vehicles and from medical device platforms to space telescopes, we apply expertise and engineering to help secure our customers. Career opportunity: Join an industry with massive socio, economic, and political importance in the 21st century Work alongside some of the best and the brightest minds in the security industry Leave an indelible mark on a company where a persons input has a real impact Be recognized, internally and publicly, for your contributions in a high profile position Align your career trajectory with a hyper-growth company that is on the move Have freedom to use whatever tools and technologies are best suited to solving the challenges at hand Core responsibilities Work with machine learning researchers and the engineering team to deploy, maintain, and optimize machine learning models in a production environment. Work with security engineers to identify and label vulnerabilities in source code and exposed attack surface infrastructure Create tools to find, ingest, organize, maintain, label and validate datasets for use in machine learning models Create tools to enable feedback from production machine learning models and the security engineers using them in order to improve the models Write data preprocessing tools in support of machine learning research Desired qualifications 5+ years development experience 3+ years experience working with machine learning models and/or datasets Experience with Google Cloud Platform and/or AWS Prior track record in a hyper-growth, high-tech company Bachelor's degree in a technical field +1 qualifications Experience deploying and optimizing machine learning models in a production environment Experience managing large, complex datasets for machine learning applications Understanding of basic machine learning principles and paradigms Experience with PyTorch and/or Tensorflow Experience with Google Vertex AI Platform, Google Compute Engine, and Google Cloud Storage Experience with a variety of programming languages (Python, Go, Java, C++, Scala, C#, JavaScript, etc.) Experience with Docker and Kubernetes Experience with Git, Mecurial, Maven, Gradle and other build and source code management tools Experience with modern technology stacks Experience with micro-services architectures Experience with cloud platforms and SaaS solutions Desired behaviors Passion for realizing the promise of machine learning to address the cybersecurity challenge Strong work ethic and the ability to maintain high levels of quality output Determination to always learn and improve and to never rest on ones laurels Personable individual who enjoys working in a team-oriented environment Comfort dealing with ambiguity in an environment where we build the plane as we fly it Ability to work within constraints and to challenge the status quo Ability to self-direct work, orient to action, and truly own the position in a hyper-growth environment Compensation & benefits Highly competitive salary Employee stock option plan Annual budget for training, certifications, and conferences 90% employee coverage and 60% dependent coverage on health insurance premiums 100% employee coverage and 60% dependent coverage on dental and vision insurance premiums 4% company 401K matching vested immediately Targeted Base Salary of 160K-180K In compliance with federal law, all persons hired will need to verify identity and eligibility to work in the United States and to complete the necessary employment eligibility verification document form upon hire. We are committed to an inclusive and diverse Praetorian. We are an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, disability, veteran status, genetic information, marital status, or any other legally protected status."
Data Engineer,Level Ex,+1 locationRemote,https://www.indeed.com/rc/clk?jk=b6d982777a612372&fccid=dd616958bd9ddc12&vjs=3,"Open to Long-Term Remote For U.S.-Based Candidates Level Ex is transforming the way medical professionals hone their skills by practicing high-risk procedures and earning training credit with the latest medical devices and diagnostic treatments in our industry-leading 3D mobile games. In the last five years Level Ex has exponentially grown, hiring top talent from the video games industry, the digital health ecosystem, and leading medical institutions. Our clients include top 20 pharmaceutical, biotech, and medical device companies including Baxter, Pfizer, Merck, and Medtronic, as well as leading medical associations. We're now looking for another experienced Data Engineer who, working across multiple teams, will build and refine a centralized data warehouse that is efficient, flexible, and scalable in a pioneering domain that combines mobile games data with healthcare provider data. We need a self-starter that will marshall the company’s data and surface it to business users and data scientists, and that will develop data pipelines and APIs to fuel data applications and business intelligence. Why You Should Join Us This job will be fun. This is a great opportunity for a data engineer to lead the implementation of important projects with autonomy and with the best, cutting-edge, cloud tooling. We use the best tools, and will continue to seek the best tools. Our Stack: AWS cloud data stack, with DBT, Snowflake, Prefect and Github. Currently using tableau for business intelligence. You'll be working on important and challenging projects. Some projects: re-architecting our events management system to increase flexibility and reduce latency; Building out our data warehouse for self-serve analytics and extending to new product classes; Integrating new data sources like Hubspot and JIRA into the data warehouse; Building a data monitoring service that identifies outliers and notifies business users of an anomaly event. The team is good. We have a positive, collaborative, open-minded team culture that is focused on learning, helping each other and finding long-term solutions to global problems rather than short term fixes. We're set up for a positive work-life. We're an agile data & analytics team that uses 2 weeks sprint cycles and 6 month product roadmaps to make a large impact with a great work life balance. What You’ll Be Doing with Us Work across multiple teams to develop and maintain data pipelines from different data sources - telemetry, sales, product cost, marketing, finance, etc - to fuel data applications, APIs and business intelligence tools. Architect, build and refine a cloud-native data warehouse that is scalable, efficient, and flexible, as new products, games, and features are introduced. Implement best-practices with metadata files and data models. Documenting pipeline details, changes to telemetry, and other important information. Load and structure new data sources and integrate them with reporting and operational tools. Develop automated testing to discover and correct data quality, structure and integrity issues. Evaluate and implement tools that will increase access to data and increase the number of questions that can be self-served by business partners. Lead large projects on a data & analytics roadmap. Act as a subject matter expert for the data engineering discipline and best practices. Writing and monitoring JIRA/development tickets. Who We Want to Meet Minimum of 1+ years of experience in building data pipelines using cloud technologies (like AWS, GCP, etc.), preferably using Python. Minimum of 2+ years of experience focusing on data engineering projects. Minimum of 2+ years of proficient SQL. Experience with Serverless cloud deployment. Experience with a programming language like Python, Scala or Java, preferably Python. Experience with cloud data warehouse tools like Snowflake. Excellent understanding of data modeling techniques. Experience with data orchestration tools like Prefect or Airflow. Ability to collaborate effectively and work as part of a team at a growing start-up. B.S. in Computer Science, Mathematics, Statistics, Economics, Analytics, Engineering or equivalent combination of education and experience. Bonus Points For Experience with ETL/ELT tools like dbt. Experience with AWS Services. Experience with Snowflake and, specifically Snowpipe. Experience with Prefect. Working knowledge of one or more business intelligence of tools like Tableau, Looker, Sisense, etc. Experience in data engineering for mobile game analytics and/or on medical analytics. M.S. or Ph.D. in Computer Science, Mathematics, Statistics, Economics, Analytics, Engineering or equivalent combination of education and experience. How We Make You Happy Multiple health insurance plans with 100% company-paid premiums 401(k) with generous company-paid match 100% remote for all U.S. employees Family-friendly benefits; Dental, vision, and optional pet insurance, 4 weeks of PTO, 2 weeks of company holidays, and more! Monthly snack allowance sent to your home- or choose a snack pack instead Remote-friendly events ie. board games tabletop simulator, Jackbox Games, DEI events, game jams, virtual happy hours Interested? Please send us your resume along with an optional cover letter detailing why you’re an excellent fit using the links below. We look forward to hearing from you and exploring the possibilities. Diversity Statement Level Ex is the collective sum of all our individual experiences, backgrounds, and influences and we pride ourselves in growing and learning together. We are an Equal Opportunity Employer committed to building an inclusive and diverse environment where everyone’s individuality is respected, and everyone has an Identity. Our commitment to inclusion across race, gender, age, religion, identity, and experience drives us forward every day. No Agency or Recruiter submissions will be accepted. Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job. Socials Twitter, LinkedIn, Facebook, YouTube"
Data Center Production Operations Lead Engineer,Facebook App,+15 locationsRemote,https://www.indeed.com/rc/clk?jk=752135f680476ef4&fccid=ba07516c418dda52&vjs=3,"Meta is seeking a technical leader to collaborate and guide Production Operations functions in our Data Center Site Operations team. The Production Operations team plays a key role at each of our data centers, assuring high reliability and availability of the server infrastructure required to meet the needs of more than 2 billion people actively engaged with Meta and our suite of applications. We partner closely with vendors and others at Meta, including infrastructure tooling & software development teams, product engineers & service owners, hardware design & manufacture, logistics & supply chain operations, quality & data analytics, project management, production & operations incident management, and maintenance management.The Production Operations Lead Engineer will assure exceptional availability and reliability of our hyper-scale fleet of servers. We seek a Subject Matter Expert who can continue to drive innovation in this space, spanning people, processes, infrastructure, reliability, tooling, automation, cost and quality. We seek someone who can quickly understand and respond to the technical needs of subject matter experts, local Site leadership, and our Production Operations teams, in a rapidly evolving technical environment. The successful candidate will gain alignment across these globally distributed teams and partner organizations, driving initiatives that deliver the most impact by prioritizing resources and focus areas. Data Center Production Operations Lead Engineer Responsibilities: Responsible for exceptional uptime, quality, and reliability of Facebook’s global fleet of data center servers, assuring the Production Operations team meets or exceeds all operational targets Organize and drive the needs and priorities of the Production Operations team in internal and partner forums, as the technical expert in this space Build trusted relationships within the team, to understand the biggest challenges and opportunities, and to advocate effectively for the right initiatives With partner organizations, collaboratively drive a roadmap that scales Site Operations, delivering high impact advances in tooling, hardware, and workflow Drive a singular operations strategy, goals, and priorities for the global Production Operations function within Site Operations Measure and benchmark the effectiveness of operational processes both internally and externally, setting performance targets and driving improvements as needed Develop scaling strategies and plans, be forward thinking by understanding infrastructure growth, identifying scaling issues before they occur, and contributing to solutions Ensure robust, timely communications across a globally distributed team, and provide the team great visibility to progress and strategy Develop close partnerships with Program Management, Tooling, Hardware Design, Data Analytics, Manufacturing, Sourcing, Logistics and other teams to deliver superb operational results and manage the performance of external vendors 30% - 40% travel required Minimum Qualifications: Proven experience as Engineering or Operations Director, or relevant Senior Technical, Operations or Engineering Lead role Organizational, technical, and leadership skills Working knowledge of IT/Operations Infrastructure Prioritization skills and proven experience leading tooling, systems, automation and process Interpersonal, partnership and communications skills Aptitude in decision-making and problem-solving BSc/BA in relevant field Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
Data Engineer,ABBVIE,"Lake County, IL+8 locations",https://www.indeed.com/rc/clk?jk=c66f0de476f17875&fccid=a3b51ece17c02aae&vjs=3,"About the Company: AbbVie’s mission is to discover and deliver innovative medicines that solve serious health issues today and address the medical challenges of tomorrow. We strive to have a remarkable impact on people’s lives across several key therapeutic areas: immunology, oncology, neuroscience, eye care, virology, women’s health and gastroenterology, in addition to products and services across its Allergan Aesthetics portfolio. For more information about AbbVie, please visit us at www.abbvie.com. Follow @abbvie on Twitter, Facebook, Instagram, YouTube and LinkedIn.. Postion Description: The Data Solutions Department within the Information Research (IR) Division is building the next generation of data management and decision support tools and services to optimize the efficiency and efficacy of research and development at AbbVie. The Real-World Data (RWD) team focuses on supporting the real-world data solutions across R&D, to support insights generation and sharing of wisdom within our data. RWD Engineer will independently identify and optimize technology solutions that address critical business needs within projects and for the team to scale solutions. Continuously seek to improve existing methods and processes. Data engineer will work on multiple RWD data projects and support the use of various types of data such as: claims, electronic health records, survey, registry studies, etc. Key Responsibilities: Demonstrate high proficiency across a wide range of technologies and platforms related to data model design and development, programming languages, data integration, data optimization, data analysis and data storage. Assist project teams to understand and follow data standards. Work with project teams to build data models fit for purpose with the intent on reusability, scalability, and performance at the core of the design. Participate in evaluation of new software, utilities, and tools and setting strategy for implementing new technologies. Provide technical leadership and consults with teams in planning, methods, procedures, standards, and best practices. Analyze and resolve technical problems using analytical problem-solving methods/techniques. Demonstrate in-depth knowledge of the pharmaceutical R&D business and utilize this knowledge in the rapid advancement of agile, impactful, and cost-effective solutions. Liaison with analytics project teams to ensure that the data is analysis ready to address the questions posed by business stakeholders. Provide comprehensive consultation to the cross-functional team in their data and technology expertise area. Prototype emerging business use cases to validate technology platforms and proposed solutions. Requirements: MS in Computer Science, or a related field with 2+ years of relevant experience. Or BS Computer Science, or a related field with 5+ years of relevant experience. Experience with big data tools: Hadoop, Spark, HDFS - EMR, Cloudera Demonstrates proficiency in SQL Experience with Clinical Trial & Real Word Evidence (EHR, Claims & Pharmacy, etc.) data format is preferred Experience with data modeling tools such as Erwin or ER studio Some fluency in one or the other programing languages, such as Python or R is preferred **Equal Opportunity Employer Minorities/Women/Veterans/Disabled**"
Data Engineer,LivCor,Remote in United States,https://www.indeed.com/rc/clk?jk=f1e0b4a5bc1ddc3f&fccid=3f1dd1e53506f3cf&vjs=3,"Overview: LivCor, a Blackstone portfolio company, is a real estate asset management business specializing in multi-family housing. Formed in 2013 and headquartered in Chicago, LivCor is currently responsible for a portfolio of over 400 Class A and B properties comprising more than 150,000 units in markets across the United States. Our business is focused on making real estate more valuable. But for us, it’s more than that. It’s people first, community always. It’s a life-filled career, not just a career-filled life. It’s doing good work, with good humans, and making a difference. It’s excellence in all its forms. Ultimately, we create great places to work, live, and grow. We do that by focusing on leaving people – and places – better than we found them. Whew! Still with us? Cool. Let’s talk about where you’d fit in: As a Data Engineer, you’re an artist. You will bring the business needs to life through beautifully crafted and well-thought-out solutions. You are a carpenter, building the scaffolding of the data workflows. You are a geek, always tinkering and making “cool” things. Above all, you are an engineer with the detail and precision often attributed to that title. You are an amazing, well-rounded individual and not “just a coder” who wants to be in a room being fed Mountain Dew and Twinkies under the door (not that we have anything against Mountain Dew or Twinkies, and we’d at least fully open the door to bring them to you). If this sounds like you and you want to be with amazing people, then we are looking for you. LivCor has a Data Engineer position who will design and develop data platforms, ingestions, and solutions for our ever-growing array of stakeholders. They will work across departments, ingesting raw data, integrating 3rd party systems, and expanding our data ecosystem. Only read further if you are: Kind Humble Honest Relentless Smart with Heart You should be: Authentic. You do you. Together, we’ll do something amazing. A passionate person with a love for real estate and investing; and believes that helping others win is a noble cause, essential to our success. An excellent team player who enjoys working with others and has strong interpersonal skills. Highly motivated, energetic, and organized Gumby. Things change. Responsibilities: What you will do: Responsible for delivering data warehouse and analytic solutions by ingesting, integrating, and curating data Builds analytical solutions and administers systems Create and maintain optimal data pipeline architecture. Our data must be woven into the fabric of our business Assemble large, complex data sets that meet functional…and sometimes non-functional business requirements Must believe that the health of a business is directly relatable to good, clean data; just like the health of the body is relatable to clean air and water Serve as a functional and content expert of the data warehouse to synthesize raw data into actionable information to be used in analytical solutions Communicating with stakeholders on project process and alignment. Must be as comfortable in a board room as you are in a data war room Developing integrated data solutions, modernizing, consolidating, and coordinating business needs across several applications Performance Tuning and Optimization of all Data Ingestion and Data Integration processes, including the Data Platform and databases Support Data Analyst and Business Stakeholder in analyzing and resolving any data issues as required. Make effective and decisive decisions when presented with multiple options for how to progress with any project Qualifications: What you should have: 3+ years hands-on with Python or related programming language. 3+ years hands-on experience as a Data Integration engineer or Software Developer 3+ years hands-on technical experience with ETL Tools BI Reports and Dashboards Understanding of data Schema modeling (Dimensions, Measures, Slowly Changing Dimension) 3+ years with SQL or NoSQL databases and data warehousing technologies. Understanding of cloud-based architecture. (AWS/Azure/GCP) Experience with Snowflake/Azure Databricks/Azure Data Factory is a big plus. Bachelor's degree or School of Hard Knocks Strong communication skills, with the ability to initiate and drive projects proactively and accurately with a large, diverse team An overwhelming desire to learn new things and to help people succeed What we offer: We know that if we take care of our team everything else will fall into place. We aren’t perfect, but we will try to set very clear expectations, always let you know where you stand, and do everything in our power to help you get where you want to go. Our culture and values matter to us. A lot. We’re definitely not serious but we take this stuff seriously, if you get what we mean. We want a place that is an ego-free zone. A place where good people do good things together and for the right reasons. It shouldn’t be rocket science in workplaces, but for some reason it still is? We’re absolutely determined to be different, and we think we’re doing a pretty good job at it. We have a CEO who makes fun of himself, and who will encourage you to tell him when he is wrong. In fact, he needs people to – we all do. Supportive challenge is good, it’s how we get better. We like getting better. We also love diversity, of all kinds. We need people who look, sound, speak, love, and exist differently from one another. This isn’t at the end of this paragraph because it’s an afterthought. It’s SO important to us we want it to stand out. Right. On to the technical stuff that we know matters to you. We offer competitive pay that is commensurate with the market and relevant experience, and a full slate of benefits that even includes things like paid parental leave. If any of this sounds interesting, then maybe we are a fit. Life is too short to work with people you don’t like. So whatever you do, don’t make that mistake. In compliance with the Colorado Equal Pay for Equal Work Act, the salary range for this position is $131,100 - $149,500 (for candidates that reside in CO). This role is bonus eligible. Benefits include generous health insurance and wellness benefits, 401(k), and paid time off. The LivCorian Values Be you. Be Real. Be Open. You do you. Together, we will do something amazing. Care, Always. We don’t want to let anyone down. Courageously Curious. We love to learn, even when it hurts. Help Others Win, Be A Good Neighbor. This is about ‘We, not Me.’ Relentless Hustle, Heart & Humility. Work hard. Be Kind. Make Better. A few of the people you will work with: Nathan Kimpel Elif Efeoglu Paul Hernacki Matt Lomas Deepa Rao Brian Chan Nick Fotopoulos Don Pochron Paul Stec LivCor is proud to be a US EPA ENERGY STAR® Partner EEO Statement Our company is proud to be an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. Our employment decisions are based on individual qualifications, job requirements and business needs without regard to race, color, marital status, sex, sexual orientation, gender identity and/or expression, age, religion, disability, citizenship status, national origin, pregnancy, veteran status and or any other legally protected characteristics. We are committed to providing reasonable accommodations, if you need an accommodation to complete the application process, please email talent@revantage.com. #LI-Remote #LI-DB1"
Data Center Tooling Engineer,Facebook App,+16 locationsRemote,https://www.indeed.com/rc/clk?jk=bc72821f7956ec79&fccid=ba07516c418dda52&vjs=3,"Meta is seeking a forward thinking, experienced Data Center Tooling Engineer to join the Data Center Site Operations team. Our data centers, and the tens of thousands of servers installed in them, are the foundation upon which our rapidly scaling infrastructure efficiently operates and upon which our innovative services are delivered. Meta is at the leading edge of the global data center industry both in terms of how data centers are designed and operated. This person should enjoy working in a fast-paced environment where adaptability and flexibility will be key to their success. The candidate we seek is a forward thinking IT professional with deep experience applying and developing software tooling and automation solutions, to address complex operational issues. The ideal candidate should have a strong software architecture background and be comfortable working independently with little supervision and creating global direction. They should also be a natural collaborator, able to distill the needs of stakeholders and subject matter experts and translate these into long-term engineering solutions. The successful candidate will be a leader, capable of providing technical guidance and mentorship, to drive continuous improvement in global operational processes and tooling. Extensive knowledge of managing servers, programming/scripting, and performing complex projects in a large-scale, distributed data center environment is an advantage. Data Center Tooling Engineer Responsibilities: Subject matter expert on operational processes and workflows, and their supporting automation and tooling. Collaboratively design, develop and execute software-based automation and tooling solutions to drive global operational processes and efficiency. Work with our Engineering and Operations teams to evaluate and recommend tools, technologies and processes to ensure the highest quality operational tooling and platforms. Collaborate with stakeholders, functional owners and subject matter experts to interpret business and operations needs and articulate how they can be addressed in partnership with engineering and programs teams. Find opportunities to globally improve and innovate in key areas such as server integration and repairs, documentation and standardization, tooling and automation, Data Center design and capacity planning. Act as a member of project teams developing new tools or enhancing existing ones, together with our engineering teams globally. Gather and define requirements from the Data Center teams, and act as the liaison between these and the engineering teams on technical project matters. Drive tooling improvements through prioritization in tooling roadmaps, in partnership with tooling and automation program managers. Work as technical lead globally, with cross-functional teams on large scale data center projects and initiatives. Support the work to investigate complex technical matters globally and spanning multiple disciplines such as Hardware, Linux, Networking and Power & Cooling. Create and influence roadmaps based on operational escalations and scaling issues for tooling improvements and further automation. Build strong relationships with other groups within engineering and/or across the company. Proactively solicit feedback from related teams, and use that feedback to improve tooling efficiency as infrastructure scales. Ability to travel up to 30% required. Minimum Qualifications: Master in Computer Engineering or Computer Science 7+ years experience designing and building software applications. Experience in processing and analyzing large sets of data. Knowledge of networking principles, technologies, protocols and standards. Experience managing multiple projects within the same time schedule and time management experience. Experience working individually as well as in groups on a regular basis. Experience working independently within a multi-disciplinary team of software and operations engineers. Proven communication skills. Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Preferred Qualifications: Large-scale data center environment experience, including deep system knowledge of Linux, Server Hardware, networking, network protocols, supply chain and Data Center automation. Experience working in Data Center environments, and a solid understanding of key infrastructure commonly found in Data Centers such as cooling, power distribution and fiber-optic cabling. Knowledge of all aspects of large-scale supply chain, logistics and asset management in a Data Center environment. Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
Data Engineer- Remote,Segmint Inc.,Remote,https://www.indeed.com/company/segmint/jobs/Data-Engineer-81b9cc4232694618?fccid=5c1e74e784656918&vjs=3,"Segmint is looking for a Data Engineer to join our small, collaborative team working with great tools and exceptional people, where you can learn, interact, and contribute in a fast-paced environment. Be part of a fun team, comprised of a group that is caring, works through challenges and creates a motivating environment where the work gets done! We believe in a culture built on work-life balance and flexibility, and the opportunity to be innovative, while always investing in career growth. We are a 100% remote company and welcome applicants from anywhere in the United States to apply. About SegmintSegmint empowers financial institutions and financial technology providers to easily understand and leverage data, interact with customers, and measure results. Derived from billions of transactions, Segmint provides the fastest and most accurate customer insights through advanced data tagging, categorization, and contextualization. Our insights enable all functions of an organization to inform strategies including competitive analysis, risk, marketing, customer experience, and product innovation. Position SummaryThe Data Engineer is responsible for the development and maintenance of Segmint’s data analytics platform and data warehouse solutions. Duties include developing, deploying, and monitoring database-centric data ingestion and analytics processes relating to anonymized banking analytics in a multi-tenant, SOC2-compliant, distributed computing environment, at scale. Also responsible for analyzing, cleansing, mapping, and integrating new, outside data models to the solution regularly. Applicants should be fast-paced, detail-oriented, organized, consistent, and analytically-minded. Required Skills Linux/Unix Bash SQL PostgreSQL/Greenplum Python Git Additional Skills S3, Lambda, etc. Docker Spark/Hadoop Cassandra/NoSQL D3.js, matplotlib, etc. Node.js Required Experience 2+ years in data warehouse development, ETL, data pipelines, or database administration Experience with data modeling and scaling for large data sets (1 TB+) Professional, team-based, agile software development with software development lifecycle Additional Experience Object-oriented or functional application development w/ API integration DevOps with Amazon Web Services cloud-based infrastructure products Experience with data visualization or business intelligence tools Data preparation for data science, feature encoding/engineering, natural language processing Benefits & Perks Competitive compensation package Benefits insurance package available, including employer HSA contribution 401K with employer matching program Flexible PTO policy Remote position Great people to work with! We are interested in every qualified candidate who is eligible to work within the United States; however, we are unable to sponsor visas at this time. Note: Due to the nature of Segmint’s business, it is necessary for all employees to sign an Intellectual Property Employee Agreement. Segmint Inc. is an Equal Employment Opportunity / Affirmative Action Employer and maintains a Drug-Free Workplace. Job Type: Full-time"
Data Engineer,BlocPower,Remote,https://www.indeed.com/rc/clk?jk=4a07291e8d11a786&fccid=5f7c8e9b696f11aa&vjs=3,"BlocPower is a clean energy leader creating smarter, greener, healthier buildings for all by reducing the barriers to money-saving, quality-of-life-improving green building upgrade. We provide engineering, financing and project implementation services for our clients, with a special focus in historically left out communities across the country. These communities, and their buildings, are underserved by traditional energy services companies because they are considered too small, too costly, or too risky. Our portfolio of projects include houses of worship, schools, non-profits, small businesses and multifamily buildings. Through our work, we save our clients money, reduce greenhouse gas emissions, improve health and create local employment opportunities. At BlocPower, we value our mission. We are trusted advisors that get things done for our customers by using data to make the right decisions. We support and expect excellence from our team members. We treat both our customers and ourselves with care and respect. As our work is centered around systematically disenfranchised communities – including people of color, people from working class backgrounds, women and LGBTQ people – we strongly encourage applications from people with these identities or who are members of other marginalized communities. About the Role To further this mission, BlocPower is looking for a friendly Data Engineer to join our growing team. This engineer will be responsible for expanding our data pipeline architecture. You should have a depth of experience building data pipelines,, and see yourself adding to as much as benefitting from a supportive team environment. This hire will help keep data consistent across projects and teams. This may look at times like helping our engineers to perform energy audits using our proprietary models, writing software that will help us analyze big data that comes into our platform via sensors installed across our projects, or optimizing the project pipelines of our construction and sales teams. The ideal candidate is someone who is self-directed, believes in our mission, and is an excellent written communicator. What You'll Do Assemble large, complex, structured/unstructured data sets from various public/non-public data sources into the raw-zone of our data lake. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Design and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data and associated architecture secure. Who You Are Ability to write good SQL, and work with a variety of databases (eg. AWS RDS, MySQL, PostgreSQL, and MongoDB) Autonomously stand up and maintain an ETL pipeline with little to no supervision, using tools such as AWS Glue, Informatica, or Talend Coherently organize a data lake, making it easy easy to collaborate on data Manipulate big data, including high-velocity streaming data using tools such as Spark, Kafka and Kinesis Strong project management and organizational skills Education/Experience BA/BS or equivalent combination of work experience and education preferably in degree/course work/experience in computer science/data engineering 2+ years of experience as a Data Engineer What You'll Get from Us Base salary between $120,000 and $130,000 Competitive equity in a growing, Series A startup Health, dental, vision benefits, plus perks like a One Medical membership Bonus Points Experience with AWS cloud services: EC2, EMR, RDS, Redshift, Glue, Sagemaker Microservice architectures Docker, Kubernetes, Docker-Compose Git and Jenkins Experience working with IoT/Sensors This job description is not intended to be a comprehensive list of the duties and responsibilities of the position. The duties and responsibilities may change without notice. BlocPower™ provides equal employment opportunities(EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, BlocPower™ complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. BlocPower™ expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of BlocPower™ employees to perform their job duties may result in discipline up to and including discharge."
"Staff Software Engineer, Data Engineering, Global Engineerin...",Bain & Company,"Los Angeles, CA 90067 (Century City area)+11 locations",https://www.indeed.com/rc/clk?jk=9e94c6bb17c1b3a6&fccid=48270b2eee62c2c6&vjs=3,"WHAT MAKES US A GREAT PLACE TO WORK We are proud to be [1] consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are currently ranked the #1 consulting firm on Glassdoor’s Best Places to Work list, and we have maintained a spot in the top four on Glassdoor's list for the last 12 years. We believe that diversity, inclusion and collaboration is key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally. We are publicly recognized by external parties such as Fortune, Vault, Mogul, Working Mother, Glassdoor and the Human Rights Campaign for being a great place to work for [2] diversity and inclusion, women, LGBTQ and parents. WHO YOU’LL WORK WITH Bain’s Global Engineering leads the firm’s software development efforts and defines engineering standards for Bain globally. The team ships software solutions to address client and internal needs, ranging from iterative prototypes to enterprise-grade production software. You will solve cutting-edge problems for a variety of industries as a data engineer. As a member of a diverse engineering team, you will participate in the full engineering life cycle designing, developing, optimizing, and deploying new data engineering solutions and infrastructure at the production scale of the world’s largest companies. WHAT YOU'LL DO Develop software solutions tackling enterprise scale challenges for Bain’s clients, as the data engineer and expert within a cross functional team Develop and champion modern data engineering concepts to technical audience and business stakeholders Build large scale data engineering solutions with automation Translate business requirements into technical requirements and implementation details Participate in the full software development life cycle including designing, writing documentation and unit/integration tests, and conducting code reviews for data engineering solutions. Provide technical guidance to external clients and internal stakeholders in Bain This role requires approximately 20% travelling to clients as needed - (post-pandemic) Architect, design, develop, build, and release robust and scalable Data Engineering solutions. (50%) Enable data and technology for data science, analytics, and other application use cases via data engineering Data ingestion at scale for batch and near real-time use cases from polyglot sources Transformations at scale including cleaning, enriching, de-duping, joining and correlated on structured, semi-structured or unstructured data Serve data on polyglot mediums (data lake, distributed file systems, database/data-warehouse, API, stream) in use-case specific formats (Parquet, Avro, Json, ORC, SQL) Enable data with governance layer including discoverability, observability, security, privacy & compliance and metadata & taxonomy Enable engineers and data scientists to productionize workloads with engineering best practices at scale Build scalable data engineering infrastructure and tooling (20%) Participate in the full software development life cycle including reviewing distributed system designs, writing documentation and unit/integration tests, and conducting code reviews Design and develop frameworks to automate data ingestion, analysis, visualization, and integration of structured and unstructured data from a variety of data sources Provide technical guidance to external clients and internal stakeholders in Bain (30%) Scoping data engineering and data platform architecture initiatives Develop work plans with insights on data engineering capability roadmap and feature prioritization Assess current data engineering capabilities and recommend maturity roadmap for use case Advise on tools and technology decision making for data engineering capabilities ABOUT YOU We are looking for someone who has: Bachelor’s in Computer Science or a related technical field. 4+ years of experience programming with Python, Scala, Java, C++, or Go 4+ years of experience with cloud-based data engineering technologies (EMR, Glue, ADF, Dataflow, Databricks, Snowflake, Kafka, Kinesis, Pulsar etc) 2+ years of experience with data engineering frameworks like Spark, Flink, Airflow, Atlas, Beam Ideal candidates will also have experience in: Advanced degree in Computer Science or a related technical field. Open-source distributed computing and database frameworks such as Apache Flink, Ignite, Presto, Apex, Cassandra and HBase Experience deploying machine learning models at scale for training and inference Application engineering experience including developing backend services at scale and front end Deployment best practices using CI/CD tools and infrastructure as code (Jenkins, Docker, Kubernetes, and Terraform). Strong interpersonal and communication skills, including the ability to explain and discuss technical concepts and methodologies with colleagues and clients from other disciplines Agile development methodology Engineering distributed systems and database internals (including handling consensus, availability, distributed query processing etc.). Deploying end-to-end logging solutions such as the EFK stack. Experience with designing and building large scale application or data platforms Experience with administering and managing Kubernetes clusters (EKS, GCP, or AKS) and Helm Applicant must have received, or be willing to receive, the COVID-19 vaccine, and be fully vaccinated (established 2 weeks following final dose) by date of employment with Bain & Company to be considered for U.S. based jobs subject to required accommodation process. ABOUT US Bain & Company is a global consultancy that helps the world’s most ambitious change makers define the future. Across 63 offices in 38 countries, we work alongside our clients as one team with a shared ambition to achieve extraordinary results, outperform the competition, and redefine industries. We complement our tailored, integrated expertise with a vibrant ecosystem of digital innovators to deliver better, faster, and more enduring outcomes. Our 10-year commitment to invest more than $1 billion in pro bono services brings our talent, expertise, and insight to organizations tackling today’s urgent challenges in education, racial equity, social justice, economic development, and the environment. We earned a gold rating from EcoVadis, the leading platform for environmental, social, and ethical performance ratings for global supply chains, putting us in the top 2% of all companies. Since our founding in 1973, we have measured our success by the success of our clients, and we proudly maintain the highest level of client advocacy in the industry. References Visible links 1. http://www.bain.com/about/what-we-do/awards/index.aspx 2. https://www.bain.com/about/diversity-inclusion/"
Data Warehouse Engineer,Pinger,Remote,https://www.indeed.com/rc/clk?jk=53bdbca9f1a553e7&fccid=8490ff0d2da14179&vjs=3,"Hello from Pinger! Our market-leading communications products have been downloaded by hundreds of millions of iOS and Android users around the world. Our simple mission is to help individuals and businesses communicate in new and surprisingly simple ways. We are profitable, growing and are having fun. Pinger is located in downtown San Jose, walking distance to dozens of restaurants and public transit and is embracing remote work. Pinger is growing and is continuing to expand into the communications market for small business professionals. We are looking for a Data Warehouse Engineer to turn data into information, information into insight and insight into business decisions. You will conduct full lifecycle activities from requirement analysis to reporting and insights, working with a close-knit engineering team while also interacting with product stakeholders. Essential functions: Design and develop ETL frameworks using Java, Talend Integration Studio and AWS Create web-based metric reports using standard frameworks Design and develop Star Schema with MySQL InnoDB Setup third party API integrations using PHP, Java or Python Identify, define and implement new process improvements Support Ad-hoc data related requests using MySQL, S3 and AWS Redshift Nice to have: Experience with ML on AWS Key Technologies: Java, Python, MySQL, PHP, Splunk, AWS (atleast S3 and Redshift) Tools: Talend Integration Studio, Excel, Git, Jenkins Requirements: BS or MS in Computer Science (or equivalent industry experience) 3+ years of experience in Data Engineering or similar Must have knowledge of database design and modeling in the context of data warehousing Strong knowledge and experience with reporting packages like Tableau, Splunk, databases like MySQL and RedShift and programming in Java, PHP and Python Strong analytical skills with the ability to collect, organize, analyze and disseminate significant amounts of data with attention to detail and accuracy"
AI/ML - Data Engineer - Siri and Language Technologies,Apple,"Seattle, WA+43 locations",https://www.indeed.com/rc/clk?jk=b95bc3d29d49ba08&fccid=c1099851e9794854&vjs=3,"Summary Posted: May 18, 2022 Weekly Hours: 40 Role Number: 200375054 Would you like to play a part in ensuring the quality of groundbreaking technology for large scale systems, big data, and artificial intelligence? Drive the quality of the Siri user experience and work with the people who built the intelligent assistant that helps millions of people get things done — just by asking? We’re looking for exceptional data engineers who are passionate about our product and values; who love working with data at scale; and who are committed to that hard work necessary to continuously improve. You will be expected to optimally partner with upstream engineering teams and downstream analytical, ML and product consumers. Key Qualifications Experience working with Spark and other distributed data technologies for building efficient & large scale data pipelines. Programming efficiency and hands on experience in Scala/Java or Python. Software engineering rigor and ability to write elegant, modularized and well tested code. Experience required in building data processing pipelines curating data for variety of stakeholders Experience in schema design and data modeling, SQL skills to analyze and explore data, identify patterns and draw insights. Strong communication and collaboration skills. Ability to work in a cross functional environment across multiple stakeholders and convert abstract requirements into concrete deliverables. Description Partner closely with machine learning engineers, data scientists, analysts, software engineers and researchers to build reliable, distributed data pipelines and intuitive data products that feed into machine learning models, analytics, research, thereby allowing our stakeholders to easily leverage data in a self-served manner. And in using this data, you will help drive an efficient utilization of tools and processes, achieving the right balance of evaluation coverage and time invested, to deliver a perfect Siri experience. You will develop new and creative methodologies to evaluate and improve Siri, in order to execute and deliver feedback to engineering partners. Education & Experience A Bachelor's or Master's in CS, Engineering, Math, Statistics, or a related field, or equivalent practical experience in data engineering. Additional Requirements You have excellent written and verbal communication skills. You are Tenacious, Relentless, and Determined You are curious: always learning new technologies, rapidly synthesizing new information, and understanding “the why” before “the what.” You are self-directed and capable of operating amid ambiguity. You are poised and display excellent judgment in prioritizing across difficult tradeoffs. You are pragmatic: not letting “the perfect” be the enemy of “the good.” You are humble, continually growing in self-awareness and possessing a growth mindset."
Sr. Data Engineer,WellSky,"Overland Park, KS+3 locations",https://www.indeed.com/rc/clk?jk=036ceaf6cf490071&fccid=ccf9f96e8cae7bb9&vjs=3,"WellSky is seeking a savvy Senior Snowflake Data Engineer to join our BI team of analytic experts to build our next generation cloud data warehouse solutions. The data engineer will be responsible for expanding and optimizing our data flow and data pipeline architecture as well as migrating our data warehouse solution to the cloud platform in Snowflake. Bring passion, creativity and dedication to your job and there is no telling what you could accomplish. A day in the life! You will be responsible for the following: Design and implement very large-scale data intelligence and data warehousing solutions in Snowflake, combined with other technologies. Creating and maintaining optimal data pipeline architecture. Expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Proactively identify and propose new, alternative technology to create scalable implementations and achieve delivery results. Provide technical guidance and support to a vibrant engineering team Respond quickly and effectively to production data warehouse issues and take responsibility for seeing those issues through resolution. Improve and scale the existing products and tools to support our growth You will join a team of top engineers creating interactive reports and dashboards with stunning visualizations. You will have direct impact on the users of our solutions, mainly doctors, nurses, and others on the front lines of healthcare and community services. Your hard work will touch the lives of real people and families navigating life and death issues with the support of our solutions. We seek to build purpose-driven teams where comradery and compassion are coupled with a dogged pursuit of excellence. Do you have what it takes? Required Experience: 5+ years of experience in designing and delivering ETL/ELT processes, data pipelines, data lakes, data warehouses and reporting platforms. 3+ years of architecting, designing, and building a fully operational production grade large scale data warehouse solution on Snowflake cloud platform. Recent hands-on experience with solid understanding of Snowflake implementation, SnowSQL, SnowPipe and query performance tuning is a must. 2+ years of experience working with data visualization and reporting tools like SisSense and/or Tableau Advanced SQL knowledge is a must. Minimum 1 years' experience with REST API development and consumption Experience working with cloud platform - AWS or GCP Experience and enjoy working in an Agile environment. Source control with Git/Git Hub Outstanding communication and interpersonal skills Must be a great team player Do you stand above the rest? Preferred Experience: Experience with Legacy Data Warehouse migration to Snowflake is a BIG plus! Highly Desirable: Knowledge of frameworks such as Angular.js, React Experience with development skills: back-end (i.e., REST API, (Micro)Services, .NET Core, C#, SQL etc.) and front-end (i.e. TypeScript, Angular, React CSS, etc.) design and programming technologies. Experience with scripting languages like Python, etc. Experience with one or more relevant tools like Kafka, Streamsets, Matillion. Leveraging Splunk, Sumo, New Relic, CloudWatch for observability and monitoring Bachelor's degree in Computer Science or equivalent Preferred Certifications: Bonus Points: Go to the top of the stack if you have Snowflake certification! Who We Are: We have an open environment where highly motivated, ambitious engineers can help drive innovation. We include a diverse group of collaborative & super intelligent teammates to work with and learn from. We constantly strive to solve large scale challenges with a variety of technologies. We strongly support a work/life balance. We believe in giving recognition for doing what you enjoy. Come help us realize care's potential! #LI-PM About WellSky WellSky is a technology company leading the movement for intelligent, coordinated care worldwide. Our next-generation software, analytics, and services power better outcomes and lower costs for stakeholders across the health and community care continuum. In today's value-based care environment, WellSky helps providers, payers, health systems, and community organizations solve tough challenges, improve collaboration for growth, harness the power of data analytics, and achieve better outcomes by further connecting clinical and social care. WellSky serves more than 20,000 client sites around the world — including the largest hospital systems, blood banks, cell therapy labs, blood centers, home health and hospice franchises, post-acute providers, government agencies, and human services organizations. Informed by more than 40 years of providing software and expertise, WellSky anticipates clients' needs and innovates relentlessly to ultimately help more people thrive. We're looking for talented individuals who want to use their skills to build a strong, technology-driven company. We offer competitive salaries, great benefits, including generous paid time off programming, and a casual and fun environment that encourages quality, creativity, and excellence. Enjoy all we have to offer. We invite you to join us. Apply today! WellSky provides equal employment opportunities to all people without regard to race, color, national origin, ancestry, citizenship, age, religion, gender, sex, sexual orientation, gender identity, gender expression, marital status, pregnancy, physical or mental disability, protected medical condition, genetic information, military service, veteran status, or any other status or characteristic protected by law. WellSky is proud to be a drug-free workplace. Applicants for U.S.-based positions with WellSky must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire. All U.S.-based employees must be fully vaccinated against COVID-19 unless a medical or religious exemption is approved."
"Data Engineer, SME",Chenega Corporation,"Fort Belvoir, VA 22060+1 location",https://www.indeed.com/rc/clk?jk=d1da4b962c587816&fccid=ebdab10e41fbc599&vjs=3,"Overview: The Data Engineer (SME) will have extensive experience in leading and developing data products (e.g., architecture, design) within the system/software development life cycle from requirements definition to architecture, design, implementation, and test, through deployment and operations and support and preparing data for analytical and/or operational uses within a defined organization, function, and/or application context. This includes an understanding and having the ability to apply/implement cloud-based data and database technologies, ability to develop data architecture and design products, knowledge of multiple databases and associated schemas, knowledge and skills to apply data standards and best practices while adhering to applicable Department of Defense (DoD) laws, policies, directives, mandates, and guidance, including data protection of sensitive information (e.g. Personally Identifiable Information (PII) and Protected Health Information (PHI)), and the ability to reconcile data models and de-duplicating data stores. Responsibilities: Lead and contribute to all aspects of data engineering activities within the software development life cycle, including development of applicable technical documentation Lead and participate in analyses to determine feasibility of achieving data engineering requirements given the limitations and constraints of the target solution Lead and participate in trade-off analyses as needed Define and develop techniques to integrate, consolidate, and structure data for analytical and operational use, including ability to inform on data aggregation and associated security implications Identify data migration strategies to transition data from legacy systems and technologies to advanced, enterprise-based solutions and establish test data sets Reconcile data models and de-duplicate data stores where multiple exist Prepare strategic and tactical recommendations with sufficient rationale to advise senior leader decisions relative to the applicability and application of data technologies Ensure data and database changes are properly implemented and tested, including assessing the impact of requirements and physical changes to the data and database design Identify and resolve data issues throughout the development life cycle Ensure compliance with data and database standards Apply cloud-based data and database technologies, data standards, and best practices while adhering to applicable DoD laws, policies, directives, mandates, and guidance, including data protection of sensitive information (e.g., Personally Identifiable Information (PII)) Identify and evaluate data engineering risks and provide mitigation recommendations related to requirements satisfaction Ensure alignment of data engineering activities with overall program schedule, milestones, and required documentation Lead Data Engineering Working Integrated Product Teams (WIPTs) Maintain current and accurate knowledge of data engineering, data architecture. and data storage best practices Other duties as assigned Qualifications: Master’s degree required 15+ years of relevant work experience Working knowledge and application of DoD 5000 and 8000 series and Business Enterprise Architecture Active or interim secret clearance The position requires a COVID vaccination or an approved accommodation/exemption for a disability/medical condition or religious belief Knowledge, Skills and Abilities Cloud-related certifications preferred Broad and deep set of engineering expertise Extensive experience in aligning systems engineering activities throughout the acquisition program life cycle phases Strong coordination, organization, teaming, and communication skills Strong customer service and excellent interpersonal skills Ability to listen and understand task descriptions and requests Ability to explain problem resolutions Ability to quickly respond to time-critical queries from leadership Ability to work independently without direct supervision or guidance #Chenega IT Enterprise Services, LLC Teleworking Permitted?: false"
Data Engineer,SmithRx,"San Francisco, CA",https://www.indeed.com/company/SmithRx/jobs/Data-Engineer-8915d4e1054b738a?fccid=b17e01bf290f8339&vjs=3,"Who We Are: SmithRx is a rapidly growing, venture-backed Health-Tech company. Our mission is to disrupt the expensive and inefficient Pharmacy Benefit Management (PBM) sector by building a next-generation drug acquisition platform driven by cutting edge technology, innovative cost saving tools, and best-in-class customer service. With hundreds of thousands of members onboarded since 2016, SmithRx has a solution that is resonating with clients all across the country.We pride ourselves for our mission-driven and collaborative culture that inspires our employees to do their best work. We believe that the U.S healthcare system is in need of transformation, and we come to work each day dedicated to making that change a reality. At our core, we are guided by our company values: Integrity: Do the right thing. Especially when it's hard. Courage: Embrace the challenge. Together: Build bridges and lift up your colleagues. Job SummaryThe Engineering team at SmithRx is developing the next-generation modern pharmacy benefits management (PBM) platform that will change how companies administer and manage pharmacy benefits. Our unified technology platform provides real-time actionable insights that drives cost savings, powers clinical services and results in a brilliant customer experience. A unified technology platform exists nowhere in the pharmacy benefit ecosystem to programmatically solve widespread deficiencies. The result is a PBM delivering unmatched service quality and operational efficiencies that exceeds all industry standards.As a Data Engineer, you will play a key role in the entire data engineering lifecycle from design, documentation, build, test and maintain our SmithRx analytics platform. You will advocate and bring best practices/methodologies, coding standards and large-scale system design perspectives to our team. We need our engineers to be versatile and driven, display leadership and ownership qualities, and be enthusiastic to take on new challenges across the organization as we continue to push technology forward.What you will do: Focus on data architecture; designing, developing and maintaining our data platform and its features using various technologies Analyze and organize raw data Build data systems and pipelines Explore ways to enhance data quality and reliability Interpret trends and patterns Conduct complex data analysis and report on results Prepare data for prescriptive and predictive modeling Build algorithms and prototypes Combine raw information from different sources Develop analytical tools and programs Collaborate with stakeholders and technical leads to build functional and technical requirements to produce high-quality, scalable information systems. Provide scope and risk estimates for systems and pipeline builds by building technical design documentation Continually build, improve, and reinforce software development best practices, design patterns, tools and technologies. Work with senior leadership to turn technical vision into a tangible roadmap every quarter Be a cornerstone for a collaborative learning culture through mentorship, code reviews, the exploration of new technologies, and other innovations What you will bring to SmithRx: Positivity; non-dogmatic, team-first attitude Flexibility; someone who is responsive and comfortable with ambiguity 5+ years of experience as a Data Engineer or in a similar role BS or advanced degree in computer science or applicable experience Experience with data modeling, data warehousing, and building ETL pipelines Experience in SQL High proficiency with relational databases such as PostgreSQL, including schema design, SQL tuning, and database monitoring Proven track record of applying data engineering for enabling business analytics Coding proficiency in at least one modern programming language (Python, Java, Golang, etc) Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets Experience building data products incrementally and integrating and managing datasets from multiple sources Highly disciplined approach to software design and development and ability to work on features independently (accurately forecast delivery milestones and work with stakeholders to ensure that expectations are met) Demonstrated knowledge of open source APIs, CI and CD pipeline, AWS platform, Docker, and Kubernetes a plus Located in California or on PST time a plus What SmithRx Offers You: Highly competitive wellness benefits including Medical, Pharmacy, Dental, Vision, Life and Disability insurance Flexible Spending Benefits Discretionary Time Off 401(k) Retirement Savings Program Commuter Benefits Paid Parental Leave benefits Professional development and training opportunities Job Type: Full-time"
GIS - Geospatial Data Engineer (Remote),Cognizant,"Remote in Johnston, RI",https://www.indeed.com/rc/clk?jk=f49652cd1965ed21&fccid=2df6a1e69a70a1e7&vjs=3,"Technology:- Geospatial Information Systems Technical Skills- GeoGoogle-Address Standardizer GeoNetwork GeoCortex Machine learning Python API scripting Geospatial Data analysis Remote sensing and GIS Roles & Responsibilities Work together with the IoT & Remote Assessments team on Proof of Value studies related to Remote Assessments. Test and debug vendor APIs for client locations third-party data aerial imagery parcel bounds building footprints and other data. Assist in curation of machine learning results. Assist in creation of training data for machine learning models. Data engineering data pipelining training data generation for machine learning models Knowledge of machine learning concepts or framework Knowledge of geospatial tools such as QGIS and aerial imagery image processing Insurance domain experience Employee Status : Full Time Employee Shift : Day Job Travel : No Job Posting : Jun 14 2022 About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant. Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview. Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information."
Data Engineer,"Take-Two Interactive Software, Inc.","New York, NY+1 location",https://www.indeed.com/rc/clk?jk=cfb8491b4ac7c4ca&fccid=2dda8667d8de78d8&vjs=3,"Who We Are: Take-Two develops and publishes some of the world's biggest games. Our Rockstar label creates Grand Theft Auto and Red Dead Redemption, two of the most critically acclaimed gaming franchises in history. Our 2K label creates games like NBA 2K, WWE 2K, Bioshock, Borderlands, Evolve, XCOM and the beloved Sid Meier's Civilization. Our Private Division label publishes Kerbal Space Program, Ancestors and The Outer Worlds. While our offices (physical and virtual) are casual and inviting, we are deeply committed to our core tenets of creativity, innovation and efficiency, and individual and team development opportunities. Our industry and business are continually evolving and fast-paced, providing numerous opportunities to learn and hone your skills. We work hard, but we also like to have fun, and believe that we provide a great place to come to work each day to pursue your passions. The Challenge: Take-Two Interactive is looking for a passionate, solution-oriented Data Engineer to join the team in building the next generation reporting and analytics platform. The ideal candidate is a strong Python developer who has experience building APIs and pipelines to support integrations of internal and external applications. The ideal candidate relishes working with large volumes and diverse types of data, enjoys the challenge of highly complex technical contexts, and, above all else, is convinced in the value of data for better decision-making. The Data Engineer will support and collaborate with architects, data analysts and data scientists and will ensure efficient data delivery architecture is consistent throughout ongoing projects. They must be proactive and comfortable supporting the data needs of multiple teams. He/she is a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoys working in a fast-paced environment. What you will take on Provide thought leadership and collaborate with other team members to continue to scale our architecture, taking into account the needs of today while remaining flexible enough to evolve for the needs of tomorrow Participate in all phases of SDLC - requirements, design, and development through testing, deployment, maintenance and support. Develop and manage stable, scalable data pipelines that cleanse, structure and integrate disparate big data sets into a readable and accessible format for end user analyses and targeting using stream and batch processing architectures. Maintain API based ETL/ELT processes from multi source raw data collection to reporting/visualization. Collaborate with Data Scientists to implement advanced analytics algorithms that exploit our rich data sets for statistical analysis, prediction, clustering and machine learning Develop data quality framework to ensure delivery of high-quality data and analyses to stakeholders. Develop and support continuous integrations build and deployment processes which use Jenkins, Docker, Git, etc. Define and implement monitoring and alerting policies for data solutions. What you bring 2+ years of professional experience in Python. 2+ years of hands-on experience in using advanced SQL queries (analytical functions), experience in writing and optimizing highly efficient SQL queries. Experience integrating with 3rd party APIs. Experience with building out an ETL pipeline. Experience of working in AWS environment highly desirable. Comfort in working with business customers to gather requirements and gain a deep understanding of varied datasets. Experienced in testing and monitoring data for anomalies and rectifying them. Knowledge of software coding practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations. Bachelor's degree or equivalent in an engineering or technical field such as Computer Science, Information Systems, Statistics, Engineering, or similar What We Offer You: Great Company Culture. Ranked as one of the most creative and innovative places to work, creativity, innovation, efficiency, diversity and philanthropy are among the core tenets of our organization and are integral drivers of our continued success. Growth: As a global entertainment company, we pride ourselves on creating environments where employees are encouraged to be themselves, to be inquisitive and collaborative and to grow within and around the company. Work Hard, Play Hard. Our employees bond, blow-off steam, and flex some creative muscles – through corporate boot camp classes, company parties, game release events, monthly socials, and team challenges. Benefits. Medical (HSA & FSA), dental, vision, 401(k) with company match, employee stock purchase plan, commuter benefits, in-house wellness program, broad learning & development opportunities, a charitable giving platform with company match and more! Perks. Fitness allowance, employee discount programs, free games & events, stocked pantries and the ability to earn up to $500+ per year for taking care of yourself and more! Take-Two Interactive Software, Inc. (""T2"") is proud to be an equal opportunity employer, which means we are committed to creating and celebrating diverse thoughts, cultures, and backgrounds throughout our organization. Employment at T2 is based on substantive ability, objective qualifications, and work ethic – not an individual's race, creed, color, religion, sex or gender, gender identity or expression, sexual orientation, national origin or ancestry, alienage or citizenship status, physical or mental disability, pregnancy, age, genetic information, veteran status, marital status, status as a victim of domestic violence or sex offenses, reproductive health decision, or any other characteristics protected by applicable law."
Data Engineer,Brave Software Inc.,Remote,https://www.indeed.com/rc/clk?jk=0bcbd2ca267472c2&fccid=c1e8803caacbb1f7&vjs=3,"Data Engineer About Brave Brave is on a mission to protect the human right to privacy online. We’ve built a free web browser that blocks creepy ads and trackers by default, a private search engine with a truly independent index, a browser-native crypto wallet, and a private ad network (opt-in!) that directly rewards you for your attention. And we’re just getting started. Already 50 million people have switched to Brave for a faster, more private web. Millions more switch every month. The internet is a sea of ads, hackers, and echo chambers. Big Tech makes huge profits off our data, and tells us what’s true and what’s not. Brave is fighting back. Join us! Summary Brave Ads is Brave’s global private ad network, redesigned from the ground up to reward users while enforcing the highest standards of user privacy. The Brave Ads team works to ensure that marketers, both large and small, receive the information they need to make the most of their campaign dollars, without sacrificing strict user privacy. We are looking for a great data engineer who can help us maintain and improve our growing data pipeline, and help create additional data products and cubes that can drive the business forward. Requirements Experience with Python or similar language Experience with SQL, Postgres, and building analytics queries Experience with complex data flow/analytics infrastructure, e.g. Kakfa, Kinesis, Redshift and large scale data problems Experience with OLAP and data visualization Comfortable working in an open source setting A passion for helping protect users’ privacy and security Written and verbal communication skills in English Proven record of getting things done Nice to haves Experience with ad-tech / marketing tech ecosystem Working at Brave Industry-leader in privacy, with a research and engineering team that’s innovating everyday to keep people safer online and beat Big Tech Highly competitive salaries & benefits, and generous home-office stipends Fully remote team (no office, no commute) Welcoming, humble, ridiculously smart teammates, and a truly flat org structure Opportunity to get in early at a hyper-growth company, and revolutionize the web Oh, and did we mention Brendan, our CEO & co-founder, invented JavaScript? Check us out LinkedIn | Glassdoor | brave.com"
Data Engineer,Colorado Community Managed Care Network,"Denver, CO 80210 (Platt Park area)",https://www.indeed.com/rc/clk?jk=0110519afa3a27c1&fccid=f9a454d7688152b6&vjs=3,"Category: Full time, Exempt Reports To: Data Engineering Director Salary Range: $70,000 - $85,000 annually (DOE) At CCMCN, our mission is to provide services that enable its members and their community partners to succeed as efficient, effective, and accountable systems of care. CCMCN’s vision is that all Coloradans have access to high-quality, integrated, accountable health care. Areas of focus include population health, accountable care, shared services, health information technology, and clinical quality improvement programming. CCMCN is governed by a Board of Directors comprised of organizational representatives from each of its health center members as well as representation from Colorado Community Health Network (CCHN) and clinician representatives. Through working with health centers and community partners, CCMCN provides technological and analytical tools that help create a more comprehensive and collaborative network of care for Coloradans. Position Description: The Data Operations department provides data management, integration, and reporting services for multiple external and internal consumers. This position will be responsible for several aspects of data integration management that support CCMCN’s production services. Candidate must have experience in Microsoft SQL database development, data integration, ETL (extract, transform and load), bi-directional data feeds, and documentation. Essential Functions: Provide development and maintenance support for data integrations between systems. Provide development and maintenance support for the EDW and supporting databases. Provide automated solutions whenever possible and proactively suggest alternative solutions. Assist in the development of new databases and associated processes as necessary. Provide data analytics report development for specific projects as needed. Develop data validation reports and analysis where applicable. Develop technical documentation of data integrations and processes. Communicate and collaborate with other team members and clients to develop innovative data solutions. Utilize up-to-date knowledge of database and data quality best practices to produce effective solutions. Remain knowledgeable in healthcare data standards, measures and code sets as well as applicable data privacy practices and legal requirements. Required Skills and Experience: Experience working in a SQL environment, especially with data transformation, stored procedures, and query development. Experience working with a variety of ETL tools. Knowledge of data warehousing best practices, concepts, and processes. Strong analytical and problem-solving skills, with demonstrated change management experience. Demonstrated ability to set and meet project timelines and deliverables. Effective interpersonal and communications skills with the ability to interact with various levels of personnel. Willing and able to quickly learn new technology. Must be flexible, organized, self-directed, able to prioritize multiple tasks, and able to manage a full workload. Experienced in Microsoft Office and Microsoft Operating Systems. Fluency in written and spoken English. Additional Preferred Skills: Strong business and technical writing abilities. Experience working in EMR integration tools. Knowledge of healthcare data standards such as HL7, FHIR, CCD, CCR, and claims data. Knowledge of standard healthcare code sets like LOINC, ICD9/10, CPT4, and SNOMED. ETL/Data Movement Certifications Ability to attend conferences and workshops for further education to expand and improve management skills. Benefits: CCMCN provides a generous, comprehensive benefits package that includes: Health, dental, and vision insurance plans FSA, DCA, and employer-sponsored HRA Life, AD&D, and long-term disability insurance plans 401K retirement plan with employer match Employee Assistance Program (EAP) Paid leave including vacation, sick, and holiday, including one floating holiday CCMCN is an equal opportunity employer and is committed to a diverse and inclusive work environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law."
Associate Data Engineer,Dealer Tire,Ohio,https://www.indeed.com/rc/clk?jk=5eaf1c60d3ac8f42&fccid=e7636a46005567c3&vjs=3,"Who We Are We’re Dealer Tire, a family-owned, international distributor of tires and parts established in 1918 in Cleveland, OH. We’re laser focused on helping the world’s largest and most trusted auto manufacturers grow their tire business—in fact, we’ve sold more than 60 million tires to date. We’re a thriving company, and we’re looking for driven individuals to join our team. That’s where you come in! As an Associate Data Engineer at Dealer Tire, you will be part of a highly skilled team of innovative data professionals who are responsible for designing and implementing our enterprise data lake, data model, and the ETL/ELT pipelines that feed our business and analytical systems. You and your teammates will collaborate with internal and external customers and our affiliate companies, empowering them to solve business problems and gain powerful insights using high-performance datasets, enterprise analytics systems, and self-service tools such as Alteryx, R, Python, and Power BI. Your essential job functions will include: Collaborate with business and IT teams to help implement a comprehensive and easily expandable Enterprise Data Model based on business need. Participate in the design and enhancement of our enterprise data model, enterprise analytics systems, data marts, and data warehouse/data lake. Build robust, scalable, and high-performing ETL/ELT solutions involving structured & unstructured data with assistance from teammates as needed. Be curious, seek assistance from others when needed, learn new systems and skillsets, and share what you learn with the team. Leverage appropriate design patterns for the problem being solved, such as near-real-time/change data capture, batch processing, streaming data, etc.. Support the team’s roadmap for the enterprise data model and the systems that support it, including their maintenance, documentation, and enhancement. Participate in design reviews to foster team accountability and maintain a high standard of quality. Be a data advocate; assist in the evangelization and democratization of our data assets and empower users with self-service tools and training to enable them to leverage those assets effectively. Engage with multiple concurrent projects both within your team and with other teams. Articulate ideas and architectural concepts clearly and concisely through verbal and written communication. Collaborate with teammates to monitor and measure system and process performance and make corrections and enhancements where needed as part of a focus on continual improvement. Provide on-call/after-hours support for processes and systems owned by the team on a rotating basis. Position Requirements Strong verbal and written communication skills are required. Ability to work cross-functionally in a fast-paced, high growth environment and manage multiple concurrent workstreams and priorities is a must. Ability to learn quickly and collaborate with teammates to solve challenging problems is a requirement. 0-3 years of experience in Data Engineering or a similar role is a plus. An associate’s or bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field is a plus. A basic understanding of database query languages (t-SQL, PL-SQL, etc.), data modeling (including data warehouse design concepts such as star schema design, etc.), data engineering, or data reverse engineering are a plus. Experience with any of the following technologies is a plus: Microsoft SQL Server, Python, Power Shell, R, Scala, Amazon AWS (EC2 instances, Redshift, lambda functions, S3, etc.), Power BI, and Windows and Linux servers. General expertise in enterprise IT architecture (databases, ERP, middleware, UI, networking, infrastructure) is a plus. Competencies Required Results Orientation Agility Initiative Customer Focus Learn Quickly Relationship Building Physical Job Requirements Continuous viewing from and inputting data to a computer screen Sitting for long periods of time Travel as necessary (less than 10%) Drug Policy: Dealer Tire is a drug-free environment. All applicants being considered for employment must pass a pre-employment drug screen before beginning work Why Dealer Tire: An amazing opportunity to join a growing organization, built on the efforts of hard working, innovative, and team-oriented people. We offer a competitive salary + bonus, and a comprehensive benefit package including: paid time off, medical, dental, vision, and 401k matching (50% on the dollar up to 7% of employee contribution). EOE Statement: Dealer Tire is an Equal Employment Opportunity (EEO) employer and does not discriminate on the basis of race, color, national origin, religion, gender, age, veteran status, political affiliation, sexual orientation, marital status or disability (in compliance with the Americans with Disabilities Act*), or any other legally protected status, with respect to employment opportunities. ADA Disclosure: Any candidate who feels that they may need an accommodation to complete this application, or any portions of same, based on the impact of a disability should contact Dealer Tire’s Human Resources Department to discuss your specific needs. Please feel free to contact us at ADAAAccommodation@dealertire.com or via phone at 833-483-8232."
SF Data Engineer/Lead,Baldwin Risk Partners,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=84de57f6c986195d&fccid=5cf6362cb82df67a&vjs=3,"What we are looking for This role offers an exciting opportunity to work on multiple projects that elevate our client experience with us. You will be playing a pivotal role in aligning the Salesforce platform’s data integrity and integrations with other applications. This role will be part of the Salesforce Platform Center of Excellence and will be working in an Agile team structure. Your responsibilities include, aligning data from various sources into the Salesforce data model, data mapping, ensuring data integrity, data de-duplication and reporting. Quality standards are paramount to us and we need you to assure that all teams’ individual work as well as dependent teams’ work is well thought out and designed appropriately. Our data leads are very hands on and we expect you to develop capabilities within the Salesforce platform such as API integrations, data rules, building reports and dashboards, preparing data sets, production to sandbox data refreshes and configure Einstein capabilities. Designing and developing proof of concepts, quickly showing results to elicit more detailed requirements is expected. Staying abreast of the Salesforce platform releases and new features is paramount to succeed in this role. An ideal candidate for this role is laser focused on delivering to our company’s objectives, able to wear multiple hats, has collaborative attitude to drive shared success with various stakeholders. Your demonstrated acumen in the Salesforce technologies, data management experience, certifications in both Salesforce and data toolkit will differentiate you as a candidate of choice for us. These credentials are strongly preferred. Position Responsibilities Strategy, Design and Planning Lead the overall data management between Salesforce platform and various connected applications. Create a plan and lead efforts towards keeping the Salesforce platform’s data clean. Continuous efforts in data migration, data de-duplication, research and development towards removing data debt is anticipated. Solution design for data integrations using APIs and other integration patterns Participate in product planning sessions and architecture sessions to contribute to the overall data flow design. Development, Testing and Deployment Build APIs, enrich data through various integrations Research, design, build and deploy various data solutions for data to and from the Salesforce platform Design and build reporting and dashboards using native Salesforce platform as well as Einstein/Tableau/BI tools where applicable. Prepare test data, ensure test data privacy in lower environments and data prep for various capabilities Assist in creating the deployment playbook for all releases, prepare data loads where necessary and ensure smooth deployment. Operational Management Continuous monitoring of the Salesforce platform data integrity. Own any data research from production issues and provide solutions. Perform all data related activities during sprint execution, testing, deployment and post go-live activities. Position Requirements Formal Education & Certification College diploma or university degree. Certifications in Salesforce technologies Certifications in any data management toolkit Knowledge & Experience Bachelor's degree with 5-8 years of experience in the Salesforce technologies 5-8 years of experience in working with data related projects and data integrations Proven experience with data management, data refreshes and data integrity within the Salesforce platform ecosystem Excellent software troubleshooting experience. Excellent understanding of the organization’s goals and objectives. Personal Attributes Hungry to learn, demonstrated continuous learning of relevant skills Excellent written, oral, and interpersonal communication skills. Ability to conduct research into data issues and tools as required. Ability to communicate ideas in both technical and business languages. Highly self-motivated and directed, with keen attention to detail. Proven analytical and creative problem-solving abilities. Able to prioritize and execute tasks in a high-pressure environment. Ability to work in a team-oriented, collaborative environment Click here for some insight into our culture!"
Data Quality Engineer,Health Catalyst,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=5c4e652d13338322&fccid=d7d403f3184c0ee9&vjs=3,"Our mission is to be the catalyst for massive, measurable, data-informed healthcare improvement through: Data: integrate data in a flexible, open & scalable platform to power healthcare’s digital transformation Analytics: deliver analytic applications & services that generate insight on how to measurably improve Expertise: provide clinical, financial & operational experts who enable & accelerate improvement Engagement: attract, develop and retain world-class team members by being a best place to work Role: Data Quality Engineer Team: Data Quality & Operations Location: US Remote Travel: <5%, US Job Summary The Data Quality & Operations team is responsible for ensuring and demonstrating are fit for purpose and reliable after implementation. The team does this by providing specialized experienced around data quality verification, validation, monitoring, and support, both when issues arise and through proactive analysis and maintenance. The Data Quality Engineer role combines data engineering and analytic skills with a sound understanding of the Data Operating System (DOS) and our specific data products to identify the root cause of ETL and data quality issues, propose and implement solutions, and escalate to and collaborate with the implementation and development team as required. This role will also conduct cross-client impact analysis, identify patterns for repeat issues, propose proactive maintenance, build/enhance tools to scale subject matter expertise, train others on data quality concepts and solutions, and continually improve the team’s knowledge base. What you'll own: Leverage Data Quality Central and other Health Catalyst software to verify, validate, and monitor the data pipeline for data quality issues and degradation. Log issues and provide detailed issue tracking and status updates using Jira Support Desk ticketing system. Conduct root cause analysis ETL performance and data quality issues. Identify and propose scalable solutions to issues, including impact analysis and preventative maintenance proposals. Update data pipeline knowledge base in run book with details around client environment nuances, root cause, solution, troubleshooting steps, and ways to determine things are correct. Escalate issues and bug fixes to the development team to ensure that they are aware of all systemic issues and can integrate solutions into code base. Train and consult with 24x7 ETL support, DOS Operations, and implementation teams to ensure the knowledge base is comprehensive and promotes their ability to independently troubleshoot and implement solutions and understand nuanced situations that require different approaches. Provide training on data quality concepts to facilitate higher quality development and implementation across the DOS platform and client environments. What you bring: Intermediate level in Structured Query Language (SQL). Experience working with Azure DevOps. Experience working with SQL Server. Experience identifying configuration or data quality gaps/issues and writing checks to facilitate validation and monitoring that covers the gap. Demonstrated ability and desire to provide excellent and proactive customer service. Demonstrated ability and desire to communicate, collaborate, and work within and across teams. Demonstrated ability to quickly understand and explain why something does/does not work and then identify scalable opportunities to improve. Demonstrated ability and desire to efficiently learn and effectively leverage new concepts, skills, and technologies; and willingness to ask for help when needed. Desire to specialize and become an expert in performance, data quality, and the interaction between the data pipeline and DOS. Lives the Health Catalyst Way attributes of smart, hard-working, and humble. Experience implementing or working with Health Catalyst tools or data products. Passionately believes that both timely AND correct data are possible. Has a testing mindset and can think of how and why something will or will not work. Focuses on scalable and lasting solutions versus custom and one-off stopgaps. Health care data experience. Visualization experience using a variety of BI tools. Quality improvement - Lean, 6 Sigma, etc. Preferred Education & Relevant Experience BS/BA in information technology, math, statistics or business-related field or equivalent relevant work experience 5+ years’ experience in technology or technology related field Information Security and Compliance Responsibilities (This section can not be changed or modified) Maintain compliance with training directives required by the organization pertaining to Information Security, Acceptable Use Policy and HIPAA Privacy and Security. Adhere to and comply with the organizations Acceptable Use Policy. Safeguard information system assets by identifying and reporting potential and actual security events to the organizations Security and Compliance Officers. The above statements describe the general nature and level of work being performed in this job function. They are not intended to be an exhaustive list of all duties, and indeed additional responsibilities may be assigned by Health Catalyst . At Health Catalyst, we appreciate the opportunity to benefit from the diverse backgrounds and experiences of others. Because of our deep commitment to respect every individual, Health Catalyst is an equal opportunity employer."
Data Engineer,Ortho Molecular Products,"Stevens Point, WI 54482",https://www.indeed.com/rc/clk?jk=5bbcf974dd7c2c66&fccid=77ad0679852a2124&vjs=3,"Overview Why Work at Ortho Molecular Products : The position is on-site at our Stevens Point, Wisconsin facility. The schedule is Monday through Friday from 8:00am to 5:00pm - this is not a remote opportunity. Responsible for providing analytic and technical skills to innovate, build, and maintain well-managed data solutions through Power BI. Will provide capabilities to solve business problems by providing dashboards and or data solutions to assist business units in monitoring performance metrics/insights. They maintain the Power BI data model and adjust the data model for new reporting needs. They are also responsible for providing training and leadership to data analyst. What to Expect : Responsible for providing data and metrics (including dashboards) in Power BI to the business units as requested Responsible for managing the Power BI data model, modifying the data model to accommodate new reporting requirements and investigating data issues with Power BI reporting Responsible for writing specs for new/revision to existing reports; documentation and testing prior to release to the business units Continually work with the user to collect reporting requirements, establish appropriate test criteria and work with manager to develop a solution if one does not exist Identify problem areas in the organization and develop a data solution through process improvement Analyze large amounts of data and report on trends/forecasts, assist with the design, development, and maintenance of the Analytic Datamarts including quality checks, identifying issues and working with partners to create solutions Create Key Performance Indicators for departments, develops advanced analytics solutions, test and design of historical and predictive analytics solutions to solve business problems What You Will Contribute : Bachelor’s degree or higher education 3 to 4 years Data Analyst experience preferred in a related field Advanced experience using Microsoft Excel, SQL, Data Warehouse with a strong understanding of Power BI and or dashboarding tools Demonstrated knowledge of how to create/improve business processes with ability to understand/perform business and functional requirement analysis Strong ability to write Excel formulas, apply statistical/analytical mathematical concepts to solve problems Experience with Power BI, Tableau or other data visualization software, SQL, DataMarts and ability to process data via PowerQuery and PowerAutomate CHARACTER QUALITIES: Thoroughness, Dependability, Orderliness, Persistence, Responsibility and Wisdom. Must be authorized to work in the U.S. as Sponsorship is not provided What You Will Receive : Competitive Compensation with Bonus Program Medical, Dental, Vision, Company Paid Life Insurance, and 401(k) with Employer Match Voluntary Benefits: Short Term Disability, Life, Critical Illness, Accident, & Hospital Indemnity Paid Time Off and Holiday Job Specific Training & Tuition Reimbursement Program Wellness & Employee Assistance Program, Gym Reimbursements, and Healthy, Company Paid Meals Free Monthly Products, Employee Discounts, and Employee Referral Incentives Simply put, our healthcare system is broken. It is expensive, complicated, and dysfunctional. At Ortho Molecular Products, our vision is to transform the practice of medicine. Every day, across America and the world, we help health care providers implement better solutions for health challenges that include lifestyle medicine and nutritional therapies proven to improve patient outcomes. We do this by manufacturing science-based products and developing innovative clinical programs for doctors that help their patients get better faster. We are looking for people who align with our mission and want to invest their lifework and passion into transforming the practice of medicine. Our team is purpose-driven, values-based, and service-focused. We are looking for likeminded people who want to join the movement that is changing the way healthcare is being delivered. Ortho Molecular Products honors the service of our military veterans and understands how that service translates to a successful career. We invite you to explore the Ortho website to learn about our career opportunities and apply. Ortho Molecular Products is an Equal Opportunity Employer."
Data Engineer 2,IQVIA,+1 locationRemote,https://www.indeed.com/rc/clk?jk=356477c229bfb4b4&fccid=6b7a1dfe07e7f037&vjs=3,"A successful candidate must be a self-starter, fast learner and able to be part of a cross-functional, SCRUM software development team. The candidate is a strong technology professional and software developer with significant experience with big data technologies and must also possess excellent analytical skills, with a focus on detail, quality, and accuracy. The position will include working with distributed business and technical resources, as well as external vendors to implement the components of the architecture. Essential Job Responsibilities Ability to grasp complex problems and develop a simple yet comprehensive solution that meets or exceeds the client’s expectations. Ability to explain difficult or complex problems and solutions to varying audiences which allows them to understand and works to build consensus. Proactively shares experiences and knowledge to help the team improve its development processes and practices. Actively seeks challenging assignments, is genuinely excited by a challenge Collaboration with Product Owner, Scrum Master, DevOps, developers and testers in an Agile team environment with strong leadership I respect and cultivating of DMD’s agile culture Develop deep expertise in the product and be passionate about creating the absolute best customer experience for the product Using first-hand customer information to improve products and services according to technical and product roadmap Being flexible and responsive to the client’s and products changing needs Continually evaluates emerging technologies to identify opportunities, trends and best practices that can be used to strengthen DMD’s technology platform and development practices Required Skills & Experience 3+ years of development experience with big data technologies 3+ years using Apache Spark (mainly with the SQL module) Advanced knowledge in programming languages such as Scala or Java Advanced knowledge of Scala unit testing Advanced knowledge in writing SQL (Hive Syntax) Strong analytic skills related to working with unstructured datasets Exposure to Cloud Service Providers (AWS) Experience with Software Development Life Cycle Eager to learn, adapt and perfect your work; you seek out help and put it to good use Experience in designing and building large scale enterprise data solutions Creative, attention to detail, multitasking and organizational capacity Impeccable written and verbal communication skills. Strong technical, process and problem-solving proficiency Demonstrated business acumen, and cross-collaboration capabilities Ability to set and deliver on priorities and deal with a degree of ambiguity Exceptional interpersonal and communications capabilities Display organizational and emotional intelligence Able to hit the ground running with a can-do attitude Additional Role Desirables Big Data Certification(s) Certified Scrum Master or Certified Product Owner Experience with JIRA and Confluence Team Collaboration Software Exposure to Medical / Pharmaceutical digital marketing industry IQVIA is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. We believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. Learn more at https://jobs.iqvia.com We are committed to providing equal employment opportunities for all, including veterans and candidates with disabilities. https://jobs.iqvia.com/eoe As the COVID-19 virus continues to evolve, IQVIA’s ability to operate and provide certain services to customers and partners necessitates IQVIA and its employees meet specific requirements regarding vaccination status. https://jobs.iqvia.com/covid-19-vaccine-status"
Data Warehouse Engineer (FieldRoutes),ServiceTitan,Remote,https://www.indeed.com/rc/clk?jk=5b41bf2e5caf0029&fccid=88323fbac065cf8f&vjs=3,"Get to know us: We’re FieldRoutes, a leading cloud-based and mobile SaaS provider in the pest control and lawn care industry. Recently acquired by ServiceTitan, the world's leading provider of software for the trades, our platform automates all aspects of field service operations for enterprise and small businesses, enabling them to accelerate growth, streamline operations, increase customer retention, and maximize revenue. When you join our team, you’ll be joining one of the fastest growing companies in the US with an award-winning culture that’s been celebrated by Inc. Magazine and Forbes. Trusted by over 1,700 field service companies across thousands of locations, our software helps clients manage upwards of a billion dollars in revenue. Our partnership with ServiceTitan will enable us to accelerate investment in our technology and people while maintaining our flexible startup culture. What you'll do: Own and drive complex technical solutions to enable our business functions, from revenue operations to FP&A, maximize the value of their data Take business requirements from different business functions (Sales, Marketing, Finance, ect.) and relate those to technical requirements Use best of breed modern data warehouse tools across traditional data warehouses and modern big data solutions. Specifically moving from AWS to Azure and from WhereScape to DBT. Key tools and platforms including but not limited to Snowflake, AWS, Azure, WhereScape, DBT, and other Cloud ETL tools such as FiveTran and Census). Participate in integrated projects that include BI solutions such as Tableau and PowerBI, specifically migrating current dashboards from PowerBI to Tableau for reporting Ingesting data from multiple snowflake instances to populate reporting views in Tableau Continuously learn about data analytics business and technology trends, and effectively communicate/share information with colleagues Mentor technical employees and contribute to their individual development, and lead performance management processes for technical delivery teams What you'll need: 3-5 years of recent, progressive experience and demonstrable technical expertise in enterprise-class data analytics solutions and services. Including advanced skills in areas such as Data Modeling, Integration, Storage, Indexing, Security, Logging, Data Quality, Master Data Management and Archiving Minimum 2 years architect and hands-on experience with modern data analytics solutions (Snowflake, AzureDW, DBT, Tableau) Experience with Architecture and applications on or incorporating cloud infrastructure-, platform-, and/or software- as a service (particularly data analytic solutions on Amazon AWS, Microsoft Azure, or other cloud platforms and service providers) Experience in core business systems (e.g. customer, call center, billing, etc.) transformation programs, with a focus on related changes in data analytics architecture, engineering, and business capabilities B.S. in Computer Science or equivalent degree or 5-7 years of professional work experience is required Strong database skills Strong Data Modeling skills (dimensional modeling, DBT) BI Tool experience (Tableau, PowerBI) WhereScape RED and 3D experience DBT experience Snowflake experience (Preferred) Be Human With Us: Being human isn’t about checking every box on a list. It’s about the experiences we have, people we meet, and the perspectives we share. So, if you have the skills but are hesitant to apply because of your background, apply anyway. We need amazing people like you to help us challenge the conventional and think differently about the problems that we’re solving. We’re in this together. Come be human, with us. What We Offer: When you join our team, you’re not just accepting a job. You’re making a career move. Here’s how we’ll support you in doing some of the most impactful work of your career: Flextime, recognition, and support for autonomous work: Flexible time off with ample learning and development opportunities to continue growing your career. We offer a comprehensive onboarding program, leadership training for Titans at all levels, and other programs and events. Great work is rewarded through Bonusly, peer-nominated awards, and Founders Club- open to all Titans. Holistic health and wellness benefits: Company-paid medical, dental, and vision (with 100% employer paid options and 90% coverage for dependents), FSA and HSA, 401k match, and telehealth options including memberships to Headspace, Galileo, One Medical, Ginger and more. Support for Titans at all stages of life: Parental leave and support, up to $20k in adoption reimbursement, on demand maternity support through Maven Maternity, free breast milk shipping through Maven Milk, pet insurance, legal advisory services, financial planning tools, and more. At ServiceTitan, we celebrate individuality and uniqueness. We believe that the convergence of fresh perspectives and experiences from all walks of life is what makes our product and culture so great. We strongly encourage people from underrepresented groups to apply. We do not discriminate against employees based on race, color, religion, sex, national origin, gender identity or expression, age, disability, pregnancy (including childbirth, breastfeeding, or related medical condition), genetic information, protected military or veteran status, sexual orientation, or any other characteristic protected by applicable federal, state or local laws."
Data Engineer,Benefitfocus,+9 locationsRemote,https://www.indeed.com/rc/clk?jk=085a9ea5a581c20a&fccid=ff72a9574709dc94&vjs=3,"About Benefitfocus: Benefitfocus, Inc. (NASDAQ: BNFT) is a leading provider of cloud-based benefits software solutions for consumers, employers, insurance carriers and brokers. Benefitfocus has served numerous consumers on its platform that consists of an integrated portfolio of products and services enabling clients to more efficiently shop, enroll, manage and exchange benefits information. With a user-friendly interface and consumer-centric design, the Benefitfocus Platform provides one place for consumers to access all their benefits. Benefitfocus solutions support the administration of all types of benefits including core medical, dental and other voluntary benefits plans as well as wellness programs. Job Description: Benefitfocus is searching for a Data Engineer to join our team. As a Data Engineer, you will work with senior engineers, architects, and senior data analysts on technical data model designs. In addition, you will also develop software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes. Other Responsibilities: Leads and implements features independently and completes all assigned tasks correctly and efficiently. Determines operational feasibility by evaluating problem definition, requirements, and proposed solutions. Ensures goals of team are being met by reporting any issues that hinder productivity or stability of product. Provides direction to other team members by being available to answer questions and perform code reviews. Shows direction in improving Benefitfocus coding standards and product lines by suggesting new ideas and methods to incorporate into our existing procedures. Other duties as assigned Experience and Skills: BA/BS degree or equivalent work experience in data engineering. 3-5 Years of software production and/or delivery experience Comprehensive knowledge of technical competencies including Power BI development, Python, SQL, T-SQL, and Git. Proven track record with planning and delivering coding assignments with high quality. Motivated, self-starter results-oriented team player willing to do “whatever it takes” in a dynamic and stimulating environment. Experience working in Agile SDLC Must be an analytical thinker with a passion for figuring things out; creative problem solving is key Must operate well in an environment with unknowns Must have the ability to handle multiple tasks simultaneously Salesforce, JIRA, Microsoft PowerApps, JetBrains suite, and AWS Cloud experience a plus myMap Data Analyst III"
SQL server Data Engineer,"Orpine, Inc. Internal",United States,https://www.indeed.com/rc/clk?jk=a83fbb791fa34c45&fccid=7df81f4c05f8d55a&vjs=3,SQL server SQL SSIS Python Azure APIs
Data & Integration Engineer,NewRez,"Coppell, TX",https://www.indeed.com/rc/clk?jk=12d061ad74d78ef7&fccid=e370c6bca0b50de6&vjs=3,"Exceed the expectations of our residential mortgage borrowers & business partners through superior service, simple processes, and effective communications. We deliver on this mission by empowering our employees by encouraging and recognizing superior performance and innovative solutions, by promoting teamwork and divisional cooperation. Job Description Summary In this transformational role you will be responsible for implementing modern architecture and engineering design patterns in a range of technologies, considering both technical and economic perspectives. Job Description We are on a mission to evolve how we use data at NewRez to grow our business and fulfill the needs of our customers. We drive creation of delightful, frictionless and compliant payment experiences while maximizing the value of our data. Join the Enterprise Data team at NewRez, where we are modernizing our data and integration platform to be best in class. In this transformational role you will be responsible for implementing modern architecture and engineering design patterns in a range of technologies, considering both technical and economic perspectives. You will partner with technical and business stakeholders to implement solutions balancing current and legacy technical standards, while keeping an eye towards scalability and resilience. You will have the opportunity to grow with the federated DevOps team across core app development and infrastructure. We are looking for someone who can design, code and execute in both cloud and on prem environments – while evangelizing the opportunities of good engineering design, modern integration architectures and data as a service. This is a very exciting in the firm’s evolution and we need passionate, collaborative, and energetic team members to help us take things to the next level! Responsibilities: Serve as a key contributor to identify, evaluate and execute the development and implementation of data infrastructure: Deliver collaborative work products that align with divisional and enterprise strategy Define and produce data integrations, models, and API interfaces to promote clean separation of responsibility in data flows. Develop highly complex SQL queries to extract data for analysis and model construction Consult with business and technical staff to understand business need and provide thought leadership on solutions during requirements gathering sessions Support critical strategic initiatives and architect simple to moderately complex data engineering projects Contribute to delivery of multiple large, complex data engineering projects simultaneously Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists Document and test data processes including performance of through data validation and verification Performance optimization for queries and dashboards Develop and deliver clear, compelling briefings to internal and external stakeholders on findings, recommendations, and solutions Analyze client data & systems to determine whether requirements can be met Test and validate data pipelines, transformations, datasets, reports, and dashboards built by team Develop and communicate solutions architectures and present solutions to both business and technical stakeholders Provide end user support to other data engineers and analysts Core Developer Stack: Languages: SQL (standard and DB-specific), Python, R, Spark/Scala, Bash Frameworks: AWS (EC2, Lambda, S3, Glue, Kinesis, Sagemaker, etc.) Tools/Products: Database Replication, ETL/ELT, Tableau, PowerBI Requirements Expertise in SQL and Python. Other programming languages (R, Scala/Spark, SAS, Java, etc.) are a plus Experience with data and analytics technologies, including RDBMS, ETL, and BI Experience with Hadoop or other big data technologies Experience with AWS or other cloud technologies Experience with agile delivery methodologies and/or JIRA Experience working on Linux command-line BS or higher in related field/ Master’s degree in related field 1-3 years of experience Preferences Cloud-based solution design and engineering, AWS data and analytics deployments. Also nice to have familiarity with comparable services for Microsoft Azure and Google Cloud. Python experience, PySpark expertise API-first architectures Real time streaming data delivery Configuration DevOps experience API Integration technologies, including MuleSoft, Apigee, etc. Company Perks: 15 Paid Time Off (PTO) days and 18 after 1st anniversary! 9 Paid Holidays Casual Workplace Employee Engagement Activities Company Benefits: Medical (including Health Savings Account & Flexible Savings Account) Dental - RX – Vision – Life, Disability Insurance – 401(k) Plan with company match! – Employee Assistance Plan Performance-based Incentives Pet Insurance Advancement Opportunities Newrez NOW: Our Corporate Social Responsibility program, Newrez NOW, empowers employees to become leaders in their communities through a robust program that includes volunteering, philanthropy, nonprofit grants, and more 1 Volunteer Time Off (VTO) day, company-paid volunteer day where all eligible employees may participate in a volunteer event with a nonprofit of their choice Employee Matching Gifts Program: We will match monetary employee donations to eligible non-profit organizations, dollar-for-dollar, up to $1,000 per employee Newrez Grants Program: Newrez hosts a giving portal where we provide employees an abundance of resources to search for an opportunity to donate their time or monetary contributions Equal Employment Opportunity We're proud to be an equal opportunity employer- and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better. CA Privacy Policy CA Notice at Collection"
Clinical Data Pipeline Engineer,Orion,"Remote in Los Angeles, CA",https://www.indeed.com/rc/clk?jk=3bd46b24e66830af&fccid=25695de265ca35f4&vjs=3,"Job description Clinical Data Pipeline Engineer Fully Remote - Open to candidates located anywhere within the US! (Choice of US time zones: Eastern, Central, Mountain, Pacific) Shift hours are typically 8 AM-5 PM 6+ month initial contract Hourly Rate: $73-77/hr Orion Group is seeking an experienced Clinical Data Pipeline Engineer to join our premiere Medical Device Manufacturing client's team as a fully remote worker. Our prestigious client is creating a data analytics and science team to generate novel insights and real world evidence (RWE) from real world data (RWD) that contain lab results generated by instruments linked to patient medical records. In this role, you will be responsible for driving technical execution and helping the team create a best-in-class data & analytics organization. You will work with various stakeholders both inside and outside the organization to execute on research initiatives. Job Responsibilities Collaborate with stakeholders to understand data requirements for ML, Data Science and Analytics projects. Assemble large, complex data sets from disparate sources, writing code, scripts, and queries, as appropriate to efficiently extract, QC, clean, harmonize and visualize Big Data sets. Write pipelines for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python, SQL, Spark, AWS, and Azure 'big data' technologies. Identify, design, and implement continuous process improvements such as automating manual processes and optimizing data delivery. Document data processes, write data management recommended procedures, and create training materials relating to data management best practices. Job Requirements Previous experience performing data engineering tasks on RWD/RWE projects involving Electronic Medical Records (EMR) data Experience with defining clinical protocols to collect RWD Fluency in Python with strong knowledge of standard data science toolkits Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Familiarity with healthcare data standards, data ontologies, toolchains, and operating procedures An associate who is independent, self-motivated, and eager to excel in a goal-oriented and multi-faceted work environment. Someone who embraces uncertainty and thrives by driving to clarity in a fast-paced ambiguous environment Excellent written and verbal communication skills and the ability to clearly articulate project goals, timelines, and key milestones, and accomplishments to stakeholders. TOP 3 QUALIFICATIONS: 1. Experience with processing (quality control, normalization, harmonization) EMR/EHR data into analysis ready datasets 2. Experience to automate the data processing by building data processing pipelines (preferably via Python) 3. Understanding of common clinical data standards and ontologies (eg SNOMED, OMOP, CDISC, LOINC) Our role in supporting diversity and inclusion As an international workforce business, we are committed to sourcing personnel that reflects the diversity and values of our client base but also that of Orion Group. We welcome the wide range of experiences and viewpoints that potential workers bring to our business and our clients, including those based on nationality, gender, culture, educational and professional backgrounds, race, ethnicity, sexual orientation, gender identity and expression, disability, and age differences, job classification and religion. In our inclusive workplace, regardless of your employment status as staff or contract, everyone is assured the right of equitable, fair and respectful treatment."
Associate Data Engineer,Truist Financial,"Charlotte, NC 28269+4 locations",https://www.indeed.com/rc/clk?jk=9f38547813a115d8&fccid=035229327af06091&vjs=3,"The position is described below. If you want to apply, click the Apply button at the top or bottom of this page. You'll be required to create an account or sign in to an existing one. Need Help? If you have a disability and need assistance with the application, you can request a reasonable accommodation. Send an email to Accessibility or call 877-891-2510 (accommodation requests only; other inquiries won't receive a response). Regular or Temporary: Regular Language Fluency: English (Required) Work Shift: 1st shift (United States of America) Please review the following job description: Assists in building, optimizing and maintaining the data pipelines and aiding in building the data ecosystem for delivering enterprise data for wide consumption including developing data models, corresponding data architecture documents and API's. ESSENTIAL DUTIES AND RESPONSIBILITIES Following is a summary of the essential functions for this job. Other duties may be performed, both major and minor, which are not mentioned below. Specific activities may change from time to time. 1. Participates in the building, management, and implementation the data and/or Big Data pipeline capabilities including data modeling, process design and overall data pipeline architecture and all phases of the ETL (extract, transform, and load) processes. 2. Assists in efforts related to partially to completely automate repeatable data preparation and integration tasks. Partner with technology teams to understand data capture, testing needs, and to build and test end-to-end solutions. 3. Participates in the analysis of information to determine business needs from requests and implement effective technical solutions by providing problem analysis and resolution in a timely manner and explain and interpret complex, difficult, or sensitive information. 4. Takes a new perspective on existing solutions to solve problems of low to moderate complexity and exercise judgment based on the analysis (e.g. modeling, testing, etc.) of multiple sources of information with some guidance from more experienced data engineers. QUALIFICATIONS Required Qualifications: The requirements listed below are representative of the knowledge, skill and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. 1. Bachelor's degree and two years of experience in systems engineering or administration or equivalent education and related training or experience 2. Basic knowledge of SQL, relational databases, ETL/ELT architecture and concepts, data integration concepts and big data concepts 3. Previous experience in planning and managing IT projects Preferred Qualifications: 1. Bachelor's degree and three years of experience or equivalent education and related training or experience 2. Banking or financial services experience OTHER JOB REQUIREMENTS / WORKING CONDITIONS Sitting Constantly (More than 50% of the time) Visual / Audio / Speaking Able to access and interpret client information received from the computer and able to hear and speak with individuals in person and on the phone. Manual Dexterity / Keyboarding Able to work standard office equipment, including PC keyboard and mouse, copy/fax machines, and printers. Availability Able to work all hours scheduled, including overtime as directed by manager/supervisor and required by business need. Travel Minimal and up to 10% Truist supports a diverse workforce and is an Equal Opportunity Employer who does not discriminate against individuals on the basis of race, gender, color, religion, national origin, age, sexual orientation, gender identity, disability, veteran status or other classification protected by law. Drug Free Workplace. EEO is the Law Pay Transparency Nondiscrimination Provision E-Verify"
Senior Software Engineer: Data Team,Codecademy,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=ee9a8abb2e1b3b9c&fccid=b9d4e9eceb3ff4c0&vjs=3,"We are NYC based, but remote friendly unless specified. (US & Canada based candidates only) Hello, World! Codecademy is on a mission to build inspiring careers in technology through engaging, accessible, and interactive online coding education. Our learners have gone on to start new jobs, launch new companies, and lead new lives thanks to their work with Codecademy, and our platform has transformed the way businesses develop and retain their teams. Since 2011, our team has grown to over 200 employees serving 50+ million learners from 190+ countries. We've raised over $82M in venture capital funding from top investors including Prosus, Owl Ventures, Union Square Ventures, Y Combinator, and more-which gives us the capital to get stuff done in an impactful way. Join us to help build a business that empowers tens of millions of people to lead better lives! We are NYC based but remote friendly! A company's ability to track events is the key to improving and optimizing its business model. An event provides information about how users interact with the company website and its product. Determining what events to track is foundational in this context, as there are hundreds or thousands of possibilities. As a result, Codecademy is looking for a Senior Software Engineer to join our data team and partner with Product, Engineering, Marketing and Design to devise a strategy to track events in our platform. Our application continues to collect and process thousands of data points each day, we use this data to provide more intelligent recommendations and learning solutions for our millions of learners. We believe that everyone's learning journey is unique and we can leverage data to personalize learning for each user. Our data team works on three key areas: building a data platform, building and supporting ML models, and building and supporting analytics (internal and external). In this role you work with engineering and design teams to implement event tracking across our products so we can better understand all of our different learners. WHAT YOU'LL DO Assess our current client-side, server side events, corresponding metadata, and tracking specs. Partner closely with the Product, Engineering, Marketing and Design teams and other key stakeholders to formulate questions for analysis. Translate questions into related events and processes. Determine what events to track. Build and maintain the event tracking system for both internal and external use cases. Design, define, implement, optimize and maintain new and existing events and their properties, entities, naming conventions and data tracking plans. Collaborate with a cross-functional team of product managers, software/data/analytics engineers and data scientists. WHAT YOU'LL NEED Ability to think critically about Codecademy's business model and how it can be improved. The ability to break down real-world situations into stages that can be described by event data. Fluency in these languages: JavaScript/TypeScript, Ruby. A plus if you are familiar with Ruby on Rails, React, and NextJS (or similar frameworks). Familiarity with the database technologies we use in production: MongoDB, Redis, PostgreSQL. Ability to make pragmatic engineering decisions, write extensive tests and create documentation. Strong project management skills; a proven ability to gather and translate requirements from stakeholders across functions and teams into tangible results. WHAT WILL MAKE YOU STAND OUT Experience working with Customer Data Platform (we use Segment) and Object-action framework. Experience with tools in our current warehousing stack: Apache Airflow, Snowflake, Segment, Apache Kafka/Confluent, dbt, Looker. Experience with Segment ecosystem - Protocols, Personas, Journeys, Functions. Experience in protecting users' privacy and familiarity with GDPR & CCPA. Comfort with containerization technologies: Docker, Kubernetes, etc. At Codecademy, we are committed to teaching people the skills they need to upgrade their careers. Codecademy aims to educate a richly diverse demographic of users with our product and in order to accomplish this, we believe our team should reflect that rich diversity. Our company celebrates diversity in all of its forms- race, gender, color, national origin, marital status, sexuality, religion, veteran status, age, ability, disability status- and works to create an inclusive workplace where people of all backgrounds and beliefs are empowered to better their futures. #LI-Remote Equal Employment Opportunity At Codecademy, we are committed to teaching people the skills they need to upgrade their careers. Codecademy aims to educate a richly diverse demographic of learners with our product and in order to accomplish this, we believe our team should reflect that rich diversity. Our company celebrates diversity in all of its forms- race, gender, color, national origin, marital status, sexuality, religion, veteran status, age, ability, disability status- and works to create an inclusive workplace where people of all backgrounds and beliefs are empowered to better their futures. #LI-Remote"
Systems and Data Engineer,Micron,"San Jose, CA",https://www.indeed.com/rc/clk?jk=f9726a778fe11d5e&fccid=be240c643a8631c5&vjs=3,"Our vision is to transform how the world uses information to enrich life for all. Join an inclusive team passionate about one thing: using their expertise in the relentless pursuit of innovation for customers and partners. The solutions we build help make everything from virtual reality experiences to breakthroughs in neural networks possible. We do it all while committing to integrity, sustainability, and giving back to our communities. Because doing so can fuel the very innovation we are pursuing. JR19758 Systems and Data Engineer As a Process Engineer you will be primarily responsible for starting up, developing and optimizing processes to improve product quality and reliability, working on process yield improvement, cost reduction, productivity improvement and risk management as well as resolving manufacturing line problems. You will also be required to identify, diagnose and resolve assembly process related problems by applying failure analysis, FMEA, 8D or SPC/FDC methodology. Additional responsibilities include coordinating and carrying out process, equipment and material evaluation/optimization to implement changes at process step, leading and participating in yield improvement and cost reduction activities, handling new process baseline qualifications and managing, auditing and liaising with material suppliers to achieve quality, cost and risk management objectives. Responsibilities include, but not limited to: Work closely with Engineering, Manufacturing, IT, RMS, TSE, TAG, EDT, ToolView on systems setup and deployment that are critical for plant startup. Respond quickly to systems related issues, analyze, and resolve system failure mechanism through effective problem solving. Strong desire to grow career as data analyst /data scientist in highly automated industrial manufacturing doing analysis and machine learning on diverse datasets. Ability to extract data from different databases via SQL and other query languages, and apply data cleansing, outlier identification, and missing data techniques. Knowledge in statistical modeling, feature extraction, and analysis, machine learning, and deep learning. Strong coding skills on languages such as but not limited to Python and/or R, Perl, VB, C, JavaScript, Angular, Tableau. Experience in cloud computing and Hadoop is a plus. Strong desire to learn systems and data analytics / data science. Good verbal and written communication skills. About Micron Technology, Inc. We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life for all . With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron® and Crucial® brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience. Please note that in order to assist in providing a safe and healthy workplace for all Micron team members, new employment offers for jobs based in India, Malaysia, Singapore, and the U.S., are contingent upon the applicant’s provision of a copy of their COVID-19 vaccination document to Micron on a confidential basis prior to their scheduled start date confirming that they have completed the COVID-19 vaccination process, subject to any written request for medical or religious accommodation and to the extent permitted by applicable law. To learn more, please visit micron.com/careers All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. To request assistance with the application process and/or for reasonable accommodations, please contact hrsupport_my@micron.com Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards. Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron."
Data Engineer,LawVu,Remote,https://www.indeed.com/rc/clk?jk=93b057909c4a9686&fccid=66b3d60fa6168010&vjs=3,"LawVu is transforming the legal industry by providing the world’s leading and most loved platform for in-house legal teams. Our aim is to make the lives of in-house legal teams and their business partners more productive and fulfilling. We are well on the way with some of the world’s leading global brands and best in-house legal teams already operating on LawVu. Growing super fast, LawVu is headquartered in Tauranga, New Zealand with teams in Australia, USA, Ireland, Philippines, UK and the EU. Our culture is strongly values aligned where we look for people to bring their whole selves and join a team doing the best work of their lives. We have offices in Tauranga and Wellington however, this role can be done remote from anywhere in New Zealand. What you’ll do.. As a Data Engineer at LawVu, you will be a key member of our expanding team, working to enable and build on our core data and analytics capability. You will be a technical data specialist applying software engineering best practices to the production and maintenance of our cloud based modern data platform. This is a position requiring an innovative problem solving approach to designing and building creative data solutions that provide valuable insights, drive performance and lead to the delivery of our strategic objectives. Your work will include the development and enhancement of our data platform with the aim of inspiring positive change for both our internal and external customers. Internally you will be part of a team that works directly with key stakeholders from our product, customer success, and sales teams to ensure the delivery of a first class data and analytics platform. Key Responsibilities Design and development of a cloud based modern data platform with metadata driven approaches Utilisation of extraction, loading and transformation (ELT) best practices and principles Creation and maintenance of testing and documentation artifacts Development and maintenance of automated system monitoring for critical components of the data platform to ensure we maintain our high SLA’s Bring in new tools/technologies as necessary to make our systems more efficient and cost effective Skills and Experience 5+ years experience in data architecture and engineering roles Strong SQL skills and experience Experience with Azure and Python would be an advantage Outstanding organisational skills and the ability to multitask Outstanding listening, negotiation and presentation skills Excellent verbal and written communications skills What sets us apart: Monthly wellness allowance to use on whatever enables you to bring your whole self to work – gym membership, massage, childcare.. the list goes on! Health insurance cover Extended paid parental leave Extra paid day off on your birthday Share options so you can have a piece of the pie Home office allowance set up for remote employees"
Cloud Data Engineer,Formlabs,"Somerville, MA",https://www.indeed.com/rc/clk?jk=8fb380c13e31a9f9&fccid=8e0192a48bd27a99&vjs=3,"To reinvent an industry, you have to build the best team. Join Formlabs if you want to bring ground-breaking professional 3D printers to the desktop of every designer, engineer, researcher, and artist in the world. As one of our first dedicated cloud data engineers to help build our data team you will be architecting cloud infrastructure for data-intensive applications involving large scale 3D printing operations with tens of thousands of 3D printers. You will get to work closely with our Software and Data Analytics teams to develop, deploy and maintain large scale real-time data pipelines, infrastructure and tooling that make data accessible to our teams, tools and products. If you're excited to design data pipelines to help Formlabs make better printers, we want you to join the Software Engineering Team as a Cloud Data Engineer. The Job: Build and maintain scaleable, reliable data infrastructure and tooling to support our engineers, products and customers Architect and develop large scale data processing pipelines and ETL tools Protect data for us and our customers We value diversity at Formlabs, and work to remove unconscious and unnecessary barriers to build the best team possible. While we've outlined what an ideal candidate could look like, we know that you may bring something unanticipated and essential to the team. If you're reading this and can see yourself contributing, please apply! You: Ready to collaborate with a wide range of technical disciplines, including Software, Hardware, and Design teams Has developed and deployed large scale real-time data pipelines and ETL tooling in production for a variety of applications Expert in performant, scalable data warehousing, data modeling and database design Experience with observability / APM for tens of thousands of hosts Comfortable with web service providers like AWS or GCE Familiar with CI/CD pipelines, infrastructure as code and container orchestration Familiar with microservice architecture and REST API design Fluent in Python and/or golang Bonus Points: Experience doing data analysis Experience working with hardware sensor data Experience with predictive models Our Perks: Flexible vacation Premium healthcare coverage Paid parental leave Commuter benefits Unlimited 3D prints We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Data Engineer,McGraw Hill,Remote in Washington State,https://www.indeed.com/rc/clk?jk=4bd79e5f09f112c9&fccid=58fef0e5bbfde084&vjs=3,"Impact the moment Would you like to work in a collaborative environment where products are developed through pair programming, mentoring and knowledge transfer sessions? Our engineering teams are working in an ecosystem where you can grow your career in a way that fits into your life while developing new skills every day. We are looking for a Data Engineer who knows how to fully exploit the potential of our Spark cluster. You will clean, transform, and analyze vast amounts of raw data from various systems using Spark to provide ready-to-use data to our feature developers and business analysts. This involves both ad-hoc requests as well as data pipelines that are embedded in our production environment. What can you expect from the position? Creating Python/Spark jobs for data transformation and aggregation Producing unit tests for Spark transformations and helper methods Writing pydoc-style documentation with all code Designing data processing pipelines What you’ll need to be successful: Proficiency with Apache Spark 2.x, and deep understanding of distributed systems (e.g. partitioning, replication, etc) Experience using MySQL DB platform, programming SparkSQL, PySpark Hands-on SQL, Spark query tuning, and performance optimization Preferred to have experience in Python, writing Apache Airflow DAGs, AWS services, data warehouse technologies, Docker, and Kubernetes Familiarity with Agile development methodologies PHP, Java & Scala desirable but not required As an education innovation company, we're proud to play our part by inspiring learners around the world. If you bring your curiosity, we'll help you grow in a collaborative environment where everyone shares a passion for success. Are you ready for a new challenge? Apply for a career at McGraw Hill and together, we'll impact the world."
AWS Data Engineer,Tekserv,+1 locationRemote,https://www.indeed.com/rc/clk?jk=9f535f059b0c624a&fccid=e30c23ebf8b00210&vjs=3,"Location: Remote (EST Work hours) Duration: 6-12 Months Interview: MS Team Video Interview Industry: Media Rate: Please advice AWS Data Engineer – 2 Opportunities (4 Positions) Opportunity 1: AWS Data Engineer with a heavy focus /experience with Data Science and Data Engineering. – 2 Positions Opportunity 2: AWS Data Engineer needs to be strong in writing and reading APIs. – 2 Positions Who You Are: A highly motivated back-end developer that can produce and maintain applications that drive media efficiencies for our clients A person who can collaborate on small team of developers tasked to develop products that set our agency apart through innovation. You have a solid foundation of technical skills including product design, coding, debugging, and implementation of web applications. A supporter of and advocate for diversity, equity, and inclusion. Required Skills & Experience 2+ years of development experience. Experience in Python, SQL, and JavaScript. Strong experience with data engineering and data science background. AWS experience Ability to work on and drive innovation of multiple products. Ability to articulate clearly and effectively in person and in writing. Excellent organizational skills and the ability to juggle multiple responsibilities. Bachelor’s degree. Preferred Skills & Experience Exposure to the following Python libraries: pandas, NumPy and openpyxl. Experience to data science and data engineering. Handling of APIs, databases, web scraping, data processing, and cloud platforms. Knowledge of Django framework. Familiarly with Windows OS and Linux OS. Experience with Jira, Confluence, Google Suite (Sheets, Docs, Slides)"
Data Engineer,Dremio,"Remote in Santa Clara, CA",https://www.indeed.com/rc/clk?jk=e66bda1888a0921c&fccid=93b8410ffb6f1701&vjs=3,"Be Part of Building the Future Dremio is the SQL Lakehouse company, enabling companies to leverage open data architectures. Dremio's SQL Lakehouse Platform simplifies data engineering and eliminates the need to copy and move data to proprietary data warehouses or create cubes, aggregation tables and BI extracts, providing flexibility and control for data architects and data engineers, and self-service for data consumers. Founded in 2015, Dremio is headquartered in Santa Clara, CA. Investors include Cisco Investments, Insight Partners, Lightspeed Venture Partners, Norwest Venture Partners, Redpoint Ventures, and Sapphire Ventures. For more information, visit www.dremio.com. Connect with Dremio on GitHub, LinkedIn, Twitter, and Facebook. If you, like us, say ""bring it on"" to exciting challenges that really do change the world, we have endless opportunities where you can make your mark. About the role Dremio's development leaders ensure that Dremio Cloud & our Data Lake value-add for the industry is enhanced with scalable, resilient solutions with uptime & performance that matches SLAs. Dremio is growing quickly and building cloud infrastructure, SaaS & services that enable developer velocity will have an immediate and visible impact on Dremio's success. You will be enabling data-driven decision making and customer engagement by creating a self-service semantic layer for the product and sales teams to leverage. What you'll be doing Creating and maintaining a data lake of customer and product usage metrics, which will be used to derive insights to drive product and growth strategies. Design and implement workflows for ingestion and transformation for various data sources (S3, GCS, Google Analytics). Optimize the retrieval of structured and unstructured data to make it actionable in real time. Help develop a strategy for a long term data architecture, which will allow Dremio to make effective data-driven decisions to optimize the customer's experience. Develop and maintain scalable and reliable data pipelines to support gradual increases in data volume and complexity. Collaborate with the Product Management and Engineering teams to incorporate new use cases and sources of data What we're looking for 5+ years of experience as a data engineer in a SaaS environment Strong logical and analytical skills Deep understanding of data lakes and relational databases Knowledge of data formats such as JSON and Parquet Experience with Apache Spark, Python libraries such as Pandas for data manipulation Experience with AWS and GCP Experience with ETL/ELT tools Experience working with data projects and ensuring the highest levels of data integrity and quality. You can scope, schedule, and resource complex projects in collaboration with other partners such as Product and Engineering. Experience working with CI/CD pipelines, DevOps and delivering quality in a fast paced environment. Familiarity with BI and data science tools such as Tableau, Superset, Jupyter. Excellent communication skills with both technical and non-technical audiences. Bonus points if you have Experience with Apache Iceberg What we offer Medical, dental and vision insurance 401(k) Plan Short term / long term disability and life insurance Pre-IPO stock options Flexible PTO 16 hours of volunteer time off 12 company paid holidays, including Juneteenth Remote work options Monthly ""Get Stuff Done"" (GSD) Days Paid parental leave Employee Assistance Program (EAP) Company-sponsored wellness programs including Aaptiv, Headspace, Physera and Ginger Quarterly swag surprise **Certain benefits are only allowed to full-time Dremio employees and may not be the same across all locations. #LI-KL1 #LI-Remote What we value At Dremio, we hold ourselves to high standards when it comes to People, Thinking, and Action. Our Gnarlies (that's what we call our employees) communicate with clarity, drive accountability, and are respectful towards each other. We confront brutal facts and focus on results while operating with a sense of urgency and building a ""flywheel"". People who like to jump in and drive momentum will thrive in our #GnarlyLife. Dremio is an equal opportunity employer supporting workforce diversity. We do not discriminate on the basis of race, religion, color, national origin, gender identity, sexual orientation, age, marital status, protected veteran status, disability status, or any other unlawful factor. Dremio is committed to providing any necessary accommodations for individuals with disabilities within our application and interview process. To request accommodation due to a disability, please inform your recruiter. Dremio has policies in place to protect the personal information that employees and applicants disclose to us. Please click here to review the privacy notice."
"Customer Engineer, Data / Microsoft SQL",Ascent Solutions,Remote,https://www.indeed.com/company/Ascent-Solutions/jobs/Customer-Engineer-9da7c6d61b0d27d7?fccid=bc3c1f4ac5cc8ebe&vjs=3,"Join Ascent Solutions Combine one of the fastest growing industries on the planet with collaboration, intellectual diversity, and a culture of excellence—this is what you get. Soaring cyber risk is here to stay, but so are our consultants. We are builders and technologists with a passion for cybersecurity. Join us on our mission to help the nation’s top companies secure, unify, and manage their enterprise architecture. Ascent is built to help companies evolve their cybersecurity posture, modernize their Microsoft solutions, and secure their journey to the cloud. Our best-in-class consultants understand the demands of today’s modern workplace as well as the technology hurdles it can create. We provide organizations with the expertise needed to move quickly beyond technical constraints and focus on achieving business results. Ascent consultants are eager to engage with clients and implement secure solutions that drive business value. Intellectual diversity and collaboration drive our innovation process. We believe in evoking a customer’s root pain point. Our consultants provide intuitive solutions to help achieve company goals. Mission Work with a premier technology provider to solve complex SQL problems. Provide deep technical expertise to high-profile customers. Coordinate conversations across multiple stakeholders and lead decision making. Support project delivery teams either remotely or through on premises oversight during project planning, deployment, and administration. Align the project team’s trajectory with customer business value. Responsibilities Apply technology knowledge to improve Microsoft products and the customer experience Represent customer needs by drafting and presenting tailored technology solutions, strategy, and delivery results to large and small audiences Analyze and interact with customer-specific needs and high-level data and technology trends Lead customer strategy by advocating for transition to or improvement of cloud services Partner with the customer’s virtual account team, providing technical expertise and forging relationships Modify and deliver existing intellectual property (IP) or create new content to suit the situation Cultivate relationships, credibility, and loyalty with customers and partners by sharing relevant business expertise Qualifications We require: 10+ years of experience working with customers in any of the following: providing technical readiness and training delivery of support services on-premises and remote technical support solution development account management technical requirements gathering 7+ years of consulting experience 7+ years working with SQL technologies, and at least 3 years of hands-on technical experience developing and supporting any of the other Data & AI technologies following: Azure Analysis Services, SQL Server Analysis Services Azure Data Factory, SQL Server Integration Services All versions of SQL Server (On-premises and IaaS) SQL migration / modernization experience Azure SQL Database (Standalone, Elastic Pool, Serverless, Managed Instance, Hyperscale) Azure Synapse Analytics SQL Server Reporting Services, Power BI Report Server, Power BI Service T-SQL, DAX, Power Query, MDX NoSQL: Azure Cosmos DB, MongoDB, Cassandra Azure MySQL/PostgreSQL Azure Blob Storage, Azure Data Lake Store Machine Learning, Artificial intelligence (AI), deep learning, Big Data Advanced data analytics: designing and building solutions using technologies such as Azure Data Factory, Azure Data Lake, Data Bricks, HD Insights, Azure Synapse Analytics, Azure Stream Analytics, Azure Machine Learning Service, Azure Cognitive Services We hire consultants who: Channel their curiosity to learn, grow, and solve problems Receive and implement technical or interpersonal feedback from team members or managers Notice and affirm team and co-workers’ successes Invest extra time and effort into customer satisfaction and projects Organize and prioritize tasks before project or client deadlines Show self-motivation to learn new technology or consulting strategies Ascent Benefits Ascent provides a 401(k) plan, health insurance, accident insurance, disability insurance, paid parental leave, and unlimited paid time off. We practice stewardship of the roles and resources entrusted to us. Our hiring process sources consultants with wholistic skillsets: technical depth, EQ- and IQ-informed communication, and a passion for spreading cybersecurity. Job Type: Full-time Pay: $135,000.00 - $150,000.00 per year Benefits: 401(k) 401(k) matching Dental insurance Employee assistance program Flexible spending account Health insurance Health savings account Life insurance Paid time off Parental leave Professional development assistance Referral program Retirement plan Vision insurance Schedule: 8 hour shift Monday to Friday Experience: Microsoft SQL: 5 years (Required) Azure: 1 year (Preferred) Consulting: 5 years (Preferred) Work Location: Remote"
Data Engineer,LendingTree,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=1b11592f4f22c2fc&fccid=e9e15932789966e0&vjs=3,"Position: QuoteWizard by LendingTree is seeking a Data Engineer to join our Data Engineering team. We have an exciting opportunity to deliver a near real-time data lake and low-latency data warehouse using world class cloud data tools and platforms including Snowflake, DBT, and FiveTran. Data Engineering provides a solid data foundation for analytics and machine learning teams that drive business decisions and strategy that power customer journeys across multiple CRM platforms. This individual will partner with architecture, technology operations, software engineering, analytic teams, and other senior leaders to develop and implement solutions to meet critical data/analytic related business needs and capabilities, while implementing technologies, platforms, and tools aligned to the LendingTree’s data strategy. We are seeking a data engineer who will be passionate about data engineering and building steaming data pipelines and will work with partners across Marketing, Product, Data Science, Analytics, Contact Center, and Technology teams to deliver on enterprise data initiatives. RESPONSIBILITIES Create real-time streaming data solutions Implement large scale, high-performance data analytics, and data integration platforms Design and develop ETL solutions Design, develop, and support database applications spanning multiple lines of business Evaluate performance and cost of data applications/environments and perform appropriate troubleshooting as necessary Collaborate effectively across various departments and teams to implement solutions Work with business users to understand project requirements and resolve issues Craft and maintain technical documents including educational materials, standards, and best practices Participate in on-call rotation for off-hours support Design and develop frameworks and other approaches for rapid development of high-quality data and reporting solutions Collaborate on product roadmap for data engineering to define the capabilities of the platforms and services and delivery timelines Perform complex data analysis to identify trends, patterns, and opportunities QUALIFICATIONS 5+ years of experience doing data warehousing, ETL development, analytics, and writing and debugging complex SQL queries. You have experience with highly scalable, distributed platforms. Experience designing and implementing data lakes and data warehouses. You have knowledge of data warehousing industry standards and standard methodologies. You understand dimensional database modeling. You have excellent data presentation skills, utilizing dashboards and other technologies. You have excellent verbal and written communication skills. You have the ability to design and implement projects with minimal guidance. You have experience with Agile methodologies. You have a dedication to being a phenomenal teammate - sharing success and struggles equally. You have real passion for learning and implementing new tools and supporting standard methodologies. PREFERRED EXPERIENCE B.S. in Computer Science, Mathematics or equivalent Experience working with Snowflake Experience working with SQL Server Experience with data visualization tools, such as Power BI Experience working with Azure Data Factory, DBT, and FiveTran Experience with scripting languages like PowerShell Experience with programming languages such as Python, C# Experience with Git SCM COMPANY QuoteWizard, a LendingTree company, is a dynamic insurance lead generation agency based in Seattle. We have been ranked by the INC 500 as one of the fastest growing private companies in the nation. We have also been listed by the Puget Sound Business Journal as a top company in Seattle. What you should know about LendingTree, our parent company: We’re a publicly-traded company (TREE). We’ve welcomed several other companies into the LendingTree family to augment our efforts at helping borrowers make their most sensible financial choices. We’ve built the LendingTree app and My LendingTree dashboard to give consumers tools to manage and monitor their financial health. CULTURE We’re a fast-paced company with an entrepreneurial bend. We work hard and test our products often. We’re collaborative, ambitious, candid and high-energy. Our teammates are some of the brightest, most talented people you’ll ever work with. We care more about your smarts than we do about the kinds of clothes you wear (but please, do wear clothes to work!), and we’re pretty good about rewarding innovation, creativity and the knack for just getting stuff done (we even have an award for employees called the GSD, “Get Stuff Done”). Come work with us! QuoteWizard by LendingTree is the kind of company that not only promotes diversity and inclusion; we thrive because of these values. We do not discriminate based on race, color, religion (or creed), gender, gender expression, age, national origin, disability, marital status, sexual orientation or military status. Compensation: $50,000-$175,000 DOE Incentive Compensation: Eligible for annual performance bonus Benefits: Medical, dental, vision insurance and 401(k) matching"
Data Engineer (Range),Pioneer Natural Resources Company,"Irving, TX",https://www.indeed.com/rc/clk?jk=1e39dfcdce302aa4&fccid=50343264b93b9f96&vjs=3,"This data engineer position will report to the Automation & Spatial Solutions group within the Strategic Planning & Field Development (SPFD) department. Automation & Spatial Solutions is responsible for department wide spatial data, automation & integration efforts, and data engineering. Responsibilities will vary by individual projects supporting both the department and organizational goals. Areas of focus will include research and development of data pipelines, analytics, data visualization, automation, data processing, and data management, concentrating on developing sustainable products/platforms. Job Duties: Prepare technical data for interpretation, conduct analyses and routine computer processing of the data, and help create final displays of the results often for formal presentations Design, develop, test, document, deploy, monitor, and support data pipelines Work with domain experts, data scientists, engineers to understand needs, constraints, and limitations Create analytical dashboards utilizing Business Intelligence software such as Spotfire, Operations Dashboard, and/or PowerBI Develop ETL processes and maintain application integrations across multiple systems and data sources Design, develop, and institute automated workflows utilizing various technologies (Python, GIS, SQL, Spotfire, Alteryx, MS Power Platform and more) to minimize human error, standardize data, and apply data management best practices with a focus on data integrity and governance Develop and optimize existing and new expansion of the systems in place Willingness to learn, experiment, try new things, fail, and grow! Perform other duties as assigned by Supervisor, to include special projects. Qualifications: Bachelor's in Data Science, Statistics, Applied Mathematics, Computer Science, Engineering, Geoscience. Must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. Driven by the prospect of optimizing or even re-designing company’s data architecture to support the next generation of products and data initiatives Functional in SQL with experience in querying relational databases, views, and normalized schemas Functional in programming (Python-preferred) with skills in algorithms, clean code, environment management Working knowledge in NoSQL (graph-based) databases as well as working familiarity with a variety of databases (Cassandra, InfluxDB, Redis, KUDU, etc.). Understanding and utilization of enterprise ETL tools; ex: Alteryx, Azure Synapse, Azure Data Factory, MS Power Platform Experience building and optimizing ‘big data’ pipelines, architectures, and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Build processes supporting data transformation, data structures, metadata, dependency, and workload management. A successful history of manipulating, processing, and extracting value from large, disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. Experience with big data tools: Spark/PySpark, Hadoop ecosystem, parallel computing, parquet, unstructured datasets Experience with data pipeline and workflow management tools: Azkaban, Airflow, Docker, Kubernetes Ability to identify opportunities for improvement / automation and development of existing workflows and processes Salary competitive and commensurate with qualifications and experience. Our Mission: RESPECT Core Values Respect We respect one another and the communities in which we operate. Ethics and Honesty We are ethical and honest and committed to uphold our strong reputation. Safety and Environment We believe no job is so important that it cannot be done in a safe and environmentally sound manner. Personal Accountability We are disciplined and personally accountable for our decisions, actions, attitude and results. Entrepreneurship We have an entrepreneur's mindset, driving innovation and striving for excellence in all we do. Communication We openly and professionally communicate among all levels and between departments and teams. Teamwork and Inclusion We believe in diverse perspectives and teams collaborating toward common objectives with a can-do attitude. Pioneer Natural Resources is an EEO Employer."
Associate Data Engineer -Streaming,"Amazon Web Services, Inc.",+126 locationsRemote,https://www.indeed.com/rc/clk?jk=408d64830055d3c5&fccid=5cc0cdc6dbb121cc&vjs=3,"• Bachelor’s degree, or equivalent experience, in Computer Science, Engineering, Mathematics or a related field • 2+ years’ industry experience as a Data Engineer with demonstrated experience in data modeling, ETL Development, Data Warehousing, Data Lakes, and/or consoliding data from distributed systems • 1+ years’ experience building enterprise level streaming and real-time architecture • Experience with implementation, integration and administration with at least one of the following Streaming Data-Streaming frameworks or services: Apache Kafka, Kinesis Data Streams, Apache Spark Streaming, Apache Flink, Apache Storm, Apache NiFi, Azure Stream Analytics, or Confluent Job summary Are you a streaming systems specialist? Do you have real-time systems experience? Do you like to solve the most complex and high scale (billions + records) data challenges in the world today? Would you like a career that gives you opportunities to help customers and partners use cloud computing to do big new things faster and at lower cost? Do you want to be part of history and transform businesses through cloud computing adoption? Do you like to work in a variety of business environments, leading teams through high impact projects that use the newest data analytic technologies? Would you like a career path that enables you to progress with the rapid adoption of cloud computing? At Amazon Web Services (AWS), we’re hiring highly technical streaming data engineers to collaborate with our customers and partners on key engagements. Our consultants develop and deliver proof-of-concepts, technical workshops, deliver implementation projects and create solutions and tools. These professional services engagements involve emerging technologies like AI, IoT, and Data Analytics. The focus of this role is helping our customers and partners with design, implementation and integration of solutions using Amazon managed streaming services. AWS Professional Services engage in a wide variety of projects for customers and partners, providing collective experience from across the AWS customer base and are obsessed about customer success. Our team collaborates across the entire AWS organization to get the right solution delivered and drive feature innovation based upon customer needs. Solution - Deliver on-site technical engagements with partners and customers. This includes participating in pre-sales on-site visits, understanding customer requirements, supporting consulting proposals, contributing to internal Area of Depth programs and Technical Field Community, authoring AWS Data Analytics best practice and creating packaged data service offerings. Delivery - Engagements include on-site projects to design and build customer’s data streaming implementations and helping customers to migrate existing self-managed and on-premises solutions to AWS. Ability to travel to client locations to deliver professional services, as needed. Inclusive Team Culture Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have thirteen employee-led affinity groups, reaching 85,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. Work/Life Balance Our team puts a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success here. We are a customer-obsessed organization—leaders start with the customer and work backwards. They work vigorously to earn and keep customer trust. Mentorship & Career Growth Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future. • Hands on experience contributing to large-scale data science/data analytics projects • Experienced developing innovative solutions to complex business and technology problems • Written and verbal technical communication skills with an ability to present complex technical information in a clear and concise manner to a variety of audiences. • Experienced in queuing theory with message-broker software like RabbitMQ or similar Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. The pay range for this position in Colorado is $98,200 - $160,000/yr.; however, base pay offered may vary depending on job-related knowledge, skills, and experience. A sign-on bonus and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. Applicants should apply via Amazon's internal or external careers site. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
"ENGINEER, DATA",Denver Public Schools,"Denver, CO 80203 (Capitol Hill area)",https://www.indeed.com/rc/clk?jk=326d4d83b980f911&fccid=edd6757e2758ac76&vjs=3,"ENGINEER, DATA (JOB ID: 55266) DEPARTMENT OF TECHNOLOGY SERVICES (DoTS) Traditional 235 work days FTE: 1.0 Salary Range: $90,575 - $113,220 E ssential Functions and Objectives: A pplies engineering principles, techniques and scientific methods in a specific area of expertise (building, construction, technology, etc.). Responsible for solving technical problems and discovering new ways to improve the district's systems, infrastructures, processes and operations. R esponsible for ingesting critical District data from applications and other sources into a warehouse environment and preparing the data for consumption using an Extract Load Transform (ELT) methodology. Data preparation includes transformation based on District specific practices and the generation of structures that are highly available and highly performant. Ensure consistent use of best practices and support accuracy and optimized performance across the data platform. Prototype data solutions to enable warehousing, event-driven data capture, and data modeling. Implement solutions using Extract Load Transform (ELT/ETL) and/or combinations of automation tools. Collaborate with data teams to develop re-usable data solution patterns to enable quick to market data assets. Analyze & profile business data in structured and unstructured formats. Design and implement conceptual and logical data models, create metadata definitions, and create a source-to-target mapping. Evaluate tools and emerging technologies within the data ecosystem to push innovation. Collaborate with data owners, functional teams, and data consumers to understand the end-to-end intention of data use. Optimize data performance throughout the ELT process. Demonstrate Students First, Integrity, Equity, Collaboration, Accountability, and Fun in all interactions with team members, other DPS employees and external partners. K nowledge, Experience & Other Qualifications: One (1) or more years of SQL experience and the ability to write basic Python task is required. Experience in acquiring data from API’s is required. Valid Colorado Driver’s License, appropriate insurance coverage and acceptable driving record for the past three years, if the position requires travel. Effective time management and organizational skills. The ability to take responsibility for one’s own performance. Works collaboratively with others on a team. High degree of integrity in handling confidential information. Aptitude for variety and changing expectations in a fast-paced environment. Ability to work in a multi-ethnic and multi-cultural environment with district and school leaders, faculty, staff and students. Experience working within a cloud based data infrastructure is preferred. Advanced proficiency in developing SQL queries is preferred. Effective communication skills. Analytical problem solver with strong attention to detail. Experience with or ability to quickly learn new tools and technologies including dbt, Snowflake, Airflow, AWS S3 is preferred. E ducation Requirements: Bachelor’s Degree in Related Quantitative Field (e.g. Mathematics, Engineering, Sciences, Operations Research) is required. Master’s Degree is preferred. O ther information: T he mission of the DPS Department of Technology Services (DoTS) is to be a proactive partner enabling the success of every child. We support the students, families, and staff of Denver Public Schools by providing the infrastructure, tools, data, and support to enable effective educators and efficient operations. Our leading-edge technology work includes delivering custom portals for our students, parents, teachers, and administrators, managing one of the largest networks in the state of Colorado, providing unparalleled levels of customer support, finding new ways to get technology in the hands of our students, and much more. We believe that technology is a positive, enabling force for parent engagement, student engagement, educator effectiveness, operational efficiency, student safety, and student achievement. By joining us, you too will be enabling the success of every child! A dditional Information: Work Year Calendars (including accrued time off): http://thecommons.dpsk12.org/Page/1129 Benefits (including DPS contributions): http://thecommons.dpsk12.org/Page/1397 Compensation Structures: http://thecommons.dpsk12.org/Page/244 Employee must live and work with a permanent home address in Colorado while working for Denver Public Schools. A bout Denver Public Schools: D enver Public Schools is committed to meeting the educational needs of every student with great schools in every neighborhood. Our goal is to provide every child in Denver with rigorous, enriching educational opportunities from preschool through high school graduation. DPS is comprised of nearly 200 schools including traditional, magnet, charter and alternative pathways schools, with an enrollment of more than 90,000 students. D PS has become the fastest-growing school district in the country in terms of enrollment and the fastest-growing large school district in the state in terms of student academic growth. Learn more at dpsk12.org . D enver Public Schools is an Equal Opportunity Employer and does not discriminate on the basis of race, color, religion, national origin, sex, sexual orientation, age, disability, or any other status protected by law or regulation. It is our intention that all qualified applicants be given equal opportunity and that selection decisions be based on job-related factors."
"Engineer, Sr. Data","Lazy Dog Restaurants, LLC","Hybrid remote in Costa Mesa, CA 92626",https://www.indeed.com/rc/clk?jk=95a3a0c21474aff3&fccid=84ce475cb269ad6c&vjs=3,"Nourishing Connections We exist to nourish connections with, and between, our teammates, guests + communities. We provide small town hospitality for every member of our Lazy Dog family and create experiences that allow people to enjoy the moment, and each other, over handcrafted food and drink. Relevant If you love to oversee the development, construct, tests and maintains architectures, such as databases and large-scale processing systems, then this is the job for you. What We Offer Competitive Salary Achievable Bonus Paid Vacations Medical, Vision, Dental, and Life Company-paid meal card 401K plan with company match Opportunities for career advancement Amazing company culture Open to Remote Candidate Hybrid workplace Responsibilities Responsible and overseeing the design, implementation, and maintenance of Data Warehouse solutions which will support our growing business needs. Interface with other technology teams to extract, transform, and load (ETL) data from a wide variety of in-house and 3rd party data sources. Lead and design, implement, and support infrastructure providing secured access to large datasets. Utilize blended data from multiple data sources to provide comprehensive reporting solutions. Perform complex ad-hoc analyses and respond to data/analytical requests. Glean insights from a large data warehouse using SQL. qualifications & experience Bachelor's degree in Information Systems or related field or commensurate experience. Five to seven years of related experience. Certifications in currently used software applications, such as Microsoft. Advanced designing, developing, and implementing Business Intelligence Solutions. Knowledge of complex SQL composition and troubleshooting. Knowledge of concepts related to the design, implementation, and maintenance of data warehouses. Excellent communication skills with a positive service-oriented demeanor. Strong analytical, time management, organizational, and hands-on problem-solving skills. Ability to work effectively in a team-oriented IT environment. Trusting, passionate, humble, and gracious. Build lasting relationships with trust and respect. Create fun. IND1 Education Required Bachelors or better in Information Technology or related field"
Junior Engineer Data Science,Verizon,"Irving, TX 75038+8 locations",https://www.indeed.com/rc/clk?jk=729d4f5080a00956&fccid=f7029f63fe5c906e&vjs=3,"When you join Verizon Verizon is one of the world's leading providers of technology and communications services, transforming the way we connect across the globe. We're a diverse network of people driven by our shared ambition to shape a better future. Here, we have the ability to learn and grow at the speed of technology, and the space to create within every role. Together, we are moving the world forward - and you can too. Dream it. Build it. Do it here. What you’ll be doing... Verizon is one of the world's leading providers of technology and communications services, transforming the way we connect across the globe. We're a diverse network of people driven by our shared ambition to shape a better future. Here, we have the ability to learn and grow at the speed of technology, and the space to create within every role. Together, we are moving the world forward - and you can too. Dream it. Build it. Do it here. Our mission is to secure all applications in the enterprise. In this role you should be comfortable working in a dynamic environment with multiple concurrent responsibilities in real time Application Log Monitoring, Fraud prevention analysis and Alert reporting for action. This role will cover log analytics skills using Splunk, Log shipping skills using Kafka/FluentD, to perform log monitoring and reporting anomalies to prevent any security incidents. As a Juniordeveloper, you will work on a Logging and Monitoring project where the team collects data from different applications and analyzes the logs to look for vulnerabilities and reports for action. Candidate will be responsible for: Using Kafka/other message broker or queueing technologies to handle data flows and distribution, Splunk ingestion and Splunk tool for log monitoring and pattern analysis. Managing Logshipping process, Handling various shippers like Logstash, FluentD, FluentBit, Splunk Forwarder and various logging libraries (Log4J, log4N, logback) Managing log onboarding process for Container based on log plugins Participating in evaluating new information security tools Working with teams on how to document and mitigate security issues Be able to troubleshoot difficult Technical Problems Research root cause for false positives and update indicators as appropriate to reduce false-positive while minimizing false-negatives. Analyze events and alerts, and properly classify as incidents or false-positives. Work with various teams regarding Application log shipping and Log Analysis requirements. Where you'll be working… In this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager. What we’re looking for... You’ll need to have: Bachelor's degree or one or more years of work experience. Experience in Java and .NET and secure coding practices Experience with logging in a distributed micro service environment. Experience in dealing with large amounts of data. Experience with Kafka/other message broker or queueing technologies to handle data flows and distribution. Experience with log shippers like Logstash, FluentD, Beats, Splunk Forwarder. Experience with various logging libraries (Log4J, log4N, logback) and Splunk tool for log monitoring and pattern analysis. Knowledge with Container based on log plugins and CI/CD tools Even better if you have one or more of the following: Two or more years of relevant work experience. Knowledge with highly scalable system architectures. Experience with at least one of the cloud platforms (AWS, Azure, Google Cloud) and aware of security data classifications and OWASP standards. Experience with Splunk MLTK/Elastic/Kibana is a plus. Excellent oral and written communication skills. Ability to present findings concisely and effectively to critical audiences Excellent presentation skills in data storytelling to senior executives. Ability to work with various application teams to assist resolving project related issues Knowledge of current industry standards for secure web and mobile design Self-starter with strong self-management skills. Ability to organize and manage multiple priorities. Ability to lead work efforts with offshore and onshore resources across different organizations Strong analytical and problem solving abilities. High Level of motivation abilities. Technology savvy abilities. Learning abilities 22CyberAPP Equal Employment Opportunity We're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more. COVID-19 Vaccination Requirement Verizon requires new hires to be fully vaccinated against COVID-19. Verizon provides reasonable accommodations consistent with legal requirements (e.g., for medical, religious, or state law recognized reasons)."
DATA ENGINEER,Tra'Bian Enterprises,"Dallas, TX",https://www.indeed.com/rc/clk?jk=6b598ac20094eb4d&fccid=acfaa464fb995fc7&vjs=3,"Location: Dallas, TX Position Type: Contract Position Term: 1 Year All submitted candidates must be on our W2. Candidates can must be able to relocate after Covid. SKILLS: Data Engineer – 10 years experience Enterprise Content Management Documentum Captiva tool Javascript"
Data Integration Engineer,Stanford University,"Redwood City, CA",https://www.indeed.com/rc/clk?jk=d93718b0b264b490&fccid=1ba7f338730ce720&vjs=3,"Stanford’s Enterprise Technology team is looking for an experienced Data Integration Engineer responsible for the analysis, design, configuration, and development of integration solutions for multiple clouds and on-premises applications that are part of the Alumni and Development Applications Platform Transition (ADAPT) program. Additional contributions will include multiple components of the program: legacy data integration, technical design documentation, and communication of designed solutions to business partners. Collaboration is crucial with all participants inclusive of project managers, developers, business analysts, technical administrators, testers, and program management. Core Duties Propose, conceptualize, design, implement, and orchestrate solutions from end-to-end integration and be responsible for the applicable technical architecture. Lead and manage integration flow development, as necessary, for application and data integration. Monitor technology trends and evaluate emerging technologies for adoption and implementation. Ensure work completion within schedule, budgetary, and design constraints; Conduct analysis, design, and testing; solve complex technical problems; provide alternative methods for achieving goals when necessary. Identify and facilitate efficiency improvements in existing integration processes. Create documentation, processes, procedures, and guidelines to ensure compliance with university policy and federal and state regulations. Research and work with other technical analysts and administrators to implement new integration methodologies, processes, and procedures. Collaborate with technical architects & leads, product owners, infrastructure support, QA, and external teams. Mentor junior staff, as necessary, working on all phases of the application development lifecycle. Other duties may also be assigned. Education & Experience Bachelor's degree and eight years of relevant experience, or a combination of education and relevant experience. Required Knowledge, Skills, and Abilities Experience in designing, developing, testing, and deploying data integrations. Experience with API and Web Services (REST/SOAP/Bulk). Experience with data design, architecture, and data modeling in distributed cloud/hybrid environments. Experience with project management practices, frameworks, and methodologies (Agile/Scrum/Waterfall). Ability to define and solve logical problems for highly technical applications. Ability to select, adapt, and effectively use a variety of programming methods. Ability to recognize and recommend needed changes in user and operations procedures including participation in code reviews. Strong communication skills with both technical and non-technical clients. Desired Knowledge, Skills, and Abilities Experience with ETL and integration platform tools (MuleSoft, Informatica, SnapLogic). Experience with Git, merging, managing branches, and resolving conflicts. Experience with manual/automated functional testing and unit testing. Experience in leading, coaching, and mentoring junior members of varying skill levels. Certifications and Licenses Salesforce Integration Architect, MuleSoft, or Informatica credentials are a plus. Physical Requirements Perform desk-based computer tasks. Frequently sit, grasp lightly/fine manipulation. Occasionally stand/walk, writing by hand. Rarely use a telephone, lift/carry/push/pull objects that weigh up to 10 pounds. Working Conditions May work extended hours, evenings, and weekends. Available for on-call work. Work Standards Interpersonal Skills: Demonstrates the ability to work well with Stanford colleagues and clients and with external organizations. Promote Culture of Safety: Demonstrates commitment to personal responsibility and value for safety; communicates safety concerns; uses and promotes safe behaviors based on training and lessons learned. Subject to and expected to stay in sync with all applicable University policies and procedures, including but not limited to the personnel policies and other policies found in Stanford's Administrative Guide, http://adminguide.stanford.edu. Location We’re located in Redwood City. Our new Stanford Redwood City campus is open and brings together 2,700 staff in a collaborative environment that reflects Stanford’s culture and mission. The campus offers amenities such as onsite cafes and a dining pavilion, a high-end fitness facility with an outdoor pool, and a childcare center. As part of our telecommute options, we have Stanford locations in San Francisco, Newark, and San Jose and a supportive work-anywhere program for our Bay Area staff. Why Stanford is for You: Stanford University has revolutionized the way we live and enrich the world. Supporting this mission is our diverse and dedicated 17,000 staff. We seek talent driven to impact the future of our legacy. Our culture and unique perks empower you with: Freedom to grow. We offer career development programs, tuition reimbursement, or audit a course. Join a TedTalk, film screening, or listen to a renowned author or global leader speak. A caring culture. We provide superb retirement plans, generous time-off, and family care resources. A healthier you. Climb our rock wall or choose from hundreds of health or fitness classes at our world-class exercise facilities. We also provide excellent health care benefits. Discovery and fun. Stroll through historic sculptures, trails, and museums. Enviable resources. Enjoy free commuter programs, ridesharing incentives, discounts, and more! The job duties listed are typical examples of work performed by positions in this job classification and are not designed to contain or be interpreted as a comprehensive inventory of all duties, tasks, and responsibilities. Specific duties and responsibilities may vary depending on department or program needs without changing the general nature and scope of the job or level of responsibility. Employees may also perform other duties as assigned. Consistent with its obligations under the law, the University will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job. Stanford is an equal employment opportunity and affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law."
Data Security Engineer,Syniverse,Remote,https://www.indeed.com/rc/clk?jk=91b0115d9900ee20&fccid=f9af5aebcecd8ef2&vjs=3,"Syniverse is the world’s most connected company. Whether we’re developing the technology that enables intelligent cars to safely react to traffic changes or freeing travelers to explore by keeping their devices online wherever they go, we believe in leading the world forward. Which is why we work with some of the world’s most recognized brands. Eight of the top 10 banks. Four of the top 5 global technology companies. Over 900 communications providers. And how we’re able to provide our incredible talent with an innovative culture and great benefits. Who We're Looking For This position is responsible for analyzing, developing, testing, and supporting complex security implementations. These security implementations must be developed and maintained with high-quality standards and minimal defects. Some of What You'll Do Designs, analyzes, and documents security applications. Investigates and analyzes verbal and written requests for application security, interpreting application requirements to construct highly complex applications. Writes technical documentation for routines and applications, facilitating their maintenance. Constructs, tests, installs, and maintains security applications. Develops highly complex security controls and principles, which is maintainable, easy to use, and satisfies implementation requirements. Develops and executes security test plans, analyzes test results, and makes appropriate revisions to ensure the applications function as specified. Contributes to the planning for acceptance testing and implementation of new security framework components, performing supporting activities to ensure that customers have the information and assistance they need for a successful implementation. Provides support to internal users and support staff. Leads investigates application incidents for missing or incorrect functionality. Assess incident resolution and estimates application changes. Applies resolutions, leading to timely, error free revisions in applications. Leads configuration management tasks. Works with and in some instances provides work direction to our vendor partners Other duties as assigned Requirements: Basic to advanced knowledge of multiple security frameworks Basic to advanced knowledge of relevant operating systems and communication interfaces Basic to advanced knowledge of security design and testing principles Basic to advanced knowledge of log aggregation and event correlation strategies 5+ years of Cyber Security Engineering Experience Bachelor's Degree in Cyber Security, Computer Science or a related field Background in the telecommunications industry desired Why You Should Join Us Join us as we write a new chapter, guided by world-class leadership. Come be a part of an exciting and growing organization where we offer a competitive total compensation, flexible/remote work and with a leadership team committed to fostering an inclusive, collaborative, and transparent organizational culture. At Syniverse connectedness is at the core of our business. We believe diversity, equity, and inclusion among our employees is crucial to our success as a global company as we seek to recruit, develop, and retain the most talented people who want to help us connect the world."
Data Engineer,Newmont Mining,"Denver, CO",https://www.indeed.com/rc/clk?jk=466911958539f2a2&fccid=d69b23188b4f955b&vjs=3,"Date: Jun 8, 2022 Location: Denver, CO, US (United States) Founded in 1921 and publicly traded since 1925, Newmont (www.newmont.com) is one of the largest gold companies in the world. Headquartered in Denver, Colorado, the company has approximately 24,000 employees and contractors, with the majority working at Newmont's core operations in the United States, Australia, Ghana, Peru and Suriname. Newmont is the only gold company listed in the S&P 500 index and in 2007 became the first gold company selected to be part of the Dow Jones Sustainability World Index. Newmont's industry leading performance is reflected through high standards in environmental management, health and safety for its employees and creating value and opportunity for host communities and shareholders. About this role It’s an entry-level information technology (IT) role, a 2-year assignment, and a unique opportunity to participate in the process of growing the Business Analytics area. You will be exposed to technology, project management, requirement gathering, design, solutioning, and interaction with different teams within the IT and business areas. The main objective of the role is to participate and support the life cycle of providing Business Analytics solutions to our Business, by leveraging solutions like SAP Analytics Claud, and integrating with others systems like SAP SaaS and AWS hosted solutions, Tableau, Enterprise Data Warehouse You will be assigned to work under the direction of senior-level IT staff and complete several assignments, which will allow you to contribute with you knowledge and experience and at the same time develop expertise and specialize. As part of the assignments in our Business Analytics area you will interact with other areas: Finance Business Planning and Consolidation (BPC) Enterprise Assets Management (EAM) Supply Chain Management (SCM) Human Capital Management (HCM) Your role will consist of Analyze, define, and document business analytics requirements Execute initiatives following project methodology (waterfall and agile) and project management tools Follow our IT operating model end to end to deliver solutions with value to our business Structure and analyze large volumes of data to uncover patterns, and make predictions Assisting on the evaluation of solutions and best practices. Work on ticket resolution by analyzing, investigating, researching problems and solutions via online resources, technical material and vendor support. Work on the development of testing strategies. Training & Experience Knowledge: Completion of a bachelor's degree program at an accredited college or university with major course work in Information Technology, Computer Science, Data Science, or Information Systems Management. Experience: 0-1 year of experience in Computer Science or Data Engineer roles, preferred but not required. Skills and Abilities: Motivated toward career growth and learning. Establish effective working relationships with colleagues, team members, supervisors, vendors and other Newmont personnel Proficiency in Word, Excel, and PowerPoint. Define problems, collect data, establish facts, and draw valid conclusions. Express ideas effectively, both orally and in writing. Effectively present information and respond to questions from managers, co-workers, and partners. Establish effective working relationships with colleagues, team members, supervisors, vendors and other Newmont personnel Knowledge of data mining, maintaining databases, data preparation, maintaining confidentiality, report preparation, troubleshooting strong problem-solving capabilities, database language, mathematics, project management. Working Conditions Willingness to put in extra hours as projects and priorities dictate. Flexible hours to accommodate global support times. Travel may be required but is projected to be minimal. Work from home according to Newmont policies The salary range offered for this role is $56,720-74,445. The salary range is tied to the Colorado market for jobs performed in Colorado. The salary offer to the successful candidate will be based on job-related education, training, and/or experience. The salary offer will not be based on a candidate’s salary history at other jobs, and by law, Newmont will not seek information about salary history, and candidates should not share such information with Newmont. This role will be eligible for participation in a discretionary annual bonus program, pursuant to which an employee may be awarded a percentage of their salary based on the company’s performance and their own individual performance. Newmont offers a competitive and inclusive benefits package to support physical, mental, financial and emotional wellbeing. This role will be eligible for the following benefits: Medical, prescription drug, dental, and vision insurance; flexible spending accounts; health savings accounts; life and accidental death and dismemberment insurance; short and long-term disability; 401(k) program with company match; pension; financial planning; employee assistance program (EAP); adoption assistance; dependent scholarship program; tuition reimbursement; paid holidays and paid time off; paid family leave; matching gifts; and discounts on home, auto and pet insurance. All bonuses and benefits are subject to the applicable eligibility and program/plan terms and may be modified or terminated at Newmont’s sole discretion. Consistent with Newmont’s values of safety and responsibility, we believe that COVID-19 vaccination is a critical tool to fight this pandemic and protect the health and safety of Newmont’s workforce and the communities in which we work and live. With the wide availability of vaccines in the United States, if you are offered this position, you will have to show proof of a COVID-19 vaccine prior to being hired. This requirement will be subject to an exemption process, as required by law. Newmont may update its vaccination policies/requirements at any time in its sole discretion. Nearest Major Market: Denver"
Data Platform Engineer,Cloudwall Capital SG Pte Ltd.,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=fd8ec0585d065463&fccid=f995acdf913f59fb&vjs=3,"Data Platform Engineer Level: Vice President Location: New York City, USA (Remote) Permanent employee, Full time SUMMARY We are seeking a senior software developer who is passionate about data engineering. As part of DevSecOps, our core engineering & production management team, you will build, deploy and support a petabyte-scale, cloud-based data platform with both batch and real-time feeds. Development will be fast-moving and iterative following Agile practices. You will collaborate closely with our frontend and risk platform developers and our test automation engineer to create a fast, reliable, resilient and maintainable system that delights our clients. You will also work with our research team to ensure they have high-quality data to meet their needs. As a senior developer, you will also work with the CTO on design and best practices for the whole data platform. RESPONSIBILITIES Design & develop complex data pipelines to support real-time and batched based services Work closely with our quant researchers to source and integrate new data feeds Work closely with our test automation engineer to build automated regression & load tests Write unit tests Peer & junior developer code review Peer & junior developer design review Configure backend systems using Kubernetes Deploy services on the public cloud SKILLS REQUIRED At least 10 years of IT industry experience Server-side Java microservice development experience (e.g. SpringCloud, Eureka) Experience building both REST, GRPC and Websockets-based API's Experience with common Big Data technologies like Hadoop Ecosystem, Flink, Spark Streaming, Redis, Pulsar, Kafka or the equivalent stacks Experience with data security best practices such as data encryption, masking and fine grained data access control Experience deploying reliable, scalable cloud-based platforms on Kubernetes Comfort working with data scientists & quantitative researchers Comfort working in a fast-moving environment with an Agile development methodology Attention to detail and a passion for assuring data quality Excellent communication skills SKILLS DESIRED Experience with second-generation data engineering packages like Flink and Flyte Knowledge of the digital asset market or traditional markets (Equities, FX and Fixed Income) Azure cloud deployment experience EEO STATEMENT Cloudwall Capital, Inc. is an equal opportunity employer. We are committed to a work environment that supports, inspires, and respects all individuals and in which personnel processes are merit-based and applied without discrimination on the basis of race, color, religion, sex, sexual orientation, gender identity, marital status, age, disability, national or ethnic origin, military service status, citizenship, or other protected characteristic. Back To Careers Interested? Apply now and we'll get in touch with you shortly. For further details, reach out to us at careers@cloudwall.capital."
Data Engineer,BAXTER,"Deerfield, IL 60015+1 location",https://www.indeed.com/rc/clk?jk=234128d0bf237dac&fccid=a108770a4ae3a921&vjs=3,"This is where you save and sustain lives At Baxter, we are deeply connected by our mission. No matter your role at Baxter, your work makes a positive impact on people around the world. You’ll feel a sense of purpose throughout the organization, as we know our work improves outcomes for millions of patients. Baxter’s products and therapies are found in almost every hospital worldwide, in clinics and in the home. For over 85 years, we have pioneered significant medical innovations that transform healthcare. Together, we create a place where we are happy, successful and inspire each other. This is where you can do your best work. Join us at the intersection of saving and sustaining lives— where your purpose accelerates our mission. Summary: Perform development work and technical support related to our data transformation and ETL jobs in support of a global data warehouse. Can communicate results with internal customers. Requires the ability to work independently, as well as in collaboration with a variety of customers and other technical authorities. What you'll be doing Development of new ETL/data transformation jobs, using PySpark and IBM DataStage in AWS. Improvement and support on existing transformation jobs. Can explain technical solutions and resolutions with internal customers and communicate feedback to the ETL team. Perform technical code reviews for peers moving code into production. Perform and review integration testing before production migrations. Provide high level of technical support, and perform root cause analysis for problems experienced within area of functional responsibility. What you'll bring 5+ years of ETL experience. Experience with core Python programming for data transformation. Intermediate-level PySpark skills. Can read, understand and debug existing code and write simple PySpark code from scratch. Strong knowledge of SQL fundamentals, understanding of subqueries, can tune queries with execution hints to improve performance. IBM DataStage experience preferred. Able to write SQL code sufficient for most business requirements for pulling data from sources, applying rules to the data, and stocking target data Experienced in solving ETL jobs and addressing production issues like performance tuning, reject handling, and ad-hoc reloads. Proficient in developing optimization strategies for ETL processes. Basic AWS technical support skills. Has ability to log in, find existing jobs and check run status and logs Will lead jobs via Control-M Can create clear and concise documentation and communications. Can document technical specs from business communications. Ability to coordinate and passionately follow up on incidents and problems, perform diagnosis, and provide resolution to minimize service interruption Ability to prioritize and work on multiple tasks simultaneously Effective in multi-functional and global environments to lead multiple tasks and assignments. Experienced in analyzing business requirements, defining the granularity, source to target mapping of the data elements, and full technical specification. Understands data dependencies and how to schedule jobs in Control-M. Knowledgeable in working at the command line in various flavors of UNIX, with basic understanding of shell scripting in bash and korn shell. Education and/or Experience Bachelors of Science in computer science preferred. 5+ years of ETL and SQL experience 3+ years of python and PySpark experience 3+ years of AWS and unix experience 2+ years of IBM DataStage experience Preferred certifications: AWS Certified Cloud Practitioner (amazon.com) Certified DataStage Professional Python and PySpark certifications The successful candidate for this job may be required to verify that he or she has been vaccinated against COVID-19, subject to reasonable accommodations for individuals with medical conditions or religious beliefs that prevent vaccination, and in accordance with applicable law. Equal Employment Opportunity Baxter is an equal opportunity employer. Baxter evaluates qualified applicants without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity or expression, protected veteran status, disability/handicap status or any other legally protected characteristic. EEO is the Law EEO is the law - Poster Supplement Pay Transparency Policy Reasonable Accommodations Baxter is committed to working with and providing reasonable accommodations to individuals with disabilities globally. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please click on the link here and let us know the nature of your request along with your contact information. Recruitment Fraud Notice Baxter has discovered incidents of employment scams, where fraudulent parties pose as Baxter employees, recruiters, or other agents, and engage with online job seekers in an attempt to steal personal and/or financial information. To learn how you can protect yourself, review our Recruitment Fraud Notice. 066002"
Associate Data Engineer,Campbell Soup Company,"Camden, NJ 08103 (Gateway area)",https://www.indeed.com/rc/clk?jk=7caf9ee95871d6ce&fccid=76c7d9c9adef7d87&vjs=3,"Imagine...working for a company that knows that its people are the key to its success in the marketplace. A company in which achieving extraordinary results and having a stimulating work experience are part of the same process. We cultivate and embrace a diverse employee population. We recognize that people with diverse backgrounds, experiences and perspectives fuel our growth and enrich our global culture. We are looking for an individual who enjoys working in a fast-paced, team oriented environment, likes to be challenged, and values the opportunity to make a difference. General Summary Works closely with customers and stakeholders in partnership with Solution architect in an Agile manner to design end to end BI solution. This includes data modeling, meta data support, development, testing and implementation. This role also works on hand off to support team. The Associate Data Engineer should be able to assess the impact of any change to the overall architecture and guide the offshore development team. The Associate Data Engineer must be proficient in data management and business intelligence technologies and must be prepared to develop and enforce standards in support of project and continuous improvement initiatives. Primary Responsibilities (25%) - Collaborate with solution architects to understand the overall solution concept in support of a project or continuous improvement effort. Works with customers of Data and Analytics to understand business needs with respect to data and analytics in order to determine optimal solutions. (30%) - Develop high-level and detailed design documents for projects and continuous improvement efforts. Develop data modeling, meta data support, development and testing for enterprise wide data warehouse. (15%) - Participate in code reviews with the development team, ensuring adherence to development standard and overall best practices. Facilitate software change management across development, test, and production landscapes. (20%) - Assist in the completion of projects using project management skills including planning; assigning, monitoring and reviewing progress and accuracy of work; evaluating results, etc. (10%) - Maintain proficiency with the tools in the current and strategic analytical portfolio through both formal and on-the-job training. Work with solution architect to evaluate and recommend new DW and BI tools that further the goals of Data and Analytics team and business overall. Complexity & Scope Independent, working under only general instructions and expected to determine how to accomplish the work assignment, operating with some latitude for un-reviewed action or decision. Responsible for working across global technology platforms and in various business unit and functional area. Responsible for good technical knowledge of back-end and front-end applications. Responsible for understanding business application functionality and architecture of multiple data and analytics applications. Ability to lead development efforts and work with external service providers. Minimum Requirements Education: Bachelor's Degree required. Educational discipline in Computer Science or Information Systems strongly desired. Advanced degree and/or system certification a plus. Length of Experience: Minimum 2 years of Data warehousing experience. Experience with BI tools desired. Certifications: At least 1 of the following certifications: Cloud platform (Azure ADF preferred / or similar) Database modeling (Oracle, MS SQL server, snowflake) SQL certification ETL certification (Informatics preferred) Reporting Tools Power BI desired Python certification Other: Must have strong written and oral communication skills. Must have relational and dimensional database experience, experience with OLAP / MDX queries, experience with both ETL and ELT models, cloud solution architecture and development experience strongly desired CI / CD experience desired, Virtualization experience desired BI tool experience Power BI strongly desired Experience working with external service providers desired Experience using Open source tools for BI / DW development desired Experience working with Agile methodology desired ACR The Company is committed to providing equal opportunity for employees and applicants in all aspects of the employment relationship, without regard to race, color, sex, sexual orientation, gender identity, national origin, citizenship, marital status, veteran status, disability, age, religion or any other classification protected by law. In that regard, U.S. applicants and employees are protected from discrimination based on certain categories protected by Federal law."
"Sr. Frontend Engineer, Data Intelligence Platform",Adobe,"San Jose, CA+3 locations",https://www.indeed.com/rc/clk?jk=b61bee8f472b4160&fccid=f89deb5a97c7738a&vjs=3,"locations San Jose Denver San Francisco Austin Seattle View All 6 Locations time type Full time posted on Posted 16 Days Ago job requisition id R127618 Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! Job Description: The Customer Insights Analytics Platform team is responsible for building analytics and data solutions to accelerate growth for Adobe's ~$11B annual recurring revenue Digital Media business. We are looking for a Sr. Frontend Engineer to develop and support an internal custom web-based BI and analytics platform to democratize data and intelligence across the Creative Cloud and Document Cloud businesses. You are a good fit for this position if you are an excellent front end engineer, experienced with data visualization, passionate about good UI/UX, comfortable in a fast paced organization, and passionate about partnering with other engineers, analysts, and the business. We are using lean product development principles — iterating quickly and incorporating extensive user research — to stay focused on delivering value and unlocking growth for the Digital Media business. Responsibilities: Improve and expand custom internal facing web-based analytics applications. This can involve everything from requirements gathering, data investigation/manipulation, prototyping, development & operations. Focus on improving, scaling, and innovating on the front-end. However, the development team is extremely agile and you will be required to wear many hats as needed. A “startup” approach is a plus. Design and implement innovative and intuitive multi-visual interfaces & features that enable the business to craft compelling narratives around their data and quickly diagnose when things go awry. Make data and insights easy to consume. Develop performant and scalable code, while maintaining a foremost focus on delivering rapid business value. Strong social skills are a must. Comfortable collaborating with analysts, domain experts, and decision-makers to develop data-driven solutions that meet the needs of the business. Requirements: Bachelor/Master’s Degree (STEM) or 6+ years of relevant experience. Strong JavaScript, HTML, CSS and D3.js (preferred) and/or other front-end visualization library experience. Experience creating systems of reusable components from scratch in your framework of choice (Vue.js preferred). Demonstratable layout & UI/UX abilities (constantly thinking about the end user). Experience with modern web dev tools/patterns/idioms, Node.js comfortable with at least one framework of choice. Working experience with business intelligence tools like Tableau, Power BI, etc. is a plus. Proficient in querying and manipulating large data sets. Comfortable writing SQL. Statistics, ML/AI modeling experience and/or interest a plus. Side projects, github, or personal portfolios are a big plus (please include front and center in resume, we will look!) At Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists (http://www.adobe.com/careers/awards.html). You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In (http://www.youtube.com/watch?v=hmL6uQZhYhw&list=UUlDSu3-Y4-BfI08784K-P4g&feature=share&index=1) approach where ongoing feedback flows freely. If you’re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog (http://blogs.adobe.com/adobelife/) and explore the meaningful benefits (http://benefits.adobe.com/) we offer. Adobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, religion, age, sexual orientation, gender identity, disability or veteran status. Pursuant to the Colorado Fair Pay Act, below is a summary of compensation elements for this role at the company if based in Colorado. Colorado Starting Salary: $133,400 - $173,200 At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP). In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award."
AWS/BI Data Engineer,Hitachi,"Seattle, WA 98101 (Downtown area)",https://www.indeed.com/rc/clk?jk=fc29b2802ce942bb&fccid=28f79c18789111e8&vjs=3,"Meet our Team SHORT INTRO TO THE TEAM - SAMPLE BELOW We represent Hitachi Vantara to enterprise clients across industries, establishing business relationships to understand customer challenges so that we can deliver profitable business for Hitachi products, services and solutions. We collaborate as a team and cross-functionally to ensure the success of our customers; success that is celebrated and shared. Our solutions bring value to every line of business and we need people like you to build those deep relationships and to passionately articulate our value proposition. What you'll be doing COUPLE OF SENTENCES SELLING THE MAIN FOCUS POINTS OF THE ROLE What you bring to the team Bullet Point 1 Bullet Point 2 Bullet Point 3 Bullet Point 4 Bullet Point 5 Our Company Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what's now to what's next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society. Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we'd love to hear from you. Our Values We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs. We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. With Japanese roots going back over 100 years, our culture is founded on the values of our parent company expressed as the Hitachi Spirit: Wa - Harmony, Trust, Respect Makoto - Sincerity, Fairness, Honesty, Integrity Kaitakusha-Seishin - Pioneering Spirit, Challenge"
Data Quality Engineer,Affinity.co,Remote,https://www.indeed.com/rc/clk?jk=88333dc8b92bff90&fccid=1b32be4e9bf5cb2a&vjs=3,"USA (Remote) With our growing customer base and our expansion into new markets and use cases, we have more to build than ever at Affinity as we execute on our vision to put relationship intelligence at every professional's fingertips. We are looking for a Data Quality Engineer, who is looking for a challenge, enjoys thinking big, and looking to make their mark on an extremely fast-growing company. If building large and building fast, working with a very talented team of engineers, and collaborating with the brightest minds is what you like, Affinity is the best experience. What you’ll be doing: Design and implement Test Automation frameworks using Python, SQL, Airflow. Develop test strategies, plans, test cases, and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality. Using Tableau, Python, Databricks and DataDog, create active quality monitoring for data pipelines and processes. Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability. Building and automating testing frameworks around data ingestion pipelines and active monitoring. Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies. Support data governance and data profiling efforts to ensure data quality and proper meta-data documentation for data lineage. Creating quality metrics to evaluate data pipelines, visualizations, and dashboards. Implement and execute test strategies on all supported platforms and languages to help improve the overall quality and test code coverage. Design and develop integration, regression, and stress tests using industry-standard tools. Collaborate with Product Management and Engineers to understand requirements, translate them into test cases and determine product quality goals and measurements. Reproduce, isolate, and debug issues, providing detailed bug reports. Develops and enhances the test infrastructure and continuous integration framework used across teams. Validate data pipelines and data processing jobs that collect data from disparate systems and store it in internal databases. Identify edge cases that can potentially break the data pipelines or compromise data quality or integrity. Qualifications Required: 4+ years of industry experience in data engineering, BI, and Quality Assurance. Experienced in Python, SQL, Data Warehouse, and Data Lake. Hands-on experience testing, ETL pipeline, Kafka, Spark, and Presto. Sound understanding of various cloud technologies, especially AWS. Experience in working with large-scale Enterprise data warehouse, data integration, data migration, and data quality verification. Hands-on testing experience in working with Databricks, Spark, and other Big data technologies. Experience with data pipelines and data processing jobs. Experience in identifying edge case defects. Skilled in integrating project testing with continuous-integration process (CI/CD). Knowledge of industry-standard test automation tools and experience in developing product test harnesses and instrumenting products to gather test results. Knowledge of relational and NoSQL databases, and queries. BA/BS Degree in Computer Science or related technical discipline, or practical experience. Nice to have: Experience performing code reviews and code quality checks. Understands designing and coding for testability to produce quality code. What you'll enjoy at Affinity We live our values as playmakers who are obsessed with learning, care personally about our colleagues and clients, are radically open-minded, and take pride in everything we do. We pay your medical, dental, and vision insurance with comprehensive PPO and HMO plans. And provide flexible personal & sick days. We want our team to be happy and healthy :) We offer a 401k plan to help you plan for retirement. We provide an annual budget for you to spend on education and offer a comprehensive L&D program – after all, one of our core values is that we’re #obsessedwithlearning! We support our employee’s overall health and well-being and reimburse monthly for things such as; Transportation, Home Internet, Meals, and Wellness memberships/equipment. Virtual team building and socials. Keeping people connected is essential. About Affinity We are passionate about helping dealmakers in the world’s biggest relationship-driven industries to find, manage, and close the most important deals. Our Relationship Intelligence platform uses the data exhaust of trillions of interactions between Investment Bankers, Venture Capitalists, Consultants, and other strategic dealmakers with their networks to deliver automated relationship insights that drive over 450,000 deals every month. We have raised over $120M and are backed by some of Silicon Valley’s best firms. With over 1700 customers in 70 countries on our platform, a 4.8 Star Glassdoor rating and being ranked in the Inc. 5000 fastest growing companies, we need more great people to help us scale even more. The more diverse our team is, the more we’ll be able to learn from each other, and the better our company and our product will be. Whatever your gender, race, sexual orientation, religion, age, veteran status, favorite Spotify playlist, or social, cultural, and economic background, we can’t wait to welcome you to Affinity!"
Data Engineer,CITADEL ENTERPRISE EUROPE LIMITED,"Chicago, IL",https://www.indeed.com/rc/clk?jk=6616afbdf6f772c7&fccid=588ae1081cd0e6e5&vjs=3,"Data Engineer At Citadel, data is the core of the investment process. Data Engineers architect and build our data platforms which drive how we source, enrich, and store data that integrates into the investment process. These Data Engineers own the entire data pipeline starting with how we ingest data from the outside world, transforming that information into actionable insights, and ultimately designing the interfaces and APIs that our investment professionals and quantitative researchers use to monetize ideas. Throughout the process, our Data Engineers partner with top investment professionals and data scientists to design systems that solve our most critical problems and answer the most challenging questions in finance. YOUR OPPORTUNITY: Develop solutions that enable investment professionals to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, sensor collection), transformations (Spark, SQL, Kafka, Python/C++/Java), and interface (API, schema design, events) Partner with the industry’s top investment professionals, quantitative researchers, and data scientists to design, develop, and deploy solutions that answer fundamental questions about financial markets Build tools and automation capabilities for data pipelines that improve the efficiency, quality and resiliency of our data platform Drive the evolution of our data strategy by challenging the status quo and identifying opportunities to enhance our platform YOUR SKILLS & TALENTS: Passion for working with data in order to accurately model and analyze complex systems such as a publicly traded company, commodity market, economy, or financial instruments Strong interest in financial markets and a desire to work directly with investment professionals Proficiency with one or more programming languages such as Java or C++ or Python Proficiency with RDBMS, NoSQL, distributed compute platforms such as Spark, Dask or Hadoop Experience with any of the following systems: Apache Airflow, AWS/GCE/Azure, Jupyter, Kafka, Docker, Kubernetes, or Snowflake Strong written and verbal communications skills Bachelor’s, Master’s or PhD degree in Computer Science or equivalent experience About Citadel Citadel is a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For thirty years, Citadel’s hedge funds have delivered meaningful and measurable results to top-tier investors around the world, including sovereign wealth funds, public institutions, corporate pensions, endowments and foundations. With an unparalleled ability to identify and execute on great ideas, Citadel’s team of investment professionals, operating from offices including Chicago, New York, San Francisco, London, Hong Kong and Shanghai, deploy capital across all major asset classes, in all major financial markets."
"Senior Infrastructure Engineer, Data & Insights Solutions","Tyler Technologies, Inc.",Remote,https://www.indeed.com/rc/clk?jk=15500f52f6ddc6a1&fccid=35fa439a19059a40&vjs=3,"At Tyler Technologies, our Data & Insights solutions are designed help government use data more strategically and effectively in the design and delivery of their programs and missions. As a Senior Infrastructure Engineer, you will build and manage the infrastructure necessary to host our exacting worldwide clients. Why Us? We exist to inspire and empower every public servant to address society's pressing issues. We do that by enabling data-driven leadership through connected data and shared insights. Our data as a service platform and cloud-based solutions support the world’s most effective open and internal data sharing programs at every level of government. What we do matters. New York, Seattle, San Francisco and 230+ other cities, states, counties and federal agencies use us to connect citizens and their internal teams with information that matters to their day to day life. Why This Job Is Important You’ll help the company design, operate, monitor, and grow the platform that hosts our global client base. You will work side-by-side with the rest of the engineering team to ensure our new features and services meet our security and performance guidelines. You will build the infrastructure that makes other engineers even more productive. Work with our transformative data solutions that help agencies address mission-critical outcomes. Our cloud-based data platform, open data solutions, and performance management solutions help agencies improve performance, transparency, and public engagement. Location Remote Responsibilities On a Typical Day, You Might... Contribute patches to open-source tools to better support our mission and operations. Participate in on-call rotation, which includes all engineering staff. Partner with security staff to implement advanced security and compliance requirements for our clients. Diagnose and fix systems and software failures and build additional automation to prevent the failure scenario from reoccurring. Manage DNS and SSL configurations for customer domains. Build out a production environment. Upgrade our infrastructure. Perform various AWS administration tasks. Qualifications AWS Building out environments (Setting up VPC, configuring ACLs and security groups) IAM user/key management CloudFormation Familiarity with other services including: EC2, S3, RDS, ECR, EKS Experience with other non-AWS infrastructure as a service platforms is also relevant. Linux Understanding of Linux OS at a systems level. Systems engineer experience is a plus Ubuntu knowledge is a plus Coding skills Strong familiarity with at least one dynamic language (Ruby or Python is a plus) Experience writing configuration as code Familiarity with objected oriented programming and data structures is a plus Configuration management Experience with and proficient with at least one configuration management tool (e.g. Chef, Salt, Ansible, Puppet, etc.) Experience specifically with Chef is a plus Containerization/Orchestration Experience with Docker Familiarity with Kubernetes Experience with Mesos and Marathon is a plus Networking skills are a plus You are interested in working with engineers to help scale and optimize their services. You are calm in high-pressure situations and skilled at triaging situations. About Us Tyler Technologies (NYSE: TYL) provides integrated software and technology services to the public sector. Tyler’s end-to-end solutions empower local, state, and federal government entities to operate more efficiently and connect more transparently with their constituents and with each other. By connecting data and processes across disparate systems, Tyler’s solutions are transforming how clients gain actionable insights that solve problems in their communities. Tyler has more than 26,000 successful installations across more than 10,000 sites, with clients in all 50 states, Canada, the Caribbean, Australia, and other international locations. A financially strong company, Tyler has achieved double-digit revenue growth every quarter since 2012. It was also named to Forbes’ “Best Midsize Employers” list in 2019 and recognized twice on its “Most Innovative Growth Companies” list. More information about Tyler Technologies, headquartered in Plano, Texas, can be found at https://www.tylertech.com/ . To learn more about our Data & Insights solutions, visit https://www.tylertech.com/solutions/transformative-technology/data-insights . Additionally, we aspire to be remarkable: in the culture we create, the products we build, and the services we deliver. We believe a diverse team that embodies different backgrounds and experiences is necessary for us to be the best we can be. Within the company, we pursue a culture of inclusivity by identifying and removing aspects of our culture that stop people from being able to do the best work of their lives in physical and emotional safety, while being their authentic selves. We seek diversity, equity, and inclusion across our organization and in our daily work as individuals. We understand change takes time and that we still have work to do; however, we are committed to making continual progress. #INDCORP State Specific Salary Range Disclosure Requirements for Colorado, Connecticut, and Nevada Salary will generally fall between $130,000 - $150,000 before adjustment for geographic differences. Recruiter can confirm if position is incentive eligible. Tyler is subject to regulations, guidelines, and/or client requirements relating to the qualifications of Tyler personnel performing certain client work. Because of the nature of this position, it is a requirement that the candidate can successfully pass a federal background check at the time an offer is extended and over the course of employment with Tyler."
Sr. Data Engineer,WellSky,"Overland Park, KS+3 locations",https://www.indeed.com/rc/clk?jk=036ceaf6cf490071&fccid=ccf9f96e8cae7bb9&vjs=3,"WellSky is seeking a savvy Senior Snowflake Data Engineer to join our BI team of analytic experts to build our next generation cloud data warehouse solutions. The data engineer will be responsible for expanding and optimizing our data flow and data pipeline architecture as well as migrating our data warehouse solution to the cloud platform in Snowflake. Bring passion, creativity and dedication to your job and there is no telling what you could accomplish. A day in the life! You will be responsible for the following: Design and implement very large-scale data intelligence and data warehousing solutions in Snowflake, combined with other technologies. Creating and maintaining optimal data pipeline architecture. Expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Proactively identify and propose new, alternative technology to create scalable implementations and achieve delivery results. Provide technical guidance and support to a vibrant engineering team Respond quickly and effectively to production data warehouse issues and take responsibility for seeing those issues through resolution. Improve and scale the existing products and tools to support our growth You will join a team of top engineers creating interactive reports and dashboards with stunning visualizations. You will have direct impact on the users of our solutions, mainly doctors, nurses, and others on the front lines of healthcare and community services. Your hard work will touch the lives of real people and families navigating life and death issues with the support of our solutions. We seek to build purpose-driven teams where comradery and compassion are coupled with a dogged pursuit of excellence. Do you have what it takes? Required Experience: 5+ years of experience in designing and delivering ETL/ELT processes, data pipelines, data lakes, data warehouses and reporting platforms. 3+ years of architecting, designing, and building a fully operational production grade large scale data warehouse solution on Snowflake cloud platform. Recent hands-on experience with solid understanding of Snowflake implementation, SnowSQL, SnowPipe and query performance tuning is a must. 2+ years of experience working with data visualization and reporting tools like SisSense and/or Tableau Advanced SQL knowledge is a must. Minimum 1 years' experience with REST API development and consumption Experience working with cloud platform - AWS or GCP Experience and enjoy working in an Agile environment. Source control with Git/Git Hub Outstanding communication and interpersonal skills Must be a great team player Do you stand above the rest? Preferred Experience: Experience with Legacy Data Warehouse migration to Snowflake is a BIG plus! Highly Desirable: Knowledge of frameworks such as Angular.js, React Experience with development skills: back-end (i.e., REST API, (Micro)Services, .NET Core, C#, SQL etc.) and front-end (i.e. TypeScript, Angular, React CSS, etc.) design and programming technologies. Experience with scripting languages like Python, etc. Experience with one or more relevant tools like Kafka, Streamsets, Matillion. Leveraging Splunk, Sumo, New Relic, CloudWatch for observability and monitoring Bachelor's degree in Computer Science or equivalent Preferred Certifications: Bonus Points: Go to the top of the stack if you have Snowflake certification! Who We Are: We have an open environment where highly motivated, ambitious engineers can help drive innovation. We include a diverse group of collaborative & super intelligent teammates to work with and learn from. We constantly strive to solve large scale challenges with a variety of technologies. We strongly support a work/life balance. We believe in giving recognition for doing what you enjoy. Come help us realize care's potential! #LI-PM About WellSky WellSky is a technology company leading the movement for intelligent, coordinated care worldwide. Our next-generation software, analytics, and services power better outcomes and lower costs for stakeholders across the health and community care continuum. In today's value-based care environment, WellSky helps providers, payers, health systems, and community organizations solve tough challenges, improve collaboration for growth, harness the power of data analytics, and achieve better outcomes by further connecting clinical and social care. WellSky serves more than 20,000 client sites around the world — including the largest hospital systems, blood banks, cell therapy labs, blood centers, home health and hospice franchises, post-acute providers, government agencies, and human services organizations. Informed by more than 40 years of providing software and expertise, WellSky anticipates clients' needs and innovates relentlessly to ultimately help more people thrive. We're looking for talented individuals who want to use their skills to build a strong, technology-driven company. We offer competitive salaries, great benefits, including generous paid time off programming, and a casual and fun environment that encourages quality, creativity, and excellence. Enjoy all we have to offer. We invite you to join us. Apply today! WellSky provides equal employment opportunities to all people without regard to race, color, national origin, ancestry, citizenship, age, religion, gender, sex, sexual orientation, gender identity, gender expression, marital status, pregnancy, physical or mental disability, protected medical condition, genetic information, military service, veteran status, or any other status or characteristic protected by law. WellSky is proud to be a drug-free workplace. Applicants for U.S.-based positions with WellSky must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire. All U.S.-based employees must be fully vaccinated against COVID-19 unless a medical or religious exemption is approved."
Data Engineer (Remote Opportunity),CustomInk,"Remote in Fairfax, VA 22031+5 locations",https://www.indeed.com/rc/clk?jk=9eceb767364d9943&fccid=7675e528c17ce6a4&vjs=3,"Custom Ink is looking for a mid level data engineer who has multiple years of experience building technical solutions that support data infrastructure. The Data Engineering team at Custom Ink works to build data solutions and implement tools to help improve data accuracy and reliability so our business can make data driven decisions with confidence. What sets us apart? ""Custom Ink is an environment where employees are enabled to innovate and deliver wins for the business."" We win awards. We've won a Google mobile web hack-a-thon, ranked in the top 10 of DC area companies that tech talent wants to work (through Hired’s Global Brand Health Report) and our Design team took 2nd place in an Adobe design contest. Custom Ink also has an award winning culture We’re involved in the engineering community. We attend, speak at, and host engineering related events, like Code and Coffee , Papers We Love , 757rb and RubyLoCo We're dedicated to Innovation. We are passionate about trying new things and we follow through with 10% time and hosting regularly scheduled full-team hack-a-thons. How you’ll make a difference: As a Data Engineer, you’ll play a key role in contributing to the overall success and growth of our data team by instilling best practices around lifecycle management of the infrastructure architecture associated with both batch and real-time data pipelines. By recognizing the importance of data democratization and leveraging your technical abilities, you’ll deliver powerful self-serve tools that free up valuable time for all involved. You’ll also act as a partner to the project and functional teams you work with. You’ll report to the Data Engineering Manager. What you’ll do: As a Data Engineer you’ll focus on improving the design and implementation of our data warehouse, ensuring reliable data infrastructure and creating data solutions for business partners. This represents a tremendous opportunity to: Fix gaps or weaknesses in our infrastructure to help drive continuous improvements Drive efficiency gains through improved reliability and stakeholder adoption of self-serve tools Leverage research and previous experience to ensure we’re up to date and continuously exploring new technologies Build data architectures that support the flow of data from multiple sources as well as both batch and real-time data pipelines Partner with Software Engineering and business partner teams to drive projects and data democratization How you’ll be measured: At Custom Ink, we love data and metrics! More than that, we love measuring the impact of our work on the experience and satisfaction of our teams and customers. As a champion for ensuring quick and easy access to accurate data, measures for this role will include: Improvements to the design and implementation of our Data Warehouse Efficiency gains through improved reliability and stakeholder adoption of self-serve tools Improved documentation Meet project deadlines and requirements Data democratization- ensure end users/business partners have trust in and actively use great self-service tools What we’re looking for: This role involves collaborating effectively with various tech teams and business partners and allows opportunity for real ownership over data improvements and new processes that will contribute to big picture success across teams. The ideal candidate will be curious, analytical and a strong problem solver with substantial programming skills, advanced knowledge of databases and other analytical tools and who understands the importance of developing best practices and reliable documentation. Accordingly, the ideal candidate will be strong in the following areas: Minimum of 2+ years data engineering experience with a proven track record for success in a fast paced environment Proven ability to extract and transform data via Python (required), Ruby, PHP or other programming languages Deep understanding of distributed systems Strong skill set in ETL (Extraction, Transformation & Load) and data modeling Familiarity with Apache Airflow and real-time processing frameworks Experience working with API’s to collect and ingest data Ability to write, analyze, and debug SQL queries in any relational database (MySQL, Oracle, Redshift, etc.) Familiarity with AWS Cloud solutions Machine learning or Predictive Modeling experience is a plus Familiarity with BI tools (Tableau, Crystal Reports, Looker, etc.) is a plus Ability to effectively collaborate with teams across all areas of the business Strong written and verbal communication skills Ability to communicate effectively with non IT users Hungry to dive in and learn new tools and keep up to date on the latest industry advancements Exceptional problem solving and analytical skills In addition, you must embody our company values-practicing the Golden Rule, taking Ownership, and driving and embracing Innovation. Please submit a letter of interest with your application. CustomInk, LLC (""""Custom Ink"""") is an Equal Opportunity Employer. We celebrate diversity in all forms and are committed to maintaining a discrimination-free workplace that treats applicants and employees with dignity and respect. Our employment process is conducted without regard to race, color, religion, nationality or ethnic background, sex, pregnancy, sexual orientation, gender identity or expression, age, disability, protected veteran status, genetic information, or other attributes protected by state, federal, and local law. Custom Ink uses E-Verify to confirm the employment eligibility of all new team members. To learn more about E-Verify, including your rights and responsibilities, please click here . Read about our commitment to the safety of our team members during COVID-19 here ."
Data Engineer,SunPower,"Austin, TX+1 location",https://www.indeed.com/rc/clk?jk=f7251492971482f2&fccid=e145a4204aee6fa7&vjs=3,"Do you want to change the world? We do, too. Solar penetration is less than 1%, but just one hour of sunlight, if harnessed, could power the entire world for a year. We have the opportunity to change the way energy is produced, distributed and consumed, and we’re looking for talented, committed people to help us drive our growth and achieve our goals. SunPower is a solar energy solutions company with a rich heritage of pioneering the best solar technologies in the world. Our solutions are unrivaled in terms of long-term reliability, efficiency, and performance. SunPower offers the only solar + storage solution designed and warranted by one company that gives customers control over electricity consumption. Through design, installation, maintenance, and monitoring, SunPower provides its world-class solar solutions to residential and commercial customers across the U.S. SunPower is changing the way our world is powered every day with a brilliant, passionate, and driven team of more than 2,500 in North America and the Philippines. In an industry that is reshaping the world’s energy future, there’s no better place to be than SunPower. We believe that our employees create our brand – with each project, each communication, each task completed and each interaction. SunPower welcomes the forward thinkers, the future savers of the world, the freedom chasers and all those demanding better, cleaner energy. SunPower Customer Care team is looking for an outstanding Data Engineer who is data-driven, uncompromisingly detail-oriented, smart, efficient, and driven to help our business succeed. You have a passion for technology. You are keen to leverage existing skills while trying new approaches. You are not tool-centric; you determine what technology works best for the problem at hand and apply it accordingly. You can explain complex concepts to your non-technical customers in simple terms. As a Data Engineer, you will be working to build foundational data to enable the highest levels of customer experience. You will design, implement and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, design data infrastructure, build up data pipelines and data sets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate. Your major responsibilities will include (but not limited to): Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and other programming languages such as Python/Java. Designing and implementing the data warehouse and subsequent maintenance. Design and implement tools and infrastructure to enable teams to consume and analyze data faster. Explore and learn the latest technologies to provide new capabilities and increase efficiencies. Deploy and utilize data validation and quality correction methodologies Designing and implementing complex ETL pipelines and other BI solutions. Work closely with business owners, developers, and Business Intelligence Engineers to explore new data sources and deliver the data. Basic Qualifications Bachelor's degree in Computer Science, Engineering, Mathematics, or a related technical discipline 5 to 8 years of industry experience in Data Engineering, BI Engineer, or related field or equivalent combination of education and experience Track record of manipulating, processing, and extracting value from data Hands-on experience and advanced knowledge of Database administration, SQL, Task Scheduling etc. Hands-on experience in distributed data processing, Data Modeling, ETL Development, and Data Warehousing Preferred Qualifications Masters in computer science, mathematics, statistics, economics, or other quantitative fields. 8 or more years of experience as a Data Engineer, BI Engineer or related field in a company with large, complex data sources. Experience working with cloud and big data technologies Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy. Familiarity with solving data quality issues and auto-detection algorithms Equal Employment Opportunity The Company is an equal employment opportunity employer and makes employment decisions, including but not limited to, hiring, firing, promotion, demotion, training, and/or compensation, on the basis of merit. Employment decisions are based on an individual’s qualifications as they relate to the job under consideration. The Company’s policy prohibits unlawful discrimination based on sex (which includes pregnancy, childbirth, breastfeeding, or related medical conditions, the actual sex of the individual, or the gender identity or gender expression), race, color, religion, including religious dress practices and religious grooming practices, sexual orientation, national origin, ancestry, citizenship, marital status, familial status, age, physical disability, mental disability, medical condition, genetic information, protected veteran or military status, or any other consideration made unlawful by federal, state or local laws, ordinances, or regulations. The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company and prohibits unlawful discrimination by any employee of the Company, including supervisors and co-workers. EOE Minorities/Females/Protected Veterans/Disabled SunPower Supports EEO Accommodation for Applicants to SunPower Corporation SunPower Corporation is an Equal Employment Opportunity / Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need a reasonable accommodation due to a disability, you may use the following alternative email address to contact us about your interest in employment at SunPower Corporation: jobs@sunpower.com. Please indicate in the subject that line of your email that you are requesting accommodation. Only candidates being considered for a position who require an accommodation will receive a follow-up response. NOTICE TO ALL APPLICANTS AND EMPLOYEES Availability of Affirmative Action Plan for Review SunPower is a federal government contractor. As a part of the Company’s obligations under law, it must develop a written Affirmative Action Program (AAP) for the Disabled, Recently Separated Veterans, Armed Forces Service Medal Veterans, Disabled Veterans and Active Duty Wartime Or Campaign Badge Veterans and for Women and Minorities as specified by law. Non-confidential and non-proprietary aspects of the AAP are available for inspection by applicants and employees, consistent with applicable law, which will be made available during office hours by contacting the EEO Officer."
Sr. Data Engineer,"RE/MAX, LLC",Remote,https://www.indeed.com/rc/clk?jk=aaba164c2825e1ea&fccid=8c5e75d52bdc1416&vjs=3,"A Data Engineer at RE/MAX works on our data ingestion platform which collects data from 500+ sources in near real time. A typical day for this role would be working with stake holders, designing, creating or troubleshooting data pipelines, analyzing data trends, and optimizing data retrieval. We manage the backend platform that powers remax.com, mobile apps, machine learning apps, BI tools and more. Our day to day tasks and projects support our staff and business needs from top to bottom. RE/MAX, LLC is looking for a Data Expert and software developer to support our microservices and database backend. This Data Engineer role will ensure the solutions are optimized for delivering critical data in a highly availability, real time environment. The Data Engineer will create, maintain and enhance data pipelines and APIs with an enterprise micro-services lens. Success in this role is bridging the demand for integration with the best fit solution for all stakeholders. This role will also work with the data aggregation team to map data from MLS boards to a common schema. Essential Duties: Develop data ingestion and pipeline solutions from business and technical data requirements Support existing integrations and API solutions that power our Elasticsearch database Map and maintain MLS board data feeds Build and foster strong relationships with all levels of technical and non-technical audiences Work effectively and collaboratively with internal and external stakeholders to ensure timely delivery of implementation Enhance data integration services for the overall benefit of sustainability and usability Address problems, change, and/or challenges quickly and enthusiastically Qualifications & Skills: Experience with data ingestion and data warehousing at scale Experience building and maintaining distributed microservice architecture Fluent in Go programming language Experience with AWS Preferred Real Estate background, managing IDX, IDX plus and VOW data feeds Experience with async NodeJS a plus Experience with Elasticsearch or other NoSQL datastore Demonstrate work ethic based on a strong desire to exceed Highly self-motivated and directed, with keen attention to detail Proven analytical and creative problem-solving abilities Experience working in an Agile environment Hire Range/Rate: $105,000 - $115,000 Actual compensation offered to candidate will be finalized at offer and may be above or below the posted range due to skill level, experience, industry specific knowledge, education/certifications, or geographic location. The offer rate represents one component of the RE/MAX Holdings total compensation package. Employees will also receive a number of benefits as listed below. Other compensation for this position may include bonus eligibility. Benefits Offered Competitive medical, dental and vision benefits 401(k) and Roth 401(k) retirement plans with optional company match Health savings account with a company contribution Flexible spending accounts (medical, dependent care and transportation) Company-paid maternity, adoption, foster and parental leave Educational assistance Student Loan Support Services Paid employee assistance program At least 7 paid holidays, and potential for up to 15, including discretionary early closures before holidays and company events. (More than your average company!) MORE Time Away Program gives employees flexibility around time off needs and lets employees take time off as they need it, rather than waiting for accruals ClassPass discount and monthly subsidy Free covered garage parking (car chargers and bike racks available) And More! Now is your chance to become part of a world-class, industry leading organization that touts the #1 real estate brand in the world! RE/MAX is a business that builds businesses. We, alongside booj, our award-winning technology company, specialize in providing the tools, training and tech to our real estate network, which includes RE/MAX and Motto Mortgage franchises, agents, brokers and consumers. Join us and build a career where your contribution is heard, your innovative ideas are valued, and hard work and collaboration truly makes a difference. RE/MAX LLC, Motto Mortgage, booj, First.io, welmo and Gadberry Group are an equal opportunity employer committed to diversity and inclusion, as well as non-discrimination in employment. All qualified applicants receive consideration without regard to race, color, religion, gender, sexual orientation, national origin, age, veteran status, disability unrelated to performing the essential task of the job or other legally protected categories. All persons shall be afforded equal employment opportunity."
Data Quality Engineer,Health Catalyst,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=5c4e652d13338322&fccid=d7d403f3184c0ee9&vjs=3,"Our mission is to be the catalyst for massive, measurable, data-informed healthcare improvement through: Data: integrate data in a flexible, open & scalable platform to power healthcare’s digital transformation Analytics: deliver analytic applications & services that generate insight on how to measurably improve Expertise: provide clinical, financial & operational experts who enable & accelerate improvement Engagement: attract, develop and retain world-class team members by being a best place to work Role: Data Quality Engineer Team: Data Quality & Operations Location: US Remote Travel: <5%, US Job Summary The Data Quality & Operations team is responsible for ensuring and demonstrating are fit for purpose and reliable after implementation. The team does this by providing specialized experienced around data quality verification, validation, monitoring, and support, both when issues arise and through proactive analysis and maintenance. The Data Quality Engineer role combines data engineering and analytic skills with a sound understanding of the Data Operating System (DOS) and our specific data products to identify the root cause of ETL and data quality issues, propose and implement solutions, and escalate to and collaborate with the implementation and development team as required. This role will also conduct cross-client impact analysis, identify patterns for repeat issues, propose proactive maintenance, build/enhance tools to scale subject matter expertise, train others on data quality concepts and solutions, and continually improve the team’s knowledge base. What you'll own: Leverage Data Quality Central and other Health Catalyst software to verify, validate, and monitor the data pipeline for data quality issues and degradation. Log issues and provide detailed issue tracking and status updates using Jira Support Desk ticketing system. Conduct root cause analysis ETL performance and data quality issues. Identify and propose scalable solutions to issues, including impact analysis and preventative maintenance proposals. Update data pipeline knowledge base in run book with details around client environment nuances, root cause, solution, troubleshooting steps, and ways to determine things are correct. Escalate issues and bug fixes to the development team to ensure that they are aware of all systemic issues and can integrate solutions into code base. Train and consult with 24x7 ETL support, DOS Operations, and implementation teams to ensure the knowledge base is comprehensive and promotes their ability to independently troubleshoot and implement solutions and understand nuanced situations that require different approaches. Provide training on data quality concepts to facilitate higher quality development and implementation across the DOS platform and client environments. What you bring: Intermediate level in Structured Query Language (SQL). Experience working with Azure DevOps. Experience working with SQL Server. Experience identifying configuration or data quality gaps/issues and writing checks to facilitate validation and monitoring that covers the gap. Demonstrated ability and desire to provide excellent and proactive customer service. Demonstrated ability and desire to communicate, collaborate, and work within and across teams. Demonstrated ability to quickly understand and explain why something does/does not work and then identify scalable opportunities to improve. Demonstrated ability and desire to efficiently learn and effectively leverage new concepts, skills, and technologies; and willingness to ask for help when needed. Desire to specialize and become an expert in performance, data quality, and the interaction between the data pipeline and DOS. Lives the Health Catalyst Way attributes of smart, hard-working, and humble. Experience implementing or working with Health Catalyst tools or data products. Passionately believes that both timely AND correct data are possible. Has a testing mindset and can think of how and why something will or will not work. Focuses on scalable and lasting solutions versus custom and one-off stopgaps. Health care data experience. Visualization experience using a variety of BI tools. Quality improvement - Lean, 6 Sigma, etc. Preferred Education & Relevant Experience BS/BA in information technology, math, statistics or business-related field or equivalent relevant work experience 5+ years’ experience in technology or technology related field Information Security and Compliance Responsibilities (This section can not be changed or modified) Maintain compliance with training directives required by the organization pertaining to Information Security, Acceptable Use Policy and HIPAA Privacy and Security. Adhere to and comply with the organizations Acceptable Use Policy. Safeguard information system assets by identifying and reporting potential and actual security events to the organizations Security and Compliance Officers. The above statements describe the general nature and level of work being performed in this job function. They are not intended to be an exhaustive list of all duties, and indeed additional responsibilities may be assigned by Health Catalyst . At Health Catalyst, we appreciate the opportunity to benefit from the diverse backgrounds and experiences of others. Because of our deep commitment to respect every individual, Health Catalyst is an equal opportunity employer."
Data Engineer,Munich Re America Services,"New York, NY+1 location",https://www.indeed.com/rc/clk?jk=21b25177005c2e06&fccid=d4448c192a012f32&vjs=3,"Data Engineer Location New York , United States Your job We’re adding to our diverse team of experts and are looking to hire those who are committed to building a culture that enables the creation of innovative solutions for our business units and clients. The Company As a member of Munich Re's US operations, we offer the financial strength and stability that comes with being part of the world's preeminent insurance and reinsurance brand. Our risk experts work together to assemble the right mix of products and services to help our clients stay competitive – from traditional reinsurance coverages, to niche and specialty reinsurance and insurance products. The Opportunity Future focused and always one step ahead This is the rare opportunity to join an extraordinary team of people on an exceptional mission. You will become a member of the Munich Engine team, a successful innovation initiative of Munich Re which got spun-out into a business unit and which is building the next generation digital underwriting engine. The team you join has a start-up entrepreneurial culture but operates within a large, high profile global company - the world’s leading reinsurance company. Key Responsibilities of this position include: Build and Maintain Munich Engine’s Data/ML Platform Build and maintain robust scalable data processing pipelines in Microsoft Azure Optimize data ingestion process for better reliability and throughput Design and develop data models for analytics Work with various complex data sources at various levels of granularity and deliver high-quality data Drive data architecture design decisions considering future growth Work closely with actuaries and data scientists to understand their objectives and translate to ensure architectural fit Own features from design through delivery with ongoing support Communicating effectively across diverse disciplines(with Product Management, Data Science, Actuarial, etc) to collect requirements. Experience providing clear data engineering technical leadership, mentoring, and best practices for data management and quality within and across teams. Develop expert knowledge of data and analytics infrastructure within Munich Re Implement processes and technology to monitor and improve data quality At Munich Re US, we see Diversity and Inclusion as a solution to the challenges and opportunities all around us. Our goal is to foster an inclusive culture and build a workforce that reflects the customers we serve and the communities in which we live and work. We strive to provide a workplace where all of our colleagues feel respected, valued and empowered to achieve their very best every day. We recruit and develop talent with a focus on providing our customers the most innovative products and services. We are an equal opportunity employer. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Your profile Successful candidates should possess the following skills/capabilities: Bachelor's degree (MS preferred) in Computer Science, Statistics, Math or equivalent combination of education and experience 5+ years of experience with data modeling, data processing, and data analytics as data engineer 5+ years of hands-on Python and SQL experience required Experience in P&C insurance industry (preferred experience working with insurance homeowner data) Expert Data Model skills on designing and building models for semi-structured, relational, graph data Expert SQL skills including T-SQL, Hive, Spark SQL, etc Expert Knowledge in database technologies such as Postgres, SQL Server, MySQL, MongoDB, Azure CosmosDB Experience in data pipeline development using Azure Data Factory, T-SQL, PySpark, Airflow, etc. Experience with data visualization tools such as Power BI 3+ yeas of hands-on Microsoft Azure experience highly preferred Drive and dedication, as well as creativity and hands-on attitude Curiosity in searching for new solutions outside of traditional approaches Demonstrated ability to experiment with and learn new technologies Strong oral and written communication and interpersonal skills Excellent analytical, problem solving and organizational skill At Munich Re US, we see Diversity and Inclusion as a solution to the challenges and opportunities all around us. Our goal is to foster an inclusive culture and build a workforce that reflects the customers we serve and the communities in which we live and work. We strive to provide a workplace where all of our colleagues feel respected, valued and empowered to achieve their very best every day. We recruit and develop talent with a focus on providing our customers the most innovative products and services. We are an equal opportunity employer. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. About us Munich Re America Services, Inc. is a services provider to affiliated group companies primarily related to general services, procurement and IT services. Apply now!"
Data Platform Engineer- Experimentation Platform,Stitch Fix,+3 locationsRemote,https://www.indeed.com/rc/clk?jk=388be1e32ddaa265&fccid=1c70eede37c5caee&vjs=3,"We’re a team of bright, kind individuals who are motivated by challenge and who care deeply about achieving great things. We know our individual strengths, but believe we only win as a team. We’re transforming the way people find what they love - and we need your big ideas. We just might be the perfect fit. ABOUT STITCH FIX Stitch Fix is the world’s leading online personal styling service, combining data science and human judgment to deliver apparel, shoes, and accessories personalized to our clients’ unique tastes, lifestyles, and budgets. Over the last 10 years, Stitch Fix has delighted customers with convenient styling services by integrating the power of data science together with human stylists to help them build a wardrobe that fits their style so they look and feel their best. The company recently expanded its experience beyond the personal styling experience delivered via fixes by adding new offerings including a direct shopping experience in a personalized feed. This new shopping feed represents the beginning of a new chapter for the company, and delivers a superior shopping experience by presenting shoppers with items that fit them and their style. We envision a future in which we continue to disrupt traditional models by leveraging our stylists and our data science capabilities to delight customers in new ways with enhancements. ABOUT THE TEAM We are senior, high-performing engineers and data scientists who value collaborative work and learning. Our work and expertise is highly sought after. Our culture is something we practice daily and strive to constantly improve. Our goal as the Experimentation Platform team is to empower our experimenters to improve their rate of innovation through the scientific study of our clients’ behaviors. Our platform is key in driving rapid iteration through the test and learn cycle. We ship work that is highly visible and impactful across the company. We believe that diverse teams are better than the sum of their parts. We encourage people from all identities, backgrounds, and experiences to apply! ABOUT THE ROLE We’re looking for a data platform engineer to help us design and implement world class experimentation techniques at scale with a focus on quality, reliability, and stability. In this role, you will participate in all phases of software development, from the design and architecting stage through implementation and ongoing support. You’ll build robust pipelines that take advantage of Postgres, DynamoDB, Redis, and S3. This role is highly cross functional and you will enjoy getting to know our partners across all areas of the business. It is an exciting time to join as we are reimagining our experimentation user experience and driving forward to implement new use cases and onboard new experimenters! A few of the things our team is thinking about: automating new use cases as our business grows, improving on our implementation of adaptive experimentation (e.g., multi-armed bandits), the creation of tools that empower our experimenters to plan, learn from, and iterate on experiments faster, the identification of interfering experiments, and creating lasting knowledge from the learnings we generate. MINIMUM QUALIFICATIONS Strong programming and design background. Expertise in Python and/or Go preferred. Experience with microservices and/or building ETLs. Experience designing public APIs (in a language and/or REST). Experience and comfort building on top of AWS. Experience working with experimentation or other relevant services. Knowledge or interest in statistics. You have good problem-solving skills and can help triage operational issues, proactively working to eliminate repetitive or manual tasks. Experience writing clear technical documentation and teaching people how to use the tools you build. PREFERRED QUALIFICATIONS Experience working with Data Scientists would be helpful. Customer empathy; you are curious about the challenges our experimenters face and are excited about building tools that help make your colleagues’ work easier and better! Some UX development exposure. An interest in sharing work externally (e.g., conferences, tech blogs). WHY YOU’LL LOVE WORKING AT STITCH FIX: We are a group of people who are bright, kind and motivated by challenge. You can be your authentic self here, and are empowered to encourage others to do the same! We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation. We are a technologically and data-driven business. We are committed to our clients and connected through our vision of “Transforming the way people find what they love.” We love solving problems, thinking creatively and trying new things. We believe in autonomy & taking initiative. We are challenged, developed and have meaningful impact. We take what we do seriously. We don’t take ourselves seriously. We have a smart, experienced leadership team that wants to do it right & is open to new ideas. We offer competitive compensation packages and comprehensive health benefits. You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day."
Off-Road App and Performance Data Recorder Systems Engineer,General Motors,Remote,https://www.indeed.com/rc/clk?jk=1784a81c3df296f6&fccid=116680a29a847a70&vjs=3,"Job Description About GM We're dedicated to achieving our vision of a world with Zero Crashes, Zero Emissions and Zero Congestion. We are looking for people who are passionate about helping us create safer, better and more sustainable solutions for personal mobility. Our bold vision won't happen overnight, but just as we transformed how the world moved in the last century, we are committed to transforming how we move today and in the future. Why Work for Us Our culture is focused on building inclusive teams, where differences and unique perspectives are embraced so you can contribute to your fullest potential as you pursue your career. Our locations feature a variety of work environments, including open work spaces and virtual connection platforms to inspire productivity and flexible collaboration. And we are proud to support our employees volunteer interests, and make it a priority to join together in efforts that give back to our communities Remote: This position does not require employee to be on-site full-time to perform most effectively. Are you interested in being a part of a team that is redefining how we interact with our vehicles today? Our Software Defined Vehicle (SDV) is reimagining our vehicle intelligence platform! This platform, Ultifi, will help enable the frequent and seamless delivery of software-defined features, apps and services to customers over the air! It offers the potential for more cloud-based services, faster software development and new opportunities to increase customer loyalty. This position will be a technical leader for requirements and design development for Off-Road App, Performance Data Recorder and related functions. The candidate will be responsible for the end-to-end implementation of the said features. They will support developing the strategy and execution of capabilities in the infotainment domain as it combines with other domains to deliver solutions for Off-Road App and PDR. They must comprehend the interfaces and interactions between in-vehicle systems, consumer devices (via connectivity technologies such as BLe, BT, Wi-Fi, etc.), GM back office and other cloud service environments, at a minimum. They will work with various multi-functional teams to drive and meet the program milestones. They will be the single point contact for the execution of the set of features from inception to launch. The utilization of 'systems level thinking' will be key in this role. Key Responsibilities: Lead multi-functional, E2E Feature Development Teams and necessary architecture changes, ensuring both changes inside & outside of Infotainment and Telematics area are completed Support creation of Feature Context Diagrams and Data Flow Diagrams Maintain System Technical Specification, Sub-System Technical Specification, and lower-level Design Element/Functional Module Specifications Allocate requirements to necessary systems, sub-systems, design elements/functional modules and components to deliver feature Provide System Modelling Tool Requirements Support documentation of Feature Requirements, including Performance Requirements Support the Feature Owner/Value Stream lead in working with the business team, program teams, and other technical teams to develop and scope new product offerings, ensuring a strategic approach is in place and the connected car technologies are maximized appropriately Support ATW Plan for Feature / Approve New Feature Content in support of feature backlog/roadmap development. Provide technical leadership for advanced technology development Provide regular and key updates to leadership and team leaders to ensure synchronization and smooth flow of information Support PI Planning sessions and issue resolution as needed from validation, service teams, CTF reports, feature checkout events, buy off rides Support agile development team with clarifications on functional and/or performance intent throughout the development lifecycle Support Feature Set & Sizing Recommendations Complete and/or support Feature FMEA and System FMEA/Fault Tree Analysis Perform and/or support integration testing Stays abreast of new technology and competitive products Additional Job Description Basic Qualifications: Bachelor of Science degree in Electrical Engineering, Software Engineering, Computer Science or related technical degree Minimum of 3 years of experience in software development, engineering design of consumer devices or automotive engineering Experience with prototyping Demonstrated knowledge of In-vehicle consumer device connectivity & communications, connected vehicle services and infotainment/telematics systems engineering & related communication protocols Demonstrated knowledge of vehicle electrical architectures, body control or other integration control modules & in-vehicle networking protocols such as Ethernet and CAN Understanding of system engineering principles/theory and principles of operation of mechanical/electrical mechanisms Demonstrated leader of cross-functional teams Strong leadership, organizational, analytical, interpersonal and communications (oral & written) skills Preferred Qualifications: MS in Electrical or Computer Engineering 5 years engineering experience Electrical systems experience preferred in following domains: infotainment/telematics, chassis, powertrain, and HVAC Compensation: The compensation information is a good faith estimate only. It is based on what a successful Colorado applicant might be paid in accordance with Colorado law. The compensation may not be representative for positions located outside of Colorado. The median level of salary compensation for this role is $113,760-$126,756 Bonus Potential: An incentive pay program offers payouts based on company performance, job level, and individual performance. Benefits: Benefits: GM offers a variety of health and wellbeing benefit programs. Benefit options include medical, dental, vision, Health Savings Account, Flexible Spending Accounts, retirement savings plan, sickness and accident benefits, life insurance, paid vacation & holidays, tuition assistance programs, employee assistance program, GM vehicle discounts and more. #LI-Remote FOR GM INTERNAL CANDIDATES: This role is posted at both the 6th and 7th level. The determination by HR and the Hiring Manager as to whether an offer will be lateral or promotional will be based on a candidate's relevant experience and whether the role will amount to a significant increase in level of responsibility. The policy of General Motors is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity/expression or veteran status. Additionally, General Motors is committed to being an Equal Employment Opportunity Employer and offers opportunities to all job seekers including individuals with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, email us at Careers.Accommodations@GM.com In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying. About GM Our vision is a world with Zero Crashes, Zero Emissions and Zero Congestion and we embrace the responsibility to lead the change that will make our world better, safer and more equitable for all. Why Join Us We aspire to be the most inclusive company in the world. We believe we all must make a choice every day - individually and collectively - to drive meaningful change through our words, our deeds and our culture. Our Work Appropriately philosophy supports our foundation of inclusion and provides employees the flexibility to work where they can have the greatest impact on achieving our goals, dependent on role needs. Every day, we want every employee, no matter their background, ethnicity, preferences, or location, to feel they belong to one General Motors team. Benefits Overview The goal of the General Motors total rewards program is to support the health and well-being of you and your family. Our comprehensive compensation plan incudes, the following benefits, in addition to many others: Paid time off including vacation days, holidays, and parental leave for mothers, fathers and adoptive parents; Healthcare (including a triple tax advantaged health savings account and wellness incentive), dental, vision and life insurance plans to cover you and your family; Company and matching contributions to 401K savings plan to help you save for retirement; Global recognition program for peers and leaders to recognize and be recognized for results and behaviors that reflect our company values; Tuition assistance and student loan refinancing; Discount on GM vehicles for you, your family and friends. Diversity Information General Motors is committed to being a workplace that is not only free of discrimination, but one that genuinely fosters inclusion and belonging. We strongly believe that workforce diversity creates an environment in which our employees can thrive and develop better products for our customers. We understand and embrace the variety through which people gain experiences whether through professional, personal, educational, or volunteer opportunities.GM is proud to be an equal opportunity employer. We encourage interested candidates to review the key responsibilities and qualifications and apply for any positions that match your skills and capabilities. Equal Employment Opportunity Statements The policy of General Motors is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity/expression or veteran status. Additionally, General Motors is committed to being an Equal Employment Opportunity (EEO) Employer and offers opportunities to all job seekers including individuals with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, email us atCareers.Accommodations@GM.com or call us at800-865-7580. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying."
Associate Data Engineer,Charles Schwab,"Hybrid remote in Westlake, TX+5 locations",https://www.indeed.com/rc/clk?jk=eb37aa63c1104a79&fccid=3c74eafe288fc8ca&vjs=3,"Your Opportunity Do you want to be part of a team handling over 120 terabytes of data and building the next generation analytics platform for a leading financial firm? At Schwab, the Data and Rep Technology (DaRT) organization governs the strategy and implementation of the enterprise data warehouse and emerging data platforms. We help Sales, Marketing, Finance and executive leadership make fact-based decisions by integrating and analyzing data. We are looking for a Data Warehouse Analyst / ETL Lead with a passion for data and a desire to excel with an amazing team. This award-winning comprehensive full time role is a part of the nine-month NERD (New Employee Recruitment and Development) program that blends on-the-job experience with an extensive training curriculum that covers tools, technologies, processes and soft skills required to be successful in Schwab Technology Services for new college graduates. NERDs have a manager, a mentor, a buddy, a coach, and others who are dedicated to their success. Workplace Flexibility Program: We're proud to support our employees in a working approach that allows you to bring your best self to work – whether that’s in the office or remote. Most Schwabbies have the opportunity to voluntarily work in the office or at home based on their preference, through the remainder of 2021.* When the firm is ready to fully return to the office, employees will have the flexibility of a hybrid work environment, spending some time working remote and some time in the office. Employees and managers can discuss and decide what works best for them, with additional flexibility available based on their role, business needs, and individual circumstances. Subject to change as Schwab is continually evaluating the current environment in order to best care for the safety and well-being of our employees. What you are good at You will be a developer working with a large team that includes onshore and offshore developers using best-in-class technologies including Teradata, Informatica and Hadoop. You'll be responsible for the design, development and implementation of enterprise data integration solutions. You’ll have the opportunity to grow in responsibility, work on exciting and challenging projects, train on emerging technologies and work with other Developers to set the future of the Data Warehouse. Your detailed duties would include: Creating/updating ETL specifications and supporting documentation Developing ETL logic utilizing Informatica workflows, scripting and load utilities Building and maintaining code for big data ingestion using Talend, Scoop, Hive etc Implementing data flow scripts using Unix / Sqoop / Hive QL / Pig scripting Designing, building and support data processing pipelines to transform data in Big Data or Teradata platforms Developing and executing quality assurance and test scripts Work with business analysts to understand business requirements and use cases Problem solving and fixing technical issues Working with technical lead and offshore development teams to ensure proper and efficient implementation of requirements What you have Currently enrolled in an undergraduate or graduate degree program in Computer Science, Management Information Systems, or related discipline with a graduation date of May 2022 or earlier. Ability to start full time with the program on June 13th, 2022 Experience with algorithm design Basic understanding of object-oriented analysis and design Experience with data structures Understanding of Java or C# development Familiarity with Data Engineering, ETL, Hadoop, and MongoDB is a plus Database modeling is a plus Inventiveness and eagerness to work with experimental technology is a must! Demonstrated Leadership Potential Passion and aptitude for solving problems utilizing Innovation and Experimentation What you will get out of the program: A full time Associate Software Developer position with benefits, paid time off, and all of the other perks of being a Schwabbie! Professional Growth - Technical and soft skills curriculum designed to accelerate your career. Hands-on Experience - Cross-functional experience and skills gained from on-the-job assignments. Knowledge Sharing - Opportunity to share and present ideas around innovation. Presentation Opportunities - Strengthen existing presentation and communication skills. Individual Coaching - One-on-one coaching and real-time development from host team. Exposure to Leadership - Experiences with leaders across Schwab Technology Services. Peer-to-peer interaction - Share ideas and experiences and as you grow alongside a cohort of peers. Why work for us? Own Your Tomorrow embodies everything we do! We are committed to helping our employees ignite their potential and achieve their dreams. Our employees get to play a central role in reinventing a multi-trillion-dollar industry, creating a better, more modern way to build and manage wealth. Benefits: A competitive and flexible package designed to empower you for today and tomorrow. We offer a competitive and flexible package designed to help you make the most of your life at work and at home—today and in the future. Explore further. Schwab is committed to building a diverse and inclusive workplace where everyone feels valued. As an Equal Opportunity Employer, our policy is to provide equal employment opportunities to all employees and applicants without regard to any status that is protected by law. Please click here to see the policy. Schwab is an affirmative action employer, focused on advancing women, racial and ethnic minorities, veterans, and individuals with disabilities in the workplace. If you have a disability and require reasonable accommodations in the application process, contact Human Resources at applicantaccessibility@schwab.com or call 800-275-1281. TD Ameritrade, a subsidiary of Charles Schwab, is an Equal Opportunity Employer. At TD Ameritrade we believe People Matter. We value diversity and believe that it goes beyond all protected classes, thoughts, ideas, and perspectives."
Data Integration Engineer Ascent,Bowman Dispensers,"Caledonia, MI 49316",https://www.indeed.com/rc/clk?jk=ebc4cde9b28beb81&fccid=a3a9aef058f26803&vjs=3,"DATE INTEGRATION ENGINEER Job Description ABOUT THE COMPANY Ascent Brands is a market leading healthcare solutions organization specializing in the design, manufacturing and sourcing of private label products. It’s our mission to provide our healthcare partners timely solutions with a straightforward approach based on knowing them and their work. Every day we strive to positively impact the lives of the people who in turn impact the health and wellness of our communities. Based in Grand Rapids, Michigan, Ascent Brands’ success is built upon a foundation of collaboration, innovation, and the belief that every team member plays a vital role in creating an exceptional customer service experience. ABOUT THE POSITION The Data Integration Engineer builds and ensures automated transactions with Trading Partners are reliable by developing, programming, monitoring, and maintaining relevant code and systems. Tasks will be accomplished by working closely with trading partners, cross-functional team members, and IT colleagues. RESPONSIBILITIES AND DUTIES Manages all aspects of EDI; code writing, mapping, and use of established protocols to respond to problems or failures and provide solutions to users Partners and manages resources with third party EDI platform providers and partners Coordinates internally with business stakeholders and cross functional team members to determine best process for business needs and translating into technical outcomes Maintains AS2 system for sending and receiving documents with trading partners Maintains business-to-business connections and interface with cross-functional team members to design, test, and monitor data transactions and performance Prepares data maps and workflows; write, test, and deploy programs for data transformation. Develops and maintains user-level and technical requirements and data specifications Communicates proactively with data consumers to improve performance of processes connecting to data. Builds data models, following enterprise architectural standards and designs. Leads data cleansing and profiling efforts. Pursues opportunities to grow business acumen and skills from more experienced team members. Provides coaching to less experienced team members Able to interpret process performance outputs and improve workflow performance for affected jobs. Demonstrated ability to prioritize competing tasks and workloads EDUCATION AND EXPERIENCE Bachelor’s degree in Computer Science, Information Systems or related discipline; or minimum 4 years relevant work experience. Experience in demonstrating informal leadership skills. Strong knowledge of database application and data query protocol (MS SQL Server, Transact-SQL). Strong functional experience with office productivity software Minimum 5 years of relevant experience with EDI format and communication standards, including but not limited to: ANSI X12, EDIFACT, AS2, SFTP, VAN, HTTPS. Experience working with APIs (SOAP, REST, Web Service) strongly preferred Experience with EDI development in distribution environment, from both customer and supply chain perspectives Minimum 3 years of experience with data integration partners and platforms (TrueCommerce, SPS Commerce, Cleo, Amazon Web Services, etc.) Ability to develop and maintain project plans and timelines when working with internal and external stakeholders Experience in scripting and automation (Python, Bash, csh, ssh, etc.). Familiarity with modern source/version control tools (Git, TFS, CodeCommit, Subversion). Familiarity with various raw data source types and how to interpret them. (Unstructured, JSON/BSON, Flat files, XML, etc.). Strong understanding of business processes, ERP, and warehouse management systems COMPETENCIES Problem Solving - the individual identifies and resolves problems in a timely manner and gathers and analyzes information skillfully. Follow Through – Builds due dates into assignments and task delegations; prioritizes and plans work activities, effectively manages obligations / work tasks to ensure expected results and realistic action plans. Holds self and others accountable to meeting targets. Confirms that actions agreed upon have been taken. Communication - The individual communicates effectively both verbally and in writing with superiors, colleagues, and individuals inside and outside the Company. Professionalism – Demonstrates a professional, confident and positive presence. Speaks with a self-assured tone of voice and maintains an enthusiastic demeanor. Teamwork - Conveys passion and rallies team members when challenged with a difficult goal. Keeps focused and on track and resolves any interpersonal issues arising that may jeopardize team success. Prompts others to contribute knowledge and information to assist the team."
Senior Data Engineer,EvolutionIQ,Remote,https://www.indeed.com/rc/clk?jk=d5a13b65fd856ec6&fccid=cfbc2963963231b6&vjs=3,"About EvolutionIQ Our mission is to harness the power of AI to transform the insurance industry, maximizing the best claim outcome for the carrier, the client and the claimant. Our AI and ML platform delivers a 10x+ ROI to our clients. The company 20Xed in value over the past few years and we’re continuing to grow. To date we’ve raised $20 million at a $160K+ valuation. We're founded by a senior Google AI expert and an algorithmic investor who previously worked at Bridgewater Associates. We were also recently named to Inc.’s Best Places to work! We have an office in NYC, but are very remote friendly. About you… You are a Data engineer/scientist with a minimum of 5+ years of experience, especially in highly scalable, application development environments You have 3+ years experience in deploying systems on GCP or AWS You know the critical questions to ask in order to understand a client’s pain points around data transformation, automated ETLing, and standardization of classification exercises You have deep exposure to ETL, data modeling, Python/Pandas data frameworks, and scalable technical concepts/solutions You’re a team player who is solutions oriented You have demonstrated the ability to effectively communicate through written and verbal communication We are looking for someone who… Implemented Data platform used for building and shipping multiple products Owned, deployed and maintained ETL pipelines in production Expert developer who writes clean, efficient, easy to understand code with unit tests, functional design patterns Excellent technical document writing skills Creativity and resourcefulness, appetite to solve previously unsolved problems Exudes our ambitious, collaborative, and empathetic values Self-starter mentality with an eagerness to solve previously unsolved problems Can effectively correspond between technical and non-technical audiences Open to giving and receiving critical feedback and collaborating effectively across teams The Adventure The $1.3 trillion insurance industry represents one of the largest single, untapped, complex, and meaningful data systems remaining in the world that has not yet had artificial intelligence applied to it at scale. At EvolutionIQ, we are bringing together world-class technical talent who want to invent, solve, and create in an entirely new technology category. For our experts in machine learning, data science, applications, and technology integration, cracking the insurance industry’s previously ‘impossible’ big data problem with deep learning AI is our version of summiting K2 or Everest. Your Impact We are looking for ambitious Senior Data Engineer focused on Data ingestion, automated data transformation/standardization, and platform development/improvements to join our growing team of Evolutioneers. Our teams are tackling challenges to modernize claims management atop a powerful AI backend, requiring sound technical judgment. In this role you will: Work with Analytics and ML Engineers to map workflows to a scalable platform Setup a reliable continuous model deployment infrastructure Setup centralized data storage to support ease of data access and EDA Setup reliable and secure client data ingestion Refactor core algorithms for improve efficiency, readability and test coverage EvolutionIQ is dedicated to attracting, motivating, and retaining exceptional talent from all walks of life. We believe diversity fosters equity, innovation, and engagement – allowing our teams, products, and solutions to thrive. Qualified candidates from all walks of life are encouraged to apply! Compensation The salary for this role is between $180k-200k, with some flexibility for the right candidate. This role and its responsibilities can be adjusted for more junior candidates demonstrating potential, or more senior candidates bringing more experience and expertise to the table. The final offering will depend on a variety of factors, both known and identified, throughout the interviewing process. These factors that may impact the offer may include (but are not limited) to seniority, responsibilities, projected position growth, fringe and other benefits, and overall career expectations. Benefits & Perks Well-Being – Full medical, dental, vision, short- & long-term disability, 401k matching. 100% of the employee contribution up to 3% and 50% of the next 2%. Home & Family – Flexible 100% paid parental leave (4 months for primary caregivers and 3 months for secondary caregivers), sick days, paid time off. For new parents returning to work we offer a flexible schedule. We also offer sleep training to help you and your family navigate life schedules with a newborn. Anti- burn out culture Our office closes between December 24th and New Year's Day to give all Evolutioneers time to rest and recharge for the year ahead. We also offer generous PTO + sick leave and weekly wellness time. Work/Life Balance – Work from home / work from NYC (whether you’re local to NYC or visiting us on a company-paid trip), or join us at off-site company trips (we have taken everyone to Jackson Hole and Puerto Rico in past years) Office Life – Catered lunches, happy hours, and pet-friendly office space, $500 for your in home office setup and $200/ year for upgrades every year after your initial setup Growth & Training –$1,000/year for each employee for professional development, the ability to grow as we do Join our growing team!"
Data Engineer,DocuSign,"Remote in Seattle, WA+1 location",https://www.indeed.com/rc/clk?jk=d9f9a90b3ec8718f&fccid=9dd30dd046d9ac7a&vjs=3,"Data Engineer IT, InfoSec, Cyber Risk & Business Operations | Seattle, WA and San Francisco, CA This position is not eligible for employment in the following states: Alaska, Hawaii, Maine, Mississippi, North Dakota, South Dakota, Vermont, West Virginia and Wyoming. Our agreement with employees DocuSign is committed to building trust and making the world more agreeable for our employees, customers and the communities in which we live and work. You can count on us to listen, be honest, and try our best to do what's right, every day. At DocuSign, everything is equal. We each have a responsibility to ensure every team member has an equal opportunity to succeed, to be heard, to exchange ideas openly, to build lasting relationships, and to do the work of their life. Best of all, you will be able to feel deep pride in the work you do, because your contribution helps us make the world better. And for that, you'll be loved by us, our customers, and the world in which we live. The team Our IT, InfoSec, Cyber Risk & Business Ops team - is in the business of trust and reliability. We create, maintain and operate scalable technology and data solutions that deliver an exceptional experience for our internal & external customers. We embrace Agile principles and values, favor DevOps practices, and view infrastructure as code, all while we create an infrastructure that scales and supports our growth and ambitious vision. This requires a smart, highly collaborative team who can identify, investigate, and implement new technologies to continue securely scaling our global business. This position DocuSign is seeking a talented and results oriented Data Engineer to focus on delivering trusted data to the business. As a member of the Global Data and Analytics Team, the Data Engineer leverages a variety of technologies to load, transform, and prepare data sets of all shapes and sizes for teams around the world. During a typical day, the Data Engineer will spend time analyzing data, developing solutions with ETL tools, and loading tested data sets into the Snowflake Enterprise Data Warehouse. The ideal candidate will demonstrate a positive ""can do"" attitude, a passion for learning and growing, and the drive to work hard and get the job done in a timely fashion. This Individual Contributor position provides plenty of room to grow - a mix of challenging assignments, a chance to work with a world-class team, and the opportunity to use innovative technologies such as AWS, Snowflake, and Data Lake tools. This role is an individual contributor role reporting to Business Intelligence Manager and is designated Flex. Responsibilities Work with business leaders to define requirements for data projects Develop and update a project plan/task list and keep all parties updated on progress Analyze source system APIs, data schema, and data profiles to define what is possible Define and document solution designs, with feedback from team members and technical architects Develop and own ETL data pipeline and data model solutions for integrating new data sets into Snowflake Own, monitor, and improve automated solutions to ensure quality and performance objectives are met Execute projects using Agile Scrum methodologies Identify recurring issues or ""value-add"" areas and proposes process, data, and/or systematic solutions Interface with analytics development teams to validate test results for new applications verifying that they meet the requirements of the business group Basic qualifications Bachelor's Degree in Computer Science, Data Analytics, Information Systems, or equivalent 2+ years of experience in data warehouse engineering (OLAP) Snowflake, Teradata, Redshift 2+ years of experience with transactional databases (OLTP) Oracle, SQL Server, MySQL 2+ years of experience with two or more commercial ETL tools – Informatica, Matillion, Talend, Pentaho, SSIS 2+ years delivering ETL solutions from source systems: databases, APIs, flat-files, XML, JSON 2+ years of data modeling, building dimensional schemas Preferred qualifications Proven track record developing Entity Relationship Diagrams Strong developing code in one of the following languages: python, powershell, java Good working with job scheduling and monitoring systems Strong working with an Information Security mindset and implementing Data Handling controls Expert building BI Dashboards with tools like Qlik and Power BI Expert managing work assignments using tools like Jira and Confluence Excellent written and verbal communication skills Based on Colorado law, the following details are for Colorado individuals only: Colorado base salary range: $93,700 - $128,875 and eligible for bonus, equity and benefits at https://www.docusign.com/company/benefits. Vaccination requirement DocuSign may require all employees to be fully vaccinated against COVID-19 and provide proof of vaccination to visit a DocuSign office, to meet with potential or actual customers or business partners, or for other business-related purposes, in accordance with local law. Please note that DocuSign has contracts with different governments globally which may require compliance with local and federal laws. About us DocuSign helps organizations connect and automate how they prepare, sign, act on, and manage agreements. As part of the DocuSign Agreement Cloud, DocuSign offers eSignature: the world's #1 way to sign electronically on practically any device, from almost anywhere, at any time. Today, over a million customers and hundreds of millions of users in over 180 countries use DocuSign to accelerate the process of doing business and simplify people's lives. And we help save the world's forests and embrace environmental sustainability. It's important to us that we build a talented team that is as diverse as our customers and where all employees feel a deep sense of belonging and thrive. We encourage great talent who bring a range of perspectives to apply for our open positions. DocuSign is an Equal Opportunity Employer and makes hiring decisions based on experience, skill, aptitude and a can-do approach. We will not discriminate based on race, ethnicity, color, age, sex, religion, national origin, ancestry, pregnancy, sexual orientation, gender identity, gender expression, genetic information, physical or mental disability, registered domestic partner status, caregiver status, marital status, veteran or military status, or any other legally protected category. Accommodations DocuSign provides reasonable accommodations for qualified individuals with disabilities in job application procedures, including if you have any difficulty using our online system. If you need such an accommodation, you may contact us at accommodations@docusign.com. #LI-Remote"
Data Engineer,Vectra AI,"Austin, TX",https://www.indeed.com/rc/clk?jk=82bbf85202d269a7&fccid=0189204a62bdb587&vjs=3,"Vectra® is the leader in AI-driven threat detection and response for hybrid and multi-cloud enterprises. The Vectra Platform captures packets and logs across network, public cloud, SaaS, and identity by applying patented security-led AI to surface and prioritize threats for rapid threat response. Vectra's threat detections are powered by a deep understanding of attacker methods and problem-optimized AI algorithms. Alerts uncover attacker methods in action and are correlated across customer environments to expose real attacks. Organizations around the world rely on Vectra to see and stop threats before a breach occurs. For more information, visit www.vectra.ai. Company Overview Vectra delivers a new class of real-time threat detection and response. Vectra picks up where perimeter security leaves off using AI to provide deep, continuous analysis of both internal and Internet-facing network traffic for all phases of the attack progression as attackers attempt to breach, spy, spread, and steal within networks. Vectra directly analyzes large data sets, including network traffic, in real time using a combination of proprietary data science, machine learning, and behavioral analysis to detect attacker behaviors and user anomalies in the network. All detections are algorithmically correlated and prioritized to show an attack in context and Vectra’s machine learning adapts as attacks evolve. For more details, see https://vectra.ai/how-it-works. Position Overview The Vectra Engineering team looks for people that are smart, very capable technically, and have fun solving the challenges that our customers face together as a team. We believe strongly that everyone can and should have significant impacts on the growth of the product as well as the company and our culture. We believe in using the right technology for each problem and building knowledge through mentorship and other things like peer code reviews. We're excited to find others to join the team that want to work on an interesting product that solves real problems. Detecting attackers in real-time requires a high-performance suite of software that enables machine learning and statistical techniques. This requires the processing and management of considerable volumes of data. We are looking for innovative and resourceful data engineers to join our growing team. Our data science and analytical capabilities rely on the fast, efficient flow of large volumes of data. Working in concert with our existing Data Science/Data Engineering you will assist in optimizing these flows as well as building out new data pipelines to support our growing product portfolio. Responsibilities Create, test and maintain optimal data pipeline architectures Identify and develop data set processes for data modeling, minding, and production Build the infrastructure required for optimal extraction, transformation, and loading of large data sets Spark fresh ideas that are infused in our culture and our products Leverage emerging tech and Big Data to ensure delivery of real time analytics solutions Work on complex, large-scale, group-wide big data projects Perform data analysis tasks required to troubleshoot data related issues and ultimately present optimized solutions. Interface with other groups including Product Management, UX, Security Research and Data Science to help customers simplify security Qualifications Required BS or M.S or Ph.D. in Computer Science (or equivalent experience) 6+ years in software development, data engineering, or equivalent Knowledge of software design principles and leading software development practices Strong communication & collaboration skills Willingness to get things done, learn new things, take initiative and challenge existing assumptions and conventions Experience building and deploying to any cloud service (AWS, Azure, GCP, etc.) Experience programming in any of the following (python, javascript, golang) Knowledge of the following tools (or similar): Git, Jenkins, JIRA etc. Desirable Distributed processing technologies (Spark, Presto, Impala, MapReduce etc.) Comfort in dealing with low level data storage formats (Parquet, Orc, Avro, Arrow etc.) Experience working with a geographically dispersed team Experience with grooming business-stakeholder requirements into achievable technical goals Ability to work in a collaborative environment Expertise in automated testing in addition to continuous integration and deployment tools Knowledge of networking and networking protocols (PCAP analysis, Zeek/Bro format) Knowledge of AI/Machine Learning and Cybersecurity A two-minute video that describes what we do at Vectra, and an article about Vectra's last funding round: https://vimeo.com/89579264 https://tcrn.ch/3gVAXNw"
Senior Data Engineer,Mobalytics,Remote,https://www.indeed.com/rc/clk?jk=1cf9e61d8f1b9e16&fccid=45c9e088a1e7a8cb&vjs=3,"The Mobalytics mission is to create the ultimate gaming companion, providing powerful tools that enable all players to step up their game and be their best self. In the last four years we have gone from just servicing League of Legends players to empowering players of different genres through Teamfight Tactics, Legends of Runeterra, and Valorant. We’ve achieved a lot but there is so much we can accomplish with the right talent onboard. We need razor sharp, experienced, and responsible professionals who can help us grow and evolve from a small adventurous party into a disciplined raid team who can conquer any challenge. We consider ourselves a gaming company even though we don’t make games because we work hand-in-hand with world-famous developers. We love these games and are members of the communities that make them thrive. What we do is not for the faint of heart. Working in a startup is hard, unpredictable, and demanding. Only the most passionate people thrive. Your love for video games, your expertise in your craft, attention to detail, and your dedication to a great user experience will take you far with us. As a Senior Data Engineer, the streaming platform you build will power the very core of our product. Our next strategic step is moving to a data streaming approach, which would bring our product to a new level, and you’re the one who’s gonna make it real. This position requires advanced technical depth, experience, and leadership. If you love all sorts of games and find yourself thinking about how it all fits together, then you are definitely in the right place in our cutting-edge raid. Your Technical Skill Set: Experience with technologies based both on Scala and Python Experience with building data streaming platforms and with technologies behind, such as Spark Streaming, Apache Beam, Dataflow Streaming Pipelines or similar Experience with Kafka Proficiency in ETL and ELT Experience working with Scylla or Cassandra Would be a plus, but not necessary: Experience with Aerospike Experience with Apache Spark or another distributed-processing system Airflow or some other workflow management platform Some experience with Go, but that’s minor We’d love it if you are someone who plays the games we create our tools around currently but are open to people who love games and the tools that players use to get better at them. No, we don’t care if you are Bronze or Diamond. What you would do if hired: Partnering with engineering, science and product teams to build our brand-new shiny data streaming platform Understanding business needs and translating them into working system, which provides business value from its first seconds of existence End-to-end designing, splitting into milestones and implementing different parts of the data platform. Writing all kinds of documentation, such as Design Documents, RFCs, one-pagers etc would be not the biggest, but very important part of your responsibilities Building observable, durable, fail-safe data platform, according to best practices Sharing experience with other folks and learning from them as well What we offer: Fully Remote Job - we're a remote company from day one. We've figured out that being remote is cool 5 years ago, before COVID made others learn it. Flexible working hours - except for scheduled meetings, we don’t have a working schedule or required amount of working hours. Mobalytics is not about time spent on achieving results but about results themselves. Homeoffice bonus after trial period. Salary paid in USD$, no matter where you are in the world. 14 vacation days + 2 more weeks of company-wide vacation in Dec-Jan. If you love games and have a strong desire to create beautiful and intelligent products for passionate communities of gamers, this is the place for you. We really want to help players be their best selves when playing with others around the world, and you should join us and help create that environment."
Data Engineer,Sentrilock LLC,Remote,https://www.indeed.com/rc/clk?jk=1667279422813094&fccid=b89c735ae1b1ca53&vjs=3,"Description: Why SentriLock? SentriLock, LLC, a global provider of access control services, is looking for a Data Engineer to join our family. A subsidiary of the National Association of Realtors, SentriLock is a nationally-certified “Great Place to Work” and provides competitive pay, excellent benefits, and a supportive work environment committed to developing our team members. Working for SentriLock is more than just a job, it’s an experience! The Data Engineer is a member of the Application Development Team, creating data pipelines, big data platforms and data integrations in databases, working with various cloud and on-premise technologies. You will be joining one of our Agile Scrum teams responsible for developing mobile applications, webpages, backends, and database as well as identifying opportunities to trial and deploy new capabilities and tools to keep current with technology. Ideal candidates will possess a drive for thinking creatively to resolve complex problems and enjoy contributing to solutions. Essential Duties and Responsibilities Plan Provide input to user stories and acceptance criteria Develop technical tasks required to complete User Stories Provide feedback regarding system performance and usability issues concerning user story development Estimate capacity for the sprint and communicate which user stories should be pulled in to work Lead design of applications, website, or server functionality Collaborate with development team to ensure consistency Willing and able to support multiple technologies or programming languages Develop Independently write clean, concise code using SentriLock model view controller framework, naming conventions, and architectural standards Interpret vague requirements into working solutions Solve difficult problems and deal with a variety of variables without a defined “right-answer” Effectively deal with ambiguity and changing priorities Stay plugged into emerging technologies/industry trends and suggest application of them into operations and activities Embrace change by assisting others in accepting and moving forward with new systems and processes Complete code review for junior developers Create/Maintain documentation along with system changes Provide visibility of production updates through change management process Lead publication of products onto production environment Test and Support Accountable for quality of completed solutions Unit Test code prior to turning over to QA Work with QA to test solutions Collaborate with QA and support personnel to troubleshoot reported bugs Lead projects to their completion using appropriate methodologies Provide insight on technical industry best practices Mentor Junior Software Developers Able to communicate effectively with business users Strong understanding of industry best practice collaboration or development tools such as Jira, Slack, Jenkins, Git, and Ansible Use Microsoft Office Suite (Outlook, Excel, Word, PowerPoint) as necessary for collaboration . Requirements: Educational Requirements / Preferences Bachelor's Degree in Computer Science or Related Degree or equivalent experience - Required Experience Requirements / Preferences 4+ Software Development in enterprise system – Required 3+ Data and Web Service Integrations - Required 3+ Systems design - Required 3+ Angular framework - Highly Preferred Other Requirements / Preferences Prefer understanding of the following: Knowledge of databases and data warehouses SQL, GCP, HTML, CSS, JavaScript, PHP, Java, Node.js Location Remote position within the Eastern or Central Time Zone - Required Ability to travel to the West Chester, OH office 3-4 consecutive days per quarter - Required"
Data Engineer,Wework,"New York, NY+1 location",https://www.indeed.com/rc/clk?jk=dd3c3c2070c58d03&fccid=e76dadb9a0d8a2cf&vjs=3,"About Us At WeWork, we provide inspiring and flexible workplace solutions to help businesses – small, medium or large – thrive in more than 150 cities globally. The future of work is happening right now, and we are leading this moment. United by a common purpose, here we will empower tomorrow’s world at work. Join us on our journey as we give our members the freedom and support to push boundaries in their industries, and work to redefine our own. About the Role WeWork is seeking a Data Engineer to join our People Analytics Team, reporting to our Manager, Data Engineering - People Analytics. The People Analytics team’s mission is to use data to help make smart People decisions and make WeWork the best place to work. Data underlies decisions related to hiring, promotions, compensation, engagement, development, careers, attrition, benefits, diversity, and the culture at the heart of WeWork. We are looking for someone with a computer science foundation, including an understanding of algorithms, databases and querying. Key Responsibilities: Assist the Senior Engineer or Manager with data engineering projects as requested Take part in ensuring data integrity of data sources in Snowflake and/or PostGre Debug processes that may fail during the day to day Help rebuild or restructure old processes as requested Manage our ELT and ETL processes Maintain and support business critical applications Requirements: 1-2+ years of experience supporting data engineering Solid knowledge of Python Understanding of data structures, such as lists, tuples, dictionaries and arrays Experience working with various APIs such as Rest, Curl to retrieve data Comfortable with query writing using any of the SQL variants (ie. PostGre, MySQL, Snowflake) and good understanding of aggregate functions, joins and subqueries Ability to think abstractly before coding Knowledge of Python, Airflow, dbt, Github, and Snowflake Comfortable programming as an individual contributor and in a team Ability to complete a project from start to finish with some supervision from the Senior Engineer or Manager Knowledge of HRIS (i.e. Workday, Greenhouse) as well as survey tools (i.e. Qualtrics) Preferred: Basic understanding of some Object Oriented programming concepts (Inheritance, Polymorphism, Encapsulation, Abstraction) Life At WeWork Being a WeWorker is more than just a job. We believe the magic of work is sparked by the passion you bring, the places you go, the people you meet and the purpose you follow. And it starts here. Here you will brush shoulders with those who dare to dream and do. Here you will be welcomed by a diverse community that embraces and inspires you—because together we can achieve more. Here we challenge ideas, and explore new ways of getting things done. Whether you are part of our Employee Community Groups, or part of a global project, we ask you to bring your open-minded attitude and collaborative spirit. In return, you will be part of a team where your unique perspectives are celebrated. WeWork is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon gender, sexual orientation, marital or civil status, pregnancy (or pregnancy-related conditions), gender identity or expression, transgender status or gender reassignment, race, color, national origin or ancestry, citizenship, religion or religious beliefs, age, physical or mental disability, genetic information (including genetic testing and characteristics), military or veteran status, or any other grounds or characteristic that is protected under the law. As part of our commitment to health and safety, WeWork — like a growing number of employers — is requiring all U.S. employees to be fully vaccinated for COVID-19 as a condition of employment, absent a legal exception for reasonable accommodation. We provide unvaccinated new hires a 45-day grace period after their start date to get fully vaccinated or, if eligible, obtain a reasonable accommodation. If you believe that a legal exception may apply to you, please still apply for any role(s) you are interested in and, if you are hired, you will receive instructions on how to request a reasonable accommodation after your start date. Please note that roles that require in-person work — currently, within our Community (excluding Member Experience), Facilities Management (including Security), Sales (excluding Sales Ops), and Member Technology teams — will not be eligible for work-from-home as an accommodation because it poses an undue hardship on our business."
Data Quality Engineer,Detroit Tigers,"Detroit, MI 48201 (Downtown area)",https://www.indeed.com/rc/clk?jk=c62035c3d98da7e4&fccid=2cde47347dc31dff&vjs=3,"JOB SUMMARY: The Detroit Tigers are currently seeking a Data Quality Engineer, Baseball Data Infrastructure. This role will be responsible for designing, managing, and automating data quality processes across our disparate data sources to support Baseball Operations initiatives. This position will report to the Director, Baseball Data Infrastructure. KEY RESPONSIBILITIES: 1. Design, implement, and use data quality assurance frameworks to support the process of identifying inconsistent data patterns. 2. Work with Tigers data engineers and data scientists to implement good data hygiene practices and procedures in our data pipelines. 3. Work with external data vendors to triage and remedy data quality issues. 4. Automate and execute test cases in data pipelines and manage data issue tracking. MINIMUM KNOWLEDGE, SKILLS, AND ABILITIES: 1. 2+ years of relevant work experience in data analysis and engineering using SQL and Python 2. Knowledgeable with data strategies and practices, such as continuous integration, regression testing, and versioning. 3. Experience querying SQL data warehouses built for data science and analytics. 4. Familiarity with cloud computing, cloud storage, and cloud services. 5. Understanding of data quality frameworks and best practices for implementation 6. Passion for baseball and familiarity with current baseball research. PREFERRED KNOWLEDGE, SKILLS & ABILITIES: 1. Strong SQL skills (T-SQL preferred). 2. Effective communication skills with an ability to explain technical concepts to developers and business partners. 3. Experience using Apache Spark (Databricks on Azure preferred). 4. Experience in generating reports and visuals on large data sources. 5. Experience with DevOps practices for CI\CD pipelines. 6. Familiarity with open-source data quality frameworks (Great Expectations preferred). 7. Familiarity with Airflow. WORKING CONDITIONS: 1. Office environment. 2. The location may be based in Detroit or fully remote. 3. Occasional evening, weekend, and holiday hours may be required. The above is intended to describe the essential job functions, the general supplemental functions, and the essential requirements for the performance of this job. It is not to be construed as an exhaustive statement of all additional duties, responsibilities, or nonessential requirements. Detroit Tigers, Inc. has the right to change, modify, suspend, interrupt, or cancel in whole or in part any job functions outlined in a job description at any time and without advance notice to the employee."
Data Engineer III,TeleTracking Technologies,+1 locationRemote,https://www.indeed.com/company/Teletracking-Technologies/jobs/Data-Engineer-0f3304f73a0ab142?fccid=acd459f967057298&vjs=3,"“TO ENSURE THAT NO ONE WILL EVER WAIT FOR CARE” *Data Engineer I*IIWHO WE AREFor over 30 years, TeleTracking has been operating with a simple mission, to ensure that no one waits for the care they need. Our state-of-the-art technology, combined with actionable best practices and a strong advisory services team, means that we provide the critical operational components required to build a responsive, resilient healthcare system. One of those key components is the centralization of hospital operations…the ability to see in real-time everything from the number of available beds to receive and treat patients to the number of pieces of available medical equipment. Teletracking values people with and entrepreneurial spirit, creativity and building strong relationships with our employees. We believe that diversity, equity and inclusion in our workforce keeps us competitive and provides opportunities for everyone. JOB SUMMARY A Data Engineer III is responsible for coding and continuous testing of complex modules and applications in support of the TeleTracking platform. This role will also be charged with understanding and interpreting requirements to contribute to the technical architecture and the associated design documents.*PRIMARY DUTIES AND RESPONSIBILITIES* Writing, debugging, unit testing, and performance test code in the data access layer in accordance with TeleTracking standards. As an agile team member, participate in code reviews, design reviews, etc. Utilize domain driven techniques and design patterns to build and contribute to technical design. Develop and maintain strong knowledge of implemented requirements and detailed application behaviors. Assists in the development and training of SE I. *EDUCATION* Bachelor's computer information technology, computer science, management required Master's preferred **EXPERIENCE *7+ years of experience in a cloud computing environment. Strong understanding and familiarity working in the Linux operating environment. Familiarity and experience executing several software development methodologies and life cycles preferred. *SKILLS* 7+ years of developing software using object-oriented or functional language experience 5+ years of SQL 7+ years working with open source Big Data technology stacks (Apache Nifi, Spark, Kafka, HBase, Hadoop/HDFS, Hive, Drill, Pig, etc.) or commercial open source Big Data technology stacks (Hortonworks, Cloudera, etc.) 3+ years with document databases (e.g. MongoDB, Accumulo, etc.) 3+ years of experience using Agile development processes (e.g. developing and estimating user stories, sprint planning, sprint retrospectives, etc.) 2+ years of distributed version control system (e.g. git) 3+ years of experience in cloud-based development and delivery Familiarity with distributed computing patterns, techniques, and technologies (e.g. ESB) Familiarity with continuous delivery technologies (e.g. Puppet, Chef, Ansible, Docker, Vagrant, etc.) Familiarity with build automation and continuous integration tools (e.g. Maven, Jenkins, Bamboo, etc.) Familiarity with Agile process management tools (e.g. Atlassian Jira) Familiarity with test automation (Selenium, SoapUI, etc.) Good software development and Object Oriented programming skills. Strong analytical skills and the ability to work with end users to transform requests into robust solutions. Excellent oral and written communication skills. Initiative and self-motivation to work independently on projects. *WORK ENVIRONMENT and TRAVEL*The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform the essential functions. The term ""qualified individual with a disability"" means an individual with a disability who, with or without reasonable accommodation, can perform the essential functions of the position. While performing the duties of this job, the employee is regularly required to communicate professionally in person, over the telephone, through email and other electronic means, move about the office, handle various types of media and equipment, and visually or otherwise identify, observe and assess. The employee is occasionally required to lift up to 10 pounds unless otherwise specified in the job description. TeleTracking is committed to providing equal employment opportunity to all people in all aspects of the employment relationship, without discrimination because of race, age, sex, color, religion, national origin, disability or status as a Vietnam era or special disabled veteran or any other unlawful basis, as defined by applicable law, and fostering a workplace free of unlawful discrimination and retaliation. This policy affects decisions including, but not limited to, hiring, compensation, benefits, terms and conditions of employment, opportunities for promotion, transfer, layoffs, return from a layoff, training and development, and other privileges of employment. An integral part of TeleTracking’s commitment is to comply with all applicable federal, state and local laws concerning equal employment and affirmative action. TeleTracking must comply with President Biden’s Executive Order on Ensuring Adequate COVID Safety Protocols for Federal Contractors and to maintain the health and safety of our workforce. You must have received or be willing to receive the COVID-19 vaccination by date of hire to be considered. Proof of vaccination or an approved exemption due to religious or medical reasons will be required. Job Type: Full-time"
Data Validation Engineer,Smarking,Remote,https://www.indeed.com/rc/clk?jk=3c92e0af6d9365bf&fccid=2d3def7f59c7da5b&vjs=3,"Smarking is a leading provider of enterprise software and data technology solutions for the massively overlooked $655B global parking industry. Clean data is one of the keys to our business. This is an excellent opportunity for an engineer who is passionate about data and and loves digging in. In this cross functional role between our customer success and engineering, you'll be our go to engineer for diagnosing and fixing data accuracy and and data flow issues. You'll work with technologies such as Python, PostgreSQL, pandas, sellenium, Microsoft Excel, Docker, AWS and be a key contributor to the success of our customers. KEY RESPONSIBILITIES Work with customer success to identify and fix data issues Be the engineering liaison to customer success Dig into the data to insure accurate interpretation of its semantics Build tools to streamline the data accuracy process Occasionally interact with customers and vendors to facilitate accurate data ingestion QUALIFICATIONS (EXPERIENCE) 2+ years professional software engineering experience desire to learn new technologies demonstrated ability to work with data experience with relational databases and tools for analyzing relational data experience with Python, pandas, and PostgreSQL and AWS would be a plus QUALIFICATIONS (CHARACTER) Hungry for responsibility, impact, and growth Humble to learn, curious to learn, open-minded to learn Team first Strong sense of ownership Treat others with respect, empathy, and constructive candor COMPENSATION Competitive salary and equity. 100% coverage of medical, dental, and vision insurances. 401K plan with 3% company hard match. $100 monthly data plan. $60 per month gym membership (or other physical activity) Unlimited paid time off. Expenses for setting up home-office. About Smarking Smarking is a group of passionate MIT PhDs, data scientists, Silicon Valley engineers, and battle-tested business professionals, committed to enable highly efficient urban mobility by building the digital infrastructure for the massively overlooked $655B global parking industry ($131B in the US). Smarking is hired by organizations like Brookfield Properties, City of Miami, ABM Industry Groups, and many other enterprise industry leaders to turn their parking data into business results. Smarking's dynamic pricing engine has been creating 40%-400% revenue uplift for online parking sales at parking facilities in Chicago, NYC, Boston, and many other cities, without any manual involvement required from property managers, leveraging fully automatic algorithm-driven yield management technologies similar to the airline and hotel industries. By providing the very first business intelligence and yield management enterprise SaaS to the parking industry, Smarking is establishing itself as an emerging leader in the US parking market. Smarking currently works with 2,500+ parking locations cross North America, based in San Francisco, and backed by top investors like Khosla Ventures and Y Combinator."
Senior Data Engineer,caresyntax,"Boston, MA",https://www.indeed.com/company/caresyntax/jobs/Senior-Data-Engineer-62b122d1fce56f27?fccid=6537791622ea2d89&vjs=3,"Role SummaryOverviewAt caresyntax®, we are on a mission to make surgery smarter and safer. We believe in the power of data-enabled technologies to reduce surgical complications and improve safety and outcomes. Our integrated applications empower surgeons and hospitals with data visibility, learning, and automation tools to address surgery’s most acute problems.Reporting to the Director of Software Engineering in Boston, MA, the Data Engineer role supports the core products of Caresyntax including our Enterprise Data Lake and Analytical Applications. This person is responsible for implementing data acquisition, loading, and transformation into the Enterprise Data Lake. This person is also responsible for implementation, enhancement, and maintenance of applications that deliver analytical solutions to the healthcare industry. This role will be a technical expert collaborating with the Product Team and other local and remote Developers to develop to deliver data storage, transformation, visualization, and analytical applications.In addition to the technical requirements, the successful candidate will be looked to as a positive, collaborative team member at Caresyntax who will help drive positive performance of our systems, products, and services to clients with a ‘can-do’, innovative attitude. Your work scopeWhat you will do: Analyze business requirements and outline solutions. Design and develop ETL and ELT solutions using SQL, Shell Scripting, Pentaho, and other tools. Analyze data requirements, complex source data and the data model to extract, transform and load the data into the data lake, data warehouse, and other systems. Create or update technical documentation and processes flows. Develop automated build, test, and deployment processes. Manage administrative tasks such as system deployment, scheduled jobs, and configuration changes. Monitor running systems including production; troubleshoot and resolve service issues. Proactively communicate innovative ideas, solutions, and capabilities over and above the specific task request Participate in design and implementation review sessions and ensure all solutions are aligned to architectural specifications. Effectively communicate status, workloads, offers to assist other areas. Work independently and collaboratively with a team both in-person and virtually. Continuously strive for high-performing business solutions. Your backgroundWhat you will need: Bachelor’s Degree in a technical area of study; preferably in Computer Science, or 3+ years equivalent work experience in Information Technology. 2+ years of previous experience implementing and supporting data-intensive analytical applications, preferably within the healthcare sector or other highly regulated environment. 2+ years of experience in relational and data warehouse database design, optimization, and performance. Working knowledge of Data Warehouse concepts. Experience with cloud-based databases such as Snowflake or Redshift preferred. Your benefits Employer sponsored insurance benefits: medical, dental, vision, life, STD/LTD, EAP Open PTO policy, 401k savings and company match, paid holidays Contact usPlease apply directly to the link! About uscaresyntax® Inc., together with its global medical device integration solutions arm, maintains a worldwide installed base of nearly 7,000 operating rooms, supporting over 10 million procedures per year. And this is just the beginning - we're growing fast! Headquartered in Boston and Berlin, with over 100 employees from more than 33 different nationalities, we seek highly-motivated and passionate individuals to join us on our mission of improving surgical care. Job Type: Full-time"
Senior Data Engineer,Shortcut,"Remote in Chicago, IL",https://www.indeed.com/rc/clk?jk=fe033f261d35b7be&fccid=16aac0a4ca5c8559&vjs=3,"About us: Based in New York but fully distributed, Shortcut builds project management software for software and product teams that people actually want to use - just ask an engineer how they feel about Jira. Thousands of the fastest-growing software companies use Shortcut to plan and build software, including Glossier, Venmo, Dataiku, Scale AI, FullStory, LaunchDarkly, and others. At Shortcut, you'll be joining a small but quickly growing team that values kindness, dedication, collaboration, and transparency across all of our work. Your role: The Senior Data Engineer will help lead and grow our Data Engineering team. As a founding member of our Data Engineering team you'll have large sway over the technical design of additions to our current Data platform, as well as our substantial greenfield development. Contributing to almost everything from Vendor selection, Large system design, setting best practices, hiring, foundational technical decisions, and understanding the costs of our platform. This role will report to our Head of Data. Our Data team is made up of various Internal and External teams. Our skillsets and functions range from Data Engineering, Analysis, Science to others as well! We're responsible for supporting our exponential Product Lead Growth (PLG) through the power of data. Shortcut is a data driven company, and our role is to surface data, dashboards, and insights for functions across Shortcut, driving a direct impact on strategy and decision making across our high growth organization. We frequently work directly with Executives, Senior Leadership, and Individual contributors to perform analysis that drives our adaptive strategy. Everyone is our stakeholder. What you'll do: Own, build, and maintain our Data Pipelines + Platform that supports a state of the art Business Intelligence function. Help drive and lead our architectural planning and rollout of various technical initiatives, including but not limited to; Data Lakes, Spark Clustering, Batch Processing, Real Time streaming, and Data Lakehouses. Perform Code Reviews of Data Team's code, ensuring built in quality and adherence to our best practices. Be a founding member of our Data team who will help establish, mentor, and scale a high quality data organization. Collaborate with our Engineering Department on planning various technical initiatives. Collaborate with our various Data teams, to support various Data Ingestion, Modeling, Integration, and Visualization tasks. You should have: Strong experience with Big Data technologies, their uses, pros, cons, and tradeoffs. Strong experience with technologies like DBT, Spark, Snowflake, Pandas, Python, SQL Strong knowledge and working experience with architectural concepts within the Data space. Batch, Streaming, Lakehouses, Clustering, 12 Factor. Experience working with end users, and demonstrable experience optimizing your communication style for audiences from various backgrounds + skillsets. Have strong opinions that are weakly held, previous experience with Technical Leadership. Experience with Devops, CI/CD, Terraform, and the control of state. Strong Professional skills, Ethics, and Communication skills. Extra credit (nice to have): People Management experience. Experience with Looker, Airflow, or other visualization/ orchestration tools. Experience in a fast paced entrepreneurial environment. Experience in tuning machine learning models. Experience with Koalas! Even if you don't meet all of the requirements listed, we still encourage you to apply. Job requirements are a wishlist, not a checklist, and we're happy to help the right candidate grow into this role - if you're excited about Shortcut, we're excited about you! What we offer: Compensation: A competitive salary in addition to meaningful equity in the company - you should be able to take ownership of what you're helping to build. Benefits: Health, Dental, and Vision insurance, FSA, OneMedical, Teladoc, Health Advocate, 401(k), commuter benefits Work-life balance: A flexible open vacation policy, in addition to 10 company holidays, 5 sick days, and 3 ""Dot Days"" (our term for bonus days off), community (volunteer) PTO, 12 weeks of fully paid parental leave. We also observe 40 hour work weeks without the expectation of after-hours or weekend work. Learning and development: A $2,000 annual stipend to use toward conferences, educational courses, books, membership fees and more WFH: We are a fully remote company, and we provide all the equipment you need to work from home in addition to an annual WFH stipend. Target base salary for this role based on experience: $145,000-$160,000 annually + target equity + benefits (including medical, dental, vision and 401(k)) At Shortcut, we embrace the different backgrounds, perspectives, and experiences our team members bring to the table. As a proud Equal Opportunity Employer, we welcome all applicants and teammates regardless of race, color, ancestry, national origin, religion or religious creed, mental or physical disability, medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, citizenship, or other characteristics protected by applicable law. If you need assistance or an accommodation due to a disability, please contact us at peopleteam@shortcut.com."
Data Engineer,Offerpad,"Chandler, AZ 85286",https://www.indeed.com/rc/clk?jk=bed74049919bc67f&fccid=f0a1b6c72239b1ba&vjs=3,"Job Description: Position Summary The Data Engineer will lead and participate in the design, development, and maintenance of our Data Warehouse at Offerpad. Duties will include dimensional modeling, troubleshooting complex data problems, and delivering enterprise level solutions to business leaders. The Data Engineer will be responsible for the testing, maintenance, construction and development of architectures such as large-scale processing systems and databases. As part of this, they are also responsible for creating data set processes for verification, acquisition, mining, and modeling. This individual will collaborate with stakeholders across the organization to ensure clarity of all business requirements. Essential Functions Lead and participate in the design, development, and maintenance of our Data Warehouse. Including dimensional modeling, troubleshooting complex data problems, and delivering enterprise level solutions to business leaders. Evaluate TSQL Queries for performance improvements. Support Power BI Reports. ETL Data from multiple different sources including API's and Flat Files. Build large-scale batch and real-time data pipelines with data processing frameworks in Azure. Collaborate with stakeholders on business processes to ensure clarity of Business Requirements. Required Experience: Minimum Qualifications Bachelor's Degree or an equivalent combination of education and related work experience. 2+ Years of experience with Microsoft SQL Server. 2+ Years of experience with ETL Tools like SSIS 1+ Years of experience with cloud platforms, preferably Microsoft Azure 1+ Years of experience with Reporting Tools like Power BI. 2+ Years of experience with Dimensional Data Models and best practices. Understanding and Experience with performance tuning, query plans, blocking, dead locking and Indexing. Experience gathering requirements from stakeholders and transforming those into data driven BI solutions. You should be able to take a single project start to finish. Experience with Multiple Database Platforms and BI Delivery Solutions. You have a high EQ (emotional intelligence) and able to effectively work well with others, fostering a great, collaborative, and fun environment, even amidst technical challenges. Preferred Qualifications A Master's degree or higher in a quantitative field (e.g. science, engineering, economics, finance, statistics, or similar) and have 2 years of work experience involving quantitative data analysis and complex problem solving. Experience in Tabular Models and writing performant complex DAX Queries. Expertise in Microsoft Azure Data Solutions and Microsoft SQL Server. Previous real estate experience a plus Experience in Azure cost management and recommending cost optimization steps. Why Work with Offerpad? It’s simple: We’re here to help. We help people by providing the best way to buy and sell a home. Period. If you’re passionate about helping people, too, in an environment where every day matters, where you’ll thrive on innovation, collaboration and recognition for your inspiring ideas and be rewarded for your results, then welcome home to Offerpad! We're a fast-growing, fast-moving, compassionate customer-obsessed team of like-minded business disruptors who are continually challenging and changing the way traditional real estate works. We’re all about homes, not houses. Since 2015, we’ve grown from an entrepreneurial upstart in three markets to an industry-leading technology innovator with more than 500 happy humans working together to help customers in 900+ cities and towns across the country. As we continue to grow and expand, our goal remains the same: Make the process as seamless and stress-less as possible to help them move freely and enjoy the best customer experience available. While we work hard to serve our customers – we have a 95% customer satisfaction rating and 84 Net Promoter Score - we also work hard at taking care of one another. We’re family here, we work hard but we have a lot of fun. Our culture is one of inclusivity and support, one that values results, nourishes creativity and relishes - and rewards - each other’s success. If home is where your heart is and making people happy is your passion, we welcome you to join our team of intrepid innovators, technology gurus, real estate experts and all-around great people at Offerpad! Check our current job postings below to see everything we have to offer! Offerpad can offer you: Competitive compensation The opportunity to make a difference in a fast-growing, startup environment Strong, collaborative team culture Full benefits including medical, dental and vision coverage 401(k) matching program 40 paid volunteer hours annually Mileage reimbursement (where applicable for role) 11 paid holidays a year Flexible PTO From: Offerpad"
Data Engineer,Koch Minerals & Trading,"Houston, TX 77046 (Greenway - Upper Kirby area)+9 locations",https://www.indeed.com/rc/clk?jk=d7bac3bc243c8018&fccid=735667c8ff2f1a48&vjs=3,"Description Koch Minerals & Trading (KM&T) is seeking a motivated and self-driven Data Engineer to join our team in Houston, TX or Wichita, KS. KM&T is a global commodity trading company participating in nearly all commodity markets but focusing on petroleum and energy. This individual will be supporting Traders and Market Analysts by developing systems and data pipelines to handle research, trading, and risk management activities for the Gas, Power and Renewables desk. A successful candidate will have the following characteristics: Pro-active and capable of working independently to achieve project deadlines Excellent communication and interpersonal skills with the proven ability to work as part of a team Ability to work accurately, efficiently, and independently Meticulous nature, detail-oriented, and producing high quality work Learning and teaching new technologies as required What You Will Do In Your Role The Quantitative Data Developer will work with a team of traders, market analysts and accounting staff to support and improve operations. Specific responsibilities include: Building and maintaining risk management and trading tools Managing market and fundamental data pipelines in accordance with governance principles Coordinating with development and support teams throughout the company to complete complex projects Creating analytic tools and visualizations to help guide trading decisions Monitoring systems and processes to ensure consistent performance and availability The Experience You Will Bring Requirements: Bachelor’s degree or higher in a quantitative field (examples may include Mathematics, Sciences, Engineering, Economics, Computer Sciences, etc.) Minimum of 3-years of experience as a Quantitative Developer or Data Engineer Python programming experience What Will Put You Ahead Experience with languages such as C#, Java, or R Experience with AWS cloud technologies including Lambda, Glue, Athena, Redshift, EMR Experience with relational databases such as Microsoft SQL server or Postgres Experience loading, transforming, and categorizing data from multiple source systems Knowledge of quantitative financial concepts such as derivative pricing Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter. At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate’s knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy. Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf"
Data Engineer,Schlumberger,"Sugar Land, TX",https://www.indeed.com/rc/clk?jk=f68d797c7aee8fcf&fccid=1a6c05c38b3b5549&vjs=3,"Data Engineer Sugar Land - United States The Data Engineer is responsible for developing and managing the data’s ETL processing, with a focus on quality and risk, to assist in the achievement of analytics objectives. The Data Engineer will work collaboratively with functional, technical and program staff to communicate findings and inform decision making through dashboards, data visualizations, interactive charts, graphs and other tools to target audiences in a clear way. Roles and Responsibilities: Build robust, fault-tolerant data pipelines that clean, transform and aggregate unorganized and messy data into databases or data sources. Compile and install database systems, write complex queries and scale to multiple machines. Process large multivariate data sets collected from equipment operations, manufacturing tests and diagnostic routines. Lay the groundwork for Digital Operations colleagues to easily retrieve the needed data for their evaluations and experiments. Provide input to the business strategy to help guide the overall direction of data management and data quality within the organization. Collaborate with different departments, technical SMEs, and testers to solve problems and convey key messages using data visualization approaches, techniques, and methods. Identify programmatic challenges and leading indicators to present the problems as well as solutions visually. Connecting to data sources, importing data and transforming data for Business Intelligence. Provide technical solutions using Process Automation Tools, Artificial Intelligence and Machine Learning. Communicate ideas, plans and results effectively via oral reports and written documentation. Generate innovative ideas, establish new research directions, and shape and execute on technical projects. Maintain state-of-the-art knowledge and contribute to technical discussions and reviews as an expert in related areas of responsibility. Participate in the areas of data science, industrial analytics, data-driven prognostics, data mining and machine learning. Apply experience with machine learning algorithms and population-based meta-heuristic optimization methods Qualifications and Experience: Bachelors in Computer Science and 3-5 years of experience. Candidate should be used to digitalization of business processes, business analysis skills. Candidates must be able to legally work and reside in the US, without sponsorship. Schlumberger is an equal employment opportunity employer. Qualified applicants are considered without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, status as a protected veteran or other characteristics protected by law. Schlumberger is a VEVRAA Federal Contractor- priority referral Protected Veterans requested."
Data Engineer,Feedzai,"Remote in Atlanta, GA",https://www.indeed.com/rc/clk?jk=d0aefbcb78d4610f&fccid=ad93a7e288dc7118&vjs=3,"Feedzai is the world's first RiskOps platform for financial risk management, and the market leader in safeguarding global commerce with today's most advanced cloud-based risk management platform, powered by machine learning and artificial intelligence. Feedzai is securing the transition to a cashless world while enabling digital trust in every transaction and payment type. The world's largest banks, processors, and retailers trust Feedzai to protect trillions of dollars and manage risk while improving the customer experience for everyday users, without compromising privacy. Feedzai is a Series D company and has raised $282M to date. With a valuation of +$1.5B, the company's technology protects 900 million people in 190 countries. Customer Success's Data Engineering team is dynamic, tenacious, and driven by their passion for new technology, new processes, big data automation, and a constant evolution mentality. They collaborate and work cross-functionally with colleagues across the globe to deliver on client needs, solve problems, and work closely with the Product team to implement scalable solutions with high business impact. We grow at a fast clip and believe no challenge is too big or too small. The whys behind our mission keep us motivated. You: Everything you do matters: all your code, machine learning models, advisory, management, and other actions/roles will have a material impact on the way our clients run their business and how effectively we fight fraud and protect people from wrongdoing. You will be able to interact and meet many people from widely different cultures around the world and understand the business like few others; also be able to say you protect people on a daily basis. You will be challenged with new technology, new processes, and new mindsets and will be asked to contribute to ensure continuous improvement. Your Day to Day: Improve the productivity of our Data Scientists by developing standalone tools and leading product innovation with proof of concept features for our Product; Work with Product and Cloud teams to improve design, optimization, automation and scalability of Feedzai's solutions; Work with multiple departments in defining data and pipelining strategies to enable them to have effective analytical capabilities; Optimize, tune and/or implement data pipelines that handle very large datasets with Big Data technologies such as Spark and Hadoop; Write reusable and testable code using the best tools for the job and participate in code reviews; Build and enhance MLops culture and practices in the full lifecycle of Data Science, including automating pipelines for data preparation, model retraining, model evaluation and model deployment, enabling the team to create solutions with reliability and scalability. You Have & You Know-how: MSc, or PhD in Computer Science, Electrical Engineering, Statistics, Applied Mathematics, Physics or similar technical discipline; Strong programming skills in Java, Python and Shell scripting; Advanced knowledge of Computer Science; Knowledge of Machine Learning and Data Science processes; Knowledge of Big Data technologies such as Spark, Hadoop and related; Knowledge of workflow orchestration tools such as Airflow, Prefect or related; Knowledge of SQL and NoSQL databases; Ability to communicate your findings in a clear way. Valued: Real-world experience in any of the above Experience with very large datasets (>1TB) Experience with CI/CD pipelines The Customer Success Team is responsible for delivering our product to our clients. This includes education, configuration, solution development, and risk strategy to enable our clients to address their pain points. We collaborate with our clients to ensure they have the right solution, build out a strategy and training plan for them, and then support them through each phase of our client lifecycle. We grow at a fast clip and believe no challenge is too big or too small. Therefore, we have an open environment that encourages us to lean in, try new things, and discover our potential. Join Us! #LI-IP1 #LI-remote Your First 30-Days at Feedzai: You will be immersed in our brand with training, connections, and one-on-one time with your manager. You may shadow your colleagues virtually or onsite at an office depending on where you work as you are supported through your Feedzai journey. In addition, you will have access to a ton of information to give you history, context, and all the knowledge you can handle about Feedzai and the team. Finally, you will start working on projects and collaborating on work currently being done. We can't wait to have you join the team! Life at Feedzai Instagram Feedzai Culture Feedzai is an Equal Opportunity Employer and we value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Feedzai does not accept unsolicited resumes from recruiters or employment agencies."
Data Engineer,State Farm,"Hybrid remote in Dunwoody, GA 30346+2 locations",https://www.indeed.com/rc/clk?jk=f749f84e74f84e1c&fccid=d2310af9b3bb8585&vjs=3,"Overview: We are not just offering a job but a meaningful career! Come join our passionate team! As a Fortune 50 company, we hire the best employees to serve our customers, making us a leader in the insurance and financial services industry. State Farm embraces diversity and inclusion to ensure a workforce that is engaged, builds on the strengths and talents of all associates, and creates a Good Neighbor culture. We offer competitive benefits and pay with the potential for an annual financial award based on both individual and enterprise performance. Our employees have an opportunity to participate in volunteer events within the community and engage in a learning culture. We offer programs to assist with tuition reimbursement, professional designations, employee development, wellness initiatives, and more! Visit our Careers page for more information on our benefits, locations and the process of joining the State Farm team! What’s In It for You Work with cutting edge technologies and business models Contribute to brand new, patent-worthy, concepts and products. Be part of small, self-empowered teams. Participate in customizable skill-level and personal development training. Opportunity to identify, research, and feed the development of new and experimental products. Freedom to utilize different technologies, languages, and frameworks that apply to the problem being solved. Influence and inform solution design efforts that consider performance, risk mitigation, user experience, and testability. Participates in Design Thinking to identify personas, develop problem solving ideas, and pitch ideas to leadership as a team. Competitive Benefits, Pay, and Bonus Potential. STEM Mentoring Opportunities: Give back to the community in your area of expertise through volunteering at STEM events for students! Local volunteer opportunities. 401k plan A Learning Culture: Mentoring, Tuition Reimbursement, Health Initiatives, and more! Office Location: State Farm Hub location: Dunwoody, GA Hybrid Work Environment: Selected applicants should plan to spend time working from home and some time working in the office as part of our flexible work environment. SPONSORSHIP: Applicants are required to be eligible to lawfully work in the U.S. immediately; employer will not sponsor applicants for U.S. work authorization (e.g. H-1B visa) for this opportunity Responsibilities: Duties and Responsibilities: Applies skills, tools, security processes, applications, environments and programming language(s) to complete complex assignments. Understands and develop/maintain data movement scripts related to storing, retrieving, or acting on housed data to AWS Cloud Tests requirements for the movement, replication, synchronization, and validation of data Identifies ways to automate and improve upon existing automation Develop and improve monitoring solutions Be willing to take on special assignments that may require additional learning Qualifications: Skillsets for the role should include: Required: Understanding in programming (e.g., Python), and database functionality (e.g., SQL, Non-SQL) Understanding in compute environments, including but not limited to Linux, Mainframe and Public Cloud Understanding of Application Programming Interface (APIs) Data Validation and Qualitative and Quantitative Analysis Strong understanding in database technologies like IBM DB2, Postgres and AWS RDS, Redshift, Aurora Certifications in AWS Cloud technologies Experience in: Advanced Python and SQL functional experience Linux experience with strong bash scripting, python with Pandas data frames and spark with Pyspark or Scala Spark experience AWS cloud experience with glue, lambda, DMS, step functions and Redshift, API Gateway Experience building and using CI/CD pipelines, leveraging tools like GitLab CI/CD SAS or R Python w/ Pandas Data Frames Pandas Profiling Spark with PySpark or Scala Spark – more data frame driven software SQL Clients; examples: DBeaver, WinSQL, PgAdminn, SQL Workbench Jupyter Notebooks SFARM #LI-KF1 #LI-Hybrid"
BI Data Engineer,BeneFit Cosmetics,"San Francisco, CA 94104 (Financial District/South Beach area)",https://www.indeed.com/rc/clk?jk=9e36e593e949a09b&fccid=01fd911ba3520ccb&vjs=3,"Summary: The BI data engineer will be in charge of leading BI projects, including gathering requirements, automate processes, project planning and building reporting solutions for Finance, Marketing, Digital, Retail teams. In addition, the role will oversee user trainings and provide good practices to the end users. Essential Duties & Responsibilities: Develop solutions to extract data from various systems and load it into databases using different technologies to transfer and load the data such as SSIS, Azure Data Factory. Work closely with the team to evaluate, maintain and support existing applications ensuring that the BI platform is accurate, available, and performant. Identify improvements and work with the BI Manager to implement solutions for the existing applications. Build out visualizations and dashboards using IBM Cognos or Power BI. Identify new reporting features that can add value for Benefit and share with the business experts. Work with different business departments to gather business needs and translate them into technical specifications. Work with the BI Manager to support BI projects from the business interviews to the roll out of the applications, ensuring all critical control points are met as per Benefit standards. Promote the use of the BI solutions across the company through trainings and presentations. Research new BI technologies. Test and determine if they would be beneficial for the company. Qualifications: 2 to 3 years of experience in data warehouse and analytics/BI architectures, including data modelling Experience with technologies like SQL Server, Azure and Google Cloud. Experience leading BI projects from the user interviews to the deployment and support of the solution Familiarity with ETL tools Experience with data visualisation tools Knowledge of the wholesale/retailer business Strong database conception skills Familiarity with SQL Server skills such as security, replication, backup. Performance testing is a plus Ability to write complex SQL queries with joins, sub queries and aggregations Ability to use ETLs such as SSIS, Azure Data Flow, Dataiku Ability to manipulate complex sets of data Ability to create data visualizations and dashboards using Power BI, Cognos Ability to write advanced calculations using proprietary calculation languages such as MDX, DAX Strong understanding of retail business in order to capture end-users requirements and translate them into working dashboards. Ability to create planning and communicate milestones BS/MS in Computer Science or Information Systems preferred or equivalent combination of education and experience."
Data Engineer (Remote),Little Otter,"Remote in Seattle, WA",https://www.indeed.com/rc/clk?jk=1adfef555f8912d2&fccid=9942dad822701e11&vjs=3,"Little Otter is reimagining the way that children receive mental health care. We pair technology, and exceptional care to deliver high-quality personalized mental health support to families and children anywhere, anytime. Developed by Dr. Helen Egger, previously Head of Child Psychiatry at NYU Langone and Duke University, and the top minds in early childhood mental health, our programs empower families to get back to what matters the most as soon as possible. Little Otter helps parents better understand their child’s emotions and behaviors, providing personalized care plans and evidence-based therapy. We are looking for team members who are mission driven and excited to actively participate in growing our offering. Our engineering team is small where there’s an opportunity to have a large impact on the work we are doing and the decision making process. Our approach is to take a data-driven and evidence-based approach to providing high-quality mental health care to families and children and we are building the platform to enable it. This will be the first of its kind - a platform that focuses on providing a family-centric model to care and one that powers our providers to provide data-driven care. We are seeking an engineer to work on our team to own our data pipelines and infrastructure. Data is at the center of our business and it’s what allows us at Little Otter to provide high quality care to each family. You will be responsible for maintaining and building our data infrastructure that powers our clinical research, our business operations, and our care model. We are looking for someone mission driven who wants to see an immediate impact of their work on team members and families. Responsibilities Develop and maintain data pipelines that power our business operations, our clinical research, and our care model Build and maintain observability for our data infrastructure Partner with business operation team and senior leadership to build key KPI dashboards Collaborate with clinical team to understand data needs and build data pipelines to power clinical research Collaborate with product development team and directly contribute necessary product changes to collect data to power our data needs Create simple APIs for accessing collected data. Maintain the data model standard that will be used by the organization. Requirements 3+ years of strong experience with data transformation on datasets using open technologies like Spark, SQL, DataBricks, DBT, Kedro, pandas, and Jupyter Notebook. 3+ years of complex SQL with strong knowledge of SQL optimization and understanding of logical & physical execution plans Experience in advanced Data Warehouse concepts & Data Modeling experience (i.e. Relational, Dimensional, internet-scale logs)\ Strong knowledge of Python, UNIX Shell scripting. Knowledge of Spark (Batch/Streaming), SparkSQL and PySpark Comfort with data visualization technologies such as matlab.pyplot or plotly. Experience working with various stakeholders to learn the data domain and manipulate data to fit the needs of the business. Nice to Haves You have worked on engineering teams in the healthcare and mental health space You understand HIPAA and other security requirements for handling healthcare data and building systems that manage them You or a loved one have benefitted from mental health services, and you wish to give back. Why Us? Join a collaborative community of mission-driven professionals who want to help children and families Build a first of its kind platform that focuses on providing a family-centric model to care and one that powers our providers to provide data-driven care. Participation in early technical direction of the company Benefits include, but are not limited to: competitive salary and equity in an early stage startup, comprehensive health benefits (health, dental, medical), a flexible remote-first working environment and parental leave Take-what-you-need PTO policy with 2 weeks off for the winter holidays Flexible remote-first working environment About the Company Early intervention is essential for lifelong health and wellness. Still, most families and children do not receive the mental health support they desperately need. Little Otter is a venture-backed startup reimagining how children and families receive mental health care. We bring technology, proprietary methods, and exceptional providers together to deliver high-quality mental health support directly to families and children anytime, anywhere. Little Otter's assessments identify a family's unique needs, providing a customized care plan that includes a mix of teletherapy and digital self-management tools. Parents receive personalized and judgment-free support that grows with their family over time. Little Otter is the first product of its kind that is sold directly to families. Our goal is to break down existing barriers to high-quality services and empower parents to help their kids when they need it the most."
Data Analytic Engineer,FacilityConneX,"Nashua, NH 03062",https://www.indeed.com/rc/clk?jk=aa0f4d942153f178&fccid=e7c9b3089870aeb5&vjs=3,"About Us FacilityConneX’s mission is to provide the industrial and commercial customer a world-class real time continuous monitoring system for any equipment or facility - Anytime, Anywhere. Partnered with GE and leveraging many of their best software technologies, FacilityConneX offers an industry leading experience for customers to gain insight on their own systems and data. Our cloud based solution, FacilityConneX, is a wholly owned subsidiary of AutomaTech, Inc. For more information, go to www.facilityconnex.com AutomaTech offers a great work environment, professional development, challenging careers, and competitive compensation. AutomaTech is an Equal Opportunity Employer. Posted Position Data Analytics Engineer I Title Career Level Entry – Mid Level Function Engineering/Development Location Opening United States, Nashua NH Is Available Relocation Negotiable Expenses Role Summary As a Data Analytics Engineer for FacilityConneX, you will be embedded in a close knit / cross- disciplinary team on commercially-facing development projects, typically involving streaming, complex data set. You will work addressing statistical, machine learning, and data understanding problems in various commercial and industrial applications. In this role, you will contribute to the development and deployment of modern machine learning and statistical methods for finding structure in large data sets. You will leverage experience from various sources such as software developers, engineers, partner subject matter experts, and end users to define business problems, work with and manipulate data, develop analytical solutions, and execute analytical models and rules into production libraries aimed at specific commercial and industrial markets. Potential application areas include remote monitoring and diagnostics across facility infrastructure and industrial sectors, energy management, and operations optimization. In this role, a heavy emphasis will be put on the practical application, use, and benefits to our customers using our system. The Data Analytics Engineer will work to assure all solutions will be optimized for performance and deployment into our Hosted Industrial Cloud environment. Essential In this role, you will: Responsibilities  Develop analytics within well-defined projects to address customer needs and opportunities.  Work alongside software developers, software engineers, and partner subject matter experts, to translate algorithms into commercially viable products and services.  Work in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.  Generate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes.  Share and discuss findings with team members Qualification Basic Qualifications: Requirements  Bachelor’s Degree in a “STEM” major (Science, Technology, Engineering, Mathematics)  Minimum 1 year analytics development in a commercial setting Eligibility Requirements  Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job  Must be willing to travel 10%  Demonstrated skill in the use of one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python)  Demonstrated skill at data cleansing, data quality assessment, and using analytics for data assessment  Demonstrated skill in the use of applied analytics and predictive analytics on industrial datasets Desired  Demonstrated awareness of real-time analytics methods Characteristics  Demonstrated awareness of analytic prototyping, analytic scaling  Demonstrated awareness of industry and technology trends in data science  Demonstrated awareness of IoT trends and real-time analytics applications  Demonstrated awareness of test-driven software development and benefits of unit testing  Demonstrated awareness of critical thinking and problem solving methods  Demonstrated awareness of presentation skills  Demonstrated awareness of how to leverage curiosity and creativity to drive business impact"
Data Science Engineer,Vanguard,"Malvern, PA",https://www.indeed.com/rc/clk?jk=f8f3efbd99af85fc&fccid=510aa29fcf8f87d9&vjs=3,"We're introducing a new role of an Analytics Engineer or a Data Science Engineer on the EA Product Analytics Team. This new role will sit within a strategic new business area for the organization, Product Intelligence at the heart of Vanguard’s Enterprise Advice division. This is a fast growing, ambitious team, and is a strategic enabler to the growth of Vanguard’s advice footprint. Our objective is to develop a deep understanding of how Vanguard’s Enterprise Advice products are being used by our clients and leveraging this knowledge to drive product innovation over time. This is a hybrid role that expects proven proficiency in analytics engineering / MLOps areas with a keen interest in contributing as a full-fledged data scientist. Specifically, this role will serve as the resident expert on all things analytics engineering / MLOps and build a reliable, scalable set of data pipelines to be leveraged by the scientists on the team and then will be expected to transition to more of a data scientist themselves. The team brings together a variety of different types of data and information, and integrates the learnings from analytics and research to (1) understand where and how our products are most successful, (2) identify opportunities to improve, and (3) measure their client impact through continuous analysis and experimentation. This role will support Vanguard’s senior management by supporting, developing and executing the product analytics efforts across EA’s global advice product lines and work closely with data engineering teams as well as product owners to build the above-mentioned analytics infrastructure, ask strategic business questions to define product success measures, and track success over time to derive key insights that drive product adoption and improve outcomes for end-investors. Successful candidates will excel in these three areas: 1. Technical ability: Demonstrated work experience in each of the following areas: Analytics Engineering: Building resilient, reusable data pipelines that transforms unstructured big data and organizes it into requisite number of structured tables for analytical use, that can either be updated daily or in an event-driven manner. Expertise in this area is usually demonstrated through experience building pipelines for similar use-cases and knowledge of pitfalls / failure scenarios. Data Structures: Experience as well as knowledge of basic computer science fundamentals includes but not limited to data structures, computational complexity, etc. Expertise in this area is usually demonstrated primarily through work experience building efficient algorithms to address business needs and optionally through undergraduate level computer science coursework. SQL / SparkSQL: Constructing complex SQL queries to perform multiple data transformational operations. SQL or specifically SparkSQL (from within Jupyter notebooks with Pyspark kernels) is the most heavily used technical skillset on our team and allows us to derive insights from raw data and construct high-quality datasets that can then serve as inputs to the rest of the enterprise. It is also expected that switching from SQL to pure programming is within reach. Foundational Linear Algebra: Foundational knowledge and experience of the basic foundations of Machine Learning usually exhibited by the ability to derive as well as explain linear regression, k-means, logistic regression from first principles. This role will benefit from a thorough understanding of the underlying assumptions (and motivations) of linear regression more than it will from a wide-ranging experience with the latest Neural Network architecture(s). 2. Strategic thinking: Proven ability in managing complex projects, formulating business and analytical problems. Asking the right questions, problem solving, and the ability to synthesize a variety of complex data points and inputs is necessary to identify the most salient metrics in driving product enhancements. Apply a deep level of understanding of Vanguard products, businesses, and clients, to develop product-level analytics strategies and identify the best approach to meet the needs of the various stakeholders and businesses in support of their key objectives. Comfort working with complex investment products. 3. Communication: This candidate will develop highly effective working relationships with internal clients, senior leaders, and key stakeholders and need to collaborate across a variety of different team members including product owners, methodology specialists, solution consultants, product strategist, business UX teams, etc. Strong executive presence and presentation of findings and results, as well as consultative support to the broader organization will be required as we build out and enhance the product analytics capabilities. Demonstrated experience in communicating complex analytical solutions, data relationships, and results and their business impacts to multiple business partners via data visualization, oral, and written communication methods. Core Responsibilities 1. Develops queries and performs extensive programming to access, transform, and prepare data for statistical modeling. 2. Performs deep dive diagnostic, predictive, and prescriptive analytics to support data-driven business decision making. 3. Identifies and diagnoses data inconsistencies and errors, documents data assumptions, and forages to fill data gaps. 4. Engages with internal stakeholders to understand and probe business processes in order to develop hypotheses. Brings structure to requests and translates requirements into an analytic approach. 5. Guides test design, research design, and model validation. Provides statistical consultation services. Serves as the analytics expert on cross functional teams for large strategic initiatives and contributes to the growth of the Vanguard analytic community. 6. Prepares and delivers insight presentations and action recommendations. Communicates complex analytical findings and implications to business partners. 7. Participates in special projects and performs other duties as assigned. Additional Responsibilities: Own, lead and execute on engineering components of analytics projects Serve as the analytics infrastructural / engineering expert on teams to enable large strategic initiatives; engage with project sponsors and stakeholders to understand the business and bring structure and translate needs into requirements through analytic approach Acquire structured and unstructured data and prepare it for analysis Investigate, extract, clean, transform, quality control, and manage data using Python, Spark, SQL from a variety of data sources including but not limited to AWS S3, Glue catalogs, etc Own, lead, execute and serve as the SME on infrastructural aspects of the role that include but are not limited to configuring AWS Service Catalog, YARN, Livy to successfully execute Jupyter Pyspark notebooks to completion Knowledge of / Interest in appropriate analytic methods and specialized tools to generate insights, answer the business questions, and fulfill project objectives Develop and apply knowledge of the company’s businesses and data to shape the analytic road map; contribute to the growth of the analytic community; mentor team to adopt best analytics engineering aspects Qualifications Minimum of three years related work experience in analytical roles. Experience with data wrangling required - Programming skills to access, transform and prepare large scale data for statistical modeling. Experience utilizing statistical and machine learning methods required. Undergraduate degree in Analytics, Applied Mathematics, Economics, Statistics or related analytical field of study or equivalent combination of training and experience. Graduate degree preferred. Special Factor Vanguard is not offering visa sponsorship for this position. About Vanguard We are Vanguard. Together, we’re changing the way the world invests. For us, investing doesn’t just end in value. It starts with values. Because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. We invest with purpose – and that’s how we’ve become a global market leader. Here, we grow by doing the right thing for the people we serve. And so can you. We want to make success accessible to everyone. This is our opportunity. Let’s make it count. Inclusion Statement Vanguard’s continued commitment to diversity and inclusion is firmly rooted in our culture. Every decision we make to best serve our clients, crew (internally employees are referred to as crew), and communities is guided by one simple statement: “Do the right thing.” We believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. We empower our crew to contribute their distinct strengths to achieving Vanguard’s core purpose through our values. When all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on Vanguard's core purpose. Our core purpose: To take a stand for all investors, to treat them fairly, and to give them the best chance for investment success. Future of Work During the pandemic, we transitioned to a work from home model for the majority of our crew and we continue to interview, hire, and on-board future crew remotely. As we have developed the path forward, we have taken a thoughtful approach that both maximizes the advantages of working remotely and the many benefits of coming together and collaborating in a shared workspace. We believe that in-person interactions among our crew are important for preserving our unique culture and advantageous for the personal development of our crew. When our Crew return to the office, many will work in our hybrid model. A smaller proportion of our crew will operate in the Work from Home work model (for example, field sales crew); or in the Work from Office model (for example, portfolio managers). The working model that your role falls into will be communicated to you in the interview process – please do ask if you are unsure. We encourage you to make the decision regarding your job interview and offer knowing which model your role will fall into. We will test and learn as our ways of working evolve and will continue to evaluate working models along the way."
Data Engineer,Initiate Government Solutions,+1 locationRemote,https://www.indeed.com/rc/clk?jk=e7374a8cca7dbb9a&fccid=60c0b6dcba006ccf&vjs=3,"Description: Founded in 2007, Initiate Government Solutions (IGS) a Woman Owned Small Business, specializes in healthcare information solutions with an emphasis on technology spectrum. IGS partners with government and commercial clients to tackle the most challenging healthcare information technology issues including large scale implementations, business informatics, analytics, and electronic health record support. IGS is currently recruiting for a remote Data Engineer to support our work with the Department of Veteran’s Affairs. Assignment of Work and Travel: This is a remote access assignment. Candidate will work remotely daily and will remotely access VA systems and therein use approved VA provided communications systems. Travel is not required; however, the candidate may be required to attend onsite client meetings as requested. Responsibilities and Duties (Included but not limited to): Data preparation experience using SQL or scripting languages to create ETL processes Perform data cleansing and check data integrity Design of new reports, interactive artifacts, or data visualizations Assemble large, complex data sets that meet functional / non-functional business requirements Identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability . Requirements: Bachelor’s degree in Computer Science, IT or similar fields Minimum 5 years of relevant experience as a Data Engineer with experience working with databases, data modeling, data management, and data curation Experience with Python, Splunk, Data Bricks, Jvbn (Ensemble), ETL Capable of supporting and working with cross-functional teams in a dynamic environment Technical expertise with data models, data mining Must be able to obtain and maintain a VA Public Trust clearance Excellent analytical and organization skills Excellent verbal and written communication skills Preferred Qualifications and Core Competencies: Active VA Public Trust Current or prior VA experience Prior, successful experience working in a remote environment Proof of vaccination will be required upon hire and reasonable accommodations will be considered on a case-by-case basis. Benefits: Initiate Government Solutions offers competitive compensation and a strong benefits package including comprehensive medical, dental and vision care, matching 401K, paid time off, flexible spending accounts, life insurance, disability coverage, an education assistance program, employee recognition program and spot bonuses, and other benefits that help provide financial protection for you and your family. Initiate Government Solutions participates in the Electronic Employment Verification Program. Initiate Government Solutions is an equal opportunity employer. Our company policy is to provide equal opportunity in all areas of employment practice without regard to race, color, religion, sex, sexual orientation, national origin, age, marital status, veteran status, citizenship or disability."
Senior Data Engineer,Gathi,Remote,https://www.indeed.com/rc/clk?jk=347da2b7e01b0527&fccid=af71395dc7e821c6&vjs=3,"Sr Data Engineer- San Antonio In this role, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. You will support our software developers, database architects, data analysts and data scientists on initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. You are self-directed and comfortable supporting the data needs of multiple teams, systems and products. You are excited by the prospect of optimizing and innovating existing data architecture to support the next generation of products and data initiatives. Responsibilities This requires understanding of the activities involved in legacy ETL code to migration of to Cloud using latest technology stack like data build tool and Snowflake database. Leverage existing/build new processes/framework to for quicker and control migration. This involves and not limited to: Analysis and Reverse Engineering of Data Stage code. Develop ELT data pipeline to migrate applications using DBT and Snowflake framework Scheduling and dependency management of data pipeline with proper auditing Register and Build ingestion pipeline with test automation of code. Implement test automation in the data pipeline. Build detailed technical design, conduct analysis, development of applications and proof of concepts. Responsible for translating functional ETL requirements into a technical design document, building the DataStage jobs and sequences to pull data from the source into staging tables, from staging tables into historical tables using Change Data Capture methodologies, and then from historical tables into dimensional data marts for reporting. Communicate progress across organization and levels from individual contributor to senior executive. Identify and clarify issues/problems that need action and drive appropriate decisions and actions relating to system integrations, compatibility, and multiple platforms. Research, test, build, and coordinate the conversion and/or integration of new products based on client requirements. Design and develop new software products or major enhancements to existing software. Overseeing the testing, implementation, maintenance, and enhancement of the applications. Consult with project teams and end users to identify any further application requirements. Troubleshoot and resolve software issues and respond to suggestions for improvements and enhancements. Instruct, assigns, directs, and checks the work of other software developers on development team. Participate in development of software user manuals. Design and build applications as per the given requirement adhering to the guidelines. Ensure consistent unit testing and support the technology infrastructure team implementation. Notify clients once updates have been made. Requirements Bachelor’s Degree or master’s degree in Computer Science, Mathematics, Statistics. 5+ years of experience as a DataStage Developer. 5+ Years of complex SQL / PL SQL development experience 2+ years of experience in writing scripts using Unix or Python Experience working in Agile framework 3+ years of experience in Migration from Data Stage to other technologies Working experience on AWS"
Data Engineer,Wise Equation Solutions,"La Vista, NE 68128",https://www.indeed.com/rc/clk?jk=d2551aa7b146492e&fccid=947ba4c552c2afc0&vjs=3,"Analyze Business Requirement Documents and Implement Technical Solutions for privacy related applications. Develop ETL process for supporting Data Extraction, transformations and loading. Perform data conversions and aggregations using different transformations such as Merge, Merge join, Union condition split, sort, order by. Derived columns convert and cast transformations and row count and lookup and fuzzy lookup transformations. Develop UNIX scripts to load the data from Source server to Teradata and validate the files between different servers. Develop new process to implement state level privacy regulations based on each state law in Big Data Platform. Create Temperory/Fact tables, loading with data and writing Teradata and Spark SQL queries. Optimize/tune ETL objects, indexing and partitioning for better performance and efficiency. Validate the performance metrics and work on performance tuning for SQL, HQL and Spark SQL queries. Perform testing and Provide test support for various level of testing phases like Unit, User Acceptance, Regression, Parallel and System testing. Promote the components to production environment through CI/CD process by using Git hub . Script task and execute SQL tasks to execute SQL code. Work on containers for loop and for each loop container to run a group of tasks into a single container and repeating tasks. Create the data flow to extract data from sources to OLEDB Source, Excel, XML, flat files sources and destination is SQL data warehouse. Minimum Education Required:- All the responsibilities mentioned above are in line with the professional background and requires an absolute minimum of a Bachelor’s degree in computer science, computer information systems, technology management, or a combination of education and experience equating to the U.S. equivalent of a Bachelor’s degree in one of the aforementioned subjects."
Data Engineer,CAPCO,"Houston, TX+2 locations",https://www.indeed.com/rc/clk?jk=f6c0cf099c283a2c&fccid=c2a63affe8751868&vjs=3,"Data Engineer About the Team: Capco specializes in advisory, implementation, and delivery of client-centered solutions across Financial Services, Energy and the Insurance industries. We support modern platform implementations, product innovation, digital transformations, end-to-end IT delivery embedded with DevOps practices and service-oriented architecture, omni-channel standardization, cloud-based data management, predictive data analytics. Working in collaboration with our digital team and industry domain practices, we advise clients with solution offerings to leverage technology to deliver efficiency, optimization and end-customer satisfaction. About the Job: As a member of the Technology team, you will help define, establish, and evolve our full-stack development capacities. You will be tasked in creating innovative solutions that advance our clients businesses. You’ll join a strong and inspiring team of technologists dedicated to improving the design, analytics, development, coding, testing and application programming that goes into creating high-quality software and new products. You’ll be tasked with keeping the team and other key stakeholders up to speed on the progress of what’s being developed. What You’ll Get to Do: You’ll be creating data pipelines, extracting data from our various applications You’ll be creating curated datasets that are conducive for stakeholder consumption You’ll be partnering with Data Analysts to ensure business requirements are met You’ll be supporting our Engineering team, providing database design support You’ll operate high-quality, cloud-based data services What You’ll Bring with You: 4+ years of experience in a Data Engineering role You have built and managed Data Lakes & Data Warehouses You have experience with big data solutions Good understanding of APIs and data processing Data manipulation tools such as: SSMS, SSIS, TOAD, Access, Excel Database handling language (SQL and variants) Data Visualization tools Solid track record of partnering and supporting Business Intelligence, Analytics and Data Science requirements. Bachelors Degree Why Capco? A career at Capco is a chance to help reshape the competitive landscape in financial services. We launch new banks, transform existing ones, and help our clients navigate complex change. As consultants, we work on the front-end business design all the way through to technology implementation. We are the largest Financial Services focused consultancy in the world, serving everyone from global banks to emerging FinTechs, from strategy through digital transformation, design, business consulting, data and analytics, cyber, cloud, technology architecture, and engineering. Capco is a young and growing firm. We maintain an entrepreneurial spirit and growth mindset, and have minimal bureaucracy. We have no internal silos that get in the way of your career opportunities or ability to focus on our clients and make a difference to the business. We offer the opportunity for everyone to learn rapidly, take on tough challenges, and get promoted quickly. We take pride in our creative, collaborative, diverse, and inclusive culture, where everyone can #BYAW. We offer highly competitive benefits, including medical, dental and vision insurance, a 401(k) plan, tuition reimbursement, and a work culture focused on innovation and creation of lasting value for our clients and employees. Ready to Take the Next Step? If this sounds like you, we would love to hear from you. This is an opportunity to make a difference and contribute to a highly successful company with a significant growth trajectory."
Supervisor - Data Engineer,Dassault Falcon Jet,"Little Rock, AR 72202 (Bill and Hillary Clinton National Airport area)",https://www.indeed.com/rc/clk?jk=49528b5153c4eda6&fccid=9ba13fd5f80ec40c&vjs=3,"*****REMOTE POSITION***** We offer a complete benefits package that includes medical, dental, vision insurance, vacation, paid holidays and a 401(k) plan. We'll even pay for your gym membership. As a Data Engineer Supervisor you will be responsible for leading and coordinating the daily activities for the Data Engineering group. In this role, you will lead and ensure the execution of data engineering activities on time, on budget and in compliance with Software Development Life Cycle (SDLC) processes and standards. PRINCIPAL DUTIES/RESPONSIBILITIES (ESSENTIAL FUNCTIONS): Supervise project, maintenance and support activities for the data engineering group. Take actions to keep project on track and alert on foreseeable issues Validate and lead the development, deployment, and support of Reports, ETL, scripts, Database scripts and Master Data Management solutions Analyze and evaluate change requests and solution analysis Ensure adherence to change management and data engineering procedures Define the data architecture of new solutions Assist in the definition of processes and standards for Report, ETL and Database development Promote Innovation, technology watch and market trend to provide up to date solutions Define the training plan for the Data Management team Supervises employees including hiring, terminating, evaluating performance, approving sick and vacation time and administering disciplinary actions."
"Data Pipeline Engineer, Technology Development Group (TDG)",Apple,"Cupertino, CA+1 location",https://www.indeed.com/rc/clk?jk=d6808a1e39e1ba92&fccid=c1099851e9794854&vjs=3,"Summary Posted: Feb 14, 2022 Role Number: 200344890 Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Data Pipeline Engineer that enjoys processing data at scale and all the challenges that are associated with it. As a member of a fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas: Key Qualifications 5+ years of experience developing data pipelines or equivalent related experiences Working Knowledge of Python Excellent problem solving and analytical thinking skills Expertise in Web development using Django (or other MVC frameworks), JavaScript/jQuery, CSS ,front-end JS Frameworks and HTML Comfortable in working with document stores (MongoDB, CouchDB) and relational databases (MySQL, PostgreSQL), Full-stack design experience Values developing comprehensive unit tests Knowledge of basic classical computer vision a big plus Experience with large scale software projects - source code control, continuous integration, documentation Able to quickly learn new and existing technologies Comfortable creating and using web based REST APIs Self-motivated, pro-active and solution-oriented individual Excellent oral and written English communication skills Strong attention to detail and excellent analytical capabilities Description You’ll be working in a team of data engineers to implement the magic behind the scenes that enables world class algorithms that push the state of the art. Your goal is to raise the quality and productivity of the team as a whole by building development tools and pipelines that allow everyone to work faster. Your job responsibilities will include: - Working with cross functional teams to implement data pipelines - Implementing and optimizing existing data processing pipelines - Cooperating with multiple teams to make sure they are efficiently utilizing every CPU cycle of our platform Education & Experience Bachelors Degree or 5+ years of industry experience in software engineering, DevOps, or related fields Additional Requirements"
Data Engineer,Entera,"Remote in New York, NY 10013",https://www.indeed.com/rc/clk?jk=1667f42ab2278a44&fccid=c8e07f37dc242ad2&vjs=3,"About Entera: We are a venture backed real estate technology company with the leading SaaS + Services platform for residential investors. Powered by machine-learning and 100% online, Entera's end-to-end residential real estate platform modernizes the real estate buying process to help our clients access and evaluate more properties, scale their operations, make data-driven investment decisions, and win more often. Many of the largest real estate investors in the world use Entera's marketplace daily. Entera's annual transaction run rate is over $3.6B across 24 markets since its launch in 2018. Entera has raised $40M of venture capital from some of the most established & trusted firms in the world. The company is headquartered in New York City, New York and Houston, Texas. The Role As a Data Engineer, you'll contribute to our best-in-class data pipeline and data-driven culture. You'll work with multi-discipline experts with hard-science backgrounds in a tight knit team to deliver on our efforts around data curation and management. You'll work with modern ETL frameworks to prepare data for exposure to both our internal business users and customers via BI tools, internal APIs, and custom built services. Within our team, you'll be able to further develop your skills and work with a team of experts to deliver on massive improvements to our data pipeline and associated systems. What You'll Do: Use Python and SQL to improve upon a best-in-class data pipeline and develop our workflows Contribute to cloud-first services that support our analysis, reporting, and metrics collection efforts Make high-level data architecture decisions to meet our rapidly scaling business needs Support development processes with maintenance of CI/CD pipelines Deliver on detailed specifications for business intelligence and reporting needs Work with product and engineering in cross-functional teams to deliver on iterative improvements to our systems Build end-to-end data pipelines and create software components to tie together all pipeline stages, from data extraction, to loading, transformation, and exposure to downstream systems Write custom ETL processes in Python and SQL to load data into our data warehouse (Snowflake), export data to / sync with other systems, and generate new datasets Maintain ETL software dependencies in Docker Manage configuration and access to our data-related cloud resources and data warehouse using Terraform Help to define and improve our internal standards for style, maintainability, and best practices for a high-scale data infrastructure Contribute to and further develop our data-driven culture Who You Are: MS or PhD in Computer Science, Mathematics, Statistics, Physics, Economics, or similar hard-science 3-4+ years hands-on experience in Data Engineering at growing product-driven tech companies Proficiency in AWS cloud services Advanced capabilities in Python and SQL Production experience with Airflow, Prefect, or similar workflow orchestration frameworks Experience with Snowflake or similar data warehousing technologies Basic knowledge of / experience with Linux command line environments and Bash scripting Software development background (strong familiarity with version control systems, CI/CD, testing, system design) Strong analytical and problem solving skills Nice to have: Understanding of dbt or similar data transformation frameworks Understanding of Spark Entera is proud to be an equal opportunity employer (EEO) that celebrates difference and diversity. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We are committed to building an inclusive work environment where all employees feel a sense of belonging and respect. If there is anything we can do to ensure you have a comfortable and positive interview experience, please let us know."
Software Engineer - Data Processing and Machine Learning Pla...,Hewlett Packard Enterprise,"San Jose, CA 95002 (North San Jose area)+1 location",https://www.indeed.com/rc/clk?jk=56f1e34b37ced9a3&fccid=216eb700022de6f6&vjs=3,"Software Engineer - Data Processing and Machine Learning Platform This role has been designated as ‘Edge’, which means you will primarily work outside of an HPE office. Job Description: Hewlett Packard Enterprise advances the way people live and work. We bring together the brightest minds to create breakthrough technology solutions, helping our customers make their mark on the world. Hewlett Packard Enterprise (HPE) is seeking an outstanding Software Developer to play a key role in developing an industry-leading HPE analytics solution – HPE GreenLake Cloud Platform (GLCP). HPE GLCP provides the infrastructure and services to collect and analyze more sensor data points from our customers’ infrastructure systems and applications than there are stars in our galaxy. Predictive Analytics are then used to correlate vast amounts of information to find the needle in the haystack and solve our customers’ most complex infrastructure issues. You will be joining an agile, empowered team, focused on extending GLCP to support Data Science use cases. Currently, HPE GLCP provides abstractions, components and infrastructure for running data processing workloads. The team leverages the latest big data and microservice-based technologies to build out the data processing platform – Apache Spark/PySpark, Jupyter, Delta Lake, Kubernetes, GraphQL, TimescaleDB, Postgres. The development stack is Scala (cats, http4s, Caliban, shapeless, lagom). The next step in the evolution of HPE GLCP involves a focus on machine learning (training and inference). The goal is to provide a platform for data scientists and machine learning engineers that is self-service, easy to use, and meets enterprise scaling requirements. In a typical day as a Software Engineer - Data Processing and Machine Learning Platform, you would Be a technical contributor, as a software developer, in a cross-functional development team, focused on building out a full featured Machine Learning platform Work with the Data Science teams to create and evolve the data platform to enable both exploratory analytics and Machine Learning Leverage big-data technologies for data processing, including Apache Spark, Kubernetes, Apache Pulsar, AWS (Lambda, S3) Contribute to the data platform ecosystem, including implementation of microservices or serverless components using Scala, http4s Work with the DevOps engineers to design and build observability features (telemetry, tracing) and CI/CD Develop unit, integration, system or any tests that are needed to help the team deliver value quickly, with a high degree of quality If you are… Good at partnering, innovating, and making things happen. You are aligned to our core values. Holding a Bachelor's or Master's degree in Computer Science, Information Systems, or equivalent A professional with strong analytical and problem solving skills Experienced 5+ years in software application design tools and programming languages such as Java or Scala Having strong distributed systems knowledge A professional with Spark/Pyspark Optimizing ML systems for cost, latency and throughput Designing declarative ML pipelines, data processing experience at scale and automating lifecycle of ML jobs Modeling compilation, and inference on heterogenous hardware TensorFlow/Keras/Hopsworks Excellent in verbal and written communication and presentation Join us and make your mark! We offer: A competitive salary and extensive social benefits Diverse and dynamic work environment Work-life balance and support for career development An amazing life inside the element! Want to know more about it? Then let’s stay connected! https://www.facebook.com/HPECareers https://twitter.com/HPE_Careers HPE is an Equal Employment Opportunity/ Veterans/Disabled/LGBT and Affirmative Action employer. We are committed to diversity and building a team that represents a variety of backgrounds, perspectives, and skills. We do not discriminate and all decisions we make are made on the basis of qualifications, merit, and business need. Our goal is to be one global diverse team that is representative of our customers, in an inclusive environment where we can continue to innovate and grow together. #hpecto #greenlakecloudplatform Job: Engineering Job Level: Specialist COLORADO ONLY: We are legally required to provide the following information for candidates seeking to staff this role in Colorado. The Colorado expected salary/wage range for this position is listed immediately below, although we reserve the right to offer above this range for exceptional candidates. Actual offer may vary from this range based upon geographic location, work experience, education, and/or skill level. Bonus, commission, and/or equity may also be offered. Information about employee benefits offered can be found at https://ah-prod.com/hpebennav/newhire.html. Annual Salary: $97,000.00 - $140,000.00 Hewlett Packard Enterprise is EEO F/M/Protected Veteran/ Individual with Disabilities. HPE will comply with all applicable laws related to the use of arrest and conviction records, including the San Francisco Fair Chance Ordinance and similar laws and will consider for employment qualified applicants with criminal histories."
Data Engineer,Object Computing Inc.,Remote,https://www.indeed.com/rc/clk?jk=9c2c1631bef5ebd3&fccid=9c6d53258d26f231&vjs=3,"Object Computing, Inc. is seeking a mid-level data engineer (3+ years experience). As a data engineer, you'll be presented with opportunities to focus on cutting-edge technologies such as image processing, artificial intelligence, cloud computing, and database management. Responsibilities include defining and implementing highly scalable data infrastructures, supporting data-driven applications, translating analytics questions into data solutions, and optimizing a complex business space for new value creation for large volume data sets. You will utilize your hands-on experience with Python, relational databases, and cloud platforms. This opportunity can support remote work (exempt CO) What You Will Bring +3 years related experience in software development, data engineering, and big data +3 years programming experience with R or Python +3 years experience in a relational database like SQL. Query building to extract and manipulate data to achieve desired results using select statements, sub-queries, functions, links of multiple tables, scripting Applied emphasis on cloud based technologies Data experience through the use of technologies such as Hadoop, MapReduce, Spark, Kafka, and SDN/NFV Clear & regular communication with business leadership and technical support colleagues on technical details & resulting insights generated from work Recommendation improvements to in-work and existing software programs as necessary Creative problem solving, resourcefulness in getting things done, and productivity created working independently or collaboratively Strong organizational and interpersonal skills What Will Make You Stand Out Cloud Certification - Data Engineer such as Google Cloud Professional Data Engineer Embedded systems experience Deployment of Machine Learning (ML) models/algorithms Working collaboratively with data science/analytics team members to integrate & scale complex ML/Deep Learning (DL) algorithms At Object Computing, Inc. we offer team members a supportive, creative, and collaborative environment where they are encouraged to enhance their collective skills and employ industry best practices. We embrace continuous learning, professional development, and foster a community that welcomes change and growth. We proudly build transformative technology solutions by leveraging open source software and our strategic partnerships with organizations like Amazon and Google. By purposefully engaging with our clients, we help them reimagine the impact and value they can achieve using smart, connective technologies. OCI has expertise in constructing solutions in a variety of industries including: Aerospace, Energy, Financial Services, and Agriculture. We partner with clients to deliver software solutions that accelerate innovation within their organization and stand up to the evolving demands of their business. Our full life cycle software engineering solutions span multiple technology domains including real-time, embedded, large-scale, integrated, and distributed systems, to modern web and cloud-enabled applications."
Data Integration Engineer 1,"Hy-Vee, Inc.","Remote in West Des Moines, IA+1 location",https://www.indeed.com/rc/clk?jk=8b3b422891bafffc&fccid=6837147f8d33dcd7&vjs=3,"At Hy-Vee our people are our strength. We promise “a helpful smile in every aisle” and those smiles can only come from a workforce that is fully engaged and committed to supporting our customers and each other. Job Description: Job Title: Data Engineer 1 Department: Information Technology FLSA : Exempt General Function An entry level professional who assists in development, implementation, and support of data pipelines for a specific area with strong mentorship and guidance. Core Competencies Partnerships Growth mindset Results oriented Customer focused Professionalism Reporting Relations Accountable and Reports to: TBD Positions that Report to you: TBD Primary Duties and Responsibilities Design, Create and maintain on premise and cloud based data integration pipelines. Assemble large, complex data sets that meet functional/non functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources. Build analytics tools that utilize the data pipeline to provide actionable insights into key business performance metrics. Research and work on data-related technical issues and support tickets. Create data pipelines to enable BI, Analytics and Data Science teams that assist them in building and optimizing their systems Knowledge, Skills, Abilities, and Worker Characteristics Basic Understanding of Database Programming Language (T-SQL, SQL, PLSQL, etc.) Basic understanding of RDMS systems Basic understanding of ETL Tools Experience and Education Bachelor degree preferred, or relevant experience. Supervisory Responsibilities (Direct Reports) None Physical Requirements Visual requirements include: ability to see detail at near range with or without correction. Must be physically able to perform sedentary work: operating a computer, occasionally lifting or carrying objects of no more than 10 pounds, and occasionally standing or walking. Must be able to perform the following physical activities: meeting with customers, kneeling, reaching, handling, grasping, feeling, talking, hearing, and repetitive motions. Working Conditions The duties for this position are performed in a general or remote office setting. There is weekly pressure to meet deadlines and handle multiple tasks in a day. Equipment Used to Perform Job Laptop and desktop computer, telephone, copier, Fax, printer, PC with Microsoft Office programs and other software relevant to specific position. Financial Responsibility None Contacts Has frequent contact with office personnel in other departments related to the position as well as occasional contact with users and customers. Confidentiality Has access to confidential information. Are you ready to smile, apply today."
Research Engineer – Data Science,"Honda Dev. and Mfg of Am.,LLC",Ohio,https://www.indeed.com/rc/clk?jk=37b04c68616269ab&fccid=dd616958bd9ddc12&vjs=3,"Research Engineer – Data Science ( Job Number: HRA00027H ) Honda Dev. and Mfg of Am.,LLC Description Research Engineer – Data Science Honda has a clear vision for the future in 2030, and it’s a joyful one. We are looking for people with the individual skills, courage, persistence, dreams that will help us reach our future-focused goals. We are seeking diversity of thought and experience to drive innovation and help us make fully informed decisions. Research Engineer – Data Science will be responsible for conducting research and development activity using applied scientific and engineering principles in the Data Science domain including data engineering, feature development, ML/AI algorithm development, platform stacks and system performance, as well as core research in methods and frameworks. At Honda, our associates take pride in their responsibilities. A typical day for a Research Engineer – Data Science will include: Responsible for completing and communicating research outcomes. Provides extensive, highly specialized, engineering skills, and applies scientific principles, technical problem solving and developing solutions in broad areas of assignments to design, develop, and complete research outcomes. Coordinates and engages internal and external expertise and resources. Stays connected to research roots as an active contributor and participant to the wider research community by partnering with internal stakeholders, universities, and developer communities. Maintains substantial knowledge of state-of-the-art principles and theories. To bring the future to Honda as Research Engineer – Data Science you must have: Qualifications Bachelors (CSE Engineering or related, Math/Stats etc.) or higher 0-5 years Passion for research, solving hard problems, and challenging the status quo. Design experiments to test hypothesis and prove them out. Scientifically analyze data provided from tests and experiments to gather knowledge and understanding of the subject of research. Knowledge and Skills Passion for research, solving hard problems, and challenging the status quo. Design experiments to test hypothesis and prove them out. Scientifically analyze data provided from tests and experiments to gather knowledge and understanding of the subject of research. Additional Position Information Must take initiative, be self-sufficient and work independently. Be capable to compare different approaches, methodologies, materials to develop the best outcome. Undertake self-directed continuous training and technical development. Total Rewards Competitive Base Pay Medical, Dental, Vision Remote Work Opportunities Bonus Program 401K Program Honda Product Programs Company Car Program Honda is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status, or any other protected factor."
Splunk Log Data Engineer,Geologics Corporation,"Reston, VA",https://www.indeed.com/rc/clk?jk=aec85b48f4fd25df&fccid=7c6a7a753350e467&vjs=3,"Log Data Engineer Remote $54 - $74 per hour* US Citizenship & Residency Required Are you a Systems Engineer with experience across a smorgasbord of operating systems and networks? Do you get satisfaction in bringing order to chaos? Are you interested in a remote role with the option of working a 4/40 work week at a great rate? Look no further! Your mission in this very large project will be to efficiently and securely centralize and normalize the logs of many applications into Splunk. This will involve working with customers to plan the best log transportation route, setting up and managing new log feeds, and creating monitoring for the newly created feeds. You'll need that wide range of experience as source systems could be Windows or Linux and the applications may have unique log storage and transmission capabilities requiring creative solutions. You'll be responsible for maintaining operation of multi-user computer systems, including coordination with network engineers. Your wide ranging duties may include setting up administrator and service accounts, maintaining system documentation, tuning system performance, installing system wide software and allocate mass storage space. We'll look to you to make recommendations to purchase hardware and software, coordinate installation and provide backup recovery. And if that's not enough, you'll also need to develop and monitor policies and standards related to the use of computing resources. Piece of cake, right? It will be if you're a US Citizen with: 18+ Years experience with a HS diploma, 14+ exp Years with AA. 12+ years with BS. 10+ years with MS or 7+ Years with PhD including: 5+ Years of System Administration 5+ Years of Log Administration (Splunk, ArcSight, Syslog, etc...) 3+ Years of Scripting and/or Programming 3+ Years of Customer Service 1+ Years of AWS, DevOps, Network Administration and Operations, or Security Operations Certificates in Splunk, Networking, and System Administration System Administration: Primarily Linux, but also Unix and Windows Strong Networking: Understanding of various transportation protocols (HTTP, FTP, SSH -SCP and SSH tunnels), Syslog, raw TCP, etc... Scripting: BASH, Python, PowerShell, Perl, Expect, etc... Splunk Usage and Administration including DBConnect System and Network Troubleshooting: Familiar with TCPDump, trace routing, analyzing PCAP, etc.. Excellent communication and documentation skills Experience with Ticketing systems: ServiceNow, Jira being used ArcSight Usage and Administration desired Apache Nifi a plus Data Engineering: Regex, sed, Splunk Query Language, etc. helpful Docker, Compose, Swarm Mode preferred AWS S3, EC2 a plus We're ready to hire! Follow the link below to apply today for swift consideration and quick response. #CB Amy Cody-Quinn Sr Recruiter acquinn@geologics.com Rates listed are not a guarantee of salary/rate. Rate offered at time of hire will depend on many factors including education, experience, interview results and skill level US Citizenship and Residency required for this direct W2 hourly defense industry contract. GeoLogics is an Equal Opportunity/Affirmative Action Employer that is committed to hiring a diverse and talented workforce. EOE/Disability/Veteran"
Consulting Data Integration Engineer (BI Specialist),HCA Healthcare,"Nashville, TN 37203+1 location",https://www.indeed.com/rc/clk?jk=b83f2bbb0bb45a34&fccid=372688670c2370a2&vjs=3,"Description SHIFT: No Weekends SCHEDULE: Full-time Consulting Data Integration Engineer (BI Specialist), needed to perform job duties in the area of Business Intelligence. Design and develop dashboards and reporting tools to retrieve data from data warehouses of information. Utilize Microstrategy and its products Command Manager, SDK, System Manager, Architect, Developer, and Administration. Will use SSRS & PowerBuilder and work with a SQL Server database. The employee may work remotely from home within commuting distance of Nashville, TN up to 3 days per week. Must have a Bachelors' degree in computer science or engineering and 5 years of overall progressive IT experience in the area of Business Intelligence which includes at least 2 years of experience in the skill sets listed in the job description. Send resumes to: elaine.healy@hcahealthcare.com Notice Our Company's recruiters are here to help unlock the next possibility within your career and we take your candidate experience very seriously. During the recruitment process, no recruiter or employee will request financial or personal information (Social Security Number, credit card or bank information, etc.) from you via email. The recruiters will not email you from a public webmail client like Gmail or Yahoo Mail. If you feel suspicious of a job posting or job-related email, let us know by clicking here. For questions about your job application or this site please contact HCAhrAnswers at 1-844-422-5627 option 1."
Data Engineer,Raland Compliance Partners,"San Diego, CA",https://www.indeed.com/rc/clk?jk=c1ec0079e1e0b965&fccid=cc2fa09b01fc3fe6&vjs=3,"Contract-To-Hire As a Data Engineer, you’ll be an early, core contributor on a dynamic, highly collaborative team delivering new data and insights from enterprise data while leveraging and deepening your skills in development of data pipelines, real-time data observability, orchestration, test automation, and continuous integration. Essential Duties and Responsibilities: Design, build, deploy, and improve data pipelines, driven by data replication or Kafka event streams for data ingest, curation, and analytics-specific data preparation / wrangling. Collaborate with distributed teams of data scientists and analytics engineers to discover analytic requirements and data sets to ingest. Curate, and wrangle analytic data sets for analytics with DBT Cloud and Snowflake. Write SQL test formulas to detect anomaly events. Qualifications: Passion and eagerness to learn, grow, and contribute to improve our team Expertise in complex SQL queries, Apache Airflow, and DBT 3+ years of combined work experience in data engineering and cloud data warehouses Expertise with data profiling, transformations, end-to-end orchestration of dependent workflows built with multiple tools, therein efficiently moving terabytes Affinity for not just Agile, but also a DataOps culture with infrastructure as code, automation of tests and deployments, observability for anomaly detection, and end-to-end pipeline ownership. Preferred Experience: Translating vague requirements for analytics into actionable user stories. Snowflake, GitHub, replication (FiveTran, HVR, Qlik, Meltano, Airbyte, Stitch) Broad data modeling expertise: 3rd normal, star schema, wide-table, sub-type / super-type, data vault. Confidence in choosing among data modeling approaches, knowing the load logic for each. Python fundamentals, some Jinja or Pandas ELT from Oracle or SQL Server Experience with continuous integration / continuous delivery (CI/CD) Familiarity with Jira and Confluence Minimum Education Level: Bachelors degree in computer science, business analytics, or related technical curricula, or an equivalent combination of working experience and certifications relevant to the above qualifications. Functional Description: Technical Individual Contributor Supports and maintains software-as-a-service (SaaS) and enterprise-wide applications associated with the collection, retrieval, accessibility and usage of data for internal department planning and activities. Performs basic configuration, setup, and updating of application, including table definitions and access control. Enters and ensures validity of data in databases. Builds and produces reports using query and flexible reporting tools to meet the requirements of business management and staff. Recommends changes in applications development, maintenance and system standards. Travel Required: Up to 15% Functional/Business Knowledge: Possesses substantial knowledge of leading technical areas. Externally recognized as a being proficient in technical field. Scope: Solid understanding to solve unique problems where analysis requires an in-depth evaluation and may impact future concepts or technologies. Judgement: Exercises independent judgment in developing methods, techniques and evaluation criteria for obtaining results. Demonstrates ability to discover and identify processes, novel science and technology which lead to increased productivity and improve outcomes."
Frontend Engineer - Marketplace Intelligence and Data,Uber,"San Francisco, CA 94103 (South of Market area)+2 locations",https://www.indeed.com/rc/clk?jk=24af00f797f280f6&fccid=f766f8bfbc3effb7&vjs=3,"About the role: Collaborates with team members to design, develop, and maintain user interfaces and features for web applications that meet the design, functionality, and complexity needs of end users. About the Team: The Product Intelligence team builds high-quality datasets, metrics, ML features, and data tools. As a front-end engineer, you will be responsible for designing and building tools that empower everyone in the company to make the best use of all the data Uber has. You will be the key to connect hundreds of Petabyte-level data sources to actual business use cases. You will directly impact the day-to-day work of tens of thousands of internal users such as operation managers, customer support agents, data scientists, engineers, and executives. Minimum qualifications: Bachelor’s degree or equivalent in Computer Science, Engineering, Mathematics or related field OR 1-year full-time Software Engineering work experience, WHICH INCLUDES 1-year total technical software engineering experience in one or more of the following areas: Programming language (e.g. JavaScript, CSS) Note the 1-year total of specialized software engineering experience may have been gained through education and full-time work experience, additional training, coursework, research, or similar (OR some combination of these). The year of specialized experience is not necessarily in addition to the years of Education & full-time work experience indicated. Technical skills: Required: API design Modern javascript Preferred: Modern js framework UX Static typing systems At Uber, we ignite opportunity by setting the world in motion. We take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 600 cities around the world! We welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently. If you have a curiosity, passion and collaborative spirit, work with us, and let’s move the world forward, together! Uber is proud to be an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Data Engineer,ACS Group,"Dallas, TX",https://www.indeed.com/rc/clk?jk=a92b0a2afab1e54d&fccid=3c7060c447d3c5c5&vjs=3,"Details of the Job: Senior Developer, Data Engineer who is proficient in data discovery and governance and an expert in data engineering and data movement technologies such as SQL and ETL. Responsibility: Helping to understand the client data needs, profile and prep the data, and create pipelines that extract data from multiple systems, transform it and load it into a centralize Snowflake environment. Qualifications and Requirements Profile Data and populate Data Dictionary Prep data for ingestion Design and build data pipelines Write tests and code Identify and correct bottlenecks and fix bugs Help maintain code quality, organization, and automatization-Identifies and manages non-functional requirements Work collaboratively with team to develop Data governance Collaborate on creating stories (use cases, technical and functional requirements), 4+ years of data discovery experience 4+ years professional experience with integrating data across multiple systems(Oracle,Snowflake, AWS) You should be an expert in one or more ETL technology stacks, preferably Domo or Snowflake, and have curiosity and willingness to become an expert in others Proficient in SQL Strong knowledge of technical design principles, patterns, and best practices Experience with unit testing and other automated testing methods Great familiarity with development lifecycle and DevOps Experience working in an agile environment Strong attention to detail Strong listening and communication skills"
Engineer - Data,SafeGraph,+1 locationRemote,https://www.indeed.com/rc/clk?jk=019e68beff650949&fccid=a7d44e65387f5f78&vjs=3,"Join SafeGraph’s small but growing Engineering team. You'll spend your time using functional programming to build and improve upon our product - the most accurate dataset on places in the US - and solving interesting data problems in the geospatial and temporal world. You should be excited by the prospect of shaping the vision of and building something new, getting in at the ground floor and helping the SafeGraph team continue to build and support a world-class data product. About you: Have attention to detail and bias for action, are a prolific communicator, and thrive in uncertainty. Are passionate about big data, looking to work in a fast-paced environment, focusing on hard problems where the solutions are often not predefined. Authorized to work within North America and are comfortable working remotely. Requirements: Minimum 3+ years of backend engineering work experience. Proficiency in writing production-quality code, preferably in Scala, Java, or Python. Familiarity with all things building data products - schema design, modeling, optimization, scalability. Deep understanding of Apache Spark and distributed data systems - that allows you to solve production-scale problems. Excellent communication skills. Great-to-haves: Experience and passion for functional programming in solving data problems (Scala). Experience with AWS. Experience working with huge data sets. Experience with building ML models from the ground up. Experience with open source development. About SafeGraph: Our goal is to be the dominant place to get any data on a physical Place. We sell our product - our datasets - to data scientists and machine learning engineers at companies of all sizes. At SafeGraph, we’ve taken a measured approach to building a long term company. We were profitable in 2019, have hired experienced leadership from the start and care deeply about democratizing access to data to everyone. We currently have over 110 employees and are growing. We recently raised a $45 million Series B ($65 million raised to date), and the CEO was previously the founder and CEO of LiveRamp (NYSE:RAMP). While SafeGraph was started in San Francisco, we’ve been fully distributed across North America since 2019 — 18 states and provinces! We get the entire company together in the same place as often as possible, and recently had a great company retreat in San Diego. We offer our employees a robust set of benefits, including health, dental & vision insurance coverage, a 401k, work-from-home stipend, mental health benefits, and much more."
Data Engineer,CEFCU,"Remote in Peoria, IL",https://www.indeed.com/company/CEFCU/jobs/Data-Engineer-48d8fef96cf730bf?fccid=3204d6b34e07eafd&vjs=3,"Are you ready to make the most of your talents and abilities, while helping others make the most of their finances? Apply to join Team CEFCU! CEFCU member service team members are critical to the success of the credit union. They provide a professional, knowledgeable, and caring experience when members contact us. We are looking for individuals who are personable, articulate, and positive to add to our already awesome team! Supports and helps implement CEFCU's Data and Analytics strategy. Helps to increase timely, transparent accessibility across the organization for CEFCU’s enterprise data via appropriate analytics and reporting resources. Helps expand, maintain and administer CEFCU’s primary analytics environment, including data model and dictionary, ELT processes, connector development, and more. Develops database models/data integration solutions and supports existing data solutions/platforms. Monday- Friday 8:00 am - 4:30pmAd-Hoc Work from homeRequired: Bachelor’s degree in computer or information science, or equivalent experience COBOL programming experience Knowledge of SQL Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Strong written and verbal communication skills Strong problem solving and analytical skills Preferred: CEFCU systems experience Experience in database administration Experience in metadata management Advanced working SQL knowledge and experience working with relational databases, data governance/data modeling, query authoring (SQL) as well as working familiarity with a variety of databases Experience working with Microsoft SQL Experience working with ETL or ELT in a data warehouse, data lake, or data mart environment. Experience data modeling (logical/physical, relational) Strong analytic skills related to working with structured and/or unstructured datasets. It is CEFCU’s policy and intent to provide equal opportunity to all persons without regard to race, color, religion, political affiliation, sex/gender (including gender expression/identity, pregnancy, childbirth and related medical conditions), marital status, registered domestic partner status, sexual orientation, age, ancestry, national origin, veteran status, disability, medical condition, genetic characteristics, and/or any other basis protected by law. This policy covers all facets of employment including, but not limited to: recruitment, selection, placement, promotions, transfers, demotions, terminations, training, and compensation. Job Type: Full-time"
Data Engineer (Remote),Vacasa,"Remote in Portland, OR+3 locations",https://www.indeed.com/rc/clk?jk=1e8ece5c49298c63&fccid=22f7ba07f9b31a96&vjs=3,"Why Vacasa We started with just one home and an idea: to bring homeowners and renters together with smart technology and caring local teams. Today, we're the largest full-service vacation rental company in North America thanks to the people who give us their best every day. You'll fit right in here if you're curious, entrepreneurial, and thrive in a rapid-growth environment. Why Software Engineering at Vacasa We build the tools that allow other departments to succeed. We're constantly experimenting and fine-tuning our products. We value stability, security, and scalability. Our favorite word is autonomy—we want everyone to have a voice. Position summary As a Data Engineer you will be responsible for maintaining the core platform and services that enable business intelligence at Vacasa. Working closely with data science and analytics teams you will play a key role in the design, build, and maintenance of data pipelines; providing timely, accurate, and reliable information to all aspects of the business. What you'll do Design, implement, and communicate the tooling required for data ingress, data transformation, and orchestration Develop data warehousing standards, transformations, and ingress patterns for production data sets Collaborate with engineering and product teams to ensure prioritization of BI and reporting goals Guide data modeling efforts, mentoring engineering and analytics teams Troubleshoot data warehouse, pipeline, or date lake performance problems and bottlenecks Skills you'll need 3+ years experience in software engineering 3+ years experience in a data-related field, including data engineering, data warehousing, business intelligence, data visualization, and/or data science Hands on experience with data orchestration tools and ETL tools Experience with relational database management systems Experience with cloud or columnar data stores such as Redshift, Snowflake, or Hive/Presto Ability to identify, repair, and troubleshoot data quality issues Ability to write, understand, and optimize complex SQL Experience supporting transformation tools such as DBT, Dataform, or AWS Glue in a production environment The desire to learn and experiment with new or emerging technologies Working conditions Ability to work from home and resides in one of the followings states: AK, AL, AZ, CA, CO DE, FL, GA, HI, ID, IL, LA, MA, MD, ME, MI, MO, MT, NC, NH, NM, OR, PA, SC, TN, TX, UT, VA, VT, WA, WI, or WY You'll be working in your home office setting. We hold virtual training sessions and weekly team meeting. Occasional offsite team meetings in your region or our HQ locations. Requires frequent, repetitive use of a computer, phone, and office equipment. Requires patient, professional communication with prospective clients, and the ability to build confidence with prospects. Compensation $85,000 - $130,000 DOE What you'll get Health/dental/vision insurance—employee & family coverage options Employer Sponsored & Voluntary Supplemental Benefits 401K retirement savings plan with immediate 100% company match on the first 6% you contribute Health & Dependent Care Flexible Spending Accounts Flexible vacation time Paid sick days and holidays Paid parental leave after one year of tenure Employee Assistance Program Career advancement opportunities Employee discounts All the equipment you'll need to be successful Great colleagues and culture Please visit our careers page to review our full benefits offerings Vacasa is an equal opportunity employer committed to fostering a diverse and inclusive workplace. We do not discriminate against applicants based upon race, color, religion, sex (including pregnancy, gender identity, and sexual orientation), national origin, age, disability, genetic information, or other classes protected by applicable law. Veterans are encouraged. Vacasa is committed to maintaining a safe and productive work environment. Possession, use, or being under the influence of alcohol or illegal drugs in the workplace is prohibited. An offer of employment for this role will be contingent upon the successful completion of a background check. #li-remote"
"Senior Infrastructure Engineer, Data & Insights Solutions","Tyler Technologies, Inc.",Remote,https://www.indeed.com/rc/clk?jk=15500f52f6ddc6a1&fccid=35fa439a19059a40&vjs=3,"At Tyler Technologies, our Data & Insights solutions are designed help government use data more strategically and effectively in the design and delivery of their programs and missions. As a Senior Infrastructure Engineer, you will build and manage the infrastructure necessary to host our exacting worldwide clients. Why Us? We exist to inspire and empower every public servant to address society's pressing issues. We do that by enabling data-driven leadership through connected data and shared insights. Our data as a service platform and cloud-based solutions support the world’s most effective open and internal data sharing programs at every level of government. What we do matters. New York, Seattle, San Francisco and 230+ other cities, states, counties and federal agencies use us to connect citizens and their internal teams with information that matters to their day to day life. Why This Job Is Important You’ll help the company design, operate, monitor, and grow the platform that hosts our global client base. You will work side-by-side with the rest of the engineering team to ensure our new features and services meet our security and performance guidelines. You will build the infrastructure that makes other engineers even more productive. Work with our transformative data solutions that help agencies address mission-critical outcomes. Our cloud-based data platform, open data solutions, and performance management solutions help agencies improve performance, transparency, and public engagement. Location Remote Responsibilities On a Typical Day, You Might... Contribute patches to open-source tools to better support our mission and operations. Participate in on-call rotation, which includes all engineering staff. Partner with security staff to implement advanced security and compliance requirements for our clients. Diagnose and fix systems and software failures and build additional automation to prevent the failure scenario from reoccurring. Manage DNS and SSL configurations for customer domains. Build out a production environment. Upgrade our infrastructure. Perform various AWS administration tasks. Qualifications AWS Building out environments (Setting up VPC, configuring ACLs and security groups) IAM user/key management CloudFormation Familiarity with other services including: EC2, S3, RDS, ECR, EKS Experience with other non-AWS infrastructure as a service platforms is also relevant. Linux Understanding of Linux OS at a systems level. Systems engineer experience is a plus Ubuntu knowledge is a plus Coding skills Strong familiarity with at least one dynamic language (Ruby or Python is a plus) Experience writing configuration as code Familiarity with objected oriented programming and data structures is a plus Configuration management Experience with and proficient with at least one configuration management tool (e.g. Chef, Salt, Ansible, Puppet, etc.) Experience specifically with Chef is a plus Containerization/Orchestration Experience with Docker Familiarity with Kubernetes Experience with Mesos and Marathon is a plus Networking skills are a plus You are interested in working with engineers to help scale and optimize their services. You are calm in high-pressure situations and skilled at triaging situations. About Us Tyler Technologies (NYSE: TYL) provides integrated software and technology services to the public sector. Tyler’s end-to-end solutions empower local, state, and federal government entities to operate more efficiently and connect more transparently with their constituents and with each other. By connecting data and processes across disparate systems, Tyler’s solutions are transforming how clients gain actionable insights that solve problems in their communities. Tyler has more than 26,000 successful installations across more than 10,000 sites, with clients in all 50 states, Canada, the Caribbean, Australia, and other international locations. A financially strong company, Tyler has achieved double-digit revenue growth every quarter since 2012. It was also named to Forbes’ “Best Midsize Employers” list in 2019 and recognized twice on its “Most Innovative Growth Companies” list. More information about Tyler Technologies, headquartered in Plano, Texas, can be found at https://www.tylertech.com/ . To learn more about our Data & Insights solutions, visit https://www.tylertech.com/solutions/transformative-technology/data-insights . Additionally, we aspire to be remarkable: in the culture we create, the products we build, and the services we deliver. We believe a diverse team that embodies different backgrounds and experiences is necessary for us to be the best we can be. Within the company, we pursue a culture of inclusivity by identifying and removing aspects of our culture that stop people from being able to do the best work of their lives in physical and emotional safety, while being their authentic selves. We seek diversity, equity, and inclusion across our organization and in our daily work as individuals. We understand change takes time and that we still have work to do; however, we are committed to making continual progress. #INDCORP State Specific Salary Range Disclosure Requirements for Colorado, Connecticut, and Nevada Salary will generally fall between $130,000 - $150,000 before adjustment for geographic differences. Recruiter can confirm if position is incentive eligible. Tyler is subject to regulations, guidelines, and/or client requirements relating to the qualifications of Tyler personnel performing certain client work. Because of the nature of this position, it is a requirement that the candidate can successfully pass a federal background check at the time an offer is extended and over the course of employment with Tyler."
Data Science Engineer,Triangulate Labs,"Remote in Cincinnati, OH",https://www.indeed.com/rc/clk?jk=981acc88e8b53811&fccid=f1678279740a4c2b&vjs=3,"Triangulate Labs is looking for a Data Science Engineer who will work closely with our technically minded founders to build and validate predictive analytics models using machine learning. You can expect to work on internal research and development as well as specific client engagements. What we’re looking for: Strong probability and statistics background Proficient in predictive analytics Proficient with Python and/or R and current high-performance machine learning libraries Degree in Computer Science, Engineering, Mathematics, or similar field– Advanced degree is a plus Collaborative attitude Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future This is a full-time position based in Cincinnati, Ohio. Telecommuting may be considered for experienced candidates. Interested in joining our team? If you are ready to work in a dynamic, fast-paced environment, apply by sending your resume and cover letter to contact@triangulatelabs.com."
Junior Data Engineer,Huntington Bank,"Remote in Columbus, OH+2 locations",https://www.indeed.com/rc/clk?jk=44d22ba1e571221f&fccid=35685a87fca04108&vjs=3,"Description As a Junior Data Engineer you will be: Responsible for expanding and optimizing our data and data pipeline Analyze and organize raw data Build and support data systems and pipelines Evaluate business needs and objectives Experience building and optimizing ‘big data’ data pipelines & data sets Requirements: Hands on experience with big data tools: Hadoop, Spark, Kafka, etc. Hands on experience with relational SQL and NoSQL databases, including SQL, Oracle, DB2, Hive, Hbase etc. 3+ years of experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Experience with data pipeline and any workflow management tools: Zena, control M, Oozie, Airflow, etc. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Working knowledge of DevOps pipeline using Jenkins, Urban code, Azure devops etc. Working knowledge of source code management using Git, Gitlab etc. Able to perform analysis and review of existing or proposed system features and integration, security, scalability and performance requirements with users, product teams, business analysts, architects and team members Develop systems and software integration patterns across a diverse IT ecosystem. These patterns should align to high level IT goals and business initiatives Provide subject matter expert advice on system design issues and contribute to ongoing planning and development of system enhancements Identify and specify technical / functional requirements, resources and required that may be needed to meet user requirements Provide guidance and reinforcement around established engineering best practices Participate in product planning and implementation Serve as an escalation point in product level support for ongoing maintenance and production issues Experience with AWS cloud services like Glue, Athena, EC2, RDS, Redshift etc. #LI-Remote Workplace Type: EEO/AA Employer/Minority/Female/Disability/Veteran/Sexual Orientation/Gender Identity Tobacco-Free Hiring Practice: Visit Huntington's Career Web Site for more details. Agency Statement: Huntington does not accept solicitation from Third Party Recruiters for any position"
Data Engineer,Bamboo Health,+2 locationsRemote,https://www.indeed.com/company/Bamboo-Health/jobs/Data-Engineer-6d9924b9dbe649fe?fccid=042f9c292184b74d&vjs=3,"We are inspired by solving big problems. We are all about progress; we set out to do something and we do it. – Rob Cohen CEO, Bamboo Health Bamboo Health is a leader in cloud-based care coordination software and analytics solutions focused on patients with complex needs, including those suffering from physical health and mental health issues and substance use disorders. We deliver on a mission of enabling better care for patients across the continuum, and our software solutions help healthcare professionals collaborate on shared patients across the spectrum of care. Join us in improving healthcare for all! Summary:The successful candidate is detail-oriented and cares deeply about data integrity. They are intimately familiar with modern data practices and design and are comfortable managing different kinds of data repository in the cloud. They will work closely with other data engineers to build a robust platform that will facilitate easy access to data and enhance analysis operations. The ideal candidate will be eager to learn and extend their existing SQL and Python skills. What You’ll Do: Establish best practices for use of data tools within data infrastructure Create and maintain extraction and analytic routines to move data between datastores Maintain and administer data repositories e.g.: RedShift clusters Create automated processes to validate data quality Use code to create and maintain cloud-based infrastructure Coordinate the implementation of analytic tools (e.g.: Jupyter Hub) and manage utilization What Success Looks Like…In 3 months… Survey existing data tools utilized within the organization and compare them against industry standard data science toolkits, identifying those that can be standardized Have a clear understanding of various data sources and existing dataflows within the organization Start planning and design of extractions for data movement In 6 months… Execute extractions and transformations in an automated fashion Maintain ETL process, with automated quality checks Continuously gather feedback on toolkits and workflows, identifying areas for optimization Be comfortable with navigating and authoring Infrastructure-as-Code flows In 12 months… Be an advocate for adopting best practices in user workflows Identify bottlenecks in the data platform and propose solutions to streamline processing What You Need: A mission-driven focus with a passion for spearheading change in complex healthcare environments, awareness of payer/provider reimbursement models, and interoperability/healthcare tech trends BA/BS degree in Computer Science, other relevant field of study, or equivalent experience 2+ years of experience in software engineering, writing and shipping high quality code in a production environment Experience with a scripting language such as Python, and/or an object-oriented language such as Java or Scala Advanced knowledge of SQL, particularly in schema design and query optimization Operational or client services background with Hospital & Health System experience preferred Experience working in a cloud-based environment, with particular focus on building infrastructure with code is a plus A work environment that is conducive to high quality virtual interactions. This includes but is not limited to being able to work from a quiet space with minimal interruptions or distractions, and a strong internet connection (minimum of 25 MBPS). The ability to travel periodically for work. A high level of judgment, analytical ability and creativity in investigating problems that require original and innovative solutions. Experience working a fast-paced, high-growth, rapidly changing work environments. What You Get: Join one of the fastest growing health IT companies in the country Have the autonomy to build something with an enthusiastically supportive team Learn from working at the highest levels and on the most strategic priorities of the company, including from world class investors and advisors Receive competitive compensation, including equity, with health, dental, vision and other benefits _Bamboo Health is proud to be an Equal Employment Opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all employees._ #LI-RemoteJob Req: R-01041 Job Type: Full-time"
Data Engineer - Multiple Levels,Red Alpha LLC,"Annapolis Junction, MD 20701",https://www.indeed.com/rc/clk?jk=437ba982373338af&fccid=6948819ab032a96b&vjs=3,"Description: A little about us: The Red Alpha Data Science practice grew out of Red Alpha's reputation in Software and System Engineering with our Department of Defense clients. As sometimes happens, customers who trust our expertise in adjacent areas asked Red Alpha to assist with some of their burgeoning Data Science problems. Culturally, it probably suffices to say that we take our work seriously, but not ourselves. Our leaders have spent time in the trenches and have cursed daylight savings time changes and trailing whitespace as many times as you have. We like to say that we spend 80% of our time cleaning the data...and 20% of our time complaining about cleaning the data. Joking aside, our voices matter, and it is easy to see how our decisions affect the Data Science practice and Red Alpha as a whole. We have a clear vision of where we are headed. Our team takes a pragmatic approach to Data Science, defining it loosely as the intersection of technical expertise, business acumen, and soft skills to solve business problems with data. We spend a lot of time trying to understand the problem before we set about building a solution, and we prefer lower tech useful solutions over shiny algorithms and dust on the shelf. Did we mention we’re pragmatic? We have a diverse set of skills across our team, and whether you are a traditional Data Scientist (whatever that means…), an Applied Research Mathematician, a Database Engineer, a Full Stack Developer, or something else in that neighborhood, if you have a knack for picking apart data to make sense of it, we would enjoy having a conversation with you. A day in the life: Despite the title of this role being “Data Engineer” (which sounds very specific), it is actually a great opportunity to demonstrate the diversity of your skills across the data science spectrum. From procurement, consolidation, and cleansing to modeling and presentation, you will influence and add value in several areas across the data science life cycle in order to answer mission and business questions. Subject areas include but are not limited to the following: Employ a variety of languages and tools (e.g., scripting languages) to integrate systems. Conduct research and leverage large volumes of data from multiple sources to answer mission and business questions. Employ sophisticated analytics, programs, machine learning, and statistical methods to prepare data for use in analytical processes and prescriptive modeling. Explore and examine data for hidden patterns. Automate work through the use of predictive and prescriptive analytics. Develop processes to extract/transform/load (ETL) data between different systems. . Requirements: What you bring to the table: Now on to the fun of formal requirements - we have to apologize in advance for the corporate-speak here, but just hold your breath for a few lines and everything will be okay. We are actively hiring data professionals for roles across a broad range of skill levels and projects. Our goal is to find the best fit for you so please note that if you apply to one of them and we see a fit elsewhere we will let you know. So do not worry about applying initially for every position you might be interested in. All of our data scientists need the following skills: Proficiency with a scripting language such as R or Python Experience with data science techniques and algorithms such as classification, clustering, random forests, deterministic forests (jk), hierarchical modeling, deep learning, Markov Chain Monte Carlo, and others. Note that you do not need to have all of these (we hope you enjoyed our random smattering of techniques…!) but you should be comfortable and capable with several of them and know some others not on this list. A B.S. Degree in Data Science, Mathematics, Computer Science or related field. For entry-level data scientists, 0-3 years of experience on Data Science projects. For mid-level data scientists, 3-6 years of experience on Data Science projects. For senior-level data scientists, at least 6 years of experience on Data Science projects with at least 3 years of experience managing teams. A TS/SCI with Polygraph security clearance. For this particular role, you will also need: Experience in identifying, developing, and deploying new approaches to automate data collection, consolidation, and analysis Proven ability to develop and deploy software and scripts needed to collect business-relevant metrics based on enterprise data These are important skills to have, but not necessarily mandatory: Exceptional interpersonal skills. You know, as in you might not be at the top of the list to be a game show host, but you do like people and enjoy solving problems jointly with your colleagues. Experience with Java, C, or other compiled languages Comprehensive knowledge of Saturday Night Live sketches (just kidding) Experience with SQL/NoSQL, Spark, Hadoop Familiarity with Javascript and Scripting Familiarity with Docker, GitLab, and React Familiarity with Agile processes and structures, and able to work on a software development team Why Red Alpha? Every day, our elite customers are pushing through ""the grind"" to defeat the enemy, even putting their lives on the line for our freedom. Rise to the occasion with us to deliver engineering excellence, to match their dedication to this nation. Join us as we bring digital transformation to the fight. Some of our perks and benefits: You can retire sooner rather than planned: Get closer to retirement with up to 12% in 401k contributions. You can have a career AND a life: Enjoy up to 5 weeks of leave (25 days of personal time off) and 11 paid floating holidays. You can stay at your best: As a member, we'll pay 100% of your premiums for comprehensive health, dental, and vision insurance. We'll also pay the majority of the premiums for your family. Free access to a fully equipped state of the art gym! $300 per year in company branded merchandise (Under Armour, Nike, Carhartt, YETI, etc.) Fun events throughout the year including a holiday gala, whisky tastings, fall festivals, happy hours, and more."
Data Engineer/Data Scientist,SEKAI Digital Twins,Remote,https://www.indeed.com/rc/clk?jk=386401325b7196c3&fccid=c50fd8b16aba3f5d&vjs=3,"About SEKAI Sekai is an enterprise software company that builds developer tools for digital twins in the energy and manufacturing industry. We build a cloud-agnostic SDK solution called the SEKAI platform. SEKAI also provides managed infrastructure to run SEKAI on behalf of customers. Our platform is a proprietary solution for large enterprises to deploy in their own datacenter, as well as custom infrastructure for private cloud deployments. We work with different size companies ranging from small, mid-size to public-listed companies, and Fortune 500s. About the role Skills: Spark, Camel, Python, R, Pyspark, Zepplin, Java, Scala Hi there! We're looking for a Data Scientist to join the cloud engineering team at SEKAI. We build distributed, highly scalable data technology using semantic and game tech in an industrial SDK for creating highly interactive, collaborative multi-user systems for assets like factories, ships, power stations and cities. We are simplifying the lives of developers and data scientists and providing an incredible technology that can be integrated into any enterprise IT environment as easily as possible. SEKAI is already powering many Apps, including PC, VR, Web and Mobile AR based tools. We skew heavily towards candidates who have professional experience with big data, SaaS, Graphing/data visualization and API driven solutions - however if you don't have experience but feel up to the challenge, please do apply! About You You love building new things. You love tinkering with new technologies. You love helping developers be more productive. You love data visualization. You love automation. You love helping customers solve problems. Your work could be on big data ETL pipelines, GraphQL API, data analysis on financial, IoT or ERP data and optimization or any areas in between. We love tinkering with new bleeding edge technologies like Qri, Databricks, Graph DB and not so new but new to the big data world such as machine learning. We encourage you to do the same! Things You Might Do You'll have a primary focus on the cloud based data sets in zeppelin and spark, though we may need to improve and tweak the automated infrastructure from time to time. The SEKAI platform is built on modern technologies like Java, Go, C++, Scala, JavaScript, React, GraphQL, Kubernetes, Postgres and Neo4j. SEKAI is a small, fast-growing, and remote-first company, so you'll likely get experience on many different projects across the organisation. That said, here are some things you'll focus on: Work on web based data driven tools. Help scale a fast-growing and unique system. Prototype new features and algorithms, Monitor and improve data processing for SEKAI and our customers. Refactor a algorithms in Python or Scala. Working with GIS data and map based visualizations, Developing applications based on GraphQL API. Plan and build product features - directly impact how our customers can be more productive. Improve our developer platform - directly impact the way developers integrate SEKAI into their IT environments. Experiment: this is a startup so engineering innovations can change. You’ll also have the opportunity to travel onsite to many parts of the world to help customers (corona permitting), attend conferences and meet new people. You also have the option of working from an office, co-working space, from a beach, or anywhere you like! The Whole Package Location: Anywhere on the planet with a reliable Internet connection! If you want to work remote, that's great. Compensation: Competitive salary. 20 days vacation. Work with a loving team that treats everyone as family. How to Apply Fill out the form below or send an email [jobs (at) sekai.io] to us with your resume, and a cover letter highlighting why you'd like to join SEKAI."
Software Data Engineer,Milliman,"Indianapolis, IN 46204 (Downtown area)",https://www.indeed.com/rc/clk?jk=dbe3a81435cda225&fccid=3d93143c99ff89a3&vjs=3,"Job Details Description About MedInsight Leading with our core values of Quality, Integrity, and Opportunity, MedInsight is one of the healthcare industry’s most trusted solutions for healthcare intelligence. Our company purpose is to empower easy, data-driven decision-making on important healthcare questions. Through our products, education, and services, MedInsight is making an impact on healthcare by helping to drive better outcomes for patients while reducing waste. Over 300 leading healthcare organizations have come to rely on MedInsight analytic solutions for healthcare cost and care management. MedInsight PRM Analytics is a subsidiary of Milliman; a global, employee-owned consultancy providing actuarial consulting, retirement funding and healthcare financing, enterprise risk management and regulatory compliance, data analytics and business transformation as well as a range of other consulting and technology solutions. MedInsight PRM Analytics, located in Indianapolis, IN, is a product group that operates in parallel with the MedInsight practice. Our products are used by health care administrators, medical directors, health care providers, and others to manage the clinical and financial risk in a patient population. Position Summary Our Software Data Engineers build systems and analytics used by health care organizations around the country for managing risk. You will gain a deep understanding of structured and unstructured data sets from the health care domain as well as proprietary and industry-standard analysts calculated on this data. Your technical challenge will be to design, develop, and test a system that ingests, aggregates, and presents millions of records of complex health data to our customers. If you enjoy programming, data analysis, and quickly learning your way into new areas, then you are probably a good fit for this role. Primary Responsibilities Write code to maintain and enhance data/analytics pipeline(s) Strive for fault tolerant processes and scalable solutions Understand and work with complex data structures and advanced analytics Work with team-members to propose technical solutions to business problems Contribute to the growth of your team by sharing knowledge Preferred Qualifications and Skills Bachelor's degree or equivalent experience Basic statistics and an intuition for data Basic software development principles (e.g. ""Don't Repeat Yourself"") Strong desire to work with code and data Communication that is clear, logical, and cordial A helpful, collaborative, and team-oriented attitude Insatiable appetite to learn Professional poise Grit to make it through the difficult problems Pride and ownership to want to make everything better Tools/techniques we utilize: Git and GitHub Python R Apache Spark Jenkins SaltStack KanBan Workflows What makes this a great opportunity? Bring your expertise and ideas to directly impact and help build the next generation of MedInsight PRM Analytics products and solutions Enjoy significant visibility in your work and ownership over our product, and be recognized for your wins Join an innovative, high-growth company with a solid industry track record Work for a company that values your wellbeing and professional growth, offering a flexible work environment, generous benefits package, and investment in the development of your career Benefits Paid Time Off (PTO) Company-supported continuing education benefits Free training through Milliman’s Learning & Development department Retirement Program: 401(k) Medical & Dental Vision FSA (Health Care Flexible Spending Account or Dependent Care Flexible Spending Account) Group Term Life Insurance Supplemental Life Insurance (Including Spouse/Domestic Partner & Dependent) AD&D Short & Long-Term Disability Paid Parental Leave Adoption Benefit Identity Theft Protection Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Senior Data Engineer,Capital One - US,"Plano, TX+57 locations",https://www.indeed.com/rc/clk?jk=22a9f12ee9648c4c&fccid=b85c5070c3d3d8c8&vjs=3,"Plano 6 (31066), United States of America, Plano, Texas Senior Data Engineer Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. What You’ll Do: Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake Utilize Kafka based frameworks to build resilient data pipelines Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance Partner with business teams to automate business processes, build visualizations and provide real time business insights to improve their business performance Basic Qualifications: Bachelor’s Degree At least 4 years of experience in application development (Internship experience does not apply) At least 1 year of experience in big data technologies Preferred Qualifications: 5+ years of experience in application development including Python, SQL, Scala, or Java 2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) 3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL) 2+ year experience working on real-time data and streaming applications 2+ years of experience with NoSQL implementation (Mongo, Cassandra) 2+ years of data warehousing experience (Redshift or Snowflake) 3+ years of experience with UNIX/Linux including basic commands and shell scripting 2+ years of experience with Agile engineering practices 2+ years of experience with visualization tools like Tableau, Quicksight, Thoughtspot etc. At this time, Capital One will not sponsor a new applicant for employment authorization for this position. No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC)."
Data Engineers,High5,United States+1 location,https://www.indeed.com/rc/clk?jk=4baae2407accac50&fccid=95d5df8c72881502&vjs=3,"Data Engineers 1. Roles focus on ETL & Data Transformation for downstream analytics processes 2. Very Strong Python Programming Basic and Advanced 3. Must have strong SQL writing experience & Unix shell scripting 4. Good at data analysis and profiling 5. Experience on Azure platform, Datalake, Blob, HiveSQL/SQL, Data Bricks, Python, CI/CD pipeline (nice to have) PySpark (nice to have) 6. Scheduling and dependency management of data pipeline with proper auditing 7. Build detailed technical design, conduct analysis, development of applications and proof of concepts. Overall 3-5 years’ experience (Developer) Experience on Azure platform, Datalake, Blob, HiveSQL/SQL, Data Bricks, Python, CI/CD pipeline (nice to have) PySpark (nice to have) Must have strong SQL writing experience Must be good at data analysis and profiling – VERY Important Good AWS hands-on experience Must have at least 3+ years’ experience in Hive Must have experience in Unix shell scripting Experience on Teradata is a plus Must have worked with performance tuning on any RDBMS Must be able to work independently and prioritize work across multiple projects Roles focus on ETL & Data Transformation for downstream analytics processes"
USA - Data Engineer-Python Pyspark,Avestacs,Remote,https://www.indeed.com/rc/clk?jk=eb62262eec4672c8&fccid=029422091c50af35&vjs=3,"Job Title: Data Engineer-Python Pyspark Type: 6-12 months Contract to Hire Location: 100% Remote About Client: Our client, a Global Giant in the IT Networking Software & Product space as also Telecommunication hardware If you are: Seeking a work from home, long term contractual opportunity while being engaged with a challenging role and a highly bright and high energy team building out a state of art data solution - please reach out at the earliest. The role offers for a Contract-To-Hire mode of engagement at the Customers sole discretion. Overview: In the role of a Data Software Engineer you would be working as part of a niche team focusing on Data Engineering and Data Processing. Core Expertise: 3 to 5 years of experience - Data Engineering involving Large Complex Diverse data sets AWS Python Pyspark Golang (Nice to have) Spark &/or Hadoop Github/Git"
Cloud Data Engineer (Remote),Charles Schwab,"Remote in Lone Tree, CO 80124+2 locations",https://www.indeed.com/rc/clk?jk=d5eabf24091c24dc&fccid=3c74eafe288fc8ca&vjs=3,"Your Opportunity Wealth & Asset Management (WAM) Engineering is part of the Schwab Technology Services (STS) organization which is responsible for company’s use of information technology including all communications, operations and client and business applications. WAM Data Engineering is aligned to support the technology needs of Schwab Asset Management (SAM) which is the investment advisor for Schwab’s proprietary mutual funds, referred to as the Schwab Funds; and it includes Schwab’s exchange-traded funds, referred to as the Schwab ETFs™. With around $8 Trillion in assets under management, SAM is the 3rd largest provider of index funds and the 5th largest provider of exchange traded funds (ETFs). What you are good at As a passionate, self-motivated individual with Python programming skills we are seeking a data engineer to build high quality, scalable and resilient data systems powered by automated development lifecycle, and CICD. As an engineer understands and help educate others on the merits of highly scalable data processing implementation in a data-centric environment. The Data Technology Team is in the middle of a multi-year effort to build out a strategic Data Platform. As a member of our Scrum team, you are expected to be cross functional to work on any task needed to complete story work. Although this is primarily a data engineer role, and you are required and willing to contribute to any task preventing the team from delivering on team commitments to the business. This may include data mapping, requirements refinement, data validation, documentation, infrastructure tasks, etc. This position will be an integral part of our scrum team and you will work closely with other team members in developing business software solutions. What you have This role requires a highly motivated and experienced developer with pride of ownership reflected through clean application design, code quality, a disciplined software development approach, and accountability for delivery. Qualifications & Experience: Four plus years of experience developing code in Python for data processing Hands-on knowledge of working with SQL Experience working with SQL and NoSQL databases Four years of experience working with data processing pipelines with Apache Spark or Apache Beam etc., Strong knowledge of database development and data testing patterns At least three years of experience with designing, implementing, and supporting highly scalable data systems and experience with GCP or AWS or Azure public clouds is preferred Experience implementing fully automated data flows including data acquisition, staging, processing, and target consumption tier for analytics, reporting, and AI/ML Demonstrate ability to work well independently in a fast-paced, team-oriented environment Ability to learn and adapt quickly to new technologies, processes and work independently Experience developing distributed data processing pipelines using Apache Spark, Beam, Flink etc., Experience with CICD process and usage of development tools including Visual Studio, PyCharm, Git/Bitbucket/Bamboo, Maven, Jenkins, Kubernetes Nexus etc., Experience with integration and service frameworks (e.g Micro services, API Gateways, Swagger API, messaging hub etc.,) Expertise with Microservices and REST based API development Four plus years of experience in data modeling, database design techniques (e.g. RDBMS, Document DB, Dimensional modeling, Star Schema, Data Vault, Kimball Model) Experience or knowledge of Control M schedulers preferred Experience working in an Agile Scrum environment planning and executing with delivery first mindset Experience writing code to automate file movement operations over multiple transmission protocols (e.g. SMB, FTP, SFTP, Object store etc.) Knowledge and experience with complex XML and XSD data structures including parsers, XPath and XQuery is a plus Ability to interact and communicate successfully with business partners and technology teams Experience in Investment Management or Financial Services a plus Education (in order of preference) Masters or bachelor’s degree in Computer Science, Engineering, Information Technology, Information Systems, or similar area of study Personal Characteristics Shows a commitment to high ethical standards and integrity and demonstrates this through action. Lifelong learner who can grasp difficult concepts and complex designs and stays on top of new and emerging technologies Inquisitive, analytical, a strategic thinker, proactive and solutions oriented. High-energy, positive, entrepreneurial in spirit while goal-oriented and results-driven. Self-starter takes initiative and can works independently. Well-organized and disciplined with high attention to detail. Flexible and adaptable working with various business domains. Direct, plain-spoken; conveys a genuine/authentic demeanor. Colorado Compensation Target Total Compensation- 110,000 - 161,400 Your actual pay will be based on your skills and experience- talk with you recruiter to learn more. Why work for us? Own Your Tomorrow embodies everything we do! We are committed to helping our employees ignite their potential and achieve their dreams. Our employees get to play a central role in reinventing a multi-trillion-dollar industry, creating a better, more modern way to build and manage wealth. Benefits: A competitive and flexible package designed to empower you for today and tomorrow. We offer a competitive and flexible package designed to help you make the most of your life at work and at home—today and in the future. Explore further. Schwab is committed to building a diverse and inclusive workplace where everyone feels valued. As an Equal Opportunity Employer, our policy is to provide equal employment opportunities to all employees and applicants without regard to any status that is protected by law. Please click here to see the policy. Schwab is an affirmative action employer, focused on advancing women, racial and ethnic minorities, veterans, and individuals with disabilities in the workplace. If you have a disability and require reasonable accommodations in the application process, contact Human Resources at applicantaccessibility@schwab.com or call 800-275-1281. TD Ameritrade, a subsidiary of Charles Schwab, is an Equal Opportunity Employer. At TD Ameritrade we believe People Matter. We value diversity and believe that it goes beyond all protected classes, thoughts, ideas, and perspectives."
"Developer Technology Engineer, Data Analytics - New College...",NVIDIA,"Santa Clara, CA+1 location",https://www.indeed.com/rc/clk?jk=690d0895c82683aa&fccid=c267f29f0f85e8b8&vjs=3,"We are now looking for a Developer Technology Engineer, Data Analytics: Data Analytics is one of the rapidly growing fields in GPU accelerated computing. Data preprocessing and data engineering are traditionally CPU based and are becoming the bottleneck for Machine Learning (ML) and Deep Learning (DL) applications, as performance of the frameworks and core ML/DL libraries has been highly optimized leveraging GPUs. Many of today’s applications have complex data analytics pipelines that can benefit from optimizations in memory management, compression, parallel algorithms like sort, search, join, aggregation, groupby, scaling up to multi GPU systems, and scaling out to many nodes. Take a look at some of the open-source projects that our Devtech team have worked on: NVIDIA nvcomp , NVIDIA Distributed join , NVIDIA cuCollections What you will be doing: In this role, you will research and develop techniques to GPU-accelerate applications across data analytics domains, e.g., ETL, ML, graphs, etc., and intersecting with DL. Work directly with key customers to perform in-depth analysis and optimization of complex data intensive workloads to ensure the best possible performance on current and next-generation GPU architectures. Collaborate with libraries, tools, system software architecture, hardware, and research teams at NVIDIA to influence the design of next-generation programming models, software, and architectures. What we need to see: You are completing a Bachelors, Masters, PhD, or equivalent experience in Computer Science, Computer Engineering, or related computationally focused science degree. Programming fluency in C/C++ with a deep understanding of algorithms and software design. Experience with parallel programming, e.g., CUDA, OpenACC, OpenMP, MPI, pthreads, TBB, etc. In-depth expertise with computer architecture fundamentals, especially memory subsystem. Good communication and organization skills, with a logical approach to problem solving, and prioritization skills. Ways to stand out from the crowd: Domain expertise in data analytics, e.g., ETL, ML, graph applications . Experience optimizing the performance of distributed systems and frameworks , Spark highly desired. Background with compression, storage systems, networking, and distributed systems. Experience with linear algebra and machine learning applications. Graduate degree in Computer Engineering, Computer Science, or related engineering discipline. The Developer Technology Engineer (DevTech) plays a crucial role in the success of NVIDIA and our customers. DevTechs work with external technologists to investigate performance of their applications, design parallel algorithms and implement optimizations in a GPU accelerated computing environment. As recognized experts in the field we publish our findings in developer blogs or at relevant conferences and workshops. With visibility to our customers, the industry, and academia we are important representatives of NVIDIA as a technology leader. Within NVIDIA we contribute valuable application expertise that influences next generation hardware and software products. As critical problem solvers, we deepen our expertise, expand our knowledge, and work across domains and organizations. Whether you are a leading industry luminary or early in your career, the Developer Technology Team provides ample opportunity for growth in the exciting field of GPU accelerated computing! NVIDIA is widely considered to be one of technology’s most desirable employers. We have some of the most forward-thinking and hardworking people on the planet working for us. Does contributing to and pushing the boundaries of state-of-the-art in GPU Accelerated Computing, HPC and Artificial Intelligence excite you? If so, we want to hear from you! The Colorado Equal Pay for Equal Work Act requires that NVIDIA provide the compensation range and benefits offered for this position if performed in Colorado. The base salary range for this position in Colorado is $111,600.00 - 153,450.00 USD. NVIDIA also offers a comprehensive benefits package. We provide health care coverage, dental and vision, 401(K), including company matching and after tax contributions, Employee Stock Purchase Program (ESPP), Employee Assistance Program (EAP), company paid holidays, paid sick leave, vacation leave, professional time off, life and disability protection. Employees in eligible sales and positions may also be eligible for commission. Base pay is based on market location and may vary based on factors including experience, skills, education, and other job-related reasons. NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law."
Data Engineer - Python,Nortal,Remote,https://www.indeed.com/rc/clk?jk=ae56a0a28222d3dd&fccid=2c763e7277b51398&vjs=3,"SOFTWARE DEVELOPMENT US REMOTE ENGINEERING A Nortal Data Engineer’s role is to lead and implement data engineering projects, support and maintain data pipelines, and provide expertise and best practices regarding data engineering for staff across the company. Typical data engineering projects focus on improving performance and adding features to existing data pipelines. As needed, the Data Engineer will design and develop new data engineering pipelines as part of the Data Engineering Team. Further, the Data Engineer will help decide how and implement improvements to pipelines, systems, and infrastructure. Data Engineers are expected to have an in-depth understanding of data engineering best practices as well as expertise with the tools needed to debug and diagnose issues. Data Engineers contribute as a team member to testing, QA, and documentation of data pipelines and systems. The Nortal Data Engineering Team is a small agile team of motivated individuals who welcome challenges, adapt quickly, strive to acquire new knowledge, learn new technologies, accept new responsibilities, and work well individually, as a team, and with other teams within the organization. You will work closely with the Data Engineering Lead, product managers, workflow developers and other software engineers to advance projects and meet objectives. We seek an experienced engineer who is interested in pursuing an advanced individual contributor technical career track over a technical management career track. Duties and Responsibilities Assembling large, complex sets of data that meet non-functional and functional business requirements Identifying, designing, and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies Building analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition Working with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues Working with stakeholders including the Executive, Product, Data and Design teams to support their data infrastructure needs while assisting with data-related technical issues Data Engineer Expectations Maintain an in-depth understanding of relevant data engineering best practices Display expertise with tools needed to debug and diagnose issues Given a medium to large understood problem, can design, implement, and deploy a solution Show initiative and help when needed without being asked Deliver feedback in a constructive manner Provide guidance to other engineers and workflow developers Work well with technical leads, incorporating feedback as needed Required Skills AWS: S3 Data Lake, Athena, Redshift, EMR, Glue, ECS, EKS Proficiency with Python in a data engineering context. Ex: Pandas, PySpark Source control using Git Proficiency with SQL Proficiency with workflow orchestration concepts Adaptable to Windows, Linux, and container-based deployment environments Workflow performance, scaling, and optimization. Big Data solutions in some cases. Security & privacy principals Desired Skill & Qualifications ETL productivity tools Spark EKS Terraform Helm Python3 APPLY FOR A JOB We like to say that Nortal is a right-sized company – big enough to undertake and impact influential projects yet small enough to care. At Nortal, your voice is heard, and everyone’s input matters. You solve critical problems for interesting customers from different domains. You work with experienced colleagues in a warm environment. You are able to execute your ideas in a reasonable time frame. And what you do and learn here are universally relevant and valuable. Last but not least, Nortal is an agile company with low hierarchy – meaning heavy on common sense, light on rules, and substance is more important than titles!"
Data Engineer - Associate,Deutsche Bank,"Cary, NC 27513",https://www.indeed.com/rc/clk?jk=3fa000cc2f53af5b&fccid=f1d8e147024abb3f&vjs=3,"Job Title: Data Engineer Corporate Title: Associate Location: Cary, NC Overview Our Sales Analytics team consumes data for reporting, deep data analysis, and advanced data science, and provides Deutsche Bank front office a clear view on client’s activity and profitability. We are building an interactive analytical platform, defining, and tracking key business metrics, helping front office in day-to-day business decisions. We are looking for a Data Engineer with strong design, coding skills, and web development to be responsible for all steps of bringing high-quality data to end users. This includes ETL (Extract, Transform, and Load), processes, data analysis and preparation, development of interactive presentation layer. What We Offer You: We offer competitive health and wellness benefits, empowering you to value life in and out of the office An environment that encourages networking and collaboration across functions and businesses Conveniently located nature trails, accessible year-round Return to Office: At this time, all individuals present in the location must be fully vaccinated for Covid-19 It is the Bank’s expectation that employees hired into this role will work in the Cary office in accordance with the Bank’s hybrid working model Deutsche Bank provides reasonable accommodations to candidates and employees with a substantiated need based on disability and/or religion Hear from our people and look inside our office: DB@The Muse Your Key Responsibilities: Build Extraction, Transformation and Load pipelines spanning multiple technologies Collaborate with Project Managers, Architect’s, and Data Scientists to deliver solutions Combine and Prepare data from multiple sources for reporting or analysis purposes Manage end to end ownership of delivery from requirements to production release and 3rd level support Conduct complex data analysis and prototyping to identify new insights for the Business Mentor less experienced resources on design and delivery technical solutions Your Skills and Experience: Experience with Java, Python, and Scala Knowledge of data modelling principles and best practice Familiarity with algorithms and data structures Knowledge of Unix Experience with oracle and data storage technologies such as data lakes, data warehouses and traditional SQL and NoSQL databases Our values define the working environment we strive to create - diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer. We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation. We are an Equal Opportunity Employer - Veterans/Disabled and other protected categories. Click these links to view the following notices: ""EEO is the Law poster"" and supplement ; Employee Rights and Responsibilities under the Family and Medical Leave Act ; Employee Polygraph Protection Act and Pay Transparency Nondiscrimination Provision ."
Cloud Data Engineer,ASU Enterprise Partners,"Remote in Tempe, AZ 85280",https://www.indeed.com/rc/clk?jk=f34ec00772b06e1a&fccid=2d77b0a9670ae5b7&vjs=3,"The Cloud Data Engineer is a member of the Data Engineering team within the Technology & Solutions (T&S) department at ASU Enterprise Partners (ASUEP). Data Engineering supports the integrity, augmentation, integration, security, and stewardship of all ASUEP data assets. This position works closely with other teams at ASUEP and ASU to support technologies and processes to ensure data is available in an accurate, complete, and timely manner to support business decisions, processes, and reporting. This position reports to the Data Engineering Director. What you will do as a Cloud Data Engineer Develop Data solutions on Microsoft AZURE Cloud Develop new and manage existing integrations between various data sources and an AZURE Cloud Data Warehouse Migrate on-premises SQL Server data systems and processes to AZURE Cloud Migrate ETL packages from SSIS to Azure Data Factory in the Cloud Create processes to manage capacity and performance of data solutions in the Cloud Develop SQL Stored Procedures, Tables and Views in a Data Warehouse environment Develop complex SQL queries to investigate data for end users Validate and clean existing data using SQL Debug complex database processes and implement fixes in a timely manner Deploy code from a repository to Production systems Work with stakeholders to identify sources of data in the environment Classify data stored in the Data Warehouse Manage multiple projects and assignments concurrently What you will need to be successful as a Cloud Data Engineer Bachelor’s degree in Information Technology or related field, and (5) five years of experience delivering information technology services which include two (2)years with AZURE Cloud technologies Expertise in managing Data Warehouses on AZURE Cloud Expertise in integrating data from various sources into Data Warehouses Experience with database technologies in a hybrid cloud/on-premises model Competency with ETL tools such as SSIS and ADF Knowledge of applicable regulatory requirements associated with PII, FERPA, and PCI-DSS Certification, or willingness to complete certification, for Azure Fundamentals or equivalent How you will be rewarded as a Cloud Data Engineer Competitive Base Salary Hybrid working Schedule (Monday and Friday work from home, Tuesday-Thursday in the office) Medical, Dental, Vision Benefits, and Flexible Spending Accounts Basic Life and AD&D insurance Disability Insurance Accident Insurance 401k plan with a 4% company match HRA Plan Tuition Reduction for Dependents; will pay 75% of dependents higher education Tuition PTO, Sick time, Parent leave, and bereavement"
Data Engineer,Brillio,"Austin, TX",https://www.indeed.com/rc/clk?jk=e3e9e08f40e48b29&fccid=a2520645450d003a&vjs=3,"Data Engineer ( Job Number: R01515568 ) Description Responsibilities: Java Spark Developer 5 years’ experience in software development using Core Java 3 years' experience in technologies including Hadoop, Spark and Big Data platforms, RBDMS, NoSQL Druid. Knowledge in Kubernetes Advanced SQL capabilities are required. Knowledge of database design techniques and experience working with extremely large data volumes is a plus Advanced experience in ETL and data wrangling using language Java Experience in other technologies such as HIVE, Kafka, TIBCO EMS, GemFire, Spring, etc. Experience in programming in Linux/Unix environment, including shell scripting Experience in Agile SDLC, JIRA, BitBucket/Git, AWS ECS, RedShift is a plus Experience in implementing successful projects Ability to adjust priorities quickly as circumstances dictate Consistently demonstrates clear and concise written and verbal communication Primary Location : US-TX-Austin Work Locations : US – TX – Austin Austin 78731 Employee Status : Regular Job Type : Standard"
Data Engineer,NXP Semiconductors,"Austin, TX 78735 (West Oak Hill area)",https://www.indeed.com/rc/clk?jk=074fc42385e0292a&fccid=d113f5fdf3e1cb7b&vjs=3,"Data Engineer Business Line Description: NXP’s Design Enablement team supports global design groups with EDA flows related to semiconductor chip development. The team supports both digital and analog EDA tools as well as other initiatives to help automate and optimize development of chips in NXP’s portfolio. Job Summary: Looking for a highly motivated individual to be part of an Analytics team within the Design Enablement group focused on improving and optimizing our semiconductor development flows and compute utilization across NXP. This role will provide an opportunity to work with many cross-functional teams such as design teams, flow developers, IT, finance, and more. Typical work will involve using the AWS cloud platform develop, automate and maintain data pipelines feeding operational analytics, opportunity analyses, forecasting and prediction engines. Key Challenges: This is a relatively new team that will be focused on analytics around general semiconductor chip development. Will be learning a number of new tools and skills Working with incomplete datasets Collaborating with different groups internally Cross Functional aspects: Opportunity to work with many different global organizations within NXP including Design Enablement, Business Lines, Sourcing/Procurement, IT, Finance, Executive teams, and more Generate data streams and analysis that will be used across NXP Job Qualifications: A bachelor's degree in computer science, information systems, data management or a related study (or equivalent work experience) is required with at least 3 years’ experience with an appetite for learning new tools and skills. Data Engineer Cloud data platform experience, AWS preferred Athena, RDS, Redshift, Glue, Cloud Formation, Spark, Lambda, Sagemaker, S3, EventBridge, EC2 AWS skills Strong SQL skills Able to architect and develop data pipelines. Strong scripting language skills Good feel for and ownership of data quality, able to anticipate problems Solid linux environment skills Develops solutions with an eye toward long term maintainability Comfortable with basic software engineering processes (CM, CI, Release Mgt, Ticketing workflows) BI tool experience a plus Semiconductor experience a plus Job Location: Austin, TX NXP is an Equal Opportunity/Affirmative Action Employer regardless of age, color, national origin, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, marital status, status as a disabled veteran and/or veteran of the Vietnam Era or any other characteristic protected by federal, state or local law. In addition, NXP will provide reasonable accommodations for otherwise qualified disabled individuals."
Optim Data Engineer (Remote),cloudteam,"Remote in Jacksonville, FL 32256",https://www.indeed.com/rc/clk?jk=a95e92d98185675f&fccid=8e2d5787f67bc92e&vjs=3,"Seeking a Optim Data Engineer with ETL skills for 100% Remote position working with Healthcare data. IT Developers are responsible for the development, programming, and coding of Information Technology solutions. They will engage in all phases of the software development life-cycle which include: gathering and analyzing user/business system requirements, responding to outages and creating application system models. IT Developers are responsible for documenting detailed system specifications and will participate in evaluating, conducting performance testing, and all planned and unplanned maintenance for both internally developed applications and purchased products. Participate in design meetings and consult with clients to refine, test and debug programs to meet business needs and interact and sometimes direct third party partners in the achievement of business and technology initiatives. IT Developers are responsible for including IT Controls to protect the confidentiality, integrity, as well as availability of the application and data processed or output by the application. Requirements 5-8 years of IT experience Experience with IBM Infosphere OPTIM Experience with ETL tools Ab Initio Tool Experience Good command of SQL for multiple relational database environments Education Bachelor’s Degree in Computer Science or Mathematics or relevant work experience"
Data Engineer,Knackshops Inc,Remote,https://www.indeed.com/company/Knack/jobs/Data-Engineer-53affeba14034be3?fccid=fc61c504f4d1cf04&vjs=3,"Description: This fully remote role is open to candidates in most states. Working remotely from a primary residence outside the United States is currently not permitted for this role.We’re seeking an experienced Data Engineer to help us build data pipelines to transform data from multiple sources into our reporting and analytics data store using modern data pipeline methodologies and technologies on AWS. Our engineers work on full stack solutions with a strong emphasis on SOA leveraging modern technologies and SDLC.As a founding member of our Data Platform Engineering team you'll help us analyze, design, and build modern data pipelines that transform data into structures needed for analysis and reporting. You have strong Python skills, exquisite SQL and MySQL knowledge, experience building real-time and scheduled data pipelines, and have experience and knowledge regarding data pipeline strategies and technologies within the AWS Cloud. You’ll add immediate value building systems that collect, manage, and transform raw data into usable information for business analysts and operations managers to leverage, making data accessible so that our organization can use it to evaluate and optimize our operations, performance, and inventory.The job responsibilities include understanding and evaluating our current platform, data schemas, and stores; and collaborating with our Product, Merchandising, and Sales teams to architect and engineer our data analysis and reporting platform to remove and reduce friction across our organization. We’ll be ripping off the “duct tape and strings” and building our next level data warehouse and reporting system.This is a unique opportunity to join a successful e-commerce company pivoting in its journey, from a retail first company, to a technology company, in order to scale our platform to match our growth goals. Come help us build a team of experienced engineers transforming our full stack and aligning our technical staff & capabilities to meet the demands of our growing business and YoY success. As we build our platform of the future you'll have an amazing opportunity to create a long lasting impact as a founding member of our staff, as you help set the roadmap and technology base for our growing engineering department.About Knack: Knackshops Inc is the market-leading custom gift platform that helps customers deepen their interpersonal relationships through meaningful gifts. At the core of what we do is a firm belief in gift giving as a creative force for good in the world, and a commitment to making gift givers the hero in everything we do. Our mission is to disrupt the $60B “send a gift” market by harnessing technology to empower gift givers and build powerful digital experiences around physical gifts.Knack offers more individualized customer experiences, ethos-based products and expert advice than any competitor in the category. The first 100% made-to-order gift challenger, our market-leading features such as video messaging, Gift Builders and Private Events are widely mimicked but not surpassed. Our latest innovation, Knest, provides flexible personal and company-branded gift sites that bring gift givers and gift recipients closer together by adding a digital experiential layer to the act of gifting.Our culture is ambitious and collaborative. We are optimistic and mission-driven. We believe that people live up to the expectations we have of them, and we expect greatness from each other. We work hard but always have each other’s backs. We problem solve but don’t blame. When challenges arise, it’s all-hands-on-deck because we expect mistakes and learn from them. We create space for employees to be their best selves. We trust our employees to manage their own time and location and we work hard to maintain our strong culture as we grow.Knack is an Equal Opportunity Employer. Knack does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit and business need.. Requirements: Who you are: Have experience evaluating and understanding legacy schemas and acquiring datasets that align with business needs. Have strong experience building, testing, and maintaining database pipeline architectures. Have experience developing algorithms to transform data into useful, actionable information. Have significant experience with Python, SQL on AWS MySQL RDS, and leveraging AWS technologies to build data pipelines. Have expertise building real-time and schedule driven data ELT (extract, load, transform) systems that provide data formatted for highly performant reporting and analytics needs. Can ensure compliance with data governance and security policies in collaboration with our Security team. Have middle-tier SOA experience and skills designing and writing micro-services in Python, Golang, etc. Experience implementing testable code and unit tests in the UI codebase and middle tier services. We focus on quality vs quantity as we implement our test and evaluate our coverage. Bonus if you have experience with containerized services via docker and Kubernetes. Have experience with Docker, AWS Technologies, MySQL, Lambda (Serverless), and comfort interacting with AWS resources via Console, SDKs, and the CLI. You have a desire to drive platform reporting and analytics architecture, design, and implementation, and can communicate architectural concepts succinctly. You have a strong passion for modern technologies and driving innovation. Learning technologies and expanding your skills is always on your mind. Job Type: Full-time"
IT Data Engineer,"SK Siltron, CSS","Bay City, MI 48706","https://www.indeed.com/company/SK-Siltron,-CSS/jobs/IT-Data-Engineer-d3545bb3a1fa6166?fccid=a4cd7f8849bb27ed&vjs=3","SK Siltron CSS, a subsidiary of South Korea-based SK Siltron and the SK Group, offers a reliable global source of leading edge, production proven, high crystal quality silicon carbide (SiC) wafers and epitaxy services. SK Siltron has been part of the semiconductor industry in Korea and throughout the world for more than 35 years, pursuing global leadership in semiconductor development through fundamental competitive innovation in technology, manufacturing, infrastructure and talented people. Recent acquisition of state-of-the-art technologies for SiC wafer production from DuPont extends the company’s capabilities in developing and manufacturing semiconductor wafers. As a vertically integrated SiC material supplier with technology and manufacturing expertise from crystal growth through wafer fabrication and epitaxy, SK Siltron CSS is well-positioned to provide technology to meet demands linked to global megatrends – including improved environmental sustainability, increased electricity demand and higher energy efficiency – through the latest generation of wideband gap semiconductor materials. Job Description: SK Siltron CSS has an exciting opportunity for an IT Data Engineer. Working closely with the Senior Product Manager and Manufacturing leaders, this role will be responsible for developing and maintaining data processing software, databases and data reporting. They will be instrumental in creating the foundational systems and processes that enable the efficient and sustainable scaling of the operations of the commercial and manufacturing teams. Duties include coordinating with executives, engineers and other professionals to create data infrastructure and reports, testing and isolating errors with data designs, and assembling complex sets of data to meet non-functional and functional business requirements. The candidate will report to the CSS IT Manager and will interact with a corporate headquarters IT team. Key responsibilities include: Define, implement, and maintain business processes, systems, and procedures for data flow into systems to meet business objectives Evaluate current business processes and systems and recommend solutions for improvement Work with other teams and stakeholders to integrate new and existing business processes Work with stakeholders to identify business requirements Facilitate pain-point discussions to gain understanding of process gaps and inefficiencies Build and evaluate financial models for cost estimation, cash flow and cost reduction Prioritize and execute projects for ongoing business improvements Test for their effectiveness of the implemented business process changes Standardization and industrialization of methods used for risk assessment of customer specifications Required and Preferred Qualifications: Bachelor’s degree in business, engineering, information technology or related field. Experience in a high-volume manufacturing or a high-volume services environment Experience with process automation Experience in relational data-base management (RDBM) and database querying (SQL). Experience creating automated reports or dashboards in R, python, PowerBI or comparable Experience creating and maintaining data pipelines Proficient in at least one major programming language (java, python, C#, javascript etc.) Familiar with REST APIs and experience utilizing APIs for integrating disparate systems Ability to recognize structural issues within the organization, functional inter-dependencies, and cross-silo redundancies Ability to assimilate and correlate disconnected business information, and articulate their collective relevance to the organization Ability to collaborate and work effectively at all levels of the organization Proficient in MS Office software Proven leadership and time management skills Excellent communication, interpersonal and negotiation skills Good verbal and written communication and presentation skills coupled with the ability to influence people across the organization, proficient in English Demonstrated ability to interact with people in a friendly and approachable manner and translate complex concepts into easy-to-follow ideas and present to all levels of the organization. Ability to make important decisions under pressure Problem-solving skills Comfortable working with minimal instructions and should be self-motivated to achieve results. Additional Qualifications: Proficient in Korean (a plus) Experience working in the semiconductor industry Familiar or experience working with SAP Cloud (or comparable) ERP software Familiar or experience working with Critical Manufacturing (or comparable) MES software Familiar or experience working with data logging software (OSI PI or comparable) Project management experience or PMP certification Benefits In addition to your competitive salary, as an SK Siltron CSS employee, you are eligible to participate in our extraordinary benefits package which includes a generous PTO and holiday allowance, comprehensive medical, dental, and vision plans with no employee premium, and an exceptional 401k plan with auto enrollment and employer matching. Additionally, employees also enjoy such benefits as supplemental voluntary life policies, flexible work arrangements, and wellness benefits. SK Siltron, CSS is proud to be an equal opportunity employer. Job Type: Full-time Benefits: 401(k) 401(k) matching Dental insurance Employee assistance program Health insurance Life insurance Paid time off Vision insurance Schedule: 8 hour shift Work Location: One location"
Data Engineer,Cincinnati Reds,"Cincinnati, OH 45202 (Central Business District area)",https://www.indeed.com/rc/clk?jk=189e910dd65e770b&fccid=e8a6241bc4fe2964&vjs=3,"Job Title: Data Engineer Department: Information Technology Reports To: VP of Information Technology FLSA: Salary, Exempt Job Purpose: The Data Engineer is responsible for maintaining the data warehouse used by business departments. The role will work within existing frameworks to build ETL processes and ensure data quality and performance. The Data Engineer will be responsible for developing, maintaining, testing and implementing, data modeling, data warehouse, working with both business & baseball. Essential Duties and Responsibilities: Work with business process owners to understand the business need and develop technical solutions that integrate existing and future applications into the organization's information systems. Develop within existing designs of various solutions in the Microsoft Azure environment to help the business get valuable insights Focus on key business cases development within Data & Analytics + Azure Suggest and implement architecture improvements Engage and collaborate with business analysts to find opportunities, understand requirements, and translate requirements into technical data science solutions Must have technical experience with SQL, ETL Build and maintain data sources and ETL/ELT processes across business operations and baseball operations Support various database (including cube) within the data warehouse. Proven communication and problem-solving skills are critical to successful performance in this role Understanding of integration services, Analysis Services, Reporting Services and SQL 2012/16. Generate SQL Database reports from existing database using BI tools (Tableau) Logical and Physical Data Modeling experience using data modeling tools. Strong knowledge and understanding of structure and unstructured data. Determines database structural requirements by analyzing client operations, applications, and programming; reviewing objectives with clients; evaluating current systems. Help ensure database integrity by building and maintaining resilient data processes, and assist with architecting data storage solutions to efficiently store and retrieve information. Installs database systems by developing flowcharts; applying optimum access techniques; coordinating installation actions; documents actions. Understand and used Microsoft Azure, and GCP mythology Provide data management expertise to the company by evaluating requirements and developing solution. Experience, Education and Licensure: Bachelor’s degree in in Computer Science, Data Engineering, Machine Learning, Statistics, Applied Mathematics, Economics, or a related field with focus on computer science, data science, or programming 3-5 years of Data Warehouse and BI/Analytics experience. Excellent presentation, written and verbal communication skills. Ability to work effectively with clients and other technical staff. Experience using data visualization software tools a plus. Knowledge. Skills, and Abilities: Ability to query and create reports from relational databases using SQL or standard report writing tools such as Business Objects, Microsoft SQL Server Reporting Services, Integration Services and Analysis Services.. Cloud understanding SQL programming skills Previous experience or understanding of data models. Ability to apply business and industry knowledge to internal applications, databases and systems. Must have an in-depth knowledge of Microsoft SQL Server Business Intelligence platform tools. Physical Demands: While performing the duties of this job, the employee is occasionally required to sit, use hands, reach with hands and arms, talk or hear. Work Environment: While performing the duties of this job, the employee is not exposed to weather conditions prevalent at the time. The noise level in the work environment is usually moderate. Expectations: Adhere to Cincinnati Reds organization policies and procedures Act as a role model within and outside the Cincinnati Reds organization Perform duties as workload necessitates Demonstrate flexible and efficient time management and ability to prioritize workload Meet department productivity standards Equal Opportunity Statement: The Cincinnati Reds are an Equal Opportunity Employer. It is the policy of the Cincinnati Reds to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, national origin, religion or creed, sex, age, military or veteran status, disability, citizenship status, marital status, genetic predisposition or carrier status, sexual orientation or any other characteristic protected by law. Disclaimer: The statements herein are intended to describe the general nature and level of work being performed by the employee in this position. The above description is only a summary of the typical functions of the job, not an exhaustive or comprehensive list of all possible job responsibilities, tasks, and duties. Additional duties, as assigned, may become part of the job function. The duties listed above is, therefore, a partial representation not intended to be an exhaustive list of all responsibilities, duties, and skills required of a person in this position."
Data Center Engineer,RK,"Aurora, CO 80011 (Norfolk Glen area)",https://www.indeed.com/rc/clk?jk=7c3438d55507c217&fccid=c5a265d640300828&vjs=3,"RK Mission Critical provides custom-engineered modular solutions for the data and telecom industries. We’re a single source solutions provider that can handle complex and high-volume projects. We listen carefully to customer needs and have the experience to develop solutions that others can’t or won’t. The peRKs: RK Contributions Four medical plans with HSA and FSA options for you and your family 401(k) plan with company match that is 100% immediately vested Dental and vision insurance Short-term and long-term disability plans available after one year Company provided life insurance and AD&D with options for supplemental buy-ups. Paid time off and holidays Weekly pay In-house Programs Career development training for all levels through RK University Wellness coaching offering exercise planning, gym discounts, health screenings, program incentives up to $2,100 a year, and more. Fun company and team building events, and volunteering opportunities. Partnership Programs Confidential counseling for personal issues, financial advice and more Discounts on entertainment including amusement park tickets, restaurant specials and more Additional discount on product and services for life's necessities such as phone, internet and work apparel What you’ll be working on: Development and maintenance of 3D models, bill of materials, and relevant drawing packages in accordance with RKMC standards, Customer specifications, and regulatory requirements. Uphold RK Mission Critical documentation and design & development standards and practices as well as product/customer specifications. Actively participate in drawing reviews for input of manufacturability. Coordinate feedback with Production. Collaborate with subject matter experts to approve submittals for engineered items. Ensure all flow-down requirements from the project are met by vendors/sub-contracts. Work directly with a Project Manager to communicate RFIs, approve design or scope changes, and validate design intent per the project contract/ product specifications. Become a subject matter expert in Data Center design and construction, including but not limited to: UL 2755, equipment selections, and specification review. Investigate design changes to produce Engineering Change Notices (ECNs) to the RKMC team to ensure training and communication. What is expected of a Data Center Engineer: Bachelor’s degree in Engineering or related field and approximately 5 years of experience. Experience in data center or modular building design favorably considered. Firm knowledge of Microsoft Suite products including Teams, Planner, and Excel. Strong computer literacy and organizational skills required. Firm knowledge of 3D manufacturing CAD software (preferably Autodesk Inventor) and detailed manufacturing drawing creation. Works in conjunction with Engineering leadership and Project Manager to execute an RK Mission Critical Data Center. Reports to the Engineering Manager. How you make Safety your top priority: Comply with all company policies and procedures. All employees are accountable for safety and health and are empowered to stop work if an unsafe condition is present. Employees should immediately notify their supervisor so that the hazard may be corrected. RK Mechanical employees and subcontractors are required to implement and maintain all safety and health systems practices including the training requirements of RK Mechanical Orientation, shop specific orientation, CPR/First Aid/AED/Bloodborne Pathogens, Hazard Identification and Reporting, and OSHA 10 Local Awards: Denver Business Journal #1 Denver-Area Mechanical Contractor 2014- Present #6 Fastest Growing Denver Area Private Company: X-Large, 2019 #7 Denver-Area Corporate Foundation, 2020 #7 Denver-Area Manufacturing Firm, 2020 #14 Denver-Area Healthiest Employers, 2020 #16 Largest Denver-Area Private Employer, 2020 #22 Denver-Area Private-Sector Employer, 2020 #23 Denver-Area Corporate Philanthropists, 2020 ColoradoBiz Magazine #8 Top 200 Private Companies List, 2020 Associated Builders and Contractors (ABC) - Rocky Mountain 1st Place Specialty Contractor Award of Excellence- Ascent Union Station 2nd Place Specialty Contractor Award of Merit- Pike Peak National Cemetery Accredited Quality Contractor (AQC) “Platinum Level” Company in STEP Safety Management System Platinum level ratings or higher from the ABC STEP program for nine of the past twelve consecutive years Colorado Manufacturing Awards RK Mission Critical- CMA Building and Construction Manufacturer of the Year Colorado Workforce Development Council 2020 Colorado Apprenticeship Program of the Year, Employer National Awards: Engineering News Record 2020 ENR Mountain States Specialty Contractor of the Year 2019 Colorado Project of the Year Winner- Gaylord Rockies 2020 Office/Retail/Mixed-Use, Award of Merit: Financial House 2020 Cultural/Worship, Award of Merit: Denver Art Museum Sie Welcome Center Top 40 and highest ranked Mechanical Firm in Colorado on ENRs Top 50 Firms in Mechanical, 2020 #8 Top 20 Firms in Sheet Metal, 2020 #19 Top 20 Firms in Steel Erection, 2020 #95 ENRs “The Top 600 Specialty Contractors”, 2020 Associated Builders and Contractors #16 Top 200 Performers, 2020 #2 Top 20 Plumbing/HVAC Contractors, 2020 #5 Top 30 Electrical Contractors, 2020 America Heart Association Gold Level Employer"
Data Engineer,Murphy Oil,"Hybrid remote in Houston, TX",https://www.indeed.com/rc/clk?jk=f44e3b0619ebd180&fccid=bb18f924ce62af2a&vjs=3,"At Murphy Oil Corporation, we believe the rich experiences and backgrounds of our employees strengthen our Company, create a productive workforce, and drive our success. We encourage you to apply for the positions for which you meet the qualifications. Job Summary The Murphy US Onshore Operations is looking for a Data Engineer to support various teams i.e.: drilling, completions, and production to gain insights from analyzing data from external and internal datasets. The Data Engineer will be a problem solver who can analyze data, identify problems, develop, and improve workflows, automate processes, and lead the business units to make data driven decisions. The right candidate would be passionate about finding solutions hidden in large datasets and working with stakeholders to improve business results. The Data Engineer will work in our Houston Corporate office and may work two (2) days a week remote. Responsibilities Perform data mining, cleansing, and manipulation; identify necessary data elements and their sources, leverage appropriate tools to acquire and consolidate large volumes of data from different sources, and identify and resolve any irrelevant, corrupt, missing, or incongruent data Identify and use appropriate technologies and platform to execute analytics against business requirements, including the ability to scale, deploy and distribute models across enterprise as needed Support the development of business cases for new solutions, with in-depth analysis of the challenge being addressed, the cost of the solution and projected business impact Support the development of performance management scorecards and dashboards to monitor adoption, implementation and impact of price and cost strategies Collaborate with cross-functional teams to frame requirements within an analytics context to tackle business goals Research and develop statistical learning models for data analysis Collaborate with product management and engineering departments to understand company needs and devise possible solutions Implement new statistical or other mathematical methodologies as needed for specific models or analysis Optimize joint development efforts through appropriate database use and project design Qualifications/Requirements Bachelors’ Degree in a quantitative field such as Computer Science, Statistics, Mathematics, engineering, or another quantitative field Minimum 3 years of professional industry experience in performing ETL jobs and data analysis. Strong proficiency with SQL & Python Good data visualization background with experience in PowerBI / Spotfire Desired/Preferred Qualifications Familiarity with Procount, Enersight, Aries and ValNav backend database would be a plus Experience in developing web applications using php / JavaScript or no-code solutions like PowerApps and PowerAutomate would be a plus PURPOSE We believe in providing energy that empowers people. MISSION We challenge the norm, tap into our strong legacy and use our foresight and financial discipline to deliver inspired energy solutions. VISION We see a future where we are an industry leader who is positively impacting lives for the next 100 years and beyond. VALUES & BEHAVIORS Do Right Always Respect people, safety, environment and the law Follow through on commitments Make it better Think Beyond Possible Offer solution Step up and lead Don’t settle for “good enough” Embrace new opportunities Stay With It Show resilience Lean into challenges Support each other Consider the implications _________________________________________________________________________________________________ Murphy Oil Corporation participates in the Department of Homeland Security U.S. Citizenship and Immigration Services' E-Verify program. Please read the E-Verify Notice-English / E-Verify Notice-Spanish and Right to Work Notice before proceeding with your job application. For additional information, you may also visit the USCIS website . Murphy Oil Corporation is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity or expression, genetic information, age, national origin, sexual orientation, disability, protected veteran status or any other category protected by federal, state or local law. EEO is the Law Poster EEO is the Law Supplement"
Data Engineer,Brave,"Remote in San Francisco, CA",https://www.indeed.com/rc/clk?jk=fc573e4b221c34f0&fccid=9e961d35e88738f2&vjs=3,"Data Engineer About Brave Brave is on a mission to protect the human right to privacy online. We've built a free web browser that blocks creepy ads and trackers by default, a private search engine with a truly independent index, a browser-native crypto wallet, and a private ad network (opt-in!) that directly rewards you for your attention. And we're just getting started. Already 50 million people have switched to Brave for a faster, more private web. Millions more switch every month. The internet is a sea of ads, hackers, and echo chambers. Big Tech makes huge profits off our data, and tells us what's true and what's not. Brave is fighting back. Join us! Summary Brave Ads is Brave's global private ad network, redesigned from the ground up to reward users while enforcing the highest standards of user privacy. The Brave Ads team works to ensure that marketers, both large and small, receive the information they need to make the most of their campaign dollars, without sacrificing strict user privacy. We are looking for a great data engineer who can help us maintain and improve our growing data pipeline, and help create additional data products and cubes that can drive the business forward. Requirements Experience with Python or similar language Experience with SQL, Postgres, and building analytics queries Experience with complex data flow/analytics infrastructure, e.g. Kakfa, Kinesis, Redshift and large scale data problems Experience with OLAP and data visualization Comfortable working in an open source setting A passion for helping protect users' privacy and security Written and verbal communication skills in English Proven record of getting things done Nice to haves Experience with ad-tech / marketing tech ecosystem Working at Brave Industry-leader in privacy, with a research and engineering team that's innovating everyday to keep people safer online and beat Big Tech Highly competitive salaries & benefits, and generous home-office stipends Fully remote team (no office, no commute) Welcoming, humble, ridiculously smart teammates, and a truly flat org structure Opportunity to get in early at a hyper-growth company, and revolutionize the web Oh, and did we mention Brendan, our CEO & co-founder, invented JavaScript? Check us out LinkedIn | Glassdoor | brave.com"
Senior Data Engineer,Vanguard,"Malvern, PA+4 locations",https://www.indeed.com/rc/clk?jk=67bcef8528f219b7&fccid=510aa29fcf8f87d9&vjs=3,"This position will support Vanguard’s system domain data engineering team. The team creates and supports ETL processes that transform raw data sourced from various platforms into curated, gold copy, data sets that are used by Vanguard’s analyst community, business leaders, project leaders, as well as AI/ML applications. The technology stack used to implement and support the ETL process includes various AWS technologies (Glue ETL, S3, IAM, SNS, SQS, Lambda), Confluence and Collibra for documentation, Jira for work/project management, BitBucket for code storage and version control, Bamboo for code deployment, and Talend for data quality. Provides advanced data solutions by using software to process, store, and serve data to others. Tests data quality and optimizes data availability. Ensures that data pipelines are scalable, repeatable, and secure. Utilizes a deep dive analytical skillset on a variety of internal and external data. Core Responsibilities 1. Writes ETL (Extract / Transform / Load) processes, designs database systems, and develops tools for real-time and offline analytic processing. 2. Troubleshoots software and processes for data consistency and integrity. Integrates large scale data from a variety of sources for business partners to generate insight and make decisions. 3. Translates business specifications into design specifications and code. Responsible for writing complex programs, ad hoc queries, and reports. Ensures that all code is well structured, includes sufficient documentation, and is easy to maintain and reuse. 4. Partners with internal clients to gain an enhanced understanding of business functions and informational needs. Gains expertise in tools, technologies, and applications/databases in specific business areas and company-wide systems. 5. Leads all phases of solution development. Explains technical considerations at related meetings, including those with internal clients and less experienced team members. 6. Tests code thoroughly for accuracy of intended purpose. Reviews end product with the client to ensure adequate understanding. Provides data analysis guidance as required. 7. Designs and conducts training sessions on tools and data sources used by the team and self provisioners. Provides job aids to team members and business users. 8. Tests and implements new software releases through regression testing. Identifies issues and engages with vendors to resolve and elevate software into production. 9. Participates in special projects and performs other duties as assigned. Qualifications Minimum of five years data analytics, programming, database administration, or data management experience. Undergraduate degree or equivalent combination of training and experience. Special Factor Vanguard is not offering visa sponsorship for this position. About Vanguard We are Vanguard. Together, we’re changing the way the world invests. For us, investing doesn’t just end in value. It starts with values. Because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. We invest with purpose – and that’s how we’ve become a global market leader. Here, we grow by doing the right thing for the people we serve. And so can you. We want to make success accessible to everyone. This is our opportunity. Let’s make it count. Inclusion Statement Vanguard’s continued commitment to diversity and inclusion is firmly rooted in our culture. Every decision we make to best serve our clients, crew (internally employees are referred to as crew), and communities is guided by one simple statement: “Do the right thing.” We believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. We empower our crew to contribute their distinct strengths to achieving Vanguard’s core purpose through our values. When all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on Vanguard's core purpose. Our core purpose: To take a stand for all investors, to treat them fairly, and to give them the best chance for investment success. Future of Work During the pandemic, we transitioned to a work from home model for the majority of our crew and we continue to interview, hire, and on-board future crew remotely. As we have developed the path forward, we have taken a thoughtful approach that both maximizes the advantages of working remotely and the many benefits of coming together and collaborating in a shared workspace. We believe that in-person interactions among our crew are important for preserving our unique culture and advantageous for the personal development of our crew. When our Crew return to the office, many will work in our hybrid model. A smaller proportion of our crew will operate in the Work from Home work model (for example, field sales crew); or in the Work from Office model (for example, portfolio managers). The working model that your role falls into will be communicated to you in the interview process – please do ask if you are unsure. We encourage you to make the decision regarding your job interview and offer knowing which model your role will fall into. We will test and learn as our ways of working evolve and will continue to evaluate working models along the way."
"Data Engineer, Business Strategy and Operations, Core",Google,"Hybrid remote in San Francisco, CA",https://www.indeed.com/rc/clk?jk=26e306badd3ac678&fccid=a5b4499d9e91a5c6&vjs=3,"Note: Google’s hybrid workplace includes remote and in-office roles. By applying to this position you will have an opportunity to share your preferred working location from the following: In-office locations: Sunnyvale, CA, USA; San Francisco, CA, USA. Remote location(s): United States. Minimum qualifications: Bachelor’s degree or equivalent practical experience. Experience in engineering, business intelligence, consulting, or a relevant industry/discipline. Experience with ETL activities such as data extraction, data transformation, batch processing, etc. Experience with database schema design creating and managing a data warehouse and experience with SQL and other business intelligence and reporting query systems. Preferred qualifications: Experience with Java database programming. Experience building databases, data modeling, normalization, and/or database performance tuning. Excellent database analysis skills. About the job The Core team's mission is to make Google work better for everyone and at scale. We synthesize and create strategy and people programs across all levels of Core and ensure that our operations are efficient and effective. We partner with Core leadership to create and implement the plans to achieve the goals of our organization and each of our groups with consistency, coherence, measurability, and accountability. Additional Information (Colorado only*) Minimum full-time salary range between $122,000 - $131,000 + bonus + equity + benefits. *Note: Disclosure as required by sb19-085 (8-5-20) of the minimum salary compensation range for this role when being hired into our offices in Colorado. Responsibilities Write SQL queries to transform data and write automated tests to verify the SQL. Use internal ETL tools to extract data from primary data sources, filter and transform the data for use in reporting and analysis, and load it into data warehouse tables. Work with internal business analyst subject matter experts to understand and accurately capture their data analysis and reporting requirements. Learn the schema of source data sets. Design and document the schema of transformed output data sets. Participate in defining and implementing the security and privacy controls for specific data sets. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form."
Data Visualization Engineer,Ginkgo Bioworks,+1 locationRemote,https://www.indeed.com/rc/clk?jk=d76cdae1f0f0a54e&fccid=825850c889c17b10&vjs=3,"On the Data Team, our focus is the strategic application of data science and engineering across the business. We tackle diverse problems that span molecular biology, robotic automation, finance & business strategy, and operations, all in service of supporting data-driven decision-making. We do that through a combination of durable software tools, closely embedded analysts, and side-by-side collaboration with data engineering. Every day we face new technical and scientific challenges that require deep cross-functional collaboration and novel solutions. Success in this evolving field is only possible with teams that represent diverse people, ideas, backgrounds, experiences, and ways of working. Active inclusion is core to how Ginkgo wins. We’re an equal opportunity employer and encourage individuals from underrepresented backgrounds to apply. As a Data Visualization Engineer, you’ll join a distributed, highly collaborative team composed of data engineers, analysts, and data scientists with a wide range of backgrounds and experiences (the team is currently located in Boston and Seattle). You'll partner closely with scientific collaborators from across Ginkgo to develop analysis plans, deliver durable reports, on-board and train partners, and work with data scientists and engineers to design data-driven software tools. Ideal candidates are self-starters with a strong technical background who can identify opportunities to solve problems with data. Candidates should be curious and eager to learn about both the science and the business, possess analytical skills and reasoning, be a strong leader who can mentor and grow the team, and excel at storytelling with data. #LI-SM1 Responsibilities Delivering end-to-end data products, i.e. ability to work across the product lifecycle from exploration and discovery, to operationalization and production Creating incremental value through rapid prototyping and iterative development Breaking down complex technical and quantitative topics for audiences with mixed levels of technical expertise; in particular, translating technical and scientific concepts into business outcomes and recommendations is essential for success in this role Building data-driven software products that are fit-to-purpose, e.g. embedded visualizations and calls to action in operational software, custom solutions for clients, externally facing tools that tell a biological story Storytelling with data, specifically supporting data-driven decisions with compelling visualizations Translating underdefined questions into data-driven tools and processes Presenting work progress, insights, and recommendations to stakeholders and senior leadership Building strong partnerships with collaborators and stakeholders, influencing and collaborating at all organizational levels Working effectively on a distributed team and adhering to common hours across time zones Minimum requirement of quarterly travel to headquarters in Boston, MA Minimum Requirements Must be able to start the day at 10am EST and have familiarity with communication strategies and tactics for managing a distributed team Deep expertise in a component framework like React, Angular, Vue, or Svelte, and experience building d3 chart components in the framework of choice Extensive experience with SQL, as weel asNoSQL data environments and tools such as Hadoop, Spark, DynamoDB is a plus Software development best practices including story estimation, test-driven development, code review, and version control with git Fluency and practical experience with data visualization techniques includingbest practices and ability to rapidly prototype in languages like R, Python, or Tableau Excellent written and verbal communication skills Strong technical writer and documenter Strong project management skills including managing complexity and making informed trade-offs to quickly escape rabbit holes and make on-time deliveries Willingness to grow and work outside your comfort zone, e.g. proactively exploring new tech, identifying new ways to solve problems, and applying pragmatism to drive solutions Preferred Capabilities and Experience Experience with the Amazon Web Services ecosystem Experience with Agile workflow practices and familiarity with Atlassian tools including Jira, and Confluence Familiarity with communication strategies and tactics for distributed teams is a plus Familiarity with biological data, specifically in the context of high-throughput screening is a plus To learn more about Ginkgo, check out some recent press: What is it really like to take your company public via a SPAC? One Boston biotech shares its journey (Fortune) Ginkgo Bioworks resizes the definition of going big in biotech, raising $2.5B in a record SPAC deal that weighs in with a whopping $15B-plus valuation (Endpoints News) Ginkgo Bioworks CEO on scaling up Covid-19 testing: ‘If we try, we can win’ (CNBC) Ginkgo raises $70 million to ramp up COVID-19 testing for employers, universities (Boston Globe) Ginkgo Bioworks Redirects Its Biotech Platform to Coronavirus (Wall Street Journal) Ginkgo Bioworks Provides Support on Process Optimization to Moderna for COVID-19 Response (PRNewswire) The Life Factory: Synthetic Organisms From This $1.4 Billion Startup Will Revolutionize Manufacturing (Forbes) Synthetic Bio Pioneer Ginkgo Raises $290 Million in New Funding (Bloomberg) Ginkgo Bioworks raises $350 million fund for biotech spinouts (Reuters) Can This Company Convince You to Love GMOs? (The Atlantic) We also feel that it’s important to point out the obvious here – there’s a serious lack of diversity in our industry, and that needs to change. Our goal is to help drive that change. Ginkgo is deeply committed to diversity, equity, and inclusion in all of its practices, especially when it comes to growing our team. Our culture promotes inclusion and embraces how rewarding it is to work with people from all walks of life. We’re developing a powerful biological engineering platform, so we must remain mindful of the many ways our technology can – and will – impact people around the world. We care about how our platform is used, and having a diverse team to build it gives us the best chance that it’s something we’ll be proud of as it continues to grow. Therefore, it’s critical that we incorporate the diverse voices and visions of all those who play a role in the future of biology. It is the policy of Ginkgo Bioworks to provide equal employment opportunities to all employees and employment applicants."
"'Next Chapter' Returnship Program - Software Engineer, Data",Audible,Remote in United States+2 locations,https://www.indeed.com/rc/clk?jk=856d2fc2352ab723&fccid=3e9b269328805689&vjs=3,"Job summary Good storytelling starts with great listening. At Audible, that means each role and every project has our audience in mind. Because the same people who design, develop, and deploy our products also happen to use them. To us, that speaks volumes. ABOUT THE PROGRAM The Next Chapter program at Audible is a 16-week paid returnship for experienced professionals returning to the workforce after taking time off for caregiving. The program is open to individuals who have at least 2 years of professional experience and have been out of the paid workforce for at least 1 year to focus on caring for a child or other dependent and is not currently in a university program. At Audible, we are excited to launch the Next Chapter program because we appreciate the skills you can offer, the perspective you provide, and the contributions you will make. This program offers you a chance to revamp your skills, update your resume with new experience, and make connections with other women and men transitioning back to the workforce. It also offers support through Path Forward, a nonprofit organization on a mission to empower people who’ve been focused on caregiving transition back to the paid workforce. This 16-week Returnship program is 100% virtual. Upon successful completion of the Returnship, there is a possibility of an offer for full-time employment. We have fully remote roles or roles based in our Newark, NJ, Cambridge, MA or LA hubs. ABOUT THIS ROLE As a Software Development Engineer, it’s up to you to define, design and refine the tech that keeps us one step ahead of listeners. Anticipate. Innovate. Bring challenging ideas and we’ll support you with the latest tech, tools, and systems that you need to succeed. We pride ourselves on our ability to imagine and invent solutions to problems of the future and you’ll be essential in this forward-thinking approach to development. Together with the team, you’ll build and maintain our platform to bring thousands of stories to millions of listeners and unleash the power of the human voice. ABOUT THE TEAM This opportunity is within Audible’s Data Engineering group. The Data Engineering group owns technology platforms and datasets that enable systems and people to uncover new insights and fine-tune operations to meet business goals. We need your help designing and building these. ABOUT YOU A great communicator who can adapt their message to ensure understanding from multiple stakeholders. A detail-oriented problem-solver who enjoys the process of scratching beneath the surface to find the best solution to challenges. Curious and unafraid to ask questions to gain deeper understanding. Adaptable team player who brings their best to every interaction and inspires the same in others. Passionate about bringing your skills to Audible while being open and eager to learn new things. As a Software Development Engineer, you will... Contribute to the development of the technical direction and strategy within the team and help influence technology across Audible and beyond. Assist in developing solutions, web solutions and services: Envisioning, designing, creating, and supporting our solutions that operate with a high degree of operational excellence. Partner with a cross-functional team to imagine, design, develop, test, and launch software that wows our community and inspires our peers. Be willing to explore technical needs and bring problems AND solutions to the table. Constantly strive to raise the bar on engineering excellence. Take advantage of the resources, training and experts around you to- stay up to date with tools, trends, technologies and frameworks both industry-wide and within Amazon and then share that knowledge in a meaningful way with the community. Basic Qualifications Bachelor’s degree or higher in Computer Science, Engineering, Mathematics, Physics, or a related field. Proficiency in functional programming languages (e.g. Python) as well as declarative programming languages (e.g. SQL, SPARQL). 2+ years of hands on experience in working on data-centric systems using MPP Database technologies and Hadoop, Spark, Kafka or AWS equivalents. Preferred Qualifications Understanding of processing and modeling large, complex data sets for Analytical use cases with Database technologies such as AWS Redshift, Teradata or equivalent. Familiarity with AWS cloud technologies such as Elastic Map Reduce (EMR), Kinesis, Athena. Familiarity with BI and Visualization platforms such as MicroStrategy and AWS Quicksight. Ability to communicate effectively and work independently with little supervision to deliver on time quality products. Willingness to learn, be open minded to new ideas and different opinions yet knowing when to stop, analyze, and reach a decision. ABOUT AUDIBLE At Audible, we innovate and inspire through the power of voice. We're changing the narrative on storytelling. As a leading creator and provider of premium audio storytelling, we've redefined the ways people access, discover, and share stories. The stories we tell have the ability to transport and transform everyday moments into meaningful experiences and it's our people who make Audible's service possible. We're listeners, storytellers, and problem-solvers. Our perspectives and experiences power our ideas and come together in our mission to unleash the power of the spoken word. The pay for this position in Colorado is $73.13/hr. Our range of benefits may include health care, employee discounts, 401(k) savings plans, paid time off, and more. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. Applicants should apply via Amazon's internal or external careers site. Audible is committed to a diverse and inclusive workplace. Audible is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Data Engineer,The Aerospace Corporation,"Remote in Chantilly, VA+1 location",https://www.indeed.com/rc/clk?jk=ff980f9069d08420&fccid=ba923b146fa75d0d&vjs=3,"The Aerospace Corporation is the trusted partner to the nation’s space programs, solving the hardest problems and providing unmatched technical expertise. As the operator of a federally funded research and development center (FFRDC), we are broadly engaged across all aspects of space— delivering innovative solutions that span satellite, launch, ground, and cyber systems for defense, civil and commercial customers. When you join our team, you’ll be part of a special collection of problem solvers, thought leaders, and innovators. Join us and take your place in space. At Aerospace, we are committed to providing an inclusive and diverse workplace for all employees to share in our common passion and aspiration – to carry out a mission much bigger than ourselves. We remain committed to maintaining a safe environment for hiring as we look forward to the future of work. Click here for information on Aerospace's COVID-19 directives and safety procedures implemented to keep our workplace safe. The Datacentric Platform and Architectures Dept. develops data analysis pipelines, tools and platforms to enable the full exploitation of historical and streaming data sets for a variety of civil and national security space customers. Do you want to do cutting edge data engineering and do innovative work on the open-source data processing frameworks with the ability to intelligently scale? Join us as a Data Engineer on the Datacentric Platform and Architectures Department team at The Aerospace Corporation! This position can be fully remote or a hybrid work model (partially remote with some onsite work in El Segundo, CA, Chantilly, VA, or Colorado Springs, CO). What You’ll Be Doing Working closely with National Security Space, United States Space Force, and other Department of Defense customers We provide data engineering and data architecture solutions for the space enterprise Data engineering is at the center of many developing and future information systems and holds a key role in the organization at large Customers rely on our capabilities as data volumes continue to grow at exponential rates This position is focused on leading development and developing highly resilient and efficient data platforms Duties, responsibilities, and activities may change, or new ones may be assigned as needed We use the development of these types of data platforms to increase velocity and innovation for Aerospace and our customers This position can be filled as a Data Engineer (Associate Member of Technical Staff) or Data Engineer (Member of Technical Staff) What You Need to be Successful Minimum Requirements for Data Engineer (Associate MTS): Bachelor's or advanced Science degree from an accredited program in computer science or other applicable STEM concentrations. Less than a year or more of professional experience in data/software engineering related work Knowledge of a programming languages i.e., Python, C/C++, Java, etc. Data architectures and platforms Cloud technology and utilization Back-end and middleware development This position requires ability to obtain and maintain a security clearance, which is issued by the US government. U.S citizenship is required to obtain a security clearance. Minimum Requirements for Data Engineer (MTS): All of the above requirements for Data Engineer 2 or more years of professional experience in data/software engineering related roles How You Can Stand Out It would be impressive if you have one or more of these: Advanced [Masters, PhD] degree from an accredited program in computer science or other applicable STEM concentration Development of data platforms Experience with data security and governance technologies Microservice architectures Knowledge of data virtualization and data access Distributed and stream data processing Grade-Based Pay Range (Min - Mid - Max) $67,573 - $117,940 - $168,307 Ways We Reward Our Employees During your interview process, our team will provide details of our industry-leading benefits. Benefits vary and are applicable based on Job Type. A few highlights include: Comprehensive health care and wellness plans Paid holidays, sick time, and vacation Standard and alternate work schedules, including telework options 401(k) Plan — Employees receive a total company-paid benefit of 8%, 10%, or 12% of eligible compensation based on years of service and matching contributions; employees are immediately eligible and vested in the plan upon hire Flexible spending accounts Variable pay program for exceptional contributions Relocation assistance Professional growth and development programs to help advance your career Education assistance programs An inclusive work environment built on teamwork, flexibility, and respect We are all unique, from diverse backgrounds and all walks of life, yet one thing bonds all of us to each other—the belief that we can make a difference. This core belief empowers us to do our best work at The Aerospace Corporation. Equal Opportunity Commitment The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, age, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender, gender identity or expression, color, religion, genetic information, marital status, ancestry, national origin, protected veteran status, physical disability, medical condition, mental disability, or disability status and any other characteristic protected by state or federal law. If you’re an individual with a disability or a disabled veteran who needs assistance using our online job search and application tools or need reasonable accommodation to complete the job application process, please contact us by phone at 310.336.5432 or by email at ieo.mailbox@aero.org . You can also review The Equal Employment Opportunity is the Law and the supplement , as well as the Pay Transparency Policy Statement ."
Data Engineer/ETL Developer,National Renewable Energy Laboratory,Remote,https://www.indeed.com/rc/clk?jk=3f444990db065251&fccid=b4ae64835618776c&vjs=3,"Posting Title Data Engineer/ETL Developer . Location Remote . Position Type Regular . Hours Per Week 40 . Mandatory COVID-19 Vaccination Protocols Employment at NREL is contingent upon your compliance with all NREL and U.S. Department of Energy (DOE) safety protocols and mitigation efforts directed at the COVID-19 pandemic. At present, NREL requires all employees to be immunized against COVID-19. However, employees may seek an exemption from this requirement as an accommodation for religious or medical reasons. Upon hire, new employees must submit a request for accommodation or be prepared to provide proof of vaccination on your first day of employment. Working at NREL From day one at NREL, you’ll connect with coworkers driven by the same mission to save the planet. By joining an organization that values a supportive, inclusive, and flexible work environment, you’ll have the opportunity to engage through our eight employee resource groups, numerous employee-driven clubs, and learning and professional development classes. NREL supports inclusive, diverse, and unbiased hiring practices that promote creativity and innovation. By collaborating with organizations that focus on diverse talent pools, reaching out to underrepresented demographics, and providing an inclusive application and interview process, our Talent Acquisition team aims to hear all voices equally. We strive to attract a highly diverse workforce and create a culture where every employee feels welcomed and respected and they can be their authentic selves. Job Description NREL’s Data Management is in search of an experienced ETL Developer. This role will be responsible for ongoing analysis of data obtained from a variety of sources. This individual will require proficiency with Informatica Power Center, SQL/PL SQL, exceptional analytical and problem solving abilities, strong data warehousing skills, knowledge of data analysis methodology, strong communication skills and use of BI presentation software. Duties shall include: Work closely with other team members and key technical resources (including the Database Administrators and Data Architect), to help design, develop, troubleshoot, and implement ETL processes supporting the data warehouse projects and enhancements Assisting with requirements gathering and designing the business process dimensional models. Develop, manage, and validate existing data models including logical and physical models of the data warehouse and source systems Develop and program test scripts to identify and manage data inconsistencies and testing of ETL processes Designing and developing exception handling and data cleansing / standardization procedures Evaluate and improve data quality throughout source systems by implementing data quality safeguards Investigate, analyze, document, and assist in resolution of data quality issues reported by business users and Information Delivery personnel. Provide production support for fiscal period financial close-out processing including manual loads and file transfers and validation of processed data Provide assistance to Business Intelligence Developers (setting up and testing reporting instances & upgrades, troubleshooting data and technical issues within reports, developing reports, performance tuning, etc.) . Basic Qualifications Relevant Bachelor's Degree and 9 or more years of experience or equivalent relevant education/experience. Or, relevant Master's Degree and 7 or more years of experience or equivalent relevant education/experience. Or, relevant PhD and 4 or more years of experience or equivalent relevant education/experience. Applies extensive IS expertise in specific field and has full knowledge of related disciplines. Evaluates new hardware, software, systems tools and applications and makes procurement recommendations. Excellent leadership and project management skills. Skilled in analytical techniques, practices and problem solving. Extensive programming and architecture abilities with various computer software programs and information systems. . Additional Required Qualifications Ability to communicate design solutions to both technical and non-technical audiences Experience in data architecture, data warehousing (star design), master data management, enterprise information integration and ETL procedures Experience with data analysis, modeling, and design specific to a data warehouse Experience with the design of large scale ETL solutions integrating multiple source systems in a hybrid on-premise/could environment Strong analytical and documentation skills Ability to independently identify, troubleshoot, and/or resolve issues Drive to be proactive rather than reactive Adhering to internal programming and development standards/guidelines Experience developing & maintaining Slowly Changing Dimensions Proficiency in using recent versions of Informatica’s Power Center ETL tools Ability to understand business processes, data entities, data producers, and data dependencies Understanding of corporate systems, data environments and BI tools Preferred Qualifications 5-10 years of experience using advanced SQL methods, such as pivoting and recursive SQL (preferred Oracle dialect) 5-10 years experience in Informatica Power Center 5 years experience in PL/SQL (or similar procedural SQL language) and stored procedures. 5 years experience in loading data warehouses and load control design/development Experience with Business Intelligence t ools Experience with Jenkins or other CI/CD scheduling tools . Annual Salary Range (based on full-time 40 hours per week) Annual Salary Range: $90,600 - $163,100 NREL takes into consideration a candidate’s education, training, and experience, as well as the position's work location, expected quality and quantity of work, required travel (if any), external market and internal value, including seniority and merit systems, and internal pay alignment when determining the salary level for potential new employees. In compliance with the Colorado Equal Pay for Equal Work Act, a potential new employee’s salary history will not be used in compensation decisions. Benefits Summary Benefits include medical, dental, and vision insurance; short*- and long-term disability insurance; pension benefits*; 403(b) Employee Savings Plan with employer match*; life and accidental death and dismemberment (AD&D) insurance; personal time off (PTO) and sick leave; paid holidays; and tuition reimbursement*. NREL employees may be eligible for, but are not guaranteed, performance-, merit-, and achievement- based awards that include a monetary component. Some positions may be eligible for relocation expense reimbursement. Limited-term positions are not eligible for long-term disability or tuition reimbursement. * Based on eligibility rules Submission Guidelines Please note that in order to be considered an applicant for any position at NREL you must submit an application form for each position for which you believe you are qualified. Applications are not kept on file for future positions. Please include a cover letter and resume with each position application. . EEO Policy NREL is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard basis of age (40 and over), color, disability, gender identity, genetic information, marital status, military or veteran status, national origin/ancestry, race, religion, creed, sex (including pregnancy, childbirth, breastfeeding), sexual orientation, and any other applicable status protected by federal, state, or local laws. EEO is the Law | Pay Transparency Nondiscrimination | Reasonable Accommodations E -Verify www.dhs.gov/E-Verify |For information about right to work, click here for English or here for Spanish. E-Verify is a registered trademark of the U.S. Department of Homeland Security. This business uses E-Verify in its hiring practices to achieve a lawful workforce."
Data Engineer,Surya Systems,+4 locationsRemote,https://www.indeed.com/rc/clk?jk=d37fc152f05c9c46&fccid=af1cebb7f11ae180&vjs=3,"Overview Position: Data Engineer Location: REMOTE Duration: 12 Months As a Data Engineer you will build curated datasets and make them accessible to our partner teams by writing at scale production data pipelines. Your work will enable the decision-makers across the service operations organization to bring together insights and support our operations strategy and customer experience. In this role you will: Design, develop, and launch extremely efficient and reliable data pipelines to move data and to provide intuitive analytics to our partner teams. Make data more discoverable and easy to use for Data Scientists and Analysts across the service operations organization Collaborate with other engineers and Data Scientists to discover the best solutions. Diagnose and solve issues in our existing data pipelines and envision and build their successors.Qualifications Qualifications: Good understanding of one or more of the following: Python, Scala, or Java Strong understanding of SQL Broad knowledge of the data infrastructure ecosystem Experience with Hadoop or other MapReduce-based architectures Experience working with large data volumes Experience in building Data Warehouses and data modeling. Experience with any of the following is a plus: BigQuery, Presto, or Hive Thanks & Regards... G Naveen Kumar Email : ************* Desk : 215-344-2345 Surya Systems, Inc"
Data Engineer,StoneX Group Inc. US,"New York, NY+1 location",https://www.indeed.com/rc/clk?jk=c033f7cbb60cf33a&fccid=95d5989e745a95bc&vjs=3,"Position Purpose: We Connect Clients to Markets. StoneX (formerly known as INTL FCStone) is an institutional-grade financial services network that connects companies, organizations, traders and investors to the global markets ecosystem through a unique blend of digital platforms, end-to-end clearing and execution services, high-touch service and deep expertise. This position will be to support and enhance the current Data Engineering and Data Science capabilities of the Data & Analytics team which currently provide marketing and customer analytics, and KPI dashboards to several stakeholders across multiple brands globally. Primary Accountabilities/Responsibilities: Manage and oversee the data pipeline that is feeding reporting and ML models (tech stack based on Python/Airflow, Dremio) Interface with Architecture and Dev teams to facilitate development of the tech stacks and additional data sources Use Python (main libraries such as pandas, Pyodbc, sqlalchemy, airflow etc) to develop custom connection and data feeds through 3rd party APIs Use SQL scripting to manipulate and extract data from large relational databases & automate the process for importing data from multiple sources and various file formats. (Flat files / ODBC / OLDB etc). Interface with Data science team in order to enable Machine Learning projects / capabilities (make right data available) Deal confidently with different data sources and data models Being a key player to support the data project roadmap spanning all stages of the data value chain: from data architecture to data engineering, data processing and model design Job Requirements: Bachelor’s degree in a quantitative field (math, statistics, comp. science, engineering, economics, etc.). Master’s degree a plus Mid-level experience of relevant data environments such as MS SQL Server 2008/2016 Expert-level experience of SQL Server programming/scripting experience Experience in programming DAG (Direct Acyclic Graphs) in Airflow 2 years’ experience in programming with python or similar languages Minimum of 2/3 years in similar role or capacity required, working across different markets as business partner. Experience or academic background on data models and relational DB schemas Attention to detail and data driven analytical & problem-solving skills Ability to manage and prioritize own workload and escalate potential risk to the line manager Physical requirements/Working conditions: Climate controlled office environment Minimal physical requirements other than occasional light lifting of boxed materials Dynamic, time-sensitive environment StoneX (formerly known as INTL FCStone) is an institutional-grade financial services network that connects companies, organizations and investors to the global markets ecosystem through a unique blend of digital platforms, end-to-end clearing and execution services, high-touch service and deep expertise. We provide access to 36 derivatives exchanges, 175 foreign exchange markets, nearly every global securities marketplace and a number of bi-lateral liquidity venues. We deliver this access with support throughout the entire lifecycle of a trade – from consulting and “boots-on-the-ground” intelligence, to best execution, to post-trade clearing, custody and settlement. In these ways, StoneX enables clients to use the global markets ecosystem to achieve their business goals through one trusted partner. We currently serve more than 30,000 commercial, institutional and payments clients, and more than 125,000 retail clients across more than 130 countries. Our clients use our institutional-grade digital platforms, our high-touch service, and our market intelligence to pursue trading opportunities, make investments efficiently, manage their market risks, and improve their business performance. Our relentless focus on helping them accomplish these objectives has enabled us to build deeply valued, long-term relationships based on guidance, integrity, transparency and trust. StoneX Group Inc. is an Equal Opportunity Employer . Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law."
Senior Data Engineer,LeaseQuery,"Hybrid remote in Atlanta, GA",https://www.indeed.com/rc/clk?jk=9c0d5b0023ee82ec&fccid=ef90848818b8658a&vjs=3,"LeaseQuery is looking for a Senior Data Engineer to join our Engineering team. We’re seeking someone with a passion for improvement; both in our processes and in yourself. We work in an Agile environment with development teams utilizing Scrum and Kanban. At LeaseQuery, a Data Engineer is a person who focuses on the design, scalability and malleability of our data infrastructure. They work on teams using agile approaches building artifacts needed to sustain the technical systems beyond data management/ETL (documentation, data dictionaries, designs and so on). The ideal candidate has deep knowledge of SQL database design, experience with data warehouses across multiple databases, and expertise in the design, creation, management, and business use of large datasets. LeaseQuery's headquarters is located in Atlanta, GA, but this role can sit 100% remote. What you will be doing: Ensure scalable, reliable, and performant AWS PostGres databases and environments Application and system monitoring and performance tuning Interfacing daily with Development teams and other departments Monitoring and providing feedback to developer driven data architecture changes Participating in release and deployments Identifying, designing, and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes Working with stakeholders including engineering, product, and executive teams and assisting them with data-related technical issues and inquiries Proposing new technologies and practices as solutions or improvements to existing systems Finding trends in data sets and developing algorithms to help make raw data more useful to the enterprise Research, assess, and enhance ETL pipeline Identify data discrepancies between systems and work with SMEs to recommend solutions What tech you will work with: Hosting and Administration: AWS RDS/Aurora Communication: Atlassian Jira, Slack Database: SQL, PostgreSQL Analytics and Logging: DataDog Build and deployment tools: Git, Liquibase What skills and experience we need you to have: 3+ years in a data engineer role 6+ years of experience working with databases and data architectures in any IT role Experience designing, building, deploying, and scaling databases Solid understanding of data architecture An attitude of success defined in team accomplishments Benefits we offer: Flexible PTO (including 11 holidays and your birthday off) 401(k) plan with employer matching Great health benefits with multiple plan option Option to choose between in office, fully remote, or a hybrid work environment for all employees Casual dress environment (when in office) Catered lunches every Tuesday and Thursday Company events each quarter Signing stipend for a work-from-home setup Free gym membership at our office Annual employee development program stipend of $2,000 for each employee Flexible parental leave with 10 weeks paid leave for ALL new parents Fertility/adoption assistance Annual tutoring stipend for your children Mentorship program available immediately Regular team outings Advancement opportunities based on results, not politics Culture that emphasizes inclusiveness driven by our REDI Committee About Us LeaseQuery simplifies complex accounting with our innovative FinTech SaaS technology. Our products, used by more than 2000+ organizations in 87 countries, are top rated for user satisfaction and ease of use by G2, and our company has appeared on the Deloitte Technology’s Fast 500 list and Georgia’s Fast 40 list among many other recent accolades over the past several years. During the past decade, our CEO, George Azih, grew LeaseQuery from a one-person company to a workforce of 280+ representing one of the fastest-growing FinTech companies today. As we move into our next phase of growth, we're looking for passionate and dedicated people who want to invest their energy to align with our company's long-term goals. #LI-Remote LeaseQuery is an equal opportunity employer to all persons, free from restrictions and prejudice based upon race, color, creed, religion, sex, domestic relationship status, parental status, family status, sexual orientation, national origin, gender identity, age, disability, and veteran status. LeaseQuery maintains a drug-free workplace."
Senior Data Engineer,Panasonic Corporation of North America,"Palo Alto, CA",https://www.indeed.com/rc/clk?jk=c4f7f0c9417c7c8a&fccid=1cd1990427c0d7e2&vjs=3,"About Yohana: Yohana is on a mission to help people find more balance and prioritize well-being. We create integrated software, services, and hardware specifically for modern families, to alleviate their mental load so they can feel present and connected. We are a fully funded independent subsidiary of Panasonic, one of the oldest purpose-driven brands in the world, with leadership from big tech, Google, Apple, Microsoft, as well as hypergrowth startups, Nest, Waymo, Casper. First up is our Yohana Membership, which just launched in Seattle. It is a personal assistant service designed for busy families – especially moms – to help lighten the mental load of having too much to do. It is the first of many meaningful things we are working on. We are building a positive, supportive culture from the ground up, where individuals and teams grow together. Maybe you should join us. About The Role: We are looking for a savvy Senior Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. What You'll Get To Do: Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional and non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS services. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. What You'll Bring: Advanced working SQL knowledge and experience working with relational databases, as well as working familiarity with a variety of databases. Experience building and optimizing big data data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable big data data stores. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools: Experience with big data tools: Snowflake, Google Analytics, Kafka, etc, huge plus if familiar with Salesforce Experience with relational SQL and NoSQL databases. Experience with object-oriented and object function scripting languages: Java, Kotlin, Python etc. What We Offer: Opportunity to join a hyper-growth startup on a mission to make well-being attainable for modern families Competitive compensation Comprehensive benefits: Medical, Dental, Vision, HSA, FSA 401k with employer match Life and Short Term Disability Insurance Supplemental Medical Coverage Unlimited PTO 12 Company Holidays Paid Maternity and Parental Leave Paid Caregiver Leave Employee Assistance Program Group and 1-on-1 Career Coaching Pet Insurance Casual Dress Code Catered Lunch and Snacks Discounts on Panasonic products Company Social Events We are proud to be an Equal Opportunity and Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity, sex, sexual orientation, national origin, disability status, protected veteran status, and any other characteristic protected by law or company policy. All qualified individuals are required to perform the essential functions of the job with or without reasonable accommodation. Pre-employment drug testing is required for safety sensitive positions or as may otherwise be required by contract or law. Due to the high volume of responses, we will only be able to respond to candidates of interest. All candidates must have valid authorization to work in the U.S. Thank you for your interest."
Data Center Design Engineer (Mechanical) - Data Center Devel...,BYTEDANCE PTE. LTD.,"Marina, CA+1 location",https://www.indeed.com/rc/clk?jk=7029e52dbfe52330&fccid=f7c1bf12d2e5610c&vjs=3,"Location Singapore, Central Singapore Planning Area MARINA SOUTH Job Type Full Time Salary $10,000 - $20,000 Per Month Date Posted 5 days ago Expiry Date 06-Jul-2022 Additional Details Job ID 234728 Job Views 209 Roles & Responsibilities Founded in 2012, ByteDance's mission is to inspire creativity and enrich life. With a suite of more than a dozen products, including TikTok, Helo, and Resso, as well as platforms specific to the China market, including Toutiao, Douyin, and Xigua, ByteDance has made it easier and more fun for people to connect with, consume, and create content. Responsibilities The Datacenter Development team is responsible for site selection, acquisition and delivery. As the Data Center Design Engineer, you will be responsible for the following: Responsible for technical evaluation of design submission by various providers Responsible for technical design of mechanical system for data centers Responsible for localisation of data center standards & critical equipment specifications Support site selection related task in Singapore/Malaysia & Other Non-China Regions Support and work closely with the design team for the optimization of data hall standards Support local operation team for trouble-shooting and optimizing design standards Support Ad-Hoc project management tasks assigned Qualifications Bachelor's Degree in Mechanical/Civil Engineering or equivalent Familiar with local code & fire code At least 2 years of experience in a similar field With relevant experience of project delivery for at least 5000 racks project WIth relevant experience of liquid cooling deployment is an added advantage Certified Professional Engineer is an added advantage Tags data center design engineer mechanical data center development"
Data Engineer,eClinicalWorks,"Westborough, MA 01581",https://www.indeed.com/rc/clk?jk=2f91933427f33d8f&fccid=27a0ffd30391d406&vjs=3,"Description We are eClinicalWorks. We are a privately held leader in healthcare IT, providing comprehensive, cloud-based EHR/PRM solutions to medical professionals worldwide to improve workflows and reduce the risk of physician burnout. We care. We are committed to positive change. And that’s where you come in. Do you value creativity and innovation? Great, so do we. At eClinicalWorks, we share a passion for improving healthcare through dedication, education, and teamwork. Everyone has that one thing they’re really good at. We value your talent and want you to join our fast-paced, fun, and culturally diverse environment. Ready to make a difference? Apply today. Position Overview This position is responsible for transfer of information from client’s existing software to eClinicalWorks software. Responsibilities This position requires a demonstrated understanding of data quality, privacy and security issues. Responsible for extraction and mining of large volumes of data sets from a variety of data sources (Relational databases, XML, flat file formats etc.) and create complex data reports for analysis Work with clients to identify, define, collate, document, and communicate data migration requirements Responsible for data profiling, data cleansing, data transformation and the loading of data into eClinicalWorks software. Design and develop algorithms and visualization tools to help manage an efficient data migration process Write Java programs, T-SQL scripts and stored procedures for the data conversions and apply quality control processes to all output to ensure accuracy Create database objects such as tables, views, indexes, triggers, stored procedures, functions, and Integration Services packages to support new and existing applications Liaison with customers and Project Managers and provide regular updates to ensure a smooth data migration experience Deliver best practice, processes, and standards for effectively carrying out data migration activities Perform quality assurance and database validation on all test and live conversions Create, debug and execute JAVA programs to handle conversions of various sets of standard document formats (RTF, HTML, Word, Text, JPEG, TIFF, PNG, XML) and other custom format documents to PDF. Ensures data integrity, data security and performance of production databases. Requirements Bachelor degree in Computer Science, Data Analytics, Data Science, Business Analytics, or similar field 2+ years of proficiency in Java 2+ years of proficiency in Microsoft SQL server and MySQL Databases 1 - 2 years of experience with other database (Oracle/PostgreSQL/Sybase/MS Access/Informix/C-tree) Open to work into Night/EST shift (5:30 PM to 2:30 AM IST) Excellent Communication Skills Other Skills/Abilities Strong communication skills Strong project management skills with ability to work well under pressure with multiple priorities and deadlines Strong research, analytical, and creative problem-solving skills Ability to work in a fast-paced work environment Demonstrated success in working with cross-functional teams Ability to analyze data, identify trends and develop/optimize workflow hypothesis. Please know, current policy requires all eCW employees to be fully vaccinated against Covid-19 for business travel or attendance at any eCW location, event or customer, to the extent permitted by applicable law. eClinicalWorks is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills, and experiences that bring us together and help create a healthy world Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Engineer,Cornerstone Defense,"Chantilly, VA+5 locations",https://www.indeed.com/rc/clk?jk=8308c5e1f0659ea4&fccid=c4dad3c95358e466&vjs=3,"Data Engineer Clearance: TS/SCI with ability to obtain Polygraph within reasonable period of time Location: Chantilly, VA Company Overview: Cornerstone Defense, in partnership with our military, intelligence, and civil government customers, supports U.S. operations worldwide through the use of many different types of intelligence, satellite, and cyber technologies. Cornerstone’s Intelligence Sector provides solutions to the United States Government for information collection, operations, exploitation and dissemination, and research activities. Our Team specializes in software development, cloud architecture, systems and network engineering, systems integration, agile management, as well as targeting operations and intelligence analysis. Our support to our mission customers includes cyber network operations, exploitation and defense, signals intelligence, human intelligence, and critical missions and networks. We are looking for team-members with creative talent who are ready to take on the challenge of Data Engineer to work with collaborative teams to help expand and optimize the data ingestion pipeline architecture, develop strategies for efficient ingestion, processing, storage, structuring, and access. In addition, the Data Engineer will support data analysts, data scientists, and big data engineers in identifying data sources, performing exploratory data analysis, developing data models, ensuring data cleanliness and accuracy to provide new Insider Threat behavioral insights. Roles and responsibilities potentially include: Support data science team by designing, developing and implementing scalable ETL process for disparate datasets into a Hadoop infrastructure Design, develop, implement, and maintain data ingestion process from various disparate datasets using StreamSets (experience with StreamSets not mandatory) Develop processes to identify data drift and malformed records Develop technical documentation and standard operating procedures Leads technical tasks for small teams or projects Required Experience and Qualifications: Requires a Bachelor’s degree in Systems Engineering, or a related Science, Engineering or Mathematics field. 5+ years of job-related experience, or a Master's degree plus 3 years of job-related experience. Desired Experience and Qualifications: Working knowledge of entity resolution systems Experience with Hadoop and Hive/Impala Experience with messages systems like Kafka Experience with NoSQL and/or graph databases like MongoDB or ArangoDB Any of the following databases: SQL, MongoDB, Oracle, Postgres Working experience with ETL processing and Python Working experience with data workflow products like StreamSets or NiFi Working experience with Python RESTful API services, JDBC Experience with Cloudera Data Science Workbench is a plus Understanding of pySpark Leadership experience Creative thinker Ability to multi-task Excellent use and understanding of data engineering concepts, principles, and theories Data Engineer Clearance: TS/SCI with CI Poly Chantilly, VA We are looking for team-members with creative talent who are ready to take on the challenge of Data Engineer to work with collaborative teams to help expand and optimize the data ingestion pipeline architecture, develop strategies for efficient ingestion, processing, storage, structuring, and access. In addition, the Data Engineer will support data analysts, data scientists, and big data engineers in identifying data sources, performing exploratory data analysis, developing data models, ensuring data cleanliness and accuracy to provide new Insider Threat behavioral insights. Roles and responsibilities potentially include: Support data science team by designing, developing and implementing scalable ETL process for disparate datasets into a Hadoop infrastructure Design, develop, implement, and maintain data ingestion process from various disparate datasets using StreamSets (experience with StreamSets not mandatory) Develop processes to identify data drift and malformed records Develop technical documentation and standard operating procedures Leads technical tasks for small teams or projects Required Experience and Qualifications: Requires a Bachelor’s degree in Systems Engineering, or a related Science, Engineering or Mathematics field. 5+ years of job-related experience, or a Master's degree plus 3 years of job-related experience. Desired Experience and Qualifications: Working knowledge of entity resolution systems Experience with Hadoop and Hive/Impala Experience with messages systems like Kafka Experience with NoSQL and/or graph databases like MongoDB or ArangoDB Any of the following databases: SQL, MongoDB, Oracle, Postgres Working experience with ETL processing and Python Working experience with data workflow products like StreamSets or NiFi Working experience with Python RESTful API services, JDBC Experience with Cloudera Data Science Workbench is a plus Understanding of pySpark Leadership experience Creative thinker Ability to multi-task Excellent use and understanding of data engineering concepts, principles, and theories"
Associate Data Visualization Engineer,Cato Institute,Remote,https://www.indeed.com/company/Cato-Institute/jobs/Associate-Data-Visualization-Engineer-cf6ba215a2a4384d?fccid=d1e2d1178f64beb3&vjs=3,"Description: As an Associate Data Visualization Engineer, you will join our Digital Team and use your analytical skills to scrutinize and visualize diverse datasets. You will investigate datasets for findings, and more importantly create compelling and informative data visualizations. You will help the organization discover new data opportunities with diverse internal and external datasets, in diverse functions from donor outreach to policy analyses.In addition to your immediate colleagues on the digital team, you will work with a diverse group of policy research scholars, and various other teams in the production workflow such as publications and social media teams.You will clean, organize, and analyze datasets and use your programming skills to visualize data for external publications, web content, and social media content of the Cato Institute. Finally, you will learn and apply cutting edge methods in data visualizations for the web.Company Overview: The Cato Institute is a public policy research organization – a think tank – dedicated to the principles of individual liberty, limited government, free markets, and peace. Its scholars and analysts conduct independent, nonpartisan research on a wide range of policy issues.Founded in 1977, Cato owes its name to Cato’s Letters, a series of essays published in 18th-century England that presented a vision of a society free from excessive government power. Those essays inspired the architects of the American Revolution. And the simple, timeless principles of that revolution – individual liberty, limited government, and free markets – turn out to be even more powerful in today’s world of global markets and unprecedented access to information than Jefferson or Madison could have imagined. Social and economic freedom is not just the best policy for a free people, it is the indispensable framework for the future.Cato Institute is an Equal Opportunity Employer.Responsibilities Find, organize, and analyze policy data in diverse research areas, including economics, education, healthcare, and immigration. Come up with ways to visualize data: design data charts, graphs and maps to convey findings. Collaborate with fellow web programmers; web, UX and graphic designers. Collaborate with policy research scholars, publication, and social media teams. Create primarily web-based data visualization tools and dashboards. . Requirements: Experience in data analysis. Fluency in programming (in one of the major programming languages like Python, R, C++). Hands-on knowledge of Microsoft Excel/Google Sheets. Experience in data visualization with diverse charts and maps. Demonstrated enthusiasm to learn and collaborate. Preferred Qualifications Bachelor’s degree or equivalent in computer science, economics, statistics, data science, mathematics, or other fields that require strong quantitative skills. Fluency in Python. Fluency in web programming (HTML, CSS, JavaScript). Strong familiarity / fluency in diverse data formats (CSV, XML, JSON) and SQL. Familiarity / experience working with a CMS (such as Drupal or WordPress). Familiarity / experience with data-dashboarding platforms, BI tools (such as Tableau, Qlik, PowerBI, Plotly etc.). Familiarity / experience with version control software (Git). Experience with data visualization libraries designed for the web (such as D3). Familiarity with, and an appreciation for, libertarian principles. Keen attention to detail. Education and Prior Experience No prior work experience required. Job Type: Full-time"
Scientific Data Engineer,Merck,"Boston, MA+1 location",https://www.indeed.com/rc/clk?jk=309030ee2a339573&fccid=c38b7d5e0419a6a7&vjs=3,"Job Description Our IT team operates as a business partner proposing ideas and innovative solutions that enable new organizational capabilities. We partner internationally to deliver the services and solutions that help everyone to be more productive and enable innovation. The Scientific Data Engineer is accountable for the design and development of software products in the Modeling and Simulation (M&S) Products Group of the Scientific Data Consumption Product Line. The M&S Products consist of the Modeling Platform, the Machine Learning Platform, and “experience” products delivering broad scientific modeling and machine learning capabilities. Tasks include gathering and reviewing technical requirements, design and development of code, and working with vendor partners to deliver products serving multiple business groups. This technical role requires knowledge and experience in both computer science and life sciences research to delivering solutions supporting pharmaceutical research. A thorough comprehension of data consumption approaches and platforms across a broad range of research activities is essential. The position will require a high level of familiarity and comfort working with the research organization. The Scientific Data Consumption Product Line (SDC) provides a combination of technology, infrastructure, software and personnel to support large scale scientific data consumption and computing comprising of the Scientific Data Platform, Modeling and Machine Learning Platforms, High Performance Computing (HPC) workflows, and “experience” products such as visualization, modeling workbenches, and analytics development environments. Primary job tasks include: Work with the Scientific Data Consumption Product Leads, Technical and Squad Leads to drive Business value through development and delivery of data and modeling software products Work with scientists to design scientific data and modeling products and integrations with commercial platforms such Databricks or Sagemaker We are seeking professionals with the following qualifications, skills and experience: Education Minimum: B.Sc. in computer sciences, engineering, or scientific disciplines Qualifications: Technical Skills: Expertise in developing, debugging and tuning software application built on traditional stacks (Java, Spring, Tomcat, etc.) and Cloud services in particular Amazon Web Services Experience in Database products (SQL Server, Oracle, Redshift) Expertise in building complex, highly available and scalable enterprise web applications Experience with Web Services and RESTful APIs Proficiency in LINUX operating systems Ability to architect, engineer, optimize and maintain software solutions to solve complex scientific problems Demonstrated ability to clearly convey technical and non-technical information verbally and in writing Demonstrated ability to work with a diverse group of professionals globally Required Experience: 3+ years in developing enterprise grade applications 2+ years in information technology support of the life sciences/pharmaceutical or other high technology industry Hands-on experience with cloud platforms (in particular AWS) Preferred: Knowledge of Machine Learning platforms and approaches (e.g. Databricks or Sagemaker) Thorough comprehension of technologies in support of data science Has used data driven methods to analyze and solve business problems Has worked with Agile methodologies and principles to drive development work Ability to present demos to users UI development experience with HTML, AJAX, Javascript/JQuery and similar technologies Knowledge of development on High Performance Computing systems Mindset Passionate in driving continuous improvement to improve delivery efficiency and practices Drive to deliver reusable and configurable solutions to enable the product line vision Keen interest in cloud and evolving technologies to help design, architect and build better solutions for our Company Passionate about modern data management, consumption and modelling capabilities and products Our Support Functions deliver services and make recommendations about ways to enhance our workplace and the culture of our organization. Our Support Functions include HR, Finance, Information Technology, Legal, Procurement, Administration, Facilities and Security. Who we are … We are known as Merck & Co., Inc., Rahway, New Jersey, USA in the United States and Canada and MSD everywhere else. For more than a century, we have been inventing for life, bringing forward medicines and vaccines for many of the world's most challenging diseases. Today, our company continues to be at the forefront of research to deliver innovative health solutions and advance the prevention and treatment of diseases that threaten people and animals around the world. What we look for … Imagine getting up in the morning for a job as important as helping to save and improve lives around the world. Here, you have that opportunity. You can put your empathy, creativity, digital mastery, or scientific genius to work in collaboration with a diverse group of colleagues who pursue and bring hope to countless people who are battling some of the most challenging diseases of our time. Our team is constantly evolving, so if you are among the intellectually curious, join us—and start making your impact today. NOTICE FOR INTERNAL APPLICANTS In accordance with Managers' Policy - Job Posting and Employee Placement, all employees subject to this policy are required to have a minimum of twelve (12) months of service in current position prior to applying for open positions. If you have been offered a separation benefits package, but have not yet reached your separation date and are offered a position within the salary and geographical parameters as set forth in the Summary Plan Description (SPD) of your separation package, then you are no longer eligible for your separation benefits package. To discuss in more detail, please contact your HRBP or Talent Acquisition Advisor. MRLITPM New hires in office-based roles in the US & Puerto Rico will be required, subject to applicable law, to demonstrate that they have been fully vaccinated for COVID-19 or qualify for a medical or religious exemption to this vaccination requirement that can be accommodated without an undue burden to the operation. However, subject to applicable law, employees working in roles that the Company determines require routine collaboration with external stakeholders, such as employees in health services, customer facing commercial, or research based roles, will be required to be fully vaccinated as a condition of employment. US and Puerto Rico Residents Only: Our company is committed to inclusion, ensuring that candidates can engage in a hiring process that exhibits their true capabilities. Please click here if you need an accommodation during the application or hiring process. Pay Transparency Nondiscrimination We are proud to be a company that embraces the value of bringing diverse, talented, and committed people together. The fastest way to breakthrough innovation is when diverse ideas come together in an inclusive environment. We encourage our colleagues to respectfully challenge one another’s thinking and approach problems collectively. We are an equal opportunity employer, committed to fostering an inclusive and diverse workplace. Search Firm Representatives Please Read Carefully Merck & Co., Inc., Rahway, NJ, USA, also known as Merck Sharp & Dohme LLC, Rahway, NJ, USA, does not accept unsolicited assistance from search firms for employment opportunities. All CVs / resumes submitted by search firms to any employee at our company without a valid written search agreement in place for this position will be deemed the sole property of our company. No fee will be paid in the event a candidate is hired by our company as a result of an agency referral where no pre-existing agreement is in place. Where agency agreements are in place, introductions are position specific. Please, no phone calls or emails. Employee Status: Regular Relocation: No relocation VISA Sponsorship: No Travel Requirements: 10% Flexible Work Arrangements: Shift: Valid Driving License: Hazardous Material(s): Number of Openings: 1 Requisition ID:R186511"
QA Engineer (Manual & Automation) - Data Feeds Testing/ETL,Haven Technologies,"Hybrid remote in New York, NY 10010",https://www.indeed.com/rc/clk?jk=2637e0840d37bfc5&fccid=3e5e72b4d1c6b869&vjs=3,"Haven Technologies has built deep capabilities in the life, annuity and disability insurance spaces. And now, our tech is your tech. The same purpose-built platform and expertise that have helped us delight customers, transform complex, advisor-driven businesses, and launch groundbreaking products with speed are available to everyone as a SaaS offering. Insurance carriers can use our advanced solutions for new business, in-force management and product development. But Haven Technologies is not just, well, all about technology. Our people and culture make our product. We believe magic happens when people have an opportunity to work with amazing colleagues and build things that matter. As a team made of over 300+ dreamers, possibility-seekers and difference-makers, we are focused on taking on challenging problems to create simple, more accessible, and more customer centric solutions. We're located in New York's Flatiron District and in case you're wondering, yes, we provide free snacks. Cold brew too. If you're creative, professional and kind, we'd love to hear from you. Curious about what it's like to work with us? Read about our culture and values here! Let's change the future of life insurance. Together. ABOUT THE ROLE You will be responsible for managing and executing the testing of our advanced insurance applications and platform. You will need to learn and understand our products at a detailed level and work with the team (primarily made up of developers, product managers, and other QA engineers) to ship high-quality products or features every two weeks. This role entails a mix of manual and automation work. We expect the automation component to grow over time, especially as driven by the person in this role once they understand the unique needs of the data team. Coding tests and automation questions are a part of the selection process for this role. Also, a Computer Science or related degree is strongly preferred. What you will do: Work with product owners and the developers to understand the requirements around data feeds and the required data mapping. As a part of feature testing, generate large feeds and review every data element to ensure compliance with the requirements. Perform regression testing to ensure that unintentional changes are not breaking data feeds. Contribute towards building and maintaining the automated regression testing suite Some of your testing responsibilities will include: Be accountable for highly complex products as the primary QA for the data team Lead or perform software test projects and tasks Review epics and stories, define the right test plan and criteria for them, and provide effort estimates Establish clear expectations of scope and timing of all testing deliverables with the team Define, execute, and document manual tests, test data, and test results with necessary detail Communicate test results to the team and help prioritize and resolve any issues Analyze and debug production defects and work with the team to prioritize and resolve them Deploy and troubleshoot local, sandbox, and/or CI/CD environments to enable testing Identify ways to make the testing process and surrounding processes more efficient and effective over time Document knowledge that will be useful for new team members looking to test your product and its dependencies Some of your automation responsibilities will include: Document and prioritize test cases for automation Automate some test cases and add them to the existing automation framework Run automated test cases during sprint testing, UAT testing, etc. Run and analyze reports for automated test results REQUIREMENTS These skills are essential for success in this position: Minimum 5 years of QA experience on web applications in multi-application production environments. Experience with multiple types of testing, for example, regression testing, ad hoc testing, feature testing, user acceptance testing, user interface testing, integration testing, performance testing, security testing, etc. Experience in creating, running and maintaining automated tests. Good knowledge of TypeScript. Hands-on experience working with Docker and setting up Docker dependencies between various applications. Good knowledge and hands-on experience of SQL and Excel/Google Sheets. Excellent communication skills, both oral and written. Strong problem solving and root cause analysis skills, including debugging and log analysis Authorized to work in the US without sponsorship now or in the future These skills are a plus: Bachelor's degree or equivalent work experience. Computer Science or related degree strongly preferred. Ability and willingness to look into code bases outside one's direct responsibility to identify potential failure points. Extensive experience with the Agile methodology and frequent releases. Experience in multi-platform testing (desktop, tablet, mobile) and multi-browser testing. Experience with quality assurance metrics and reporting. Intermediate coding skills. Ability to set up and troubleshoot local and sandbox environments. BENEFITS We have a stellar team of co-workers, a really cool office, a flexible hybrid work schedule, and lots of fun activities. Oh yeah, and we pay competitive base salaries and we reward performance. Our salary structure is commensurate with experience. In addition, you will be eligible to participate in our comprehensive benefits program including medical insurance and 401(K). We believe that one of the benefits to working here is our people and culture! We're proud to share that we've been consistently named a top workplace by Great Places to Work (#11 Best Workplaces in New York, #15 Best Workplaces in Financial Services and Insurance) and BuiltIn (Top 10 Best Midsize Company to Work For in NYC)! As part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. These requirements may include sharing information in our vaccine record tool, vaccination or regular testing, mask-wearing, social distancing, and daily health checks. Requirements may change in the future with evolving public health landscape. Haven Technologies will consider all legally required exemptions and accommodation requests."
Big Data Engineer,Cotocus,"Sacramento, CA 95822 (Airport area)+2 locations",https://www.indeed.com/rc/clk?jk=bfa59c5316baa518&fccid=67014df0f8d8ef3d&vjs=3,"Job Description We are looking for an experienced and passionate Data Engineer with 6+ years of experience in building scalable, high-performance distributed systems that deal with large data volumes. You will be responsible for development work on all aspects of Big Data, data provisioning, modeling, performance tuning and optimization. Responsibilities: Work closely with business and dev teams to translate the business/functional requirements into technical specifications that drive Big Data solutions to meet functional requirements. Participate in software design meetings and write technical design documents. Design, develop, implement and tune large-scale distributed systems and pipelines that process large volumes of data; focusing on scalability, low -latency, and fault-tolerance in every system built. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Maintain application stability and data integrity by monitoring key metrics and improving code base accordingly. Understand & maintain existing codebase by regular re-factoring and applying requested fixes and features. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Should be flexible to learn new technology / required frameworks. To apply for this position, please upload your resume at : DevOpsSchool.com/Cv We prefer to select professionals those who are Certified in their domain from ""Official Certification company's"" like RedHat, Chef Software Inc, Puppet, Docker, Google, Amazon Inc. etc. or authorized training partners like scmGalaxy Inc. DevOpsCertification.co etc."
Healthcare Data Analyst/Data Engineer,Milliman,"Minneapolis, MN 55438",https://www.indeed.com/rc/clk?jk=a0f7f996069c54f0&fccid=3d93143c99ff89a3&vjs=3,"Job Details Description Company Overview: Leading with our core values of Quality, Integrity, and Opportunity, MedInsight is one of the healthcare industry’s most trusted solutions for healthcare intelligence. Our company purpose is to empower easy, data-driven decision-making on important healthcare questions. Through our products, education, and services, MedInsight is making an impact on healthcare by helping to drive better outcomes for patients while reducing waste. Over 300 leading healthcare organizations have come to rely on MedInsight analytic solutions for healthcare cost and care management. MedInsight is a subsidiary of Milliman; a global, employee-owned consultancy providing actuarial consulting, retirement funding and healthcare financing, enterprise risk management and regulatory compliance, data analytics and business transformation as well as a range of other consulting and technology solutions. Position Summary: The Healthcare Data Analyst/Data Engineer will join a team that thrives on leveraging data, analytics, and technology to deliver meaningful business value. This is a team with technical aptitude and analytical prowess that enjoys building efficient and scalable products and processes. Ultimately, we are passionate about effecting change in healthcare. We also believe that collaboration and communication are cornerstones of success. The Healthcare Data Analyst/Data Engineer will join a mix of Engineers, Analysts, Managers, Consultants, and Principals. We aim to provide everyone with a supportive environment, where we foster learning and growth through rewarding challenges. Milliman's MedInsight group is looking for a driven, entrepreneurial, and self-learning data engineer to join their team. The data engineer position at Milliman offers many different opportunities to develop both professional and technical skills while receiving experience and training to become data and analytics professional. The opportunity allows each employee to take on responsibility for client work while making meaningful contributions to projects and the firm. Our data engineers are independent problem-solvers who care about the quality of the work that is delivered to clients and to each other. They take personal responsibility for their work and are motivated to succeed in their own careers, as well as to help the firm succeed. What Will You Do? Analyze and interpret our client’s source data Scrub, clean and validate data Transform data into common data models Analyze data, summarize and share findings with project managers and internal consultants. Write and review SQL for ad hoc analyses and production client processes Develop SQL based ETL processes to meet client business requirements Review peers’ work product to validate quality results What Do We Look For? Bachelor’s degree in Computer Science, Mathematics, Management Information Systems, Computer Engineering, related field, or equivalent work experience 2 or more years of experience writing SQL Able to interpret, scrub, process, and explain data Familiarity with relational databases and data warehousing concepts Sharp critical thinking skills, sound judgment, and decision-making ability, and both the ability and willingness to clearly articulate your ideas Strong communication skills and experience working with a team The ability to work both collaboratively and independently Proven ability to work in a fast-paced environment where the client is always first Applies training and knowledge to perform job duties Learns and can use enterprise tools and processes to perform work Enhances knowledge through learning and challenging project assignments Applies enterprise quality risk management guidelines into work Additional competencies: Attention to Detail Time Management Diversity, Equity and Inclusion (respectful, collaborative behavior) Completion of Milliman ARM Workshop (upon hire) It’s great if you have: Undergraduate GPA of 3.0 or above Healthcare claim data experience, eligibility data and healthcare industry knowledge 1 or more years – Azure Databricks Exposure to reporting tools such as Microsoft Reporting Services, Power BI, Tableau What Makes this a Great Opportunity? Join an innovative, high growth company with a solid industry track record. Bring your expertise and ideas to help build the next generation of MedInsight products. Enjoy significant visibility in your work and be recognized for your wins. Work for a company that values your wellbeing and professional growth offering a flexible work environment, generous benefits package, and investment in your career development. Benefits: Medical & Dental Vision Group Term Life Insurance Supplemental Life Insurance (Including Spouse/Domestic Partner & Dependent) AD&D Short & Long-Term Disability Paid Parental Leave FSA (Health Care Flexible Spending Account or Dependent Care Flexible Spending Account) Adoption Benefit Identity Theft Protection Retirement Program: 401(k) Paid Time Off (PTO) Access to free training through Milliman’s L&D department Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Engineer II,Memorial Sloan Kettering Cancer Center,"New York, NY 10017 (Turtle Bay area)",https://www.indeed.com/rc/clk?jk=9e905c338e50e866&fccid=1320c50b75f44505&vjs=3,"Company Overview: At Memorial Sloan Kettering (MSK), we’re not only changing the way we treat cancer, but also the way the world thinks about it. By working together and pushing forward with innovation and discovery, we’re driving excellence and improving outcomes. We’re treating cancer, one patient at a time. Join us and make a difference every day. In compliance with applicable New York and New Jersey State regulatory authorities, COVID-19 vaccination (2 doses of either the Pfizer or Moderna vaccine or one dose of the Johnson & Johnson vaccine) is mandatory for all MSK employees, contingent workers, and volunteers. Exceptions are permitted for those employees who request and receive an approved medical or fully remote exemption. Staff working at a MSK New Jersey location must be up to date with COVID-19 vaccination, which includes having completed the primary COVID-19 vaccination series and booster once eligible as mandated by New Jersey State. All New Jersey staff not yet eligible for a booster must receive a booster within 3 weeks of becoming eligible as a condition of continued employment at MSK. Note: Individuals are eligible to receive a COVID-19 booster five months after receiving the second dose of either the Pfizer or Moderna vaccine or two months after the J&J vaccine. Job Description: Are you passionate about technology? Do you want to play a key role in redefining the future of cancer care? We Are: We are seeking a Data Engineer II to join MSK’s Digital Pathology team as we meet the challenge of converting pathology from an analog to a digital practice. You will create pipelines to consolidate and deliver vital data that will drive research and analytics focused on improving patient care. You are a highly skilled data engineer who is comfortable working with large volumes of data. You can design and develop complex solutions using modern practices and technologies. You are an eager, self-starting learner who can quickly pick up new technologies. You Will: Engineer infrastructure and tools to deliver critical data to downstream systems and industry partners Design and build backend integrations using various technologies and taking a creative approach when working with legacy systems. Engineer features of the data platform that will help ensure quality and robustness. Collaborate in an agile team with Product Owners, Scrum Masters, System Architects, other Development Teams and Users. Participate in full SAFe and Agile development life cycle including analysis, design, built and release of data pipelines. You Are: Proficient in relational database schema and query design Proficient in using scripting languages such as Python, bash, and R Proficient with industry standard tools for ETL design and administration (i.e. Data Stage) Familiar with linux environments and server administration Experience using Docker, Kubernetes or similar container technologies and setting up CI/CD pipelines is a plus. Experience designing RESTful APIs is a plus. Experience and familiarity with Cloud providers (AWS, Azure) is a plus. Benefits Competitive compensation packages | Sick Time |Generous Vacation+ 12 holidays to recharge & refuel| Internal Career Mobility & Performance Consulting | Medical, Dental, Vision, FSA & Dependent Care|403b Retirement Savings Plan Match|Tuition Reimbursement |Parental Leave & Adoption Assistance |Commuter Spending Account |Fitness Discounts &Wellness Program | Resource Networks| Life Insurance & Disability | Remote Flexibility We believe in communication, openness, and thinking beyond your 8-hour day @ MSK. It’s important to us that you have a sense of impact, community, and work/life balance to be and feel your best. #LI-Remote Closing: MSK is an equal opportunity and affirmative action employer committed to diversity and inclusion in all aspects of recruiting and employment. All qualified individuals are encouraged to apply and will receive consideration without regard to race, color, gender, gender identity or expression, sexual orientation, national origin, age, religion, creed, disability, veteran status or any other factor which cannot lawfully be used as a basis for an employment decision. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment."
Sr. Data Quality Engineer,CentralReach,United States,https://www.indeed.com/rc/clk?jk=853383e5231b48dd&fccid=97a24bbcb574323f&vjs=3,"CentralReach is the #1 provider of SaaS software solutions for autism care. Trusted by more than 115,000 users, we enable therapy providers, educators, and employers to scale the way they deliver Applied Behavior Analysis therapy with innovative technology, market-leading industry expertise, and world-class customer satisfaction. Reporting to the Director of Quality Assurance, you will be responsible for formulating a robust and comprehensive set of test plans, along with SQL and automated scripts that will be used to test various data stores in the CentralReach Enterprise system. You will interface with members of the Product, Engineering and QA team to validate backend system changes as well verify data for correctness. You will collaborate closely with all members of the Quality Assurance team to produce a test strategy for creating and executing test plans that provide the most comprehensive set of test coverage. The Sr. Data Quality Engineer will have the opportunity to make highly significant and positive impacts on one of the company’s most important initiatives to achieve high scalability of our systems coupled with high quality. If you have a passion for software quality, enjoy working with data, and are a self-starter that wants to own and implement testing strategies to maximize efficiency of Quality Assurance, this is a great opportunity and we’d love to hear from you. Key Accountabilities: Responsible for the certification of all database changes impacting system functionality and performance that follow QA standards and process for achieving the highest level of quality Enhance the test case library to increase test coverage around database and related system domains Create test cases for verification and validation of all backend data stores, ETLs, data warehouse and data mart as well as those backend services supporting our web and mobile applications Develop complex SQL queries for testing of the database, keeping pace with the Agile team and reporting and finding bugs/defects Analyze, identify and map the relation of backend systems to application areas and fully document for knowledge sharing with the QA team Promote and encourage collaboration and quality related activities with the Product and Engineering teams Ensure quality releases of software with no production downs and/or critical impediments to users Desired Skills and Experience: Responsible for the certification of all database changes impacting system functionality and performance that follow QA standards and process for achieving the highest level of quality Enhance the test case library to increase test coverage around database and related system domains Create test cases for verification and validation of all backend data stores, ETLs, data warehouse and data mart as well as those backend services supporting our web and mobile applications Develop complex SQL queries for testing of the database, keeping pace with the Agile team and reporting and finding bugs/defects Analyze, identify and map the relation of backend systems to application areas and fully document for knowledge sharing with the QA team Promote and encourage collaboration and quality related activities with the Product and Engineering teams Ensure quality releases of software with no production downs and/or critical impediments to users #LI-Remote #LI-JM1 CentralReach was developed for Clinicians by Clinicians. The story of CentralReach begins in 2012 when the company’s founder, a practicing Board Certified Behavioral Analyst, decided there had to be a better way to manage her operations so she could spend more time on what mattered most — working with her clients and patients. To help ABA practices focus on what they do best, CentralReach launched the first iteration of its EMR and practice management platform. Today, under the leadership of Chris Sullens, an award-winning CEO in the technology space, CentralReach is committed to their mission of providing cutting-edge technology and services to help clinicians and educators produce superior client and patient outcomes. Already a market leader, CentralReach is expected to grow exponentially through its four core tenets: hire and develop great people; build industry-leading products; provide exceptional service to customers and continuously invest in systems, processes and infrastructure. We value our employees and offer a robust benefits package including health and dental, paid time off, life insurance, disability coverage and a 401(k) matching. We also provide comprehensive onboarding, ongoing training, mentoring and career pathing to help you develop your career. We pride ourselves on our fun and energetic environment that also provides our employees with a meaningful way to make a difference by helping clinicians produce superior outcomes for children and adults with disabilities."
Big Data Engineer,e-Zest Solutions,Texas,https://www.indeed.com/rc/clk?jk=e7fa2c221092c863&fccid=2381912c1388a84a&vjs=3,"Big Data Hadoop Scala Python We are looking for a passionate, highly motivated, flexible, organized, and detail oriented Big Data Developer to join our dynamic team. Responsibilities We are seeking an Executive Advisor, Big Data Engineer to help us build an enterprise strategy around big data and data lake implementation and roll-out across business units. As an Executive Advisor, you will contribute by leading a portfolio of innovative projects that provide differentiated value for a number of business units. One of the key focus areas for data lake strategy is to work with IT to define the data lake architecture and tool sets required to support the different analytic use cases including Data Engineering, BI, and Data Science by bringing in your deep experience, and analyzing tools and technologies available in the market place including on premise, Cloud or Hybrid model. You will define the user adaption strategy and plan and drive the business user adaption of data lake platforms. You will define the best practices around data lake platform for analytical users. You will also define the migration strategy to migrate the analytical applications from the traditional warehouse platforms to Data Lake platforms and execute the strategy to migrate the analytical applications by working with business leaders/users, and IT leaders. You will bring your strong experience in building analytical tools to support analytic discovery projects and rapid prototyping across business cases with a view to reducing the manual effort requiring multiple analysts across business areas to create reports and insights across traditional data warehouse and data lake platforms. We will need you to apply your deep data analytics and technical experience to define common requirements across teams for metrics and KPIs, define data gaps and data road-map based on the business needs. Define project scope based on the road map and work with IT to implement the data solutions, and work with the business to deliver business intelligence tools/solutions that provide significant value to business teams. Provide oversight on managing and addressing operational data issues by establishing workarounds and/or bringing in cross functional teams to solve the issues in timely manner Requirements To qualify for this role, candidates will need to have a minimum of 5 years of significant experience in delivering analytics/reporting solutions including experience in Big data and data lake solutions, strong data management, data engineering specifically big data/Hadoop and traditional data warehousing experience. Experience in working with cross functional business team to understand the business needs to define and manage the data road map. Experience in leading and guiding matrix business and IT teams to co-ordinate rapid prototyping and data discovery, as well as business support for traditional data warehouse and data lake development processes. Ability to meet tight deadlines without compromising on quality of deliverables. Experience with traditional warehouse technologies like Teradata, SQL, BTEQ, BI Tools and Big data technologies Hadoop, Spark, Hive, Hive LLAP, Scala, R, Python, big data on Cloud, and others. Strong verbal and written communication skills. Solid organizational skills with focus on accuracy and attention to detail."
Data Engineer,"HTC Global Services, Inc.","Charlotte, NC 28216 (Mountain Island area)+6 locations",https://www.indeed.com/rc/clk?jk=7a537d48dfd83c9c&fccid=41cf219fb91d61d8&vjs=3,"At HTC Global Services our consultants have access to a comprehensive benefits package. Benefits can include Paid-Time-Off, Paid Holidays, 401K matching, Life and Accidental Death Insurance, Short & Long Term Disability Insurance, and a variety of other perks. Strategizing and planning AI/ML efforts/projects JD Data Ingesting/Training Data pipeline. Labeling Model Dataset. Identifying data distributions. Validating Data Quality. Strong SQL and phython Skills on data Handling. Find a purpose Help clients embrace emerging technologies. Create inventive solutions and meet intriguing client challenges. Solve, fix, design and innovate. Be a part of something bigger by helping clients go digital, create engaging customer experiences and transform their business. Move ahead Our success as a company is built on practicing inclusion and embracing diversity. HTC Global Services is committed to providing a work environment free from discrimination and harassment, where all employees are treated with respect and dignity. Together we work to create and maintain an environment where everyone feels valued, included, and respected. At HTC Global Services, our differences are embraced and celebrated. HTC is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce. HTC is proud to be recognized as a National Minority Supplier. About HTC Global Services Shaping careers since 1990 - our long tenured employees are a testimony of the work culture. Join our global employee base of 12,000 and help us bring human expertise to tech in order to deliver purposeful solutions that amplify value."
Data Engineer,Jam City,"San Francisco, CA",https://www.indeed.com/rc/clk?jk=28e0c196095484b2&fccid=92938f0e989918d3&vjs=3,"As a leading mobile games developer, Jam City is looking to “level up” our talent. We’re on the hunt for innovators who consider themselves dynamic, collaborative and thrive in a fast-paced environment. PERKS & BENEFITS Unlimited Vacation, Paid Sick Days, Kin Care & Holidays* 100% Covered Medical and Company-Sponsored Dental & Vision ( Plans Vary)* Life Insurance, 401k, Flexible Spending Accounts, Commuter Benefits & More* Wellness Activities & Programs (Yoga & Zumba) 12 Weeks Paid Parental Leave* Happy Hours Company Events Dog-Friendly* Only applies to full-time positions. The Data Platform team is small, but is the powerhouse of the company and the role that our team plays is truly unique. We are currently searching for a talented Platform Engineer to join this team! In this role, you will have the opportunity to work alongside a small team of talented individuals using cutting-edge technologies to build top-notch data pipelines, machine learning, and analytics tools. We have a data lake that contains trillions of events and multiple petabytes of data. Every day, we strive to break the mold, helping to create better experiences for our players. RESPONSIBILITIES Expanding, maintaining, and improving Jam City’s expansive data platform. Adding to our MLOps capabilities. Executing data pipeline deployments both internally and with external vendors and partners. Building and deploying technical back-end solutions that consider data scientists and analysts who rely on the product. Supporting operations of existing data platform services. QUALIFICATIONS 3+ years of experience on data intensive systems. Desire to use, or quickly acquire, requisite technologies: Data ingestion and transformation using Apache Spark and Kafka (scala/python/SQL). Machine learning model operations using MLflow. Building data microservices using Apache Cassandra. Comfortable using AWS cloud services (s3, ec2, rds, sqs, sms). Ability to operate independently in creating new capabilities and serving the internal customers who use the data platform. NICE TO HAVE Databricks, Visualization (tableau), Kubernetes CHECK OUT LIFE AS A JAM CITIZEN: Company news and events on our LinkedIn Company Blog Employee Feedback on our Comparably page Find videos on our teams and games on our Youtube OUR COMMITMENT TO EQUITY, DIVERSITY, & INCLUSION We believe in creating games that unite people across the world and that showcase our commitment to providing an environment that is both inclusive and diverse for our players and employees. We strive to create a workforce that is reflective of our global player community as we know that we are stronger and better when we play together. To help promote an inclusive culture, we celebrate the visible and invisible diversity of our Jam Citizens through initiatives including Employee Resource Groups, cultural events, trainings, speaker series, and more. Jam City is an equal opportunity employer. We enthusiastically accept our responsibility to make employment decisions without regard to race, age, sex (including pregnancy), national origin, ancestry, religion, ethnicity, marital, or domestic partnerships status, disability, genetic information (including the refusal to submit to genetic testing), predisposing genetic characteristics, military status, veteran status, domestic violence victim status, sexual orientation, gender identity or expressions, or any other classification protected by federal, state, and local laws. Our management is committed to following this policy with respect to hiring, placement, promotion, transfer, demotion, layoff, termination, recruiting, pay, and other forms of compensation, training, and general treatment during employment. ABOUT JAM CITY Jam City is an award-winning mobile entertainment studio providing unique and deeply engaging games that appeal to a broad, global audience. Led by CEO Chris DeWolfe, former MySpace co-founder and CEO, and COO Josh Yguado, former 20th Century Fox executive, Jam City is the creative powerhouse behind some of the highest-grossing and most enduring mobile games. Jam City’s global franchise Cookie Jam has generated more than half a billion dollars, and Panda Pop has more than 120 million downloads to date. The company also is the go-to studio for Hollywood, having developed immersive, narrative-rich mobile games around iconic entertainment brands. The company’s popular RPG game Harry Potter: Hogwarts Mystery was the #1 game in more than 40 countries at its launch in April 2018. Jam City has nine studios located in Los Angeles (HQ), Berlin, Buenos Aires, Bogotá, Burbank, Cedar Falls, San Diego, San Francisco, and Toronto."
Data Engineer,Offerpad,"Chandler, AZ 85286",https://www.indeed.com/rc/clk?jk=bed74049919bc67f&fccid=f0a1b6c72239b1ba&vjs=3,"Job Description: Position Summary The Data Engineer will lead and participate in the design, development, and maintenance of our Data Warehouse at Offerpad. Duties will include dimensional modeling, troubleshooting complex data problems, and delivering enterprise level solutions to business leaders. The Data Engineer will be responsible for the testing, maintenance, construction and development of architectures such as large-scale processing systems and databases. As part of this, they are also responsible for creating data set processes for verification, acquisition, mining, and modeling. This individual will collaborate with stakeholders across the organization to ensure clarity of all business requirements. Essential Functions Lead and participate in the design, development, and maintenance of our Data Warehouse. Including dimensional modeling, troubleshooting complex data problems, and delivering enterprise level solutions to business leaders. Evaluate TSQL Queries for performance improvements. Support Power BI Reports. ETL Data from multiple different sources including API's and Flat Files. Build large-scale batch and real-time data pipelines with data processing frameworks in Azure. Collaborate with stakeholders on business processes to ensure clarity of Business Requirements. Required Experience: Minimum Qualifications Bachelor's Degree or an equivalent combination of education and related work experience. 2+ Years of experience with Microsoft SQL Server. 2+ Years of experience with ETL Tools like SSIS 1+ Years of experience with cloud platforms, preferably Microsoft Azure 1+ Years of experience with Reporting Tools like Power BI. 2+ Years of experience with Dimensional Data Models and best practices. Understanding and Experience with performance tuning, query plans, blocking, dead locking and Indexing. Experience gathering requirements from stakeholders and transforming those into data driven BI solutions. You should be able to take a single project start to finish. Experience with Multiple Database Platforms and BI Delivery Solutions. You have a high EQ (emotional intelligence) and able to effectively work well with others, fostering a great, collaborative, and fun environment, even amidst technical challenges. Preferred Qualifications A Master's degree or higher in a quantitative field (e.g. science, engineering, economics, finance, statistics, or similar) and have 2 years of work experience involving quantitative data analysis and complex problem solving. Experience in Tabular Models and writing performant complex DAX Queries. Expertise in Microsoft Azure Data Solutions and Microsoft SQL Server. Previous real estate experience a plus Experience in Azure cost management and recommending cost optimization steps. Why Work with Offerpad? It’s simple: We’re here to help. We help people by providing the best way to buy and sell a home. Period. If you’re passionate about helping people, too, in an environment where every day matters, where you’ll thrive on innovation, collaboration and recognition for your inspiring ideas and be rewarded for your results, then welcome home to Offerpad! We're a fast-growing, fast-moving, compassionate customer-obsessed team of like-minded business disruptors who are continually challenging and changing the way traditional real estate works. We’re all about homes, not houses. Since 2015, we’ve grown from an entrepreneurial upstart in three markets to an industry-leading technology innovator with more than 500 happy humans working together to help customers in 900+ cities and towns across the country. As we continue to grow and expand, our goal remains the same: Make the process as seamless and stress-less as possible to help them move freely and enjoy the best customer experience available. While we work hard to serve our customers – we have a 95% customer satisfaction rating and 84 Net Promoter Score - we also work hard at taking care of one another. We’re family here, we work hard but we have a lot of fun. Our culture is one of inclusivity and support, one that values results, nourishes creativity and relishes - and rewards - each other’s success. If home is where your heart is and making people happy is your passion, we welcome you to join our team of intrepid innovators, technology gurus, real estate experts and all-around great people at Offerpad! Check our current job postings below to see everything we have to offer! Offerpad can offer you: Competitive compensation The opportunity to make a difference in a fast-growing, startup environment Strong, collaborative team culture Full benefits including medical, dental and vision coverage 401(k) matching program 40 paid volunteer hours annually Mileage reimbursement (where applicable for role) 11 paid holidays a year Flexible PTO From: Offerpad"
"Civil Engineer, Data Center Design",Facebook App,Remote,https://www.indeed.com/rc/clk?jk=10dec882dbb313e8&fccid=ba07516c418dda52&vjs=3,"Facebook is seeking a Civil Engineer to support the execution and development for our Site Infrastructure Engineering program within the Data Center Design team. In this role, you will provide oversight of the civil engineering and site development aspects for multiple data center campuses around the world. The ideal candidate will have strong leadership skills, a proven track record in proactive cross-functional and team leadership, a strong background in all aspects of site development as well as experience working on large industrial development projects within a global portfolio. A thorough understanding of interdependent disciplines, such as electrical and fiber, is strongly desired. This person shall be detail-oriented, possess strong organizational skills, and be a self-starter that can excel with little direction. Our data centers are the foundation upon which our software operates enabling innovation for the company. Building and operating data centers the ""right"" way from the day they go live is synonymous with ensuring capacity availability and capital conservatism. The data center design team approaches facility design from the chips on the server boards to the facility mechanical and electrical distribution systems which ensure and maximize efficiency of our compute infrastructure. This position is full-time. Civil Engineer, Data Center Design Responsibilities: Manages multiple phases of site development and civil engineering projects and related consultants, including infrastructure design, site layout, building interface coordination, Civil3D modeling, geotechnical studies, and stormwater management Manages documentation supporting the civil engineering and related disciplines Manages the development of data center civil engineering standard processes and templates Manages consultant scope, including authoring scope of work and developing proposals Supports projects through agency permitting Working knowledge of geotechnical engineering Develops and updates the design standards and specifications for consistency Provides engineering review services to data center operations teams Supports the implementation of data center engineering and commissioning for new data center concepts under development Travel (around 25%) to datacenter sites when needed for engineering studies, systems audits, testing, and commissioning Participate in system failure or related incident Root-Cause-Analysis (RCA) Respond on an as-needed basis to emergencies Minimum Qualifications: Bachelor’s Degree in Civil Engineering, or related field Professional Engineer registration, or European equivalent Experience creating technical playbooks, standards, and template documentation for use within a portfolio of facilities Experience in civil engineering globally Minimum of twelve (12) years professional experience supporting large industrial campus site and utility planning and construction Experience managing the production of site infrastructure documents including preliminary utility, grading, and drainage plans as well as roadway infrastructure Knowledge of Geophysics and Geotechnical engineering, including soil mechanics, grading, stormwater management, and erosion/sediment control engineering Knowledge of campus planning strategies and regulatory processes, entitlement, and permitting Knowledge of mission critical building systems, including mechanical, electrical, fire protection, structural, and architectural systems Knowledge of industry standards, building codes and safety standards including IBC, ASCE, and European equivalents Experience with trouble shooting and problem solving Experience providing solutions to complex projects under pressure Effective communications skills, fluent in English Working knowledge of AutoCAD Civil 3D, Infraworks, ArcGIS, MS office, StormCAD, Hydroflow, ICPR or other industry accepted software Preferred Qualifications: Knowledge of mission critical projects (e.g. data centers, aviation, industrials, etc.) Master’s Degree in Civil Engineering or related field LEED AP PMP Certification 8+ years experience supporting data center engineering and construction Experience in managing design consultants from the owner’ side Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
"Data Engineer, Zoro",Zoro Tools,Illinois+1 location,https://www.indeed.com/rc/clk?jk=298f3f4cbb005490&fccid=80bd79d813274903&vjs=3,"Company Summary: Zoro offers millions and millions of products — an endless aisle with everything you need to run your business. We offer fast and free shipping, no-hassle returns, and exceptional customer service. We’ve grown quickly in a short time and are continuing to do so while aggressively growing our revenue. We are excited to be a part of an award-winning culture — we have been named a Great Place to Work for multiple years in a row, among other local and national accolades. We think Zoro is a pretty amazing place to work and grow, and think you will too! Primary Function: As a Data Engineer at Zoro you will be involved in designing and building cloud native data pipelines on a scrum squad. You will be responsible for collaborating with stakeholders on work items to deliver tested, documented, and efficient data pipelines. Your day to day activities will include participating in: cadence meetings. technical debt working sessions. pairing sessions. master data management initiatives. data pipeline support. Duties and Responsibilities: Follow software craftsmanship and Zoro norms to design, develop, document, deploy, and maintain data pipelines. Collect, analyze, and profile various batch and streaming data sources. Participate in master data management efforts within the squad and tribe. Participate in guild and chapter meetings. Collaborate with stakeholders to groom ideas into small, independent, and testable work items. Collaborate with DataOps to automate code analysis, testing, building, and deploying. Collaborate with the squad and tribe to groom technical debt. Qualifications: Strong experience with RDBMS, No-SQL DBs, data modeling, and ETL/ELT processes. Strong experience with Python and SQL, with focus on data manipulation and analysis. Strong experience with building, deploying, and maintaining data pipelines. Strong experience with sourcing and profiling highly variable data. Strong experience in software craftsmanship, behavior-driven development (BDD), and unit testing. Strong people skills, must be able to form strong, meaningful, and lasting collaborative relationships. Moderate experience with collaborating on scrum squads with preference for experience with Large Scale Scrum (LeSS). Moderate experience with cloud infrastructure services with preference for experience with Google Cloud Platform (GCP). Moderate experience with MongoDB, BigQuery, Jira, Git, Kubernetes, Jenkins, Terraform, GCP Deployment Manager, Apache Airflow, Apache Beam, and Apache Spark. Bachelor's degree in Computer Science, Applied Mathematics, Engineering, or other technology related field. An equivalent of this educational requirement in working experience is also acceptable. Zoro Values and Inclusive Culture: We share a commitment to our Zoro values – Win & Lose Together (We prefer winning!), Take Ownership, We Are Transparent, and Aspire to be Customer-Obsessed. Everything we do at Zoro is centered around delighting our customers. It's a natural extension of our company culture and how we care for each other. We believe when we act in ways that are consistent with these values, we can solve any technical challenge that lies ahead of us. As a Zoro employee, you can expect to work with smart, energetic people, learn something every day, and be valued for your perspective. Zoro is dedicated to fostering an environment where people of all backgrounds and beliefs are represented, and all team members can be confident that their experiences and perspectives are valued. Zoro aims to empower all employees to learn about, raise awareness, and promote diversity and inclusion through all of our workplace interactions. Zoro is a place where everyone can learn, grow and thrive. We recognize the courage and effort it takes to apply for your next opportunity. We also recognize that there is rarely such a thing as a perfect candidate. Even if you do not meet every qualification, we still encourage you to apply - we do not want to miss out on meeting the next person who could emerge as a key contributor to our business and culture. Zoro is an Equal Opportunity Workplace and an Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status."
Data Engineer - Remote,PatientPoint,"Remote in Cincinnati, OH 45236+1 location",https://www.indeed.com/rc/clk?jk=cb0b4211105d8f84&fccid=3a2aae3e210f8d0e&vjs=3,"Position: Senior Data Engineer Location: Remote in Cincinnati, OH, Chicago, IL, New York City, NY, or Nashville, TN About PatientPoint PatientPoint® is the patient engagement platform more providers trust. Our innovative, tech-enabled solutions create more effective doctor-patient interactions and deliver high value for patients, providers and healthcare sponsors. Through our nearly 140k unique healthcare provider relationships, PatientPoint’s solutions impact roughly 750 million patient visits each year, further advancing our mission of making every doctor-patient engagement better®. Learn more at patientpoint.com. What We Offer We know you bring your whole self to work every day. That is why we are committed to providing modernized benefits and cultural perks to our teammates. We offer: competitive compensation, comprehensive and affordable benefits, flex time off to rest and charge, where applicable, a hybrid work model, mental & emotional wellness resources and coaching, 401K and more. Job Description The Data Engineer is responsible for developing architecture data models to support data visualization, business intelligence, and data science. As a data expert, the Data Warehouse Architect will gather requirements from business stakeholders and build and deploy advanced SQL queries. This position will work directly with business leaders, team members, and IT leadership to provide agile data delivery to support business decisions. Primary Duties: Translate business requirements into a star schema data model and validate results with business representatives Solve and model complex business requirements using SQL Collaborate on a team with infrastructure, BI report development, and business analyst resources, and clearly communicate solutions to both technical and non-technical team members Uses an understanding of Data Warehouse best practices, relational structures, dimensional data modeling, structured query language (SQL) skills, data warehouse, and reporting techniques to make decisions Design, develop, enhance and support data infrastructure including data lake and data warehouse structures primarily using Snowflake and Fivetran. Communicate with team members regarding projects, development, tools, and procedures Minimum Qualifications: Bachelor's Degree in Computer Science or a related field 5+ years of professional experience Advanced SQL query writing experience required Hands-on experience in relational and multi-dimensional data modeling, including multiple source systems from databases and flat file Experience implementing complex stored procedures and standard DWH and ETL concepts Preferred Qualifications: Knowledge of developing dimensional data models and awareness of the advantages and limitations of Star Schema and Snowflake schema designs preferred Understanding of Kimball Data Warehousing design principles is preferred Knowledge of Python, GitHub, Airflow preferred Build/Design data pipeline using Python/Snowflake/Airflow preferred Experience implementing data quality initiatives such as test harnesses, monitoring, and auditing features on data preferred Experience with AWS data storage and management technologies such as S3 Essential SAFe experience helpful PatientPoint requires its employees to be fully vaccinated (as defined by the CDC) against COVID-19, where allowable under the law, unless they are approved for a reasonable accommodation based on their qualifying disability/medical condition, or sincerely-held religious beliefs that prevent them from being vaccinated. #LI-Remote"
BigQuery Data Engineer,Alldus,"Washington, DC+6 locations",https://www.indeed.com/rc/clk?jk=22f7b3748a7cddd2&fccid=b4df24bc350094d0&vjs=3,"BigQuery Data Engineer We are currently recruiting a BigQuery Data Engineer to join a major digital media company. As a Data Engineer, you will play an important role working all stages of the data warehouse life cycle to build out their large-scale custom data platform. You will work with (clean, transform, and bring together) a variety of data sources that have been ingested into BigQuery. Technical Qualifications: B.S. in a highly quantitative field (e.g., Computer Science, Engineering, Physics, Mathematics, Operations Research, etc.) or equivalent experience (Advanced Degree preferred) Proven extensive experience working with BigQuery Proven experience working with ETL/ELT concepts Proven experience working with Google Cloud Platform Proven experience working with different data engineering languages, tools, and databases (Python, BigQuery, PostreSQL, DataStudio, etc.) Excellent written and verbal communication skills Bonus: Experience with version control Understanding of Google Analytics/Ad Manager data Experience with AI/ML services If you are interested, please apply or send a resume to samuel@alldus.com"
Enterprise Analytics Data Engineer,AmeriHealth Caritas,"Newtown Square, PA",https://www.indeed.com/rc/clk?jk=53743e389d5a673f&fccid=289e75237f4c1edd&vjs=3,"Job Brief This position is responsible for Automation of report production in Business Intelligence (BI) systems that integrate with databases, data warehouses/marts and data lake. Your career starts now. We’re looking for the next generation of health care leaders. At AmeriHealth Caritas, we’re passionate about helping people get care, stay well and build healthy communities. As one of the nation's leaders in health care solutions, we offer our associates the opportunity to impact the lives of millions of people through our national footprint of products, services and award-winning programs. AmeriHealth Caritas is seeking talented, passionate individuals to join our team. Together we can build healthier communities. If you want to make a difference, we’d like to hear from you. Headquartered in Philadelphia, AmeriHealth Caritas is a mission-driven organization with more than 30 years of experience. We deliver comprehensive, outcomes-driven care to those who need it most. We offer integrated managed care products, pharmaceutical benefit management and specialty pharmacy services, behavioral health services, and other administrative services. Discover more about us at www.amerihealthcaritas.com. Under the leadership of the Manager of Data Engineering & Automation, this position is responsible for Automation of report production in Business Intelligence (BI) systems that integrate with databases, data warehouses/marts and data lake. Responsibilities also include developing solutions/framework for provisioning data for consumption for required state and regulatory reports, as well as supporting production reporting environments. Responsibilities: Develop, maintain and execute automation of plan and enterprise level reports Develop testing scenarios/cases to address areas such as database impacts, software scenarios, regression testing, boundary/negative testing, error or defect retests and usability including automated scripts Develop high quality automation test engineering best practices, test strategy and principles in Tableau Design test plans, scenarios, scripts, and/or procedures to determine product quality or release readiness Follow defect tracking processes including defect documentation, defect tracking tool utilization and ensuring open defects are monitored and escalated as needed Partner with product owners to deliver high performing quality customer experiences that are engaging, purposeful and powerful in their simplicity Participate in automation script code reviews and provide guidance on their compliance with automation best practices Demonstrate skills using code repositories Interact with the product delivery team and participate in product requirement/design reviews to provide input on completeness of functional requirements, product designs and schedules Identify interdependencies, ambiguities or omissions and make suggestions to improve requirements and ensure usability/testability Review software documentation to ensure technical accuracy, compliance or completeness with focus to mitigate risks Learn rapidly and enthusiastically, focusing on understanding the application/product/area in detail Perform other duties as assigned by Management. Education/ Experience: Bachelor’s Degree Computer Science or related field. 1 to 3 years automation of reporting environment; agile environment; report automation engineering; batch and real time processing; agile methods; experience in health care industry."
Data Engineer III,CEdge Software Consultants,Remote,https://www.indeed.com/rc/clk?jk=3999846a26728feb&fccid=93e7b158c0208ba6&vjs=3,"CEdge has an opportunity for an Data Engineer III located in St Louis MO(REMOTE). If you are ready to work alongside World Renowned Technology experts, and carry the skills below, this is the opportunity that will inevitably take your career to unbelievable levels! Job Title: Data Engineer III DATA GOVERNANCE ENGINEER About The Position Lead the design and implementation of the Enterprise Data Quality Framework. Drive the business understanding of the data flows and their dependencies and ensure that data quality and governance is a priority for the business. Lead the creation of Informatica Data Quality mappings, sessions, workflows, scripts and orchestration schedules. Responsible for resolving data quality issues and providing support Own and leverage internal data governance tools to ensure business glossary accuracy, set alerts and monitoring tasks to ensure data is maintained accurately across platforms Key responsibilities include: Define roles and responsibilities related to data governance and data quality, develop related processes and procedures, and establish a common understanding and visibility of all agency data assets. Lead the design & implementation the data quality standards, roles, and metrics Works with cross-functional business and technology teams to design the data quality processes and services Ensuring the resolution of data quality issues are completed and suitable processes are in place to stop repeat of issue Design & implement metadata model maps and lineage across data assets in the data governance project Participate in alignment with EA teams and data strategy across the organization. Coordinate with the project teams and others to ensure that data standards and models align with the overall enterprise architecture and applicable standards. Lead the creation of specification documents for new data management requirements Conduct requirement gathering, business analysis and any data architecture activities with the data governance & quality programs. Participate in the data maturity assessment sessions and gap analysis. Develop a strong working relationship with the appropriate business users and provide business-impact-driven analysis and communicate results to stakeholders. Understands the Digital organization’s objectives, and the impact on own projects; contributes to development of new data governance strategies Demonstrates strong working knowledge of agile software development processes and the development lifecycle; liaises with scrum masters and coaches to move projects forward Perform an objective technical analysis of a potential integration solution for metadata and multiple data catalogs Coaches less experienced co-workers and provides feedback to enhance skills and knowledge Qualifications Bachelor’s degree required, preferably in mathematics, statistics, computer science or business 7+ years of relevant experience In addition to the above qualifications, the successful candidate will demonstrate: Deep expertise in databases and data structures. Expert in Structured Query Language (SQL). Deep expertise in using Information Analyzer and ability to interrogate scripts Extensive knowledge in in identifying and mapping Data Flows Extensive knowledge in data Governance & quality policies, standards, procedures, and metrics. Extensive knowledge in Meta-data management (Data Classifications, Glossary, and data lineage) Deep understanding of data governance and data quality and metadata management tools like Informatica and Collibra Strong understanding of DMBOK (Data Management Body Of Knowledge) Ability to organize and deliver trainings to the data governance established offices and client teams. Strong understanding of agile and project methodologies and processes Strong analytical and creative thinking to address complex business problems Thank you, WHAT’S IN IT FOR YOU? Full Benefits Package 10 Days PTO 10 Paid Holidays 401K WHO ARE WE? CEdge Software Consultants is an innovative IT consulting firm, and a strategic business partner. We offer IT solutions to Federal and State governments, as well as, Commercial Enterprises throughout the United States. Our main objective is to create an integrity-based culture that takes pride in working as a collaborative team that focuses on growth and is driven by the desire to provide purely ethical services for both our clients and teammates."
Sr. Data Engineer III,OppFi,"Remote in Chicago, IL",https://www.indeed.com/rc/clk?jk=8bb0ef6721f83cc4&fccid=dd616958bd9ddc12&vjs=3,"As a leading financial technology platform, OppFi powers banks to bring credit access to millions of everyday consumers who are locked out of mainstream financial options. We go beyond our mission - to help people rebuild financial health - and go further to ensure we keep the customer at the center of everything we do. We are creating a Customer-obsessed culture, with the capital ""C"". And it starts with our team here. We are a team of caring, innovative, and inclusive individuals who thrive in being immersed in diverse talents, expertise, perspectives and backgrounds. Our employees approach every new challenge with an unparalleled ability to see what could be rather than settle for what is. We welcome individuals who want to make a difference in the financial system through creating and building simple, transparent products that facilitate credit access, enable savings, and build wealth. A few other fun facts about us. OppFi is an Inc. 5000 company for six straight years, a Deloitte's Technology Fast 500™, the seventh fastest-growing Chicagoland company by Crain's Chicago Business, and was named on Built In's 2022 Best Places to Work in Chicago. What you get to do: Data Engineers are important members of the Database team who work collaboratively to design database solutions to meet our reporting, analytics and data science needs. Our team supports architecture, design, ETL, and database administration tasks for both OLTP systems (PostgreSQL) and data warehouses (Snowflake). Reporting to the Staff Engineer, Data, you will: Lead a team of 2 Database Engineers working primarily on database administration and operations. Leverage Snowflake to make several layers of OppFi data available for reporting, Data Science and analytics. Hands-on work administering and architecting our Snowflake Data Lake/Warehouses/Marts Enforce corporate data security and privacy standards in the Snowflake environment Support and refine Business Intelligence and Data Warehouse environments at both a strategic/architectural level as well as an operational level. Work with our Data Science team to integrate more Snowflake Data Shares into our data ecosystem Focus on the efficient usage of Snowflake across OppFi both in terms of total costs as well as performance Operate in close partnership with the site reliability engineering team to develop PostgreSQL and Snowflake infrastructure Participate in a weekly on-call rotation about once every 2 months Participate in the hiring process for technology candidates within a well-defined process What you will bring to the team: 8+ years of experience of hands-on data engineering and/or administration experience, preferably including both Snowflake and PostgreSQL databases At least 1 year of experience as a manager/lead of an engineering team At least 2 years of hands-on experience with Snowflake, preferably with some level of Snowflake certification Substantial SQL experience (required) A sense of customer service and empathy Our Tech Stack: Snowflake PostgreSQL (AWS RDS) AWS Datadog Terraform Harness Jira Airflow Reports to: Staff Engineer, Data Job Level: Senior Data Engineer III, DBA, team lead The minimum salary for this role is $175,000. The total compensation package includes eligibility for performance-based bonuses as well as a 1-time equity grant based on level. The actual offer, reflecting the total compensation package and benefits, will be at the company's sole discretion, and determined by a myriad of factors including, but not limited to, years of experience, depth of experience, and other relevant business considerations. Total Rewards and Benefits OppFi offers a flexible remote environment, 401(k) matching program, and flexible paid vacation. Other benefits include medical benefits, dental and vision coverage, and tuition reimbursement. To support your wellness & growth, we provide monthly meditation and yoga classes and access to all LinkedIn Learning courses. We also offer Fringe, which is a lifestyle benefits platform that lets you decide how you want to spend your rewards from dozens of vendors like Uber, Doordash, and Urban Sitter. Dress code is casual. EEOC Statement: OppFi is an equal opportunity employer and does not discriminate based on any actual or perceived legally recognized protected bases under local, state, or federal law or regulations. Our goal as a company is to build an equitable workplace that actively works to dismantle systems of oppression in our processes, procedures, and interactions. We aim to help our employees thrive where they work and beyond. Check out our Culture page here. OppFi is committed to the full inclusion of all qualified individuals. As part of this commitment, OppFi will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact our People team at recruiting@oppfi.com. Pursuant to the requirements of the California Consumer Privacy Act, OppFi is providing the ""OppFi California Employee Privacy Policy"", which details the categories of personal information collected and your rights under the policy. If you are a California resident, please review the policy here: https://www.oppfi.com/careers/"
Data Engineer,MagnaFlow,"Oceanside, CA 92056",https://www.indeed.com/rc/clk?jk=ddd93954c8605078&fccid=3d377775a9d2ae64&vjs=3,"Are you looking for a career with an industry leader with growth, stability, and an engaging work environment? MagnaFlow offers career growth, competitive pay, and an outstanding benefit package with medical, dental, vision, life insurance, paid time off, holidays, and a birthday holiday! GENERAL DESCRIPTION: The unique mix between the business intelligence expert and SQL guru the Business Intelligence Data Engineer brings to the table the ability to translate ambiguous user requirements and heterogeneous data into data models feeding reports that tell a compelling story. They complement this with the know-how to help us make our BI infrastructure work like a well-oiled machine. Reporting to the Director of Business Intelligence they are primarily responsible for development and maintenance of MagnaFlow's business intelligence databases and data models with some ad hoc report development responsibilities. This includes query optimization, debugging reports and DAX measures, collaborating on development and maintenance of ETL processes and data modeling. They will work directly with stakeholders at all levels in the organization to support their analytics needs aligning with our core BI strategy: ""To develop a system of processes and procedures for the delivery of relevant, accurate, actionable business intelligence in reports and analysis delivered in a timely fashion for members of MagnaFlow's executive, finance, operations and sales teams by capitalizing on Microsoft's technology stack, engaging in continuous learning, agile development and having fun boldly going where no man or woman has gone before."" DUTIES AND RESPONSIBILITIES: Owns availability, recoverability, scalability, security, and performance of our BI related Azure SQL Server databases. Verifies accuracy and integrity of data loaded to MagnaFlow's BI solution. Identifies opportunities for data integrity improvements in source systems. Assists in maintaining BI database indexes through manual and automated solutions, in optimization of data types across tables. Assists in maintenance of backups and deployment schedules for data and reporting solutions. Supports business users in understanding business opportunities through data analysis and innovative, and practicable reporting solutions (Power BI & ad-hoc reports). Assists in maintaining and upgrading existing inventory of reports and data models and development of new reports and data models affecting all areas of the business. Assists in development and maintenance of scalable ETL solutions (ADF & Power Automate) ensuring data served to users via BI is current, accurate and unambiguous. Through thorough analysis builds a solid understanding of MagnaFlow's data. Identifies improvement opportunities in MagnaFlow's BI landscape and work with stakeholders to implement solutions. Assists in development of ad hoc solutions supporting MagnaFlow's business intelligence function. Prepares documentation, training materials and participates in our monthly Lunch & Learn program. Demonstrates continuous dissatisfaction with the status quo. Required Skills and Specifications Bachelor's degree in Business, Business Administration, Information Systems, Computer Science or related field or relevant experience. 3 or more years of experience in business intelligence, data engineering, data analysis, or database administration. Strong SQL knowledge with proven aptitude at query optimization, report writing, and database architecture development. Strong knowledge of, and experience with, reporting services (Azure / SQL Analysis Services or Power BI preferred). Strong analytical skills and critical thinking skills with the ability to collect, organize, analyze and disseminate information with attention to detail and accuracy. Effective oral and written communication skills. #MFLOW2"
Data Engineer,KIND,United States,https://www.indeed.com/rc/clk?jk=3c2f4e122c46fef8&fccid=7fe31231d8054866&vjs=3,"Job Description: Who are we? Since 2004, KIND has been on a mission to create a kinder and healthier world - one snack and one act at a time. Its iconic KIND© bars - made with real, recognizable ingredients - sparked the growth of an entirely new healthy snacking category. Today, KIND has a family of more than 80 snacks that offer solutions for a variety of occasions. All of KIND's products lead with a nutrient-dense first ingredient - whole nuts, whole grains or whole fruit - and do not contain genetically engineered ingredients, sugar alcohols or artificial sweeteners. Inspired by the belief that acts of kindness can be a transformative force for good, both the KIND brand and The KIND Foundation seek to inspire kindness and empathy. We're looking for passionate collaborators to help us become the foremost leader in health & wellness and positively impact society along the way. If you're looking to be a part of an inspiring, energetic and entrepreneurial environment, you’ve found the right place. What you’ll do As the Data Engineer you will join our data and analytics team to create and maintain sustainable and standardized data pipelines and warehouses. You will work closely with the Analytics Engineers and data visualization specialists to understand data requirements and source data from across the organization. You will design and create data marts necessary to empower the business to make data driven decisions. Your ability to partner with cross functional groups to understand the business and develop solutions in an agile collaborative fashion will make you successful in this role. And this is how you’ll do it… Own all aspects of the KIND data warehouse and data pipeline processes Implement and follow a sustainable data ops process for CI/CD Serve as subject matter expert for KIND data stack and technology needs Manage data pipelines between key systems and external data providers to the data warehouse, supporting data needs across the organization Develop and implement processes to monitor data quality and timeliness across all platforms Identify, design and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes Systematically ensure data integrity between source systems and data warehouse Lead documentation and training of warehouse design and structures Manage multiple enhancement and development projects independently keeping stakeholders and management informed What you’ll bring to KIND Strong analytical, data processing and problem-solving skills Exceptional attention to detail and ability to assess impact in a complex environment Experience in monitoring and automating data transformations Ownership mindset and consistent timely delivery on commitments Data Engineering best practices You are… An automation enthusiast A technologist interested in developing scalable and efficient solutions Proficient in Python Understand the CPG business model and metrics and data that supports the business Detailed oriented and focused on high quality testing A great requirements gatherer who can ask all the right questions Flexible and able to develop in an agile and quick fashion A SQL and ETL expert Required Experience: You have… 4+ years experience as a data engineer/architect deploying ETL and data warehouses Mastery of database and data warehouse methodologies from ERP databases and external data sources Expertise in designing data warehouses using SQL server and Snowflake Fluency in different SQL techniques for data transformation Experience developing data pipelines in SSIS, Azure Data Factory or other ETL tools Strong communication and prioritization skills to manage multiple stakeholders Knowledge of reporting and data visualization tools Bachelor's degree in Computer Science, Data Science, Statistics, Informatics, Information Systems or related field What KIND offers Competitive salary, including a target bonus and an impressive benefits package! Flexible Paid Time Off. Choose what works best for you, including summer hours Excellent health, dental & vision insurance, with options to fit you & your family’s needs Your health is important! Our wellness strategy focuses on mental and physical well-being through in office programs like Drs, Nutritionists, Mindfulness, Chair Massages & others Casual office dress code - feel free to wear your KIND gear Stock up on your favorite KIND bars to share with your family & friends, through a quarterly voucher Training & tuition reimbursement program, because continuing to learn matters and we support your development A dynamic, ambitious, fun and KIND work environment The opportunity and responsibility to be KIND everyday Covid-19 Requirements Where permitted by applicable law, you must have received or be willing to receive the COVID-19 vaccine by date of hire to be considered for U.S. and Canada based jobs. Proof of vaccination will be required. If you require a special accommodation, please let us know. Since we are a NYC based company, you will be asked to show proof of vaccination if you are required to enter into our NYC headquarters for an in-person interview. EEO At KIND, we are committed to an inclusive workplace where diversity in all its forms is championed. KIND is proud to be an equal opportunity workplace and we are an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants with criminal histories, consistent with legal requirements. If you require special accommodation, please let us know. From: KIND"
Senior Data Engineer [Remote],Braintrust,"Remote in San Francisco, CA+7 locations",https://www.indeed.com/rc/clk?jk=edcd05f96d9e1267&fccid=cffd065f9ff9e672&vjs=3,"ABOUT US: Braintrust is the only network that gives in-demand talent all the freedom of freelance with all the benefits, community and stability of a full-time role. As the first decentralized talent network, our revolutionary Web3 model ensures the community that relies on Braintrust to find work are the same people who own and build it through the blockchain token, BTRST. So unlike other marketplaces that take 20% to 50% of talent earnings, Braintrust allows talent to keep 100% of earnings and to vote on key changes to improve the network. Braintrust is working to change the way freelance works – for good. JOB TYPE: Freelance, Contract Position (no agencies/C2C - see notes below) LOCATION: Remote - United States and Canada Only HOURLY RANGE: Our client is looking to pay $100 – $130/hr ESTIMATED DURATION: 40h/week - long-term, ongoing project THE OPPORTUNITY What You Have 5+ years of experience in Data Engineering role 3+ years of programming experience with at least one language such as Python, Scala, Java, or other modern OOP programing language 3+ years' experience in writing SQL statements 3+ years' experience with schema design and dimensional data modeling Experience building and optimizing 'big data' data pipelines, architectures, and data sets Experienced developing in cloud platforms such as Google Cloud Platform (preferred), AWS, Azure, or Snowflake at scale Experience with real-time data streaming tools like Kafka, Kinesis, Apache Storm, or any similar tools Experience in designing data engineering solutions using open source and proprietary cloud data pipeline tools such as Airflow, dbt, Glue, and Beam Experience in development of custom built BI and big data reporting solutions using tools like Looker, DataStudio, or any similar tools Experience with code management tools (e.g., Git, SVN) and DevOps tools (e.g., Docker, Jenkins) Excellent communication and presentation skills, strong business acumen, critical thinking, and ability to work cross functionally through collaboration with engineering and business partners What we'd love to see (but isn't required) Supply Chain or Ecommerce analytics experience a strong plus Bachelor's or Masters in Computer Science, Computer Engineering, Statistics, or another quantitative discipline What you'll be working on Senior Data Engineer, Supply Chain Data Engineering Data Engineering is the engine that powers our client data obsessed eCommerce enterprise. They move fast, iterating quickly on big business problems. Data Engineering efforts are instrumental in further growing their market share in a $800 billion home goods market. Every day, they ingest billions of rows of data about how people pick out the perfect items for their home, and this data is what drives their business strategies and decisions. They build cutting-edge data platforms enabling advanced analytics and insights across their business and analytics teams. As a senior data engineer, you will be a hands-on developer who designs, and delivers Data Warehouses, Data Lake, Self-service tooling, Real-time streaming, and Big Data Solutions for their rapidly growing Supply Chain Operations. Working within the Data Engineering organization, this individual will tightly partner with business, product managers and engineering leaders to build data platforms enabling these goals. You will be instrumental in building out the data pipelines to ensure their data is generated, transformed, and mutated over time, working to build a cohesive, scalable, accurate, and performant foundational source of truth upon which all data & analytics users across the company will build. What You'll Do Build data pipelines to assemble large, complex sets of data that meet non-functional and functional business requirements Deliver Data Engineering capabilities for streaming and batch-based data ingestion, enrichment, and aggregation. Design and develop sophisticated data models and visualizations that support multiple use cases across different products or domains. Define and manage SLA for all data sets in allocated areas of ownership. Work closely with data architect, SMEs, and other technology partners to develop & execute on the data architecture roadmap for different functional areas Mentor and grow technical skills of engineers across multiple sprint teams by giving high quality feedback in design and code reviews and providing training for new methods, tools, and patterns Collaborate with your stakeholders and other business analytics team leaders Apply Now! #PL-BT ABOUT THE HIRING PROCESS: Qualified candidates will be invited to do a screening interview with the Braintrust staff. We will answer your questions about the project, and our platform. If we determine it is the right fit for both parties, we'll invite you to join the platform and create a profile to apply directly for this project. C2C Candidates: This role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we'd welcome your application. Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status."
Data Engineer,Wex Europe Services Ltd,+1 locationRemote,https://www.indeed.com/rc/clk?jk=c8220823deb6c4d8&fccid=67cf6319601a0310&vjs=3,"Here is the Job Description :- Responsibilities: Hands-on development in the implementation of Informatica IICS and Informatica Power Center Work directly and collaboratively with Architect, Informatica Admin, and Development Analysts Client facing with technical and business stakeholders Develop and maintain effective working relationships with team members Demonstrate the ability to adapt and work with team members of various experience level Sound knowledge of Data Warehouses and LakeHouse concepts and practical implementation experience . - Excellent Data Analysis and Data Profiling skills using IICS or any other profiling tools to solve business critical issues. - Ability to manage tasks independently. Qualifications + Bachelors in Computer Science or Equivalent with 10 years of experience in Data Engineering and data warehousing or Master with 7 years worth of experience in Data Engineering and DataWarehousing. + Informatica cloud (IICS) – Expert level working knowledge in Integration Service and DI . + 7+ Years of experience in IICS / Informatica + Expert level working Knowledge of RDBMS (Oracle & Postgresql ) and Snowflake. + At least 9+ years of working experience in RDBMS and snowflake will be a plus. + Experience in API based integration, Real time integration. + Familiarity with AWS is needed. + Interfacing with other systems such as Salesforce using IICS is a plus. + Knowledge of other informatica products is always a plus + Good communication skills. + Ability to interact with Business Teams and come up with an integration Architecture. + Work with team of developers to deliver the integration solutions. The base pay range represents the anticipated low and high end of the pay range for this position. Actual pay rates will vary and will be based on various factors, such as your qualifications, skills, competencies, and proficiency for the role. Base pay is one component of WEX's total compensation package. Most sales positions are eligible for commission under the terms of an applicable plan. Non-sales roles are typically eligible for a quarterly or annual bonus based on their role and applicable plan. WEX's comprehensive and market competitive benefits are designed to support your personal and professional well-being. Benefits include health, dental and vision insurances, retirement savings plan, paid time off, health savings account, flexible spending accounts, life insurance, disability insurance, tuition reimbursement, and more. For more information, check out the ""About Us"" section. Salary Pay Range: $110,000.00 - $147,000.00"
AWS/BI Data Engineer,Hitachi,"Seattle, WA 98101 (Downtown area)",https://www.indeed.com/rc/clk?jk=fc29b2802ce942bb&fccid=28f79c18789111e8&vjs=3,"Meet our Team SHORT INTRO TO THE TEAM - SAMPLE BELOW We represent Hitachi Vantara to enterprise clients across industries, establishing business relationships to understand customer challenges so that we can deliver profitable business for Hitachi products, services and solutions. We collaborate as a team and cross-functionally to ensure the success of our customers; success that is celebrated and shared. Our solutions bring value to every line of business and we need people like you to build those deep relationships and to passionately articulate our value proposition. What you'll be doing COUPLE OF SENTENCES SELLING THE MAIN FOCUS POINTS OF THE ROLE What you bring to the team Bullet Point 1 Bullet Point 2 Bullet Point 3 Bullet Point 4 Bullet Point 5 Our Company Hitachi Vantara is part of the Global Hitachi family. We balance innovation with an open, friendly culture and the backing of a long-established parent company, known for its ethical reputation. We guide customers from what's now to what's next by unlocking the value of their data and applications to solve their digital challenges, achieving outcomes that benefit both business and society. Our people are our biggest asset, they drive our innovation advantage and we strive to offer a flexible and collaborative workplace where they can thrive. Diversity of thought is welcomed and our employee base is represented by several active Employee Resource Group communities. We offer industry leading benefits packages (flexible working, generous pension and private healthcare) and promote a creative and inclusive culture. If driving real change gives you a sense of pride and you are passionate about powering social good, we'd love to hear from you. Our Values We strive to create an inclusive environment for all and are open to considering home working, compressed/flexible hours and flexible arrangements. Get in touch with us to explore how we might be able to accommodate your specific needs. We are proud to say we are an equal opportunity employer and welcome all applicants for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. With Japanese roots going back over 100 years, our culture is founded on the values of our parent company expressed as the Hitachi Spirit: Wa - Harmony, Trust, Respect Makoto - Sincerity, Fairness, Honesty, Integrity Kaitakusha-Seishin - Pioneering Spirit, Challenge"
Senior Data Engineer,Cradlepoint,"Remote in Boise, ID 83702+1 location",https://www.indeed.com/rc/clk?jk=fd5b9d3fd8bc3253&fccid=cf2a618027c975ad&vjs=3,"Overview: ~This is a remote opportunity~ Cradlepoint was born in Boise and built for wireless. We are a team of authentic, hard-working, and innovative people driven by a shared vision to Connect Beyond the limits of wired networks. We help customers — big and small, across industries and around the world — utilize LTE and 5G cellular technology to connect people, places, and things, anywhere. We’re at the forefront of the Wireless WAN and 5G — the next big waves in networking — and we remain as hungry and humble as the day we started. If you’re hungry to be part of something big, come join us. Responsibilities: How Will You Contribute to the Company? Cradlepoint's Visibility and AI/ML Team is seeking a Senior Engineer - Data Lake Architecture to build high quality, scalable and resilient data lake systems. This person will provide data lake architecture and design solutions and be responsible for developing some of the key components of our platforms and collaborate with multi-functional teams to capture requirements. What Will You Do? Design, implement and maintain data infrastructure platform Work on the automation of data infrastructure Manage data infrastructure on AWS Help with database performance monitoring and tuning Work with teams on requests for extracting/loading data Comprehend and translate business requirements into technical specifications and build sophisticated, efficient, and scalable solutions based on specifications Recommend and implement standard methodologies for Rest API integration framework/model Work well independently in a fast-paced, team-oriented environment Create recurring and ad-hoc reports for the business as needed Perform other duties as assigned Qualifications: Bachelor’s degree, in Computer Science, Engineering, Mathematics or a related field 8+ years of experience of IT platform implementation in a technical and analytical role 5+ years of experience working on designing and developing data lake systems. Strong knowledge of data lake tools such as S3, Snowflake, DynamoDB, Cassandra, and Qubole Strong expertise in SQL and NoSQL databases Strong knowledge and experience with AWS services Strong experience using appropriate indexes for performance improvement Good understanding of software engineering principles and fundamentals including data structures and algorithms Excellent problem solving and debugging skills with attention to detail Good time management and can incrementally deliver to tight schedules Excellent oral and written communication skills Previous experience with networking (preferred, but not required) Note: Did you know that women and other marginalized groups often hold back on applying to jobs if they don’t meet 100% of all listed requirements? We don’t want you to hold back! If you don’t check every single box above but still feel like you could successfully do the work, we encourage you to apply! We’d love to connect and see how you could add to our team. Why Cradlepoint? At Cradlepoint, we’re one team - all in on inclusion. Celebrating the uniqueness of our individual team members across the globe helps us build diverse teams where we all can thrive. Our connected, community-focused culture enables each one of us to perform at our best and fully be ourselves. Our Cradlepoint values drive everything we do: Stay humble and hungry: Be a curious learner, resilient, and competitive. Don’t point a finger; lend a hand: We are one team! Communicate, provide support, and lift others. Make a difference: Prioritize, innovate, differentiate, and think big for customer success. Make a difference in work and in our communities. Keep it simple: Eliminate complexity. Reduce time to value. Enjoy the ride: Celebrate – appreciate – grow. Trust, Respect, and transparency: Be ethical, data-driven, respectful, and straight shooters who share openly. We are creating the future of global connectivity & community. Come join us. You belong here. Benefits & Perks: Competitive salary with a focus on a global market; Annual and Incremental Incentive plans; 401K retirement plans (where available) Flexible Time Off with Global Holiday Schedules to promote work-life balance Wellness initiatives focused on the health and mental well-being of our team members and their families, including free membership to Headspace (a mindfulness and well-being app), an International Employee Assistance Program, and dedicated quarterly Well-being Days and No Internal Meeting Fridays. Ongoing training and development opportunities Eligible to participate in customary health and other benefit plans and programs based on location Work from home opportunities across our global locations with a culture rooted in inclusion and teamwork #LI-BK1 #LI-Remote Cradlepoint’s Diversity, Equity, Inclusion, and Belonging mission is to create an inclusive work environment where all employees’ differences are celebrated, their thoughts matter, and everyone feels safe to bring their authentic selves to work. We’re proud to be an equal opportunity employer and aim to attract, develop, and engage top talent from a diverse candidate pool. It is our policy and commitment to provide equal opportunity employment for all persons and not discriminate in employment decisions by placing the most qualified person in each job, without regard to any other classification protected by federal, state, or local law."
"AMZ Robotics Data Engineer, Amazon Robotics",Amazon.com Services LLC,"Westborough, MA 01581",https://www.indeed.com/rc/clk?jk=2fe8148d425222af&fccid=fe2d21eef233e94a&vjs=3,"2+ years of experience analyzing and interpreting data and experience with Redshift, Oracle, NoSQL etc. Experience with data modeling, data warehousing, and building ETL pipelines Bachelor's degree in a quantitative/technical discipline such as Computer Science, Engineering, Statistics 1+ years of experience as a Data Engineer or in a similar role Knowledge of distributed systems as it pertains to data storage and computing B.S. degree or higher in Computer Science, Engineering, applied math or other algorithmic-centric discipline Experience building software and/or data applications through internships, course projects, hackathons or personal projects Understanding of Object Oriented Programming, data structures and algorithms Proficient oral and written communication skills Ability to collaborate effectively with a diverse, talented team Job summary Are you inspired by invention? Is problem solving through teamwork in your DNA? Do you like the idea of seeing how your work impacts the bigger picture? Answer yes to any of these and you’ll fit right in here at Amazon Robotics. We are a smart team of doers that work passionately to apply cutting edge advances in robotics and software to solve real-world challenges that will transform our customers’ experiences in ways we can’t even imagine yet. We invent new improvements every day. We are Amazon Robotics and we will give you the tools and support you need to invent with us in ways that are rewarding, fulfilling and fun. Amazon Robotics is seeking talented and motivated Data Engineers to design, develop and test software that controls and optimizes mobile-robotic fulfillment systems used by Amazon.com operations. Amazon Robotics software facilitates user workflows, robotic control and machine to user interfaces, advanced algorithms and mobile technology. Our Engineers experiment with disruptive technologies and integrate them within our current software and data solutions using agile methodologies in a collaborative team environment. As a Data Engineer, you will: Actively support and foster a culture of inclusion Identify and develop solutions to current business problems Work with your manager and team to create milestones and deliverables Use a broad range of data design approaches and know when it is appropriate to use them (and when it is not). Make enhancements that improve data processes (e.g., data auditing solutions, management of manually maintained tables, automating, ad-hoc or manual operation steps). Works with engineers to develop efficient data querying and modeling infrastructure. Create coherent Logical Data Models that drive physical design. A day in the life You will work with stakeholders to dive deep into the manufacturing and supply chain operations problem space. You will design data infrastructure solutions that enable BIEs, DSs and business partners to enable insights for Robotics operations. You'll be part of a talented team with end-to-end skill-sets in software development, data engineering and data science. You will be in the driver's seat of your research projects with the ability to bring new ideas into production. About the team We are a cross-functional team of software developers, data engineers and data scientists who work together to deliver high-impact solutions. We operate in a collaborative environment where your perspective matters - we encourage new ideas and hold regular design review meetings to think beyond the here and now. Relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Data Engineer,Dark Wolf Solutions,"Arlington, VA",https://www.indeed.com/rc/clk?jk=d8a6d33d71d7a59b&fccid=06ae465446de20ec&vjs=3,"Dark Wolf Solutions is looking for a Data Engineer to design, develop, test, and validate AI/ML pipelines that will be implemented within this platform. The Data Engineer will specifically focus on enabling an AI/ML Data pipeline as part of a Minimal Viable Product (MVP). The person will test and validate the performance of the AI/ML Data Factory. The Data Engineer will also assist with data acquisition, ingestion, and tagging; data exploration and understanding; feature extraction and analysis; data engineering and conditioning; data labeling; and constructing, training, and validating AI/ML Datasets. Required Qualifications: 5+ years of experience performing data engineering efforts to include: data architecture, modeling, cleansing, ingesting, updating, and visualization 2+ years of experience working with Cloud environments 1+ year experience using scripting languages such as R, Python, or Javascript 1+ years experience using Big Data technologies and tools (e.g. Spark, Hadoop, Hive, Cassandra, Druid, Flink, Drill, Trino, NoSQL) Experienced with a variety of open source and commercial ETL tools for preparing and loading data for AI/ML analytics Ability to manipulate raw data into effective visualization dashboards Ability to communicate end to end data outcomes visually Demonstrates a deep understanding of multiple database concepts Understanding of SQL Bachelor's Degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience US Citizenship and an active TS/SCI security clearance required Desired Qualifications: Master's degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience A cloud certification in AWS, Azure, or GCP Previous experience supporting the DoD This position is located is located in Crystal City, VA or Fort Belvoir, VA. We are proud to be an EEO/AA employer Minorities/Women/Veterans/Disabled and other protected categories. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire."
Data Integration Engineer,The Walt Disney Company (Corporate),"Orlando, FL",https://www.indeed.com/rc/clk?jk=f52cdaeedae919b8&fccid=4ed80f3a97849f22&vjs=3,"At Disney, we‘re storytellers. We make the impossible, possible. We do this through utilizing and developing cutting edge technology and pushing the envelope to bring stories to life. Now is your chance to join our talented team that delivers unparalleled creative content to audiences around the world. Imagine yourself as a Data Integration Specialist for People Insights Data Operations where your natural passion for working with data will allow you to be part of a team that enables insights to drive the enterprise HR strategy of The Walt Disney Company. In this role, you will have the chance to leverage your expertise and knowledge to assist in management, governance and integration of workforce data in service of analytics and decision science needs. You will bring skills and experience to increase capability and ease of use of our complex datasets and you’ll develop a deep understanding of our priorities and envision how Snowflake can be best utilized to deliver insights to our organization. You will have the opportunity to inspire data analysts of varying levels of experience while building data expertise across the greater team. Responsibilities : Partner within and across People Insights as well as Enterprise Business Systems to translate functional requirements into data and reporting needs Partner with data developers to implement and test data infrastructure enhancements Design integrations and table structures for reliable and scalable reporting use Document enhancements and create audits for data quality validations Research ad-hoc data questions and tune SQL queries to support partners as required Communicate data updates to technical and non-technical partners Basic Qualifications : 3+ years’ of relevant experience You are proficient in SQL with a thorough understanding of data and systems' infrastructures You are a solutions-oriented critical thinker You have deep technical knowledge and experience in data integration or management You demonstrate the ability to translate business issues and requirements into actionable plans, and to deliver against those plans You are passionate about the benefits of accurate and actionable data, you drive consistency and enjoy partnering with others to accomplish the task You have the capability to work autonomously and make independent decisions to meet deliverables with minimal oversight You can effectively handle and maintain confidential information Required Education : Bachelor’s degree in Computer Science, Engineering or related field and SQL expertise, Snowflake/AWS, ELT/ETL design experience preferred HR and/or Talent Acquisition Data experience also preffered #LI-KG2"
Data Engineer,Resultant,"Indianapolis, IN",https://www.indeed.com/rc/clk?jk=2e8fdcb4cb0fcee2&fccid=377b9d8e1817a140&vjs=3,"Company Description We are a passionate team of 300+ engineers, mathematicians, data analysts, project managers, and business consultants. But more importantly, we are active listeners, deep thinkers, and courageous problem solvers. The Resultant team purposefully comes together to produce a positive outcome. Our name symbolizes our commitment to empathy and collaboration—of not just delivering our clients with the best solutions, but to deeply listening to them, understanding their needs, and learning from each other in the process. The force of Resultant comes from the combined knowledge, passion, and innovation of our team and partners. Together, we partner with clients in the public and private sectors to help them overcome their most complex challenges, empowering our clients to drive meaningful change in their organizations and communities. In everything you do, you’ll help your clients, colleagues, and communities thrive. Resultant was founded as KSM Consulting in 2008. Job Description We are looking for Data Engineers to join our talented data analytics team. As a Data Engineer, you will work closely with many teams across our company on complex, advanced analytical projects to perform data sourcing, data profiling, and other data manipulation functions. You will be directly responsible for the solutions we build for our clients, addressing their business needs through requirements gathering and collaborating on solution reviews. We are looking for self-starters with the skills necessary to empathize with the clients’ needs, translate technical complexities, develop appropriate solutions, and contribute to the growth of our technology and data-driven company. Here’s what a typical day for you might look like: Work closely with the solution leads, project managers, data architects, and data scientists on solution design, architecture, and implementation Perform extraction, transformation, and loading of data from a wide variety of data sources using various data engineering tools and methods. Query and process large data sets and perform data profiling and data quality assessments. Design and implement data solutions for integration across systems that are both secure and operational. Assist in creating database models and architecture design and documentation Conduct research and development as well as contribute to the long-term positioning of and emerging technologies related to data sourcing, cleansing, and integration Document and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code. Improve operations by conducting systems analysis; recommending changes in policies and procedures. Participate in client-facing project activities such as requirements gathering, solution reviews, and explaining technical complexities and business benefits in layperson terms. Qualifications Some of the qualifications and skills we are expecting include the following: A Bachelor’s degree in Computer Science, Engineering or a similar field is required (Master’s a plus) 2+ years of data engineering, software engineering, or similar experience 2+ hands-on industry experience working with SQL on various relational database platforms (Microsoft, Oracle, Hana, Postgres, etc). NoSQL a plus 2+ ETL experience with tools like Azure Data Factory, Pentaho, SSIS, etc. 2+ years of hands-on experience with object-oriented programming in Python (preferred) or similar such as Go, Rust, C#, etc. 2+ years of data modeling experience Strong verbal and communication skills Collaborative team player who is detailed oriented, focused on solution quality and execution Comfortable working across a wide range of project sizes and industries Familiarity or experience with cloud platforms such as AWS, Azure, or GCP a plus Experience with Docker for containerization and Kubernetes for orchestration a plus Additional Information What you should know about Resultant: Rezzers are humble, hungry, and smart. We solve big problems, serve lots of clients, and are entirely committed to delivering transformative outcomes. Rezzers are team players, deeply dedicated to the mission of the organization and to helping everyone around us be successful. Resultant compensates well, rewarding performance that delivers positive outcomes for our clients and ensuring incentives are aligned to achieve our goals. Resultant leaders work hard, serving as a shining example of what it means to be a great Rezzer. They are servant leaders, helping their team to be successful in all possible ways. We have a great benefits package including unlimited vacation, significant 401k contributions, and several opportunities to develop yourself. We pride ourselves in having the best talent in the industry and hope that you’re up for the challenge! What our team members say about us… “I love our true empathy and concern for our clients, it's very rare and appreciated. It is a pleasure to be a part of an organization like Resultant.” ""I learn something new every single day, and I feel like I'm a part of building an organization that has legs. I appreciate that I'm consistently humbled by the talent and caliber of our team.” “The culture of the company is amazing, and the climate of my team is great. The benefits that employees are offered are better than competitors, and the one-on-one presence that my team lead gives is extremely beneficial to me.” All qualified applicants will receive consideration for employment without regard to age, color, sex, disability, national origin, race, religion, or veteran status. Equal Opportunity Employer"
"Software Engineer, Data",Pinterest,"Remote in San Francisco, CA 94103+1 location",https://www.indeed.com/rc/clk?jk=0e9f450352758f8c&fccid=43014b1412e0a7b6&vjs=3,"About Pinterest: Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet. Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more. The Enterprise Data Platform team is looking for a software engineer with experience building web applications using python. You'll work on building a self service framework that will potentially become the standard to manage RBAC(Role Based Access Control) on Snowflake in the industry. This will involve researching the current RBAC architectures, understanding the current Snowflake usage patterns and then designing and building the self service framework. What you'll do: Build a self service framework to do RBAC on Snowflake. Snowflake has a very powerful RBAC system but it is almost impossible to manage the web of access relationships it creates. You will be building a self service framework that will potentially become the standard to do RBAC on Snowflake in every company. Design and implement APIs and frameworks centered around making Snowflake a truly self service solution for end users. This will be open sourced after validating it internally, so it is a unique opportunity to start a greenfield open source project. What we're looking for: Strong skills in Python. Hands-on experience in developing web applications in python. Experience in translating abstract product needs into a technical solution. Ability to design and work with multiple layers: API, data storage and architecture, data retrieval. #LI-BB1 #LI-Remote Our Commitment to Diversity: At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds. Not Specified 0"
Data Center Engineer,Adena & Associates,"Seattle, WA 98188",https://www.indeed.com/rc/clk?jk=12b0d534a918a17d&fccid=20ed696c094e20bb&vjs=3,"Seattle, WA A prominent multi-billion-dollar private equity firm with a strong commercial real estate division which includes holdings in Data Center, Life Science and Class A Office is looking for a Engineer for a high value Data Center asset in Seattle. They are owner operators with a diverse nationwide portfolio with fortune 100 clients. This is a great opportunity that offers growth and upward mobility. This offers a generous salary plus bonus and exceptional benefits. Extensive knowledge of structured cabling systems, networking and connectivity standards and hardware installation requirements are a must."
Data Engineer,"VIZIO, Inc.","Denver, CO 80206 (Cherry Creek area)",https://www.indeed.com/rc/clk?jk=3b7ab1d5e1610958&fccid=2ac0dbed95f0e3bf&vjs=3,"About the Team: Vizio is looking for a Data Engineer to join the growing Data Infrastructure team. The successful candidate will assist the Director of Data Infrastructure by implementing the designs and plans for the Data Lake. By implementing the architecture and executing the data performance processes, the Data Lake will continue to evolve to a higher-level data structure that also evolves the security as the lake expands. What You Will Do: Collaborate in the Big Data infrastructure effort Review data infrastructure on a regular cadence for optimizations Work with teams across the Vizio enterprise to bring their data into the Big Data ecosystem. Enable highly performant data operations Keep tools updated and optimized Keep apprised of latest trends and capabilities in big data industry About You: You work well in a collaborative, team-based environment You are recent college graduate with a BS or MS in computer science or data engineering disciplines or an experienced engineering with < 3 years of experience You have a passion for big data structures You possess strong organizational and analytical skills related to working with structured and unstructured data operations You are looking to gain experience implementing and maintaining high performance / high availability data structures You are most comfortable operating within cloud based eco systems You enjoy leading projects and mentoring other team members Technology Stack knowledge: Experience or knowledge with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience or knowledge with AWS cloud services: EC2, MSK, S3, RDS, SNS, SQS Experience or knowledge with stream-processing systems: i.e., Storm, SparkStructured-Streaming, Kafka consumers. Experience or knowledge with object-oriented/object function scripting languages: i.e., Python, Java, Scala, R, SQL. Experience or knowledge with data pipeline and workflow management tools: i.e., AWS Data Pipeline, Apache Airflow, Argo. Experience or knowledge with big data tools: i.e., Hadoop, Spark, Kafka. Experience or knowledge with software engineering tools/practices: i.e., Github, VSCode, CI/CD. About VIZIO: We are Beautifully Simple. Headquartered in Irvine, California, VIZIO is a leading HDTV brand in America and the #1 Sound Bar Brand in America. VIZIO's mission is to deliver high performance, smarter products with the latest innovations at a significant savings that we can pass along to our consumers. Our loyal following and industry-wide praise continues to grow as we redefine what it means to be smart. VIZIO, Inc. is an Equal Opportunity Employer committed to diversity in the workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, protected veteran status, or any other basis protected by applicable law, and will not be discriminated against on the basis of disability. We do not accept unsolicited agency resumes. We will not pay fees to any third-party agency, outside recruiter or firm without a mutually agreed-upon contract and will not be responsible for any agency fees associated with unsolicited resumes. Unsolicited resumes will be considered our property and will be processed accordingly. For Colorado-based employment: The minimum salary for this position is $85,000.00/year. The compensation package includes annual bonus in addition to a range of medical, dental, vision, financial and other benefits."
Data Engineer III (Remote),Windstream Communications,+1 locationRemote,https://www.indeed.com/rc/clk?jk=9286f0e4615f7724&fccid=60e96bab83ded6e7&vjs=3,"Position Overview: The Data Engineer III will primarily serve as a Data Developer specialist with responsibility for the development and support of complex jobs and algorithms within the Data Warehouse. This position requires excellent technical, communication, and project management skills. Consultant-Marketing responsibilities: Maintain and enhance the existing data warehouse database Develop import/export procedures which satisfy provided specifications Monitor jobs to ensure they are functioning as expected Provide business users the data required for metrics and analysis Maintaining SLA's for input and extracts related to the Data Warehouse Perform and execute data extraction, transformation and loading using ETL tools Ensure compliance of standards and conventions within the development cycle Ability to independently translate business requirements into robust solutions Resolve and troubleshoot complex issues rapidly and accurately with minimal supervision Technical skills and experience required for this position will include: Strong SQL experience, TSQL required, PLSQL a plus Experience with the following: Microsoft SQL Server, Oracle, Exadata Advanced SQL proficiency working with large relational databases Awareness of Data warehousing methodologies Advanced query tuning and index optimization Relational database design Database administrative experience is a plus High degree of analytical and problem-solving skills Strong organizational and time management skills to effectively prioritize multiple projects Strong aptitude for learning and initiative to work independently The ideal candidate should possess Telecom experience Job Requirements Minimum Requirements: College degree in a Technical or related field and 3-5 years professional level experience with 0-1 year supervisory experience for roles with supervision; or 7 years professional level related Technical experience with 0-1 year supervisory experience for roles with supervision; or an equivalent combination of education and professional level related Technical experience required. EEO Statement: Windstream is an equal opportunity employer. At Windstream, we celebrate the authenticity and uniqueness of our people and their ideas. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, genetic information, protected veteran status, current military status, disability, sexual orientation, gender identity, marital status, creed, citizenship status, or any other status protected by law, and to give full consideration to qualified disabled individuals and protected veterans. The diverse voices of our employees fuel our innovation and our inclusive culture. Employment at Windstream is subject to post offer, pre-employment drug testing."
Data /Software Engineers,Ars Quanta,"Seattle, WA",https://www.indeed.com/rc/clk?jk=b2fcf701492b9d04&fccid=962b551e7e354052&vjs=3,"We are looking for a Data Engineer to help us with implementing new data capabilities at our clients. This is contract, and part-time or full-time, remote, and potentially contract to hire. What You’re Good At Building Data Pipelines Python AWS BI/DW architectures Flask, Django etc. Relational data bases Working with other software engineers; Experience working with Data Scientists a plus; Experience with data science tools, ML, etc. a plus."
Data Engineer (EMEA),kraken,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=56f5d6c8075d0151&fccid=66d394411dd2efad&vjs=3,"About Kraken As one of the largest and most trusted digital asset platforms globally, we are empowering people to experience the life-changing potential of crypto. Trusted by over 8 million consumer and pro traders, institutions, and authorities worldwide - our unique combination of products, services, and global expertise is helping tip the scales towards mass crypto adoption. But we’re only just getting started. We want to be pioneers in crypto and add value to the everyday lives of billions. Now is not the time to sit on the sidelines. Join us to bring crypto to the world. Kraken Culture Explained About the Role This role is for applicants on EMEA timezones, if you are on North/South American timezones please apply here: https://jobs.lever.co/kraken/e63cb413-e109-423f-ba97-18930a41b475 The data engineering team is responsible for designing and implementing scalable solutions that allow the company to make data-driven decisions fast and accurately on several terabytes of data. The team maintains the company’s data warehouse and data-lake, and you will be responsible for creating various pipelines to move and process vast amounts of data into the different data products. The team deals with both batch and streamed data, and split into different responsibilities and areas matching both the engineer’s and Kraken’s interest. Responsibilities Build scalable and reliable data pipeline that collects, transforms, loads and curates data from internal systems Augment data platform with data pipelines from select external systems Ensure high data quality for pipelines you build and make them auditable Drive data systems to be as near real-time as possible Support design and deployment of distributed data store that will be central source of truth across the organization Build data connections to company's internal IT systems Develop, customize, configure self service tools that help our data consumers to extract and analyze data from our massive internal data store Evaluate new technologies and build prototypes for continuous improvements in data engineering Requirements 5+ years of work experience in relevant field (Data Engineer, DWH Engineer, Software Engineer, etc) Experience with data warehouse technologies and relevant data modeling best practices (Presto, Druid, etc) Experience building data pipelines/ETL and familiarity with design principles (Apache Airflow is a big plus!) Excellent SQL and data manipulation skills using common frameworks like Spark/PySpark, Pandas, or similar Proficiency in a major programming language (e.g. Scala, Python, Golang,..) Experience with business requirements gathering for data sourcing Nice to have Experience working with cloud services (e.g. AWS, GCP, ..) and/or Kubernetes Experience in building and contributing to data lakes on the cloud Designing and writing CI/CD pipelines Working with petabytes of data Enjoys Dockerizing services Location Tagging: #EU #LI-Remote #LI-DD2 We’re powered by people from around the world with their own unique and diverse experiences. We value all Krakenites and their talents, contributions, and perspectives, regardless of their background. As an equal opportunity employer we don’t tolerate discrimination or harassment of any kind. Whether that’s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws. Stay in the know Follow us on Twitter Catch up on our blog Follow us on LinkedIn"
Principal Data Engineer,Noodle,"Remote in New York, NY 10003",https://www.indeed.com/rc/clk?jk=e762929c7b3d1669&fccid=db056ec58d565514&vjs=3,"Principal Data Engineer Online education is no longer a novel or niche idea. It is the fastest-growing segment in higher education, accounting for 20% of all enrollees and 35% of graduate-level certificates and degrees. It's also getting increasingly competitive, as more and better programs are launched each semester. Universities need to go online quickly, economically, and elegantly, creating programs that students can't wait to tell their friends about and that their professors want to teach. Noodle helps universities bring programs online with flexibility, transparency, alignment, efficiency, and joy. That's why more top universities chose us last year than all other online program managers combined. We are a passionate team of technologists, educators, and experts. Online learning has the potential to transform higher education; if you’re interested in being part of that journey, keep reading! Reports to: Chief Technology Officer (Russ Tarafdar) As our Principal Data Engineer you will: Directly train and manage junior engineers, assisting with day to day duties as needed as well as providing mentorship and career development advice. Define organization-level engineering policies. Develop programs and resources to promote engineering best practices, improve team cohesiveness, and increase the engineering team’s visibility within the company Make key technology decisions and provide implementation and improvement recommendations to team leads and engineers. Independently audit and develop initiatives to address deficiencies in Noodle’s technology products and processes Lead development of core engineering software products Mentor junior engineers, assisting with day to day duties as needed as well as providing technical and career development advice. Work to improve overall software quality by implementing and leading code review, automated testing, continuous integration, and other QA best practices. Assist in high level technology design and project planning. You have: At least 10+ years Python development experience Strong experience with Python data analysis libraries (such as pandas, numpy) Strong relational database and SQL skills Experience with AWS AppSync Experience in agile software development methodologies and best practices At least 4 years experience working with AWS technologies Preferred additional qualifications: Familiarity with Apache Airflow or similar scheduling tools Experience with AWS Appsync Working with various IDP and Okta integration Experience managing infrastructure as code using AWS CDK or similar tools Automated testing and data quality assurance experience At Noodle, we hire people who will help us change the future of online education. Even if you don't think you check off every bullet point on this list, we still encourage you to apply! We value both current experience and future potential. Meet the team! Noodle Benefits: Work from our beautiful NYC office! OR Work from the comfort of your home office! Great compensation package! 401K + match, bonus potential, and equity opportunities Tools you need on us! Mac is our computer of choice Our insurance plan offers medical, dental, vision, short- and long-term disability coverage, plus supplementals for all employees and dependents 12 weeks paid Parental Leave Pre-tax commuter benefits 3 weeks paid vacation + 10 paid holidays + paid sick leave Monthly Gym stipend and Membership to premium medical services like Eden Health Monthly mobile connectivity stipend Access to mental health services like Ginger and Talkspace Annual education stipend for lifelong learning Growth - we pride ourselves on creating environments where employees can be themselves and grow within and around the company Noodle is committed to creating a welcoming and inclusive workplace for everyone. We value and celebrate our differences because those differences are what make our team shine. We hire great people from different backgrounds, not just because it's the right thing to do, but because it makes us stronger as a whole. Women, people of color, LGBTQIA2S+ individuals, and members of other underrepresented groups are strongly encouraged to apply. Noodle is an equal opportunity employer and does not discriminate against candidates on the basis of race, ethnicity, religion, sex, gender, sexual orientation, gender identity, disability status, or veteran status. Noodle won Built In NYC’s 100 Best Places to Work, Best Midsize Companies, and Best Perks & Benefits 2021, and 2022 and was named one of Crain’s 100 best places to work in NYC in 2021. #LI-Remote"
Azure Data Engineer,Mental Health Partners,"Lafayette, CO 80026",https://www.indeed.com/rc/clk?jk=9abb1d41a1cedb85&fccid=21e9ce53c9ef4970&vjs=3,"$80,000 - $125,000 Purpose: As the Azure Data Engineer you will be responsible for building functional and scalable data infrastructure to provide the organization the ability to make informed decisions. You will report to the Data Services Supervisor. Essential Functions: Develop scalable data solutions within an Azure environment Assess and determine governance, stewardship, and frameworks for managing data across the organization. Develop and promote data management methodologies and standards. Continuously improve the existing data infrastructure framework with new and existing technologies Ability to integrate data utilizing a variety of internal and external datasets Help to establish guidelines for the design and development of information and data analytics. Collaborate with project managers and business unit leaders for all projects involving enterprise data Develop and implement key components as needed to create testing criteria to guarantee the fidelity and performance of data architecture. Document the data architecture and environment in order to maintain a current and accurate view of the larger data picture. Identify and develop opportunities for data reuse, migration, or retirement. Ensure the success of enterprise-level application rollouts Liaise with vendors and partners organizations to select the products or services that best meet company goals. Other duties as assigned. What’s In It For You: A 40 hrs. per week role and with benefits (medical, dental, vision, life, disability and retirement plan) Paid time off and paid holidays Engaged employer who believes you are an important factor in delivering our mission to the community You will receive training and professional growth opportunities You will have leadership support to contribute to your growth Mental Health Partners offers a diverse, quality work environment, a great compensation package and a comprehensive benefits package. Our benefits include paid time-off policy (paid holidays, paid vacation and paid personal days-off), medical, dental, vision, flexible spending accounts, and percentage match-up retirement contribution. We are an Equal Opportunity Employer. As a condition of employment, you will be required to receive the COVID-19 vaccination (and any subsequent boosters) and the annual influenza vaccine. Medical exemptions or religious accommodations may be requested. What We Need: Bachelor’s degree in computer science, or 5 years relevant experience. Seven (7+) years’ in Data Engineering. Three (3+) years’ experience in Azure. Experience in building Data Lakes and Data Warehouses in Azure. Familiar with SQL Server. Affinity for learning new technologies, data analysis, and identifying data patterns and trends Strong troubleshooting and interpersonal skills. Possess high critical thinking and reasoning skills."
Data Engineer,Children's Hospital & Medical Center,"Omaha, NE",https://www.indeed.com/rc/clk?jk=ce8c6d8aeae0ef9f&fccid=44aacdbf63c10f1e&vjs=3,"We are currently searching for a Data Engineer to develop strategies for warehouse implementation and data archiving. Designs and builds data models to optimize reporting. Designs, builds and supports ETL solutions to centralize and automate data collection. Assists in the development, maintenance, and support of an enterprise data warehouse and its corresponding data marts and data pipelines. Troubleshoots and tunes system performance. Essential Functions Design and build solutions to build a strong data architecture (ETL/Data architecture/Data reporting/Data management/Data Warehouse) Design and develop data pipelines as needed for internal or external data sources (Data extraction/Uploading/Formatting/Storing) Design and develop data models for efficient reporting (Data architecture) Develop, optimize, and maintain our data warehouse Design and build actionable reporting/visual solutions Contribute to the advancement of our organizational data management blueprint Improve system performance by conducting tests, troubleshooting, and integrating new elements Provide the supporting framework for enterprise data activities Support and troubleshoot issues in data solutions/pipelines/systems Build efficient solutions to identify and handle errors in data solutions/pipelines/systems KNOWLEDGE, SKILLS AND ABILITIES Problem-solving attitude Expertise in MS SQL server (T-SQL, SQL server) Experience with MS Azure/AWS or other cloud-based data warehouse systems Proficient with ETL tools (SSIS/ActiveBatch) In-depth understanding of database structure principles (DBA/Architect background) Data Analytics background Knowledge of scripting languages Software-engineering background Troubleshooting Experience gathering and analyzing system requirements EDUCATION AND EXPERIENCE Bachelor's degree in Information Technology, Data Science, Computer Science, or a related field OR equivalent years of experience required. Minimum 3 years’ experience in Data warehouse development required. Minimum 5 years’ experience in MS SQL (Expert level in SQL coding, query parameterization, code optimization, server objects, jobs etc.) required. Minimum 3 years’ experience in developing and maintaining ETL solutions/packages required. Minimum 3 years’ experience in developing SSIS packages (Expert level in building SSIS packages, scripting inside SSIS, variables, advanced behavior) preferred. Experience in the healthcare industry preferred. CERTIFICATIONS/LICENSURE REQUIREMENTS Microsoft SQL(Programming in T-SQL) or SSIS certification preferred EPIC’s Clarity Administration required. Must be obtained within 1 year of hire. EPIC’s Caboodle Certification preferred. SPECIAL REQUIREMENTS: Rare evening and/or weekend work may be required during system downtime, issues or upgrade EOE/Vets/Disabled IND123 Make a meaningful difference improving the lives of children! At Children’s, the region’s only full-service pediatric healthcare center, our people make us the very best for kids. Come cultivate your passion, purpose and professional development in an environment of excellence and inclusion, where team members are supported and deeply valued. Opportunities for career growth abound as we grow our services and spaces, including the cutting-edge Hubbard Center for Children. Join our highly engaged, caring team—and join us in providing brighter, healthier tomorrows for the children we serve."
Data Engineer,Unioncrate,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=98c7d54fd7af7a10&fccid=669061a8c6675a9d&vjs=3,"What We Do Unioncrate enables CPG companies to build and manage a supply chain that is driven by consumer demand. If you want to be part of building a next-generation supply chain platform and help control how goods move around the world then this is the position for you! Who We’re Looking For We are growing and looking for a data engineer to join our data science team! This role is ideal for someone with some back end development experience looking to work more closely with data. What You’ll Do As a data engineer, you will provide input into architectural design decision, develop code to meet business needs and ensure the applications built are meeting high standards of quality and support-ability. This position will be part of the data science team and will require high collaboration within and across the different Unioncrate teams. Primary Responsibilities Collaborate with the different teams to normalize client data to Unioncrate standards Write Python code to improve and optimize complex ETL process for batch data processing from a variety of SQL and non-SQL data sources Take loosely-defined business questions and translate them into clearly-defined technical/data specifications for implementation Ensure that data pipelines are scalable, repeatable and secure Add to our portfolio of client libraries that interface with 3rd party API’s Assist the Data Science team in optimizing newly developed algorithms Work with the Cloud Engineering team to improve our current deployment process Ensure all deliverables and processes are of high-quality throughout the project by adhering to best practices Mentor less experienced members of the team Qualifications / Requirements 2-3 years of hands-on experience designing and implementing large-scale, complex ETL applications using industry-leading products/platforms 2-3 years of experience using SQL to perform complex data manipulation 1+ year experience with Python Ability to deal with ambiguity and work with rapidly-changing business data Team player, great communicator, collaborative and optimistic by nature Comfortable working in a startup environment with remote colleagues across the globe Familiarity with common programming tools and best practices such as unit testing, Git, and Jira This position is for the New York City Office Nice-to-haves Exposure to time series data / signal processing Experience writing client API libraries Experience working with Docker containers Experience working with functional programming paradigms Experience in any of the more popular Clouds (Azure, AWS or GCP) Interested? Email us a PDF of your resume at careers@unioncrate.com."
"Infrastructure Operations Data Engineer, Infra AGE","Amazon Data Services, Inc.","Herndon, VA+3 locations",https://www.indeed.com/rc/clk?jk=565a5f6319828fc0&fccid=fe2d21eef233e94a&vjs=3,"Bachelor’s Degree in Computer Science, Information Systems, Mathematics, Statistics, or related field or equivalent experience 5+ year experience with Data modeling, SQL, ETL , Data Warehousing and Datalakes 5+ year experience in the design, creation, management, and business use of large datasets. Current active US Government Security Clearance of Top Secret or above. Job summary As a Business Intelligence / Data Engineer you will enable data-driven decision making within the Amazon Web Services (AWS) Data Center Infrastructure Operations organization. The Infrastructure Operations Team is responsible for planning, implementing, monitoring and continuously improving the global Amazon Data Center infrastructure. The team supports all aspects of the Data Center based organizations, including but not limited to: Safety, Security, maintenance, daily operations, logistics, engineering and equipment management. You should be passionate about working with huge data sets and be someone who is able to bring data sets together to answer business questions and drive growth. You will have an opportunity to work with big data and emerging technologies while driving business intelligence solutions end-to-end: business requirements, data modeling, ETL, metadata, reporting, and dash boarding. The Business Intelligence Data Engineer will: · Primarily support teams within the Infrastructure environment, and long term will have opportunities to support teams in the overall Amazon Web Services community. · Build ETLs to ingest the data into the data warehouse and datalake, as well as end-user facing reporting applications. · Develop, implement and maintain the metrics and reports to enable decision support systems for the organization. This includes working with other teams to develop those metrics from their services. · Partner with business customers and development teams to define analytics requirements and then deliver flexible, scalable, end-to-end solutions. This position can sit in Herndon, VA, Seattle, WA, or Denver, CO. The pay range for this position in Colorado is $132,100 - 178,800 per year; however, base pay offered may vary depending on job-related knowledge, skills, and experience. Sign-on payments, Clearance Bonus, and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. Applicants should apply via Amazon's internal or external careers site. This position requires that the candidate selected be a US Citizen and must currently possess an active Top Secret security clearance. The position further requires that, after start, the selected candidate obtain and maintain an active TS/SCI security clearance with polygraph and satisfy other security related requirements. Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. Ability to balance and prioritize multiple conflicting requirements with high attention to detail. Experience with writing SQL scripts Experience with enterprise-class Business Intelligence tools such as Microstrategy, PowerBI, Tableau, Oracle BI, Pentaho, AWS Quicksight, etc. Experience communicating with business owners to understand their data and reporting requirements. Experience with data presentation skills to summarize key findings and communicate with both business and technical teams. Experience working in a Linux environment Experience with scripting language such as Python, Perl, Ruby or Javascript Experience with MPP databases such as Redshift Experience with Datalake development Knowledge of predictive/advanced analytics and tools (such as R, SAS, Matlab) Knowledge of noSQL databases (such as DynamoDB, MongoDB) Knowledge in an enterprise class RDBMS Knowledge of AWS products and services Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Python Data Engineer,Hap Capital,"New York, NY 10014 (West Village area)",https://www.indeed.com/rc/clk?jk=69c258eb6864e32c&fccid=db0af0ad6162783b&vjs=3,"Python Data Engineer HAP Capital is seeking a Python Data Engineer to manage the data infrastructure on the Delta One Team. The team ingests a variety of external sources of data, with a particular focus on categorical basket data as well as large scale trading and research data. This individual will focus on a variety of data systems, working closely with the trading team and developers at HAP. Requirements Wide experience in database design including relational and non-relational database technologies Proficiency in Python, with a particular emphasis on packages related data manipulation and cleaning Strong communication and organization skills working in a team environment 3+ years in Python Development, SQL and ETL pipeline experience Comfortable working in fast paced environment Additional skills/experience that will reflect favorably Proficiency in C++, especially with large scale, low-latency Linux systems Experience working with React for user dashboards Experience building real-time data solutions and processes Academic background in finance/accounting or experience working in quantitative trading Knowledge of large-scale distributed data frameworks like Kafka, Spark, etc"
Senior Data Engineer,Starr Companies,"Atlanta, GA",https://www.indeed.com/rc/clk?jk=bea4dfe4d7701caa&fccid=a64031f02900a058&vjs=3,"Description: Starr Companies is seeking an experienced Data Engineer to be part of a team of developers/analysts responsible for the design and implementation of the company’s data integration platform. The Data Engineer will report to the Director of Data Engineering, and will work in collaboration with data analysts, developers, and key stakeholders to design robust data solutions. Who you are Passionate about intuitive data models and an expert in distributed data processing patterns. Highly proficient in SQL as well as the ability to help others build and tune their SQL statements. Comfortable with at least one of C#, Python or Scala. Experience developing and deploying data pipelines and real-time data streams within a cloud native infrastructure, preferably Azure. Conceptually familiar with fully virtualized cloud environments and Hybrid Cloud Data Warehouses. Understand the Data Lifecycle and concepts such as lineage, governance, privacy, retention, anonymity, etc. What you will be doing Act as a trusted technical advisor and strategic thought leader to the IT department. You will lead and design data pipelines, and reporting solutions, in a hands-on manner. Gather and translate business requirements into technical specifications. Help in improving data quality and record-keeping procedures to ensure the highest levels of data integrity Research and implement best practices to continuously optimize existing processes Help Starr modernize our hybrid technology solutions including the opportunity to work on modern warehousing and integration technologies. Collaborate with reporting and engineering teams to define technology roadmap and architectural designs to improve our data platform scalability. Become a domain expert within Starr's data stores and support the build of high-quality analytics as an architect and an individual contributor. Engage in troubleshooting production issues and root cause analysis. Preferred Qualifications At least 5-8 years of experience in software engineering and data management. At least 3 years of experience with designing pipelines. 3 years of experience working with SQL Server 2+ years of REST or similar API development experience Experience on Cloud technologies with Azure Snowflake or Redshift Data warehouse implementation experience. Candidates requiring sponsorship and/or H1-B transfer are eligible to apply. #LI-MF3 Except as required by law, Starr requires all applicants and employees to be fully vaccinated in accordance with the CDC guidelines."
Data Engineer,Notion,"San Francisco, CA 94110 (Mission area)+1 location",https://www.indeed.com/rc/clk?jk=10bd162d451f3130&fccid=7095ffd299c81ef3&vjs=3,"About Us: We're on a mission to make it possible for every person, team, and company to be able to tailor their software to solve any problem and take on any challenge. Computers may be our most powerful tools, but most of us can't build or modify the software we use on them every day. At Notion, we want to change this with focus, design, and craft. We've been working on this together since 2016, and have customers like Pixar, Mitsubishi, Figma, Plaid, Match Group, and thousands more on this journey with us. Today, we're growing fast and excited for new teammates to join us who are the best at what they do. We're passionate about building a company as diverse and creative as the millions of people Notion reaches worldwide. About The Role: Since the launch of Notion, the company has been on a mission to make toolmaking ubiquitous - from wikis to documents, notes, tasks, databases, etc. A strong product intuition and focus on users have helped the company achieve adoption across businesses of all sizes. Today, millions of users rely on Notion's building blocks to get their work done. As Notion continues to grow quickly, there is a unique opportunity to build the foundations of data and help the product and company reach their full potential. This is where you come in — to design and build reliable, trusted and timely datasets that accelerate the decision-making process of key product and business functions. You will have a strong impact on the roadmap and the growth trajectory of the company. What You'll Achieve: You'll define the processes and ETL infrastructure to transform and make data readily available across the company You'll build core datasets to serve as unique sources of truth for product and business functions (product, marketing, sales, finance, customer experience, data science, business operations, IT, engineering) You'll partner with data scientists and other internal stakeholders to understand their needs and then design, build and monitor pipelines that meet today's requirements but can gracefully scale with our growing data size You'll implement automated workflows that lower manual/operational cost for stakeholders, define and uphold SLAs for timely delivery of data, move the company closer to democratizing data and a self-serve model (query exploration, dashboards, data catalog, data discovery) Skills You'll Need to Bring: You are a self-starter and continuously gather and synthesize high-impact needs from business partners, design and implementing the appropriate technical solutions, and effectively communicating about deliverables, timelines and tradeoffs You've spent 3+ years as a data engineer building core datasets and supporting business verticals as needed. You are passionate about analytics use cases, data models and solving complex data problems You have hands-on experience shipping scalable data solutions in the cloud (e.g AWS, GCP, Azure), across multiple data stores (e.g Snowflake, Redshift, Hive, SQL/NoSQL, columnar storage formats) and methodologies (e.g dimensional modeling, data marts, star/snowflake schemas) You are an SQL expert. You intimately understand aggregation functions, window functions, UDFs, self-joins, partitioning and clustering approaches to run correct and highly-performant queries You are highly comfortable with object-oriented programming paradigms (e.g Python, Java, Scala) Nice to Haves: You have worked at a fast-growing start-up, a SaaS company or are eager to contribute in such an environment (being a current Notion user would be great!) You have hands-on experience in designing and building highly scalable and reliable data pipelines using BigData stack (e.g Airflow, DBT, Spark, Hive, Parquet/ORC, Protobuf/Thrift, etc) Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Notion. Notion is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Notion considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Notion is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation made due to a disability, please let your recruiter know. #LI-Onsite"
Data Engineer Professional,Children's Hospital Colorado,"Aurora, CO",https://www.indeed.com/rc/clk?jk=6110f2768f3d6b8b&fccid=098552e8f8353e68&vjs=3,"Why Work at Children's.... Here, it’s different. Come join us. Children's Hospital Colorado has defined and delivered pediatric healthcare excellence for more than 100 years. Here, the nation’s brightest nurses, physicians, scientists, researchers, therapists, and care providers are creating the future of child health. With an optimist’s outlook, a trailblazing spirit, and a celebrated history, we’re making new strides every day. We’ve been Magnet-designated four times by the American Nurses Credentialing Center and are consistently recognized among the nation’s top 10 pediatric hospitals by U.S. News & World Report. As a national leader in pediatric care, we serve children and families from all over the nation. Our System of Care includes four pediatric hospitals, 11 specialty care centers, 1,300+ outreach clinics and more than 10,000 healthcare professionals representing the full spectrum of pediatric care specialties. Here, we know it takes all of us, every role, to deliver the best possible care to each child and family we treat. That’s why we build our teams toward a foundation of equity in access, advancement, and opportunity. We know teams of individuals with different identities and backgrounds can nurture creativity and innovation. We know we can see, treat, and heal children better when our team reflects the diversity of our patient population. We strive to attract and retain diverse talent because we know a truly inclusive and equitable workforce will help us one day realize our most basic calling: to heal every child who comes through our doors. A career at Children's Colorado will challenge you, inspire you, and motivate you to make a difference in the life of a child. Here, it’s different. Additional Information Department: RI-Research informatics Hours per week: 40, eligible for benefits Shift: Full time, benefits eligible Job Overview This position is responsible for standard level work in data transformation and support of data systems for research. This position develops, tests, promotes, supports and maintains infrastructure and systems for data generation, storage and movement, systems analysis, design and applications programming for single and multiple information systems, software applications, architectures, data warehouses, databases, and data extraction and reporting. Duties include designing, planning, testing, implementing, maintenance, problem solving, documenting, and developing software code, queries, standards, principles and practices. Specialty Areas include Research Data Warehousing, Data Virtualization, Epic, ETL and Data Networks Specifically, the Software Developer/ETL Programmer will provide the technical database expertise required to build and maintain research data warehouses and databases, including design and development of system architecture, and development of databases and ETL. This position will design, administer and program in an Agile development environment that makes heavy use of open source tools, R, Python and SQL programming. Development and maintenance of APIs for various projects is also required. In addition, this position will ensure data is high-quality, including developing and maintaining data quality methods. This position is expected to have a high level of autonomy, in addition to collaborating with internal staff and customers (technical and clinical) and external collaborators (technical and clinical). This position interfaces frequently with analysts and staff to develop database scripts against disparate data sources, and to execute on technical components of projects. There will be opportunities to publish work in collaboration with colleagues. This position is a critical resource in developing and applying informatics and data warehousing techniques to obtain, validate, standardize, and manage scientific and clinical concepts. Experience with both Windows and Linux environments is preferred. Responsibilities POPULATION SPECIFIC CARE No direct patient care. ESSENTIAL FUNCTIONS An employee in this position may be called upon to do any or all of the following essential functions. These examples do not include all of the functions which the employee may be expected to perform. Analyzes, designs, builds, modifies, implements, tests and debugs new or existing software applications, architectures, databases, and systems integration to automate business processes, as applicable. Prepares time lines, project plans and flow charts for the development or enhancement of new and existing software application programs. Gathers, analyzes and documents business and user requirements, functional requirements and data specifications. Designs, writes and documents technical specifications to design or redesign complex applications. Collaborates with applications staff and users of information systems to evaluate, plan, design, develop, test, implement, and maintain application development efforts and/or reports. Works with applications staff to translate and document user needs and system requirements into report specification and/or technical documents. Integrates data between multiple systems for reporting as necessary. Collaborates with database tuning and configuring; developing backup and recovery processes, repeatable methods to refresh non-production environments from production, data life-cycle management, and system upgrades. Writes stored procedures, packages, and functions. Recommends, develops and creates peripheral technologies and IT processes in support of application platforms. Recommends, develops, documents and maintains software coding and development standards, principles and practices. Troubleshoots performance and system availability problems ensuring quality of the enterprise application and/or data warehouse. Consults with end users and information technology staff to identify user problems. Designs, develops, tests, debugs, implements, and prepares flow charts for both new and existing systems. Participates in Production Support on-call rotation as necessary. Other Information SCOPE AND LEVEL Guidelines: Possesses knowledge of and applies the fundamental concepts, practices and procedures within a particular field of specialization. Complexity: Duties and tasks are varied and somewhat complex, but usually involve limited responsibility. Procedures, methods and techniques to carry out work may not be well defined, requiring greater analysis. Decision Making: Has some discretion in making some decisions. Decisions and recommendations are made after contemplative analysis and with independent judgment and ingenuity. May escalate the most complex and important decisions to a higher level employee, supervisor and/or manager. Communication: Communicates explanatory and/or interpretive information relative to the organization and/or own function with team members, peers, management, clients and in limited cases, the public. Uses some discretion and independent judgment when information is exchanged, gathered and/or presented. Defers to higher level team members and/or management in many situations. Supervision Received: Works under some supervision, conferring with higher level employees, supervisor and/or manager as needed. Qualifications EDUCATION – Bachelor's degree is required. EXPERIENCE – Minimum of three (3) years of related experience is required. EQUIVALENCY – Combination of post-high school education, job related certification and/or related experience equivalent to seven (7) years may be considered in lieu of minimum requirements. Physical Requirements Ability to Perform Essential Functions of the Job Vision - Near: clear vision at 20 inches or less Weight Lifted/Force Exerted: up to 10 pounds/4.5 kilos, up to 1/3 of time Hearing: able to clearly hear details Sit: 2/3 or more of time Talk: able to communicate verbally Mental/Emotional: able to work in close proximity to others and/or in a distracting environment Mental/Emotional: able to cope with stress effectively Mental/Emotional: able to prioritize effectively Work Environment Mental/Emotional: able to tolerate ambiguity Mental/Emotional: able to prioritize effectively Mental/Emotional: may be subject to many interruptions Office Work Environment: Regular/frequent exposure Bloodborne Pathogen Category 2: Occasional exposure to blood/body fluid Equal Employment Opportunity It is our intention that all qualified applicants be given equal opportunity and that selection decisions be based on job-related factors. We do not discriminate on the basis of race, color, religion, national origin, sex, age, disability, or any other status protected by law or regulation. Be aware that none of the questions are intended to imply illegal preferences or discrimination based on non-job-related information. Salary Information Annual Salary Range (Based on 40 hours worked per week): $90,743.16 to $136,114.74 Hourly Salary Range: $43.63 to $65.44 Benefits Information As a Children’s Hospital Colorado team member, you will receive a competitive pay and benefits package designed to take care of your needs that includes base pay, incentives, paid time off, medical/dental/vision insurance, company provided life and disability insurance, 403b employer match (retirement savings), and a robust wellness program."
Data Quality Engineer,Affinity.co,Remote,https://www.indeed.com/rc/clk?jk=88333dc8b92bff90&fccid=1b32be4e9bf5cb2a&vjs=3,"USA (Remote) With our growing customer base and our expansion into new markets and use cases, we have more to build than ever at Affinity as we execute on our vision to put relationship intelligence at every professional's fingertips. We are looking for a Data Quality Engineer, who is looking for a challenge, enjoys thinking big, and looking to make their mark on an extremely fast-growing company. If building large and building fast, working with a very talented team of engineers, and collaborating with the brightest minds is what you like, Affinity is the best experience. What you’ll be doing: Design and implement Test Automation frameworks using Python, SQL, Airflow. Develop test strategies, plans, test cases, and engineering best practices related to software test engineering, both manual and automated testing with a specific focus on data quality. Using Tableau, Python, Databricks and DataDog, create active quality monitoring for data pipelines and processes. Work closely with data engineers, data scientists and analysts to inform solution designs in terms of testability. Building and automating testing frameworks around data ingestion pipelines and active monitoring. Build and maintain testing frameworks for big data environments that are highly secure, scalable, flexible, and performant using appropriate SQL technologies. Support data governance and data profiling efforts to ensure data quality and proper meta-data documentation for data lineage. Creating quality metrics to evaluate data pipelines, visualizations, and dashboards. Implement and execute test strategies on all supported platforms and languages to help improve the overall quality and test code coverage. Design and develop integration, regression, and stress tests using industry-standard tools. Collaborate with Product Management and Engineers to understand requirements, translate them into test cases and determine product quality goals and measurements. Reproduce, isolate, and debug issues, providing detailed bug reports. Develops and enhances the test infrastructure and continuous integration framework used across teams. Validate data pipelines and data processing jobs that collect data from disparate systems and store it in internal databases. Identify edge cases that can potentially break the data pipelines or compromise data quality or integrity. Qualifications Required: 4+ years of industry experience in data engineering, BI, and Quality Assurance. Experienced in Python, SQL, Data Warehouse, and Data Lake. Hands-on experience testing, ETL pipeline, Kafka, Spark, and Presto. Sound understanding of various cloud technologies, especially AWS. Experience in working with large-scale Enterprise data warehouse, data integration, data migration, and data quality verification. Hands-on testing experience in working with Databricks, Spark, and other Big data technologies. Experience with data pipelines and data processing jobs. Experience in identifying edge case defects. Skilled in integrating project testing with continuous-integration process (CI/CD). Knowledge of industry-standard test automation tools and experience in developing product test harnesses and instrumenting products to gather test results. Knowledge of relational and NoSQL databases, and queries. BA/BS Degree in Computer Science or related technical discipline, or practical experience. Nice to have: Experience performing code reviews and code quality checks. Understands designing and coding for testability to produce quality code. What you'll enjoy at Affinity We live our values as playmakers who are obsessed with learning, care personally about our colleagues and clients, are radically open-minded, and take pride in everything we do. We pay your medical, dental, and vision insurance with comprehensive PPO and HMO plans. And provide flexible personal & sick days. We want our team to be happy and healthy :) We offer a 401k plan to help you plan for retirement. We provide an annual budget for you to spend on education and offer a comprehensive L&D program – after all, one of our core values is that we’re #obsessedwithlearning! We support our employee’s overall health and well-being and reimburse monthly for things such as; Transportation, Home Internet, Meals, and Wellness memberships/equipment. Virtual team building and socials. Keeping people connected is essential. About Affinity We are passionate about helping dealmakers in the world’s biggest relationship-driven industries to find, manage, and close the most important deals. Our Relationship Intelligence platform uses the data exhaust of trillions of interactions between Investment Bankers, Venture Capitalists, Consultants, and other strategic dealmakers with their networks to deliver automated relationship insights that drive over 450,000 deals every month. We have raised over $120M and are backed by some of Silicon Valley’s best firms. With over 1700 customers in 70 countries on our platform, a 4.8 Star Glassdoor rating and being ranked in the Inc. 5000 fastest growing companies, we need more great people to help us scale even more. The more diverse our team is, the more we’ll be able to learn from each other, and the better our company and our product will be. Whatever your gender, race, sexual orientation, religion, age, veteran status, favorite Spotify playlist, or social, cultural, and economic background, we can’t wait to welcome you to Affinity!"
Data Engineer (AWS / TypeScript / Snowflake),Mutual of Omaha,Remote,https://www.indeed.com/rc/clk?jk=7d9453bdb8a910a9&fccid=7f07a4e82fbeccf8&vjs=3,"Location: Various Locations Work Type: Full Time Regular Job No: 500331 Categories: Information Technology, Remote Work, Featured Application Closes: Open Until Filled Mutual of Omaha's Data engineers focus on data warehouses (Teradata / Snowflake), development (TypeScript / Python) and data integration with our next-gen insurance and financial applications as we move to AWS cloud. You will improve how millions of people interact with our products, the way business partners support our customers and use data, as well as explore new technologies to better meet those needs. It’s a mission that takes some serious smarts, intense curiosity and determination to be the best. Come be part of the team who makes it possible. WHAT YOU’LL DO: Research, design, build, optimize and maintain reliable, efficient and accessible data systems, data pipelines, and/or models. Can support, with guidance, the analytic and/or operational use of data. Align closely with Enterprise partners in data science, architecture, governance, infrastructure, and security to apply standards and optimize production environments and practices. Collaborate with business owners to optimize data collection, storage and usage to maximize the value of information within supported systems. Translate business needs into data architecture solutions, designing and implementing in production environments within supported data systems. Implements data orchestration pipelines, data sourcing, cleansing, augmentation and quality control processes within supported data systems. Deploys applications to production in partnership with business units. Develops, tests and integrates new data features and functionality as defined by the product owners and business teams This job posting is reflective of the Engineer I essential functions, qualifications, and physical requirements. The Engineer II level has variable essential functions, qualifications and physical requirements. Competency and skill set will determine level of placement within the posted job family. ABOUT YOU: Professionally impacted solution development and implementation over the last three or more years with: Teradata or Snowflake, Informatica (ETL), Relational Databases, SQL, Multiple Scripting Languages (Unix / Window), API Integration Programming with TypeScript (preferably with CDK), JavaScript or Python Amazon Web Services (AWS) - preferably with Glue and Athena Data Warehouse Design, Data Modeling and Integration Ability to maintain data quality through systematic approaches and methodologies (e.g. MDM) within supported data systems. Understands the Agile mindset and iterative development process You: Help promote a culture of diversity and inclusion within the department and the larger organization Value different ideas and opinions Listen courageously and remain curious in all that you do You are able to work remotely and have access to high-speed internet Located in the United States and territories VALUABLE EXPERIENCE: Informatica Intelligent Cloud Services (IICS) Kafka, MuleSoft Extract, Load, Transform (ELT) Scaled Agile Framework (SAFe) WHAT WE CAN OFFER YOU: A diverse workplace where associates feel a sense of belonging. To learn more about our commitment of Diversity, Equity and Inclusion, please visit our website An organization that feels like a small, close-knit community and has the strength of a Fortune 300 company. Tuition reimbursement, training and career development. Comprehensive benefits plan that includes medical, dental, vision, disability and life insurance. Flexible spending accounts for healthcare and childcare needs. 401(k) plan with a 2% company contribution and 6% company match. Competitive pay with an opportunity for incentives for all associates. Flexible work schedules with a healthy amount of paid time off. For more information regarding available benefits, please visit our Career Site. Estimated Salary: $85,000 - $130,000 Pay commensurate with experience. Recognized as a certified Great Place to Work®. MUTUAL OF OMAHA: Mutual of Omaha serves more than 4.8 million individual product customers and 39,000 employer groups. Our legacy of stability creates an environment where every associate is encouraged to experiment, innovate and grow in their own unique career path. From day one, you’ll have the tools to be your best self at work. Here you’ll do meaningful work and your talents will have a positive impact on peoples’ lives as we help our customers protect what they care about and achieve their financial goals. Each associate is a unique contributor to creating a diverse, dynamic, thriving and inclusive workplace. We want you to become engaged … feel a sense of belonging … and contribute to the company’s exceptional future. For inquiries about the position or application process, contact our HR Helpline at 1-800-365-1405. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at 1-800-780-0304. We are available Monday through Friday 7 am to 4:30 pm CST we will reply within 24 hours. Mutual of Omaha and its affiliates are an Equal Opportunity /Affirmative Action Employer. Qualified applicants will receive consideration without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. To All Recruitment Agencies: We do not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes. Circa Help: 800-365-1405"
Data Engineer *Remote Work*,Genentech,"Remote in New York, NY+4 locations",https://www.indeed.com/rc/clk?jk=bbe0b5a653e7c26e&fccid=2525cc4a9a704809&vjs=3,"THE POSITION This position may be based out of New York, USA, with remote work locations possible in The United States. The Position The Engineering group within Prescient Design seeks exceptional data engineers who have a demonstrated background in software engineering, a passion for technical problem-solving, and a proven ability to realize and deliver scalable data pipelines and infrastructure for modeling molecular data. The group provides a dynamic and challenging environment for cutting-edge, multidisciplinary research including access to heterogeneous data sources, close links to top academic institutions around the world, as well as internal Genentech Research and Early Development (gRED) partners and research units. Our mission is to develop and apply methods in designing novel macromolecules. The Data Engineer will work closely with teams in Structural & Computational Biology and Machine Learning to enable end-to-end data workflows for large-scale data ingestion, processing, analysis, and modeling, including our core machine learning framework. Fundamentally, our engineering and research goals will enable us to collaborate closely with and–contribute uniquely to–many different project teams across the company. The Role Enable cutting-edge research in machine learning and applications to drug discovery, design, and development through the collection, design, and management of data pipelines and infrastructure. You will collaborate closely with cross-functional teams across both Prescient Design and gRED to solve complex problems in the life sciences, including understanding and analyzing algorithm issues. You will interface with other teams at gRED in developing a common data architecture and model and in formalizing best practices. You will be expected to help develop, manage, and scale data pipelines and infrastructure for analysis and modeling in production. You will be expected to solve core engineering challenges including the design and implementation of stable data architecture and models. You will be expected to serve as an expert and resource for multiple, diverse groups at Prescient Design and gRED. Qualifications B.S., M.S., or Ph.D. in Computer Science, Statistics, Applied Mathematics, Computational Biology, Physics, related technical field, or equivalent practical experience. Strong programming skills in languages like C++, Python, Java, Scala, or SQL. Strong experience with data modeling and schema design, including databases and file systems for scientific data Experience with containerization and orchestration tools like Docker, Singularity, Airflow, and Kubernetes. Experience developing and maintaining codebases and software libraries, following industry best practices. Experience with CI/CD and automation tools like Terraform, CloudFormation, Jenkins, and Ansible. Experience with tools and platforms for MLOps like Weights & Biases. Intense curiosity about the biology of disease and eagerness to contribute to scientific and computational efforts. Who We Are Genentech, a member of the Roche group and founder of the biotechnology industry, is dedicated to pursuing groundbreaking science to discover and develop medicines for people with serious and life-threatening diseases. To solve the world's most complex health challenges, we ask bigger questions that challenge our industry and the boundaries of science to transform society. Our transformational discoveries include the first targeted antibody for cancer and the first medicine for primary progressive multiple sclerosis. Diversity and Inclusion (D&I) are critical to the success of our company and our impact on society. We believe that by championing diversity of background, thought and experience, we can foster a sense of belonging and provide an environment where every employee feels valued, included, and able to contribute their best for the patients we serve. We’re focused on attracting, retaining, developing and advancing our people to their full potential by rewarding bold ways of thinking and integrating inclusive behaviors into every aspect of our work. Genentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our Genentech Careers page. RAB-eligible employees For Colorado-based and New York-based applicants, the expected salary range for this position is $163,795.00 - $211,970.00. Actual pay will be determined based on experience, qualifications, and other job-related factors permitted by law. A discretionary annual bonus may be available based on individual and Company performance. This position also qualifies for the benefits listed below. Benefits Roche offers highly competitive benefit plans and programs, including: •Medical, dental and vision insurance •401(k) and 401(k) matching •Paid time off •Roche Long Term Incentive Plan (available at certain position levels) #LI-DC1 Genentech is an equal opportunity employer, and we embrace the increasingly diverse world around us. Genentech prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin or ancestry, age, disability, marital status and veteran status. Genentech requires all new hires to be fully vaccinated against COVID-19 as of their start date. This requirement is a condition of employment at Genentech, and it applies regardless of whether the position is located at a Genentech campus or is fully remote. If you are unable to receive the vaccine due to a disability or serious medical condition, or because it is prohibited as a result of your sincerely held religious beliefs, you will have an opportunity to request a reasonable accommodation. JOB FACTS Job Sub Category Computational Biology Schedule Full time Job Type Regular Posted Date Jun 10th 2022 Job ID 202206-123435"
Staff data Engineer,Gap Inc.,"Pleasanton, CA 94588+2 locations",https://www.indeed.com/rc/clk?jk=2d4e769dd598c21f&fccid=76644a33987f2488&vjs=3,"About Gap Inc. Our brands bridge the gaps we see in the world. Old Navy democratizes style to ensure everyone has access to quality fashion at every price point. Athleta unleashes the potential of every woman, regardless of body size, age or ethnicity. Banana Republic believes in sustainable luxury for all. And Gap inspires the world to bring individuality to modern, responsibly made essentials. This simple idea—that we all deserve to belong, and on our own terms—is core to who we are as a company and how we make decisions. Our team is made up of thousands of people across the globe who take risks, think big, and do good for our customers, communities, and the planet. Ready to learn fast, create with audacity and lead boldly? Join our team. About the Role In this role, you will design highly scalable and high performing technology solutions in an Agile work environment and produce and deliver code and/or test cases using wide-ranging experience, professional concepts, company objectives and Agile practices. You will collaborate closely with key business support teams, product managers, architecture to assist in resolving complex critical cross-team and cross-domain production issues to help simplify and improve business processes through the latest in technology and automation. You are a technical expert and will lead through the requirements gathering, design, development, deployment, and support phases of a product. You will leverage your comprehensive knowledge of domain and core programming technologies or packages to mentor and advise team members. What You'll Do Lead significant projects and define technical specifications and development requirements that result in high performing technology that are also domain specific. Develop and enhance data product independently to solve complex business problems by keeping customer experience at the forefront. Adopt and model a DevOps mindset by applying automation, continuous integration and continuous delivery in everything we do. Foster innovation by applying best practices and learning from emerging data technologies and through collaboration with cross functional stakeholders. Communicate difficult concepts and lead teams through design and interpretation. Mentor and subject matter expert in support of domain areas, leading assignments of diverse scope. Balances project delivery objectives with organizational initiatives. Who You Are Data platform Development experience and knowledge of the data product Delivery Lifecycle, Security Compliance and Agile and SCRUM methodology, industry and competitor practices. Comprehensive knowledge of various software languages and platforms such as SQL, Oracle, Databricks, Azure etc. Expert at leading technical requirements and interpretation of business requirements. Experience with leading significant projects and mentoring teams. Experience with developing teams that are cross functional and include internal and external stakeholders. Qualifications 4+ years of total experience working with data and data pipeline technologies at scale. 3+ years of solid SQL, Oracle development experience – including: Robust unit and integration testing and Git driven CI/CD to production 2+ years of proven experience developing streaming data processing tasks using Databricks and SparkSQL Design and develop data engineering jobs with an eye on quality attributes (and trade-offs) such as simplicity, reliability, scalability, extensibility and performance Benefits at Gap Inc. Merchandise discount for our brands: 50% off regular-priced merchandise at Old Navy, Gap, Banana Republic and Athleta, and 30% off at Outlet for all employees. One of the most competitive Paid Time Off plans in the industry.* Employees can take up to five “on the clock” hours each month to volunteer at a charity of their choice.* Extensive 401(k) plan with company matching for contributions up to four percent of an employee’s base pay.* Employee stock purchase plan.* Medical, dental, vision and life insurance.* See more of the benefits we offer. For eligible employees Gap Inc. is an equal-opportunity employer and is committed to providing a workplace free from harassment and discrimination. We are committed to recruiting, hiring, training and promoting qualified people of all backgrounds, and make all employment decisions without regard to any protected status. We have received numerous awards for our long-held commitment to equality and will continue to foster a diverse and inclusive environment of belonging. This year, we’ve been named as one of the Best Places to Work by the Human Rights Campaign for the seventeenth consecutive year and have been included in the 2021 Bloomberg Gender-Equality Index for the fourth year in a row."
D3 Data Analytics Engineer,Allstate,"Remote in Northbrook, IL+3 locations",https://www.indeed.com/rc/clk?jk=ab8ecd3a3d07e044&fccid=3a71a4d2f7990a25&vjs=3,"The world isn’t standing still, and neither is Allstate. We’re moving quickly, looking across our businesses and brands and taking bold steps to better serve customers’ evolving needs. That’s why now is an exciting time to join our team. You’ll have opportunities to take risks, challenge the status quo and shape the future for the greater good. You’ll do all this in an environment of excellence and the highest ethical standards – a place where values such as integrity, inclusive diversity and accountability are paramount. We empower every employee to lead, drive change and give back where they work and live. Our people are our greatest strength, and we work as one team in service of our customers and communities. Everything we do at Allstate is driven by a shared purpose: to protect people from life’s uncertainties so they can realize their hopes and dreams. For more than 89 years we’ve thrived by staying a step ahead of whatever’s coming next – to give customers peace of mind no matter what changes they face. We acted with conviction to advocate for seat belts, air bags and graduated driving laws. We help give survivors of domestic violence a voice through financial empowerment. We’ve been an industry leader in pricing sophistication, telematics, digital photo claims and, more recently, device and identity protection. We are the Good Hands. We don’t follow the trends. We set them. Compensation offered for this role is and is based on experience and qualifications. The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen. Good Work. Good Life. Good Hands®. As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life - including a generous paid time off policy. For a full description of Allstate’s benefits, visit allstate.jobs/benefits/ Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video. Allstate generally does not sponsor individuals for employment-based visas for this position. Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component. For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance. For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance. To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint. It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment."
Data Engineer,ZineOne,"Milpitas, CA",https://www.indeed.com/rc/clk?jk=0454627118d1dc42&fccid=f6c6952dc69eac33&vjs=3,"Data Engineer What You Will Do Design and implement data pipelines to process clickstream data for building online ML models. Implement, test and deploy scalable big data techniques to transform clickstream data into large-scale encoded and vectorized sequences Own data quality analysis to drive checks and improvements in data pipeline processing Collaborate with data scientists to train and evaluate new and existing models using RL, DL and GBMs. Improve automation and operations for model training, scoring and performance measurement using MLOps platform Represent data engineering within the Data Science team to ensure ML models maintain high quality implementations that are repeatable, performant, efficient and measurable Innovate to address new customer use cases in target or new industries, and contribute to expand our ML model portfolio Qualifications Bachelor's Degree or higher in Computer Science, Data Science or similar area 3+ years of hands-on data engineering experience implementing data pipelines and machine learning ideally in Retail, QSR or Finance Experience working with customers and in the software engineering process for delivering large scale and quality applications. Strong knowledge of big data techniques including the Hadoop/Hive ecosystem, distributed data processing, message queues, high-performance databases (columnar, sharding, etc.), and massive parallel processing and micro-batch processing engines such as Apache Spark. Experienced in statistics & analytical modeling, time-series data analysis, forecasting modeling, machine learning algorithms, and deep learning approaches and frameworks. Have a proven track record of delivering robust, scale and quality data analytical applications in a cloud environment. Comfortable working with a high performance, geographically distributed team with members in the US as well as overseas locations (India, Canada). Possess excellent communication skills and cross-team collaboration skills to effectively share customer needs across sales, customer success, and engineering."
Firmwide Data Management - Data Use Engineer - Associate,"JPMorgan Chase Bank, N.A.","Newark, DE 19713",https://www.indeed.com/rc/clk?jk=639ee0e4baccf0cf&fccid=aaf3b433897ea465&vjs=3,"Firmwide Data Management ('FDM') serves as the governing body to create firmwide standards that drive consistent data management practices, develop technologies and processes to support data management priorities, and partner with Lines Of Business ('LOBs') to embed data management best practices and capabilities. Within FDM, the Data Use team was established in response to the emerging risk of data use, and focuses on initiatives that enhance and protect the value of JPMC's data in the rapidly evolving \""Big Data\"" economy. Role Description This role involves substantial cross business interaction and a strong risk and control mind set. The immediate focus for this candidate will be to collaborate with the FDM and product teams in implementation of new strategic initiatives aligned to our maturing capability and in response to new Policy and Standard requirements. Responsibilities: Support data use governance by assisting in the development and socialization of enterprise governance documents, including the Firmwide Data Use Guidelines, the Firmwide Data Use Standards, and Data Use Policy Implementation Support the data use case life cycle operations as related to Corporate data use cases Develop education and training materials to raise awareness of data use risks Gather, analyze and validate indicators of performance and quality metrics and ensure compliance with data related policies, standards, roles and responsibilities, and adoption requirements The role will require working on multiple projects & strategic initiatives simultaneously. Develop Partnership Develop mutually beneficial relationships across business lines Influence without direct authority to drive governance approach alignment Qualifications 2 - 5 years of experience in or related to technology with demonstrated appreciation and aptitude for supporting complex projects within a business to business environment with sophisticated stakeholders. Bachelors degree preferred or equivalent experience Knowledge and practical understanding of a broad set of products and processes. Competencies in use of MS Office Suite or equivalent, documentation of process flows, build presentations and basic analysis Must be controls-minded; experience with a Business or Tech Controls function a plus. Demonstrated ability to interact and work effectively with senior management and other stakeholders to support the goals of the business. Effective influencing and persuasion skills with groups not directly working for you; ability to build consensus. Excellent verbal, written, presentation and communication skills. High tolerance for ambiguity matched with desire to create structure and drive results. Demonstrated interest in emerging technology and ""Big Data"" in the financial services industry. Hands on data experience which may include experience with SQL or BI reporting a Plus JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management. We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs. The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment. As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law. Equal Opportunity Employer/Disability/Veterans"
Data Engineer,Bloomberg BNA,"Arlington, VA 22202 (Aurora Highlands area)",https://www.indeed.com/rc/clk?jk=3137a42bd9974b6a&fccid=1184ecce6b1e770e&vjs=3,"Full time Bloomberg Industry Group runs on data. As the Commercial Analytics team, we are responsible for driving analytics throughout the organization to improve our products, engage better with our customers, create greater efficiencies, and drive new businesses by providing data insights. Our data captures the who, what, when, where and why of how our company goes to market. Senior business leaders rely on our work every day to make strategic decisions. What you will do: Work with senior business stakeholders to break down business problems and design analytics solutions. Provide technical leadership to drive best practices for data modeling, ETL, and data quality. Design and build data pipelines to enable decision making through analytics. Develop automated solutions to replace manual data processes. Refine and enhance reporting data models. Act as a champion for data quality by proactively identifying data quality issues and coordinating with system owners to resolve issues quickly. Build relationships with senior business leaders to gather requirements and evangelize data analytics best practices. You need to have: 6+ years of hands-on development experience with SQL and an ETL tool. Alteryx is preferred, but any similar tool can be considered. Advanced SQL capabilities are required. Knowledge of database design techniques and experience working with extremely large data volumes is a plus. Strong understanding of data warehousing methodologies, ETL processing and dimensional data modeling. Programming experience in Python. Knowledge of reporting tools such as QlikSense, Tableau, or Power BI is a nice to have. Bachelors degree in a financial or technical field, or equivalent work experience. Master’s degree is a plus. Bloomberg Industry Group IS AN EQUAL OPPORTUNITY EMPLOYER and fully subscribes to the principles of Equal Employment Opportunity. Bloomberg Industry Group has adopted an Affirmative Action Program to ensure that all applicants and employees are considered for hire, promotion, and job status without regard to race, color, religion, sex, national origin, age, disability, gender identity, sexual orientation, marital or familial status, pregnancy, childbirth, or related medical issues, genetic information, disabled veteran, veteran, a veteran of the Vietnam Era, or any other classification protected by law. INDG requires all employees to be fully vaccinated for COVID-19 as a condition of employment. Prospective and/or new employees will be required to adhere with INDG's vaccination policy. All INDG employees must be fully vaccinated and they must submit proof of vaccination on their first day of employment. Prospective or new employees may seek a medical or religious exemption to the vaccination requirement but must have an approved exemption prior to the start of their employment."
Senior Mechanical Computer Aided Design Data Center Engineer,Google,"Sunnyvale, CA (Lakewood area)",https://www.indeed.com/rc/clk?jk=16f082c6480c2d26&fccid=a5b4499d9e91a5c6&vjs=3,"Minimum qualifications: Bachelor's degree in Engineering or equivalent practical experience. 10 years of experience with mechanical design and documentation using 3D CAD tools. Experience in developing product models/ documentation from inception to production release with revision management and with mechanical geometric dimensioning and tolerancing. Experience with Dassault Systems 3DExperience platform, Solidworks, and Catia. Preferred qualifications: Certified SOLIDWORKS Expert. Experience in designing complex modular building scale assemblies. Experience with other 3D CAD systems such as Autodesk Revit and Inventor. Knowledge of mechanical engineering and design principles with specific expertise in the areas of design for medium-scale production, structural beams/elements, manufacturing, and international building codes. About the job Our thirst for technology is a part of everything we do. The Data Center Engineering team takes the physical design of our data centers into the future. Our lab mirrors a research and development department - cutting-edge strategies are born, tested and tested again. Along with a team of great minds, you take on complex topics like how we use power or how to run state-of-the-art, environmentally-friendly facilities. You're a visionary who optimizes for efficiencies and never stops seeking improvements - even small changes that can make a huge impact. You generate ideas, communicate recommendations to senior-level executives and drive implementation alongside facilities technicians. With your technical expertise, you ensure compliance with codes and standards, develop infrastructure improvements and serve as an expert in your specialty (e.g., cooling, electrical). Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible. Responsibilities Develop models for data center infrastructure products and systems from inception to production release. Implement technical designs for new services and modify existing services in accordance with design, transition, and change management policies and procedures. Conduct routine systems maintenance, monitoring, and systems administration tasks to support the daily operations of the system-wide infrastructure. Maintain detailed documentation of all managed systems, act as the Engineering teams advocate for initiatives, and assist with setting up file structures and nomenclature standards. Implement, maintain, and manage future direction of multiple divisions, conduct training for divisions on various topics and develop and improve workflows and CAD processes to accommodate Design Engineering and other groups' needs. Improve efficiency and communication. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form."
Data Engineer,Capital Group,"Hybrid remote in San Antonio, TX 78251+7 locations",https://www.indeed.com/rc/clk?jk=ac5e2d619bd20544&fccid=a892c8c946e25608&vjs=3,"Req ID: 52441 Location: San Antonio Other location(s): San Antonio (TX) “I can be myself at work.” You define yourself by more than just a job title, and we want you to feel comfortable bringing your true self to work. We value your talents, your traditions and your take on the world ̶ everything that makes you unique. We’re working hard to advance diversity, equity and inclusion in our organization and our communities because we know that what makes us different makes us better. We want you to feel a strong sense of belonging. We value and welcome your experiences, ideas and identity. Over 40 employee resource groups unite our people and help to develop our collective empathy through unfiltered conversations about race, ethnicity, gender, gender identity, sexual orientation, faith, disabilities, mental health and so much more. “I can influence my income.” You want to feel recognized at work. Your performance will be reviewed annually, and your compensation will be designed to motivate and reward the value that you provide. You’ll receive a competitive salary, bonuses and benefits. Your company-funded retirement contribution will be the equivalent of 15% of your annual pay (including bonuses). “I can lead a full life.” You bring unique goals and interests to your job and your life. Whether you’re raising a family, you’re passionate about where you volunteer, or you want to explore different career paths, we’ll give you the resources that can set you up for success. Enjoy generous time-away and health benefits from day one, with the opportunity for flexible work options Receive 2-for-1 matching gifts for your charitable contributions and the opportunity to secure annual grants for the organizations you love Access on-demand professional development resources that allow you to hone existing skills and learn new ones “I can succeed as a Data Engineer at Capital Group.” As a Data Engineer, you will contribute to the creation of a best-in-class DataOps function to support a data supply chain that provides for Capital’s data and analytics needs across its lines of business. You will contribute to defining data operations processes and support model, work with complex data pipelines, big data platforms hosted in the cloud, and provide innovative ways to operate and support complex data delivery solutions. You will also contribute to our goal of operational excellence through leadership, rigorous analysis, continuous improvement, and contribute to enhancement decisions that reduce friction and increase reliability, while developing a thorough understanding of standards and best practices used by your team. “I am the person Capital Group is looking for.” You have a bachelor’s degree in Computer Science, Mathematics, Statistics, or other technical field You have at least 5 years of experience in Data Engineering You have advanced quantitative experience such as business intelligence, big data platforms, reporting, analytics, machine learning, and database development, which demonstrate your ability to support and operate complex technical solutions You have demonstrated experience in leading projects across multiple teams You have advanced knowledge of technical and functional designs for SQL, databases, ETL, data pipelines, data warehousing, data lakes, and data modeling You have experience with data analysis utilizing SQL and technologies such as R, Python, Tableau or Alteryx You have demonstrated understanding of Hadoop/Spark or other big data solutions You have demonstrated understanding of Microsoft Azure, AWS or other cloud platforms You have ability to learn new technologies and business areas quickly to provide informed guidance to our business partners “I can apply in less than 4 minutes.” You’ve reviewed this job posting and you’re ready to start the candidate journey with us. Apply now to move to the next step in our recruiting process. If this role isn’t what you’re looking for, check out our other opportunities and join our talent community. “I can learn more about Capital Group.” At Capital Group, the success of the people who invest with us depends on the people in whom we invest. That’s why we offer a culture, compensation and opportunities that empower our associates to build successful and prosperous careers. Through nine decades, our goal has been to improve people’s lives through successful investing. We know that our history is a testament to the strength of the people we hire. More than 7,800 associates in 30+ offices around the world help our clients and each other grow and thrive every day. Find us on LinkedIn, Glassdoor, FairyGodBoss, DiversityJobs and Instagram. We are an equal opportunity employer, which means we comply with all federal, state and local laws that prohibit discrimination when making all decisions about employment. As equal opportunity employers, our policies prohibit unlawful discrimination on the basis of race, religion, color, national origin, ancestry, sex (including gender and gender identity), pregnancy, childbirth and related medical conditions, age, physical or mental disability, medical condition, genetic information, marital status, sexual orientation, citizenship status, AIDS/HIV status, political activities or affiliations, military or veteran status, status as a victim of domestic violence, assault or stalking or any other characteristic protected by federal, state or local law. #LI-Hybrid"
Data Engineer,Ascent360,Remote,https://www.indeed.com/rc/clk?jk=e3f812e52ccfda7a&fccid=0b9605374f662bfa&vjs=3,"Ascent360 is seeking a Data Engineer to join our growing team of professionals. This individual will work with the Senior Database Architect and other developers to build core data systems to support the Ascent360 product and business. Essential Functions: Adapt existing data systems & processes to new technology solutions Develop scalable data pipelines and support data processes Learn new technologies to build the best solutions possible Take requirements created by the business teams to build Education & Experience: Bachelor’s Degree in Computer Science, or other related field or equivalent experience. 5+ years experience delivering real-world data solutions 2+ years experience with Python, Spark or PySpark Beneficial Experience: Cloud platforms like Azure or AWS Experience with Databricks or similar cloud-based products Relational database systems like SQL Server & PostgreSQL Azure Data Lake Storage, Delta Lake, or similar solutions Other open source NoSQL technologies *Critical features of this job are described herein. They may be subject to change at any time due to reasonable accommodation or other reasons. Compensation and Benefits: Competitive base salary and equity in our high growth SaaS company Benefits – Medical, dental, vision, retirement matching, flexible PTO + paid holidays, gym & gear discounts About Ascent360 and Why Us? At Ascent360, our mission is simple; to help B2C companies develop authentic, lifelong relationships with their customers. We are a cloud based data driven marketing platform that enables highly targeted, omni-channel marketing engagement direct to customers and prospects. We work with over 100 different brands, retailers, and resorts to integrate all relevant data sources, providing a real time, 360 degree view of their customer, allowing for needle moving marketing campaigns. Based in Denver, CO, Ascent360 supports work from home and hires locally as well as throughout the United States. With flexible PTO, flexible work hours and great benefits, we truly believe in a healthy work-life balance. We are privileged to work with clients you know and love from industries like retail, resort and outdoor & active lifestyle. At Ascent360 we work and function as a team and each day live and breath our core values. To apply: Data Engineer"
"Software Engineer, Data",System1,+2 locationsRemote,https://www.indeed.com/company/System1/jobs/Software-Engineer-1bcd1eea16100309?fccid=0471f3a5f9f7f44f&vjs=3,"System1 is looking for engineers with production data experience to join the Data Engineering team. This team is the horizontal layer that supports business intelligence, optimization, machine learning, and external & internal reporting. We process and report on billions of events and user attributes per day, gathered from an extremely heterogeneous and large set of data streams. Our bread and butter is Python. We utilize a range of technologies including AWS SNS, SQS, EC2, S3, Secrets Manager, Redis, Apache Airflow, Docker, Flask, as well as PostgreSQL and Snowflake for our data warehousing.What You Can Expect on the Team Prototype, develop, optimize, and expand an ecosystem of services that work with data: backend services for retrieving, managing, and monitoring data; streaming and batch data processing; frameworks for data ingestion Evaluate, recommend, and perform proof-of-concepts for new services and frameworks Guide architectural design, anticipating needs and highlighting tradeoffs in performance and functionality Participate in peer code reviews and produce high quality documentation Take projects through the full engineering lifecycle: designing, ticketing, building, testing, deploying, and debugging tools and products Help grow a team and work with a tight knit group of engineers and data stakeholders Flexibility in working with different teams, products, and their data needs What You Will Bring Bachelor’s in Computer Science or equivalent professional experience Strong experience with Python development Demonstrated experience working and reasoning with large datasets (Experience with PostgreSQL and Snowflake a plus) Experience developing backend APIs in a python framework (Experience with Flask a plus) Understanding of NoSQL datastores like DynamoDB and Redis Experience with Linux and the AWS ecosystem Experience with Docker a plus Experience with Airflow a plus What We Have to Offer Competitive PTO 11 Company Holidays Untracked sick time 100% covered Medical, Dental, Vision for employees 401k w/match Paid professional development Leadership & growth opportunities Virtual company and team building events #BI-Remote #LI-Remote Job Type: Full-time"
Data Engineer,USI Holdings Corporation,Remote,https://www.indeed.com/rc/clk?jk=6bce3d5aedeca3f3&fccid=1799f789a0c53bdc&vjs=3,"General Description: Responsible for expanding, optimizing, and monitoring data collection, data flows and datasets. Partner with data scientists and analysts on transforming, consolidating, integrating, and cleaning data. Support our next generation of products and data initiatives. Responsibilities: Build and maintain data pipelines and datasets for data science and analytics projects. Drive initiatives to analyze and acquire free and paid data from third parties. Collaborate with data science and data services teams to develop best practices. Includes data ingestion, dataset creation, storage and updates, naming conventions and retention. Work with stakeholders on data-related technical issues and data infrastructure needs. Implement methods to improve data reliability and quality. Partner with data and analytics experts to improve functionality in data systems. Assemble large and complex data sets that meet functional/non-functional business requirements. Identify, design, and implement internal process improvements. Includes automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability. Support data governance activities. Monitor and report on data lineage and data quality. Strong technical writing skills. Ability to work in a team environment. Knowledge, Skills and Abilities: Bachelor’s degree or equivalent experience in Computer Science, Statistics, or related field. 2 years + Python programming experience. Jupyter notebook experience a plus. 2 years + SQL programming, SQL database design, and data architecture concepts. 1 year + experience working with scrum agile processes. Azure Devops preferred. Technical expertise with data models, data mining, and data warehousing. Experience with Microsoft Azure components. Includes DevOps, ADLS, Databricks, ADLS, CosmosDB, ML Services or equivalent cloud resources. Broad working knowledge of insurance brokerage or sales workflows and systems preferred. Self-motivated. Comfortable managing needs of multiple teams, systems, and products. Physical Demands: Work is performed in a climate-controlled office environment with minimal noise and limited to no exposure to chemicals or toxins. Employees operate office equipment including telephone - headset, Computer, computer monitors, keyboard, mouse, copier, scanner, and mail machine. Physical tasks of job include walking, sitting, standing, and bending. Analysis of Physical Demands: Constantly (over 66% of time) work performed requires employees to use repetitive hand motions such as typing, using a keyboard, and sitting at a desk. Frequently (34%-66% of time) work performed requires employees to handle and grasp things, walk on normal surfaces, stand, bend and travel to various USI offices. Occasionally (1%-33% of time) work performed requires employees walk on uneven or slippery surfaces to and from work and occasionally reach outward to grab things and bend. Rarely (< than 1 hour per week) work performed requires lifting/carrying items that range from 10-50lbs, pushing/pulling items that range from 10-50lbs, twisting/ turning including reaching over shoulder or above head, kneeling or squatting. USI is committed to providing a full-suite of competitive benefits for our growing population and its diverse needs. We offer a wide range of health, welfare and financial benefits including medical, wellness, dental and vision, 401(k), flexible spending and health savings accounts, short and long-term disability, life insurance and other unique employer-sponsored and voluntary programs. USI also offers a generous paid time off policy, paid family leave benefit as well as paid holiday time. Job ID: 24360"
Data Scientist/ Engineer,University of Colorado,"Aurora, CO 80045 (Fitzsimons area)",https://www.indeed.com/rc/clk?jk=399002e7720b2bd2&fccid=e370394a608927d2&vjs=3,"Data Scientist/ Engineer - 25870 Faculty Description University of Colorado | CU Anschutz Medical Campus School of Medicine - The Department of Pediatrics, Kempe Center for the Prevention of Child abuse and Neglect Working Title: Data Scientist/ Engineer Position #793111 – Requisition #25870 Applications are accepted electronically ONLY at www.cu.edu/cu-careers The University of Colorado has a requirement for COVID-19 vaccinations and full completion thereof by 9/1/21 or upon start date. Information regarding this requirement, and exemptions can be found at: Anschutz: https://www.ucdenver.edu/docs/librariesprovider284/default-document-library/3000-general-admission/3012-covid-19-vaccination-requirement-and-compliance.pdf?sfvrsn=4e9df3ba_2 Denver: https://www.ucdenver.edu/coronavirus Exemptions vary by campus location/department. Campus/Unit-Specific Exemptions: Anschutz Campus – Exemptions are allowed for medical or religious reasons. Denver Campus - Exemptions are allowed for medical, religious, or personal reasons. Consolidated/Central Services Administration – Will follow Anschutz policy on exemptions. The University of Colorado Anschutz Medical Campus seeks individuals with demonstrated commitment to creating an inclusive learning and working environment. We value the ability to engage effectively with students, faculty and staff of diverse backgrounds. The University of Colorado Anschutz Medical Campus is a world-class medical destination at the forefront of transformative science, medicine, education and patient care. The campus encompasses the University of Colorado health professional schools, more than 60 centers and institutes, and two nationally ranked independent hospitals - UCHealth University of Colorado Hospital and Children's Hospital Colorado - that treat more than two million adult and pediatric patients each year. Innovative, interconnected and highly collaborative, the University of Colorado Anschutz Medical Campus delivers life-changing treatments, patient care and professional training and conducts world-renowned research fueled by over $650 million in research grants. For more information, visit www.cuanschutz.edu. Nature of Work: The University of Colorado Denver - Anschutz Medical Campus is seeking applications for a Data Engineer/Scientist. This is a full-time position that will support the Kempe Center for the Prevention of Child Abuse and Neglect. While this position is considered an Instructor rank by the university, there are no teaching duties associated with the position. Kempe is a world leader in the prevention and treatment of child abuse and neglect. We bring together leading research and treatment professionals, policy makers and community members to make sure every child has the opportunity to develop and grow in a safe, healthy, and nurturing environment. The Kempe Center research and evaluation group (clinical and systems) utilizes administrative data extensively to support several initiatives, many of which are supported by child welfare agencies, and UC Health and Children’s Hospital, but also from other jurisdictions and to support other research collaborations in the US and other countries (Canada and Germany among them). Each of these often require bespoke requests to the data provider organization involving multiple steps including approvals, query programming, data quality checks, data exchanges, data linkage across systems, and data analytics. The Kempe Center is also in need of this capacity to support longer term research infrastructure development (e.g., data warehousing), and as part of the basis for research and evaluation funding. These functions and others are often described as “big data” and have become part of the landscape for academic research centers. This data engineer/scientist position is intended to support both the research and organizational needs for informatics to inform program development, and decision making. The incumbent will need to have well developed programming skills and be able to prepare and implement data queries. A critical component of the job functions will be to implement and maintain ongoing analytic data management of data sets including quality assurance. The incumbent will also need to have knowledge of and experience using child welfare systems, and be conversant with how data available from such systems are organized. Corresponding familiarity with health care data sets is also desirable, and their use will be an ongoing aspect of the job expectations. Finally, the incumbent will need to provide user training in for data products and processes. The University of Colorado and the Kempe Center are dedicated to initiatives concerning equity, diversity, inclusion and justice (EDIJ) within the Center, as well as impacting these issues through our research, programming and in the community at large. The data engineer/scientist can support these efforts as the Kempe Center conducts research and evaluation aimed at the safety and well-being of children of all backgrounds and identities. Further, the data engineer/scientist will have an opportunity to develop and contribute to the knowledge base of methods for “big data” use and analysis which do not reinforce existing disparities present in child and family serving systems. All aspects of work will require collaboration with the internal Kempe faculty and staff, School of Medicine IT staff, and our agency partners necessitating the application of team building skills. Examples of Work Performed: Develop data products (e.g., dashboards) that could be shared, especially with our child welfare agency collaborators, and potentially shared via the Kempe website as a resource for the state. Link complex datasets at the case or person level across data sources; for example, case information of children who received medical evaluations for abuse/neglect from CARE Network designated providers with child welfare administrative case data and/or electronic health records data from Health Data Compass datasets with reports of abuse/neglect in child welfare administrative data. Ensure routine access to Colorado Department of Human Services child welfare administrative data and integration with the Child Welfare Training System Learning Management System, to yield the capacity to assess impacts from a range of staff development services, by linking the staff development services to performance information (productivity, case outcomes, etc.) available through child welfare administrative data. Support epidemiologic studies using child maltreatment administrative data (child welfare and health data). Provide supports to research teams working with administrative data from a range of jurisdictions/sources (i.e. various systems, states, countries). Provide supports to research teams working with administrative data from a range of jurisdictions/sources (i.e. various systems, states, countries). Salary and Benefits: The salary range (or hiring range) has been established at $70,000 to $90,000 The salary of the finalist(s) selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. The above salary range (or hiring range) represents the University’s good faith and reasonable estimate of the range of possible compensation at the time of posting. Your total compensation goes beyond the number on your paycheck. The University of Colorado provides generous leave, health plans and retirement contributions that add to your bottom line. Benefits: https://www.cu.edu/employee-services/benefits Total Compensation Calculator: http://www.cu.edu/node/153125 Diversity and Equity: The University will provide reasonable accommodations to applicants with disabilities throughout the employment application process. To request an accommodation pursuant to the Americans with Disabilities Act, please contact the Human Resources ADA Coordinator at hr.adacoordinator@ucdenver.edu. The University of Colorado Denver | Anschutz Medical Campus is committed to recruiting and supporting a diverse student body, faculty and administrative staff. The university strives to promote a culture of inclusiveness, respect, communication and understanding. We encourage applications from women, ethnic minorities, persons with disabilities, persons within the LGBTQ+ community, and all veterans. The University of Colorado is committed to diversity and equality in education and employment. The University of Colorado Denver | Anschutz Medical Campus is dedicated to ensuring a safe and secure environment for our faculty, staff, students and visitors. To assist in achieving that goal, we conduct background investigations for all prospective employees. Qualifications Minimum Qualifications: 2 years experience working with large, complex datasets. Master’s degree in relevant field, including but not limited to MA, ME, MS, MPH. At least 1 year experience cleaning/organizing data for analysis. Required: Applicants must meet minimum qualifications at the time of hire Conditions of Employment: Must successfully pass a drug test through Children’s Hospital Colorado Must be willing and able to pass a national criminal background check Preferred Qualifications: Proficiency in SQL coding for data management and extraction, as demonstrated by coursework, examples of coding projects or other documentation. Prior work with a social or human service delivery system. Experience developing and implementing quality assurance methods. Experience developing and implementing at least one data use/sharing agreement. Competencies: Strong organizational, leadership, and time-management skills to help develop and grow Kempe’s administrative data research program over time. Ability to effectively communicate with providers and external organizations, and other faculty Ability to manage, multiple tasks, timelines, and resources. Ability to run Zoom and other virtual platforms to perform meetings and trainings. Ability to use Excel, PPT, Microsoft Office, and project management tools. Understanding of and commitment to principles of data analysis related to disparities and intersectionality; demonstrated commitment and leadership ability to advance diversity and inclusion. Ability to communicate effectively with professional, administrative and other personnel; to effectively present information both orally and in written form in the office setting as well as outside the Center. Ability to perform with a high degree of independent action and to prioritize a high volume of work to achieve a high level of productivity and accuracy. Efficiently construct/format/link datasets to prepare for analysis. Possess expertise using relational databases. Proficient in one or more of the following: a statistical package (Stata, SAS or R), data visualization (e.g. Tableau and/or infographics), predictive modeling (e.g. logistic regression, tree-based models). Special Instructions to Applicants : Review of applications will begin immediately and will continue until the position is filled. Application Materials Required : Cover Letter, Resume/CV, List of References Application Materials Instructions : Required Application Materials: To apply, please visit: http://www.cu.edu/cu-careers and attach: 1. A letter of application which specifically addresses the job requirements and outlines qualifications 2. A current CV/resume 3. List of three to five professional references (we will notify you prior to contacting both on and off-list references) Please be advised that the University does check references as part of the employment process. Please do not submit any of your application material (via email) to the job posting contact. Job Category : Faculty Primary Location : Aurora Department : U0001 - DENVER & ANSCHUTZ MED CAMPUS - 20932 - SOM-PEDS Kempe-GenOps Schedule : Full-time Posting Date : May 5, 2022 Unposting Date : Ongoing Posting Contact Name : Michele Bugos Posting Contact Email : Michele.bugos@cuanschutz.edu Position Number : 00793111"
Data Analytics Engineer,Pattern Energy Group LP,"Houston, TX 77002 (Downtown area)+1 location",https://www.indeed.com/rc/clk?jk=290190a49112c613&fccid=7b28733b7afedc61&vjs=3,"Overview: Company Overview Pattern Energy Group is an independent, fully integrated energy company that develops, constructs, owns and operates renewable energy projects and transmission assets across North America, Japan, and parts of Latin America. The company focuses primarily on wind, solar and transmission. The Pattern Energy Group team has a history as one of the top North American renewable energy and transmission providers in the industry. The team is dedicated to delivering the highest value for its customers, partners, financial supporters and the communities in which it works, while exhibiting a strong commitment to promoting environmental stewardship and corporate responsibility. Pattern Energy Group operates in the United States, Canada, Japan, the Netherlands, and Mexico with offices in San Francisco, Houston, San Diego, New York, Tokyo, Amsterdam, and Toronto. Pattern Energy Group’s corporate headquarters is in San Francisco. Responsibilities: Job Purpose The primary purpose of the Data Analytics Engineer is to oversee the development and automation of business intelligence tools that highlight key performance indicators for the Pattern fleet, including downtime, turbine availability, lost energy & lost revenue calculations, as well as to support the Operations team through various analytics, data engineering & science approaches. This role requires cross functional interaction across the company, while managing the oversight of multiple data platforms & software. This role will develop an understanding of how renewable systems function and develop the skills to assess performance, energy market trends, and equipment reliability issues. Key Responsibilities The key responsibilities will include the following: Work in cross functional teams to and develop analytics tools, reports, and dashboards that will be used across all business units to provide insight into operational performance metrics and KPIs. Master domain knowledge to design data sets and/or tabular models that incorporate a variety of technical, energy market, and financial related data. Monitor data quality of front-end facing tools, respond to discrepancies, troubleshoot, and resolve issues in a timely manner by identifying the root cause and providing a solution. Document published content and maintain a repository for informational training material and self-service knowledge sharing to build transparency and trust within the user base. Collaborate with team members on data ETL/ELT, cloud-based data management, data science visualizations, and internal software support related to fleet performance. Act as a subject matter expert for customers by maintaining and providing continuous support and training on published/productionized reporting tools. Perform ad hoc studies as needed relating to fleet performance, energy markets, engineering, and/or meteorology. Qualifications: Education/Experience/Qualifications Required Educational Experience A bachelor’s degree in computer science, mathematics/statistics, physics, or engineering OR demonstration of equivalent work experience is required as a minimum. Work Experience 2+ years of experience in computer programming, advanced data analysis automation or math and science equivalent (College Work, internships or part time work may qualify) Data Engineering and/or Data Science background preferred but not required. Wind power operations or Electric Utility operations preferred but not required Additional Qualifications Strong technical capabilities and a creative, curious, self-driven work ethic Ability to work well in and/or lead cross functional teams Ability to travel (Up to 10% travel) Technical Skills Highly proficient with BI visualizations and reporting tools primarily in Power BI, Power BI Report Builder, Logic Apps, and Power Automate. Experience designing, developing, and implementing tabular data models and complex SQL scripts. Experience with cloud storage, computing, and processing in Microsoft Azure, Data Factory, and/or Databricks. Familiar with data science visualization tools such as R Shiny and Plotly. Ability to organize requirements and listen to customer needs while balancing a back log of priorities and projects. Demonstrated programming skills with software applications, databases, and historians. Demonstrated excellence and ability to learn new programming skills and languages. Familiarity with SCADA systems (particularly in electrical utility applications). Data Science knowledge in Python, R, Matlab or other statistical based languages. Ability to read and understand plans, specifications, drawings, and documents relating to computers and data systems. Ability to quickly assess emergency situations and requirements and to develop and implement appropriate action plans. Ability to occasionally perform physical requirements including standing, sitting, walking, kneeling, twisting, reaching, and climbing at project locations in order to install or inspect equipment. Pattern Energy Group is an Equal Opportunity Employer. #LI-SJ1"
Data Engineer,Savista,Remote,https://www.indeed.com/rc/clk?jk=da13cf6d60bc2810&fccid=9d8d0921e436777e&vjs=3,"Here at Savista, we enable our clients to navigate the biggest challenges in healthcare: quality clinical care with positive patient experiences and optimal financial results. We partner with healthcare organizations to problem solve and deliver revenue cycle improvement services that enable their success, support their patients, and nurture their communities, all while living our values of Commitment, Authenticity, Respect and Excellence (CARE). The Data Engineer is responsible for driving positive change within Service Solutions by working on the ETL process, data warehouse, and reporting platforms. This position will work closely with project managers, visualization developers, technology solution developers, and IT. Essential Duties & Responsibilities: Create and maintain complex stored procedures using TSQL. Design and build ETL solutions against various data sources. Monitor and perform troubleshooting on ETL processes and resolve issues effectively. Ensure accuracy of monthly reporting of the key performance metrics for executive meetings. Interface with project managers, visualization developers, technology solution developers, and operations leaders to gather source to target data mapping. Demonstrates integrity and ethics in day-to-day tasks and decision making, adheres to Savista’s core values of courage, authenticity, respect, excellence, and service, operates effectively in Savista’s environment and the environment of the work group, maintains a focus on self-development and seeks out continuous feedback and learning opportunities. Minimum Qualifications & Competencies: Bachelor‘s degree or equivalent in technology, MIS, or equivalent work experience. 2 years of work experience writing and maintaining complex stored procedures in TSQL. 2 years of work experience in developing and deploying ETL solutions. Expertise in at least 2 of: SQL Server Integration Services, SQL Server Administration, Azure Data Factory, DataBricks. Expertise in capturing, analyzing, and communicating root causes of ETL issues. Knowledge of data warehouse and ODS and ability to implement. Knowledge of a ticketing system and its processes. Knowledge of IT infrastructure and change control process. Strong time management and project management skills. Proficiency in using data and analytic technologies including Microsoft Office tools and SQL and data visualization tools. Preferred Qualifications: Experience with Azure cloud data stores Experience with C#, Python, and rest API Experience with Scrum or Kanban Familiarity with PowerApps Experience in the healthcare industry, specifically Revenue Cycle Management Physical Demands: The physical demands and work environment characteristics described here are representative of those that an employee must meet to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Physical Demands: the employee is occasionally required to move around the work area; sit; perform manual tasks; operate tools and other office equipment such as computer, computer peripherals and telephones; extend arms; kneel; talk and hear. The employee must occasionally lift and/or move up to 15 pounds. Mental Demands: the employee must be able to follow directions, treat others with respect, and address stressful situations in a positive manner. Work environment: minimal noise level in the work environment. SAVISTA is an Equal Opportunity Employer and does not discriminate against any employee or applicant for employment because of race, color, age, veteran status, disability, national origin, sex, sexual orientation, religion, gender identity or any other federal, state or local protected class."
Senior Data Engineer,Spring Health,"Remote in New York, NY 10003",https://www.indeed.com/rc/clk?jk=8152c54e0ad56b75&fccid=675ee465d3812bad&vjs=3,"Our mission: to eliminate every barrier to behavioral health. Spring Health is a comprehensive mental health solution for employers and health plans. Unlike any other solution, we use clinically validated technology called Precision Mental Healthcare to pinpoint and deliver exactly what will work for each person — whether that’s meditation, coaching, therapy, medication, and beyond. Today, Spring Health serves more than 200 companies, from start-ups to multinational Fortune 500 corporations, and is a preferred mental health provider to companies like General Mills, Guardian, Bain, and Instacart. We have raised over $300 million from prominent investors including Kinnevik, Tiger Global, Northzone, RRE Ventures, Rethink Impact, Work-Bench, William K Warren Foundation, SemperVirens, Able Partners, True Capital Ventures, and a strategic investor, Guardian Life Insurance. Thanks to their partnership, our current valuation has reached $2 billion. Our mission: to eliminate every barrier to mental health. Spring Health is a comprehensive mental health solution for employers and health plans. Unlike any other solution, we use clinically validated technology called Precision Mental Healthcare to pinpoint and deliver exactly what will work for each person — whether that’s meditation, coaching, therapy, medication, and beyond. Today, Spring Health serves more than 200 companies, from start-ups to multinational Fortune 500 corporations, and is a preferred mental health provider to companies like General Mills, Guardian, Bain, and Instacart. We have raised over $300 million from prominent investors including Kinnevik, Tiger Global, Northzone, RRE Ventures, Rethink Impact, Work-Bench, William K Warren Foundation, SemperVirens, Able Partners, True Capital Ventures, and a strategic investor, Guardian Life Insurance. Thanks to their partnership, our current valuation has reached $2 billion. We are looking for a Senior Data Engineer to join our team. You will help to define our product and engineering roadmaps and work as a part of a cross-functional product team to find elegant solutions to mental healthcare’s many problems. We are an award-winning, passionate, and mission-driven team with the support of leaders in psychiatry, and backed by prominent VCs including Rethink, RRE, and General Catalyst. About the Role At Spring Health we believe that data-driven technology and decision making is a critical part of solving the thorny, complex challenges of provider quality and accessibility in a broken system. We are looking for an experienced Sr Data Engineer who cares about impact, ownership, cross-functional projects, and mentorship. What you’ll be doing: Be part of a team of innovative engineers working on core pieces of our data infrastructure, pipelines, and data services underlying our product Lead and contribute to the code, systems and integrations Work on implementing and designing a data warehouse for all data use cases Work with stakeholders on requirements and solutions for data pipelines and data views Partner with Data Engineering and other stakeholders to improve our data platform Work with data scientists on the team when you discover game-changing opportunities for larger modeling and machine learning projects What we expect from you: Ability to write high-quality code in Python (or related languages) and a track record of shipping impactful data projects Experience in building fault-tolerant data pipelines with logging, alerting and data validation that goes beyond simple scripting Experience implementing and designing data warehouses using MPP databases such as AWS Redshift, Snowflake or BigQuery Ability to build data models using SQL for business analysts to consume with a data governance focus Data visualization experience a plus such as Tableau, Looker Experience working with highly sensitive data in a healthcare environment A track record of making quality vs. deadline tradeoffs in fast paced environments Strong communication skills and ability to generate consensus and buy-in within the team Organizational skills and the ability to simplify complex problems and prioritize what matters most for the sake of the team and the business Experience applying data and analytics concepts to business problems cross-functionally Proven success in partnering with and explaining data and analytics concepts to non-technical team members at any level of seniority Humble, scrappy, highly motivated, and thrive in fast-paced environments Benefits of working at Spring Health: Focus on total health including: Generous medical, dental, vision coverage available day 1 + access to One Medical Access to Spring Health’s platform which includes (10) free therapy sessions Unlimited time off in addition to (12) paid holidays 16-18 weeks paid parental leave $500 per year Wellness Reimbursement Creating a culture you can thrive in: Flexible remote and hybrid work style arrangements Calm Fridays to encourage meeting & distraction free days Donation matching to support your favorite causes Employee resource groups Supporting you financially through: Competitive mix of salary and stock options Employer sponsored 401(k) match In addition to finding people who are truly excellent at what they do, we take our values at Spring Health seriously: Members Come First We are genuine member advocates. Move Fast to Change Lives We build with urgency and intention. Take Ownership We extend trust and hold ourselves accountable. Embrace Diverse Teams & Perspectives We find strength in the diversity of cultural backgrounds, ideas, and experiences. Science Will Win We will achieve impact by innovation and evidence based frameworks. Candor with Care We are open, honest and empathetic. Spring Health is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex, marital status, ancestry, disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. We also consider qualified applicants regardless of criminal histories, consistent with applicable legal requirements. Spring Health is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans. If you have a disability or special need that requires accommodation, please let us know. #LI-remote #LI-OK1 Benefits of working at Spring Health: Focus on total health including: Generous medical, dental, vision coverage available day 1 + access to One Medical Access to Spring Health’s platform which includes (10) free therapy sessions Unlimited time off in addition to (12) paid holidays 16-18 weeks paid parental leave $500 per year Wellness Reimbursement Creating a culture you can thrive in: Flexible remote and hybrid work style arrangements Calm Fridays to encourage meeting & distraction free days Donation matching to support your favorite causes Employee resource groups Supporting you financially through: Competitive mix of salary and stock options Employer sponsored 401(k) match In addition to finding people who are truly excellent at what they do, we take our values at Spring Health seriously: Members Come First: We are genuine member advocates. Move Fast to Change Lives: We build with urgency and intention. Take Ownership: We extend trust and hold ourselves accountable. Embrace Diverse Teams & Perspectives: We find strength in the diversity of cultural backgrounds, ideas, and experiences. Science Will Win: We will achieve impact by innovation and evidence based frameworks. Candor with Care: We are open, honest and empathetic. Spring Health is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex, marital status, ancestry, disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. We also consider qualified applicants regardless of criminal histories, consistent with applicable legal requirements. Spring Health is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans. If you have a disability or special need that requires accommodation, please let us know. #LI-remote"
Data Engineer,Fisker Inc,Remote,https://www.indeed.com/rc/clk?jk=c4fa8b1a6b7404b8&fccid=38c354bb9b09f488&vjs=3,"About Fisker Inc. California-based Fisker Inc. is revolutionizing the automotive industry by developing the most emotionally desirable and eco-friendly electric vehicles on Earth. Passionately driven by a vision of a clean future for all, the company is on a mission to become the No. 1 e-mobility service provider with the world’s most sustainable vehicles. To learn more, visit www.FiskerInc.com – and enjoy exclusive content across Fisker’s social media channels: Facebook , Instagram , Twitter , YouTube and LinkedIn . Download the revolutionary new Fisker mobile app from the App Store or Google Play store. We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. Job Responsibilities: Conduct requirement analysis and design source to target mappings Architect, Design, develop and unit test data pipelines in Azure Data Factory and Databricks or similar technologies Build CI/CD pipelines for data integration Assist in building data model & architecture for various layers in the data lake / data warehouse (snowflake etc.) Responsible for the design, development, implementation, and support of critical enterprise E2E Business Intelligence ETL solutions Provide technical guidance to other internal and external teams Assess current processes, recommend, and implement approaches to efficiently handle increasing volumes of data Document and communicate technical specifications to ensure that proper and optimized techniques, queries, data standards, and final outputs are understood and incorporated into data and analytics processes Participate in business analysis activities to gather required reporting and dashboard requirements Handle the product's or project's conception, translate business requirements, design initial technical specifications, and develop data solutions Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Design and develop reports and dashboards with data from potentially multiple data sources Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure and/or AWS ‘big data’ technologies. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and Cloud regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. Qualifications: 4+ years of experience Candidate should have good understanding of ETL concepts and Expertise and hands on experience in Azure Data Factory, Azure Data Lake Storage and Data bricks or similar technologies Hands on experience of working on cloud database tools like Azure SQL Database, Azure Synapse Strong SQL writing skills and good understanding of Data Lake and Data Warehousing concepts including data modeling Knowledge of Azure DevOps and agile methodology desirable Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Strong project management and organizational skills. Good communication and interpersonal skills 5+ years’ experience in ETL, Data Engineering, or BI fields with concentration on data transformations Familiar with Data Visualization standard methodologies BS in Computer Science, Engineering or a related technical role or equivalent experience Fisker Inc. is an Equal Opportunity Employer; employment at Fisker Inc. is governed based on merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status. Applicants wishing to view a copy of Fisker Inc.’s Affirmative Action Plan for veterans and individuals with disabilities, or applicants requiring reasonable accommodation to the application/interview process should notify the Human Resources Department #LI-SM1 #LI-REMOTE"
Data Engineer (Talend),DataEconomy,"Remote in Dublin, OH 43017+1 location",https://www.indeed.com/rc/clk?jk=a71a28c159d8e108&fccid=e8b25353b98ebe33&vjs=3,"About us About DATAECONOMY: We are a fast-growing data &amp; analyticscompany headquartered in Dublin with offices inDublin, OH, Providence, RI, and an advanced technology center in Hyderabad,India. We are clearly differentiated in the data &amp; analytics space via oursuite of solutions, accelerators, frameworks, and thought leadership. Job Description Urgent need for Talend Developers to join our work force at DataEconomy. Location: Remote Mode of Employment: CORP TO CORP Experience Level Mid level to Seniors If you are interested, Please share your resume to jason@dataeconomy.io or call 614-734-1434 Requirements As a Talend Developer, successful candidate will function as a primary member for developing ETL flows to provide data for Business Users across the organization Create Talend jobs (ETL) Design, develop and implement databases, data collection systems, data analytics and other strategies to support the tactical and strategic reporting and analytics needs. Develop and maintain scripts and queries to import, manipulate, clean, transform data from different sources Perform quality assurance on generated results to ensure accuracy and consistency using Data visualization software and techniques Design, evaluate and monitor key metrics, understanding root causes of changes in metrics Developing and publishing Talend Jobs. Participate in analysis sessions to understand functional and non-functional requirements Create/develop code and jobs in Talend while following enterprise best practices Document application designs, data structures Provide technical insight and develop work estimates to project planners Deploy and maintain application services in a production environment Continuously optimize, enhance and monitor support and maintain all Talend data integration processes Should be responsible for building extraction and mapping rules for loading data from multiple sources for data warehouse implementation based on MS Azure Must have strong knowledge on Data Warehousing (DWH) concepts, ETL concepts, data analysis capabilities and experience in the Talend Experience in Talend Data Stewardship Console and Data Prep Strong experience in Data Quality, Source Systems Analysis, Business Rules Validation, Source Target Mapping Design, Performance Tuning and High Volume Data Loads Work with business users to translate requirements into system flows, data flows, data mappings etc., and develop solutions to complex business problems Maintain workload and time tracking within Jira Development experience working in Agile Scrum environment Benefits NO BENEFITS - ALL INCLUSIVE HOURLY BILLING RATE ON CORP TO CORP I'm interested Job Information Industry IT Services City Dublin State/Province Ohio Country United States Zip/Postal Code 43017"
Data Engineer,"The Leading Hotels of the World, Ltd.","New York, NY 10017 (Midtown area)","https://www.indeed.com/company/The-Leading-Hotels-of-the-World,-Ltd./jobs/Data-Engineer-33d3c34d234e590f?fccid=aefa31d2c62f8d95&vjs=3","Position SummaryAs a Data Engineer, you will work in a cross-functional Agile team environment to comprehensively architect, develop, and maintain databases, data pipelines, and a data warehouse. You will participate in a Data Governance committee and drive discussion about KPIs, data governance, data quality, and data lineage. You will develop and implement strategies for improving analytics capabilities data cleanliness, and machine learning. You will work closely and communicate clearly with Product Owners, developers, architects, and ScrumMasters daily. About you: You can work collaboratively with all team members despite department or position You are able to work independently You have strong problem-solving skills and clearly articulated complexity You can effectively communicate with stakeholders in business terms and high-level technical terms You are able to lead technical discussions using the voice of the business with technical and business stakeholders You are able to reframe and respond to requests in writing You listen and internalize complex business processes and help stakeholders flush out business processes when required You can understand and tell a story to stakeholders about patterns and anomalies in the data On a day to day you will: Architect and implement data pipelines, design data schemas, and maintain transactional databases, data warehouses, and data lakes Collaborate with the Analytics team to provide curated data sets, perform data analysis, and develop data services to make data more accessible Build reports and dashboards to help detect data quality issues Troubleshoot data quality issues and develop solutions to fix immediate data qualities issues and execute long term strategic business and technical initiates Write and maintain documentation: data dictionary, business glossary, and data linage Optimize performance of Redshift data warehouse Evaluate, test, and implement different data engineering tools (mostly AWS resources) Develop and execute plans for increasing data quality Work on and develop strategies for building a data lake Experiment with different products for the implementation of a data lake (mostly AWS resources) Technical Skills and Responsibilities: Design, implement, and QA data pipelines (any language and toolset) Understands APIs and has code development skills (any language), must be able to write code (any language) Understand the concepts and implementation practices of ETL, must be able to use different toolsets Designing databases and data warehouses (Redshift, Dremio, or similar technology), Data strategies for processing med-high data volumes for pushing out to the data warehouse Building SQL (Stored Procedures, Functions, advanced select statements) Excellent debugging and code-reading skills Optimization and monitor database and data warehouse performance Help develop data standards and implement and apply data governance strategies Knowledge and implementation of some reporting technology Knowledge of handling systems with med-high data volume Usage or knowledge of data blending tools Knowledge of machine learning implementation or training Knowledge of NoSQL is a plus As part of the LHW team you will be able to: Able to work with a mid-sized progressive company that is looking to grow their technical abilities Must be able to understand complex business scenarios and learn to speak in the voice of the business Able to work closely with stakeholders and participate and make recommendations in large collaborative groups Work in an agile methodology on all projects (does not require you to know agile methodology) About The Leading Hotels of the World, Ltd. (LHW)Comprised of more than 400 hotels in over 80 countries, LHW is the largest collection of independent luxury hotels. In 1928, 38 independent hoteliers came together to create LHW. Since then, the Company has carefully curated distinctive hotels, resorts, inns, chalets, villas, and safari camps from the snow-capped Alps of Europe to the African veldt, to share them with adventurous souls who seek the remarkably uncommon. The LHW community is filled with exceptional individuals, united by a passion for the surprising discoveries and details that come with every experience. LHW’s collection covers the globe and promises a broad range of destinations and uncommon experiences, enhanced by LHW’s tiered guest loyalty program Leaders Club. From converted former palaces, and countryside retreats run by the same families for generations, to gleaming skyscrapers in dynamic urban centers, serene private island escapes, and glamorous tented camps – and beyond – explore, find inspiration, and experience unforgettable travel moments. For more information visit: www.lhw.com, Facebook at @LeadingHotels, Twitter at @LeadingHotels, and Instagram @leadinghotelsoftheworld LHW is proud to be an equal-opportunity employer. LHW does not discriminate on the basis of religion, race, creed, color, national origin, sex, age, disability, handicap, veteran status, sexual orientation, genetic information, or any other applicable legally protected category. Job Type: Full-time"
Data Engineer,Acima,"Hybrid remote in Draper, UT 84020",https://www.indeed.com/rc/clk?jk=7cf2f4a7a6b71940&fccid=6fa8a3ac70e320b0&vjs=3,"ACIMA Responsibilities: Create and maintain data pipelines and ETL jobs using Python and SQL Assemble large, complex data sets that meet functional / non-functional business requirements Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Collaborate with business leaders, Executives, Data Scientists, BI Analytics, Product, Engineering, and other operational departments to ensure successful delivery of data integration and BI projects Perform data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Note: work from home (WFH) options available Benefits & Compensation Acima understands that employment is the sum of many parts. Our compensation is very competitive and total benefits round out to what we feel is a complete package. Benefits include: Unlimited discretionary time off (DTO) We offer a traditional insurance plan AND 3 QHDHP plans with company contribution to an HSA plan. $750 per year for individuals and $1,500 per family (2+). Medical insurance in the IHC/United network, Acima pays 85% of the employee premium Dental and Vision Insurance Health Savings Account (HSA) with company contribution Supplemental Insurance (long-term/short-term disability, life insurance, etc.) Paid Parental Leave Company Paid Holidays 401K with company match (EAP) Paid Employee Assistance Program with fully covered mental health benefits and more. Options for a hybrid work from home and in office Flexible schedules available Onsite Gym & Bike Lockers College Tuition Reimbursement Program Training, education, and recertification reimbursement Competitive Pay - Our posted pay range for this position starts at $85,000+ However, we understand that each candidate brings their own skills and experience. We evaluate each candidate and review salary requirements to provide the most appropriate and competitive offers. Skills, Experience & Qualifications: 2+ years of experience in Data Engineer role Bachelor's degree or equivalent experience in Computer Science or related technical field Strong Python experience Strong SQL experience Strong REST API experience Experience using Linux Experience with data warehousing: Redshift and Snowflake Warehouse data modeling experience is a plus Ability and motivation to learn new technologies quickly with minimal support and guidance Strong communication skills Experience supporting and working with cross-functional teams in a dynamic environment."
Data Engineer (100% Remote is an Option - Global),Corteva Agriscience,"Remote in Des Moines, IA+1 location",https://www.indeed.com/rc/clk?jk=a62eacd30131085e&fccid=d2536e400fa1f147&vjs=3,"Description Data Engineer Who are we, and what do we do? Corteva Agriscience is the only major agriscience company in the world completely dedicated to agriculture. Our purpose is to enrich the lives of those who produce and those who consume, ensuring progress for generation to come. Our inspiration is to be a market shaper, driving the next generation of agriculture products that help farms and farmers flourish and through partnering with society becoming the most trusted partner in the global agriculture and food community. With a global footprint and over 22,000 employees, Corteva is building the future of agriculture and leading breakthroughs in the innovation and application of science and technology that will better the lives of people all over the world and fuel the progress of humankind. Corteva Agriscience is searching for a Data Engineer. The overall objective of this position is to provide data engineering expertise to projects across the scope of the business. This position will be part of an organization who provide a variety of data services to product and business analytic teams around the globe. This position will coordinate with various internal and external stakeholders to ensure deliverables are consistent with company standards and security practices. Key Responsibilities - What you will do to help us grow! Design, build and maintain data pipelines using company standard technologies. Assist with renovating the data management infrastructure to drive automation in data integration and management. Work with architecture and data analysts to refine data requirements for various data and analytics initiatives. Propose appropriate (and innovative) data ingestion, preparation, integration, and maintainable techniques in addressing data requirements. Work with the Data, Analytics & Automation Leader to establish and maintain company practices and security requirements in the data space. Qualifications Qualifications and Experience – What you'll bring to the table! Education A bachelor’s degree in computer science, data science, information science or related field, or equivalent work experience. Experience/Skills 2+ years of experience in data engineering or a related field. Advanced analytical skills and attention to detail. Proven ability to quickly learn new applications, processes, and procedures. Able and willing to collaborate in a team environment and exercise independent judgment. Excellent verbal and written communication skills. Knowledge of SQL, Databases (particularly MS SQL Server and SAP Hana), and Azure capabilities (Data Factory, DataBricks, data lakes). SAP Hana Calculation View experience helpful. Knowledge and experience using Azure DevOps or comparable tools for code and release management. Strong problem-solving skills and using innovation to find solutions. Experience in integrating complex processes and information strategies, and/or designing strategic metrics and scorecards. Industry experience desirable, but not required. Let’s peek at just a few of the advantages to working at Corteva and how you can grow your wellbeing, health, and future. Strike a better work-life balance with robust time off benefits including paid maternity, paternal and family illness leave. Prepare for your future with our competitive retirement savings plan, tuition reimbursement program, and more. Enjoy access to health benefits for you and your family on your first day of employment. And much, much more. Take the next step to #GrowWhatMatters in your career with Corteva and apply today. We look forward to seeing your application."
Data Engineer,Kodeva,"San Jose, CA",https://www.indeed.com/rc/clk?jk=b3e347f47d9e17f8&fccid=32d71ee27593fcf4&vjs=3,"Location: San Jose CA Duration: 12 Months Job Description : Profile should have more than 8years of experience Hands on experience in designing and executing projects on Google Cloud Platform features like App Engine, Compute, storage, Big Query, Data Proc, Data Flow. Strong Programming Skills in R, Python or Spark. Strong Knowledge on Data Engineering, Simulation and Modelling concepts Proficiency in handling the billions of structured or unstructured transactional data. Proficiency in modeling techniques such linear regression, logistic regression, GLM Knowledge on machine learning techniques such as Decision Trees, xgboost, random forest, PCA etc. Knowledge on unsupervised Machine learning techniques such as Clustering, Segmentation Strong knowledge on Data Manipulation and transformation Knowledge on data loading to GCP services like big query, cloud storage. Knowledge in Hadoop, HIVE and Pig languages. Good communication skills."
Data Engineer,Zartico,"Salt Lake City, UT 84101 (People's Freeway area)",https://www.indeed.com/rc/clk?jk=bc8dad9da11f70a8&fccid=dd616958bd9ddc12&vjs=3,"Welcome to Zartico. We know applying for and taking on a new role at any company requires a leap of faith. Here are a few things about Zartico we think you should know: Zartico Mission and Purpose Zartico’s Purpose: We believe tourism is a force for good because it builds connection, understanding, and appreciation of our world’s cultures, history and natural resources. We believe data and the right metrics allow us to make better decisions because transparent data helps focus on the right issues, problems and therefore, solutions, to be better stewards of our world's most precious destinations. Zartico’s Mission: Zartico’s mission is to empower DMOs to be better stewards of the world’s tourist destinations through improved data intelligence and decision-making. Makers of the first Destination Intelligence Platform, Zartico harnesses and streamlines complex data to provide a full-spectrum of data science, benchmarking and analytical services for use in marketing, community development and sustainability efforts. Based in Salt Lake City, Utah, Zartico has over thirty years of experience in technology, tourism, and destination and travel marketing. If this resonates with you, Zartico is hiring Data Engineers. As an engineer on the core product team you'll provide intelligence to the rest of the company that will enable making better product decisions. You'll make use of the latest advances in large scale data processing to uncover insights in data. You’ll work on building critical data warehouse tables with world-class engineers towards the mission of enabling data-driven products and insights at Zartico. You will develop data infrastructure that is able to ingest and transform data at scale coming from many different sources, different customers, and in many different varieties. You will build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and build robust data pipelines that collect, process, and compute business metrics from activity data. You will create critical datasets for machine learning, growth funnels, business forecasting, and many other strategic initiatives. Primary Technologies Required Python Google Cloud Platform (BigQuery, GoogleCloud Storage) SQL Infrastructure as Code (e.g. Terraform) Extra Credit for Experience with data visualizations Experience and Mindset Needed 2+ Years of experience as a Data Engineer or Software Engineer BA/BS in a quantitative or computer science field Fluency in SQL and a programming language A successful history of manipulating, processing and extracting value from large disconnected datasets Quick learner - we face new challenges every day Expert in coding -we develop real products Compensation Competitive Salary and Benefits (unlimited PTO) Stock incentive program Career plan and lifelong learning - We want you to grow in your role based on their curiosity, passion, and ability to learn and evolve Zartico’s Commitment to Diversity and Inclusion Diversity, inclusion, and belonging. We’re building a global community—one that’s safe for people of all backgrounds. We are an equal opportunity employer where our diversity and inclusion are central pillars to our company strategy. We look for applicants who understand, embrace and thrive in a multicultural and increasingly globalized world. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. When you join our team, you agree to a code of conduct. Hiring Update: Due to the COVID-19 pandemic, our hiring process will now be completely virtual. All interviews and onboarding activities will be held online or over the phone."
Data & Visualization Engineer,Levi Strauss & Co.,"San Francisco, CA",https://www.indeed.com/rc/clk?jk=6fdb40abb20d6f48&fccid=dc023faa36b88bf2&vjs=3,"JOB DESCRIPTION Key Responsibilities: Gather information from the business stakeholders and translate them into a technical design Develop routines and optimize code for enhanced performance with a strong knowledge in SAP-Hana, Spark, Python and NoSQL Databases Monitor and maintain the real time Data Pipelines, Discretized Streaming processes in the Data and Analytics eco system Involve in the whole Software Life Cycle management from Analysis to Go-Live using SAP, BigData and Cloud Environments Minimum Education Required: Bachelor’s degree, GPA of 3.0 or above Years and Type of Experience Required: 3 to 5 Years Knowledge, Skills, and Abilities Required: Spark, Java, Python, SAP BW Hana, SQL EOE M/F/Disability/Vets LOCATION San Francisco, CA, USA FULL TIME/PART TIME Full time Current LS&Co Employees, apply via your Workday account."
Cloud Data Engineer / Scientist,KBR,"Houston, TX",https://www.indeed.com/rc/clk?jk=cd3607734428513b&fccid=cbfa56f19cc95796&vjs=3,"KBR Government Solutions delivers full life cycle professional and technical solutions that improve operational readiness and drive innovation. Our solutions help ensure mission success on land, air, sea, space and cyberspace for the Department of Defense, intelligence community, NASA and other federal agencies. KBR’s areas of expertise include engineering, logistics, operations, science, program management, mission IT and cybersecurity. Our people make the world a more productive, efficient and fascinating place. And thats only the beginning. KBR is looking for an experienced Data Engineer / Data Scientist to support our asset management analytics business. The Data Engineer / Scientist will report to the Senior Manager, Asset Management within the KBR Readiness & Sustainment Solutions (R&SS) business unit. Duties & Responsibilities: The Data Engineer / Scientist will be responsible for all data management activities associated with design and implementation of a cloud-based, Platform-as-a-Service (PaaS) asset management analytics product. Responsibilities include the following: Data Strategy. Develop and implement a technology roadmap for the product based on planned product functionality improvements and technology advancements. Data Model. Manage the cloud data model that underlies the analytics product. Data Architecture. Establish a robust and scalable data architecture that includes structures for real-time and transactional data, Internet of Things (IoT) technologies, and analytics (reporting, statistical, artificial intelligence / machine learning (AI/ML). Data Standards. Manage the set of R&SS asset management data standards. Data Management Processes. Design, implement and document. Security / Regulatory Compliance. Ensure the data solution complies with relevant U.S. Government cybersecurity requirements. Vendor & Subcontractor Selection & Technical Oversight. Ensure work performed by third parties complies with the R&SS data standards and processes. Consulting Support. Provide consulting support to customers to align / migrate their existing data to the cloud analytics product. Participate in KBR Communities of Interest / Centers of Excellence. Collaborate Establish relationships with cloud professionals in other parts of the KBR business. • Perform other duties as assigned. Qualifications: Experience Five (5) years of cloud data solution design experience with PaaS / SaaS applications. Prior U.S. military experience preferred but not required. Education BS degree in Computer Science; MS preferred, or equivalent relevant experience considered. One or more of the following certifications highly preferred: MS Azure Data Scientist / Azure Data Engineer / Azure Database Administrator. Other Requirements: US Citizen with valid Passport. Ability to obtain a security clearance at SECRET level. Willingness to travel - 25% travel expected Additional Skills and Experience: Expert level knowledge of cloud data engineering / data solution design. Familiarity with U.S. Government cybersecurity framework and requirements. Ability to interact with coworkers at all levels in the organization. Solid technical writing and communication skills. Strong work ethic. Ability to multi-task. Ability to adapt to changing work requirements. #LI-SC1"
Data Engineer,Digital Remedy,"New York, NY",https://www.indeed.com/rc/clk?jk=af7c1ce04562aa23&fccid=d6b510a398be0300&vjs=3,"Digital Remedy is looking for a savvy Data Engineer to join our growing team of analytics experts. This position will enable data-driven decision making by collecting, transforming, and visualizing data. The ideal candidate will be responsible for designs, builds, maintaining and troubleshooting data processing systems with a particular emphasis on the security, reliability, fault-tolerance, scalability, fidelity and ever improving efficiency for these critical enterprise systems. The right candidate will be excited by the prospect of optimizing our company’s data architecture to support our next generation of products and data initiatives. Responsibilities Design and plan a cloud solution to maintain an optimal data pipeline architecture. Assemble large, complex data sets that meet business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Model business processes for analysis and optimization Implement end-to-end data analytics solutions (from data ingestion through visualization) for large-scale, complex data ecosystems. Qualifications We are looking for a candidate with 1-4 year(s) of experience in a data analytics/engineering role, who has attained a Bachelor’s or Master's Degree in data analytics, computer science, or software engineering. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Ability to build processes supporting data transformation, data structures, metadata, dependency and workload management. Our Ideal Candidate Has experience in Digital Marketing, Advertising, Media and/or (especially) Ad Tech or related digital industries. Is fluent in Python and SQL Nice to know: JavaScript, HTML, CSS, and PowerShell. Cares deeply about solving big, systemic problems. Looks beyond the surface to understand root causes of issues, enabling the build of long-term solutions for the whole ecosystem. Believes in not only serving customers, but also empowering them by providing knowledge and tools. Takes smart technical risks and produces outsized wins. Refuses to accept mediocrity; needs to deliver an amazing product, and won’t stop until it is completed. Digital Remedy does not discriminate in employment matters on the basis of race, color, religion, gender identity or expression, national origin, age, military service eligibility, veteran status, sexual orientation, marital status, disability, or any other protected class. We support workplace diversity and believe strongly that it contributes to a broader collective perspective that consistently leads to better products and a better company. We are working hard to increase the diversity of our team."
Cloud Data Engineer,Google,"Palo Alto, CA+1 location",https://www.indeed.com/rc/clk?jk=72ce3c9a924856b4&fccid=a5b4499d9e91a5c6&vjs=3,"Minimum qualifications: Bachelor's degree in Computer Science, Mathematics, or a related technical field or equivalent practical experience 5 years of experience in a technical project management or customer-facing role 3 years of experience in development using the Google Cloud Platform or other public cloud platforms Experience with data ingestion and data processing pipelines Preferred qualifications: Experience in the data management domain, including data quality, data lineage, and data security Experience with developing infrastructure as code and the DevOps discipline Experience writing software in one or more languages, such as Java, Python, Go, and/or JavaScript Experience in working with/on data warehouses, including data warehouse technical architectures, infrastructure components, ETL/ELT, and reporting/analytic tools, environments, and data structures Experience in the healthcare industry About the job As a Cloud Data Engineer on the Solution Architecture Team in Google for Clinicians, you will help shape the future of our innovative Google Health products by building with Google Cloud technologies. You will guide our clients through the technical journey of implementing the Google for Clinicians product suite, leaning on your extensive knowledge of Google Cloud and Data Engineering practices. Specifically, you will help our clients implement solutions to ingest, store, validate, and integrate their electronic health records (EHR) data. You will work with clients and partners to implement data processing systems, data pipelines optimized for scaling, and troubleshoot potential deployment challenges. You will also perform builds and automate key components of our infrastructure. Finally, you will work with our Engineering teams to build and drive enhancement and excellence in our products. Google Health has made major advances in healthcare research, such as detecting eye disease more quickly and accurately than experts, planning cancer radiotherapy treatment in seconds rather than hours, and working to detect patient deterioration before it happens with electronic records. Fundamental research is at the core of Google Health - the multidisciplinary team collaborates with partners to publish novel research in renowned scientific journals. They then work to apply this research into the medical field through clinical hardware and products developed in Google. Working alongside colleagues across Google, you’ll help make this vision a reality. Additional Information (Colorado only*) Minimum full-time salary range between $109,000 - $117,000 + bonus + equity + benefits. Note: Disclosure as required by sb19-085 (8-5-20) of the minimum salary compensation range for this role when being hired into our offices in Colorado. Responsibilities Guide customer implementations using the Google Cloud Platform. Perform builds and automations of customer implementations. Collaborate with clients to solve cloud challenges, especially challenges relating to data engineering. Setup and manage Google internal infrastructure and data pipelines for our clients. Collaborate with internal technical teams to communicate feedback from clients and provide input to evolve our products. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form."
Electrical Engineer - Data Center Design,Facebook App,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=d1b60bd11f4243ef&fccid=ba07516c418dda52&vjs=3,"Meta is seeking an Electrical Engineer experienced in the design and operations of Critical Facilities to become part of our Data Center Design team. Our data centers are the foundation upon which our software operates with efficient ease. Building and operating data centers the ""right"" way from the day they go live is synonymous with ensuring capacity availability and capital conservatism. The Meta Data Center Design team endeavors to be the benchmark of innovation for the data center industry and improve reliability, safety and efficiency through innovative solutions, enabling Infrastructure teams to excel in achieving their goals. Electrical Engineer - Data Center Design Responsibilities: Lead the team in the development of prototype design of data center electrical infrastructure for improved reliability, efficiency, speed to market and cost Create criteria to evaluate benefits and feasibility of the solution for scalable deployment Cross-functional collaboration with other Meta teams including Software Engineering, Hardware Engineering, Network Engineering, Operations and Capacity Analysis teams Provide technical due diligence review and evaluation for the data center site selection process Develop strong industry relationships with other data center peers and organizations to remain current on industry trends and future directions Travel domestically and internationally to data center sites for engineering studies, electrical systems audits, and collaboration with local teams as required Minimum Qualifications: BS in Electrical Engineering or related field 8+ years professional experience in electrical systems design, construction, operations, and maintenance Electrical Professional Engineer registration Experience in high voltage substation design, medium voltage distribution systems, mission critical power distribution, generators, UPS, PDU, and Building Management System Experience in High Voltage electrical transmission, distribution, and utility interconnection processes Knowledge of industry standards, building codes and safety standards including NEC, NETA, ANSI, IEEE, NFPA, UL, UFC and UBC Knowledge of international standards including IEC, CE and EN Cross-discipline knowledge of complete critical facility systems Proven troubleshooting and analytical skills Experience providing solutions to complex projects under pressure Proven presentation and communications skills Preferred Qualifications: Large and complex system design experience, including campus systems Research & Development experience including concept, design, modeling, prototyping, testing, and production support Lean Construction certification/experience LEED Certification/Credentials Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
Mechanical Engineer - Data Center (REMOTE),Jacobs,"Remote in Portland, OR 97222+1 location",https://www.indeed.com/rc/clk?jk=b0b5d0d5b4cbe6d4&fccid=de56d7554bea5214&vjs=3,"Our People & Places Solutions business – reinforces our drive to improve the lives of people everywhere and epitomizes the ""why"" of what we do – the tremendous positive impact and value our solutions bring to our communities and society as a whole. From facilities delivering life-saving therapies and ensuring clean water to enabling the connection of people through all modes of transportation and providing access to technology – we're integrating a multitude of these solution elements to build the smart environments of tomorrow. Start your Jacobs career with a company that inspires and empowers you to deliver your best work so you can evolve, grow and succeed – today and into tomorrow. Your Impact: At Jacobs, we don’t settle – always looking beyond to raise the bar and deliver with excellence. We apply our expertise and knowledge as we look into the future with great optimism and focus. We don’t settle until we give our best and know that we’re making a difference. We're looking for a Mechanical Engineer who is excited about working on projects that enable the heart of our clients’ business. Join us and you’ll have the chance to work on projects at some of the world’s most state of the art industrial and commercial facilities. You’ll be accountable for schedule and technical quality of challenging engineering tasks, as you gain familiarity with the client’s expectations, scope, budget, and schedule. You will work in a multi-discipline, highly interactive team to successfully deliver on the design, development, application, evaluation, recommendation, and specification of engineered systems and products for building HVAC, Plumbing, and Fire Protection Systems. You will perform all aspects of mechanical engineering and design and independently apply advanced engineering techniques and analysis within the discipline. You will also develop designs that require innovation and ingenuity, be expected to perform work with little to no supervision, review work of discipline team for adequacy on completion and provide technical guidance to drafters/designers and engineers. Your role keeps our company connected and we’ll support you with what you need to be successful. Bring your creativity, ambitious spirit and extreme attention to detail, and we’ll help you grow, pursue and fulfill what drives you – so we can deliver extraordinary solutions for a better tomorrow, together. At Jacobs, we’re partnering across the globe to create the best project outcomes by maximizing the design, digital technology, and support capabilities of our Global Integrated Delivery (GID) teammates. By joining Jacobs, you’ll commit to supporting and engaging with these teams, as we work to build a company like no other. Here’s What You’ll Need: Bachelor's degree in Mechanical Engineering At least 10 years of practical application of mechanical engineering, including HVAC, fire protection, plumbing, piping, boiler, chiller, or related mechanical building systems Experience with semiconductor or data center Professional Engineer Registration (PE) Ideally, you’ll also have: Effective communication, analytical, and problem-solving skills Experience leading junior engineers and designers on complex multi-discipline design project from concept development through detail design and construction Working knowledge of Navisworks and Revit Ability to be forward thinking, learn best practices, and contribute with innovative ideas Ability to collaborate and work effectively in multi-disciplinary teams Passion for buildings and construction #afelectronics #LI-Remote Jacobs is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, religion, creed, color, national origin, ancestry, sex (including pregnancy, childbirth, breastfeeding, or medical conditions related to pregnancy, childbirth, or breastfeeding), age, medical condition, marital or domestic partner status, sexual orientation, gender, gender identity, gender expression and transgender status, mental disability or physical disability, genetic information, military or veteran status, citizenship, low-income status or any other status or characteristic protected by applicable law. Learn more about your rights under Federal EEO laws and supplemental language. At Jacobs, we’re challenging today to reinvent tomorrow by solving the world’s most critical problems for thriving cities, resilient environments, mission-critical outcomes, operational advancement, scientific discovery and cutting-edge manufacturing, turning abstract ideas into realities that transform the world for good. With $13 billion in revenue and a talent force of more than 55,000, Jacobs provides a full spectrum of professional services including consulting, technical, scientific and project delivery for the government and private sector."
Data Engineer,Infosys,+3 locationsRemote,https://www.indeed.com/rc/clk?jk=d90693faed503864&fccid=c67533a523c83a4c&vjs=3,"Infosys is seeking Data Engineer. In the role ,you will interface with key stakeholders and apply your technical proficiency across different stages of the Software Development Life Cycle including Requirements Elicitation, Application Architecture definition and Design. This role will play an important role in creating the high-level design artifacts. This role will also deliver high quality code deliverables for a module, lead validation for all types of testing and support activities related to implementation, transition and warranty. This role will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued. This position is currently remote, however when Client office open, candidate must be located within commuting distance of Beaverton, OR or be willing to relocate to the area. This position may require travel in the US. U.S. citizens and those authorized to work in the U.S. are encouraged to apply. We are unable to sponsor work visa at this time. Qualifications: Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education. At least 2 years of experience with Information Technology. Must have skills and experiences: Experience in developing in the Hadoop, Python, Scala, Hive programming language . Experience using Spark and AWS (AWS S3 Spark, AWS Lambda) Services. Preferred Skills and experiences: Experience with continuous integration delivery tools – GIT, Jenkins, Docker. Experience in Business Process analysis, problem definition, Architecture/Design of AWS Cloud Bigdata solutions. At least 2 years of experience in Client engagement. At least 2 years of Agile Scrum experience. Experience in Demand planning and merchandising domain preferred . Knowledge of architectural frameworks and design principles. Basic domain knowledge in Retail, CPG and Logistics. Analytical skills. Experience and desire to work in a Global delivery environment. The job entails sitting as well as working at a computer for extended periods of time. Should be able to communicate by telephone, email, or face to face. Travel may be required as per the job requirements. About Us Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem. Visit www.infosys.com to see how Infosys (NYSE: INFY) can help your enterprise navigate your next. EOE/Minority/Female/Veteran/Disabled/Sexual Orientation/Gender Identity/National Origin"
Data Engineer,"Parallax Volatility Advisers, LP","Jersey City, NJ",https://www.indeed.com/rc/clk?jk=889ed830b67e0880&fccid=70503a4649c91055&vjs=3,"REPORTING RELATIONSHIP: Head of Database ROLE AND RESPONSIBILITIES: Parallax is looking to add a Data Engineer to our team. This position will spend a significant portion of their time responding to and resolving data challenges. In addition, this role will also work on developing and maintaining data feeds for the Parallax information architecture. This position will interact with a number of departments at the firm including, but not limited to, Traders, back office, IT and developers. Specific Responsibilities include but not limited to: SqlServer TSQL advanced query semantics SqlServer TSQL limited writing of stored procedures, functions, table and index definitions. Powershell and Python scripting, ability to troubleshoot, create, and maintain scripts. SqlServer Integration Services data feed package troubleshooting Unix shell scripting Source code management with Subversion and Git Basic Sqlagent and Bamboo job management QUALIFICATIONS: Bachelor's Degree in Computer Science, Data Science, Science. Minimum of 3 years' experience in relevant field to Data Quality Management; preferably within a hedge fund or related firm Must be a U.S citizen or authorized to work in the U.S on a permanent basis TECHNICAL ABILITIES/PROGRAMS: SQL Server Suberversion/GIT Bamboo Powershell Python SKILLS/KNOWLEDGE: Knowledge of hedge fund data operations and hedge fund trading products (options, futures, stocks, swaps) Clear and effective written and spoken communications External vendor and support channel handling Ability to operate and prioritize own assignments Ability to respond to operational interruptions Parallax offers extremely competitive compensation and benefits, including (not limited to): paid health insurance and continuing education opportunities. Parallax is an equal opportunity employer. Please no calls or recruiters."
Data Visualization Engineer 2,Humana,"Remote in Louisville, KY 40202+3 locations",https://www.indeed.com/rc/clk?jk=c340a7c5f7fb3a85&fccid=5f1f0e6dcc6cbc83&vjs=3,"Responsibilities As a Data Visualization Engineer in Health Informatics, you will be part of a growing team that is disrupting the way we view and understand members, helping our business partners engage smarter, faster, and more holistically with their population. We are dedicated to a positive work environment where you will be encouraged, rewarded, and cheered on for working out loud, continuous learning, and dreaming big. This role will work with large volumes of data from Humana to uncover hidden insights. To be successful in this role, the candidate should be curious and never afraid to ask why, have an entrepreneurial attitude, and the confidence, skill and will to accomplish their goals. The Humana Military-Health Informatics Data Visualization Engineer will have considerable latitude to create a compelling visual story of our members, segments and company. The work will also include a range of tasks involving GIS data development; user support and outreach; and various additional initiatives for Health Informatics. You will serve as an influencer and thought leader for all stages of the development, documentation, and dissemination of dashboards, with the goal of gaining a deeper understanding of health equity, SDoH, and our population’s whole health. The environment is highly collaborative, and you will work closely with research scientists, informaticists, data engineers, and leaders. We are constantly challenging the status quo of data processing and dissemination methods, and there is considerable opportunity for innovation and creativity by all members of the team. KEY ACCOUNTABILITIES 40% Develop visualizations using Tableau and Power BI that assist stakeholders to address gaps in care, improve efficiencies and reduce preventable events related to SDOH and health disparities by utilizing quantitative and qualitative tools to identify unmet health and social needs across Humana. This will include the development of various performance measures and dashboards like the community health dashboard, provider metrics and equity interventions on population health; partnering with Humana teams for opportunities to improve health-related social resource needs and outcomes. 40% Lead efforts in building portfolio of visual aids across Humana seeking out new and innovative use cases. Collaborate internally and externally utilizing ACG to provide strategic analytical support and insight for partner and potential new partner opportunities. Align ACG communication with the Health Informatics and stakeholders to continuously improve approaches to integrate SDOH and population health strategies into care and support delivery. 20% Lead collaborative efforts to build and enhance work streams for clinical and operational efficiency that will ensure customer and stakeholder satisfaction by creating visualizations to monitor trends, utilization and timelines that enhance stakeholder overall understanding of population health and trends. This role description in no way states or implies that the key accountabilities above are the only ones being performed by the individual(s) with this role description. The individual(s) may be called upon and required to follow other instructions or perform other duties and tasks requested by his or her supervisor, consistent with the purpose of the position, department and/or company objectives. Required Qualifications Bachelor’s degree in Computer Science or related field Demonstrated experience producing high functioning dashboards using Power BI and Tableau Demonstrated expertise in data analysis, conducting geospatial analysis (raster and vector) in support of population health monitoring root cause analysis Expertise with HTML/CSS/Javascript, D3, Angular.j 3 plus years of experience with analyzing and interpreting data using statistical tools, algorithms, models and software to include R, rStudio, Shiny, MATLAB and/or Python Strong interpersonal, verbal and written communication skills Experience in problem solving, analytical thinking and consultation with complex environments Our Department of Defense Contract requires U.S. citizenship for this position Successfully receive interim approval for government security clearance (eQIP - Electronic Questionnaire for Investigation Processing) Work at Home/Remote Requirements WAH requirements: Must have the ability to provide a high speed DSL or cable modem for a home office. Associates or contractors who live and work from home in the state of California will be provided payment for their internet expense. A minimum standard speed for optimal performance of 25x10 (25mpbs download x 10mpbs upload) is required. Satellite and Wireless Internet service is NOT allowed for this role. A dedicated space lacking ongoing interruptions to protect member PHI / HIPAA information Preferred Qualifications Three (3) plus years of experience providing thought leadership in support of health plans and/or TRICARE Experience developing provider level population health reporting Recent knowledge of TRICARE compliance and contractual requirements and standards Knowledge of community based digital platforms that link CBOs and create longitudinal member records of community resource linkages Familiarity with Military families, geography and cultures Additional Information Interview Format As part of our hiring process, we will be using an exciting interviewing technology provided by Modern Hire, a third-party vendor. This technology provides our team of recruiters and hiring managers an enhanced method for decision-making. If you are selected to move forward from your application prescreen, you will receive correspondence inviting you to participate in a pre-recorded Voice Interview and/or an SMS Text Messaging interview. If participating in a pre-recorded interview, you will respond to a set of interview questions via your phone. You should anticipate this interview to take approximately 10-15 minutes. If participating in a SMS Text interview, you will be asked a series of questions to which you will be using your cell phone or computer to answer the questions provided. Expect this type of interview to last anywhere from 5-10 minutes. Your recorded interview(s) via text and/or pre-recorded voice will be reviewed and you will subsequently be informed if you will be moving forward to next round of interviews. Scheduled Weekly Hours 40"
Data Governance Engineer,Woven Planet,"Palo Alto, CA 94304",https://www.indeed.com/rc/clk?jk=3baef9b4bc228769&fccid=f567639d850ddd52&vjs=3,"Woven Planet is building the safest mobility in the world. A subsidiary of Toyota, Woven Planet innovates and invests in new technologies, software, and business models that transform how we live, work and move. With a focus on automated driving, smart cities, robotics and more, we build on Toyota's legacy of trust and safety to deliver mobility solutions for all. For nearly a century, Toyota has been delivering products and services that improve lives. Automation that originated to increase the efficiency of daily activities has evolved into the safe, reliable, connected automobiles we enjoy and depend on today. Now, we are looking to the next 100 years and to extending that dream for a better life for all people. At Woven Planet we strive to build a safer, happier, more sustainable world. Our unique global culture weaves modern Silicon Valley innovation and time-tested Japanese quality craftsmanship. The complementary strengths enable us to optimize safety, advance clean energy, elevate well-being, and improve how people live, work, and play. We envision a human-centered future where world-class technology solutions expand global access to mobility, amplify the capabilities of drivers, and empower humanity to thrive. About the Organization Woven Planet is developing automated driving technology using a data-driven approach. We're building products at autonomy levels 2-4 to drive both near- and long-term improvements to mobility for all. Woven Planet has the backing of one of the world's largest automakers, the talent to deliver on our goal, and a built in path to product and revenue—a combination rarely seen in the mobility industry. We're looking for doers and creative problem solvers with a passion for improving lives. Each member of our diverse and talented group of software and hardware engineers has the opportunity to make a meaningful impact on our technology and products. Our growing team works in brand new garages and labs in Palo Alto, tests AVs at our dedicated test track in Silicon Valley, and explores the industry's most compelling research problems at our office in London. With support from our Woven Planet colleagues in Tokyo, our work to improve the future of mobility spans the globe. About the Team: Arene is Woven Planet's flagship platform to enable programmable mobility. The Arene Platform is being developed to accelerate the creation of value towards a future where 'mobility' replaces 'transportation.' Arene enables true state-of-the-art mobility programming, it is the basis for next-generation vehicles. Its development-to-deployment process is revolutionary in its simplicity and efficiency. Getting safe software solutions from concept to market has never been easier, faster, or more accessible. These innovations are delivered by Arene which is also characterized by the longstanding principles of fine craft and hardware know-how that have been perfected by seasoned automakers. Tight integration between the vehicle and the cloud provides a unique programming platform, pioneering a lower barrier to entry for innovation, and allowing engineers to invent in new and exciting ways. The Arene Plane team is responsible for end to end collection and processing of data across the vehicle and the cloud. This data is central to enabling programmable mobility, development of new features for upcoming vehicles and creating an optimized supply chain for OEMs. You will be an integral part of the team designing services for our next generation of vehicle data management platform. You will work alongside some of the finest engineering minds managing vehicular data collection, data ingestion, event driven processing pipelines, and data enrichment of exabyte scale while meeting strict functional safety requirements. About the Role: At Woven Planet, we are building the Arene automotive platform using world class technology to build the safest mobility in the world. The Arene data platform is a modern vehicle data management system built around a distributed data architecture that is capable of generating, ingesting and managing several petabytes of data every day. The data platform creates measurable value for Toyota and other OEMs through data services and vehicle feature development. We are looking for a highly-motivated Data Governance engineer responsible for designing and implementing data governance and quality assurance frameworks for the Arene data platform. The ideal candidate will have the necessary technology, communication and leadership skills to hands-on manage highly visible and complex projects from start to finish. You will be responsible for architecting and implementing data governance solutions including metadata models, data quality, data lineage, roles and role based access models on a data platform that collect and manage data across millions of vehicles at an exabyte data scale. What You'll Do: Develop data governance strategy for automotive data management systems in collaboration with other stakeholders Define and implement data governance roadmap and frameworks to ensure compliance with internal and external regulations. Partner with data architects to define standards and processes for technical and business data elements, data dictionary, data lineage, quality, processes, classification, and policies that align with the data governance strategy Implement data catalog and automate data governance workflows across distributed data nodes. Understand business domain requirements and design/map roles and responsibilities to data access, incorporating compliance to privacy, security and global governance standards such as GDPR. Understand wider company architecture, as well as industry trends. Lead cross-functional and cross-organizational initiatives on data governance. What You'll Bring: Required Skills 5+ years of experience in roles related to data governance, metadata management, audit and/or data analytics Experience with developing data governance strategies, roadmaps and frameworks, translating them into operational plans and delivering & monitoring them. Experience working with data catalogs such as DataHub or Amundsen to implement and streamline data discovery and metadata management. Ability to drive clarity out of ambiguous and uncertain scenarios and define precise requirements, priorities and actionable outcomes. Understanding of global data privacy regulations and compliance requirements and experience incorporating them in data governance frameworks. Ability to work across teams and organizations to drive consensus Hands on skills with data modeling and data management Preferred Skills Experience with federated data governance Experience with distributed data architectures such as Data Mesh and with modeling Data as a Product Understanding of the automotive domain. Familiarity with RDF, ontologies and/or vehicle signal models Rev up your future, apply here. OUR COMMITMENT ・We are an equal opportunity employer and value diversity. ・We pledge that any information we receive from candidates will be used ONLY for the purpose of hiring assessment."
Software Engineer - Data Focus,Principal Financial Group,"Remote in Des Moines, IA 50392+1 location",https://www.indeed.com/rc/clk?jk=bf1abfb95e1cf03e&fccid=591be181c58fd89d&vjs=3,"Responsibilities: As a Software Engineer in Enterprise Data and Applications (EDA), you’ll join a group of engineers in an Agile Scrum team in our data space. Here in EDA, we are at the intersection of many strategic and digital initiatives that impact the enterprise! This provides unique opportunities to solve key business problems impacting our customers. You will work with our stakeholders and other technology peers as you elicit requirements, develop software, integrate data and provide operational support. If you like working with data and understanding how data flows through our various systems, then this is just the team for you. We do use the Informatica MDM tool, so experience with that tool is a necessity, but your skills in working with data and all things data will help you be successful in this role. Here are few examples of the kinds of things engineers in our department do: Embrace a Product Mentality by focusing on outcomes over outputs, pursue fast feedback loops, and deliver solutions iteratively with low risk and low cost Grow our DevOps approach and culture by continuously maturing and optimizing our SDLC through automation and safe/frequent delivery Engage in all facets of software engineering from understanding the problem, evaluating designs, creating the solution, validating the outcome, etc. Understand and continue driving our journey to a cloud-first technology community Appreciate and promote Cloud Engineering – AWS PaaS, cloud integration patterns, cloud security, cloud operations, etc. Network and communicate with cross-functional teams and collaborate with both IT and non-IT partners Learn new technology and continuously grow through creative solutioning Qualifications: We’re looking for someone with: Associate's or Bachelor's degree with a preference in a science, technology, engineering, or math related field or equivalent work experience (6 years of experience equates to an Associate’s degree when defining “equivalent work experience”) 2+ years of experience with the Informatica MDM tool (some of the modules we use are MDM, Data Quality, IDD, Match, Merge) Strong SQL & Relational Database experience Experience or exposure to data and/or data technologies (more specifically, how that data moves from system to system) Eagerness and proven ability to learn Additional preferred technical experience: Object oriented development experience (professional, academic, or community exposure) Salary Range Information: Salary ranges below reflect targeted base salaries. Non-sales positions have the opportunity to participate in a bonus program. Sales positions are eligible for sales incentives, and in some instances a bonus plan, whereby total compensation may far exceed base salary depending on individual performance. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Salary Range: $58700 - $142800 / year Additional Information: Hours This position may require on-call responsibilities. Job level We’ll consider talent at the next level with the right experiences and skills. Work Authorization/Sponsorship At this time, we're not considering candidates that need any type of immigration sponsorship (additional work authorization or permanent work authorization) now or in the future to work in the United States? This includes, but IS NOT LIMITED TO: F1-OPT, F1-CPT, H-1B, TN, L-1, J-1, etc. For additional information around work authorization needs please use the following links. https://www.uscis.gov/working-in-the-united-states/temporary-nonimmigrant-workers and https://www.uscis.gov/green-card/green-card-eligibility/green-card-for-employment-based-immigrants Investment Code of Ethics For Principal Global Investors positions, you’ll need to follow an Investment Code of Ethics related to personal and business conduct as well as personal trading activities for you and members of your household. These same requirements may also apply to other positions across the organization. Experience Principal While our expertise spans the globe, we're bound by one common purpose: to foster a world where financial security is accessible to all. And our success depends on the unique experiences, backgrounds, and talents of our employees – individually and all of us together. Explore our core values, benefits and why we’re an exceptional place to grow your career. Principal is an Equal Opportunity Employer All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status. #LI-Remote"
BI Data Engineer,IMC Financial Markets,"Chicago, IL+1 location",https://www.indeed.com/rc/clk?jk=0142930738386156&fccid=93998d7f12d61ef7&vjs=3,"LIFE AT IMC AS A BI DATA ENGINEER WHO WE ARE AND WHAT WE DO IMC is a leading global market maker, using algorithmic trading and advanced technology to buy and sell securities on multiple trading venues worldwide. We provide liquidity to the financial markets, driving efficiencies for buyers and sellers. Founded in 1989, we are an ambitious, innovative company and identified early on the importance technology would play in the fast-paced evolution of trading. This entrepreneurial spirit still drives us today and can be found in all of our offices around the world. OUR TEAM We now operate globally from offices in Europe, the US and Asia Pacific. Our employees work closely together in multidisciplinary teams, making our success possible. Technology - At IMC, technology is not a department, it is at the heart of everything we do. Our technologists push the limits of possibility, and then look beyond. In our fast-paced environment, short feedback loops mean projects worked on in the morning can enter production the next day. Trading – Although our traders come from many backgrounds they all have one thing in common: they are at their best solving complex problems. Their insight into global events, market shifts and pricing ensure we are trading in the right place, at the right time. Business Support - Around the world, IMC’s business support teams are essential for sustaining our success. In our dynamic environment, we have many exciting challenges and multidisciplinary opportunities to shape our operations and make a real impact. OUR CULTURE Our employees are our greatest asset so we give them lots of responsibility and the support they need to make a difference. Our flat structure fosters a culture of openness and collaboration, encouraging the sharing of ideas and knowledge. It makes no difference if you have been with us for three days or three years, the best idea wins. While we work hard, we also have a lot of fun; whether solving complex challenges or in team building, leisure and sporting activities. IMC also enables its employees to contribute towards a better society through our foundation. BUSINESS INTELLIGENCE & ANALYSIS TEAM AT IMC The BP&A Team plays an important role in our finance operations and partners closely with the finance, trading, and middle office teams to understand their needs and provide them with meaningful insights through data analysis and reporting. Responsibilities: You will be focused on database development, maintenance, ETL process improvement and automation (ETLs mostly in python and Elastic Database) Work closely with other Data Analysts/Engineers to maintain and develop best practices and keep the middle office, finance, and trading teams up to speed with various migrations. You collaborate with global teams in Chicago and Sydney, reporting to the local BP&A lead. Analyze big data and extract valuable information, making it readily available in the decision-making process. You maintain existing and develop new business reporting solutions and you develop tools that increase efficiencies, data processing, and load times. The ideal candidate acts as a true partner to the business and is both technical and business-savvy, displaying strong analytical and interpersonal skills. WHAT MAKES IT FUN: You will act as a true partner to all areas of the business We strive to create cohesive global teams and you will collaborate with teams in Chicago and Sydney reporting into a global lead You will work closely with other data analyst/engineers to maintain and develop best practices and keep the middle office, finance, and trading teams up to speed with various migrations WHO YOU ARE: Degree in Computer Science, Mathematics, Statistics, Econometrics or other quantitative backgrounds or equivalent work experience 2-5 years of work experience as a Business Intelligence Analyst, preferably in a (Strategy) Consultancy role or a similar client-facing position Strong interpersonal and communication skills Strong business acumen Interest in and preferably exposure to finance processes Proficiency in SQL and Python Experience developing and managing business intelligence solutions for the organization Experience creating ETLs (preferred using Python / Qlik) Experience with developing business reporting applications (Qlikview strongly preferred) Someone who thrives within a dynamic, quickly changing environment OUR HIRING PROCESS To set you up for success, you can find our hiring process including tips on applying and interviewing with us on our website. Now it’s up to you! Apply today to start an amazing journey with IMC."
Data Infrastructure Engineer (Datamesh),Vericast,"Austin, TX",https://www.indeed.com/rc/clk?jk=91136f4441ef6807&fccid=401b88eb612fbde1&vjs=3,"Company Description We are Vericast. We create meaningful connections between business and the people that they serve - how, when and where it matters. By pushing the boundaries of data and insights, we spark discovery and inspire action to create profitable results. Vericast is a big data company. We receive over 100 billion intent signals daily, which assist in understanding a person’s in-market drivers across 1300 topics. Vericast uses its vast data assets to reimagine marketing solutions one business-to-human connection at a time. By influencing how over 120MM households eat, shop, buy, save, and borrow, Vericast fuels commerce, drives economic growth and directly accelerates revenue potential for over 70,000 brands and businesses. While its award-winning portfolio of products, technology, and solutions - including Illumis™, Valassis Consumer Graph™, and Harland Clarke ChecksCXTM - are a piece of the Vericast story, its people are the true differentiators, trailblazers in data intelligence, marketing services, transaction solutions, campaign management and media delivery. Job Description The Data Infrastructure Engineer – Data Mesh is a critical contributor to developing and growing a new data architecture and framework for scalable analytics and innovation called Data Mesh. This new architecture and framework enable an organization to build valuable datasets and make them discoverable, safe, reliable, and reusable by applying software product thinking to the job of making datasets easy and fun to use. This role will build the key architectural and feature components for the data mesh, including but not limited to search, catalog, data API and documentation, data lineage, and user access. Additionally, the project includes implementing the orchestration, transformation, and data movement of the datasets involved in the data mesh architecture. The Data Infrastructure Engineer – Data Mesh will report to the Sr. Director of Software Engineering. Qualifications Required Skills, Experience, Qualification: 3-5+ years of hands-on application engineering experience, preferably in a cloud or hybrid cloud environment Experience working with technical product owners building runtime systems that deliver automation of complex tasks through process design and scripting Experience building data pipelines and data orchestration systems is required Programming languages including Java, JavaScript, Python required Extensive experience building and documenting APIs with high availability and performance standards is required Experience with HTML and CSS is preferred but not required Experience working in an Agile Scrum team is required Primary Responsibilities: Developing the architectural components of the Data Mesh using multiple frameworks, services, and languages such as Python, Java and JavaScript Developing data pipelines using both commercial and/or open-source data pipeline tools such as Apache Kafka, Apache Airflow, Confluent, AWS Data Pipeline or AWS Glue Developing microservices, authentication and authorization capabilities Developing and documenting APIs using commercial, full API lifecycle management tools and best practices Build unit test cases for data products and execute them for coverage Contribute to a cross functional Agile Scrum team using Agile Scrum best practices, ceremonies, and artifacts Additional Information What's in it for you? Vericast offers a generous total rewards benefits package that includes medical, dental and vision coverage, 401K matching and generous PTO allowance. A wide variety of additional benefits like life insurance, employee assistance and pet insurance are also available, not to mention smart and friendly coworkers! Who we are: Valassis, a Vericast business, is the leader in marketing technology and consumer engagement. We work with over 60,000 companies and brands in a wide array of industries, partnering to anticipate consumer intent, inspire action, and create demand. Follow Valassis on LinkedIn, Instagram, Facebook and Twitter. #LI-LC1 #DICE"
Senior Data Integration Engineer,"JPMorgan Chase Bank, N.A.","Columbus, OH+1 location",https://www.indeed.com/rc/clk?jk=295337b045287b5b&fccid=aaf3b433897ea465&vjs=3,"Our Software Engineering Group supports several lines of business within Consumer and Community Banking by providing finance solutions to support profitability reporting, business insights, analytics, regulatory reporting and forecasting. We are a global team with colleagues across several locations in the US and in India and we have plans to expand to more locations in the near future. Our group is heavily focused on data processing utilizing several different technology stacks and we continually seek to improve our technology environment as part of our ongoing modernization journey. Our modernization plans include executing various on-prem version upgrades (Cloudera/Hadoop, Essbase, etc.), automating manual legacy processes, and migrating to new Data Centers and the public cloud (AWS). Whether you are passionate about Web App (JavaScript, ReactJS, Spring boot), Big data (Hadoop, Spark), traditional relational databases (Oracle, SQL Server), AWS, or any of the related toolsets or stacks, you will have the opportunity to also learn about the others. We are looking for someone who is very strong in at least one of the tech stacks, can help with automation efforts, or has AWS experience, and is willing to learn through our modernization journey together. Candidates that are always curious about technology will find our team primed with lots of opportunities for learning, building out skill sets, and continued growth as a technologist. Required Skills Strong experience with relational enterprise databases (Oracle and/or SQL Server) Proficiency in one or more modern programming language (Java, C#, Python) Advanced knowledge of SQL and query optimization concepts (TSQL and/or PL/SQL) Unix shell scripting and/or Windows scripting (PowerShell, Perl, Batch scripts) Creating/maintaining ETL processes AWS knowledge/certification (huge plus), Data Processing S3 objects, Redshift for Analytical Solutions Working proficiency in SDLC CI/CD Execution (GitHub, Jenkins, SNOR, Spinnaker, AIM etc.) Good understanding of Change management process (ServiceNow) Well versed with Data analysis and Data modeling Applying Process automation design principles and patterns Advanced knowledge of application, data, and infrastructure architecture disciplines Knowledge of industry-wide technology trends and best practices Passionate about building an innovative culture Ability to work in large, collaborative teams to achieve organizational goals BS. or MS. in computer science, information systems, math, business, or engineering Preferred Skills (not required but would be a plus for this position) Experience in migrating data workflows on-premises to public cloud Scheduling tools like Autosys or Control M Familiarity with API development experience JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management. We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs. The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment. As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law. Equal Opportunity Employer/Disability/Veterans"
Data Engineer,Burton,"Remote in Burlington, VT 05401",https://www.indeed.com/rc/clk?jk=968767ec5a96ec8c&fccid=48edf0ac3d689fc7&vjs=3,"Requisition Number: 762 Position Title: Data Engineer External Description: Burton’s benefits package includes health insurance (medical, dental and vision), life insurance (company paid), flex spending, short- and long-term disability insurance (company paid), great parental benefits, 401k plan with company match, and paid-time-off. Other perks include a discounted season pass, free lessons, product discounts, free demo equipment, ride days, casual work environment, and many more... The Breakdown: As a Data Engineer, you will play a key role in growing and transforming our operational and analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, and business intelligence/insights. This position may be based 100% remotely or in one of our global offices. What You Get to Do: Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment. Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate. Test data movement, transformation code, and data components. Experience with Informatica MDM Experience with configure Match and Merge and refining match rules based on business requirement and data specification. Experience with Web services and understanding of micro services architecture, experience integrate with MDM real time service. Basic understanding of Agile preferred. Basic understanding of DevOps preferred. Problem Solving - Strong problem solver who ensures solutions are built for the long term, canresolve new issues, recognizes mistakes using them as learning and teaching opportunities and consistently breaks down large problems into smaller, more manageable ones. Communication - Strong communicator who possesses the ability to articulate information clearly and concisely with the business, document work in a clear, easy to follow manner, collaborate well with team members as both a mentor and mentee What You'll Bring to The Team: Bachelor’s degree in STEM related field or equivalent training with data tools, techniques, and manipulation. 4 years of data engineering or equivalent experience / 5+ years of related experience Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices. Travel: The position does not require any travel. Work/Physical Environment: This position is in a typical, stationary office setting. Over 80% of the day will be spent sitting in 1 location. What’s next? Please submit an application with resume and cover letter on why you want to work for Burton. Applicants identified for first round selections will be provided with “Your Burton Timeline” encompassing what your work in this role will entail within 1 month, 3 months, 6 months, and 12 months on the job. Other steps may include questions via email to gain further insight into your experience, an informal phone call to connect on details of the role/ask questions, and one or more formal interviews via Zoom. City: State: Community / Marketing Title: Data Engineer Company Profile: EEO Employer Verbiage: At Burton, we are a purpose-led brand rooted in snowboarding and the outdoors. We fight for the future of our people, planet, and sport. We aim to maximize our positive social impact and minimize our negative environmental impact while delivering high-quality performance products. As a global leader in snowboarding, we’re committed to diversity, equity, and inclusion for the long-term health of our company, sport, and community. Through these efforts, we aim to make snowboarding and the outdoors accessible to all. Burlington, Vermont US The Burton community believes in respect for all people and the planet. We embrace and strive for a community that values differences and stands for equality and the fight to get there. Regardless of how you identify, how the world sees you, or how you play outside, please feel welcome to apply and join our community."
Data Engineer,ASR ANALYTICS LLC,"Phoenix, AZ 85007 (Central City area)",https://www.indeed.com/rc/clk?jk=00c409723e7414cb&fccid=7ae0026f5f516306&vjs=3,"ASR’s State and Local practice is seeking entry to mid-level data engineers to support the development of proprietary software applications. The ideal candidate will have a good understanding of data modeling in a NoSQL database, with experience building data pipelines to ingest and transform data, maintaining schemas, and developing APIs to leverage data in software applications."
Data Engineer,Fetch Rewards,"Remote in Birmingham, AL+1 location",https://www.indeed.com/rc/clk?jk=84dee327aabe373b&fccid=2e5a195d27f5250c&vjs=3,"What we're building and why we're building it. Fetch is a build-first technology company creating a rewards program to power the world. Over the last 5 years, we've grown from 0 to 14M active users and taken over the rewards game in the US with our free app. The foundation has been laid. In the next 5 years we will become a global platform that completely transforms how people connect with brands. It all comes down to two core beliefs. First, that people deserve to be rewarded when they create value. If a third party directly benefits from an action you take or data you provide, you should be rewarded for it. And not just the ""you get to use our product!"" cop-out. We're talkin' real, explicit value. Fetch points, perhaps. Second, we also believe brands need a better and more direct connection with what matters most to them: their customers. - Brands need to understand what people are doing, and have a direct line to be able to do something about it. Not just advertise, but ACT. Sounds nice right? That's why we're building the world's rewards platform. A closed-loop, standardized rewards layer across all consumer behavior that will lead to happier shoppers and stronger brands. Fetch Rewards is an equal employment opportunity employer. The Role: The data engineering team is working to use all the latest technology to build a performant, reliable, and scalable platform for delivering data. The work of data engineers is to enable all stakeholders to be able to access and use endless amounts of data that come from an ever-growing variety of data sources. At fetch our motto is to make data processing appear seamless and effortless for both producers and consumers of data. With a goal of having world class data availability with terabytes of daily data, data engineering is critical to Fetch's success. You Possess: Must be able to program in: Python, Java, TypeScript or Go! (Our DE's program a lot here at Fetch Rewards) Solid SQL skills Familiarity with Unix systems, shell scripting, and Git Experience with relational (SQL), non-relational (NoSQL), and/or object data stores (e.g., Snowflake, MongoDB, S3, HDFS, Postgres, Redis, DynamoDB) Interest in building and experimenting with different tools and tech, and sharing your learnings with the broader organization The desire to work with other teams in the organization (e.g., Development, Business Intelligence, Data Science) to build tools and solutions that support and help manage data within the Fetch ecosystem Bachelor's degree in Computer Science (or equivalent) At least 3 years of relevant full-time work experience Bonus points for: Excellent written and verbal communication skills Familiarity with open source software and dependency management ETL process, data pipeline, and/or micro-service development experience Cloud engineering and DevOps skills (e.g., AWS, CloudFormation, Docker) Familiarity with messaging and asynchronous technologies (e.g., SQS, Kinesis, RabbitMQ, Kafka) Big data development skills (e.g., Spark, Hadoop, MPP DW) Experience with visualization tools (e.g., Tableau) Love of Dogs! . . . Or just tolerance. We're a very canine-friendly workplace At Fetch Rewards, we'll give you the tools to feel healthy, happy and secure. Stock Options 401K Match - Up to 3% PPO and HDHP plans | Dental | Vision | Life Insurance Pet Insurance Education Reimbursement Unlimited PTO 10 Paid Holidays + End of Year Break Flexible 9 weeks of Parental Leave Full time wellness coach to help meet your exercise & wellness needs WFH Setup. Whatever hardware and software you need to get the job done Regularly scheduled virtual events, happy hours, cooking classes, etc."
Data Engineer I,"Jewelers Mutual Insurance Company, SI","Remote in Dallas, TX 75206",https://www.indeed.com/rc/clk?jk=c8c2dbf32d437596&fccid=d108b7465e2824ee&vjs=3,"Jewelers Mutual Group, United States and Canada’s leading insurer, risk advisor, and technology provider for the jewelry industry is hiring a Data Engineer I! This role is open to a hybrid or remote work model. WHY JM: We are a financially secure, exceptionally positioned, and intellectually curious company driven by our core values of Agility, Accountability and Relevancy! We continue to raise the tide of the jewelry industry we’ve served since 1913 through our innovative people, our unyielding customer commitment, and evolution of our products and services to be the most trusted advisor to all we serve. With a generous benefits package, office locations throughout the United States, and a mantra of “making your mark today”, consider evolving your career and shining bright with Jewelers Mutual Group! SUMMARY Responsible for creating and maintaining data pipelines, data integrations and data products; technical pipeline development and improvement efforts. ESSENTIAL DUTIES AND RESPONSIBILITIES include the following. Other duties may be assigned. Design, build and maintain scalable data pipelines and data products Collaborate with other Data, BI and Test engineers to review design, code and test plan Utilize CI/CD framework from data pipelines Creates technical documentation and data flow diagrams To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. QUALIFICATIONS Strong programming experience in Python Development experience with Airflow is required Experience in developing data solutions in Microsoft Azure Cloud services including Blob Storage, Data Factory, AKS, Azure Cloud Database, Data Bricks Knowledge of Google Cloud Platform, Cloud Composer, Docker, Windows, SQL and Google Big Query Experience with cloud database technologies (RedShift, Big Query, Snowflake, etc.) Experience with reporting solutions, Microsoft Power BI preferred Thinks analytically and the ability to drive business decisions based on data and reporting Ability to interact effectively at varying levels of business and technical organization Excellent verbal, written and interpersonal skills Knowledge and understanding of incident management Advance problem solving and technical troubleshooting capabilities Strong organizational, multi-tasking and prioritizing skills Experience with developing real time data processing EDUCATION & EXPERIENCE REQUIREMENTS Bachelors degree or higher in science or technology 1+ year of data engineering experience, including internship 1+ year of experience with Cloud platforms like GCP, Azure, and open source tools like Airflow 1+ year of data warehouse, relational database and SQL experience 1+ year of supporting ETL process and job scheduling experience 1+ year of supporting Business Intelligence solution, reports and dashboards experience Azure certifications are desired"
Data Engineer & Analyst,Benelynk,"Remote in Salt Lake City, UT 84111+17 locations",https://www.indeed.com/rc/clk?jk=9899133dacb08430&fccid=9656435542936ad4&vjs=3,"COMPANY OVERVIEW Does the idea of applying your talents at a company that assists people in understanding how to obtain additional health care benefits and compensates well for doing so, inspire you? We call it “Doing good while doing well” and invite you to apply to join us and begin moving forward along a beneficial career path – one built on providing solutions by helping others navigate through the complex world of health care benefits. Here at BeneLynk, our mission is to improve lives and positively impact social determinants of health barriers by providing our healthcare partners with the information they need, and people with the advocacy they deserve. We are laser-focused on our longstanding area of expertise in the healthcare world. We fully understand barriers and surface solutions, then provide the advocacy that changes lives and improves outcomes. Everything we do, from the systems we build, to our government relations, to our outreach operations, is in service of this one central vision. WHO WE ARE We are big-hearted people, passionate about serving our health plan clients, their members, and each other. We are a team in every sense of the word, striving toward a common mission – that is the goal of everyone at BeneLynk. Every day, we are relentless in helping people who need essential resources to make their lives easier and healthier. The members we serve call us ""miracles,"" ""kind,"" ""professional,"" ""human,"" and ""compassionate,"" and all with ""service that gets the job done."" We pride ourselves on creating a healthy environment for our employees to thrive in their ability to assist others. DATA ENGINEER & ANALYST POSITION SUMMARY The Data Analyst will report directly to the Manager of Business Intelligence and Analytics and is responsible for supporting a broad variety of team responsibilities. The Data and Analytics team is responsible for all internal and external Reporting and Analytics. To accomplish this, the team owns and maintains an ETL process into a Data Warehouse. From that space, the team supports a variety of extracts and dashboards that are delivered to internal operations and to external clients. The Data and Analytics team partners with clients and operations to improve performance and win new business by supporting and driving ad hoc analytics. And finally, the team is responsible for data science and strives to create a key competitive advantage for BeneLynk. The Data Analyst will work under the direction of their Manager and the VP of Data and Analytics to make key contributions in all of these areas, with the opportunity to grow their ownership and contributions to the company’s success. The ideal candidate can quickly do the data-driven work they are assigned. They can ask for support as it is needed. They can think through a request to identify all dependencies and can think of several ways to accomplish a goal before identifying the best approach. Candidates who are recent graduates are invited to apply! KEY RESPONSIBILITIES General and Backend: Help to maintain an SQL data warehouse. Update the ETL process and anticipate bugs. Understand operations and the data created by operations (supported by a development team) Learn Azure platform tools to execute work. Especially Azure Data Flows, Azure Logic Apps, and Azure Analysis Services. Able to solve problems independently Able to identify key decisions and raise awareness and questions to appropriate parties Reporting and Analytics: Support and improve existing dashboards. Support and improve data extracts to internal and external stakeholders. Identify operational reporting gaps. Support management team efforts to tell stories and keep clients informed. Conduct troubleshooting and root cause analysis for complex issues. QUALIFICATIONS Education – Bachelor’s degree or higher required in Computer Science, Computer Information Systems, Engineering, Statistics or Mathematics, or equivalent Experience – Technical experience with data modeling and database design, including data warehousing. Experience utilizing ETL tools (Azure Data Factory, AWS Glue, Stitch, etc.) Excellent communication and problem-solving skills. Must have extraordinary attention to detail and immaculate data management skills to ensure proper verification and consistency of data inputs and outputs. Prior experience with Python is a plus Experience with business intelligence software a plus (Power BI, Tableau, etc.) Experience with Cloud platforms a plus (Azure, GCP, AWS, etc.) PHYSICAL DEMANDS The physical demands described here are representative of those that must be met by an employee to successful perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Physical Activities – While performing the duties of this job, the employee is frequently required to remain in a stationary position as well as communicate ideas to others. The employee is occasionally required to move about their office space. Weight Lifted/ Force Exerted – The employee’s job does not require weight to be lifted or force exerted. WORK ENVIRONMENT This role is a remote position. POSITION TYPE/ EXPECTED HOURS OF WORK Full-time HOURS To be determined SALARY Based on Experience EMPLOYEE BENEFITS We offer competitive salaries and benefits here at BeneLynk, as we truly value our employees and the amazing work that they do each day. Please see below for a list of some of our awesome employee benefits: Monthly Bonus Incentives Medical, Dental, Vision and Employee Assistant Program Benefits 401K Match 15 Paid Days Annually Excellent Growth & Advancement Opportunities EMPLOYEE PERKS Work hard, play hard! Having an engaged workforce and positive work environment is one of our top priorities here at BeneLynk. We do so through numerous initiatives that can be found below. We like to call our virtual work community, “The Bene-Verse”. We also have an internal Culture Ambassador committee dedicated to ensuring all employees have a pleasant and exciting work experience. Monthly Company Town Hall Events: We love the opportunity to come together as a company. Join us monthly as we discuss exciting company updates, internal promotions, internal awards, upcoming events, and more! Monthly Internal Mental Health Newsletters: Our Culture Ambassadors spearhead an internal newsletter centered on mental health topics. Our employees’ overall wellbeing is our top priority, so we like to provide support whenever it is needed through this uplifting internal newsletter. Monthly Streaming Services Perk: Yes- we pay YOU to enjoy the television shows that you enjoy! We pay up to a $12 per month for any streaming service subscriptions that you currently have. Tickets at Work Perk: Enjoy discounted movie tickets, hotel stays, and more through our company’s ‘Tickets at Work’ perk! Monthly Lunch & Learn Events: Meet key members of our Senior Management team through engaging Lunch & Learn sessions on a monthly basis. Lunch is on us for those employees that sign up! Monthly Bene-Verse Events: We put on awesome monthly events for our employees including virtual trivia, team building exercises, guided painting sessions, and more! EEO STATEMENT At BeneLynk, we don’t just accept differences; we celebrate, support, and thrive on them for the benefit of our employees, our products, and the communities that we serve. All employees share in the responsibility for fulfilling this company’s unwavering commitment to equal employment opportunity. BeneLynk is an equal opportunity employer, and as such, employment here is solely based on a person's merit and qualifications directly related to their professional expertise. BeneLynk does not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, military status, marital/familial status, pregnancy, or related condition, including breastfeeding, or any other classes protected by law. It is BeneLynk’s policy to comply with all applicable federal, state, and local laws pertaining to nondiscrimination and equal opportunity. The company's EEO policy, as well as its affirmative action obligations, includes the full support of the company, including its Chief Executive Officer because it's just the right thing to do and we hope that you think so too. If you require reasonable accommodation in completing an application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to our HR team at HR@BeneLynk.com. E-VERIFY BeneLynk participates in E-Verify. We will provide the U.S. Social Security Administration (SSA) and, if necessary, the U.S. Department of Homeland Security (DHS) with information from each new employer’s Form I-9 to confirm work authorization. ***Offer of employment is contingent upon the results of a required background and drug screening.***"
Electrical Engineer - Data Center Design,Facebook App,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=d1b60bd11f4243ef&fccid=ba07516c418dda52&vjs=3,"Meta is seeking an Electrical Engineer experienced in the design and operations of Critical Facilities to become part of our Data Center Design team. Our data centers are the foundation upon which our software operates with efficient ease. Building and operating data centers the ""right"" way from the day they go live is synonymous with ensuring capacity availability and capital conservatism. The Meta Data Center Design team endeavors to be the benchmark of innovation for the data center industry and improve reliability, safety and efficiency through innovative solutions, enabling Infrastructure teams to excel in achieving their goals. Electrical Engineer - Data Center Design Responsibilities: Lead the team in the development of prototype design of data center electrical infrastructure for improved reliability, efficiency, speed to market and cost Create criteria to evaluate benefits and feasibility of the solution for scalable deployment Cross-functional collaboration with other Meta teams including Software Engineering, Hardware Engineering, Network Engineering, Operations and Capacity Analysis teams Provide technical due diligence review and evaluation for the data center site selection process Develop strong industry relationships with other data center peers and organizations to remain current on industry trends and future directions Travel domestically and internationally to data center sites for engineering studies, electrical systems audits, and collaboration with local teams as required Minimum Qualifications: BS in Electrical Engineering or related field 8+ years professional experience in electrical systems design, construction, operations, and maintenance Electrical Professional Engineer registration Experience in high voltage substation design, medium voltage distribution systems, mission critical power distribution, generators, UPS, PDU, and Building Management System Experience in High Voltage electrical transmission, distribution, and utility interconnection processes Knowledge of industry standards, building codes and safety standards including NEC, NETA, ANSI, IEEE, NFPA, UL, UFC and UBC Knowledge of international standards including IEC, CE and EN Cross-discipline knowledge of complete critical facility systems Proven troubleshooting and analytical skills Experience providing solutions to complex projects under pressure Proven presentation and communications skills Preferred Qualifications: Large and complex system design experience, including campus systems Research & Development experience including concept, design, modeling, prototyping, testing, and production support Lean Construction certification/experience LEED Certification/Credentials Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
Data Engineer,"Quadrint, Inc.","McLean, VA 22101",https://www.indeed.com/company/Quadrint/jobs/Data-Engineer-0c976f06a3ac3297?fccid=d790a02569d5b88c&vjs=3,"Quadrint is a fast-growing, Information Technology consulting company in the public sector that has been named to The Washington Post's Top Workplaces for the past five years! We pride ourselves in our employees feeling welcomed, valued, and involved. Full vaccination against COVID-19, and compliance with Quadrint’s vaccination verification procedures, is required for this position, unless the individual is legally entitled to a reasonable accommodation. Quadrint is seeking a Data Engineer in the McLean, VA area. A qualified candidate will have the opportunity to implement data engineering activities on some of the most mission-driven projects in the industry. In support of talent efforts, will have the opportunity to build out ETL pipelines, write custom code, interface with data stores, perform data ingestion, and build data models. Display analytical exploration and examination of data to support the assessment, design, building, and maintenance of scalable platforms, and work with clients to solve their most pressing challenges. Security Clearance Requirement: Active/current TS/SCI with Polygraph is required. Required Qualifications: BA or BS degree. 2+ years of experience in data engineering. Experience performing data pipeline and ETL processing. Experience designing and deploying secure data environments. Experience regularly interacting with technology and business partners. Knowledge of database design, query, including SQL, and optimization. Ability to work on complex technical solutions. Preferred Qualifications: Experience working with core AWS capabilities to include RDS, EC2, and S3 through the management console and CLI. Experience with Angular, Flask or other web development frameworks. Experience building Tableau dashboards. Experience with Databricks / Apache Spark / NiFi. Experience working with core AWS capabilities to include RDS, EC2, and S3. Quadrint is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, genetic information, national origin, age, marital status, protected veteran status, status as an individual with a disability, or any other protected status. Job Type: Full-time"
Sr. Cloud Data Warehouse Engineer,Twin Health,"Remote in Mountain View, CA",https://www.indeed.com/rc/clk?jk=fd2219818f604806&fccid=4f8617ef408c69f9&vjs=3,"Twin Health At Twin Health, we empower people to reverse, prevent and improve chronic metabolic diseases. Twin Health invented The Whole Body Digital Twin™ , a dynamic representation of each individual's unique metabolism, built from thousands of data points collected daily via non-invasive sensors and self-reported preferences. The Whole Body Digital Twin delivers a new standard of care, empowering physicians and patients to make personalized data-driven decisions. Early trials demonstrate that over 90% of patients achieve type 2 diabetes reversal and 93% eliminate all diabetes medication including insulin. Working here Our team is passionate, talented, and driven by our purpose to improve the health and happiness of our members. Our culture empowers each Twin to do what's needed to create value for our customers and our company, and enjoy their experience at work. Twin Health was awarded Innovator of the Year by Employer Health Innovation Roundtable (EHIR) (out of 358 companies), named to the 2021 CB Insights Digital Health 150, and recognized by Built In's 2022 Best Places To Work Awards. In October 2021, Twin Health announced its Series C funding round of $155M, led by ICONIQ Growth, enabling us to scale services in the U.S. and globally, helping to solve the global chronic metabolic disease health crisis. We are building the company you always wished you worked for. Join us in revolutionizing healthcare and building the most impactful digital health company in the world! Excited to join us and do your part in improving people's health and happiness? Twin Heath is expanding rapidly across health providers nationwide in the US as well as India. We are seeking an experienced Data Warehouse Engineer to join our growing team to own the entire process of building data warehouse from scratch and managing ETL pipelines, working collaboratively with internal business stakeholders and customers. Responsibilities Drive analysis, architecture, design, and development of Cloud based data warehouse and business intelligence solutions Design and develop data flows and models for data warehousing and self-serve reporting Design and build extensible data acquisition and integration solutions to meet business reporting and analytics needs. Own and develop architecture supporting the translation of analytical questions into effective reports that drive business action Automate and optimize existing data processing workloads to integrate with the enterprise data warehouse Understand and translate business needs into data models to support long-term, scalable, and reliable solutions Create data models for self-serve reporting. Build data pipelines from systems such as CRM, ERP and internal applications with the emphasis on scalability and reliability Partner with business users, senior architects, and infrastructure engineers to form complete end-to end-solutions Drive data quality across the organization; develop best practices for standard naming conventions and coding practices to ensure consistency of data models and tracking Prepare to respond to ad hoc reporting needs of business functions. Work in a fast-paced environment and perform effectively in a sprint based agile development environment. Collaborate with developers and analysts on technical and functional designs Analyze query performance and perform query tuning to assist development engineers in designing and optimizing queries Qualifications Bachelor's degree in computers Ince or related field. At least 8 year of overall experience building data warehouse solutions with solid data modeling skills At least 3 years of hands-on experiencein building Cloud Data Warehouses in Snowflake or Redshift At least 2 years of experience creating DBT models andin a cloud, data Warehouses platform Knowledge of advanced SQL scripting and ability to write complex queries Experience using new age ETL tools like Fivetran, Matillion etc. Experience in developing data pipelines using Python or Java Experience designing highly scalable ETL/ELT processes with complex data transformations, data formats including error handling and monitoring. Excellent analytical, problem solving, and troubleshooting skills to manage complex process and technology issues Strong verbal and written communication skills Benefits Twin has an ambitious vision to empower people to live healthier and happier lives, and to achieve this purpose, we need the very best people to enhance our cutting-edge technology and medical science, deliver the best possible care, and turn our passion into value for our members, partners and investors. We are committed to delivering an outstanding culture and experience for every Twin employee through a company based on the values of passion, talent, and trust. We offer comprehensive benefits and perks in line with these principles, as well as a high level of flexibility for every Twin A competitive compensation package in line with leading technology companies A remote and accomplished global team Opportunity for equity participation Unlimited vacation with manager approval 16 weeks of 100% paid parental leave for delivering parents; 8 weeks of 100% paid parental leave for non-delivering parents 100% Employer sponsored healthcare, dental, and vision for you, and 80% coverage for your family; Health Savings Account and Flexible Spending Account options 401k retirement savings plan Free membership with One Medical, Carrot Fertility, Aaptiv, Headspace and other perks in line with our focus on employee wellbeing"
Junior Engineer Data Science,Verizon,"Irving, TX 75038+8 locations",https://www.indeed.com/rc/clk?jk=729d4f5080a00956&fccid=f7029f63fe5c906e&vjs=3,"When you join Verizon Verizon is one of the world's leading providers of technology and communications services, transforming the way we connect across the globe. We're a diverse network of people driven by our shared ambition to shape a better future. Here, we have the ability to learn and grow at the speed of technology, and the space to create within every role. Together, we are moving the world forward - and you can too. Dream it. Build it. Do it here. What you’ll be doing... Verizon is one of the world's leading providers of technology and communications services, transforming the way we connect across the globe. We're a diverse network of people driven by our shared ambition to shape a better future. Here, we have the ability to learn and grow at the speed of technology, and the space to create within every role. Together, we are moving the world forward - and you can too. Dream it. Build it. Do it here. Our mission is to secure all applications in the enterprise. In this role you should be comfortable working in a dynamic environment with multiple concurrent responsibilities in real time Application Log Monitoring, Fraud prevention analysis and Alert reporting for action. This role will cover log analytics skills using Splunk, Log shipping skills using Kafka/FluentD, to perform log monitoring and reporting anomalies to prevent any security incidents. As a Juniordeveloper, you will work on a Logging and Monitoring project where the team collects data from different applications and analyzes the logs to look for vulnerabilities and reports for action. Candidate will be responsible for: Using Kafka/other message broker or queueing technologies to handle data flows and distribution, Splunk ingestion and Splunk tool for log monitoring and pattern analysis. Managing Logshipping process, Handling various shippers like Logstash, FluentD, FluentBit, Splunk Forwarder and various logging libraries (Log4J, log4N, logback) Managing log onboarding process for Container based on log plugins Participating in evaluating new information security tools Working with teams on how to document and mitigate security issues Be able to troubleshoot difficult Technical Problems Research root cause for false positives and update indicators as appropriate to reduce false-positive while minimizing false-negatives. Analyze events and alerts, and properly classify as incidents or false-positives. Work with various teams regarding Application log shipping and Log Analysis requirements. Where you'll be working… In this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager. What we’re looking for... You’ll need to have: Bachelor's degree or one or more years of work experience. Experience in Java and .NET and secure coding practices Experience with logging in a distributed micro service environment. Experience in dealing with large amounts of data. Experience with Kafka/other message broker or queueing technologies to handle data flows and distribution. Experience with log shippers like Logstash, FluentD, Beats, Splunk Forwarder. Experience with various logging libraries (Log4J, log4N, logback) and Splunk tool for log monitoring and pattern analysis. Knowledge with Container based on log plugins and CI/CD tools Even better if you have one or more of the following: Two or more years of relevant work experience. Knowledge with highly scalable system architectures. Experience with at least one of the cloud platforms (AWS, Azure, Google Cloud) and aware of security data classifications and OWASP standards. Experience with Splunk MLTK/Elastic/Kibana is a plus. Excellent oral and written communication skills. Ability to present findings concisely and effectively to critical audiences Excellent presentation skills in data storytelling to senior executives. Ability to work with various application teams to assist resolving project related issues Knowledge of current industry standards for secure web and mobile design Self-starter with strong self-management skills. Ability to organize and manage multiple priorities. Ability to lead work efforts with offshore and onshore resources across different organizations Strong analytical and problem solving abilities. High Level of motivation abilities. Technology savvy abilities. Learning abilities 22CyberAPP Equal Employment Opportunity We're proud to be an equal opportunity employer - and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more. COVID-19 Vaccination Requirement Verizon requires new hires to be fully vaccinated against COVID-19. Verizon provides reasonable accommodations consistent with legal requirements (e.g., for medical, religious, or state law recognized reasons)."
Data Engineer,Knackshops Inc,Remote,https://www.indeed.com/company/Knack/jobs/Data-Engineer-53affeba14034be3?fccid=fc61c504f4d1cf04&vjs=3,"Description: This fully remote role is open to candidates in most states. Working remotely from a primary residence outside the United States is currently not permitted for this role.We’re seeking an experienced Data Engineer to help us build data pipelines to transform data from multiple sources into our reporting and analytics data store using modern data pipeline methodologies and technologies on AWS. Our engineers work on full stack solutions with a strong emphasis on SOA leveraging modern technologies and SDLC.As a founding member of our Data Platform Engineering team you'll help us analyze, design, and build modern data pipelines that transform data into structures needed for analysis and reporting. You have strong Python skills, exquisite SQL and MySQL knowledge, experience building real-time and scheduled data pipelines, and have experience and knowledge regarding data pipeline strategies and technologies within the AWS Cloud. You’ll add immediate value building systems that collect, manage, and transform raw data into usable information for business analysts and operations managers to leverage, making data accessible so that our organization can use it to evaluate and optimize our operations, performance, and inventory.The job responsibilities include understanding and evaluating our current platform, data schemas, and stores; and collaborating with our Product, Merchandising, and Sales teams to architect and engineer our data analysis and reporting platform to remove and reduce friction across our organization. We’ll be ripping off the “duct tape and strings” and building our next level data warehouse and reporting system.This is a unique opportunity to join a successful e-commerce company pivoting in its journey, from a retail first company, to a technology company, in order to scale our platform to match our growth goals. Come help us build a team of experienced engineers transforming our full stack and aligning our technical staff & capabilities to meet the demands of our growing business and YoY success. As we build our platform of the future you'll have an amazing opportunity to create a long lasting impact as a founding member of our staff, as you help set the roadmap and technology base for our growing engineering department.About Knack: Knackshops Inc is the market-leading custom gift platform that helps customers deepen their interpersonal relationships through meaningful gifts. At the core of what we do is a firm belief in gift giving as a creative force for good in the world, and a commitment to making gift givers the hero in everything we do. Our mission is to disrupt the $60B “send a gift” market by harnessing technology to empower gift givers and build powerful digital experiences around physical gifts.Knack offers more individualized customer experiences, ethos-based products and expert advice than any competitor in the category. The first 100% made-to-order gift challenger, our market-leading features such as video messaging, Gift Builders and Private Events are widely mimicked but not surpassed. Our latest innovation, Knest, provides flexible personal and company-branded gift sites that bring gift givers and gift recipients closer together by adding a digital experiential layer to the act of gifting.Our culture is ambitious and collaborative. We are optimistic and mission-driven. We believe that people live up to the expectations we have of them, and we expect greatness from each other. We work hard but always have each other’s backs. We problem solve but don’t blame. When challenges arise, it’s all-hands-on-deck because we expect mistakes and learn from them. We create space for employees to be their best selves. We trust our employees to manage their own time and location and we work hard to maintain our strong culture as we grow.Knack is an Equal Opportunity Employer. Knack does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit and business need.. Requirements: Who you are: Have experience evaluating and understanding legacy schemas and acquiring datasets that align with business needs. Have strong experience building, testing, and maintaining database pipeline architectures. Have experience developing algorithms to transform data into useful, actionable information. Have significant experience with Python, SQL on AWS MySQL RDS, and leveraging AWS technologies to build data pipelines. Have expertise building real-time and schedule driven data ELT (extract, load, transform) systems that provide data formatted for highly performant reporting and analytics needs. Can ensure compliance with data governance and security policies in collaboration with our Security team. Have middle-tier SOA experience and skills designing and writing micro-services in Python, Golang, etc. Experience implementing testable code and unit tests in the UI codebase and middle tier services. We focus on quality vs quantity as we implement our test and evaluate our coverage. Bonus if you have experience with containerized services via docker and Kubernetes. Have experience with Docker, AWS Technologies, MySQL, Lambda (Serverless), and comfort interacting with AWS resources via Console, SDKs, and the CLI. You have a desire to drive platform reporting and analytics architecture, design, and implementation, and can communicate architectural concepts succinctly. You have a strong passion for modern technologies and driving innovation. Learning technologies and expanding your skills is always on your mind. Job Type: Full-time"
Data Engineer,WellNow Urgent Care,"Chicago, IL",https://www.indeed.com/rc/clk?jk=ced99aabaf7a4d9c&fccid=8f8b24a6fb7522ae&vjs=3,"WellNow Urgent Care℠ is here to help our patients get well. Founded in 2011 with just 12 locations, we have quickly grown to 96+ locations across New York, Illinois, Ohio and Michigan. Our growth-focused model positions us as one of the fastest-growing providers of quality urgent, virtual, and occupational care. Come join our team today! The Data Engineer is a key member of WellNow’s Analytics team. Their work enables data-driven decision making across the organization by collecting, transforming, and publishing data from various structured or unstructured sources. They lead by example, building high-performing data pipelines and data stores that are efficient, organized, and reliable. Their work focuses on creating enterprise data models which are flexible, robust, and highly available while being cost-effective. They work cross functionally as a solution partner, having daily interactions with internal teams across WellNow as a collaborator and colleague, and on occasion with external parties. In time, they become subject matter experts regarding WellNow’s data and processes, able to use their expertise to manage multiple projects at once, while making recommendations to ease support issues. Responsibilities: Design, develop and monitor large scale data pipelines empowering executive dashboards, operational reporting, and machine learning algorithms Consume and process data from a variety of sources (RDBMS, APIs, FTPs and other cloud storage systems) and file formats (Excel, CSV, XML, JSON, Parquet) Use advanced data modeling skills to design and develop dimension and fact tables supporting a near real-time enterprise data model Create and maintain documentation pertaining to data systems (configurations, test plans, functional specs, etc.) Use consultative skills to better understand and mature customer requirements while identifying and resolving potential design issues Perform duties and responsibilities specific to department functions & activities and any other assigned task by reporting manager Minimum Education and Experience: Bachelor’s or higher degree in Computer Science, Data Science, or related technical discipline Advanced MS SQL Server knowledge (MS SQL Server 2016+ preferred) Development expertise with MS SQL Server Integration Services (SSIS) Able to author complex DAX queries Experienced using Power BI Dataflows and Power Query Proficient with cloud DW and ETL/ELT solutions (e.g., Snowflake, BigQuery, Talend, Matillion, etc.) What Sets You Apart: Expert Microsoft t-SQL and DAX development skills Extensive experience using various data modeling techniques (Kimball, Inmon, or Data Vault) Experience using the Power Platform, particularly Power Bi and Power Automate Familiar with Azure and/or GCP WellNow is an EOE"
Expert Data Engineer (ORM),Prescient Edge Federal,"Washington, DC 20032 (Anacostia area)+7 locations",https://www.indeed.com/rc/clk?jk=d3433654e0bde428&fccid=bfb11e13c321848d&vjs=3,"Job Description: Prescient Edge is seeking an Expert Data Engineer (ORM) to support a federal government client. Please note that the availability of this position is contingent upon contract award. Benefits: At Prescient Edge, we believe that acting with integrity and serving our employees is the key to everyone's success. To that end, we provide employees with a best-in-class benefits package that includes: A competitive salary with performance bonus opportunities. Comprehensive healthcare benefits, including medical, vision, dental, and orthodontia coverage. A substantial retirement plan with no vesting schedule. Career development opportunities, including on-the-job training, tuition reimbursement, and networking. A positive work environment where employees are respected, supported, and engaged. Security Clearance: Security clearance required TS/SCI with the ability to obtain CI POLY Job Requirements: Qualifications: Designs, implements, and operates data management systems for intelligence needs. Designs how data will be stored, accessed, used, integrated, and managed by different data regimes and digital systems. Works with data users to determine, create, and populate optimal data architectures, structures, and systems. Plans, Designs, and optimizes data throughout and query performance. Participates in the selection of backend database technologies (e.g. SQL, NoSQL, HPC, etc.), their configuration and utilization, and the optimization of the full data pipeline infrastructure to support the actual content, volume, ETL, and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness. Demonstrates ability to define problems, supervise studies and lead surveys to collect and analyze data to provide advice and recommend solutions. Demonstrates analytic leadership and expertise in identifying, planning, developing, and executing analytic production methodologies, tradecraft and techniques aligned with labor category mission. Demonstrates extensive ability to provide strategic advice, technical guidance and expertise to Defense planners and policymaker (e.g., Undersecretary level or higher). Desired Experience: Minimum 20 years of experience conducting analysis relevant to the specific labor category with at least a portion of the experience within the last 2 years. Desired Education: Master's degree in an area related to the labor category from a college or university accredited by an agency recognized by the U.S. Department of Education. Location: DIA HQ."
Data Engineer,Tron,Remote in California,https://www.indeed.com/rc/clk?jk=4e6f954d4879a9c5&fccid=0291d13b357c085b&vjs=3,"Come help us build the data pipelines driving the business behind one of the world's largest internet networks. Design, develop and deploy the systems that empower teams across the organization to be data-driven. Iterate alongside other engineers and business leaders to continue to deliver on the promise of being a data-driven company. The Role As a Data Engineer you will be responsible for our ETL/ELT data processing at scale. Our ideal candidate Experience with ETL/ELT processing, pipeline management and debugging Strong understanding of data processing at scale: map-reduce, streaming Fluency in Python 3 Fluency with SQL and relational databases concepts Experience with MapReduce using Java or Python 2+ years of big data development experience Familiarity with Airflow (or similar) and dbt An understanding of the concepts behind git and basic command-line proficiency Familiarity with AWS RDS, S3, Redshift, Glue, Athena and other AWS data-related services Experience working with cross-functional teams with diverse skill sets You will Perform ETL/ELT processing with Python at scale Be in charge of ensuring correctness and performance of both ad-hoc and reporting pipelines processing dozens to hundreds of gigabytes daily Build pipelines that can ingest and correlate terabytes of historical analytics and instrumentation data Work alongside a cross-functional team including engineering, product, design, infrastructure and business intelligence Influence and improve the design of instrumentation and analytics related components behind distributed applications Work alongside Data Science and Data Analysts teams to ensure the data pipelines are correct, performant and efficient for a given experiment Participate in code reviews, provide guidance and support to developers across the organization in all matters related to data BitTorrent is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status or disability status."
Data Engineer,NXP Semiconductors,"Austin, TX 78735 (West Oak Hill area)",https://www.indeed.com/rc/clk?jk=074fc42385e0292a&fccid=d113f5fdf3e1cb7b&vjs=3,"Data Engineer Business Line Description: NXP’s Design Enablement team supports global design groups with EDA flows related to semiconductor chip development. The team supports both digital and analog EDA tools as well as other initiatives to help automate and optimize development of chips in NXP’s portfolio. Job Summary: Looking for a highly motivated individual to be part of an Analytics team within the Design Enablement group focused on improving and optimizing our semiconductor development flows and compute utilization across NXP. This role will provide an opportunity to work with many cross-functional teams such as design teams, flow developers, IT, finance, and more. Typical work will involve using the AWS cloud platform develop, automate and maintain data pipelines feeding operational analytics, opportunity analyses, forecasting and prediction engines. Key Challenges: This is a relatively new team that will be focused on analytics around general semiconductor chip development. Will be learning a number of new tools and skills Working with incomplete datasets Collaborating with different groups internally Cross Functional aspects: Opportunity to work with many different global organizations within NXP including Design Enablement, Business Lines, Sourcing/Procurement, IT, Finance, Executive teams, and more Generate data streams and analysis that will be used across NXP Job Qualifications: A bachelor's degree in computer science, information systems, data management or a related study (or equivalent work experience) is required with at least 3 years’ experience with an appetite for learning new tools and skills. Data Engineer Cloud data platform experience, AWS preferred Athena, RDS, Redshift, Glue, Cloud Formation, Spark, Lambda, Sagemaker, S3, EventBridge, EC2 AWS skills Strong SQL skills Able to architect and develop data pipelines. Strong scripting language skills Good feel for and ownership of data quality, able to anticipate problems Solid linux environment skills Develops solutions with an eye toward long term maintainability Comfortable with basic software engineering processes (CM, CI, Release Mgt, Ticketing workflows) BI tool experience a plus Semiconductor experience a plus Job Location: Austin, TX NXP is an Equal Opportunity/Affirmative Action Employer regardless of age, color, national origin, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, marital status, status as a disabled veteran and/or veteran of the Vietnam Era or any other characteristic protected by federal, state or local law. In addition, NXP will provide reasonable accommodations for otherwise qualified disabled individuals."
Senior Data Engineer,Disney Media & Entertainment Distribution,"Seattle, WA+5 locations",https://www.indeed.com/rc/clk?jk=a68d16b43b9d362c&fccid=c3092a91bcb42ca9&vjs=3,"This Data Engineer, Personalization and Recommendations is a position within the CXP group of The Walt Disney Company’s DMED division. This role reports to Data Team Lead, Personalization and Recommendations. If hired, you will play a meaningful role in the evolving experiences across consumer facing digital products, with responsibilities for the technical design and implementation of medium size projects and features. We are looking for you if you are Highly adaptable and committed to learning Have a track record of delivering solutions utilizing Python Thrive in an agile and collaborative environment. #LI-AUU1 #CXPNGS Responsibilities : Create and maintain optimal data pipeline architecture Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Design, develop, test, deploy, maintain and improve software Participate in the design and implementation of core Platforms and Content Distribution systems Collaborate with internal & external teams to define requirements and delivery schedules for projects Design and deliver high quality code for small to medium size projects and make critical contributions working with others on larger projects Work with the team to iteratively improve development practices and processes Build strong relationships with the team while collectively finding opportunities for improvements around quality and automation Basic Qualifications : 7+ Years of relevant work experience Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing data pipelines, architectures and data sets. Robust programming skills and strong experience with Python Experience with the following technologies is a plus: AWS, Kafka, Airflow, Postgresql, Spark Exposure to full lifecycle of application development, including practices like continuous integration, unit testing, code reviews, documentation, etc. Interest in industry trends on new technologies, best practices and solutions. A passion for innovation and raising the bar in all development aspects. Proven ability to work on a diverse scope of software projects requiring strong attention to detail and creative problem solving. Passion for software quality and for advancing testing as an engineering discipline Required Education : Bachelor’s degree, with equivalent work experience in MIS, Computer Science or related discipline"
Snowflake Developer or Data Engineer,Kaizen Technologies,"San Jose, CA",https://www.indeed.com/rc/clk?jk=3f73462455320b6b&fccid=c1edd7669511bab9&vjs=3,"Required Skills : Snowflake Job Description : Position: Snowflake Developer or Data Engineer Location: San Jose - CA Duration: Contract Job Description: 1.Job title COGNIZANT IS LOOKING FOR SNOWFLAKE DEVELOPER / DATA ENGINEER 2. Job summary The Snowflake Senior Developer must have at least 6 to 9 years of experience. Required Experience and Skills: - At least two years of experience in Snowflake development - Highly proficient at SQL development. - Significant experience in Python development/DBT/ETL. - Current SnowPro Certification Preferable (Not mandatory). - Airflow (not mandatory) 3.Experience 8to10yrs 4.Required Skills Technical Skills- SQL Developer, Snowflake, Apache Airflow Domain Skills- 5.Nice to have skills Technical Ski 3.Experience 11to14yrs 4.Required Skills Technical Skills- SQL Developer, Snowflake, Apache Airflow Domain Skills- 5.Nice to have skills Technical Skills- Domain Skills- 6.Technology Data Management 7.Shift Day 8.Roles & Responsibilities 2000 Chars The Snowflake Senior Developer must have at least 6 to 9 years of experience. Required Experience and Skills: - At least two years of experience in Snowflake development - Highly proficient at SQL development. - Significant experience in Python development/DBT/ETL. - Current SnowPro Certification Preferable (Not mandatory). - Airflow (not mandatory) 3. Experience 8to10yrs 4. Required Skills Technical Skills- SQL Developer, Snowflake, Apache Airflow Domain Skills- 5. Nice to have skills Technical Skills- Domain Skills- 6.Technology Data Management 7.Shift Day 9 AM - 7 PM EST 8.Roles & Responsibilities Must have experience developing the different layers within Snowflake Staging Integrated and DM and performing data transformations between the different layers. - Must be able to perform batch and incremental loads within Snowflake using ETL tools Snow Pipe Streams and Tasks. - Must have very strong SQL experience. - In-depth knowledge of Cloud services. - Experience in databases like Oracle, RDS, Redshift, SQL Server. - Hands-on experience with Snowflake utilities such as SnowSQL, Snow Pipe. - AWS Experience - Agile experience 9. Job Location Primary: USCASNJC01-San Jose - CA USA, CLT Alternate: 10. Job Type 60CW00 Business Associate 11. Demand Requires Travel? N 12. Certification (s) Required NA"
Data Engineer,Helen of Troy,"Hybrid remote in El Paso, TX+1 location",https://www.indeed.com/rc/clk?jk=249e20d6dd00d080&fccid=6ff64ca2c1146e61&vjs=3,"Join our Information Technology (IT) Team at Helen of Troy as our Data Engineer (hybrid work onsite and from home), and make an immediate impact on our trusted brands, including our 9 leadership brands: OXO, Hydro Flask, Osprey, Honeywell , PUR , Braun , Vicks , Hot Tools , Drybar . Together, we build innovative and useful products that elevate people's lives everywhere every day! Look around your home, and you'll find us everywhere: In your kitchen, living room, bedroom, and bathroom. We are already making your everyday lives better. We are powered by knowledgeable, enthusiastic, and forward-thinking people committed to developing a culture of inclusion. Whether you are just starting your career or in need of a challenge, we recognize, develop, and empower talent! *Relocation Assistance will be provided to candidates willing to relocate to one of our Corp Office sites in OR, TX, or MS* *We will consider candidates currently based in the USA that might require sponsorship* What you will be doing: Looking for an expert in Data Engineering to help us extract value from our Operational, Sales and Marketing data to improve Business Process efficiency and Product quality, who will support all the processes from data collection, cleaning, and preprocessing, to Design and training models. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing data infrastructure for greater scalability. Ensure the effective collection, organization, and distribution of data, from a variety of data sources. Build processes supporting data transformation, data structures, metadata, dependency, and workload management Successful execution of data flows provides tasks completion Data flows performance measures standard methodologies applicability Data flow design artifacts gives understanding of data extraction process Translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies. Create and maintain excellent data documentation that allows the data to be understood (Metadata) and demonstrated for additional use. Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions. Technical design documents measure accurately translating business needs Analyze data to find concrete insights and “tell the story” of our business as well as help deliver solutions to any business needs using machine learning, text-mining/NLP to extract insights from structured and unstructured data to assist in new product development, improving the quality of the products, improving customer service experience Explore/Analyze Company’s Operational data and find correlation between different business process to improve and/or recommend changes to Business Processes Develop programs to assist business in improving Marketing strategy, Product Pricing and customer retention Implementing packages and mapping to desired results measures technical ability Finalized data model's accuracy provides in depth understanding of machine learning concepts and Correct application and tuning of models Performance of models provide application of standard methodologies Reasoning backed up with research and industry examples while choosing a solution measures critical and logical thinking. Build strong relationships with the different departments, teams, and support functions to understand the business needs. Collaborate and knowledge share with internal partners to ensure single source of truth for all data Conduct written and verbal presentations to share insights and recommendations to audiences of varying levels of technical sophistication Resolves business information needs, identifies system requirements, critical metrics, and methods for the data warehouse to assist with operational and strategic planning. Develops and implements effective/strategic business solutions through research and analysis of data and business processes Solve data quality issues - identifying root cause/system & documentation/communication of resolution Deliver value solutions at the speed of business Artifacts developed to present product results to End Users and other technical people provide person’s ability of strong and clear communication Successful completion of requirements matrix and mapping to end results provides collaboration with users Business Users Feedback provides customer orientation Skills needed to be successful in this role: Experience articulating business questions and using quantitative techniques and driving insights for business. Driven by solutions with an ability to identify and assess risk and prioritize challenging demands Strong communication skills with the ability to explain technical data analysis results to business users. And explain challenges and issues to technical people Curious, independent mentality and demeanor – you explore new technological & methodical options independently Minimum Qualifications: Bachelor’s degree 1+ years working on Data Platforms 1+ years on a Modern Data Platform (AWS, Snowflake, Redshift, etc.,) Knowledge of data warehousing concepts Experience in data mining, profiling, and analysis Ability to create and maintain optimal data pipeline architecture Experience in using at least one of the ELT tools Experience in evaluating, designing, and implementing data platforms and data pipelines to scale and automate the extraction of data from multiple internal and external sources Knowledge of Waterfall and Agile methodologies Experience in relational databases such as Oracle and proficiency with SQL Preferred Qualifications: Strong programming skills in R/Python or equivalent tools for exploratory and predictive analytics Experience in predictive/perspective models design Wondering if you should apply? Helen of Troy welcomes people as diverse as our brands. Have the confidence to come as who you are because your point of view, skills, and experience will make us stronger. If you're eager to share new ideas and try new things, we want to hear from you. #LI-AB1 #LI-Hybrid For more information about Helen of Troy, visit www.helenoftroy.com . You can also find us on LinkedIn , Glassdoor , Facebook , Instagram and Twitter . Helen of Troy is an Equal Opportunity/Affirmative Action Employer. We are committed to developing a diverse workforce and cultivating an inclusive environment. We value diversity and believe that we are strengthened by the differences in our experiences, thinking, culture and background. We do not discriminate on the basis of race, color, religion, sex, national origin, sexual orientation, gender identity, age, marital status, disability, protected veteran status or any protected basis. We will provide individuals with disabilities reasonable accommodation to participate in the job application process. If you would like to request an accommodation, please contact Human Resources at (915) 225-8000. Incorporated in 1968, Helen of Troy has grown into a leading global consumer products company with career opportunities in North America, South America, Europe and Asia. We offer creative solutions for our customers through a diversified portfolio of well-recognized and widely trusted brands, including OXO®, Hydro Flask®, Osprey®, Honeywell®, PUR®, Braun®, Vicks®, Hot Tools®, Drybar®. Most of these brands rank #1 or #2 in their respective categories. We boldly bring brands into our family, where we nurture what makes them great. We collaborate internally and externally, always striving to provide the consumer-centric innovation, operational excellence, scale, global reach, and stellar shared services to make them soar. The above statements are intended to describe the general nature and level of work performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities and duties required of personnel so classified. Management retains the right to add or to change duties of the position at any time."
Data Scientist / ML Engineer,INFISWIFT TECHNOLOGIES,"Remote in Milpitas, CA 95035",https://www.indeed.com/rc/clk?jk=e00c5c00e7802a46&fccid=da0e448e9f23dcc3&vjs=3,"Infiswift Technologies is looking for a strong machine learning engineer for the team that is developing several new and exciting IoT+AI applications for one of our multi-billion-dollar customers. Examples of these applications are: forecasting energy consumption and production in renewable energy space based on weather, irradiance and other features optimization of industrial energy storage battery charge and discharge schedule based on constraints such as energy tariff, solar production, penalty for exceeding maximum energy consumption from grid, etc. optimization of complex manufacturing pipelines using machine learning on the data from hundreds of sensors. detecting incorrect product installations using image recognition techniques to improve safety and productivity predicting faults by detecting anomalies and recognizing complex behavioral patterns from petabytes of data generated from industrial equipment to avoid expensive maintenance The common goal of these applications is to increase productivity, predicting and preventing downtime that would save hundreds of millions of dollars for our customers, while building the tools in parallel to reuse and generalize such work into our core IoT+AI Fabric to reduce the development time for future applications. Also these applications should improve their performance continuously over time by automatically learning and adapting from the availability of new data and help customers forecast demand and production to optimize the cost of using resources. Qualifications Minimum qualifications: Ability to design and implement AI and machine learning algorithms for enterprise and research applications Ability to write solid, production grade code in Python with minimal supervision Strong logical and analytical reasoning and problem-solving skills Demonstrable proficiency in at least one ML framework such as Tensorflow, Keras, Pytorch or Mxnet Bachelor’s Degree or relevant experience in Computer Science, Electrical Engineering, Data Science, Mathematics or Statistics with specialization in AI and Machine Learning Preferred qualifications: Master’s Degree or relevant experience in Computer Science, Electrical Engineering, Data Science, Mathematics or Statistics. At least two years of relevant work experience. Experience building IoT/Analytics-related features and/or products Demonstrable ability to learn basic concepts of any new domain where data science techniques are to be applied (energy industry, manufacturing etc) and to be able to review existing literature on various methods that could be used to solve problems in such domains. Proficiency in computer science fundamentals such as data structures, algorithms and networking Knowledge of Big Data tools like Hadoop, Spark and Hive. General-purpose python programming (backend, front end, or both) to develop end-to-end AI-driven applications and automation tools. How to Apply This position may be based near our Milpitas, California office, or may be filled from a remote location. Interested candidates should email careers@infiswift.tech."
Data Engineer,Foursquare,"Chicago, IL+3 locations",https://www.indeed.com/rc/clk?jk=bc8f5b04bbc2d751&fccid=f65aedcd2de292bf&vjs=3,"Foursquare is the leading independent location technology and data cloud platform, dedicated to building meaningful bridges between digital spaces and physical places. Our proprietary technology unlocks the most accurate, trustworthy location data in the world, empowering businesses to answer key questions, uncover hidden insights, improve customer experiences, and achieve better business outcomes. A pioneer of the geo-location space, Foursquare’s location tech stack is being utilized by the world’s largest enterprises and most recognizable brands. Foursquare’s flexible building blocks include technology to maximize marketing impact and drive incremental real-world engagement (Attribution, Audience, Proximity, SDK); data to deeply understand points of interest and real-world behavior patterns (Places and Visits), and tools to conduct advanced analysis, data enrichment, unification and visualization (Unfolded Studio). About the Team Foursquare’s Visits team is responsible for inferring the real-world behaviors of millions of consumers every day. We write software and manage systems for performing geospatial analysis at scale and provide our inferences on time to internal and external customers. Foursquare’s Visits power location solutions for some of the world’s largest companies as well as Foursquare’s market-leading Targeting and Attribution products. About the Role Foursquare’s Visits team is interested in hiring an experienced data engineer to work on backend infrastructure and manage data pipelines. The engineer who fills this role will support and improve our data ingestion practices as well as internal pipeline architecture. In this role, you will be a key player at the foundation of Foursquare’s business, and in a position to make an outsized impact on the direction and success of Foursquare. Responsibilities of the Role Design and write software in our data ecosystem, perform code review for teammates Work closely with our data scientists to support their analyses and help them bring their insights and improvements to production Recommend and implement improvements to our data model and design architecture Implement and maintain best practices for alerting (ie. PagerDuty) in regards to client/data issues Communicate technical concepts with clarity to non-technical stakeholders Qualifications 4+ years of experience working as a data engineer Professional experience with Hadoop MapReduce or Spark Strong coding skills in Scala, Python, and/or Java A demonstrated track record of developing and managing big data pipelines Strong written and verbal communication skills Nice to have Experience working with data orchestration services (ie. Airflow, Luigi) Experience working with Docker and Kubernetes Experience with geospatial data Perks and benefits Learning and development programs from individual contributors to managers Individual, professional coaching for all full-time employees Flexible time off - rest and recharge when you need it! Comprehensive and competitive health, vision, dental, life insurance 401(k) with company match Home office setup: you get all necessary hardware and internet reimbursement Family planning programs via Carrot and Maven Employee Resource Groups to help you stay connected Foursquare is proud to foster an inclusive environment that is free from discrimination. We strongly believe in order to build the best products, we need a diversity of perspectives and backgrounds. This leads to a more delightful experience for our users and team members. We value listening to every voice and we encourage everyone to come be a part of building a company and products we love. Foursquare is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other characteristic protected by law."
Data Engineer,Raymond James Financial,"Saint Petersburg, FL 33716 (Carillon area)+1 location",https://www.indeed.com/rc/clk?jk=f85338a0036eddb9&fccid=a29e9c4c46532426&vjs=3,"Data Engineer - 2202223 Description Gather requirements, assess gaps and build roadmaps and architectures to help the analytics-driven organization achieve its goals. Analyze source system data and work with technical and business representatives to determine strategies for handling data anomalies that are identified. Builds scalable and reliable ETL/ELT systems to pull large and complex data together from different systems efficiently. Develop, implement, & optimize stored procedures, views, and functions using T-SQL, PL-SQL. Partner with cross-functional teams to build analytics tools that utilize the data pipeline to provide actionable insights into key business performance metrics. Collaborate with technical/business leaders, product owners, software engineers, and business analysts to acquire and understand requirements/acceptance criteria. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability. Provides on-call support of Data Integration Batch processes on a rotating basis and other on-call as required. Performs other duties and responsibilities as assigned. Qualifications REQUIREMENTS: Bachelor’s degree in Computer Science, MIS, Engineering (any), or related. Five (5) years of required Development, Engineering, or related experience must include: Database Architecture; SQL; Database performance/Optimization; Experience in CI/CD build, release, deploy process with Git or Docker containers; Linux; Perl; Shell scripting; Large data analysis and defect analysis; SSIS; ODI; T-SQL; PL/SQL; and ETL concepts and building ETL solutions. Raymond James Guiding Behaviors At Raymond James our associates use five guiding behaviors (Develop, Collaborate, Decide, Deliver, Improve) to deliver on the firm's core values of client-first, integrity, independence and a conservative, long-term view. We expect our associates at all levels to: Grow professionally and inspire others to do the same Work with and through others to achieve desired outcomes Make prompt, pragmatic choices and act with the client in mind Take ownership and hold themselves and others accountable for delivering results that matter Contribute to the continuous evolution of the firm At Raymond James – we honor, value, respect the uniqueness, experiences, and backgrounds of all of our Associates. When associates bring their best authentic self, our organization, clients and communities thrive, it is part of our part of our people-first culture. The Company is an equal opportunity employer and makes all employment decisions on the basis of merit and business needs. Job Technology Primary Location US-FL-St. Petersburg-Saint Petersburg Organization Technology Schedule Full-time Shift Day Job Travel No"
Data Engineer,SunPower,"Austin, TX+1 location",https://www.indeed.com/rc/clk?jk=f7251492971482f2&fccid=e145a4204aee6fa7&vjs=3,"Do you want to change the world? We do, too. Solar penetration is less than 1%, but just one hour of sunlight, if harnessed, could power the entire world for a year. We have the opportunity to change the way energy is produced, distributed and consumed, and we’re looking for talented, committed people to help us drive our growth and achieve our goals. SunPower is a solar energy solutions company with a rich heritage of pioneering the best solar technologies in the world. Our solutions are unrivaled in terms of long-term reliability, efficiency, and performance. SunPower offers the only solar + storage solution designed and warranted by one company that gives customers control over electricity consumption. Through design, installation, maintenance, and monitoring, SunPower provides its world-class solar solutions to residential and commercial customers across the U.S. SunPower is changing the way our world is powered every day with a brilliant, passionate, and driven team of more than 2,500 in North America and the Philippines. In an industry that is reshaping the world’s energy future, there’s no better place to be than SunPower. We believe that our employees create our brand – with each project, each communication, each task completed and each interaction. SunPower welcomes the forward thinkers, the future savers of the world, the freedom chasers and all those demanding better, cleaner energy. SunPower Customer Care team is looking for an outstanding Data Engineer who is data-driven, uncompromisingly detail-oriented, smart, efficient, and driven to help our business succeed. You have a passion for technology. You are keen to leverage existing skills while trying new approaches. You are not tool-centric; you determine what technology works best for the problem at hand and apply it accordingly. You can explain complex concepts to your non-technical customers in simple terms. As a Data Engineer, you will be working to build foundational data to enable the highest levels of customer experience. You will design, implement and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, design data infrastructure, build up data pipelines and data sets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate. Your major responsibilities will include (but not limited to): Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and other programming languages such as Python/Java. Designing and implementing the data warehouse and subsequent maintenance. Design and implement tools and infrastructure to enable teams to consume and analyze data faster. Explore and learn the latest technologies to provide new capabilities and increase efficiencies. Deploy and utilize data validation and quality correction methodologies Designing and implementing complex ETL pipelines and other BI solutions. Work closely with business owners, developers, and Business Intelligence Engineers to explore new data sources and deliver the data. Basic Qualifications Bachelor's degree in Computer Science, Engineering, Mathematics, or a related technical discipline 5 to 8 years of industry experience in Data Engineering, BI Engineer, or related field or equivalent combination of education and experience Track record of manipulating, processing, and extracting value from data Hands-on experience and advanced knowledge of Database administration, SQL, Task Scheduling etc. Hands-on experience in distributed data processing, Data Modeling, ETL Development, and Data Warehousing Preferred Qualifications Masters in computer science, mathematics, statistics, economics, or other quantitative fields. 8 or more years of experience as a Data Engineer, BI Engineer or related field in a company with large, complex data sources. Experience working with cloud and big data technologies Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy. Familiarity with solving data quality issues and auto-detection algorithms Equal Employment Opportunity The Company is an equal employment opportunity employer and makes employment decisions, including but not limited to, hiring, firing, promotion, demotion, training, and/or compensation, on the basis of merit. Employment decisions are based on an individual’s qualifications as they relate to the job under consideration. The Company’s policy prohibits unlawful discrimination based on sex (which includes pregnancy, childbirth, breastfeeding, or related medical conditions, the actual sex of the individual, or the gender identity or gender expression), race, color, religion, including religious dress practices and religious grooming practices, sexual orientation, national origin, ancestry, citizenship, marital status, familial status, age, physical disability, mental disability, medical condition, genetic information, protected veteran or military status, or any other consideration made unlawful by federal, state or local laws, ordinances, or regulations. The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company and prohibits unlawful discrimination by any employee of the Company, including supervisors and co-workers. EOE Minorities/Females/Protected Veterans/Disabled SunPower Supports EEO Accommodation for Applicants to SunPower Corporation SunPower Corporation is an Equal Employment Opportunity / Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need a reasonable accommodation due to a disability, you may use the following alternative email address to contact us about your interest in employment at SunPower Corporation: jobs@sunpower.com. Please indicate in the subject that line of your email that you are requesting accommodation. Only candidates being considered for a position who require an accommodation will receive a follow-up response. NOTICE TO ALL APPLICANTS AND EMPLOYEES Availability of Affirmative Action Plan for Review SunPower is a federal government contractor. As a part of the Company’s obligations under law, it must develop a written Affirmative Action Program (AAP) for the Disabled, Recently Separated Veterans, Armed Forces Service Medal Veterans, Disabled Veterans and Active Duty Wartime Or Campaign Badge Veterans and for Women and Minorities as specified by law. Non-confidential and non-proprietary aspects of the AAP are available for inspection by applicants and employees, consistent with applicable law, which will be made available during office hours by contacting the EEO Officer."
Data Engineer,G/O Media,"New York, NY",https://www.indeed.com/rc/clk?jk=d7efc6bab221b540&fccid=1cba5ce49ead97f8&vjs=3,"Why G/O Media? G/O Media is the publisher of the web's most original media brands, including Gizmodo, Kotaku, Lifehacker, Deadspin, Jezebel, Jalopnik, The Root, The Onion and The A.V. Club, and reaches 100 million unique visitors a month—more than one-third of all Americans. We connect with the young, diverse audiences that are shaping our future. Through fearless journalism, provoking comedy, and high-impact storytelling, we elevate the stories and issues our readers and viewers are passionate about. Your impact? At G/O Media, we are seeking a coach/player to work with our talented team. This is a great opportunity for a senior backend engineer who wants to transition to a management role. You get to work with different areas of software development, Big Data pipelines, A/B testing, personalized recommendation engines and real-time alerting. We embrace service oriented architecture in the implementation of all core platform features. Our platform runs on AWS and Google Cloud Platform, our deployments are automated. Technologies we use: Scala Play framework Akka SQL Redis Pub/Sub BigQuery Kubernetes GCP Jenkins Fastly AWS services What will you be doing: Work with our data science team on ETL and data delivery Help us finetune and improve our data pipeline As an innovative builder, you will partner with others in Product, DevOps and Business to work on our first party data Platform. Qualifications: At least 3 years in a data engineering role, or a backend engineering/devops role with a focus on data Strong Python and SQL skills Experience working with small data science teams Familiarity with analytics and/or adtech is a huge plus Familiarity with Data Warehousing Strong communication skills G/O Media is deeply committed to fostering a transparently inclusive workplace environment and people of color, women, people with disabilities, veterans, and LGBTQ candidates are very strongly encouraged to apply. Our company-wide mission is to reach very diverse audiences and so, we are deeply committed to having teams and leaders that reflect this mission."
Senior Data Engineer,Moss Adams,"Seattle, WA",https://www.indeed.com/rc/clk?jk=fee2459f9258e15c&fccid=25d4103caba1cb8f&vjs=3,"At Moss Adams, we champion authenticity. For us, that means fostering a culture of talented people who care—about you, about our clients, and about our communities. Here, you’ll work towards our mission of empowering others to embrace opportunity, growing as a leader along the way. Our firm’s size, middle-market clients, customized career paths, and supportive culture make this a reality. Join a values-driven firm where you’ll have fun while solving complex and interesting business challenges. Introduction to the Team: The Senior Data Engineer functions as the technical support on the firm’s analytics, data warehouse, and data integrations projects. This individual will help continue to build out the firm’s business intelligence reporting. This position required expertise in complex DAX development and data modeling. This role collaborates with other Data Engineers, SQL Developers, and with other IT resources. Strong customer service and experienced in working with business stakeholders to gather requirements preferred. Individuals who thrive at Moss Adams exhibit the following success skills – Collaboration, Critical Thinking, Emotional Intelligence, Executive Presence, Growth Mindset, Intellectual Curiosity, and Results Focus. Responsibilities: In collaboration with the data analytics & reporting team, manage and support Azure Machine Learning environment Develop ETL using data factory, SSIS tools Design, construct, and manage the data lake environment including: Data ingestion, staging, data quality monitoring, and business modeling Develop, construct, test and maintain architectures (databases and large-scale processing systems) Design, develop and implement technical solutions in SQL environment (databases, SQL, data marts, integrations) Develop visual reports in Power BI Maintain and develop queries and stored procedures using T-SQL Support data integrations Analyze data and identify gaps, data quality and integrity issues Work in all aspects of development, design, reviews, troubleshooting and post-production issue resolution Follow SDLC and create and maintain required documentation of newly developed and refactored applications Qualifications: Bachelor’s degree or equivalent experience required; emphasis in Computer Science, Computer Engineering or related field preferred Minimum of 3 years of related experience required; experience in a professional services environment preferred Highly skilled in SQL programming in T-SQL building stored procedures and jobs Strong functional understanding of Azure Machine Learning Ability to manage large volume data integration/ETL; experience with SQL Server Integration Services (SSIS) including ability to configure SQL Server agent Expertise in identifying and mapping data elements across multiple systems Knowledge of Power BI report visualizations, Data Analysis Expressions (DAX), Power Query (M), and Power BI data modeling Hands-on experience in writing DAX queries and custom calculations Strong understanding of data integration, quality and validation Strong understanding of MDM, Data Warehouse/Data mart and relational database design Excellent written and verbal communication skills and able to interact with multiple IT teams and business partners both formally and informally Should possess sound knowledge of SDLC using Azure DevOps Self-motivated with the ability to work both independently and in a team environment Effective time management, ability to multi-task with changing priorities while continuing to provide exceptional client service Ability to travel as needed, approximately 5% Moss Adams is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation, gender identity or any other characteristic protected by law. Moss Adams complies with federal and state disability laws and makes reasonable accommodations for applicants and employees with disabilities. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@mossadams.com."
Big Data Engineer,YouAppi,"Los Angeles, CA",https://www.indeed.com/rc/clk?jk=de39305b9f664cf2&fccid=7759bd0f8541efc8&vjs=3,"YouAppi is looking for a Big Data Engineer YouAppi’s programmatic app user acquisition and mobile app retargeting products puts our customers app where they want it - top of mind. A holistic marketing funnel approach activates valuable users, keeping them engaged, growing app revenue. YouAppi Ranked Number 94th Fastest-Growing Company in North America on the 2021 Deloitte Technology Fast 500™ Responsibilities To be part of the big data team, that is responsible for the data collection, enrichment, transform, and preparation for ML and analytics. Requirements 3 years’ experience in Scala, experience as developer on big data projects.Experience in working with some of the big data tools like ES, Hive, Presto, Kafka, and so on. Self driven and reliable and result oriented. Advantages Experience with MySQL, Redis, ES, Kafka, Docker, ECS, Spark, Airospike."
Sr. Data Engineer / Analyst (Open to 100% Remote),Perrigo Company,"Remote in Allegan, MI 49010",https://www.indeed.com/rc/clk?jk=ef10b149a3a068b2&fccid=81c5aa94f4595406&vjs=3,"Perrigo Company is dedicated to making lives better by bringing high quality and affordable self-care products that consumers trust everywhere they are sold. Help us do it. *Open to 100% remote for this position* The Data Engineer / Analyst is tasked with data migration activities that include data analysis, reporting, conversions, harmonization and business process analysis, ensuring the accuracy and availability of Perrigo’s primary data. Identifying customer business requirements which are translated to data mappings for data migrations for integration projects or reporting purposes. This role will be directly in contact with projects or day to day support activities of the transformations developed. Responsibilities: Participate in all aspects of Data migration design, development, maintenance, and support; and establish standards and processes which ensure the reliability of Perrigo’s SAP data. Independently develop and maintain functional and technical requirement specifications documentation and issue resolution for Data Migration, Data Integration, SAP MDG & SAP BusinessObjects Data Services application. Work with Perrigo SAP Business Analysts and subject matter experts to gather and document process flows, requirements and business value drivers, and develop estimates for assigned projects. Develop solutions in coordination with other IT staff, including Data Migration Analysts, SAP Developers, Basis, Infrastructure, and project managers. Review, debug, test, and deploy customizations, ETL or enhancements supporting Data Migrations, SAP MDG, SAP BO Data Services and projects. Maintain project, validation & change control documentation to ensure compliance in Perrigo’s validated cGMP environment. Required Experience: The candidate must have good knowledge of Master Data Governance, Master Data Management and ETL. Experience with tools like SAP MDG, SAP BusinessObjects Data Services and familiarity with ETL developing techniques and development life cycles is preferred. Good familiarity with different type of databases connections and profiles. Strong analytical and communication skills, and the ability to translate business processes or concepts into technical requirements are essential. Comprehensive understanding of SAP master data elements from one or more of the following domains: Material, Customer, Vendor or Finance. As well as comprehensive understanding of data mapping and data conversion is necessary, with the ability to read and interpret process flow documentation and translate this into mapping, harmonization, cleansing packages. Ability to test programming and interfaces that align to data standards and business rules is preferred, and the ability to debug programs is also preferred, but not required. Must work independently on multiple concurrent projects, and in supporting problem tickets by working with end users, subject matter experts, and SAP Business Analysts to gather requirements, present solutions and participate in the selection of the best solutions. These skills are normally acquired through possession of a Bachelor degree in Business Information Systems, Computer Science, or a relevant business discipline, combined with 3 to 7 years experience as a Master Data Analyst. #DIV"
Senior Data Engineer,Comcast,"West Chester, PA 19380+14 locations",https://www.indeed.com/rc/clk?jk=15d021b2e8a738a1&fccid=ea25315ee9da22e5&vjs=3,"Comcast’s Technology, Product & Experience organization works at the intersection of media and technology. Our innovative teams are continually developing and delivering products that transform the customer experience. From creating apps like TVGo to new features such as the Talking Guide on the X1 platform, we work every day to make a positive impact through innovation in the pursuit of building amazing products that are enjoyable, easy to use and accessible across all platforms. The team also develops and supports our evolving network architecture, including next-generation consumer systems and technologies, infrastructure and engineering, network integration and management tools, and technical standards. We offer a flexible working environment to balance the need to work independently wherever you choose, with days that require collaboration at one of our offices. Our roles primarily reside inside or around one of our Tech Hubs (Philadelphia and surrounding suburbs, Denver, Austin, Silicon Valley, Washington DC/N. Virginia). Some roles can work virtual full-time if they are not near a Tech Hub, but that is dependent upon the needs of the position and amount of collaboration required. Job Summary The Senior Data Engineer is responsible for planning and designing new software and web applications. They will analyze, test and assist with the integration of new applications; also oversee the documentation of all development activity. A mentor to share knowledge and to train non-technical personnel, assist with tracking performance metrics, integrate knowledge of business and functional priorities, act as a key contributor in a complex and crucial environment. May lead teams or projects and shares expertise. Job Description Required Technical Knowledge Scala, Spark, SQL, AWS. Knowledge of data warehousing concepts. Core Responsibilities Collaborates with project collaborators to identify product and technical requirements. Conducts analysis to resolve integration needs. Crafts new software and web applications, supports applications under development and customizes current applications. Develops software update process for existing applications. Assists in the roll-out of software releases. Trains junior Software Development Engineers on internally developed software applications. Leads all aspects of the researching, writing and editing of documentation and technical requirements, including evaluation plans, test results, technical manuals and formal recommendations and reports. Keeps current with technological developments within the industry. Monitors and evaluates driven applications and products. Reviews literature, patents and current practices relevant to the solution of assigned projects. Provides technical leadership throughout the design process and guidance with regards to practices, procedures and techniques. Serves as a guide and mentor for junior level Software Development Engineers. Assists in tracking and evaluating performance metrics. Ensures team delivers software on time, to specification and within budget. Works with Quality Assurance team to resolve if applications fit specification and technical requirements. Displays expertise in knowledge of engineering methodologies, concepts and skills and their application in the area of specified engineering specialty. Displays expertise in process design and redesign skills. Presents and defends architectural, design and technical choices to internal audiences. Consistent exercise of independent judgment and discretion in matters of significance. Regular, consistent and punctual attendance. Other duties and responsibilities as assigned. Employees at all levels are expected to: Understand our Operating Principles; make them the guidelines for how you do your job. Be responsible for the customer experience - think and act in ways that put our customers first, give them detailed digital options at every touchpoint, and make them promoters of our products and services. Know your stuff - be hard-working learners, users and advocates of our exciting technology, products and services, especially our digital tools and experiences. Win as a team - make big things happen by working together and being open to new insights. Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers. Get results and growth. Respect and promote inclusion & diversity. Do what's right for each other, our customers, investors and our communities. Disclaimer: This information has been crafted to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications. Comcast is an EOE/Veterans/Disabled/LGBT employer. Education Bachelor's Degree While possessing the stated degree is preferred, Comcast also may consider applicants who hold some combination of coursework and experience, or who have extensive related professional experience. Relevant Work Experience 7-10 Years Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details."
Data Warehouse Engineer,Deloitte,"Hybrid remote in Tampa, FL 33602+17 locations",https://www.indeed.com/rc/clk?jk=86c0182d54874270&fccid=9e215d88a6b33622&vjs=3,"Do you thrive on developing creative and innovative insights to solve complex challenges? Want to work on next-generation, cutting-edge products and services that deliver outstanding value and that are global in vision and scope? Work with other experts in your field? Work for a world-class organization that provides an exceptional career experience with an inclusive and collaborative culture? Want to make an impact that matters? Consider Deloitte Global. Work you'll do: Build, Test and Run of data assets tied to tasks and user stories from the Azure DevOps instance of GD&A Bring a level of technical expertise of the Big Data space that contributes to the strategic roadmaps for Enterprise Data Architecture, Global Data Cloud Architecture, and Global Business Intelligence Architecture, as well contributes to the development of the broader GD&A Engineering community. Actively participate in regularly scheduled contact calls to transparently review the status of in-flight projects, priorities of backlog projects, and review adoption of previous deliveries from GD&A with the GD&A management team. Work to resolve any issues with the portfolio of deliveries that are a part of the Data Warehouse engineering team's work pipeline. Act as the last line of defense of ensuring deliveries are of the appropriate level of quality for downstream work to continue or against user's expectations. Contribute to, produce and maintain processes, procedures, operational and architectural documentation Change Control - ensure compliance with Processes and adherence to standards and documentation Assist in mentoring new staff in the data management space, especially Big Data Work with leadership and service teams in reviewing documentation and aligning KPIs to critical steps in our service operations What you'll be part of - our Deloitte Global Culture: At Deloitte, we expect results. Incredible-tangible-results. And Deloitte Global professionals play a unique role in delivering those results. We reach across disciplines and borders to serve our global organization. We are the engine of Deloitte. We develop and implement global strategies and provide programs and services that unite our network. In Deloitte Global, everyone has opportunities. We see the importance of your perspective and your ability to create value. We want you to fit in-with an inclusive culture, focus on work-life fit and well-being, and a supportive, connected environment; but we also want you to stand out-with opportunities to have a strategic impact, innovate, and take the risks necessary to make your mark. Deloitte Technology Services works at the forefront of technology development and processes to support and protect Deloitte around the world. In this truly global environment, we operate not in ""what is"" but rather ""what can be"" to help Deloitte deliver and connect with its clients, its communities, and one another in ways not previously conceived. * 5+ years of broad-based IT experience with technical knowledge of Microsoft SQL Server, Azure SQL Data Warehouse, Azure Data Lake Store, Databricks, Azure Data Factory Demonstrated experience Apache Framework (Spark, Scala, etc.) Bachelor's Degree in Computer Science or equivalent industry experience How you'll grow: Deloitte Global inspires leaders at every level. We believe in investing in you, helping you embrace leadership opportunities at every step of your career, and helping you identify and hone your unique strengths. We encourage you to grow by providing formal and informal development programs, coaching and mentoring, and on-the-job challenges. We want you to ask questions, take chances, and explore the possible. Benefits you'll receive: Deloitte's Total Rewards program reflects our continued commitment to lead from the front in everything we do-that's why we take pride in offering a comprehensive variety of programs and resources to support your health and well-being needs. We provide the benefits, competitive compensation, and recognition to help sustain your efforts in making an impact that matters. Corporate citizenship: Deloitte is led by a purpose: to make an impact that matters. This purpose defines who we are and extends to relationships with our clients, our people, and our communities. We believe that business has the power to inspire and transform. We focus on education, giving, skill-based volunteerism, and leadership to help drive positive social impact in our communities. #LI-Hybrid Hybrid work, remote may be an option"
Data Engineer,State Auto Insurance Companies,"Columbus, OH 43215 (Downtown area)+1 location",https://www.indeed.com/rc/clk?jk=46407c4bdb455143&fccid=995a81a623813d98&vjs=3,"It's fun to work in a company where people truly BELIEVE in what they're doing! We're committed to bringing passion and customer focus to the business. Summary & Key Responsibilities This role on the Enterprise Data team will support our Data Engineering initiatives, including the development of our “Data Lake” architecture. This role is primarily project based, but also may provide support and maintenance to applications in production. Key Responsibilities: Build distributed, scalable, and reliable data pipelines that ingest and process data at scale and in real-time Create metrics and apply business logic using Spark, Scala, R, Python, and/or Java Model, design, develop, code, test, debug, document and deploy an application to production through standard processes Harmonize, transform, and move data from a raw format to consumable, curated views Analyze, design, develop, and test applications Contribute to the maturation of Data Engineering practices, which may include providing training and mentoring to others Perform Data Designer activities to transform raw data to meaningful datasets and extracts, such as business logic design, source-to-target mappings, data sourcing strategy, and transformation rules. Apply strong Data Governance principles, standards, and frameworks to promote data consistency and quality while effectively managing and protecting the integrity of corporate data. Minimum Experience/Education: Bachelor’s degree in Computer Science, Computer Engineering, Programming, Management Information Systems, or related field. Insurance industry experience is a plus. Minimum of five years of prior data engineer experience. Strong hands-on experience in Spark, Scala, R, Python, and/or Java. Programming experience with the Hadoop ecosystem of applications and functional understanding of distributed data processing systems architecture (Data Lake / Big Data /Hadoop/ Spark / HIVE, etc). Amazon Big Data ecosystem (EMR, Kinesis, Aurora) experience is a plus. Extensive knowledge of source system data, such as Guidewire PolicyCenter, is a plus. Communication and Collaboration Skills: Written: Must be able to convey key messages in technical terms and business terms. Must be able to create technical documentation, such as specifications, design documents, and testing documents. Oral: Ability to collaborate and communicate with a wide range of partners, including IT and business, across all levels of the organization. Must actively manage expectations with stakeholders. Problem Solving: Must understand the business need and develop technical solutions to meet those needs. Innovation, creativity, and critical problem-solving skills are required to be successful in this role. Solutions need to be comprehensive, flexible for future changes and delivered with a high degree of quality. State Auto offers a competitive salary, an annual bonus program, an excellent benefits program including medical, dental, vision and prescription insurance coverage, life insurance, matching 401(k) plan, flexible spending accounts, tuition assistance, and a stock purchase plan. State Auto is committed to the principle of equal employment opportunity for all associates and applicants and to providing associates with a work environment that is free from discrimination and harassment. All employment decisions (hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and work assignments) are based on business needs, job requirements and individual qualifications without regard to race, color, religion, gender, sex, sexual orientation, gender identity, national origin, age, disability, genetic information, marital status, citizenship status, military status, or status as a covered veteran in accordance with applicable federal, state and local laws. State Auto will not tolerate discrimination or harassment based on any of these characteristics. State Auto is a smoke-free work environment. We utilize background checks as a condition of of employment. For all exempt positions, we also obtain motor vehicle reports (MVR s). State Auto will not accept candidates from third-party recruiters without a signed agreement with State Auto. #LI-SA Full Time / Part Time Full time Worker Sub-Type Regular If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!"
Data Engineer,OneGlobe LLC,"Remote in Washington, DC+1 location",https://www.indeed.com/rc/clk?jk=961ea5ede455e09e&fccid=dd37eff9580713e0&vjs=3,"Job Opportunity: Our team is seeking a talented Data Engineer to work in our Reston, VA location. What You'll Get to Do as a Data Engineer: Work closely with clients and data to understand mission and data. Develop data pipelines to stream the data and make analysis possible Provides highly technical and specialized guidance and solutions to complex IT problems; performs elaborate analyses and studies. Evaluates, recommends, and executes new technologies and updates existing infrastructure to ensure optimal performance and efficiency. Develops IT strategies to ensure the systems meet existing and future requirements based on needs and regulations. Works in a variety of environments and has excellent verbal and non-verbal communication skills. Works effectively and independently. You'll Bring These Qualifications: Must be a U.S. Citizen to obtain a DoD Security clearance 8 or more years' experience working in the IT industry 2 or more years' experience implementing event/data streaming services such as Kafka Experience working with big data technologies Experience working with multiple database types such as SQL, Redis and MongoDB Experience building and integrating the at the application and database level Experience developing microservice APIs and messaging protocols and formats Experience with statistical analysis, machine learning, predictive modeling, and/or optimization Experience prototyping front-end visualizations utilizing data visualization suites such as Kibana or Splunk Experience implementing and building event driven architectures Familiarity with event driven finite state machines High proficiency in SQL to include schema design, data definition, and advanced queries Experience with MPP data warehouses Experience with scripting languages for automating repetitive tasks Experience with creating automated data pipelines for complex systems Extensive Linux server management background Can prototype visualizations with lightweight data visualization suites Excellent verbal and written communications skills along with the ability to present technical data and approaches to both technical and non-technical audiences. About OneGlobe: OneGlobe LLC was founded in 2005 to provide quality Information Technology solutions that exceed expectations. We focus on IT System Modernization using agile software development practices and DevSecOps to deliver intuitive and maintainable systems that we help our customers improve their processes and capabilities. We provide full service IT solutions and have the skill to identify, plan and perform cost-saving steps throughout the system lifecycle to enhance system efficiency, while optimizing the value that we deliver to our customers. Our team has the drive and right mindset to feel ownership on the projects they work. They partner with our customers to give the extra effort sometimes required to deliver success. We provide highly competitive benefits package to include: extensive medical/dental/vision, 7% of your annual salary toward 401(k), Paid Time Off (PTO), $5K annually toward ongoing education and training, and more. We also have monthly social and tech events! See additional positions at: http://www.oneglobeit.com/#careers OneGlobe is a proud equal opportunity employer. We are a drug free, EEO employer committed to a diverse workforce. We will consider all qualified candidates regardless of race, color, national origin, sex, age, marital status, personal appearance, sexual orientation, gender identity, family responsibilities, disability, political affiliation or veteran status."
Senior Data Engineer,Department of Administrative Services,"Salem, OR",https://www.indeed.com/rc/clk?jk=2db31369d4814bdb&fccid=b666f84c472fc273&vjs=3,"Initial Posting Date: 05/26/2022 Application Deadline: 06/23/2022 Agency: Department of Administrative Services Salary Range: $5,708 - $8,627 Position Type: Employee Position Title: Senior Data Engineer Job Description: What You Will Do The Sr. Data Engineer will work as part of a development team to connect, transform, and automate data sharing to support State and government agencies in their functions and to support transparency as part of the State’s Open Data Program. The Sr. Data Engineer is responsible for supporting both secured and open data publication and in management of data in multiple formats, including geospatial datasets. This role will work both internally (Office of Data Governance and Transparency, EIS) and externally (state agencies, other public and private entities) to architect and advise on data, workflow, process improvement, tools, requirements and systems. Perform strategic planning for data systems which include numerous users and needs, and build interface and data pipelines which migrate data from source systems to new enterprise wide data systems. For more information on the job duties of this position, please click here . Complete applications for the position will require the following: Resume Cover Letter Link to an online portfolio of projects relevant to the position The Benefits of Joining Our Team The State of Oregon offers a competitive and affordable health and benefits package, including excellent medical, vision and dental coverage, paid holidays off, and personal business leave, as well as paid and accrued vacation leave and sick leave. In addition to standard medical benefits and employee leave, the state also provides additional optional benefits, such as basic life insurance, short-term disability, long-term disability, deferred compensation savings program, and flexible spending accounts for health care and childcare expenses. What We Are Looking For Six (6) years of information systems experience in: data management, ETL/ELT deployment, data manipulation, curation, and management, SQL and database management OR An Associate's degree in Computer Science, Information Technology, or related field, OR completion of a two (2) year accredited vocational training program in information technology or related field; AND four (4) years of information systems experience in: data management, ETL/ELT deployment, data manipulation, curation, and management, SQL and database management OR A Bachelor's degree in Information Technology, Computer Science, or related field AND two (2) years of information systems experience in: data management, ETL/ELT deployment, data manipulation, curation, and management, SQL and database management; OR Master's degree in Information Technology, Computer Science, or related field may substitute for all of the above. Additional skills, abilities and requirements: Must be adept at navigating varied and sometimes conflicting interests of internal and external stakeholders. Demonstrated skill in making decisions and negotiating outcomes where complexity and conflict may exist. Demonstrated ability to consistently operate with high standards of ethics and accountability Demonstrated ability to work independently, be self-directed and perform duties with minimal oversight and supervision. Ability to effectively work remote with a distributed team as needed. Strong organizational skills Demonstrated ability to clearly and effectively communicate technical information to a non-technical community. Understanding of developing and maintaining data pipeline architectures. Experience in automating manual processes and optimizing data delivery. Experience using FME Desktop to perform data ETL. Experience in creating meaningful and actionable insight from data through charting, web maps, or other visualizations. Experience or interest in building and optimizing ‘big data’ data pipelines. Strong analytical skills related to working with unstructured datasets, extracting data from disconnected sources, and combining datasets that adhere to standardized schemas. Understanding or interest in job queuing backends or job scheduling for distributed or time-based job processing. Strong understanding of relational databases with advanced working knowledge of writing SQL Understanding of object-oriented software design. Software development experience using Python, NodeJS, or other relevant object-oriented languages. Experience with distributed-version control using Git with an understanding of common Git workflows such as Gitflow. Knowledge of continuous integration and software deployment techniques. Strong desire to collaborate on projects and contribute to team growth through effective communication and code reviews. Knowledge of testing best practices through writing functional, unit, and integration tests. Desire to learn new technologies, pitch new ideas, build prototypes, and showcase your work to others. How to Apply Your candidate profile, cover letter, and resume are the perfect place to display your interest in the position and highlight the skills and experience you will bring, making you the best candidate for the position. Submissions are screened for consistency of information and communication skills at the professional level (attention to detail, spelling, grammar, etc.). Current State of Oregon employees - You must apply through your employee Workday account. At the time of application, please attach your current cover letter and resume External Applicants - Please visit the State of Oregon job opportunities web-page to submit your application for the position, which includes your current cover letter and resume Want to Know More? Let Me Help! The salary listed is the non-PERS qualifying salary range. If the successful candidate is PERS qualifying, the salary range will reflect the additional 6.95% This announcement is for one, full-time, Information Systems Specialist 7 position - Please review the Classification and Compensation page for more details on the classification, or you may visit our website for information on the job offer process following pay equity If you have questions about the job announcement, or need an alternate format top apply, please contact the Senior Recruiter, Francisco Garibay, at: Francisco.garibay@oregon.gov | 971-719-6326 Applicants must be authorized to work in the United States. Applicants who require VISA sponsorship will not be considered at this time This position requires a background or security check and fingerprinting to handle confidential or negotiable documents. Adverse background data may be grounds for immediate disqualification This announcement may be used to fill future vacancies as they occur Helpful Links & Resources Oregon Job Opportunities Webpage Workday Applicant FAQ Veterans | Oregon Department of Veterans' Affairs at: 1-800-692-9666 What You Need to Know to Get the Job How to Set Job Alerts Come for a job. | Stay for a career. | Make a difference... for a lifetime! The Department of Administrative Services is an Equal Opportunity, Affirmative Action Employer Committed to Workforce Diversity"
Data Senior Engineer,City National Bank,"Los Angeles, CA",https://www.indeed.com/rc/clk?jk=5d84c620343518ef&fccid=55a861ecd89109ee&vjs=3,"DATA SENIOR ENGINEER - TECHNOLOGY WHAT IS THE OPPORTUNITY? The Data Engineer Senior works with department and lines of business subject matter expert (SMEs) across the enterprise to meet departmental and organizational objectives. The engineer will follow end-to-end process standards and guidelines to ensure accurate and efficient build out of data pipeline architecture within project timeframes. Technology and Innovation Division As a member of City National's Technology & Innovation group, you will drive, develop, and maintain solutions for clients and colleagues. This is an exciting time of technology advancement and innovation across the bank, particularly within our technology teams. WHAT WILL YOU DO? Function in accordance with the Software Development Life Cycle (SDLC) framework and governance processes Participate in development of test plans and perform quality assurance and testing of own work and that of peers Function in accordance with the Software Development Life Cycle (SDLC) framework and governance processes Ensure work includes necessary audit controls such as Audit, Balance and Control (ABC) Framework and security controls within all design and deliverables Document data workflows including but not limited to: functional specs, technical specs, mapping / workflow diagram, testing plans, production “run books”, training materials, etc. Accurately define and execute transformations, aggregations and other data manipulations to meet requirements Participate in development of test plans and perform quality assurance testing of own work and that of peers Identify development and data quality issues and work with senior team members and management to mitigate Conduct peer and team review sessions Assist in the creation of standards, templates and procedures for the department Contribute to the design of the data structure/data model and data flow Design and develop data workflows and mappings to extract, transform, and load data for purposes of analytics , reporting and integration WHAT DO YOU NEED TO SUCCEED Must-Have* Bachelor's Degree 5+ years of relevant experience Skills and Knowledge Advanced senior professional with wide ranging experience uses professional concepts and to resolve complex issues in creative and effective ways Perform various tasks to design and deliver data pipeline solutions with accuracy, reliability, and quality. Requires specialized depth and or breadth of expertise Compensation Starting base salary: $119,012 - $154,574 per year. Exact compensation may vary based on skills, experience, and location. This job is eligible for bonus and/or commissions. To be considered for this position you must meet at least these basic qualifications The preceding job description has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. INCLUSION AND EQUAL OPPORTUNITY EMPLOYMENT City National Bank is an equal opportunity employer committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other basis protected by law. ABOUT CITY NATIONAL We start with a basic premise: Business is personal. Since day one we've always gone further than the competition to help our clients, colleagues and community flourish. City National Bank was founded in 1954 by entrepreneurs for entrepreneurs and that legacy of integrity, community and unparalleled client relationships continues to drive phenomenal growth today. City National is a subsidiary of Royal Bank of Canada, one of North America’s leading diversified financial services companies. Positions based in New York City: In order to work on-site at City National Bank in New York City, you must be fully vaccinated against COVID-19, per city requirements. Shortly after your start date, you will be required to attest to your vaccination status and will be required to provide proof of vaccination. Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled"
Data Engineer Ssr Ba3711,Nisum,+3 locationsRemote,https://www.indeed.com/rc/clk?jk=0d8785a96019a224&fccid=51280efa86c03cda&vjs=3,"Location: Remote Latin American Team: Data Science & Analytics Work Type: Full Time Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto “ Building Success Together®,” Nisum has grown to over 1,800 professionals across the United States, Chile,Colombia, India, Pakistan and Canada. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today’s world, with immersive and seamless experiences across digital and physical channels. Para tener éxito en este rol, esperamos que cuentes con las siguientes habilidades y experiencia: Spark HDFS (Hadoop Distributed File System) / Apache HIVE / ZEPPELIN Pruebas de performance (de carga de flujos de datos) Librerías o framework para desarrollo de ETL (mallas de procesos, desarrollo de procesos, integración con sistemas legados) GCP (Dataproc, Cloud Storage, gcloud, gsutil) Conocimiento de Scala Perfil de conocimientos (deseable) GCP (bigquery, data catalog) Huemul (http://www.huemulsolutions.com/) o similares #Li-Remote ¿Qué te ofrecemos? Pertenecer a una empresa internacional y multicultural que apoya la diversidad. Formar parte de proyectos internacionales con presencia en Norteamérica, Pakistán, India y Latam. Entorno de trabajo con amplia experiencia en trabajo remoto y distribuido, usando metodologías ágiles. Cultura de constante aprendizaje y desarrollo en tecnologías actuales. Ambiente agradable y colaborativo, con foco en el trabajo en equipo. Acceso a plataformas de aprendizaje, certificaciones Google Cloud, Databricks, clases de inglés y español, Tech Talks, etc. Formar parte de diversas iniciativas y participación continua en actividades internas y externas de innovación, hackathon, tecnología, agilidad, charlas, webinars, bienestar y cultura con posibilidades no solo de participar sino de ser expositor. Si resides en Chile, accedes además a estos beneficios: Tarjeta Sodexo, beneficio de Sala Cuna, convenio con el gimnasio SmartFit, acceso a Seguro Complementario de Salud, Mutual de Seguridad, ¡entre otros! Para que tengas en cuenta :) Nisum Latam se encuentra trabajando de manera remota. Este puesto es full time. Nisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace."
Data Engineer,GoTo,+1 locationRemote,https://www.indeed.com/rc/clk?jk=6ecfc979baca0528&fccid=75d8817dffc3069a&vjs=3,"Job Description Our Customer Retention Team is looking for a Data Engineer to partner with Customer Success, Analytics and Data Science on providing highly visible data products that power predictive models, analyses, and critical enablement for customer engagement teams. As a part of this team, you will be responsible for building and maintaining insightful, scalable, and robust systems and solutions using AWS and related technologies such as Spark, Hive, Presto, ML Flow, DataBricks etc. This position will support our operational and business objectives, working with Analysts and Data Scientists on new and existing data initiatives. The ideal candidate will have experience in data manipulation and constructing ETL pipelines, have demonstrable data intuition, and the ability to iterate quickly to develop robust data products and solutions. You should be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. Your day to day as a Data Engineer you would be working on: Design, build, and manage production-level ETL pipelines and ensure timely SLAs on all managed sources Be subject matter expert for team on ETL/programming best practices, query optimization, and LogMeIn’s data platform infrastructure Build and maintain a data quality framework that monitors data sources used by Analysts and Data Scientists to ensure data correctness and availability Partner with machine learning engineers and data scientists on model deployment, monitoring, and retraining Work with Customer Engagement teams to provide critical customer data to various endpoints (Gainsight, Marketo, Salesforce, etc.) Transform raw event-level data into formatted tables for modelling and BI consumption Generate accurate and effective documentation What We are Looking For: Bachelor’s degree in Computer Science, Information Technologies, Engineering, or related field 2-3 years of relevant work experience Familiarity writing production ETL using data technologies that allow analysis of large amounts of data (Spark, Hadoop, Hive, Presto, etc) Expert programming skills in one or more general purpose languages (Python, R, Scala, etc.) and highly proficient in SQL Strong work ethic complimented by a proactive problem solver attitude Strong communication/interaction skills Desire to learn new technologies, programming paradigms, and stay up-to-date on current industry standards to share with the team Experience with AWS and Spark preferred"
Data Engineer,Huckleberry Insurance,Remote,https://www.indeed.com/rc/clk?jk=4f037ac8fac25f22&fccid=cff710ddd500db7d&vjs=3,"About Huckleberry: Huckleberry is rebuilding small business insurance from the ground up. In a multi-trillion dollar industry where paper forms and fax machines still predominate, and customers are wasting countless hours navigating byzantine processes, we provide small business owners with the capability to manage all of their insurance needs through a single, elegant interface. Our team is rethinking every aspect of the experience, from pricing, to underwriting to claims. We’re backed by Tribe Capital, Uncork Capital, Crosslink Capital, e.ventures, Postmates CEO Bastian Lehman, Apartment List CEO John Kobs, and several others. We’re looking for a Data Engineer to join our growing team of insurance innovators. As an early member of the Huckleberry team, you will own finding the best solutions to design, architect and implement across our stack. Our data stack is built on numerous cloud technologies running on AWS, Airflow, and DBT. We treat our data pipelines as code with a focus on scalability and performance. We rigorously test our data, use a Dockerized deployment model and Github for code reviews. About the Day-to-Day: Drive the collection of new data and the refinement of existing data sources. Define, improve, and maintain our data infrastructure and any related architecture. Build tooling that can be used by other engineers to capture essential product-related data. Build tooling that can be used by product teams to analyze and evaluate business needs. Develop analytical solutions using machine learning / statistical modeling. Work closely with product and engineering teams to identify important questions / processes that can be answered or improved with data. About You: 3+ years of professional experience working with and analyzing large data sets to solve problems. Intermediate-level Python, Java, or another language with the ability and willingness to learn. Advanced-level SQL. Drive and passion for solving challenging and sometimes ambiguous problems with little oversight. You are excited about contributing and coming up with innovative solutions. Understanding of trade-offs in database and infrastructure design choices. Strong commitment to quality designs, automated testing, and documentation. Good communication skills in English, both written and spoken. Sense of ownership and ability to drive issues and new ideas. Why You’ll Love Working at Huckleberry: Comprehensive medical, dental and vision insurance with 95% of premiums paid for by Huckleberry Free One Medical subscription Flexible Spending Account and 401k Commuter benefits Paid maternity and paternity leave Company-sponsored happy hours and outings"
Cloud Data Engineer (Remote),Charles Schwab,"Remote in Lone Tree, CO 80124+2 locations",https://www.indeed.com/rc/clk?jk=d5eabf24091c24dc&fccid=3c74eafe288fc8ca&vjs=3,"Your Opportunity Wealth & Asset Management (WAM) Engineering is part of the Schwab Technology Services (STS) organization which is responsible for company’s use of information technology including all communications, operations and client and business applications. WAM Data Engineering is aligned to support the technology needs of Schwab Asset Management (SAM) which is the investment advisor for Schwab’s proprietary mutual funds, referred to as the Schwab Funds; and it includes Schwab’s exchange-traded funds, referred to as the Schwab ETFs™. With around $8 Trillion in assets under management, SAM is the 3rd largest provider of index funds and the 5th largest provider of exchange traded funds (ETFs). What you are good at As a passionate, self-motivated individual with Python programming skills we are seeking a data engineer to build high quality, scalable and resilient data systems powered by automated development lifecycle, and CICD. As an engineer understands and help educate others on the merits of highly scalable data processing implementation in a data-centric environment. The Data Technology Team is in the middle of a multi-year effort to build out a strategic Data Platform. As a member of our Scrum team, you are expected to be cross functional to work on any task needed to complete story work. Although this is primarily a data engineer role, and you are required and willing to contribute to any task preventing the team from delivering on team commitments to the business. This may include data mapping, requirements refinement, data validation, documentation, infrastructure tasks, etc. This position will be an integral part of our scrum team and you will work closely with other team members in developing business software solutions. What you have This role requires a highly motivated and experienced developer with pride of ownership reflected through clean application design, code quality, a disciplined software development approach, and accountability for delivery. Qualifications & Experience: Four plus years of experience developing code in Python for data processing Hands-on knowledge of working with SQL Experience working with SQL and NoSQL databases Four years of experience working with data processing pipelines with Apache Spark or Apache Beam etc., Strong knowledge of database development and data testing patterns At least three years of experience with designing, implementing, and supporting highly scalable data systems and experience with GCP or AWS or Azure public clouds is preferred Experience implementing fully automated data flows including data acquisition, staging, processing, and target consumption tier for analytics, reporting, and AI/ML Demonstrate ability to work well independently in a fast-paced, team-oriented environment Ability to learn and adapt quickly to new technologies, processes and work independently Experience developing distributed data processing pipelines using Apache Spark, Beam, Flink etc., Experience with CICD process and usage of development tools including Visual Studio, PyCharm, Git/Bitbucket/Bamboo, Maven, Jenkins, Kubernetes Nexus etc., Experience with integration and service frameworks (e.g Micro services, API Gateways, Swagger API, messaging hub etc.,) Expertise with Microservices and REST based API development Four plus years of experience in data modeling, database design techniques (e.g. RDBMS, Document DB, Dimensional modeling, Star Schema, Data Vault, Kimball Model) Experience or knowledge of Control M schedulers preferred Experience working in an Agile Scrum environment planning and executing with delivery first mindset Experience writing code to automate file movement operations over multiple transmission protocols (e.g. SMB, FTP, SFTP, Object store etc.) Knowledge and experience with complex XML and XSD data structures including parsers, XPath and XQuery is a plus Ability to interact and communicate successfully with business partners and technology teams Experience in Investment Management or Financial Services a plus Education (in order of preference) Masters or bachelor’s degree in Computer Science, Engineering, Information Technology, Information Systems, or similar area of study Personal Characteristics Shows a commitment to high ethical standards and integrity and demonstrates this through action. Lifelong learner who can grasp difficult concepts and complex designs and stays on top of new and emerging technologies Inquisitive, analytical, a strategic thinker, proactive and solutions oriented. High-energy, positive, entrepreneurial in spirit while goal-oriented and results-driven. Self-starter takes initiative and can works independently. Well-organized and disciplined with high attention to detail. Flexible and adaptable working with various business domains. Direct, plain-spoken; conveys a genuine/authentic demeanor. Colorado Compensation Target Total Compensation- 110,000 - 161,400 Your actual pay will be based on your skills and experience- talk with you recruiter to learn more. Why work for us? Own Your Tomorrow embodies everything we do! We are committed to helping our employees ignite their potential and achieve their dreams. Our employees get to play a central role in reinventing a multi-trillion-dollar industry, creating a better, more modern way to build and manage wealth. Benefits: A competitive and flexible package designed to empower you for today and tomorrow. We offer a competitive and flexible package designed to help you make the most of your life at work and at home—today and in the future. Explore further. Schwab is committed to building a diverse and inclusive workplace where everyone feels valued. As an Equal Opportunity Employer, our policy is to provide equal employment opportunities to all employees and applicants without regard to any status that is protected by law. Please click here to see the policy. Schwab is an affirmative action employer, focused on advancing women, racial and ethnic minorities, veterans, and individuals with disabilities in the workplace. If you have a disability and require reasonable accommodations in the application process, contact Human Resources at applicantaccessibility@schwab.com or call 800-275-1281. TD Ameritrade, a subsidiary of Charles Schwab, is an Equal Opportunity Employer. At TD Ameritrade we believe People Matter. We value diversity and believe that it goes beyond all protected classes, thoughts, ideas, and perspectives."
Data Engineer,Ally Financial,"Hybrid remote in Charlotte, NC 28202+1 location",https://www.indeed.com/rc/clk?jk=fd78d56f205ba8a6&fccid=f8c85b296194776f&vjs=3,"General information Career area Technology Work Location(s) 601 S. Tryon Street, Charlotte, NC Remote? No Ref # 12573 Posted Date Thursday, May 12, 2022 Working time Full-time Ally and Your Career Ally Financial only succeeds when its people do - and that’s more than some cliché people put on job postings. We live this stuff! We see our people as, well, people - with interests, families, friends, dreams, and causes that are all important to them. Our focus is on the health and safety of our teammates as well as work-life balance and diversity and inclusion. From generous benefits to a variety of employee resource groups, we strive to build paths that encourage employees to stretch themselves professionally. We want to help you grow, develop, and learn new things. You’re constantly evolving, so shouldn’t your opportunities be, too? The Opportunity At Ally, you get a startup feel, but experience the benefits of a company that’s worked out the kinks and is fulfilling its purpose. We’re always evolving and see that as a good thing. From owning our work to seeing its impact in the real world, our team is relentless in finding new ways technology can help make experiences better and help people. We are problem solvers, we value diverse thinking, we support one another, and we challenge ourselves to think bigger in the journey to deliver customer-obsessed tech solutions. As a Data Engineer at Ally, you’ll work closely with agile teams to build high quality data pipelines and drive analytic solutions. These solutions allow us to generate insights and make data-driven decisions in real-time and drive impact immediately The Work Itself Think outside of the box on a daily basis to promote data-driven decision making through the capture of data and development of innovative solutions Implement, test, and develop a portfolio of best-in-class data tools that contribute directly to the success of Ally’s strategic, technical, and business initiatives Collaborate with business partners and drive the management, refinement, and utilization of data models and tools Actively problem solve to and seek out information to keep the team on track and voice opinions on the most effective way forward The Skills You Bring 3+ years of experience in data warehousing, modeling principles/methods including conceptual, logical & physical Data Models. Deep understanding of different modeling patterns including Data Vault, Dimensional Star-Schema, 3NF, etc. 3+ years of experience creating views, tables, and stored procedures Bachelor's degree in computer science, information systems or relevant field of study preferred Experience in data wrangling, translating/mapping relational data models into XML, JSON Schemas and vise-versa. Proficient in querying skills on traditional relational and no-sql databases Working understanding of AWS services, including but not limited to, EC2, S3, Lambda, AWS CLI, AWS databases, Terraform etc Preferred experience with NiFi and Snowflake Desire to work within a diverse group of people and passion for challenging the status quo Strong work ethic and drive with an enthusiasm for owning your work and driving development How We'll Have Your Back Ally's compensation program offers market-competitive base pay and pay-for-performance incentives (bonuses) based on achieving personal and company goals. But Ally’s total compensation – or total rewards – extends beyond your paycheck and is designed to support and enrich your personal and professional life, including: Time Away: competitive holiday and flexible paid-time-off, including time off for volunteering and voting. Planning for the Future: plan for the near and long term with an industry-leading 401K retirement savings plan with matching and company contributions, student loan and 529 educational assistance programs, tuition reimbursement, and other financial well-being programs. Supporting your Health & Well-being: flexible health and insurance options including dental and vision, pre-tax Health Savings Account with employer contributions and a total well-being program that helps you and your family stay on track physically, socially, emotionally, and financially. Building a Family: adoption, surrogacy, and fertility support as well as parental and caregiver leave, back-up child and adult/elder day care program and childcare discounts. Work-Life Integration: other benefits including LifeMatters® Employee Assistance Program, subsidized and discounted Weight Watchers® program and other employee discount programs. Who We Are: Ally Financial is a customer-centric, leading digital financial services company with passionate customer service and innovative financial solutions. We are relentlessly focused on ""Doing it Right"" and being a trusted financial-services provider to our consumer, commercial, and corporate customers. For more information, visit www.ally.com. Ally is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity or expression, pregnancy status, marital status, military or veteran status, genetic disposition or any other reason protected by law. Where permitted by applicable law, must have received or be willing to receive the COVID-19 vaccine by date of hire to be considered, if not currently employed by Ally. We are committed to working with and providing reasonable accommodation to applicants with physical or mental disabilities. For accommodation requests, email us at work@ally.com. Ally will not discriminate against any qualified individual who is capable of performing the essential functions of the job with or without reasonable accommodation. #LI-Hybrid"
Big Data Engineer,Intone Networks,+8 locationsRemote,https://www.indeed.com/rc/clk?jk=f2cd633b1a72dbcb&fccid=3ed0572c448b2368&vjs=3,"Job Description Norfolk Southern Corporation is currently seeking an experienced Data Engineer - Big Data individual for their Midtown office in Atlanta, GA. The successful candidate must have Big Data engineering experience and must demonstrate an affinity for working with others to create successful solutions. Join a smart, highly skilled team with a passion for technology, where you will work on our state of the art Big Data Platforms (Cloudera). They must be a very good communicator, both written and verbal, and have some experience working with business areas to translate their business data needs and data questions into project requirements. The candidate will participate in all phases of the Data Engineering life cycle and will independently and collaboratively write project requirements, architect solutions and perform data ingestion development and support duties. Skills and Experience: Required: • 6+ years of overall IT experience • 3+ years of experience with high-velocity high-volume stream processing: Apache Kafka and Spark Streaming o Experience with real-time data processing and streaming techniques using Spark structured streaming and Kafka o Deep knowledge of troubleshooting and tuning Spark applications • 3+ years of experience with data ingestion from Message Queues (Tibco, IBM, etc.) and different file formats across different platforms like JSON, XML, CSV • 3+ years of experience with Big Data tools/technologies like Hadoop, Spark, Spark SQL, Kafka, Sqoop, Hive, S3, HDFS, or Cloud platforms e.g. AWS, GCP, etc. • 3+ years of experience building, testing, and optimizing 'Big Data' data ingestion pipelines, architectures and data sets • 2+ years of experience with Python (and/or Scala) and PySpark • 2+ years of experience with NoSQL databases, including HBASE and/or Cassandra • Knowledge of Unix/Linux platform and shell scripting is a must • Strong analytical and problem solving skills Preferred (Not Required): • Experience with Cloudera/Hortonworks HDP and HDF platforms • Experience with NIFI, Schema Registry, NIFI Registry • Strong SQL skills with ability to write intermediate complexity queries • Strong understanding of Relational & Dimensional modeling • Experience with GIT code versioning software • Experience with REST API and Web Services • Good business analyst and requirements gathering/writing skills"
Data Engineer - (Immediate Opening),IDEA Public Schools,"Weslaco, TX 78596",https://www.indeed.com/rc/clk?jk=8ddc024b32cb2554&fccid=4c58f1f52a144526&vjs=3,"Role Mission: The Data Engineer will be responsible for improving IDEA’s operational processes and supporting critical strategies by assisting in the new development and implementation related to our internal applications systems. The Engineer will deliver the testing, ongoing evaluation, and validation of organizational data structures and identify issues in current processes while providing proven strategies for ongoing database and data warehouse development relating to internal custom applications development and deployment. This position will provide recommendations and insight on IDEA’s IT operations and strategy from an applications development standpoint. This job requires the ability and desire to work and communicate well in a dynamic team environment as well as dependability and self-sufficiency. What You’ll Do – Accountabilities : On-time Product Delivery: Drive to and maintain on-time development and delivery of high-quality features for custom applications and business intelligence tools as defined by monthly sprint plans as measured by: % of Critical defects due to SQL code changes and ETL functioning should be limited to a max of 5% % of spilled over development tasks should be limited to a max of 5% Should acquire the complete ownership of at least 20% of the features developed % of reopened defects should be limited to a max of 2% Effective Requirements Analysis: New major product work and execution is detailed with full requirements analysis and effective preparation for sprint planning, with detailed task/effort estimates as measured by: Difference between estimated effort and actual effort should be limited to a max of 15% and decrease gradually Defects due a mis-match in understanding of the requirements should be limited to a max of 10% Efficient Object-Oriented Analysis and Design: Thorough object-oriented analysis and design of features with the documentation of necessary design artifacts as measured by: Refactoring time to enhance/improve SQL code changes and ETL development should be less than 15% of the original effort. At least 20% of the code developed should be reusable Reuse of code should be leveraged when possible. Duplication, if any, should be limited to a max of 5%. Adherence to Effective Scrum Practices: Adhering to all of the Scrum processes, with active and punctual participation in Scrum meetings as measured by: Absenteeism in scrum ceremonies including daily huddles, retrospectives, product reviews, and planning sessions should be limited to a max of 5% with prior intimation All planned leaves (both short and long duration) should be intimated in advance and documented so that sprint commitments are not affected. Deviation should be limited to 5%. Unplanned leaves (both short and long duration) should be intimated as soon as possible and documented so that sprint commitments are not affected. Deviation should be limited to 5%. Continuous Improvement of Domain, Technical, and Behavioral Skills: Continuously enhancing the Product domain knowledge, technical, and behavioral competencies to grow to the next level as measured by: Relevant trainings/actions need to be identified, planned and attended 3 times within the year (1 skill from each area – domain, technical, and behavioral) Development and demonstration of these skills for the purpose of the facilitation of team training and/or mentoring should be developed for each team member (1 opportunity per year) We look for Team and Family who embody the following values and characteristics: Believes and is committed to our mission and being an agent of change: that all students are capable of getting to and through college Has demonstrated effective outcomes and results, and wants to be held accountable for them Has a propensity for action, willing to make mistakes by doing in order to learn and improve quickly Works with urgency and purpose to drive student outcomes Thrives in an entrepreneurial, high-growth environment; is comfortable with ambiguity and change Seeks and responds well to feedback, which is shared often and freely across all levels of the organization Works through silos and forges strong cross-departmental relationships in order to achieve outcomes We believe in education as a profession and hold ourselves to high level of conduct, professionalism and behaviors as models for our colleagues and students Note: At IDEA, the Data Engineer role is a mid to high level role with a focus on building upon the IDEA data warehouse. The IDEA data warehouse is the central data store for all analytics and reporting. As a result, the Engineer is responsible for data extraction, transformation, and loading of data into the data warehouse and is the primary keeper of this system. These processes require strong skills with a variety of specialized tools and techniques for data cleansing, preparation, modeling, and integration. This role is also required to have a strong background in analytics and server-side processing. Supervisory Responsibilitie s : This role leads and oversees the work of others in a project capacity as a project technical lead: Planning and directing Data Integration/ETL Developer team member activities on projects Assigning work Overseeing proper maintenance and back-up of source code Participation in evaluating performance (for Data Integration/ETL Developers) Mediating conflict resolution Qualifications: Education: Bachelor's degree from four-year college or university in Information Technology, Computer Science, Computer Engineering, and Software Engineering Experience: 6+ years related work experience and/or training; or equivalent combination of education and experience. Certification/License: Microsoft Certified Solutions Associate (SQL 2016 BI Development), Certified Associate in Project Management (CAPM) preferred What We Offer Compensation: Salaries for people entering this role typically fall between $66,626 and $80,618, commensurate with relevant experience and qualifications and in alignment with internal equity. This role is also eligible for a performance bonus based on individual and organizational performance and goal attainment. Other Benefits: We offer a comprehensive benefits plan, covering the majority of the employee premium for the base medical plan and subsidizing the majority of costs for a spouse/domestic partner and children. Other benefits include dental and vision plans, disability, life insurance, parenting benefits, flexible spending account options, generous vacation time, com‐muter benefits, referral bonuses, professional development, and a 403(b) plan. We also offer an inclusive environment where staff are encouraged to bring their whole selves to work every day. IDEA may offer a relocation stipend to defray the cost of moving for this role, if applicable. To Apply : Please submit your application online through Jobvite. It’s in your best interest to apply as soon as possible. It is recommended that you include a cover letter in your application addressing why you are interested in IDEA and how your experience has prepared you for this position."
Project Engineer - Master Data Management,FedEx Logistics,"Remote in Miami, FL 33126+5 locations",https://www.indeed.com/rc/clk?jk=e48d42b12d3103e9&fccid=c10d511b96782b65&vjs=3,"Company: FedEx Logistics Job Title: Project Engineer - Master Data Management Job Requisition Number: RC528100 Time Type: Full Time Job Type: Regular Primary Job Posting Location: Remote United States Additional Locations: 170 Cooper Avenue Tonawanda, New York 14150 United States 15022 132nd Avenue New York, New York 11434 United States 701 Waterford Way Miami, Florida 33126 United States 1101 Busse Road Elk Grove Village, Illinois 60007 United States 17210 S Main St Gardena, California 90248 United States Posting Date: 2022-06-14 Job Posting End Date: 2022-06-21 Colorado Residents Only – Compensation: Monthly Salary $6510.8 - $12353.8 The estimate displayed represents the typical salary range or starting rate of candidates hired in Colorado. Factors that may be used to determine your actual salary may include your specific skills, your work location, how many years of experience you have, and comparison to other employees already in this role. This information is provided to applicants in accordance to the Colorado Equal Pay for Equal Work Act. This role will lead in maintaining data integrity and following MDM standards in our Freight Forwarding applications. Quality data management is at the heart of our ability to turn data into an asset. Only standardized, non-duplicated, accurate and complete data can effectively serve global operations. You’ll work with our internal IT teammates, as well as our Operations and Finance teams, to assist with application settings, reference data, reports, workflow engine and various other duties supporting users in more than 50 countries worldwide. Responsibilities: This role will lead in maintaining master data and settings within our freight forwarding system (Cargowise One). This role will provide standards, governance and stewardship, data processes, and will oversee application configuration settings. Maintenance and Management of the MDM in the freight forwarding system includes: Application configuration settings Ongoing maintenance of reference data and security settings. Responsible for developing standards, guidelines, processes and expertise to consistently address recurring master data issues. Engaging and collaborating with leaders and peers in evolving Master Data Management within the organization's applications and processes Assist with mass updates or downloads of data for special projects Customization of documents and reports Work with application Workflow configurations Participate in testing of new releases in the system Knowledge and Experience Bachelor’s Degree in Industrial Engineering or a related engineering discipline. Five (5) years professional or related experience. Experience in Logistics and familiarity with CargoWise One is required. Strong sense of urgency and quality awareness in a fast-paced business environment, with the ability to multi-task, problem solve, and prioritize Must be a strong self-starter able to work independently under limited supervision and meet deadlines. Ability to build a consensus and to work through others in achieving desired results and objectives. Ability to analyze varying stakeholder concerns, proactively working with diverse groups to address concerns SPECIAL SKILLS: Must speak English fluently Must be proficient in Excel. Experience with SQL and ability to perform queries preferred Very detail-oriented and able to look thoroughly through extensive data sets determining patterns and issues #LI-Remote This position will be remote. #LI-Remote FedEx Logistics provides freight forwarding, as well as import and export services that allow companies to reach markets throughout the world. They help customers of all sizes solve the intricacies of shipping goods globally by providing comprehensive international ocean and air freight forwarding, surface transportation and distribution, customs brokerage, trade and customs advisory services, and advanced e-commerce and trade facilitation solutions. We're glad you stopped by and hope your job search experience with FedEx Logistics, Inc. will be rewarding. We look forward to hearing from you! FedEx Logistics, Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to their protected veteran or disability status. FedEx Logistics, Inc. participates in the Department of Homeland Security U.S. Citizenship and Immigration Services' E-Verify program (For U.S. applicants and employees only). Please ready the E-Verify Notice available in English (https://e-verify.uscis.gov/emp/media/resourcesContents/E-Verify_Participation_Poster.pdf) and Spanish (https://e-verify.uscis.gov/emp/media/resourcesContents/E-Verify_Participation_Poster_ES.pdf) before proceeding with your job application. Click here to read the Right to Work Notice available in English (http://ftn.fedex.com/careers/OSC_Right_to_Work_Poster.pdf) and Spanish (http://ftn.fedex.com/careers/OSC_Right_to_Work_Poster_ES.pdf). Additional information about the E-Verify program can also be found at www.uscis.gov. The Company offers a comprehensive benefits package including health, dental, and vision care coverage, retirement savings, vacation pay, holiday pay, sick time, and life insurance to eligible employees. Pay Transparency Policy Statement: The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless required to do so by law or the FedEx Logistics Legal Department. Import Notice to All Applicants: FedEx Logistics is engaged in an industry regulated by federal law that prohibits it from employing convicted felons. Therefore, it must determine whether applicants have been convicted of felonies before a hiring decision is made. A criminal background check will be required of all selected applicants before a hiring decision is made. Equal Employment Opportunity: As a federal government contractor, we are committed to employ and promote qualified minorities, females, individuals with disabilities, and covered veterans (including, but not limited to, disabled veterans, recently separated veterans, Armed Forces service medal veterans, and other protected veterans. Our philosophy and commitment to equal employment opportunity and non-discrimination is the bedrock to job opportunities for all employees and applicants without regard to an individual's protected status (i.e. race/ethnicity, color, national origin, ancestry, sex/gender, gender identity/expression, sexual orientation, marital/parental status, pregnancy/childbirth, or related condition, religion, creed, age, disability, genetic information, veteran status, or any other protected status.) Click here and here to read more about ""Equal Employment Opportunity is the Law."" FedEx Logistics will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the FAIR Chance Initiative for Hiring Ordinance (FCIHOO) for the City of Los Angeles (LAMC 189.00) FedEx Logistics will not rely on the wage history of a prospective employee from any current or former employer when determining the wages for such individual at any stage in the employment process, including in the negotiation or drafting of any employment contract in accordance with Philadelphia Ordinance No. 160840."
Data Engineer,GoTo,+1 locationRemote,https://www.indeed.com/rc/clk?jk=6ecfc979baca0528&fccid=75d8817dffc3069a&vjs=3,"Job Description Our Customer Retention Team is looking for a Data Engineer to partner with Customer Success, Analytics and Data Science on providing highly visible data products that power predictive models, analyses, and critical enablement for customer engagement teams. As a part of this team, you will be responsible for building and maintaining insightful, scalable, and robust systems and solutions using AWS and related technologies such as Spark, Hive, Presto, ML Flow, DataBricks etc. This position will support our operational and business objectives, working with Analysts and Data Scientists on new and existing data initiatives. The ideal candidate will have experience in data manipulation and constructing ETL pipelines, have demonstrable data intuition, and the ability to iterate quickly to develop robust data products and solutions. You should be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. Your day to day as a Data Engineer you would be working on: Design, build, and manage production-level ETL pipelines and ensure timely SLAs on all managed sources Be subject matter expert for team on ETL/programming best practices, query optimization, and LogMeIn’s data platform infrastructure Build and maintain a data quality framework that monitors data sources used by Analysts and Data Scientists to ensure data correctness and availability Partner with machine learning engineers and data scientists on model deployment, monitoring, and retraining Work with Customer Engagement teams to provide critical customer data to various endpoints (Gainsight, Marketo, Salesforce, etc.) Transform raw event-level data into formatted tables for modelling and BI consumption Generate accurate and effective documentation What We are Looking For: Bachelor’s degree in Computer Science, Information Technologies, Engineering, or related field 2-3 years of relevant work experience Familiarity writing production ETL using data technologies that allow analysis of large amounts of data (Spark, Hadoop, Hive, Presto, etc) Expert programming skills in one or more general purpose languages (Python, R, Scala, etc.) and highly proficient in SQL Strong work ethic complimented by a proactive problem solver attitude Strong communication/interaction skills Desire to learn new technologies, programming paradigms, and stay up-to-date on current industry standards to share with the team Experience with AWS and Spark preferred"
Data Analytics Engineer (contract),Noodle,"Remote in Tulsa, OK 74114+10 locations",https://www.indeed.com/rc/clk?jk=f65b2db08dd38596&fccid=2fa3aafd0cd164bc&vjs=3,"Data Analytics Engineer (contract) Online education is no longer a novel or niche idea. It is the fastest-growing segment in higher education, accounting for 20% of all enrollees and 35% of graduate-level certificates and degrees. It's also getting increasingly competitive, as more and better programs are launched each semester. Universities need to go online quickly, economically, and elegantly, creating programs that students can't wait to tell their friends about and that their professors want to teach. Noodle helps universities bring programs online with flexibility, transparency, alignment, efficiency, and joy. That's why more top universities chose us last year than all other online program managers combined. We are a passionate team of technologists, educators, and experts. Online learning has the potential to transform higher education; if you’re interested in being part of that journey, keep reading! About the Role: As a Data Analytics Engineer at Noodle, you would build analytics products to inform strategic decision making, both internally and for our university partners. Our products help senior leaders understand successes and opportunities across all parts of the student journey, from engagement with our online marketing materials through enrollment, all the way to graduation. As a Data Analytics Engineer (contract) at Noodle you will: Be responsible for collaboratively building data analytics pipelines and dashboards for multiple stakeholders. This includes… Translating high-level product requirements into technical requirements Identifying new data we need and developing ingestion processes Clarifying business rules and implementing them in code Transforming data using SQL to power our analytics products Writing automated tests, documenting your work, and reviewing others’ work Building Tableau visualizations to make data actionable Teaching stakeholders how to use your products and incorporating their feedback You have: Experience using git, complex SQL, and AWS to build and deploy data products Experience creating visualizations in Tableau Ability to work cross-functionally to iteratively develop data products and processes Experience analyzing data from digital marketing, CRM, SIS or LMS tools Experience using Python, dbt, AWS Athena, or CircleCI (Bonus) At Noodle, we hire people who will help us change the future of online education. Even if you don't think you check off every bullet point on this list, we still encourage you to apply! We value both current experience and future potential Noodle benefits: Work from our beautiful New York office! OR Work from the comfort of your home office! Competitive salary 401K + match, bonus potential, and equity opportunities Tools you need on us! Mac is our computer of choice Our insurance plan offers medical, dental, vision, short- and long-term disability coverage, plus supplementals for all employees and dependents 12 weeks paid Parental Leave Pre-tax commuter benefits 3 weeks paid vacation + paid holidays + paid sick leave Monthly Gym Reimbursement and Membership to premium medical services like One Medical and Eden Health Monthly cell phone reimbursement Annual education stipend for lifelong learning Growth - we pride ourselves on creating environments where employees can be themselves and grow within and around the company Noodle is committed to creating a welcoming and inclusive workplace for everyone. We value and celebrate our differences because those differences are what make our team shine. We hire great people from different backgrounds, not just because it's the right thing to do, but because it makes us stronger as a whole. Women, people of color, LGBTQIA2S+ individuals, and members of other underrepresented groups are strongly encouraged to apply. Noodle is an equal opportunity employer and does not discriminate against candidates on the basis of race, ethnicity, religion, sex, gender, sexual orientation, gender identity, disability status, or veteran status. Noodle won Built In NYC’s 100 Best Places to Work, Best Midsize Companies, and Best Perks & Benefits 2021, and 2022 and was named one of Crain’s 100 best places to work in NYC in 2021. #LI-Remote"
Senior Data Engineer [Remote],Braintrust,"Remote in San Francisco, CA+7 locations",https://www.indeed.com/rc/clk?jk=edcd05f96d9e1267&fccid=cffd065f9ff9e672&vjs=3,"ABOUT US: Braintrust is the only network that gives in-demand talent all the freedom of freelance with all the benefits, community and stability of a full-time role. As the first decentralized talent network, our revolutionary Web3 model ensures the community that relies on Braintrust to find work are the same people who own and build it through the blockchain token, BTRST. So unlike other marketplaces that take 20% to 50% of talent earnings, Braintrust allows talent to keep 100% of earnings and to vote on key changes to improve the network. Braintrust is working to change the way freelance works – for good. JOB TYPE: Freelance, Contract Position (no agencies/C2C - see notes below) LOCATION: Remote - United States and Canada Only HOURLY RANGE: Our client is looking to pay $100 – $130/hr ESTIMATED DURATION: 40h/week - long-term, ongoing project THE OPPORTUNITY What You Have 5+ years of experience in Data Engineering role 3+ years of programming experience with at least one language such as Python, Scala, Java, or other modern OOP programing language 3+ years' experience in writing SQL statements 3+ years' experience with schema design and dimensional data modeling Experience building and optimizing 'big data' data pipelines, architectures, and data sets Experienced developing in cloud platforms such as Google Cloud Platform (preferred), AWS, Azure, or Snowflake at scale Experience with real-time data streaming tools like Kafka, Kinesis, Apache Storm, or any similar tools Experience in designing data engineering solutions using open source and proprietary cloud data pipeline tools such as Airflow, dbt, Glue, and Beam Experience in development of custom built BI and big data reporting solutions using tools like Looker, DataStudio, or any similar tools Experience with code management tools (e.g., Git, SVN) and DevOps tools (e.g., Docker, Jenkins) Excellent communication and presentation skills, strong business acumen, critical thinking, and ability to work cross functionally through collaboration with engineering and business partners What we'd love to see (but isn't required) Supply Chain or Ecommerce analytics experience a strong plus Bachelor's or Masters in Computer Science, Computer Engineering, Statistics, or another quantitative discipline What you'll be working on Senior Data Engineer, Supply Chain Data Engineering Data Engineering is the engine that powers our client data obsessed eCommerce enterprise. They move fast, iterating quickly on big business problems. Data Engineering efforts are instrumental in further growing their market share in a $800 billion home goods market. Every day, they ingest billions of rows of data about how people pick out the perfect items for their home, and this data is what drives their business strategies and decisions. They build cutting-edge data platforms enabling advanced analytics and insights across their business and analytics teams. As a senior data engineer, you will be a hands-on developer who designs, and delivers Data Warehouses, Data Lake, Self-service tooling, Real-time streaming, and Big Data Solutions for their rapidly growing Supply Chain Operations. Working within the Data Engineering organization, this individual will tightly partner with business, product managers and engineering leaders to build data platforms enabling these goals. You will be instrumental in building out the data pipelines to ensure their data is generated, transformed, and mutated over time, working to build a cohesive, scalable, accurate, and performant foundational source of truth upon which all data & analytics users across the company will build. What You'll Do Build data pipelines to assemble large, complex sets of data that meet non-functional and functional business requirements Deliver Data Engineering capabilities for streaming and batch-based data ingestion, enrichment, and aggregation. Design and develop sophisticated data models and visualizations that support multiple use cases across different products or domains. Define and manage SLA for all data sets in allocated areas of ownership. Work closely with data architect, SMEs, and other technology partners to develop & execute on the data architecture roadmap for different functional areas Mentor and grow technical skills of engineers across multiple sprint teams by giving high quality feedback in design and code reviews and providing training for new methods, tools, and patterns Collaborate with your stakeholders and other business analytics team leaders Apply Now! #PL-BT ABOUT THE HIRING PROCESS: Qualified candidates will be invited to do a screening interview with the Braintrust staff. We will answer your questions about the project, and our platform. If we determine it is the right fit for both parties, we'll invite you to join the platform and create a profile to apply directly for this project. C2C Candidates: This role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we'd welcome your application. Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status."
"ENGINEER, DATA",Denver Public Schools,"Denver, CO 80203 (Capitol Hill area)",https://www.indeed.com/rc/clk?jk=326d4d83b980f911&fccid=edd6757e2758ac76&vjs=3,"ENGINEER, DATA (JOB ID: 55266) DEPARTMENT OF TECHNOLOGY SERVICES (DoTS) Traditional 235 work days FTE: 1.0 Salary Range: $90,575 - $113,220 E ssential Functions and Objectives: A pplies engineering principles, techniques and scientific methods in a specific area of expertise (building, construction, technology, etc.). Responsible for solving technical problems and discovering new ways to improve the district's systems, infrastructures, processes and operations. R esponsible for ingesting critical District data from applications and other sources into a warehouse environment and preparing the data for consumption using an Extract Load Transform (ELT) methodology. Data preparation includes transformation based on District specific practices and the generation of structures that are highly available and highly performant. Ensure consistent use of best practices and support accuracy and optimized performance across the data platform. Prototype data solutions to enable warehousing, event-driven data capture, and data modeling. Implement solutions using Extract Load Transform (ELT/ETL) and/or combinations of automation tools. Collaborate with data teams to develop re-usable data solution patterns to enable quick to market data assets. Analyze & profile business data in structured and unstructured formats. Design and implement conceptual and logical data models, create metadata definitions, and create a source-to-target mapping. Evaluate tools and emerging technologies within the data ecosystem to push innovation. Collaborate with data owners, functional teams, and data consumers to understand the end-to-end intention of data use. Optimize data performance throughout the ELT process. Demonstrate Students First, Integrity, Equity, Collaboration, Accountability, and Fun in all interactions with team members, other DPS employees and external partners. K nowledge, Experience & Other Qualifications: One (1) or more years of SQL experience and the ability to write basic Python task is required. Experience in acquiring data from API’s is required. Valid Colorado Driver’s License, appropriate insurance coverage and acceptable driving record for the past three years, if the position requires travel. Effective time management and organizational skills. The ability to take responsibility for one’s own performance. Works collaboratively with others on a team. High degree of integrity in handling confidential information. Aptitude for variety and changing expectations in a fast-paced environment. Ability to work in a multi-ethnic and multi-cultural environment with district and school leaders, faculty, staff and students. Experience working within a cloud based data infrastructure is preferred. Advanced proficiency in developing SQL queries is preferred. Effective communication skills. Analytical problem solver with strong attention to detail. Experience with or ability to quickly learn new tools and technologies including dbt, Snowflake, Airflow, AWS S3 is preferred. E ducation Requirements: Bachelor’s Degree in Related Quantitative Field (e.g. Mathematics, Engineering, Sciences, Operations Research) is required. Master’s Degree is preferred. O ther information: T he mission of the DPS Department of Technology Services (DoTS) is to be a proactive partner enabling the success of every child. We support the students, families, and staff of Denver Public Schools by providing the infrastructure, tools, data, and support to enable effective educators and efficient operations. Our leading-edge technology work includes delivering custom portals for our students, parents, teachers, and administrators, managing one of the largest networks in the state of Colorado, providing unparalleled levels of customer support, finding new ways to get technology in the hands of our students, and much more. We believe that technology is a positive, enabling force for parent engagement, student engagement, educator effectiveness, operational efficiency, student safety, and student achievement. By joining us, you too will be enabling the success of every child! A dditional Information: Work Year Calendars (including accrued time off): http://thecommons.dpsk12.org/Page/1129 Benefits (including DPS contributions): http://thecommons.dpsk12.org/Page/1397 Compensation Structures: http://thecommons.dpsk12.org/Page/244 Employee must live and work with a permanent home address in Colorado while working for Denver Public Schools. A bout Denver Public Schools: D enver Public Schools is committed to meeting the educational needs of every student with great schools in every neighborhood. Our goal is to provide every child in Denver with rigorous, enriching educational opportunities from preschool through high school graduation. DPS is comprised of nearly 200 schools including traditional, magnet, charter and alternative pathways schools, with an enrollment of more than 90,000 students. D PS has become the fastest-growing school district in the country in terms of enrollment and the fastest-growing large school district in the state in terms of student academic growth. Learn more at dpsk12.org . D enver Public Schools is an Equal Opportunity Employer and does not discriminate on the basis of race, color, religion, national origin, sex, sexual orientation, age, disability, or any other status protected by law or regulation. It is our intention that all qualified applicants be given equal opportunity and that selection decisions be based on job-related factors."
"Senior Data Engineer, AWS Managed Services","Amazon Web Services, Inc.","Seattle, WA",https://www.indeed.com/rc/clk?jk=ba6ad8c78f1b5970&fccid=5cc0cdc6dbb121cc&vjs=3,"Degree in Computer Science, Engineering, Mathematics, or a related field or 5+ years industry experience 5+ years of experience with demonstrated strength in ETL/ELT, modeling, warehouse technical architecture, infrastructure components and reporting/analytic tools. 5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large sets. 3+ years of experience in scripting languages like Python, Scala etc. Job summary AWS Managed Services (AMS) is seeking a Data Engineer to join our engineering team. This individual will work with the business intelligence, engineering, and product teams to help deliver business intelligence and customer facing data and reporting that is timely, accurate, and actionable. AMS customers are large enterprise companies (Fortune 100, Fortune 500, Global 2000) and AWS has culture of data-driven decision-making, you will have an immediate influence on day-to-day decision making. Responsibilities AMS is a fast paced environment where every day brings new challenges and new opportunities. Our Data Engineer will build and maintain the infrastructure to answer questions with data. They will use software engineering best practices, data management fundamentals, data storage principles, and recent advances in distributed systems (e.g. MapReduce, MPP architectures, NoSQL databases). This individual would be responsible for producing data infrastructure that enables insight. Optimizing data persistence processing, and accessibility for Online Transaction Processing (OLTP) and Online Analytic Processing (OLAP). You will interact with customers to gather requirements and structure solutions. Design, implement and drive adoption of new analytic technologies and solutions. Promote industry standard best practices. Interface with business customers, gathering requirements and gaining a deep-dive understanding of key datasets. Tuning application and query performance against large, complex data structures. Graduate degree in Computer Science, Engineering or related technical field. Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets. Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets. Experience building data products incrementally and integrating and managing datasets from multiple sources. Experience with AWS Tools and Technologies (S3, EC2, Data Pipeline etc.). Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space. Experience in Python and/or other data ingestion languages and tools. Effective analytical, troubleshooting and problem-solving skills. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Senior Data Engineer,ServiceTitan,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=ae86cd3b36abe30a&fccid=88323fbac065cf8f&vjs=3,"Ready to be a Titan? Service Titan is seeking an exceptional Senior Data Engineer to join one of the fastest-growing tech startups in Southern California, backed by the best VC firms in the SaaS space. You will join a small, but rapidly growing, team that prides itself on being a solution-driven, strategic partner to Service Titan business operators. ServiceTitan is a data-driven company at all levels of the organization, and you will see the impact you make on the company’s future. You will be empowered to challenge the status quo, dream big and make a massive impact. Your contribution will lead to further democratizing data at ServiceTitan by providing transparent data culture. What you'll do: Help build our Business Insights capabilities, including defining and implementing requirements for our company-wide Enterprise Data platform Collaborate with business, service, and solution architects to understand data architecture and maximize the value of data across the organization Collaborate with team members to design, develop, test, document, and implement data integration, data warehousing, and business intelligence solutions Develop logical data models and physical database designs applied across multiple computing environments Develop integration processes with different external platforms to extract data efficiently and accurately Automate frameworks for data quality and integrity Monitor performance and advise any necessary infrastructure changes Ensure optimal end-user experience by establishing system performance assessment processes and associated action plans Establish quality working relationships with internal users and help them understand the data and metrics in our data warehouse Develop standards, process flows, and tools that promote and facilitate the mapping of data sources, documenting interfaces and data movement across the enterprise. What you'll need: Bachelor’s degree in computer science, management information systems, or equivalent 5-7 years of industry experience Strong understanding of database and data model concepts Advanced knowledge of SQL Hands-on experience building data pipelines and ETL/ELT at scale A strong understanding of the Snowflake database architecture, as well as experience with Snowpipe for Snowflake data ingestion, is a plus Deep understanding of ETL best practices, scalability, complex process management, self-healing Knowledge of Python, advanced Python for data management is preferred Good understanding of big data technologies and frameworks Strong analytical skills Ability to work independently and cross-functionally Familiarity with Analytical/Reporting Solutions like Tableau, PowerBI is a plus. Data auditing skills to verify data integrity, understand discrepancies, and resolve them effectively Be Human With Us: Being human isn’t about checking every box on a list. It’s about the experiences we have, people we meet, and the perspectives we share. So, if you have the skills but are hesitant to apply because of your background, apply anyway. We need amazing people like you to help us challenge the conventional and think differently about the problems that we’re solving. We’re in this together. Come be human, with us. What We Offer: When you join our team, you’re not just accepting a job. You’re making a career move. Here’s how we’ll support you in doing some of the most impactful work of your career: Flextime, recognition, and support for autonomous work: Flexible time off with ample learning and development opportunities to continue growing your career. We offer a comprehensive onboarding program, leadership training for Titans at all levels, and other programs and events. Great work is rewarded through Bonusly, peer-nominated awards, and Founders Club- open to all Titans. Holistic health and wellness benefits: Company-paid medical, dental, and vision (with 100% employer paid options and 90% coverage for dependents), FSA and HSA, 401k match, and telehealth options including memberships to Headspace, Galileo, One Medical, Ginger and more. Support for Titans at all stages of life: Parental leave and support, up to $20k in adoption reimbursement, on demand maternity support through Maven Maternity, free breast milk shipping through Maven Milk, pet insurance, legal advisory services, financial planning tools, and more. At ServiceTitan, we celebrate individuality and uniqueness. We believe that the convergence of fresh perspectives and experiences from all walks of life is what makes our product and culture so great. We strongly encourage people from underrepresented groups to apply. We do not discriminate against employees based on race, color, religion, sex, national origin, gender identity or expression, age, disability, pregnancy (including childbirth, breastfeeding, or related medical condition), genetic information, protected military or veteran status, sexual orientation, or any other characteristic protected by applicable federal, state or local laws."
Data Engineer (Remote),"Knowesis, Inc.",Remote in United States,https://www.indeed.com/rc/clk?jk=5b532f2b98121add&fccid=87dc0c4bdcdb1ffe&vjs=3,"Knowesis is seeking a Data Engineer. The Data Engineer will be responsible for translating business requirements and methodologies into code sets to extract and process data. This includes establishing configuration control and executing scheduled jobs and ad-hoc data requests. Work may also include evaluating new data sets, integrating and blending data, and maintaining analytic products (views, cubes, reports, and Business Data Extracts). Critical to this role is a technical and functional understanding of the MHS data. This position requires a Public Trust clearance and requires U.S. Citizenship (applicants without proof of U.S. citizenship will not be considered due to the position's security clearance requirement). Duties and responsibilities include but are not limited to: Import, clean, and prepare very large data sets for advanced data manipulation and statistical analysis, Operate in consultation with colleagues and program staff to provide data extraction, data mining, and curation. Provide consultation and assistance to supported units to identify opportunities and methods for capturing data relating to MHS programs and initiatives, Prepare reports and presentations that accurately convey data trends and associated analyses, Enter and analyze and curate data within government systems. Additional Requirements: The successful candidate must not be subject to employment restrictions from a former employer (such as a non-compete) that would prevent the candidate from performing the job responsibilities as described. COVID-19 Due to the COVID-19 Pandemic, Knowesis requires all employees to be fully vaccinated as a condition of employment. An employee is considered fully vaccinated two weeks after receiving the second dose of a two-dose COVID-19 vaccine or one week after receiving a single-dose COVID-19 vaccine. All newly hired employees will be required to provide proof of vaccination. Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities Knowesis will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c) Experience Required Experience analyzing direct care MHS data and understanding of corporate data repositories. Experience with the DHA data and the AVHE MIP, Amazon Red Shift, cloud environments, and reporting applications. Three years, or more, of data mining and curation experience in academic, social services, government, healthcare, or laboratory setting. Excellent communication skills and highly detail-oriented and organized. Proficiency with Data Management and Data Mining disciplines. Must have advanced proficiency with MS SQL, MS Server, SSIS Packaging, Python, Business Objects, Tableau Desktop, Prep Builder, and data modeling tools, etc. Advanced proficiency with the suite of Microsoft Office programs, including Word, Excel, Project, and Access. Preferred Data Management Body of Knowledge or Data Management Professional certifications. Education Required Bachelors or better in Science/Mathematics or related field"
Data Engineer,Diamond Foundry,"Hybrid remote in San Francisco, CA",https://www.indeed.com/rc/clk?jk=bef7087fcbbd9c6a&fccid=c7342f41f3559451&vjs=3,"Diamond Foundry Inc. is one of the fastest growing, profitable technology startups. Creating the future of diamonds for jewelry and semiconductor applications, we use proprietary plasma reactor technology to produce high-quality diamond without carbon footprint and sell diamond jewelry online via our VRAI direct-to-consumer brand. We are looking for a hybrid onsite/remote data-focused software engineer to troubleshoot, test, and design improvements for manufacturing related data pipelining and aggregation. Our internally developed data system is used to both report key business metrics as well as analyze our manufacturing process in real-time. You'll be working with an experienced team of mechanical, electrical, and software engineers, both assisting senior engineers and taking responsibility for your own engineering projects. Your goal will be to achieve maximum productivity for our production line through improving data extraction techniques, standardizing data collection methods, generating accessible and comprehensive data views, and ensuring data security. Responsibilities: Assess user needs and requirements Communicate results and new products to key stakeholders Develop and improve data processing systems to curate, transform, and refine production data into useful and intuitive datasets Work with team members to aggregate, analyze, interpret, and visualize large data sets for statistical inference and ML model training and evaluation Ensure disaster-proof datasets, with high availability Implement, troubleshoot, and maintain security standards for data storage, transfer, and interpretation Normalize data storage for efficient but available retention Requirements: Bachelor's degree in Computer Science or similar engineering discipline 3+ years of software/SQL/CS engineering experience Experience with maintaining security protocols across an organization A qualified candidate will have a subset of these skills: Software: SQL, NoSQL, ML, Python, Linux, Windows CMD/PowerShell, HTML, Java, LabVIEW Experience in building reports and real time BI analytics Diamond Foundry welcomes applications from candidates who are fully vaccinated against COVID-19. Proof of vaccination will be required as a condition for hiring."
Data Engineer,Govini,"Pittsburgh, PA",https://www.indeed.com/rc/clk?jk=3a5c87a0670faa13&fccid=932bcab1f7ee18f8&vjs=3,"Company Description Govini is a decision science firm dedicated to transforming the business of national security through data science and machine learning. Through its National Security Knowledge Graph and Decision Science Platform, Govini delivers objective, decision-grade information at scale to the national security enterprise, so that leaders can better direct investments to innovation and modernization. Govini has offices in Arlington, Virginia, San Francisco, California, and Pittsburgh, Pennsylvania. Job Description We are seeking an exceptional and experienced data engineer who shares our passion and obsession with quality. You'll be a core member of our product and engineering team dedicated to helping our clients replace time-consuming, manual processes to reach informed real-time decisions about government markets, competitors, and agency relationships. We need a skilled and dedicated data nerd to join our team to lead us in uncovering truth and meaning in data. You must be a hands-on engineer with a strong understanding of both data management and governance standards. You must also have strong interpersonal skills to work cross-functionally across internal teams as well as directly with end users and Govini platform SMEs. In order to do this job well, you must be a curious and eager problem solver with a hunger for delivering high-quality data solutions. You have a passion for great work and nothing less than your best will do. You share our intolerance of mediocrity. You’re uber-smart, challenged by figuring things out and producing simple solutions to complex problems. Knowing there are always multiple answers to a problem, you know how to engage in a constructive dialogue to find the best path forward. You’re scrappy. We like scrappy. This is a team member position, working onsite in our Pittsburgh, PA office. Scope of Responsibilities Define and lead Govini's data lifecycle strategy across data acquisition, data ingestion, data cleansing, normalization and linkage. Ensure key entities within datasets are identified, resolved and linked to existing entities within the current master data repository. Apply various techniques to produce solutions to large-scale optimization problems, including data pre-processing, indexing, blocking, field and record comparison and classification. Improve data sharing, increase data repurposing and improve cost efficiency associated with data management efforts. Build best practices that help with chain of custody of data so it can be easily traced back to the source for accuracy and consistency. Work across functional teams to understand advanced statistical, machine learning, and text processing models and incorporate them into Govini’s existing data engineering infrastructure. Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Work directly with users as well as SMEs to establish, create and populate optimal data architectures and structures, as well as articulate techniques and results using non-technical language. Requirements Must be able to work in the United States without visa sponsorship now or in the future Required Skills Bachelor's degree in Computer Science, Mathematics or related technical field 3-5 years experience with programmatically transforming data Experience with RDBMS Advanced SQL programming skills Proficient usage of common data formats such as CSV, XML, and JSON Requires strong analytical ability and attention to detail Ability to work independently with little supervision A burning desire to tackle hard problems and create sustainable solutions Desired Skills Experience using Amazon Web Services Experience in or exposure to the nuances of a startup or other entrepreneurial environment Working knowledge with large (multiple terabytes) amounts of data We firmly believe that past performance is the best indicator of future performance. If you thrive in ambiguity, are a self-starter, and care about solving technical problems in the national security domain, we’re eager to hear from you. Govini is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans status or any other characteristic protected by law."
Data Engineer,Apptegy,"Little Rock, AR",https://www.indeed.com/rc/clk?jk=848095db1470c186&fccid=75ccaccd94aea9ec&vjs=3,"About Apptegy Since our start in 2015, we’ve gone from a group of individuals to a community pushing toward the same goal of building a fantastic company with great people, great products, and, most importantly, a great culture. To date, we have grown from a handful of school districts in Arkansas to thousands of school districts across the U.S. Apptegy is building products to empower school leaders to run better schools. We have the opportunity to help schools as they go through a radical shift in how they operate and to provide great technology to make that transition. We are growing quickly and are focused on bringing thoughtful, high-performers together to craft an experience for our clients and to make Apptegy a better place than it already is. A Data Engineer at Apptegy is... someone who will work within our growing team of analytics experts. This person will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. As a Data Engineer, you will… Support our software developers, database architects, data analysts and data scientists on data initiatives, and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Support the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Python technologies. Setup and configure analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. What you should bring to the table: Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with disparate datasets and how to stitch them together. Build processes supporting data transformation, data structures, metadata, dependency and workload management. Working knowledge of message queuing, stream processing, and highly scalable data stores. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. Experience designing and building data warehouses and data marts. We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Experience in the following areas is a plus: Experience with relational SQL databases, such as Postgres, etc. Experience with data pipeline and workflow management tools, such as CloverDX, Informatica, etc. Experience with AWS cloud services, such as EC2, RDS, SQS, Lambda, etc. Experience with one or more of Python, Java, Ruby, etc. Experience with the Salesforce platform What else should I know? We take our responsibility as a company seriously and aim to make this the best job that you’ve had (and one that sets you up for future success). We want your day at work and your time at home to be a joyful experience that’s why we provide: Medical, dental, vision insurance for you and dependents Matching 401(k) retirement plan Discretionary/flexible paid time off policy Parental leaveDependent Care FSA Annual Travel Stipend If the challenge of building a rapidly growing startup excites you as much as it does us, we hope that you’ll consider joining us."
Principal Data Engineer,Noodle,"Remote in Tulsa, OK 74114+14 locations",https://www.indeed.com/rc/clk?jk=fbd71192aeb84429&fccid=2fa3aafd0cd164bc&vjs=3,"Principal Data Engineer Online education is no longer a novel or niche idea. It is the fastest-growing segment in higher education, accounting for 20% of all enrollees and 35% of graduate-level certificates and degrees. It's also getting increasingly competitive, as more and better programs are launched each semester. Universities need to go online quickly, economically, and elegantly, creating programs that students can't wait to tell their friends about and that their professors want to teach. Noodle helps universities bring programs online with flexibility, transparency, alignment, efficiency, and joy. That's why more top universities chose us last year than all other online program managers combined. We are a passionate team of technologists, educators, and experts. Online learning has the potential to transform higher education; if you’re interested in being part of that journey, keep reading! Reports to: Chief Technology Officer (Russ Tarafdar) As our Principal Data Engineer you will: Directly train and manage junior engineers, assisting with day to day duties as needed as well as providing mentorship and career development advice. Define organization-level engineering policies. Develop programs and resources to promote engineering best practices, improve team cohesiveness, and increase the engineering team’s visibility within the company Make key technology decisions and provide implementation and improvement recommendations to team leads and engineers. Independently audit and develop initiatives to address deficiencies in Noodle’s technology products and processes Lead development of core engineering software products Mentor junior engineers, assisting with day to day duties as needed as well as providing technical and career development advice. Work to improve overall software quality by implementing and leading code review, automated testing, continuous integration, and other QA best practices. Assist in high level technology design and project planning. You have: At least 10+ years Python development experience Strong experience with Python data analysis libraries (such as pandas, numpy) Strong relational database and SQL skills Experience with AWS AppSync Experience in agile software development methodologies and best practices At least 4 years experience working with AWS technologies Preferred additional qualifications: Familiarity with Apache Airflow or similar scheduling tools Experience with AWS Appsync Working with various IDP and Okta integration Experience managing infrastructure as code using AWS CDK or similar tools Automated testing and data quality assurance experience At Noodle, we hire people who will help us change the future of online education. Even if you don't think you check off every bullet point on this list, we still encourage you to apply! We value both current experience and future potential. Meet the team! Noodle Benefits: Work from our beautiful NYC office! OR Work from the comfort of your home office! Great compensation package! 401K + match, bonus potential, and equity opportunities Tools you need on us! Mac is our computer of choice Our insurance plan offers medical, dental, vision, short- and long-term disability coverage, plus supplementals for all employees and dependents 12 weeks paid Parental Leave Pre-tax commuter benefits 3 weeks paid vacation + 10 paid holidays + paid sick leave Monthly Gym stipend and Membership to premium medical services like Eden Health Monthly mobile connectivity stipend Access to mental health services like Ginger and Talkspace Annual education stipend for lifelong learning Growth - we pride ourselves on creating environments where employees can be themselves and grow within and around the company Noodle is committed to creating a welcoming and inclusive workplace for everyone. We value and celebrate our differences because those differences are what make our team shine. We hire great people from different backgrounds, not just because it's the right thing to do, but because it makes us stronger as a whole. Women, people of color, LGBTQIA2S+ individuals, and members of other underrepresented groups are strongly encouraged to apply. Noodle is an equal opportunity employer and does not discriminate against candidates on the basis of race, ethnicity, religion, sex, gender, sexual orientation, gender identity, disability status, or veteran status. Noodle won Built In NYC’s 100 Best Places to Work, Best Midsize Companies, and Best Perks & Benefits 2021, and 2022 and was named one of Crain’s 100 best places to work in NYC in 2021. #LI-Remote"
Senior Data Engineer,g2o,"Columbus, OH 43231 (Northern Woods area)",https://www.indeed.com/rc/clk?jk=c01b259952e8b060&fccid=66a65f7fce69d034&vjs=3,"Columbus, OH | Full-Time Your future starts here Imagine being part of a team that helps clients build better relationships with customers. When you join us, you'll help top-notch clients to execute the digital strategies of the future. Every day, we collaborate with clients and each other to provide technology expertise, human-centered design and industry experience to deliver real business results. Position description We’re passionate about designing and delivering top-notch digital experiences for our clients — and their customers — and helping them create efficiencies using data and technology. But what’s most important about us is that we have a diverse team of experts all dedicated to getting clients from goals to outcomes — and that’s where you come in. Required qualifications As a Sr. Data Engineer, you’ll be joining our team of talented experts. The right candidate will: Provide scripting and automation horsepower for projects. Understand problem statements, designing and building solution steps using scripting, to achieve for meta-data extraction, XML and JSON data parsing, data manipulation, comparison, fuzzy matching, deduplication, entity resolution and automation. Possess 3-4 years of experience in Python/PySpark design and development, primarily using Python for meta-data extraction, XML and JSON data parsing, data manipulation, comparison, fuzzy matching, deduplication, entity resolution and automation. Have strong understanding and experience with different Python Packages used for above purpose (for data parsing, manipulation, comparison, dedupe, automation etc, including Pandas, dedupe). Have hands-on experience developing optimized, complex SQL. Possess ETL experience on any Integration tools Informatica, Ab-Initio, Talend, DataStage, Syncsort. Have experience with Big Data/Hadoop platforms like Cloudera, Hortonworks. Have experience working on Data intensive projects (Data Warehouse preferred). Utilize scripting languages such as Shell and Perl and experience with Regex (regular expressions). Exude strong communication skills are a must. Healthcare domain experience is highly desired. Required education and experience University/College degree or equivalent."
Data Engineer,Cincinnati Children's Hospital,"Cincinnati, OH 45219 (CUF area)+1 location",https://www.indeed.com/rc/clk?jk=0d9faed7dd9b008a&fccid=1cf1d6e36473c700&vjs=3,"Description SUBFUNCTION DEFINITION: Focuses on how to design, integrate, and manage complex data and analytic systems over their life cycles. Uses a combination of core software engineering principles and domain specific data and analytic knowledge to ensure the enterprise as seamless access to actionable, meaningful and well-governed data across all domains. CCHMC SALARY GRADE:10 REPRESENTATIVE RESPONSIBILITIES Data Pipelines Build, test and manage simple data pipelines from data sources or endpoints of acquisition to integration to consumption for production for key data and analytics consumers like business/data analysts, data scientists, etc. Comply with data governance and data security requirements while creating, improving and operationalizing data pipelines, following standards set by more senior data and platform engineers. Perform maintenance changes and updates to ETL processes and support upgrade and testing initiatives as necessary Understand bench-marking and process improvement data requirements and develop solutions to address these requests. Metadata Management & Data Modeling Follow team standards for managing metadata to ensure data is used in the right business context and with minimal data duplication. Assist in curation of new data needs, business context association, or sensitivity analysis. Ensure the governance lifecycle for all onboarded data and change workflows as data or business context changes. Update documentation of data models and extract processes. Update support documentation so teams can be cross trained to support users and processes. Modify, test and deploy updates to data models under direction and guidance from senior staff. Work with reporting teams to help them develop best practices approaches to writing and tuning new reporting objects. Technical & Business Skill Foundational knowledge of several Data Management practices and architectures, such as Data Modelling, Data Warehousing, Data Lake, Data Hub, etc. and foundational understanding of the others. Proficiency with SQL, object-oriented/object function scripting and DevOps principles. Develop understanding of core CCHMC clinical, business and research processes to help build appropriate data solutions. Obtain Epic certifications as appropriate/needed. Technical Support & Customer Services Ensure outstanding end-user support is provided, including ongoing monitoring of Service Level Agreements for incident management and collaboration with other areas to ensure customer-centered incident management and support. Adhere to change management policies and procedures. Model outstanding customer service behavior, including timely and effective follow-up with customers. Work with vendors when necessary to ensure CCHMC investments and requests are being adequately supported and enhanced. Escalate support issues with urgency. Take 24 hour call on a staff rotation. Project Execution Execute own project tasks with urgency and to a high level of quality. Communicate status clearly and effectively using departmental project management tools. Follow time-tracking and other project management requirements. Qualifications EDUCATION/EXPERIENCE Required: Bachelor's degree in a computer science, statistics, applied mathematics, data management, information systems, information science or a related quantitative field. No directly related experience Preferred: Unique Skills:"
Associate Data Engineer,C Space,"Boston, MA",https://www.indeed.com/rc/clk?jk=f9b7a1c30d32771b&fccid=0be05c61670bbd88&vjs=3,"Associate Data Engineer - 2022 Boston, MA C Space is looking for an Associate Data Engineer with good working knowledge of SQL Server, Excel, database fundamentals, scripting language to create automation processes, data visualization techniques, and 1-3 years of experience. This is a full-time hybrid position based in our C Space headquarters in Boston, MA. Who You Are You love technology. Self-taught or degree-bearing, you have a passion for data quality and creating automated processes and staying current with industry trends. You have 1-3 years of experience and you’re ready to work towards taking a larger ownership stake in a company’s systems and platforms. You are looking for a role where you’re growing your responsibilities as an engineer and as you grow your career: you want to build efficiencies/integrations, create beautiful dashboards while working with cross-functional teams across the business to join teams together and simplify data. Most importantly, you want to work in a collaborative environment where you can grow without pulling late nights and working weekends. What You’ll Do Your average day at C Space might consist of building automations/dashboards, new integrations, working with cross-functional teams to create efficiencies and simpler, better ways of working with company data. This is a role where your voice and opinion will matter: if you have an idea, we want to hear it – help us improve our processes and how we work with data! About the Business Operations Team Our business operations team is critical to the successful operation of C Space. This team ensures continuity of data from source to display for many business-critical systems. This includes business logic and translation to ensure an excellent user experience. The team also handles special projects providing unique deliverables aligned with important business outcomes. About the Role Act as a partner across the data team to support ongoing data quality and reporting Partner with data scientists and engineers to develop reliable and consistent data products for end-users Take pride in reliability and up-time of data feeds Manage company-wide Business Intelligence reporting (dashboarding, ad-hoc reporting) Develop and maintain data pipelines Identify and implement process improvements across all pipelines Administer databases and/or data management systems that allow for the secure storage, query, protection, and utilization of data Comfortable troubleshooting complex problems Desired Skills and Qualifications 1-3 years of related experience SQL (understand sub-queries, various join types, query efficiency, etc.) Excel (Advanced) Database fundamentals (keys, UID, caching strategies, etc.) PowerShell/Python or equivalent scripting language (think process automation) Data Visualization (Graphing, dashboarding, dynamic filtering, etc.) Tableau/Periscope BI/Looker or equivalent Familiarity with SFTP’s and data transfer processes We are focused on building a diverse and inclusive business and we welcome applications from people from diverse backgrounds, abilities, and walks of life – talented, creative people with their own voice, ideas and perspectives. So if you think you have the right skills and mindset for this position, whether through education, work or life experience, please apply. In 2021, C Space has won awards for Best Career Growth and Best CEOs for Women by Comparably. Comparably Awards are provided yearly to top performing company cultures based on real feedback from our employees. About C Space Our clients call us their customer agency. We create rapid insight and business change, putting customers at the heart of companies and solving problems from the customer’s perspective. We keep our clients relevant by building real, ongoing relationships with customers that in turn help them deliver superior experiences, launch successful products and build loyalty. Our customized approaches are tailored to specific business needs and include online insight communities, immersive storytelling, data and analytics, activation events, innovation projects and business consulting. We do this for many of the world’s best-known brands – like Bose, Walmart, Jaguar Land Rover, Mars, Samsung, IKEA and more – to create “Customer Inspired Growth”. We are passionate about our people and proud of our culture. We co-created a set of values to ensure that we are delivering fantastic work, continuing to learn and developing and building a high-performance culture which creates opportunities for those who work here: I’ve got this: taking the initiative; doing what we say we will Only accept awesome: taking pride in your work; creating value for our clients and company Show the love: being kind to others; taking care of yourself too Do what scares you: challenging ourselves, taking risks and embracing opportunities for personal growth Tell it like it is: caring enough about people and the work to provide meaningful feedback; speaking up when you have a different perspective Open up and listen: embracing feedback from others; working hard to understand different points of view Find what fascinates: being relentlessly curious; having a learning mindset We before me: remembering we succeed or fail as a team Leave your mark: driving results through your work; shaping our culture C Space is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment at C Space without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. C Space is a part of the Brand Consulting Group, a division of Omnicom Group Inc. We are headquartered in Boston, with offices in London, New York and San Francisco. To learn more, visit www.cspace.com or follow us on Twitter @CSpaceGlobal and Instagram @c_spaceglobal."
Data Engineer - SQL Server,Bonterra,"Remote in Washington, DC 20005+1 location",https://www.indeed.com/rc/clk?jk=a1a4a4e9622a83ec&fccid=f506b4bae016196e&vjs=3,"Overview: The EveryAction platform is built by some of the leading experts in the Nonprofit technology space and provides an integrated communication and fundraising platform to nonprofits of all sizes. At EveryAction, we stand behind our progressive values with a commitment to our employees to provide a safe, equitable, and highly effective environment that better reflects the world we want to build. Where we are at: It was recently announced that EveryAction is combining with CyberGrants and Social Solutions to create the second-largest and fastest-growing social good software company in the world. How we’re growing bigger, better, stronger: Our number one goal remains the same as ever: keeping our shared culture of being mission-minded and passionately committed to propel social good. Bringing three like-minded companies together was deliberate – we all provide individual solutions that help social impact; but combined we’re creating a mammoth opportunity to accelerate change. We are actively recruiting across roles in the US and beyond. Currently we are a remote workforce and have equipped our teams with the technology to stay connected to each other and as close to our customers as possible. Responsibilities & Requirements: The Data Engineer will work as a part of a dedicated data warehousing team to design and implement ETLs for both internal and external data sets. They will also be responsible for collaborating with the Data Science team to support their work and assist with data modeling. Responsibilities Design and implement ETL processes in a cloud environment Document datasets for data warehouse consumers Serve as a technical resource for Data Science team Crucial Skills/Experience - A good candidate will have all of these: 3+ years of experience building ETL processes 2+ years of experience with one or more cloud-hosted databases (Azure SQL Hyperscale, Synapse Analytics, Snowflake, Redshift, Databricks), preferably in Azure. Strong understanding of ETL principles and practices Excellent SQL skills Additional Skills/Experience - A great candidate will have several of these Experience with Azure Data Platform technologies Exposure to Azure AD and RBAC Experience utilizing third-party ETL tools (FiveTran, Qlik Replicate, DBT) Experience with Powershell, Python, or other scripting languages Experience managing semi-structured data About Us: Our Culture: Our team is made up of industry experts and advocates who are 100% committed to supporting the doers of social good. We are currently undergoing an effort to create the vision and values that embody our collective organization and embrace the individuals who make up our community. Some of our comprehensive and competitive benefits include: Generous PTO policy Equity for ALL regular, full-time employees from individual contributors to management – share in our success! Up to 15 paid company holidays including some commemorating social justice events and self-care Paid volunteer time Resources for savings and investments Paid parental leave Health, vision, dental, and life insurance with additional access to health and wellness programs. Opportunities to learn, develop, network, and connect When we can—company-sponsored events and swag!! Job Tags: #LI-JV1#LI-Remote"
Sr. Systems Engineer - Data Services (Remote),CrowdStrike,Remote,https://www.indeed.com/rc/clk?jk=316283177adc35b4&fccid=64e4cdd7435d8c42&vjs=3,"#WeAreCrowdStrike and our mission is to stop breaches. As a global leader in cybersecurity, our team changed the game. Since our inception, our market leading cloud-native platform has offered unparalleled protection against the most sophisticated cyberattacks. We’re looking for people with limitless passion, a relentless focus on innovation and a fanatical commitment to the customer to join us in shaping the future of cybersecurity. Consistently recognized as a top workplace, CrowdStrike is committed to cultivating an inclusive, remote-first culture that offers people the autonomy and flexibility to balance the needs of work and life while taking their career to the next level. Interested in working for a company that sets the standard and leads with integrity? Join us on a mission that matters - one team, one fight. About the Role CrowdStrike is looking to hire a Senior Engineer to the Data Services team to help us take our database systems to the next level. We’re looking for a highly-technical, hands-on engineer, who loves to work with data plane services like Cassandra, ElasticSearch, Kafka and Hadoop, and is comfortable building automation around large-scale cloud-based critical systems. We’ll be looking at candidate CVs with an eye on achievement - what you’ve accomplished in the past tells us the most about what you can do for us in the future. Responsibilities Maintain a deep understanding of the data components - including Cassandra, ElasticSearch, Kafka, Zookeeper, Hadoop, and Spark, and use that understanding to operate and automate properly configured clusters. Work with Engineering to roll out new products and features. Develop infrastructure services to support the CrowdStrike engineering team’s pursuit of a full devops model. Work closely with Engineering and Customer Support to troubleshoot time-sensitive production issues, regardless of when they happen. Keep petabytes of critical business data safe, secure, and available. Desired Skills & Experience Experience with large scale datastores using technologies like Cassandra, ElasticSearch, Kafka, Zookeeper, Hadoop, and Spark. Experience with large-scale, business-critical Linux environments Experience operating within the cloud, preferably Amazon Web Services Proven ability to work effectively with both local and remote teams Track record of making great decisions, particularly when it matters most Rock solid communication skills, verbal and written A combination of confidence and independence... with the prudence to know when to ask for help from the rest of the team Experience in the information security industry preferred, but not required Bachelor’s degree in an applicable field, such as CS, CIS or Engineering #LI-SS1 #LI-JF1 #LI-MK1 #LI-MA2 #LI-Remote #HTF Benefits of Working at CrowdStrike: Remote-first culture Market leader in compensation and equity awards Competitive vacation and flexible working arrangements Comprehensive and inclusive health benefits Physical and mental wellness programs Paid parental leave, including adoption A variety of professional development and mentorship opportunities Offices with stocked kitchens when you need to fuel innovation and collaboration We are committed to fostering a culture of belonging where everyone feels seen, heard, valued for who they are and empowered to succeed. Our approach to cultivating a diverse, equitable, and inclusive culture is rooted in listening, learning and collective action. By embracing the diversity of our people, we achieve our best work and fuel innovation - generating the best possible outcomes for our customers and the communities they serve. CrowdStrike is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. CrowdStrike, Inc. is committed to fair and equitable compensation practices. For applicants in Colorado the salary range is $133,770 - $222,950 + bonus + equity + benefits. A candidate’s salary is determined by various factors including, but not limited to, relevant work experience, skills, and certifications. The salary range may differ in other states. CrowdStrike participates in the E-Verify program. Notice of E-Verify Participation Right to Work"
Sr Data Engineer,Lowe's,"Charlotte, NC 28202 (Downtown Charlotte area)+9 locations",https://www.indeed.com/rc/clk?jk=a6d7f763ce0657a0&fccid=402f23c7b01ca527&vjs=3,"Job Summary: The primary purpose of this role is to translate business requirements and functional specifications into logical program designs and to deliver modules, stable application systems, and Data or Platform solutions. This includes developing, configuring, or modifying complex integrated business and/or enterprise infrastructure or application solutions within various computing environments. This role facilitates the implementation and maintenance of complex business and enterprise Data or Platform solutions to ensure successful deployment of released applications. Key Responsibilities: Translates complex cross-functional business requirements and functional specifications into logical program designs, modules, stable application systems, and data solutions; partners with Product Team to understand business needs and functional specifications Collaborates with cross-functional teams to ensure specifications are converted into flexible, scalable, and maintainable solution designs; evaluates project deliverables to ensure they meet specifications and architectural standards Guides development teams in the design and build of complex Data or Platform solutions and ensures that teams are in alignment with the architecture blueprint, standards, target state architecture, and strategies Coordinates, executes, and participates in component integration (CIT) scenarios, systems integration testing (SIT), and user acceptance testing (UAT) to identify application errors and to ensure quality software deployment Participates and coaches others in all software development end-to-end product lifecycle phases by applying and sharing an in-depth understanding of complex company and industry methodologies, policies, standards, and controls Has solid grasp of software design patterns and approaches; understands application level software architecture; makes technical trade-off decisions at application level Automates and simplifies team development, test, and operations processes; develops detailed architecture plans for large scale enterprise architecture projects and drives the plans to fruition Solves complex architecture/design and business problems; solutions are extensible; works to simplify, optimize, remove bottlenecks, etc. Provides mentoring and guidance to more junior level engineers; may provide feedback and direction on specific engineering tasks Executes the development, maintenance, and enhancements of data ingestion solutions of varying complexity levels across various data sources like DBMS, File systems (structured and unstructured), APIs and Streaming on on-prem and cloud infrastructure; demonstrates strong acumen in Data Ingestion toolsets and nurtures and grows junior members in this capability Excels in one or more domains; understands pipelines and business metrics and develops expertise on cloud-based data stacks and pipeline development Builds, tests and enhances data curation pipelines integration data from wide variety of sources like DBMS, File systems, APIs and streaming systems for various KPIs and metrics development with high data quality and integrity Supports the development of feature / inputs for the data models in an Agile manner; Hosts Model Via Rest APIs; ensures non-functional requirements such as logging, authentication, error capturing, and concurrency management are accounted for when model hosting Works with Data Science team to understand mathematical models and algorithms; recommends improvements to analytic methods, techniques, standards, policies and procedures; participates in continuous improvement activities including training opportunities; trains others Works to ensure the manipulation and administration of data and systems are secure and in accordance with enterprise governance by staying compliant with industry best practices, enterprise standards, corporate policy and department procedures; handles the manipulation (extract, load, transform), data visualization, and administration of data and systems securely and in accordance with enterprise data governance standards Maintains the health and monitoring of assigned data engineering capabilities that span analytic functions by triaging maintenance issues; ensures high availability of the platform; monitors workload demands; works with Infrastructure Engineering teams to maintain the data platform; serves as an SME of one or more application Executes the development, maintenance, and enhancements of BI solutions of varying complexity levels across different data sources like DBMS, File systems (structured and unstructured) on-prem and cloud infrastructure; creates level metrics and other complex metrics; use custom groups, consolidations, drilling, and complex filters Excels in one or more domains; understands pipelines and business metrics and develops expertise on cloud-based BI stacks Demonstrates database skill (Teradata/Oracle/Db2/Hadoop) by writing views for business requirements; uses freeform SQLs and pass-through functions; analyzes and finds errors from SQL generation; creates RSD and dashboard Builds, tests and enhances BI solutions from a wide variety of sources like Teradata, Hive, Hbase, Google Big Query and File systems; develops solutions with optimized data performance and data security Works with business analysts to understand requirements and create dashboard/dossiers wireframes; makes use of widgets and Vitara charts to make the da EEO Statement Lowe’s is an equal opportunity employer and administers all personnel practices without regard to race, color, religious creed, sex, gender, age, ancestry, national origin, mental or physical disability or medical condition, sexual orientation, gender identity or expression, marital status, military or veteran status, genetic information, or any other category protected under federal, state, or local law."
Data Engineer,Stitch Fix,+1 locationRemote,https://www.indeed.com/rc/clk?jk=c3421b6846868c8c&fccid=1c70eede37c5caee&vjs=3,"We’re a team of bright, kind individuals who are motivated by challenge and who care deeply about achieving great things. We know our individual strengths, but believe we only win as a team. We’re transforming the way people find what they love - and we need your big ideas. We just might be the perfect fit. ABOUT THE TEAM The data engineering team is a small, nimble group of data engineers that drive the company toward clean and informative data. As a member of the data engineering team, you’ll contribute toward a clear, concise data model to help power data science, ETLs and tools to make us efficient, as well as self-service data and tools to facilitate scalable decision-making. As a team, we are driven by the thrill of helping our colleagues use data with less friction, which ultimately increases the velocity at which the business can progress! ABOUT THE ROLE Individual contributor position on the data engineering team, within our Algorithms organization, working with a team that focuses on our internal business partners You will build and own large additions to our data engineering framework, contributing to a code framework that centralizes ETL logic and definitions You will help to define, build and maintain a clear, concise data model, especially focused on scalable analytics infrastructure You will build scalable data engineering solutions & frameworks to solve business and data problems You will be involved in the day-to-day operations of the team, including maintaining and improving our current tools & scripts and supporting data that powers our business You will have autonomy to help shape the future of data engineering at Stitch Fix by bringing your ideas on improving and automating what we do and how we do it YOU’RE EXCITED ABOUT THIS OPPORTUNITY BECAUSE YOU WILL... You will work with a variety of cross functional partners including product managers, analysts and data scientists to deliver up-to-date metrics to our partners in Merchandise, Styling, CX and Operations. You will focus on our data infrastructure, optimization, and scalability Be part of a fast-growing team which has high visibility across the organization Contribute ideas and direct the team’s investment to impactful directions Contribute to a culture of technical collaboration and scalable development WE GET EXCITED ABOUT CANDIDATES WHO HAVE… 5+ years of independent and significant project experience Experience in building out data models and data engineering capabilities Experience coding and designing extensible and reusable Python and SQL Experience in working autonomously and taking ownership of projects. Ability to think globally, devising and building solutions to meet many needs rather than completing individual projects or tasks Strong prioritization skills with business impact in mind Familiarity with using Spark to access an S3 data warehouse Strong cross functional communication skills that help simplify and move complex problems forward with business partners YOU’LL LOVE WORKING AT STITCH FIX BECAUSE… We are a group of bright, kind and goal oriented people. You can be your authentic self here, and are empowered to encourage others to do the same! We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation We are a technologically and data-driven business We are committed to our clients and connected through our vision of “Transforming the way people find what they love” We love solving problems, thinking creatively and trying new things We believe in autonomy & taking initiative We are challenged, developed and have meaningful impact We take what we do seriously. We don’t take ourselves seriously We have a smart, experienced leadership team that wants to do it right and is open to new ideas We offer competitive compensation packages and comprehensive health benefits You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day ABOUT STITCH FIX At Stitch Fix, we’re about personal styling for everybody, and we believe in both a service and a workplace where you can be your best, most authentic self. We’re the first fashion retailer to combine technology and data science with the human instinct of a Stylist to deliver a deeply personalized shopping experience. This novel juxtaposition attracts a highly diverse group of talented people who are both thinkers and doers. All of this results in a simple, powerful offering to our customers and a successful, growing business serving millions of men, women, and kids. We believe we are only scratching the surface on our opportunity, and we’re looking for incredible people like you to help us carry on that trend. Please review Stitch Fix's Recruiting Privacy Policy here: https://www.stitchfix.com/privacy/usrecruitingprivacy #LI-SG1"
Data Engineer,Chargebee,Remote,https://www.indeed.com/rc/clk?jk=06914f8989b99888&fccid=df08fdaba67fac7c&vjs=3,"Job Summary: Data Engineer works on all kinds of data projects Develops and owns data pipelines/workflows. Manages the integrity and quality of the data by defining and developing data quality metrics, processes and tools Communicate with other teams on the data projects and deliver accurate data with complete ownership. Skills and Experience: 2-5 years of experience in data engineering or data-focused software engineering Enterprise experience in working with data warehousing architecture and data modelling best practices Knowledge in business intelligence and Big Data Management Expert level knowledge in SQL and enterprise experience with Mysql, PostgreSQL, Redshift and advanced performance tuning techniques Proficiency in Python and at least one OO language (Java/scala preferred) Experience with other database platforms, NoSQL, R, data modelling for modern analytics visualization tools, such as Tableau and PowerBI, and cloud data warehouses, such as Amazon Redshift, Google Bigquery and SnowFlake, are all a plus. Strong analytical skills including the ability to define problems, collect data, establish facts, and draw valid conclusions Strong software engineering fundamentals; experience in an Agile/Scrum environment preferred Experience in data and system analysis/troubleshooting Deliver business value in the form of high-quality data and services in adherence with policies on security, performance, longevity and integration testing Years of Experience looking for this position ? 2+ relevant years of experience with SaaS product application related Data Engineering domain Responsibilities Solving the recurring data needs through automation and data visualization. Design and implement highly scalable data pipelines to handle streams, CDC events, and batch processing. Schedule, orchestrate and maintain data pipelines Perform data processing for structured and unstructured data Working on AWS Glue(Or similar ETL tool) to create pipelines to extract and load data to AWS Redshift(Or similar Cloud MPP data warehouse) Identifying/developing optimised data integrations for third-party tools used in Chargebee Staging and Transforming raw data for reporting and analysis Maintaining and enhancing the existing data pipelines/workflows. Data Quality Assurance Must Have SQL, Python, Big Data, Enterprise Data Warehousing, ETL Good to Have Cloud Data Tools, Redshift, Bigquery, AWS Glue, Airflow Chargebee might be the opportunity you’re looking for If you’re interested in how subscription businesses can get more efficient. If you’re hungry to give and receive feedback, fully understanding that challenging perspectives are the only way that you can grow. If you can bring empathy to problem solving. If this sounds interesting but you’re not sure you'll tick all the boxes, apply anyway! There’s tons of room to grow at Chargebee."
Data Engineer,Govini,"Pittsburgh, PA",https://www.indeed.com/rc/clk?jk=3a5c87a0670faa13&fccid=932bcab1f7ee18f8&vjs=3,"Company Description Govini is a decision science firm dedicated to transforming the business of national security through data science and machine learning. Through its National Security Knowledge Graph and Decision Science Platform, Govini delivers objective, decision-grade information at scale to the national security enterprise, so that leaders can better direct investments to innovation and modernization. Govini has offices in Arlington, Virginia, San Francisco, California, and Pittsburgh, Pennsylvania. Job Description We are seeking an exceptional and experienced data engineer who shares our passion and obsession with quality. You'll be a core member of our product and engineering team dedicated to helping our clients replace time-consuming, manual processes to reach informed real-time decisions about government markets, competitors, and agency relationships. We need a skilled and dedicated data nerd to join our team to lead us in uncovering truth and meaning in data. You must be a hands-on engineer with a strong understanding of both data management and governance standards. You must also have strong interpersonal skills to work cross-functionally across internal teams as well as directly with end users and Govini platform SMEs. In order to do this job well, you must be a curious and eager problem solver with a hunger for delivering high-quality data solutions. You have a passion for great work and nothing less than your best will do. You share our intolerance of mediocrity. You’re uber-smart, challenged by figuring things out and producing simple solutions to complex problems. Knowing there are always multiple answers to a problem, you know how to engage in a constructive dialogue to find the best path forward. You’re scrappy. We like scrappy. This is a team member position, working onsite in our Pittsburgh, PA office. Scope of Responsibilities Define and lead Govini's data lifecycle strategy across data acquisition, data ingestion, data cleansing, normalization and linkage. Ensure key entities within datasets are identified, resolved and linked to existing entities within the current master data repository. Apply various techniques to produce solutions to large-scale optimization problems, including data pre-processing, indexing, blocking, field and record comparison and classification. Improve data sharing, increase data repurposing and improve cost efficiency associated with data management efforts. Build best practices that help with chain of custody of data so it can be easily traced back to the source for accuracy and consistency. Work across functional teams to understand advanced statistical, machine learning, and text processing models and incorporate them into Govini’s existing data engineering infrastructure. Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns. Work directly with users as well as SMEs to establish, create and populate optimal data architectures and structures, as well as articulate techniques and results using non-technical language. Requirements Must be able to work in the United States without visa sponsorship now or in the future Required Skills Bachelor's degree in Computer Science, Mathematics or related technical field 3-5 years experience with programmatically transforming data Experience with RDBMS Advanced SQL programming skills Proficient usage of common data formats such as CSV, XML, and JSON Requires strong analytical ability and attention to detail Ability to work independently with little supervision A burning desire to tackle hard problems and create sustainable solutions Desired Skills Experience using Amazon Web Services Experience in or exposure to the nuances of a startup or other entrepreneurial environment Working knowledge with large (multiple terabytes) amounts of data We firmly believe that past performance is the best indicator of future performance. If you thrive in ambiguity, are a self-starter, and care about solving technical problems in the national security domain, we’re eager to hear from you. Govini is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans status or any other characteristic protected by law."
"Staff Engineer, Data",HEB,"Dallas, TX 75220 (Northwest Dallas area)",https://www.indeed.com/rc/clk?jk=8732da0abae746b2&fccid=c629e32155ebd42c&vjs=3,"Overview: H-E-B is one of the largest, independently owned food retailers in the nation operating over 420+ stores throughout Texas and Mexico, with annual sales generating over $34 billion. Described by industry experts as a daring innovator and smart competitor, H-E-B has led the way with creative new concepts, outstanding service and a commitment to diversity in our workforce, workplace and marketplace. H-E-B offers a wealth of career opportunities to our 145,000+ Partners (employees), competitive compensation and benefits program and comprehensive training that lead to successful careers. Responsibilities: Since H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, how they make food decisions, and how they ultimately get food into their homes. This is an exciting time to join H-E-B Digital-we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience. If you enjoy taking on new challenges, working in a rapidly changing environment, learning new skills, and applying it all to solve large and impactful business problems, we want you as part of our team. Our Partners thrive The H-E-B Way. In the Staff Engineer, Data job, that means you have a... HEART FOR PEOPLE... you can serve as technical authority and coordinate work for a group of engineers HEAD FOR BUSINESS... you make sound, mature technical judgments that result in significant impact PASSION FOR RESULTS... you can deliver sweeping technical initiatives with minimal guidance What You'll Do Work with HEB Digital teams to provide data solutions for ecommerce, supply chain, store operations, finance, and marketing reporting and analytics platforms Contribute to existing data platforms and implement new technologies Develop a deep understanding of HEB’s data and become a domain expert Ensure data is distributed in a timely and accurate manner Make data discoverable and accessible to business users Coach and mentor junior engineers in engineering techniques, processes, and new technologies; enable others to succeed Contribute to overall system design, architecture, security, scalability, reliability, and performance of applications Identify, scope, and architect solutions for new features while applying sound technical judgment that considers technology alternatives, impact on affected / adjacent systems, and tradeoffs Get the opportunity to stay ahead of new technologies with an eye to evaluating and potentially incorporating them into your team’s architecture Projects You'll Impact Warehouse Inventory Management System integration - Build out the streaming architecture for ingesting critical product supply data from a cloud application into our enterprise data lake and enabling advanced analytics and machine learning. Warehouse capacity analytics - Build out near-time pipelines that integrate data from our massive warehousing operation and feed decisions about optimal inventory levels, warehouse efficiency, and product allocation. Manufacturing analytics - Build out streaming pipelines to ingest production planning, resource allocation, and machine/IoT data to optimize manufacturing cost, increase production output, and predict production line failures. Vendor scorecard - Build out a near-time analytics solution to help analysts monitor how well our thousands of vendors are complying with their purchase-order integration contracts with us by measuring product accuracy, shipment notification performance, and error rates. Who You Are 7+ years of data engineering experience Proficient with data technologies (e.g. Spark, Kinesis, Kafka, Airflow, Oracle, PostgreSQL, Redshift, Presto, etc.) Experienced with designing and developing ETL data pipelines using tools such as Airflow, Nifi, or Kafka. Strong understanding of SQL and data modeling Understanding of Linux, Amazon Web Services (or other cloud platforms), Python, Docker, and Kubernetes Experienced with common software engineering tools (e.g., Git, JIRA, Confluence, or similar) Bachelor's degree in computer science or comparable field or equivalent experience A proven understanding and application of computer science fundamentals: data structures, algorithms, design patterns, and data modeling Who We Are H-E-B is one of the largest, independently owned food retailers in the nation operating over 420+ stores throughout Texas and Mexico, with annual sales generating over $34 billion. Described by industry experts as a daring innovator and smart competitor, H-E-B has led the way with creative new concepts, outstanding service and a commitment to diversity in our workforce, workplace and marketplace. H-E-B offers a wealth of career opportunities to our 145,000+ Partners (employees), competitive compensation and benefits program and comprehensive training that lead to successful careers. 10-2019 DEVS3232 Our digital team is excited to share our growth in the Dallas area! The open roles for Data Solutions are currently only available in Dallas. Relocation packages are available."
Data Engineer,"VIZIO, Inc.","Denver, CO 80206 (Cherry Creek area)",https://www.indeed.com/rc/clk?jk=3b7ab1d5e1610958&fccid=2ac0dbed95f0e3bf&vjs=3,"About the Team: Vizio is looking for a Data Engineer to join the growing Data Infrastructure team. The successful candidate will assist the Director of Data Infrastructure by implementing the designs and plans for the Data Lake. By implementing the architecture and executing the data performance processes, the Data Lake will continue to evolve to a higher-level data structure that also evolves the security as the lake expands. What You Will Do: Collaborate in the Big Data infrastructure effort Review data infrastructure on a regular cadence for optimizations Work with teams across the Vizio enterprise to bring their data into the Big Data ecosystem. Enable highly performant data operations Keep tools updated and optimized Keep apprised of latest trends and capabilities in big data industry About You: You work well in a collaborative, team-based environment You are recent college graduate with a BS or MS in computer science or data engineering disciplines or an experienced engineering with < 3 years of experience You have a passion for big data structures You possess strong organizational and analytical skills related to working with structured and unstructured data operations You are looking to gain experience implementing and maintaining high performance / high availability data structures You are most comfortable operating within cloud based eco systems You enjoy leading projects and mentoring other team members Technology Stack knowledge: Experience or knowledge with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience or knowledge with AWS cloud services: EC2, MSK, S3, RDS, SNS, SQS Experience or knowledge with stream-processing systems: i.e., Storm, SparkStructured-Streaming, Kafka consumers. Experience or knowledge with object-oriented/object function scripting languages: i.e., Python, Java, Scala, R, SQL. Experience or knowledge with data pipeline and workflow management tools: i.e., AWS Data Pipeline, Apache Airflow, Argo. Experience or knowledge with big data tools: i.e., Hadoop, Spark, Kafka. Experience or knowledge with software engineering tools/practices: i.e., Github, VSCode, CI/CD. About VIZIO: We are Beautifully Simple. Headquartered in Irvine, California, VIZIO is a leading HDTV brand in America and the #1 Sound Bar Brand in America. VIZIO's mission is to deliver high performance, smarter products with the latest innovations at a significant savings that we can pass along to our consumers. Our loyal following and industry-wide praise continues to grow as we redefine what it means to be smart. VIZIO, Inc. is an Equal Opportunity Employer committed to diversity in the workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, protected veteran status, or any other basis protected by applicable law, and will not be discriminated against on the basis of disability. We do not accept unsolicited agency resumes. We will not pay fees to any third-party agency, outside recruiter or firm without a mutually agreed-upon contract and will not be responsible for any agency fees associated with unsolicited resumes. Unsolicited resumes will be considered our property and will be processed accordingly. For Colorado-based employment: The minimum salary for this position is $85,000.00/year. The compensation package includes annual bonus in addition to a range of medical, dental, vision, financial and other benefits."
Associate Data Engineer,Campbell Soup Company,"Camden, NJ 08103 (Gateway area)",https://www.indeed.com/rc/clk?jk=7caf9ee95871d6ce&fccid=76c7d9c9adef7d87&vjs=3,"Imagine...working for a company that knows that its people are the key to its success in the marketplace. A company in which achieving extraordinary results and having a stimulating work experience are part of the same process. We cultivate and embrace a diverse employee population. We recognize that people with diverse backgrounds, experiences and perspectives fuel our growth and enrich our global culture. We are looking for an individual who enjoys working in a fast-paced, team oriented environment, likes to be challenged, and values the opportunity to make a difference. General Summary Works closely with customers and stakeholders in partnership with Solution architect in an Agile manner to design end to end BI solution. This includes data modeling, meta data support, development, testing and implementation. This role also works on hand off to support team. The Associate Data Engineer should be able to assess the impact of any change to the overall architecture and guide the offshore development team. The Associate Data Engineer must be proficient in data management and business intelligence technologies and must be prepared to develop and enforce standards in support of project and continuous improvement initiatives. Primary Responsibilities (25%) - Collaborate with solution architects to understand the overall solution concept in support of a project or continuous improvement effort. Works with customers of Data and Analytics to understand business needs with respect to data and analytics in order to determine optimal solutions. (30%) - Develop high-level and detailed design documents for projects and continuous improvement efforts. Develop data modeling, meta data support, development and testing for enterprise wide data warehouse. (15%) - Participate in code reviews with the development team, ensuring adherence to development standard and overall best practices. Facilitate software change management across development, test, and production landscapes. (20%) - Assist in the completion of projects using project management skills including planning; assigning, monitoring and reviewing progress and accuracy of work; evaluating results, etc. (10%) - Maintain proficiency with the tools in the current and strategic analytical portfolio through both formal and on-the-job training. Work with solution architect to evaluate and recommend new DW and BI tools that further the goals of Data and Analytics team and business overall. Complexity & Scope Independent, working under only general instructions and expected to determine how to accomplish the work assignment, operating with some latitude for un-reviewed action or decision. Responsible for working across global technology platforms and in various business unit and functional area. Responsible for good technical knowledge of back-end and front-end applications. Responsible for understanding business application functionality and architecture of multiple data and analytics applications. Ability to lead development efforts and work with external service providers. Minimum Requirements Education: Bachelor's Degree required. Educational discipline in Computer Science or Information Systems strongly desired. Advanced degree and/or system certification a plus. Length of Experience: Minimum 2 years of Data warehousing experience. Experience with BI tools desired. Certifications: At least 1 of the following certifications: Cloud platform (Azure ADF preferred / or similar) Database modeling (Oracle, MS SQL server, snowflake) SQL certification ETL certification (Informatics preferred) Reporting Tools Power BI desired Python certification Other: Must have strong written and oral communication skills. Must have relational and dimensional database experience, experience with OLAP / MDX queries, experience with both ETL and ELT models, cloud solution architecture and development experience strongly desired CI / CD experience desired, Virtualization experience desired BI tool experience Power BI strongly desired Experience working with external service providers desired Experience using Open source tools for BI / DW development desired Experience working with Agile methodology desired ACR The Company is committed to providing equal opportunity for employees and applicants in all aspects of the employment relationship, without regard to race, color, sex, sexual orientation, gender identity, national origin, citizenship, marital status, veteran status, disability, age, religion or any other classification protected by law. In that regard, U.S. applicants and employees are protected from discrimination based on certain categories protected by Federal law."
Data Engineer,Modak Analytics,"Louisville, KY",https://www.indeed.com/rc/clk?jk=840d0d94452a3e4f&fccid=eaec5b20bb043431&vjs=3,"About Modak Modak is a fast-growing data engineering firm that enables enterprises manage and utilize their data landscape effectively. Modak provides technology, cloud, and vendor agnostic to customer datafication initiatives. Modak uses machine learning (ML) techniques to transform how structured and unstructured data is prepared, consumed, and shared. Modak’s Nabu™ is an enterprise software product and has been covered in Gartner’s “Market Guide to Data preparation 2019.” Job Description We are looking for a Data Engineer for our dynamic team. As part of the role, the selected candidate would be working on extensive data modeling, large scale data migration and working on data lakes and data fabrics. The candidate would be a critical part of the team that builds and automates data migration. We have extensive focus on cloud (MS-Azure, AWS, GCP etc.) and scalable solutions. The Data Engineer will be responsible for expanding and optimizing our data pipeline architecture, as well as optimizing the flow of data. We are looking for someone who enjoys coding and has a genuine interest in engaging with customer projects. Also, at the same time is interested in solving challenging problems, ranging from back-end data processing and machine learning to front end visualization and dashboarding. Mandatory Skills BS or MS degree in Computing/Data/Data Science related field from top universities in US, and a minimum up to 1 year of work experience Understanding of Stream processing with knowledge on Kafka Knowledge of traditional programming and software development methodologies Knowledge or Experience with development languages i.e., Python, Perl, Java, MS.Net etc. Knowledge or Experience in building data pipelines to MS Azure or AWS or GCP Knowledge or Experience with SQL (RDBMS), NoSQL (MongoDB), and PostgreSQL Understanding of Data Flows, Data Architecture, ETL and processing of structured/unstructured data Demonstrated ability to work in a fast paced and changing environment with short deadlines, interruptions, and multiple tasks/projects occurring at once. Preferred Skills: Knowledge or Experience with Cloud (MS Azure / GCP / AWS) infrastructure deployments – application resource management in GCP environment(s). Experience with cloud provider data services. Knowledge with data pipeline applications (Kafka/Spark/Casandra) Have strong Data Science and/or software engineering knowledge or experience. Excellent interpersonal and documentation skills."
Research and Development Engineer - Data Science,Penn State University,"University Park, FL",https://www.indeed.com/rc/clk?jk=3ba32a0510dae06e&fccid=ee32437d8dec00bd&vjs=3,"JOB DESCRIPTION AND POSITION REQUIREMENTS: We are seeking a Research and Development Engineer to join our Visual Analytics Department in the Applied Research Laboratory (ARL) at Penn State University. This position will investigate and evaluate scientific theories and engineering principles, perform full cycle engineering product development, and conduct experiments and tests in collaboration with other data scientists and engineers. You will : Contribute to the design, development, implementation, and analysis of data science, AI, and ML products, systems and subsystems Investigate and evaluate practical applicability of data science and AI/ML techniques in the development and improvement of various engineering systems Apply standard practices and techniques in specific situations, correlate data, recognize discrepancies in results and follow operations through a series of related detailed steps or processes Conduct experiments/tests in the laboratory/field to test, prove or modify theoretical propositions on basis of research findings and experiences of others researching in related technical areas; may include taking measurements and recording observations, collecting, compiling and processing data Initiate or contribute data/analysis/design for use in technical reports, documents, proposals, or oral/written presentations Perform tasks of a larger scope and lead specific tasks within the project scope Collaborate with team members, engineers, and scientists to accomplish organizational goals; provide ideas to improve efficiency at group level; may network beyond own technical peer group This position can be filled as a Level 1 or Level 2 depending on successful candidate's education and experience. Typically requires a Bachelor’s degree in Engineering or a Science discipline for a Level 1. Additional education, experience and/or competencies required for higher level positions. Additional responsibilities of a Level 2 include: Supervise the work of undergraduate students Requirements include: Algorithmic development Strong Math skillset Exposure to Data Science either through coursework, projects or internships Preferred skills include: Programming in Python, R or SQL Machine LearningData visualization ARL at Penn State is an integral part of one of the leading research universities in the nation and serves as a University center of excellence in defense science, systems, and technologies with a focus in naval missions and related areas. You will be subject to a government security investigation, and you must be a U.S. citizen to apply. Employment with the ARL will require successful completion of a pre-employment drug screen. ARL is committed to diversity, equity, and inclusion; we believe this is central to our success as a Department of Defense designated University Affiliated Research Center (UARC). We are at our best when we draw on the talents of all parts of society, and our greatest accomplishments are achieved when diverse perspectives are part of our workforce. FOR FURTHER INFORMATION on ARL, visit our web site at www.arl.psu.edu . CAMPUS SECURITY CRIME STATISTICS: Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act and the Pennsylvania Act of 1988, Penn State publishes a combined Annual Security and Annual Fire Safety Report (ASR). The ASR includes crime statistics and institutional policies concerning campus security, such as those concerning alcohol and drug use, crime prevention, the reporting of crimes, sexual assault, and other matters. The ASR is available for review here . Employment with the University will require successful completion of background check(s) in accordance with University policies. EEO IS THE LAW Penn State is an equal opportunity, affirmative action employer, and is committed to providing employment opportunities to all qualified applications without regards to race, color, religion, age, sex, sexual orientation, gender identify, national origin, disability or protected veteran status. If you are unable to use our online application process due to an impairment or disability, please contact 814-865-1473. Penn State Covid-19 Vaccination or Testing Requirements Penn State is committed to the health of our local and global communities. As a condition of employment, all employees are required to comply with COVID-19 vaccination or testing requirements. Click on Penn State Covid-19 Vaccination or Testing Requirements to learn about the requirements as well as general COVID-19 information at Penn State."
Data Engineer - Customer Product Usage,Harley-Davidson,"Yucca, AZ",https://www.indeed.com/rc/clk?jk=80665830bf626564&fccid=d606abf5c6b70531&vjs=3,"Auto req ID: 16462 Title: Data Engineer - Customer Product Usage Job Function: Engineering Location: APG Company: Harley-Davidson Motor Company Full or Part-Time: Full Time Shift: SHIFT1 At Harley-Davidson, we are building more than machines. It’s our passion and commitment to continue the evolution of this storied brand, and heighten the desirability of the Harley-Davidson experience. To keep building our legend and leading our industry through innovation, evolution, and emotion we need the best and brightest talent. We stand for the timeless pursuit of adventure. Freedom for the soul. Are you ready to join us? Our Arizona Proving Ground (APG) location is home to all product testing. Test miles are supported by Test Riders, Mechanics, Engineers, Coordinators, Technical Specialists and Administrative personnel. APG provides motorcycle testing services related to motorcycle development, performance, validation and certification. Job Summary We are currently looking for a Data Engineer to specialize in Customer Product Usage for the Arizona Proving Ground. This position reports to the Durability Lab Lead at the Arizona Proving Ground (APG), Yucca, AZ and is an integral part of the Product Development team at Harley-Davidson. The Data Engineer – Customer Product Usage will be responsible for leveraging industry-leading statistical and data acquisition methods to understand product requirements for new markets, and motorcycle segments by: Working with instrumentation experts and key stakeholders to prioritize and obtain new customer usage data requests and to determine best approach (i.e. additional vehicle data acquisition, existing data, surveys etc.) Providing reliability analysis of raw data to convert into useful engineering requirements and information to support CAE and Component Testing Developing a Sharepoint site to make existing customer usage data and information relevant and easily accessible Determining 3rd party sources for environmental data and linking to the Sharepoint site Recommending priorities and strategy for expanding capabilities and throughput of this Customer Correlation function Supporting both EV and ICE vehicle requests Job Responsibilities Consideration of representative customer product expectations operations and conditions Selection of representative vehicle types to cover the variety of product lineup Selection of suitable evaluation factors (e.g., measurement channels) for loads Instrumentation of vehicles to collect, organize and analyze data Documentation of influencing parameters varying conditions (e.g., customer expectations, market conditions etc.) Categorization and distribution of field measurements (e.g., input loads acting on various components of the motorcycle: wheels, front suspension, rear suspension, frame, stressed members) Generation of test duty cycles based on statistical analyses of collected data Leverage of statistical analysis methods (e.g., parametric distribution estimation, Monte-Carlo) for the simulation of customer load cases and computation of field to test events correlations Map Proving Ground test events scenarios to the derived customer loading profiles Determine acceleration factors for test mileages with an equivalent damage ratio compared to the customer normal usage over determined product life Deliver test and lab goals while demonstrating Fairness and Honesty in all interactions with a Positive attitude and while finding Creative solutions in their work. Education Specifications This position requires a bachelor's degree in Mechanical Engineering, Statistics, or related advanced technical degree. Experience Requirements Typically requires a minimum of 3 years of related experience, in test and/or engineering environment. In addition, the successful candidate will have demonstrated the following: Demonstrated Statistical Analysis and applied methodologies expertise Design of experiments Recorded data management and analysis methods, software scripts, limitations, and their appropriate usage Analysis of test data in both time and frequency domain. Develop basic testing strategies for motorcycle systems and/or components as needed. Demonstrated ability to work effectively within a group and/or team Provide guidance to new team members such as engineers, technical specialists, mechanics, and riders. Understanding of fatigue concepts from undergraduate college courses or seminars. Can perform simple fatigue calculations based on stress-life or strain-life material curves and simple cyclic loading. Has a demonstrated practical and conceptual understanding of the overall functioning systems in a motorcycle (Battery Electric and/or Internal Combustion variants) through acquired experience as a rider, through formal training methods. Has demonstrable practical experience in understanding, creating, and troubleshooting software scripts to monitor automotive electrical systems (including CAN protocols). Beneficial to have experience in Data acquisition systems and techniques Harley-Davidson is an equal opportunity employer that continues to build a culture of inclusion, belonging and equity through our commitment to attracting and retaining diverse talent from all backgrounds, without regard to race, color, religion, sex, sexual orientation, national origin, gender identity, age, disability, veteran status or any other characteristic protected by law. We believe in fairness and providing a level playing field for all. We foster a culture that thrives on diverse perspectives and contributions to ignite the creativity and innovation to fuel our business and enhance the employee and customer experience. We offer an inclusive compensation package for all full-time salaried employees including, but not limited to, annual bonus programs, health insurance benefits, a 401k program, onsite fitness centers and employee stores, employee discounts on products and accessories, and more. Learn more about Harley-Davidson here. Applicants must be currently authorized to work in the United States. Direct Reports: No Travel Required: 10 - 25% COVID-19 Vaccine Required: No Visa Sponsorship: This position is not eligible for visa sponsorship Relocation: This position is not eligible for relocation assistance"
Data Engineer,Brookhaven National Laboratory,"Upton, NY 11973",https://www.indeed.com/rc/clk?jk=98b1ffa363423521&fccid=e3775e5ec8ee0d6e&vjs=3,"Brookhaven National Laboratory (www.bnl.gov) delivers discovery science and transformative technology to power and secure the nation’s future. Brookhaven Lab is a multidisciplinary laboratory with seven Nobel Prize-winning discoveries, 37 R&D 100 Awards, and more than 70 years of pioneering research. The Lab is primarily supported by the U.S. Department of Energy’s (DOE) Office of Science. Brookhaven Science Associates (BSA) operates and manages the Laboratory for DOE. BSA is a partnership between Battelle and The Research Foundation for the State University of New York on behalf of Stony Brook University. Organizational Overview Brookhaven National Laboratory is entering an exciting new chapter with one of the newest and most advanced synchrotron facilities in the world. National Synchrotron Light Source II (NSLS-II) enables the study of material properties and functions with nanoscale resolution and exquisite sensitivity by providing world-leading capabilities for X-ray imaging and high-resolution energy analysis. This facility is open to users from academia and industry and its operations are at a time when the world enters a new era with a global economy fueled largely by scientific discoveries and technological innovations. NSLS-II provides the research tools needed to foster new discoveries and create breakthroughs in critical areas such as energy security, environment, and human health. Position Description NSLS-II is seeking an exceptional candidate to contribute to a multi-disciplinary project where they will build a Data repository working with BNL, participating universities and other partners to design, develop, and implement a data repository solution to facilitate data sharing and enhance coordination across the center. The candidate will work closely with the C2QA Center’s Cross-cutting co-design team, Thrust Leaders and NIST partners to coordinate project milestones and deliverables. You will be based at BNL and part of National Synchrotron Light Source II's Data Science and Systems Integration (DSSI) Program, which provide supports and expertise to meet the scientific computing needs of the NSLS-II Essential Duties and Responsibilities: Spearhead a focused effort to develop a user-friendly data management tool/database which will be used by center members to support data sharing, coordination and collaboration Collaborate with the Center’s scientists to identify and implement strategies for data handling, sharing, management and analysis Provide documentation, training and support for the database and software solutions developed. Collaborate with NIST partners to develop the public facing interface for the data repository Develop protocols and tools for data validation and publication Position Requirements Bachelor's or higher level degree in Computer Science, Physical Sciences, Applied Mathematics or related field and a minimum of one (1) years of relevant experience Demonstrated experience of data and code management best practices Ability to implement agile software engineering methodologies Experience in collaborative development of software and cloud infrastructure, especially in distributed teams. Demonstrated experience in multiple programming languages, including Python and script Excellent communication skills Preferred Knowledge, Skills and Abilities (experience in one or more of the following): Software design, development and deployment with version control Working with NoSQL and/or Relational databases Use of infrastructure systems (storage, networked accessible systems, collaborative tools) Containerized development and deployment (e.g. AWS, Docker) Design and use of standard APIs Developing training resources, including documentation, manuals, and tutorials of software tools for users. Providing user support (i.e. center members) Experience with Linux operating systems. Other information: Candidate will be placed at appropriate level contingent upon depth and breadth of experience. At Brookhaven National Laboratory we believe that a comprehensive employee benefits program is an important and meaningful part of the compensation employees receive. Our benefits program includes, but is not limited to: Medical, Dental, and Vision Care Plans Flexible Spending Accounts Paid Time-off and Leave Programs (vacation, holidays, sick leave, paid parental leave) 401(k) Plan Flexible Work Arrangements Tuition Assistance, Training and Professional Development Programs Employee Fitness/Wellness & Recreation: Gym/Basketball Courts, Weight Room, Fitness Classes, Indoor Pool, Tennis Courts, Sports Clubs/Activities (Basketball, Ping Pong, Softball, Tennis). Brookhaven National Laboratory and the Energy and Photon Sciences Directorate are committed to your success. We offer a supportive work environment and the resources necessary for you to succeed. Brookhaven Science Associates requires proof of a COVID-19 vaccination for all employees. Proof of full vaccination as recognized by the CDC and/or WHO, inclusive of the two-week waiting period, is required at the start of your employment. Brookhaven National Laboratory (BNL) is an equal opportunity employer that values inclusion and diversity at our Lab. We are committed to ensuring that all qualified applicants receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, status as a veteran, disability or any other federal, state or local protected class. BNL takes affirmative action in support of its policy and to advance in employment individuals who are minorities, women, protected veterans, and individuals with disabilities. We ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. VEVRAA Federal Contractor"
Senior Data Engineer (Europe),PEX,Remote,https://www.indeed.com/rc/clk?jk=b50ff1059e618609&fccid=0e6d6f415d0f96c3&vjs=3,"Here at Pex, we're on a mission to democratize digital rights for everyone. We are the team behind the Attribution Engine, a licensing infrastructure for the Internet enabling fair compensation and increased access to content. With its advanced identification technology, Attribution Engine ensures compliance and safety for platforms, gives rightsholders total control of their content, increases access and confidence for creators, helps law enforcement prevent toxic content, and provides brand safety for advertisers. As a Senior Data Engineer, you will play a key role as part of Pex’s Data Team that you will help build and develop. We are looking for a seasoned data engineer who’s eager to bring our data architecture to life and build and evolve solid data pipelines that will support Pex’s data needs and their stakeholders. Our scale is massive, so scalability and maintainability must always be top of mind. The Team Our engineering organization is made up of fully distributed and cross-functional teams that have talented engineers from various backgrounds and skill levels. The Analytics Team currently includes a Staff Data Architect, a Senior Data Engineer, two Senior Backend Engineers and a Site Reliability Engineer. At Pex, we value transparency and clear communication, and we strive to create an environment where all team members feel safe and supported to take initiative, experiment, learn from mistakes, and share opinions freely. The Role We’re looking for an accomplished and pragmatic data engineer who will work on the implementation of our data vision across the organization. As a Senior Data Engineer, you will: Be a trusted go-to person for everything data-related at Pex Support Pex in its data-driven business approach by developing and evolving the data platform Promote data best practices within the team and beyond Development, maintenance and evolution of Pex’s data environment Pex’s Unified Analytics Architecture Pex aspires to become a data-driven company. Our data architecture follows a unified analytics approach where we are leveraging a single modern cloud-native data platform to enable all types of workloads (batch/stream), all types of consumer profiles (BI & Reporting / ML & AI), and all types of data (structured, semi-structured and unstructured). To this end, we have chosen Snowflake as our cloud data platform implementing a Data Lakehouse architecture pattern. Our technology stack includes dbt+Airflow for data transformation, and for our ingestion layer we use Debezium for CDC-based extract and load operations and Apache Pulsar as our message queue. Currently, we offer BI functionality embedded into our core product, Attribution Engine, but we are also looking into modern BI platforms to include into our technology stack. About You We have a lot of people who did not follow the traditional career path. We value people who are curious and collaborative and bring their unique perspectives to work each day. While we’re excited to learn what you can bring to the team, there are a few key things you’ll need that are essential to success in this role: Deep understanding of large scale data architectures Deep understanding of data warehousing concepts, data update strategies, data modeling, data pipelines, and workflows Experience in building production-level data pipelines for analytic purposes with the use of ETL/ELT tools and/or SQL Proven experience with data management over large volumes of data (10s to 100s of TB of data) stored in heterogeneous data sources Understanding of Business Intelligence tools (Looker, Power BI, Tableau, Qlik or similar) and concepts plus experience with delivering analytical applications to customers A modest attitude which is a key for good collaboration Outstanding communication skills in English (both spoken and written) Perks and Benefits Salary: $115,200 - $122,400/year Equity, with perks like a 10-year exercise window 30 days of paid time off + 9 paid holidays + the day off on your birthday Generous paid parental leave A fully remote working environment and supportive culture that cares about both excellent work and work-life balance Pex is an equal opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status or disability status. Since Pex is committed to the full inclusion of all qualified individuals, we strive to ensure that people with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, please let us know when applying for a particular role in the “Additional Information” section."
Data Engineer,MIT,"Cambridge, MA 02139 (MIT area)",https://www.indeed.com/rc/clk?jk=99536e77cfc3eb9c&fccid=71cf745ec1b3aae4&vjs=3,"Information on MIT’s COVID-19 vaccination requirement can be found at the bottom of this posting. TECHNICAL ASSOCIATE I, Sloan School of Management-Food Supply Chain Analytics and Sensing (FSAS) Initiative, to support the FSAS on a project that aims to understand and manage the risk associated with intentional adulteration of food supply chains (i.e., poultry,beef, pork, milk, seafood, and produce), with a focus on economically motivated adulteration (EMA). Will be responsible for the development and deployment of data products (e.g., models, pipelines), helping to stand up a robust data pipeline, conducting quality control checks, maintaining a data lake to support research and data products, conducting and writing up research, and performing other duties as needed. Job Requirements REQUIRED: bachelor’s degree in a relevant scientific field (computer science, engineering, mathematics); two years’ relevant experience; familiarity with Python, SQL, and Github; ability to work both independently and as a member of a team; attention to detail; and familiaritywith basic statistical techniques (e.g., hypothesis testing, simple linear models). PREFERRED: experience working with databases (MSSQL), Docker, Selenium, and machine learning (TensorFlow); an interest in food safety and security issues; and advanced-levl Chinese language skills. Job #20350"
Data Engineer,"Reach Platform, Inc.","Remote in Boston, MA",https://www.indeed.com/rc/clk?jk=3b1ef58c5c8bb113&fccid=dd616958bd9ddc12&vjs=3,"We are looking for an experienced Data Engineer to join our rapidly scaling team. The ideal candidate will use various methods to transform raw data into useful data systems. Overall, the Data Engineer will strive for efficiency by aligning data systems with business goals and needs to build a data-driven culture and foundation for a scaling company. To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources. Data engineer skills also include familiarity with several programming languages and knowledge of learning machine methods. The ideal candidate will be passionate about helping to create the data infrastructure for a rapidly scaling Web3 company! Responsibilities: Maintaining, optimizing, and automating data delivery and extraction from multiple data sources Analyze and organize raw data Build data systems and pipelines: building and maintaining data systems, ensuring data quality and efficiency, and constructing datasets that are easy to analyze for business users across the company Evaluate business needs and objectives to create the right solutions Conduct complex data analysis and report on results Prepare data for prescriptive and predictive modeling Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality and reliability Identify opportunities for data acquisition Develop analytical tools and programs Collaborate with data scientists and architects on several projects Collaborate with and across the engineering team to design, develop, test, and support technical solution on Tableau Understand reporting database schema/model, identify joins/tables, and perform data analysis Uses SQL programming code to develop required reports Requirements Minimum four (4) years of experience in Data Engineering Minimum two (2) years of hands-on experience designing and architecting reporting dashboards using an advanced reporting tool such as Tableau Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming languages (e.g. Java and Python) Hands-on experience with SQL database design Great numerical and analytical skills Data engineering certification (e.g IBM Certified Data Engineer) is a plus Strong understanding of data warehousing concepts, relational data models and the data flow process end-to-end from ingestion to consumption Advanced programming skills in Python and/or SQL (and their related data science, machine learning, and visualization libraries Strong verbal and written business communication skills Ability to be nimble in a startup culture and have the ability to thrive quickly. Our Commitment to You Reach is committed to a diverse and inclusive workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Our Perks Employee stock-options Competitive salary Flexible work schedule Unlimited PTO Health and dental insurance"
Data Analytics Engineer,Scientific American,"New York, NY 10017 (Midtown area)",https://www.indeed.com/rc/clk?jk=26ac8e794bb1e921&fccid=d22d3aaf5cb69f00&vjs=3,"Scientific American, the longest continuously published magazine in the U.S., has been bringing its readers unique insights about developments in science and technology since 1845. Scientific American has 3.5 million print and tablet readers worldwide, more than 7.5 million visitors on ScientificAmerican.com, and appears in 13 translated editions, which are read in more than 30 countries. .sfpanel .content {padding: 0 40px !important;} Springer Nature is seeking a Data Analytics Engineer for its New York based Scientific American Team. The team develops new data products for the research community. This is an exciting opportunity for the Data Analytics Engineer, expanding from strong foundations to build new solutions and services. We are looking for someone who is able to deliver solutions and work independently, with support from the wider team where necessary. As a Data Analytics Engineer, you will be responsible for ensuring continuous flow of data with minimum latency between data sources. You will be developing, testing and deploying data pipelines into the production environment. You’ll be responsible for implementation of Google Analytics 4 server side tracking, following the existing solution that will be provided. You’ll be analyzing big data from very highly trafficked websites and content. You will provide actionable analysis and insight into the behavior of users. Driving change that improves their experience with SpingerNature and our customers, contributing to our purpose to advance discovery with some of the most interesting datasets available. You’ll be working in close partnership with data analysts, scientists and engineers and researchers from Springer Nature. You’ll be working with the latest data and analytics technologies including graph databases, Google Analytics, Google Tag Manager, BigQuery, Looker and Plotly Dash as well as previewing solutions from Google and other partners. Role responsibilities will include: Build streaming/batch Data pipelines for extraction/loading/transforming data between various data sources at scale in different formats. Work closely with Data Scientists /Analysts to understand the requirements and develop the data solutions in line with the business requirements. Maintain the current cloud infrastructure and help onboard the new applications. Developing sophisticated segmentation, analysis and dashboards that support Springer Nature and its customers to advance discovery. Implementing cutting edge analytics and data science solutions in partnership with the wider teams Consulting with stakeholders throughout the business to shape and implement solutions in support of business objectives. Play a key role in shaping solutions, creating the right governance and safety checks to maintain tracking accuracy. Role requirements: BA degree with a strong analytical/quantitative background Minimum of 3 - 4 years experience in the field or equivalent experience (e.g. Data Science, Statistics, Mathematics, Econometrics, Physics, Computer Science etc.) Strong working knowledge of SQL, Google Analytics, Google Tag Manager and Python Excellent problem solving capabilities Knowledge of Machine Learning concepts is beneficial but not essential as training will be provided Prior experience with schema designing data modeling Familiarity with Google Cloud products (BigQuery, Colab, Data Studio, Looker, Dataform, Google Analytics) or other cloud data platforms is beneficial but not essential Well organized and accurate with good time management If you are an internal candidate please inform your line manager. We offer a comprehensive benefits package that includes: Medical, Dental and Vision Life and AD&D 401(k) Flexible Spending Accounts Transit Accounts Tuition Assistance Summer Hours Springer Nature is an Equal Opportunity Employer that complies with the laws and regulations set forth in the following “Equal Employment Opportunity Is The Law” poster: http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf. For information about our Research Editorial and Publishing career opportunities please visit the new Springer Nature E&P website at www.springernature.com/editorial-and-publishing-jobs. Springer Nature is a leading global research, educational and professional publisher, home to an array of respected and trusted brands providing quality content through a range of innovative products and services. Springer Nature is the world’s largest academic book publisher, publisher of the world’s highest impact journals and a pioneer in the field of open research. The company numbers almost 13,000 staff in over 50 countries and has a turnover of approximately EUR 1.5 billion. Springer Nature was formed in 2015 through the merger of Nature Publishing Group, Palgrave Macmillan, Macmillan Education and Springer Science+Business Media. At Springer Nature we value the diversity of our teams. We recognize the many benefits of a diverse workforce with equitable opportunities for everyone. We strive for an inclusive workplace that empowers all our colleagues to thrive. Our search for the best talent fully encompasses and embraces these values and principles."
Data Engineer,Tyler Technologies,"Olathe, KS 66061+3 locations",https://www.indeed.com/rc/clk?jk=a6431bcd38e40164&fccid=35fa439a19059a40&vjs=3,"The Mid-Level Data Engineer is responsible for analyzing data problems, designing and developing data pipeline and model solutions, and implementing those solutions. The data engineer will work closely with the data science team and product teams to analyze business problems and recommend solutions. The data engineer should have a background in development and data design and the know-how to move data between systems through automation. To develop the solutions, the data engineer will need to adhere to data best practices, including data security and data quality. The Data Engineer will be a member of the enterprise architecture team. Requirements Must have programming experience examples (Python, Julia, etc.) Development Experience in data pipelines AWS Glue, AWS DMS, Python, or other ETL Strong SQL Experience Data Analysis of relational and non-relational databases Development of Dimensional Data Models Computer Science, Computer Engineering, or similar BS degree or work experience equivalent. Knowledge of Data Warehousing best practices, including Data Cataloging, Data Security, and Data Quality Five years relevant experience Desired (not required) Skills Cloud and AWS Experience Experience with Data Visualization / D3 Experience with Enterprise Service Bus"
Senior Data Engineer,Validere Technologies,+1 locationRemote,https://www.indeed.com/rc/clk?jk=aaf46c090078907f&fccid=e967e2adf60716db&vjs=3,"Who we are: Validere is the leading all-in-one commodity management platform for the energy industry. We believe the future of energy requires a modernized supply chain, so we’re reducing the barriers to actionable insights to make the energy landscape better for everyone. Through people and technology, we bring clarity to commercial, operational, and environmental challenges, provide ways to act on the learnings and facilitate predictions for the future state. Founded at Harvard University, Validere has since raised $70M+ from leading technology and energy investors, including Mercuria Energy America, BlackRock, Wing VC, Greylock Partners, and Y Combinator. With offices in Houston, Calgary, and Toronto, our 100+ employees focus every day on delivering the highest value, removing friction, and scaling results for every one of our customers. Who you are: To support our rapid growth, we are looking for a Senior Data Engineer with a passion for solving complex problems related to data infrastructures for large scale and fast-growing datasets, including data ingestion, data consumption, processing and automation. Above all, we’re looking for someone who is driven and excited about the positive impact technology can have on business. This is a remote first opportunity and we looking for candidates anywhere in Canada/USA. Let’s give you a purpose: Design and implement the data infrastructure platforms including the data ingestion, data consumption and stream processing on AWS Write code to automate ingestion and transformation of data from different sources (from conception to production) Design, build, and own highly resilient data processing jobs Build systems that represent real-world intricacies of physical commodities Collaborate with Services team to identify and map different data sources Participate in code reviews to push for high quality and coding standards Support the development and maintenance of data engineering guidelines, policies, standards and process narratives Mentor and guide other data engineers in the team Our tech stack: Platform: Python, AWS (Airflow, Lambda, EKS, etc), Postgres, Redis, Docker, GraphQL, Terraform, Prometheus What you'll bring along: Bachelor’s degree in Software Engineering, Computer Science or extensive practical experience with software development 5+ years of professional experience, preferably in a fast-paced environment such as a startup or rapidly growing company Strong foundation in algorithms and data structures Proficiency in Python (numpy, scipy, panda) and SQL Comfortable working in Linux and writing shell scripts Strong sense of ownership and accountability Nice to have Experience with CI/CD pipelines Experience with Docker We love it here, you will too: Competitive compensation Comprehensive health benefits Stock options (at Validere, we're all owners) RRSP/401(k) matching programs Flexible working arrangements Professional development budget to master your craft Generous time-off with parental/family leave Quarterly Employee Wellbeing Days and No Meeting Friday Afternoons An inclusive, ego-free environment where diversity of people and thought is valued Opportunity to impact the trajectory of a fast growing tech company Our shared values: Deliver (the highest) value Remove friction Everyday is more scalable Be well, fair & transparent Validere is an equal employment opportunity employer. We welcome and encourage applications from everyone regardless of race, colour, religion, gender, sexual orientation, age, or disability status. Accommodations are available on request for candidates taking part in all aspects of the interview process and beyond. We are committed to providing an inclusive, open, and diverse work environment."
Data Engineer,Tricolor Auto Group,"Dallas, TX",https://www.indeed.com/rc/clk?jk=bdbaeb0e009f2059&fccid=0c6a206362227e72&vjs=3,"Job ID: T3032022 PRODUCT US-TX-DALLAS 6021 CONNECTION DRIVE, FLOOR 4 IRVING Job description Who we are? Tricolor Holdings is an integrated retail and financial services company providing vehicle sales and financing to the Hispanic community in Texas, California, New Mexico, Arizona and Nevada. The Company is focused on providing the best customer experience across our retail and financing operations through mission-driven fulfillment of our desire to improve the lives of our customers and our employees. The Role As a Data engineer, you will be an integral part of the Product and Engineering team and a key player in ensuring Tricolor has an efficient data platform and access to data from every system in the ecosystem. Data is the backbone of Tricolor, and this role will be responsible for ensuring everyone at the company has access to that data in a seamless fashion. You will also work very closely with Data Analytics and Data Science team in architecting the data model and platform across the whole company. Our Offer Take Care of Yourself – We offer different health, visual and dental insurance options, you can select a plan that best suits your lifestyle and your family needs. Plus, you will be eligible on the 1st day of the month after only 30 days of employment! We Care for You – Tricolor pays for employees’ life insurance policy, that also covers accidents. Keep Learning – Learn @ Tricolor provides learning opportunities for employees that will enhance professional and personal development skills, offering monthly classes on a variety of topics that employees can attend voluntarily, at the office or virtually. Keep Growing – Tricolor is committed to considering employees for new career opportunities and professional advancement, we take pride on having a culture of promotion. Plan for the Future – You are eligible for our 401K plan, and we will match 100% of what you contribute up to 4%. Child Care – With KinderCare you can choose from more than 1,400 centers nationwide and get 10% off tuition with your employee benefit. Employee Discount Program – As a Tricolor family member you will have access to discounts on Travel, Cars, Hotel, Groceries, Electronics, Theme Parks and even a special down payment price to buy a car with Tricolor Auto! What will you be doing at Tricolor? The Data Engineer role is a blend of data management, platform support and advanced analytics Extracting, Loading, Transforming, cleaning, and validating data using cloud ETL/ELT tools Designing data engineering pipelines and architectures for data processing Data modeling and schema design that will range across multiple business domains within the cloud for large enterprise data warehouse and data lakes solutions Design and develop platform standards, common reference architecture and data governance policies, perform vendor/tool comparisons and present recommendations Design, develop and validate enterprise reporting, queries, extracts, visualizations, graphs, and data mapping for delivery to clients or internal stakeholders Responsible for leading network data engineering from data sourcing, ingestion, and exposing the data for AI/ML model development, curation, and data production Partner with internal business partners in gathering business requirements and developing data engineering pipelines This is the right opportunity for you, if you have… BS in Computer Science or equivalent degree 5+ years of experience with creating and fine tuning ETL processes 3+ years of experience utilizing Snowflake for Data warehousing 3+ years of experience with Python scripting 3+ years working with SQL Server and Stored Procedures 2+ experience with Matillion / Talend or similar ETL tool Strong analytic skills related to working with semi-structured datasets Experience with consuming data from APIs Experience using source control Apply today and join Tricolor on our expansion adventure! If this is the right job for you, our Recruiting Team will be contacting you for a first phone interview during the next days. Then, you will meet with the hiring manager to discuss the role and meet the team and the office! Lastly, you will complete a pre-employment background check and drug test. And we will be ready to get you onboard! We are looking forward to receiving your application!"
Data Science Engineer,One Model,"Austin, TX",https://www.indeed.com/rc/clk?jk=064a1a6b9f56d6f5&fccid=74f25238bffb518e&vjs=3,"One Model, the leading workforce analytics data management platform, is seeking an enthusiastic Data Science Engineer to join our growing team. The ideal candidate will develop, maintain, test and evaluate big data solutions, and possess a high level of confidence and comfortability in wrestling with problems associated with database integration and messy, unstructured data sets. This position will report to the CEO. Location Austin, Texas Responsibilities Bachelor’s or Master’s Degree specializing in a relevant field such as Probability, Statistics, Machine Learning, Data Mining, Artificial Intelligence, Computer Science, or Operations Research. 3 to 5 years of relevant experience. Preferred Qualifications Hands-on proficiency with languages such as Scala/R/Python. Proficiency in writing SQL. Experience/Interest diving into analytics Experience working on AWS Cloud computing technology (RedShift, EC2, EMR, Spark). Experience with Big Data Technologies like Apache Hadoop, Apache Spark, and MapReduce. Why You’re Going to Love Working with One Model (aka, Benefits) Healthcare Reimbursement Program - Healthy employees are happy employees. Get reimbursed for medical, dental, vision, and/or other qualified healthcare-related expenses. Unlimited PTO - Relax and recharge with One Model’s generous vacation policy. Profit Sharing - When One Model wins, the whole team wins. Enjoy monthly bonuses that reflect the company’s successes. Supportive Team - Join a team that wants to see you succeed! We’ll give you help when you need it, and autonomy to kill it on your own when you don’t. Awesome Company - Join a team that’s passionate about what we do, work with customers who LOVE the product, and join an industry that’s excited about One Model’s solution! About One Model One Model provides a comprehensive suite of people analytics directly from various HR technology platforms to measure all aspects of the employee lifecycle. Use its out-of-the-box integrations, metrics, analytics, and dashboards, or create your own. One Model’s newest tool, One AI, integrates cutting-edge machine learning capabilities into its current platform, equipping HR professionals with readily-accessible, unparalleled insights from their people analytics data."
"Data Engineer, Data to Insights Initiative (D2I)",University of Texas at Austin,"Austin, TX 78701 (Downtown area)",https://www.indeed.com/rc/clk?jk=e4883d930d034924&fccid=f7282ad3490137c7&vjs=3,"Job Posting Title: Data Engineer, Data to Insights Initiative (D2I) - Hiring Department: IQ - Information Quest - Position Open To: All Applicants - Weekly Scheduled Hours: 40 - FLSA Status: Exempt - Earliest Start Date: Immediately - Position Duration: Expected to Continue Until Dec 31, 2025 - Location: Texas - Job Details: General Notes The Data to Insights (D2I) Initiative at UT Austin is an investment to build a trusted, integrated, and scalable information infrastructure that transforms complex UT data into valued insights for data-informed decisions. As part of D2I’s leadership group, you will work with a cross-campus team using the latest cloud technologies to build a next-generation data ecosystem via the UT Data Hub. The Associate Director for Legacy Data Services will skillfully plan and oversee the migration of UT’s current legacy data capabilities to the Data Hub. The goal of all of D2I’s work is to improve the availability of trusted information and data in support of operational and decision-making needs. We believe the best ideas arise from collaborative work among colleagues from varied backgrounds and experiences. We actively seek diversity of viewpoint and perception in our student, faculty, and staff recruiting and retention practices. If you’re the type of person who loves to learn and wants to know your work has meaning, you may find your career home at UT Austin. Please note that this position is currently funded through December 31, 2025. The University of Texas at Austin provides an outstanding benefits package to staff, including: Competitive health benefits (Employee premiums covered at 100%; family premiums at 50%) Vision, dental, life, and disability insurance options Paid vacation, sick leave, and holidays Teachers Retirement System of Texas (a defined benefit retirement plan) Additional voluntary retirement programs: tax sheltered annuity 403(b) and a deferred compensation program 457(b) Flexible spending account options for medical and childcare expenses Training and conference opportunities Tuition assistance Athletic ticket discounts Access to UT Austin's libraries and museums Free rides on all UT Shuttle and Capital Metro buses with staff ID card For more details, please see: https://hr.utexas.edu/prospective/benefits and https://hr.utexas.edu/current/services/my-total-rewards This position requires you to maintain internet service and a mobile phone with voice and data plans to be used when required for work. This position provides life/work balance with typically a 40-hour work week and travel generally limited to training (e.g., conferences/courses). Purpose The Data Engineer for the UT Data Hub improves university outcomes and advances the UT mission to transform lives for the benefit of society by increasing the useability and value of institutional data. You will create complex data pipelines into UT’s cloud data ecosystem in support of academic and administrative needs. In collaboration with our team of data professionals, you will help build and run a modern data hub to enable advanced data-driven decision making for UT. You will leverage your creativity to solve complex technical problems and build effective relationships through open communication Responsibilities Data Engineering: Assist in designing and automating scalable data integration solutions between institutional data sources, including the UT mainframe, and the Amazon Web Services cloud platform Assure performance and reliability of integration processes through monitoring, performance analysis and development of automated alerting processes Participate in end to end delivery of technical projects involving design and development of data pipelines for complex datasets Work closely with business partners to design and manage data pipeline elements including load frequency, data delivery mechanisms, and transformations Ensure that data pipeline solutions align with industry best practices, and adhere to UT security guidelines Develop and maintain detailed technical documentation of data pipeline processes Collaborate with key stakeholders including enterprise data architect, data modelers, data stewards, and subject matter experts (SMEs) Other responsibilities: Participate in change management processes to coordinate and communicate team activity. Other related functions as assigned Required Qualifications BS degree in Computer Science, Information Systems, Engineering, or equivalent professional experience. One year of Data Engineering experience with Amazon Web Services. One year of experience implementing and monitoring complex data pipelines and automation of cloud-based workloads. Proficiency in one or more scripting languages and/or programming languages, preferably Python. Advanced SQL knowledge and experience working with relational databases. Demonstrated experience of developing and implementing Continuous Integration and Continuous Delivery (CI/CD) systems. Proficiency in systems analysis, design, and a solid grasp of development, quality assurance, and integration methodologies. Excellent problem solving and troubleshooting skills. Relevant education and experience may be substituted as appropriate. Preferred Qualifications Three years of experience in Data Engineering or related field. One year of experience working in a cloud-based data warehouse environment. Two years of experience building and monitoring complex data pipelines. AWS Developer and/or Solutions Architect certification. Two years of experience with Agile software development methodologies. Two years of experience with issue tracking systems (JIRA). Experience with Spark, Kafka etc., is a plus. Salary $110,000 + depending on qualifications Working Conditions May work around standard office conditions Repetitive use of a keyboard at a workstation Use of manual dexterity Location up to 100% remote at employee discretion with office work environment also an option. Majority of team is located in Austin, TX, and working remotely with infrequent in-office presence. Required Materials Resume/CV 3 work references with their contact information; at least one reference should be from a supervisor Letter of interest Important for applicants who are NOT current university employees or contingent workers: You will be prompted to submit your resume the first time you apply, then you will be provided an option to upload a new Resume for subsequent applications. Any additional Required Materials (letter of interest, references, etc.) will be uploaded in the Application Questions section; you will be able to multi-select additional files. Before submitting your online job application, ensure that ALL Required Materials have been uploaded. Once your job application has been submitted, you cannot make changes. Important for Current university employees and contingent workers: As a current university employee or contingent worker, you MUST apply within Workday by searching for Find UT Jobs. If you are a current University employee, log-in to Workday, navigate to your Worker Profile, click the Career link in the left hand navigation menu and then update the sections in your Professional Profile before you apply. This information will be pulled in to your application. The application is one page and you will be prompted to upload your resume. In addition, you must respond to the application questions presented to upload any additional Required Materials (letter of interest, references, etc.) that were noted above. - Employment Eligibility: Regular staff who have been employed in their current position for the last six continuous months are eligible for openings being recruited for through University-Wide or Open Recruiting, to include both promotional opportunities and lateral transfers. Staff who are promotion/transfer eligible may apply for positions without supervisor approval. - Retirement Plan Eligibility: The retirement plan for this position is Teacher Retirement System of Texas (TRS), subject to the position being at least 20 hours per week and at least 135 days in length. - Background Checks: A criminal history background check will be required for finalist(s) under consideration for this position. - Equal Opportunity Employer: The University of Texas at Austin, as an equal opportunity/affirmative action employer, complies with all applicable federal and state laws regarding nondiscrimination and affirmative action. The University is committed to a policy of equal opportunity for all persons and does not discriminate on the basis of race, color, national origin, age, marital status, sex, sexual orientation, gender identity, gender expression, disability, religion, or veteran status in employment, educational programs and activities, and admissions. - Pay Transparency: The University of Texas at Austin will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. - Employment Eligibility Verification: If hired, you will be required to complete the federal Employment Eligibility Verification I-9 form. You will be required to present acceptable and original documents to prove your identity and authorization to work in the United States. Documents need to be presented no later than the third day of employment. Failure to do so will result in loss of employment at the university. - E-Verify: The University of Texas at Austin use E-Verify to check the work authorization of all new hires effective May 2015. The university’s company ID number for purposes of E-Verify is 854197."
Entry Level Product Data Management Engineer,BOEING,"Everett, WA",https://www.indeed.com/rc/clk?jk=04eb2649994398b0&fccid=edae4285faf6c2f0&vjs=3,"At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us. Corporate (CORP) is seeking an Entry Level Product Data Management Engineer to support our team in Everett, WA. Position Responsibilities: Gathers data to support the analysis and verification of process and product baselines Collects data for product and subsystem level technical design reviews and audits for new and derivative products Processes product changes and assists with the documentation and implementation of engineering technical program plans of limited scope and complexity Gathers data to assist in the analysis of product trades/changes for change proposals Assists with the documentation of Configuration and Data Management standards, processes and tools Gathers customer input data for Configuration and Data Management requirements for product hardware, software, and engineering design data systems Gathers data to assist in the resolution of issues with engineering product structure Works under close supervision Key skills to be successful in this role: STRONG project management skills and experience Communication skills at all levels of leadership Be able to get team members to work together using influence skills Think large scale and sustainable (goal is not just to fix the problem today, but also to make sure the problem doesn’t come back) Be open to new ideas and be able to challenge team to think differently This position allows telecommuting. The selected candidate will be required to perform some work onsite at one of the listed location options. The position must meet Export Control compliance requirements, therefore a “US Person” as defined by 22 C.F.R. § 120.15 is required. “US Person” includes US Citizen, lawful permanent resident, refugee, or asylee. Basic Qualifications (Required Skills/Experience): Bachelor’s degree or higher in accredited course of study in engineering, computer science mathematics, physics or chemistry. Preferred Qualifications (Desired Skills/Experience): Possess strong written and oral communication skills Flexible & adaptable in a diverse & demanding environment and work schedule Able to interact positively with people throughout Boeing & customers Ability to learn in a fast paced environment Typical Education/Experience: Education/experience typically acquired through advanced technical education from an accredited course of study in engineering, computer science, mathematics, physics or chemistry (e.g. Bachelor) or an equivalent combination of technical education and experience. In the USA, ABET accreditation is the preferred, although not required, accreditation standard. Relocation: This position offers relocation based on candidate eligibility. Employee Referral: Referral to this job is eligible for bonus Drug Free Workplace: Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies. Shift Work Statement: This position is first shift Union: This is a non-union represented position Equal Opportunity Employer: Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law."
Data Engineer,Sound Transit,"Seattle, WA 98104 (International District area)",https://www.indeed.com/rc/clk?jk=349107f44c1ee76d&fccid=2a80f36ff3f60bea&vjs=3,"Important information pertaining to our COVID-19 protocols, including our hybrid workforce options, can be found here. GENERAL PURPOSE: Under minimal supervision, designs, builds, tests, and delivers, end-to-end, automated data pipelines over complex on-prem and off-prem platforms. Automates the collection of data from multiple source systems containing structured, semi-structured and unstructured data; integrates, transforms, organizes, stores, and serves data to data analysts, data scientists, and other data consumers within the agency departments. Possesses excellent programming, debugging, testing and problem-solving skills. Leverages pragmatic data management practices and principles to ensure coherent movement of data that are relied upon across the agency as the single source of truth. ESSENTIAL FUNCTIONS: The following duties are a representative summary of the primary duties and responsibilities. Incumbent(s) may not be required to perform all duties listed and may be required to perform additional, position-specific duties. Analyzes business requirements, designs, and implements enterprise-class data solutions for new data projects. Develops and operationalizes data pipelines to make data available for consumption Owns the design, development, and ongoing maintenance of data warehouses, data marts, multi-dimensional cubes, and data lakes. Writes complex SQL queries, stored procedures, ETL workflows, views, temporary tables, and other database objects. Utilizes latest data technologies and cloud platforms; collects, integrates, ingests, transforms, and organizes, and serves data and information to support data analyses, reporting, dashboarding and modern analytics across the agency. Works in tandem with tech leads, data architects and peer data engineers to design data pipelines and recommends ongoing optimization of, data ingestion, data quality, data storage and orchestration. Evaluates existing legacy data solutions; redesigns and implements modern data infrastructure for robustness and greater scalability. Assists customers with their data related technical issues and data platform needs. Builds analytics tools that ingest data from large disparate datasets to draw actionable insights into operational efficiencies and key business performance metrics. Identifies ways to improve data reliability and efficiency. Develops automated test scripts to monitor and report on data quality issues; conducts root cause analyses in response to data issues and implements cost effective resolutions for data anomalies. Collaborates with the IT Enterprise Architecture team to define data architecture framework and implement data solutions and toolsets. Provides input into data governance initiatives and influences the development of sustainable data management and governance practices across the agency. Creates and maintains architecture diagrams, system documentation, data models, mapping documents, business rules, data flow diagrams and other design related artifacts. Actively participates in architecture design, and code review sessions with peers, solution architects, consultants, and vendors. Attends professional group meetings; stay abreast of new trends and innovations in the field of information technology. Conducts research and makes recommendations on emerging technologies, toolsets, applications, and systems, considering among other factors cost savings, adoption, standardization/simplification, flexibility, and reuse. Troubleshoots and resolves production issues quickly to ensure system uptime meets service level agreements. Performs peer reviews for other data engineer’s work. Follows agency’s data classification policies and procedures, and maintain compliance with established security standards and best practices Communicates statuses of all assigned tasks clearly and concisely to the project team, stakeholders, and management. Works cooperatively with coworkers, product managers, customers, project managers and vendors. Champions and models Sound Transit's core values and demonstrates values-based behaviors in everyday interactions across the agency. Contributes to a culture of diversity, equity and inclusion in alignment with Sound Transit’s Equity & Inclusion Policy. It is the responsibility of all employees to follow the Agency safety rules, regulations, and procedures pertaining to their assigned duties and responsibilities, which could include systems, operations, and/or other employees. It is the responsibility of all employees to integrate sustainability into everyday business practices. Other duties as assigned. MINIMUM QUALIFICATIONS: Education and Experience: Bachelor’s Degree in computer science, information technology, engineering, or closely related field and five years of experience in information technology in the areas of data engineering, business intelligence and analytics; OR an equivalent combination of education and experience. Required Licenses or Certifications: None Required Knowledge and Skills: Basic principles of computer science, database technologies and information systems. Advanced principles, best practices, methods, and techniques used in data engineering, business intelligence, data management, data warehousing concepts, data mapping, data modeling, reporting, analytics, and data science. Relational database management systems, NoSQL databases and Big Data ecosystem Data pipelines, stream processing, Supervisory Control And Data Acquisition (SCADA) and Internet of Things (IoT). Enterprise data catalog, meta-data and master-data concepts and management. Full-stack DevOps engineering with understanding of compute, network, storage with cost optimized implementations. DevOps tools like ADO, Git, Jenkins, Dockers etc. Enterprise application systems related to Finance, Human Resources, Asset Management, Transit Rider Technologies, and other subject areas as needed. Evaluating business requirements and developing information technology solutions. Operational characteristics of a variety of computer and network systems, applications, hardware, software, and peripheral equipment, including enterprise business systems. Various methods of service delivery including agile and waterfall. Software development life cycle, source code version control systems, release management, change management, and ITIL processes (Incident and Change Management). Principles, practices, methods, and techniques used in the installation, troubleshooting, and maintenance of software systems and applications. Quality Assurance techniques and automated testing practices. Principles and practices of project management. Pertinent federal, state, and local laws, codes, and regulations. Designing and implementing Business Intelligence/Analytics platforms using Azure services such as Azure Synapse Analytics, Azure Data Factory, Azure Data Lake to improve and speed up delivery of data services. Relational Database Management Systems (RDBMS), Microsoft SQL Server, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS), and other relevant technologies. Message based integration using Kafka and/or Azure Event Hub Logical and physical data modeling for both OLTP and OLAP. Reporting technologies including but are not limited to Microsoft SQL Server Reporting Services (SSRS), Microsoft Report Builder, Power BI, Crystal Reports, Business Objects Enterprise, etc. Working knowledge and advanced skills in Excel as a data source and reporting tool. Big Data tools like Spark, MapReduce, Hive, Pig, Oozie, etc. NoSQL solutions like HBase, MongoDB, Cassandra etc. Programming using C#, Java, Scala, and Python; scripting using PowerShell. Creating and consuming various data formats such as CSV, XML, JSON, etc. including using of APIs or web services for data acquisition. Learning new applications, programming languages, development tools, and technologies quickly. Establishing and maintaining effective working relationships with peers, other department staff, management, vendors, outside agencies, community groups, external business partners and the public. Effective oral and written communication and the ability to convey technical details to non-technical stakeholders, senior leadership, and executives both in written and verbal form Working effectively under pressure, meeting tight deadlines, and adjusting to changing priorities. Physical Demands / Work Environment: Work is performed in a standard office environment. Subject to standing, walking, bending, reaching, stooping, and lifting of objects up to 40 pounds; may occasionally be exposed to dangerous machinery, extreme temperatures, and extreme noise when working in the data center environment or when working in the field. The Agency promotes a safe and healthy work environment and provides appropriate safety and equipment training for all personnel as required. Sound Transit is an equal employment opportunity employer. No person is unlawfully excluded from employment action based on race, color, religion, national origin, sex (including gender identity, sexual orientation and pregnancy), age, genetic information, disability, veteran status or other protected class. Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Engineers,Artha Solution,"Scottsdale, AZ 85260 (North Scottsdale area)+1 location",https://www.indeed.com/rc/clk?jk=a9335a3bb68258c7&fccid=2f6b4b4d070b7bbd&vjs=3,"Job: Data Engineers / Interns – Entry level Positions: Multiple Preferable Locations: Scottsdale AZ, Naperville, IL We are looking for talented individuals to become part of our growing business and grow with us. The right person should have the interest to learn new tools and adapt to fast paced environment. Experience/knowledge on databases, data management, data integration, Big Data, Data warehouse, reporting, and data analytics is preferable. The role and compensation will depend upon any prior experience and exposure to technology areas and demonstrated education. Education, Skills, and Abilities: BS/BA in Computer Science or related discipline required. Experience in writing SQL queries and basic functions & Stored procedures. Fundamental Knowledge of databases, data warehousing, data integration, and BI tools. Exposure to data management concepts, reporting, and analytics tools is an advantage. Experience in RDBMS, No SQL and Java is an advantage concepts/ exposure to Cloud Computing Attention to detail, Analytical, and problem-solving skills. Ability and willingness to learn new tools and applications. Effective written and verbal communication skills with the ability to convey complex technical concepts to business users and management."
Data Engineer,ZM Financial Systems,"New York, NY",https://www.indeed.com/rc/clk?jk=6c74e2b30d233f05&fccid=7e9f8411cc2b1ce8&vjs=3,"Imagine what we can DEVELOP with you True leaders are always learning. Moody’s is home to information architects, thinkers, builders, and passionate problem solvers, a collection of diverse viewpoints working together to bring out our best. Join us. Forward Together. Moody’s (NYSE: MCO) is a global integrated risk assessment firm that empowers organizations to make better decisions. Our data, analytical solutions and insights help decision-makers identify opportunities and manage the risks of doing business with others. We believe that greater transparency, more informed decisions, and fair access to information open the door to shared progress. With over 11,000 employees in more than 40 countries, Moody’s combines international presence with local expertise and over a century of experience in financial markets. Learn more at moodys.com. At Moody’s, we’re taking action. We’re hiring diverse talent and providing underrepresented groups with equitable opportunities in their careers. We’re educating, empowering and elevating our people, and creating a workplace where each person can be their true selves, reach their full potential and thrive on every level. Learn more about our DE&I initiatives, employee development programs and view our annual DE&I Report at moodys.com/diversity Moody’s Analytics provides financial intelligence and analytical tools supporting our clients’ growth, efficiency and risk management objectives. The combination of our unparalleled expertise in risk, expansive information resources, and innovative application of technology, helps today’s business leaders confidently navigate an evolving marketplace. Department Moody’s Analytics products are becoming an essential tool in the rapidly expanding Commercial Real Estate market. We deliver an integrated and holistic platform that automates critical processes and generates insights and recommendations to drive better decisions. Lenders, asset managers and brokers are some of our biggest customers. Our analytics provide key property performance indicators, research, and risk assessment, giving our customers a good understanding of their future cashflows. We have a team of brokerage and lending solutions experts as well as passionate sales, marketing and technology professionals who constantly strive to add value to our customers’ experience. Role/Responsibilities As a Data Engineer, you will be a core member of a cross-functional team responsible for developing and executing a vision for how to grow the CRE business monumentally through new product innovation. We practice an agile, highly customer focused, and learning-based approach to product development that aims to bring new products to market in 9-12 months. You will be responsible for building and maintaining high quality data pipelines that drive analytic solutions and product development. These solutions will draw on Moody’s Analytics unique and rich data sources to generate insights for innovative products that create a new standard in the CRE space. You bring not only a deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows, but also a passion for translating those skills into business impact for our customers. Specifically, you will have the opportunity to: Design, develop, optimize, and maintain scalable data architecture and pipelines that adhere to ETL principles and business goals Solve complex data problems to deliver insights that help the organization’s business to achieve their goals Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions Improve operational processes and documentation Qualifications 2+ years of experience working in a fast-paced software development environment Expertise in SQL and data analysis and experience with at least one programming language (Python preferred) Experience developing and maintaining data warehouses in big data solutions Experience with developing solutions on AWS cloud computing services and infrastructure in the data and analytics space (preferred) Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data Experience working on a collaborative product team passionate about Agile software processes, data-driven development, and experimentation Excellent communication, listening, and influencing skills Ability to work efficiently with a solid sense for setting priorities Ability to guide own learning and contribute to domain knowledge building Self starter Must be fully vaccinated for COVID-19 (i.e., at least 2 weeks after last dose) and, if hired, present proof of vaccination on start date, as determined by Moody’s. Moody’s is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, gender, age, religion, national origin, citizen status, marital status, physical or mental disability, military or veteran status, sexual orientation, gender identity, gender expression, genetic information, or any other characteristic protected by law. Moody’s also provides reasonable accommodation to qualified individuals with disabilities or based on a sincerely held religious belief in accordance with applicable laws. If you need to inquire about a reasonable accommodation, or need assistance with completing the application process, please email accommodations@moodys.com. This contact information is for accommodation requests only, and cannot be used to inquire about the status of applications. For San Francisco positions, qualified applicants with criminal histories will be considered for employment consistent with the requirements of the San Francisco Fair Chance Ordinance. This position may be considered a promotional opportunity, pursuant to the Colorado Equal Pay for Equal Work Act. Click here to view our full EEO policy statement. Click here for more information on your EEO rights under the law. Click here to view our Pay Transparency Nondiscrimination statement. For Colorado-based roles only: the anticipated base salary range for this position is $90,800 to $131,750, depending on factors such as experience, education, level, skills, and location. This range is based on a full-time position. In addition to base salary, this role is eligible for annual performance incentive compensation. Moody’s also offers a competitive benefits package, including not but limited to medical, dental, vision, parental leave, paid time off, a 401(k) plan with employee and company contribution opportunities, life, disability, and accident insurance, a discounted employee stock purchase plan, and tuition reimbursement. Candidates for Moody’s Corporation may be asked to disclose securities holdings pursuant to Moody’s Policy for Securities Trading and the requirements of the position. Employment is contingent upon compliance with the Policy, including remediation of positions in those holdings as necessary."
Data Applications Engineer,SunPower,"Richmond, CA 94804 (Marina Bay area)",https://www.indeed.com/rc/clk?jk=db4ac6e3a42e2329&fccid=e145a4204aee6fa7&vjs=3,"Do you want to change the world? We do, too. Solar penetration is less than 1%, but just one hour of sunlight, if harnessed, could power the entire world for a year. We have the opportunity to change the way energy is produced, distributed and consumed, and we’re looking for talented, committed people to help us drive our growth and achieve our goals. SunPower is a solar energy solutions company with a rich heritage of pioneering the best solar technologies in the world. Our solutions are unrivaled in terms of long-term reliability, efficiency, and performance. SunPower offers the only solar + storage solution designed and warranted by one company that gives customers control over electricity consumption. Through design, installation, maintenance, and monitoring, SunPower provides its world-class solar solutions to residential and commercial customers across the U.S. SunPower is changing the way our world is powered every day with a brilliant, passionate, and driven team of more than 2,500 in North America and the Philippines. In an industry that is reshaping the world’s energy future, there’s no better place to be than SunPower. We believe that our employees create our brand – with each project, each communication, each task completed and each interaction. SunPower welcomes the forward thinkers, the future savers of the world, the freedom chasers and all those demanding better, cleaner energy. Summary of Role: We are looking for someone to help proactively maintain our fleet, improve technical support response, and improve the efficiency of ongoing operations – using analytical skills and data flow prowess. The Data Applications Engineer will work directly with the monitoring platform development team, fleet operations center analysts, and customer support agents – the goal is to improve efficiency and customer experience by getting the right information to the right teams and automating workflows. We are looking for candidates with experience using telemetry data to inform decisions and driving closed-loop learning activities, particularly in the realm of power electronics and control system engineering. A successful candidate will help the organization improve the accuracy of technical support responses, pinpoint areas for improvement, and ensure accurate tracking of quality metrics. For this reason, some level of power electronics experience is preferred. Excellent candidates will be capable of designing an analytical framework and system. Additionally, the person filling this role will interact directly with our development team to design data systems and applications that quantify performance losses and diagnose the underlying causes. A strong technical analytics background is expected, and an understanding of data systems, database structure, and business processes will be important. What You’ll Be Doing Build and extend our platform capabilities to better monitor and diagnose the health of our expansive fleet of residential solar installations Improve on existing data systems with an emphasis on scalability and durability Develops toolset for internal users – primarily engineering & quality Develops with BI tools & data systems (Tableau, Power BI, etc.) Writes procedures and technical training notes for users of the monitoring platform Minimum Qualifications: B.S. degree in a STEM field and 4+ years of related experience or M.S. Degree and 2+ years or Ph.D. and 0+ years OR an equivalent combination of education and years of related experience Experience with BI toolset (Tableau, PowerBI) Strong proficiency with Python and ETL pipelines Strong proficiency working with databases (SQL & NoSQL) Experience with version control systems Experience working in a Linux environment Preferred Qualifications: Firm understanding of statistical concepts Experience developing in cloud environments (We use AWS) Experience building and ingesting data from REST APIs Experience using Airflow Nice to haves: Power electronics and/or control system experiences General understanding of Machine Learning concepts Physical Demands and Working Conditions: Primarily office work Fieldwork at installation sites will be required on rare occasions Light lifting may be required Some travel may be required Equal Employment Opportunity The Company is an equal employment opportunity employer and makes employment decisions, including but not limited to, hiring, firing, promotion, demotion, training, and/or compensation, on the basis of merit. Employment decisions are based on an individual’s qualifications as they relate to the job under consideration. The Company’s policy prohibits unlawful discrimination based on sex (which includes pregnancy, childbirth, breastfeeding, or related medical conditions, the actual sex of the individual, or the gender identity or gender expression), race, color, religion, including religious dress practices and religious grooming practices, sexual orientation, national origin, ancestry, citizenship, marital status, familial status, age, physical disability, mental disability, medical condition, genetic information, protected veteran or military status, or any other consideration made unlawful by federal, state or local laws, ordinances, or regulations. The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company and prohibits unlawful discrimination by any employee of the Company, including supervisors and co-workers. EOE Minorities/Females/Protected Veterans/Disabled SunPower Supports EEO Accommodation for Applicants to SunPower Corporation SunPower Corporation is an Equal Employment Opportunity / Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need a reasonable accommodation due to a disability, you may use the following alternative email address to contact us about your interest in employment at SunPower Corporation: jobs@sunpower.com. Please indicate in the subject that line of your email that you are requesting accommodation. Only candidates being considered for a position who require an accommodation will receive a follow-up response. NOTICE TO ALL APPLICANTS AND EMPLOYEES Availability of Affirmative Action Plan for Review SunPower is a federal government contractor. As a part of the Company’s obligations under law, it must develop a written Affirmative Action Program (AAP) for the Disabled, Recently Separated Veterans, Armed Forces Service Medal Veterans, Disabled Veterans and Active Duty Wartime Or Campaign Badge Veterans and for Women and Minorities as specified by law. Non-confidential and non-proprietary aspects of the AAP are available for inspection by applicants and employees, consistent with applicable law, which will be made available during office hours by contacting the EEO Officer."
Data Center Engineer (East Coast),Akuna Capital,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=a8a22942c1bb9aff&fccid=53708619218b979f&vjs=3,"About Akuna: Akuna Capital is an innovative trading firm with a strong focus on collaboration, cutting-edge technology, data driven solutions and automation. We specialize in providing liquidity as an options market-maker – meaning we are committed to providing competitive quotes that we are willing to both buy and sell. To do this successfully we design and implement our own low latency technologies, trading strategies and mathematical models. Our Founding Partners, including Akuna's CEO Andrew Killion, first conceptualized Akuna in their hometown of Sydney. They opened the firm's first office in 2011 in the heart of the derivatives industry and the options capital of the world – Chicago. Today, Akuna is proud to operate from additional offices in Sydney, Shanghai, and Boston. What you'll do as a Data Center Engineer at Akuna: We are looking for a Data Center Engineer, based on the East Coast, to join our IT Infrastructure team at Akuna. This is a highly impactful role where you will contribute to supporting and evolving a high-performance and sophisticated multi-data center environment, in addition to driving projects that aid in the expansion to new markets and asset classes. In this role, you will: Be responsible for building, organizing, and maintaining our data center infrastructure at colocation facilities in Secaucus, Carteret, Mahwah, and other East Coast US locations. Install, replace, and move cables and equipment, including switches, servers, and hardware components. Work with our IT Infrastructure and Development teams to plan and execute data center moves and re-organization, ensuring those plans are completed accurately and in a timely manner. Manage asset tracking and reporting, including warranties, service contracts, hardware, and software. Maintain an inventory of cables and equipment. Use monitoring tools to detect and respond to critical issues. Troubleshoot technical issues and respond in a timely manner to hardware failures. Coordinate with third-party vendors for support and remote hands. Develop and maintain documentation of data center procedures and deployments. Work with the IT Infrastructure team to ensure our data centers have the necessary space, power, and cooling, and that we have appropriate monitoring of the same. Qualities that make great candidates: 2+ years of data center experience. Bachelor's degree in Computer Science, Information Systems, or a related field preferred, but not required. Knowledge of data center procedures (hardware racking, network cabling, etc.) and experience working in a modern, large-scale data center. Strong attention to detail and a commitment to executing plans accurately and on time. Understanding of network hardware (switches, SFP's), servers (memory, hard drives), and cabling (fiber optic cabling standards / types). Ability to diagnose a problem quickly and identify solutions that ensure the uptime of the system. Highly motivated and organized self-starter. Basic Linux systems administration experience (PXE, Hardware & Software Raid, User Management, boot processes). Exposure to multiple infrastructure areas, hardware support, cable management, and low latency networking a plus. Understanding of data center cabinet power distribution / power management. Ability to clearly communicate detailed instructions both verbally and written. Additional requirements: Out-of-state travel and the ability to work outside of core business hours and on weekends. Ability to commute to critical data centers in the New York metro area – must have own transportation and valid driver's license. Ability to travel and provide support to other regions occasionally as needed. Ability to lift equipment weighing up to 50 pounds."
Data Quality Engineer,"Ilitch Holdings, Inc.","Detroit, MI 48226 (Downtown area)",https://www.indeed.com/rc/clk?jk=5acb3e4df9556710&fccid=47e5a6628ac6ded9&vjs=3,"This role will be responsible for managing analytics and research within Baseball Operations. This position will report to the Director, Baseball Analytics. KEY RESPONSIBILITIES Perform advanced quantitative analysis to improve Baseball Operations decision-making, including predictive modeling and player projection systems. Complete ad hoc data queries and effectively present analysis through the use of written reports and data visualizations. Assist with the integration of baseball analysis into our proprietary tools and applications. Contribute to baseball decision-making by generating ideas for player acquisition, roster construction and in-game strategies. Support the current data warehousing process within Baseball Operations. Monitor, identify and recommend new or emerging techniques, technologies, models and algorithms. Meet with vendors and make recommendations for investment in new data and technology resources. Other projects as directed by Baseball Operations leadership team. MINIMUM KNOWLEDGE, SKILLS AND ABILITIES Demonstrated expert-level knowledge of baseball-specific data, modern statistical techniques, and sabermetric analysis. Expertise with SQL and relational databases is required. Relevant work experience with statistical software (R, STATA, SPSS, SAS, or similar) and scripting languages such as Python. Demonstrated ability to communicate difficult and complex concepts to colleagues possessing a wide range of backgrounds and perspectives. Degree or equivalent experience in statistics, mathematics, computer science, or a related quantitative field. Self-starter. Team Player. Ability to work evenings, weekends and holidays as dictated by the baseball calendar. Willing and able to relocate to the Detroit metro area. WORKING CONDITIONS Office environment. Evening, weekend, and holiday hours required."
Senior Data Engineer,Tangent Logic,"New York, NY",https://www.indeed.com/rc/clk?jk=4988868a60b275e5&fccid=f56e987506c52c25&vjs=3,"What you will do: As the ideal candidate you will have experience working on backend data pipelines and be comfortable navigating remote VMs and using containerization technology. You will be expected to build scalable data ingress and egress pipelines across data storage products, deploy new ETL pipelines and diagnose, troubleshoot and improve existing data architecture. Responsibilities Be able to create and deploy ETL pipelines on AWS cloud architecture, using tools including but not limited to AWS Glue, RedShift, S3, EMR & Lambda functions. Troubleshoot and fix bugs and diagnose data issues Work independently to solve issues while collaborating with your direct Data Engineering team as well as the larger Product & Technology organization. Write unit and integration tests with a goal of full critical path code coverage with a robust logging & reporting focus. Provide training to team members on areas of expertise Experience 3-5+ years’ professional experience Fluency in one (or more) programming language such as Python, PySpark Experience writing ETL pipelines on a cloud infrastructure, especially in Python Solid understanding of SQL and RDBMS Understanding of distributed data processing (Hadoop, map/reduce, ect) Knowledge of Docker and Kubernetes AWS experience is Key, as well as accessing VMs, serverless technology and distributed data processing"
Data Engineer Senior,Zayo Group,United States+1 location,https://www.indeed.com/rc/clk?jk=968dfcbbf6af584f&fccid=44666e7051739fbb&vjs=3,"Company Description Zayo provides mission-critical bandwidth to the world’s most impactful companies, fueling the innovations that are transforming our society. Zayo’s 133,000-mile network in North America and Europe includes extensive metro connectivity to thousands of buildings and data centers. Zayo’s communications infrastructure solutions include dark fiber, private data networks, wavelengths, Ethernet, and dedicated Internet access. Zayo serves wireless and wireline carriers, media, tech, content, finance, healthcare and other large enterprises. Position Description This role is responsible for the design, development, deployment of an MSSQL data warehouse to support analysis and reporting. The position is also responsible for maintaining, supporting, and enhancing existing integration systems as well as assisting in the ongoing development of technical best practices for data movement, data quality, data cleansing and other ETL related activities. This is an individual contributor position with no personnel responsibilities. Responsibilities Member of the data engineering team working to protect, improve, and leverage the value of our data assets Build and automate new ETL processes to pull from many disparate data sources to centralize information in a new data warehouse design Maintain and develop existing data warehouse integrations and ETL processes to move data efficiently between various enterprise systems. Miscellaneous automation of data processes across a wide variety of customer platforms • Implements interfaces to meet changing integration requirements after fully understanding company specific configurations Production support for integration servers SQL & Reporting support across various business groups Follows standard test plan to test each client and ensure that configured functionality meets the needs of the company Negotiates and makes changes to existing interfaces as needed Ability to handle multiple priorities and meet aggressive deadlines Required to be part of an on-call rotation and will occasionally be responsible for after-hours maintenance work Qualifications Intermediate to Advanced SQL skills Proficiency in MS SQL Server, SSRS & MS BI stack preferred Experience computing in a Cloud Datalake/Warehouse environment preferred Experience with version control and deploy via GitHub/GitLab preferred Bachelor's degree Business Intelligence, Computer Information Systems or similar 5 or more years database design, data management, reporting and ETL. The ability to collaborate across functional groups. The ability to communicate effectively at all levels of the organization. Prior experience with data migration/integration efforts Prior experience with Salesforce.com a plus Prior experience with Cast Iron integration application or similar tools a plus Prior experience with DbAmp a plus Prior experience with dbt or similar data transformation tool a plus Base salary range for CO $92,000 - $135,000 #LI-MB1 Benefits, Rewards & Wellness Excellent Health, Dental & Vision Insurance Retirement 401(k) Savings Plan Fitness membership discounts Generous paid time off policy including paid parental leave Please note, in accordance with Zayo's commitment to providing and maintaining a workplace free of recognized hazards, all U.S. and Canadian employees and any employee, vendor, customer, or visitor who enters a Zayo office or facility in the U.S. and Canada must be fully vaccinated against COVID-19 and provide proof of such vaccination. If you are hired by Zayo, you will be required to provide proof of vaccination or have a valid religious or medical reason not to be vaccinated."
Data Engineer,Stanford Health Care,"Palo Alto, CA 94303",https://www.indeed.com/rc/clk?jk=ff7490b9af19c836&fccid=1e9dc60a2424f016&vjs=3,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered. Day - 08 Hour (United States of America) This is a Stanford Health Care job. A Brief Overview The Data Architect II is responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications. Locations Stanford Health Care What you will do Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc. Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts With little supervision, performs analysis of the scope and requirements for projects Prepares specifications, designs, data models and diagrams from which databases can be developed Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools. Troubleshoots incidents surrounding supported databases and solutions. Tunes performance of databases, ETL processes and queries Education Qualifications Bachelor's degree in analytics or business-related field or equivalent work experience preferred. Experience Qualifications Two (2) years of experience in analytics, business intelligence or healthcare technology. Required Knowledge, Skills and Abilities Delivers high quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.). Proficient with best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role. Troubleshoots incidents and enhancement requests surrounding supported applications. Recommends improvements to supported applications. 1+ years experience with SQL in an Oracle and/or SQL Server enviroment. Very proficient with SQL (joins, multpile joins, subqueries, unions) including DDL for creation of tables, views, materialized views, etc. Ability to perform basic performance tuning to optimize queries to meet user needs. Demonstrated proficiency with Data Warehousing and ETL concepts, including: source to target mapping, transformations, error handling, job control, logging, alerting, and scheduling. Demonstrated proficiency in Data Definition Language (DDL) , Data Manipulation Language (DML), and Extraction, Transformation and Loading (ETL) design and development using SQL Server tools (SQL Management Studio, T-SQL, SSIS, Team Foundation, etc.) and/or Epic Clarity Compass. Complex Report writing & some metadata (universe) creation with SHC standard tools. Operates with minimal supervision. Accountable interaction up to Tier 4 levels of the organization Demonstrated ability for completing moderately complex projects and/or multiple assigned projects. Highly capable individual with expanded skill sets Understands SHC's vision and communicates it to others. Appropriately questions how their assigned work relates and supports this vision. Mastered one domain and learning others. Ability to anticipate design or technical problems and suggest viable alternatives. Partner with multidisciplinary teams with limited supervision. Track record of consistently good work with only occasional problems or defects. Utilizes strategic A3s and is proficient with Lean methods Makes reliable operational internal decisions with limited supervision. Can present ideas to peers and peer-group end-users. Effective verbal, written, and interpersonal communication skills. Licenses and Certifications None These principles apply to ALL employees: SHC Commitment to Providing an Exceptional Patient & Family Experience Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery. You will do this by executing against our three experience pillars, from the patient and family’s perspective: Know Me: Anticipate my needs and status to deliver effective care Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health Coordinate for Me: Own the complexity of my care through coordination Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements."
Data Engineer,Vectra AI,"Austin, TX",https://www.indeed.com/rc/clk?jk=82bbf85202d269a7&fccid=0189204a62bdb587&vjs=3,"Vectra® is the leader in AI-driven threat detection and response for hybrid and multi-cloud enterprises. The Vectra Platform captures packets and logs across network, public cloud, SaaS, and identity by applying patented security-led AI to surface and prioritize threats for rapid threat response. Vectra's threat detections are powered by a deep understanding of attacker methods and problem-optimized AI algorithms. Alerts uncover attacker methods in action and are correlated across customer environments to expose real attacks. Organizations around the world rely on Vectra to see and stop threats before a breach occurs. For more information, visit www.vectra.ai. Company Overview Vectra delivers a new class of real-time threat detection and response. Vectra picks up where perimeter security leaves off using AI to provide deep, continuous analysis of both internal and Internet-facing network traffic for all phases of the attack progression as attackers attempt to breach, spy, spread, and steal within networks. Vectra directly analyzes large data sets, including network traffic, in real time using a combination of proprietary data science, machine learning, and behavioral analysis to detect attacker behaviors and user anomalies in the network. All detections are algorithmically correlated and prioritized to show an attack in context and Vectra’s machine learning adapts as attacks evolve. For more details, see https://vectra.ai/how-it-works. Position Overview The Vectra Engineering team looks for people that are smart, very capable technically, and have fun solving the challenges that our customers face together as a team. We believe strongly that everyone can and should have significant impacts on the growth of the product as well as the company and our culture. We believe in using the right technology for each problem and building knowledge through mentorship and other things like peer code reviews. We're excited to find others to join the team that want to work on an interesting product that solves real problems. Detecting attackers in real-time requires a high-performance suite of software that enables machine learning and statistical techniques. This requires the processing and management of considerable volumes of data. We are looking for innovative and resourceful data engineers to join our growing team. Our data science and analytical capabilities rely on the fast, efficient flow of large volumes of data. Working in concert with our existing Data Science/Data Engineering you will assist in optimizing these flows as well as building out new data pipelines to support our growing product portfolio. Responsibilities Create, test and maintain optimal data pipeline architectures Identify and develop data set processes for data modeling, minding, and production Build the infrastructure required for optimal extraction, transformation, and loading of large data sets Spark fresh ideas that are infused in our culture and our products Leverage emerging tech and Big Data to ensure delivery of real time analytics solutions Work on complex, large-scale, group-wide big data projects Perform data analysis tasks required to troubleshoot data related issues and ultimately present optimized solutions. Interface with other groups including Product Management, UX, Security Research and Data Science to help customers simplify security Qualifications Required BS or M.S or Ph.D. in Computer Science (or equivalent experience) 6+ years in software development, data engineering, or equivalent Knowledge of software design principles and leading software development practices Strong communication & collaboration skills Willingness to get things done, learn new things, take initiative and challenge existing assumptions and conventions Experience building and deploying to any cloud service (AWS, Azure, GCP, etc.) Experience programming in any of the following (python, javascript, golang) Knowledge of the following tools (or similar): Git, Jenkins, JIRA etc. Desirable Distributed processing technologies (Spark, Presto, Impala, MapReduce etc.) Comfort in dealing with low level data storage formats (Parquet, Orc, Avro, Arrow etc.) Experience working with a geographically dispersed team Experience with grooming business-stakeholder requirements into achievable technical goals Ability to work in a collaborative environment Expertise in automated testing in addition to continuous integration and deployment tools Knowledge of networking and networking protocols (PCAP analysis, Zeek/Bro format) Knowledge of AI/Machine Learning and Cybersecurity A two-minute video that describes what we do at Vectra, and an article about Vectra's last funding round: https://vimeo.com/89579264 https://tcrn.ch/3gVAXNw"
"Language Engineer , AWS AI Data | Transcribe","Amazon Dev Center U.S., Inc.",+2 locationsRemote,https://www.indeed.com/rc/clk?jk=33544a8f22e8988c&fccid=fe2d21eef233e94a&vjs=3,"PhD in Computational Linguistics, Linguistics with a computational component, or an equivalent field; alternatively, MA with 3+ years of experience Excellent knowledge of semantics, pragmatics, conversation analysis, and/or discourse analysis Experience owning and executing language data collection projects, including guidelines, labelset and annotation workflow development Proficiency in Python and other analytics tools such as R to process and analyze language data Experience in developing and evaluating data annotation and data quality metrics Job summary The AI Data Team in Amazon Web Services (AWS) is looking for a forward-looking and collaborative Language Engineer II to join us in developing solutions for natural language data collections. This position is an opportunity to apply your expertise in a challenging but supportive environment. The position may be remote, with a preference for Santa Clara, Seattle, or New York City. The mission of the AI Data Team is to engineer the datasets critical to the success of AWS’s machine learning services. From chatbots to subtitles to search results and beyond, these products support dozens of languages and impact millions of people every day. We are a group of language engineers, linguists, data scientists, data engineers, and program managers, and we partner closely with the science, engineering, and product teams. We are customer obsessed and committed to delivering results with the highest quality and integrity. As a Language Engineer, you will start by diving deep into a high profile project to launch a new product offering. You will consult with stakeholders in science, engineering, and product teams to strategize on data collection and annotation. You will analyze, follow, and improve processes for annotating transcribed conversations, assessing data quality and automating where appropriate. You will then expand your scope by using the principles of data-centric AI to understand the role our data plays with regard to model performance specifically, as well as the larger ML pipeline. You will apply state-of-the-art ML and NLP techniques to analyze how well our data represents human language and run experiments to gauge downstream interactions. You will work collaboratively with other language engineers and scientists to design and implement principled strategies for data optimization. Key job responsibilities Source, validate, and deliver high-quality language artifacts and linguistic data. Collaborate with stakeholders to design and oversee data collection and development efforts. Innovate on data collection methodologies, guidelines, quality metrics to support new requests. Extend existing data collection and annotation efforts to support feature and language expansion. Automate repetitive workflows and improve existing processes. About the team The AI Data Team at AWS is responsible for delivering high-quality annotated data and a variety of language artifacts to ensure the best performance of different AWS machine-learning language services. These ML-based language services enable customers to readily add intelligence to their business operations and AI applications to drive positive outcomes. Ability to explain complex concepts and solutions in easy-to-understand terms Experience working in the medical domain Experience building ontologies, taxonomies, and other semantic relation frameworks Practical knowledge of version control systems such as GitHub Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. Workers in New York City who perform in-person work or interact with the public in the course of business must show proof they have been fully vaccinated against COVID or request and receive approval for a reasonable accommodation, including medical or religious accommodation."
Data Center Engineer II,Astreya,"Sunnyvale, CA+1 location",https://www.indeed.com/rc/clk?jk=3ad9015088da49bc&fccid=f7fcb231ff95ee5c&vjs=3,"Company Description Astreya is the leading IT solutions provider to deliver technology-enabled services and fuel digital transformation to some of the most exciting companies on the planet. We are at the cusp of a new way of working with our delivery model that helps our clients be positively productive by matching exceptional people to on-site teams delivering world-class IT service. With engineers in over 30 countries and 70 cities around the world, we are a global company working with the world's most recognizable and innovative organizations. Job Description What this Job Entails: The Data Center Engineer II will be heavily involved in the design of the datacenter collocations, infrastructure hardware, and provide technical consultations. The incumbent will build/create all drawings for datacenter POP’s and develop/write Scopes of Work (SOW) for new POP builds. The Data Center Engineer will create detailed installation MOP’s (Method of Procedure) for multiple types of optical transport and switching equipment, overheads (fiber raceway, ladder, basket) and power AC/DC. The incumbent will also communicate with all departments and provide tech support for Network Engineers. Scope: Resolves a wide range of issues in creative ways Seasoned, experienced professional with a full understanding of their speciality Works on problems of a diverse scope Receives little instruction on day to day work, general instruction on new assignments Your Roles and Responsibilities: Deploy, configure, and support a large-scale production and corporate network and server infrastructure in data centers and Point of Presence (POP) sites. Calculate and document equipment power requirements and work with Engineering, Facilities Operations, and/or collocation vendors to meet these requirements. Manage project timelines to support network turn-up within expected completion intervals. Responsible for asset management of networking gear in datacenter and POP sites. Contribute to documentation, automation and processes as they evolve. Create network and server rack face elevations, floor plans, wiring diagrams, and detailed port maps for new deployments and documentation. Create statements of work for vendors at the POP sites. Create cage and rack designs and understand the overall needs of POP infrastructure. Document and follow RMA processes and procedures for all relevant vendors. Assist in following, improving, and implementing data center and POP best practices. Work closely with Network Engineering, Logistics, and equipment vendors as new equipment and technologies are integrated into the production network. Other duties as required. This list is not meant to be a comprehensive inventory of all responsibilities assigned to this position Required Qualifications/Skills: Bachelor’s degree (B.S/B.A) from four-college or university and 2 to 5 years’ related experience and/or training; or equivalent combination of education and experience Builds productive internal and external working relationships Exercises judgment within defined procedures and practices to determine appropriate action Understanding of Data center practices (i.e. cable routing, calculating power usage and cooling). Familiarity with creating As-Built drawings for Datacenter POPs and creating the 3rd module on DC-CAD Knowledge of how to build/create SOW’s for new POP builds Understanding of field-based work in POPs, carrier hotels, or Central Office environments. Understanding of fiber-optic technology including cable types, connector types, optic types, patch panels, and optical transport technologies. Excellent communication skills, should be able to work with carriers/vendors Understanding of importance of dealing with service providers and colocation facilities Ability to work within a global team in a fast-paced and dynamic environment with limited supervision Strong attention to detail with excellent time management and organization skills Preferred Qualifications: Physical Demand & Work Environment: Must have the ability to perform office-related tasks which may include prolonged sitting or standing Must have the ability to move from place to place within an office environment Must be able to use a computer Must have the ability to communicate effectively Some positions may require occasional repetitive motion or movements of the wrists, hands, and/or fingers What can Astreya offer you? Employment in the fast-growing IT space providing you with a variety of career options Opportunity to work with some of the biggest firms in the world as part of the Astreya delivery network Introduction to new ways of working and awesome technologies Career paths to help you establish where you want to go Focus on internal promotion and internal mobility - we love to build teams from within Free 24/7 accessible Professional Development through LinkedIn Learning and other online courses to give you opportunities to upskill at your own pace Education Assistance Dedicated management to provide you with on point leadership and care Numerous on the job perks Market competitive compensation and insurance, health and wellness benefits Additional Information Astreya Partners is an equal employment and affirmative action employer. We evaluate qualified applicants on merit and business needs and not on race, color, religion, creed, gender, sexual orientation, national origin, ancestry, age, disability, genetic information, marital status, veteran status or any other factor protected by law. #INDG1 #LI-GN1"
Data Engineer,Avalon Healthcare Solutions,Remote,https://www.indeed.com/rc/clk?jk=1e2945d04bab152f&fccid=3748c93dadbb2e71&vjs=3,"About the Company: Avalon Healthcare Solutions, headquartered in Tampa, Florida, is a clinical services and information technology company using evidence-based medicine to develop and deploy medical policies and protocols in the high-volume, dynamic and complex diagnostic lab environment. The company manages the appropriate use of thousands of existing lab tests and researches new tests to determine efficacy and impact on patient care. Studies show that 30% of clinical laboratory testing is unnecessary or overused. Inappropriate testing or missing a key screening can lead to complications and expense arising from unwarranted care, or not obtaining proper care when needed, leading to increased health risks and costs. Avalon helps ensure delivery of the right test, at the right time, and in the right setting. We seek to ensure the most effective patient treatment, improve clinical outcomes, and optimize cost and affordability. Avalon is a portfolio company of Francisco Partners, a global private equity firm that specializes in investments in technology and technology-enabled service companies. Since its launch 15 years ago, FP has raised approximately $10 billion and invested in more than 150 companies. Avalon is a high growth company where every associate has an opportunity to make a difference. You will be part of a team that shapes a new market and business. You’ll enjoy seeing the results of your work as we rapidly implement our plan. Most importantly, you will help Avalon to achieve its mission and improve clinical outcomes and health care affordability for the people we serve. For more about Avalon, please visit our web site at http://www.avalonhcs.com. About the Data Engineer Position: Within the analytics department, the Data Engineer will aid teammates by using various methods to transform raw data into useful data systems, prepping data for modeling, and constructing maintaining the infrastructure used for analytics. The Data Engineer will also be responsible for assessing and reporting on data quality and striving for efficiencies by aligning data systems with business goals. This position entails ensuring the reporting team and business owners have valid and reliable data available for consumption by internal and external clients. The ideal candidate will be self-motivated, self-reliant and has product development experience. This is a full-time, W-2 position. At this time, we can consider only candidates authorized to work in the US. No sponsorship is available. No recruiter calls, please. Data Engineer - Essential Functions and Responsibilities: Analyze and organize raw data Acquire data to meet project requirements Build data systems and pipelines to generate reliable and repeatable processes to onboard data Evaluate business needs and objectives Interpret trends and patterns Conduct complex data analysis and report on results Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality, integrity, and reliability Identify opportunities for data acquisition Curate data for advanced analytics and data science Develop analytical tools and programs Collaborate with team members on several projects at once Employ strong analytical and organizational skills and attention to detail Integrate model outputs with visualization and BI tools Data Engineer - Minimum Qualifications: Bachelor's degree in relevant field or 5+ years of relevant work experience Strong analytical skills Python and Redshift experience Product development experience Strong, hands-on experience with SQL data management and database design Excellent problem solving and communication skills Desire to learn new software and methods Familiar with cloud service offerings such as Azure, AWS Data Engineer - Preferred Qualifications: Healthcare experience – pharmacy, managed care, health plans, hospitals, pharmaceuticals Previous experience as a data engineer or in a similar role Excellent numerical and analytical skills Familiar with statistics and statistical modeling Experience in big data applications and processes Experience in data dashboarding in PowerBI PM18"
Digital Manufacturing & Data Engineer (USA) - VIE,Plastic Omnium,"Greer, SC 29651",https://www.indeed.com/rc/clk?jk=0e30c0f3c06c302f&fccid=aaec0480e2e19692&vjs=3,"Date: Jun 17, 2022 Location: Greer-South Carolina, SC, US Company: Plastic Omnium Job description You will join a multi competences team to help deploying Digital Factory initiatives for IES Americas business unit. Your main tasks will include: Support the launch & ramp-up of the new implementation of Digital factory applications Support installation of Digital Factory MES applications on the Injection, Paint and Assembly part of the process, and traceability system using RFID technology Assist with relevant processes which coordinate both physical and information flows Suggest and formalize relevant MES-related evolutions following active presence on shopfloor Support traceability/RFID activation in Plants Imagine creative solutions to better assist operators and go towards a more Visual factory on shopfloor Root-cause analysis of issues encountered on the shopfloor (mainly related to data) Support the develop of Data Factory and Opint Reports. Support the Industrial System Controller on these technologies and act as L2 support for local IT’s. To review the dashboards regularly with the local IT teams to investigate trends and areas for improvement. To liaise with the Central Europe region and Division teams where inaccuracies are detected in the data and monitor remediation measures. This role will give you international exposure and first responsibilities in a working environment with the potential to further develop a career in the company. Profile You are a highly motivated young graduate with a Master's degree in IS/IT engineering or a Master's in Computer Science. You are a team player, a self-learner and have demonstrated some good communication and project management skills. You have an interest for the industry and a first experience or internship in this sector would be an advantage. Open-minded and with a serious desire to learn, you can demonstrate a clear willingness to embark on an international career. You are also rigorous and team-oriented. You have an advanced knowledge of IT and manufacturing processes. You are fluent in English, another language would be appreciated. To qualify for a 18-months visa, candidates must justify of 52 weeks of professional experience in the field of the VIE mission. Duration 18 months, beginning December 2022 Location Greer, USA"
Cloud Data Engineer,Republic Airways,"Indianapolis, IN 46268 (College Park area)",https://www.indeed.com/rc/clk?jk=f21d6b029470d4a7&fccid=46a09f103177da03&vjs=3,"POSITION PURPOSE: Ensures the successful design, development and delivery of technology-based solutions including a specialization in enterprise data warehouse and cloud technologies. Drives on-time, high quality development deliverables to multiple environments including operations test, develop and production releases. Assists in the definition and maturation of processes to optimize efficiency and quality. ESSENTIAL DUTIES To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions. Proactively builds models used in artificial intelligence, machine learning & predictive analysis for decision-making recommendations. Utilizes data to drive ROI, efficiencies and streamlined operations. Conducts data analysis, data profiling, and data extraction from disparate sources (relational and non-relational databases, data warehouses, data lakes and flat files). Designs, develops, analyzes, and automates reporting solutions. Develops reports that support analysis and key business decisions on an ad-hoc and scheduled basis. Extracts and prepares large quantities of data from source systems. Communicates effectively and proactively with internal stakeholders to ensure information is presented logically and consistently. Ensures effective communication of user requirements. Provides consultation to users for the development of reports and also systems impacting the data output. Designs and develops enterprise and departmental business intelligence, data warehousing and reporting solutions. Works closely with business partners to create technical requirements, database design and BI solutions that will empower business partners to embrace data confidently and responsibly in addressing their complex challenges. Develops and implements interactive analytic reports and dashboards. Provides technical and business knowledge support to the team. Builds enterprise scalable, complex data visualizations, dashboards, KPI scorecards, and KRI reports, etc. in Power BI Desktop. Keeps up-to-date with latest technology trends. Performs other duties as assigned. REQUIRED KNOWLEDGE, SKILLS AND ABILITIES The requirements listed below are representative of the knowledge, skill, and/or ability necessary to perform this job. EDUCATION and/or EXPERIENCE Bachelor’s degree (B.A. / B.S.) in Information Technology, Informatics, or related field. Experience with Azure Cloud data management and related technologies 5-7 years of experience with large, complex, and diverse datasets in an analytics/reporting oriented team Expert experience with SQL or Python programming in an analytics environment. Experience with PowerBI, Tableau and/or QlikView. Experience with data modeling in an analytics environment Strong data analytics skills, ability to identify data discrepancies, irregularities, trends, and patterns. Ability to work SSRS for on premises and cloud services. Strong problem-solving skills; ability to performance tune and query optimization. PREFERRED EDUCATION and/or EXPERIENCE Ability to calibrate Machine Learning (ML) models and experience with Artificial Intelligence (AI) preferred Knowledge of predictive and analytic dashboards and reporting strongly preferred. Experience with designing and implementing self-service models Hands-on experience with implementing data and analytics management programs LANGUAGE SKILLS Ability to read, analyze, and interpret general business periodicals, professional journals, technical procedures, or governmental regulations. Ability to write reports, business correspondence, and procedure manuals. Ability to effectively present information and respond to questions from groups of managers, clients, customers, and the public. Be an excellent communicator and collaborator, engaging with multiple technical and business stakeholders and leaders. Be able to translate the information architecture contribution to business outcomes into simple briefings for use by various data-and-analytics-related roles. REASONING/PROBLEM SOLVING ABILITY Ability to solve practical problems and deal with a variety of concrete variables in situations where only limited standardization exists. Ability to interpret a variety of instructions furnished in written, oral, diagram, or schedule form. DECISION MAKING Makes decisions daily on use of resources, performance and budgets. Decisions could require additional expenditure of resources if not sound decisions. PHYSICAL DEMANDS The physical demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job. Able to move about the work environment. Frequently required to stand, walk, sit, talk and hear. Able to focus with clear vision at 20 inches or less (computer screen. WORK ENVIRONMENT The work environment characteristics described here are representative of those an associate encounters while performing the essential functions of this job. Typically not exposed to extreme environmental conditions. TRAVEL REQUIREMENTS Travel up to 10% of the time."
Data Engineer (Range),Pioneer Natural Resources Company,"Irving, TX",https://www.indeed.com/rc/clk?jk=1e39dfcdce302aa4&fccid=50343264b93b9f96&vjs=3,"This data engineer position will report to the Automation & Spatial Solutions group within the Strategic Planning & Field Development (SPFD) department. Automation & Spatial Solutions is responsible for department wide spatial data, automation & integration efforts, and data engineering. Responsibilities will vary by individual projects supporting both the department and organizational goals. Areas of focus will include research and development of data pipelines, analytics, data visualization, automation, data processing, and data management, concentrating on developing sustainable products/platforms. Job Duties: Prepare technical data for interpretation, conduct analyses and routine computer processing of the data, and help create final displays of the results often for formal presentations Design, develop, test, document, deploy, monitor, and support data pipelines Work with domain experts, data scientists, engineers to understand needs, constraints, and limitations Create analytical dashboards utilizing Business Intelligence software such as Spotfire, Operations Dashboard, and/or PowerBI Develop ETL processes and maintain application integrations across multiple systems and data sources Design, develop, and institute automated workflows utilizing various technologies (Python, GIS, SQL, Spotfire, Alteryx, MS Power Platform and more) to minimize human error, standardize data, and apply data management best practices with a focus on data integrity and governance Develop and optimize existing and new expansion of the systems in place Willingness to learn, experiment, try new things, fail, and grow! Perform other duties as assigned by Supervisor, to include special projects. Qualifications: Bachelor's in Data Science, Statistics, Applied Mathematics, Computer Science, Engineering, Geoscience. Must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. Driven by the prospect of optimizing or even re-designing company’s data architecture to support the next generation of products and data initiatives Functional in SQL with experience in querying relational databases, views, and normalized schemas Functional in programming (Python-preferred) with skills in algorithms, clean code, environment management Working knowledge in NoSQL (graph-based) databases as well as working familiarity with a variety of databases (Cassandra, InfluxDB, Redis, KUDU, etc.). Understanding and utilization of enterprise ETL tools; ex: Alteryx, Azure Synapse, Azure Data Factory, MS Power Platform Experience building and optimizing ‘big data’ pipelines, architectures, and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Build processes supporting data transformation, data structures, metadata, dependency, and workload management. A successful history of manipulating, processing, and extracting value from large, disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. Experience with big data tools: Spark/PySpark, Hadoop ecosystem, parallel computing, parquet, unstructured datasets Experience with data pipeline and workflow management tools: Azkaban, Airflow, Docker, Kubernetes Ability to identify opportunities for improvement / automation and development of existing workflows and processes Salary competitive and commensurate with qualifications and experience. Our Mission: RESPECT Core Values Respect We respect one another and the communities in which we operate. Ethics and Honesty We are ethical and honest and committed to uphold our strong reputation. Safety and Environment We believe no job is so important that it cannot be done in a safe and environmentally sound manner. Personal Accountability We are disciplined and personally accountable for our decisions, actions, attitude and results. Entrepreneurship We have an entrepreneur's mindset, driving innovation and striving for excellence in all we do. Communication We openly and professionally communicate among all levels and between departments and teams. Teamwork and Inclusion We believe in diverse perspectives and teams collaborating toward common objectives with a can-do attitude. Pioneer Natural Resources is an EEO Employer."
Engineer Data Pipeline Monitoring (India),DynPro,Remote in United States,https://www.indeed.com/rc/clk?jk=aa1070115e8fae4e&fccid=f511d6a4d4b04eb0&vjs=3,"Reference # : 22-00094 Title : Engineer Data Pipeline Monitoring (India) Location : DL Position Type : Contract Experience Level : Start Date : 03/17/2022 Description Engineer Data Pipeline Monitoring Start ASAP Duration Long Term Location India (Remote) Monitor data pipelines flowing across customer system stack Airflow, Superset, Hive, Jira, Presto, Minerva Triage issues with the pipelines & ensure successful completion Monitor system logs, respond to Slack & Jira messages related to pipeline issues Create RCA for major incidents alongside L2 and client stakeholders Work with SDA to update Runbooks as needed Basic SQL/PLSQL skills (MySql, MS Sql, Oracle) Python scripting Basic Accounting background or working in the Finance Department will be good to have. var jobnumber='22-00094';"
Sr. Data Engineer - open to remote,Principal Financial Group,"Remote in Des Moines, IA 50392",https://www.indeed.com/rc/clk?jk=7ef7f49a525c367c&fccid=591be181c58fd89d&vjs=3,"Responsibilities: We are seeking a Data Engineer to join our team and partner with Principal's global marketers to deliver enterprise-wide marketing data solutions. Our team enables the enterprise to get the most out of our marketing technology investments, including Google Analytics, Salesforce Marketing Cloud, Medallia and more. We integrate our marketing technology stack with other enterprise solutions to connect data and deliver a cohesive customer experience. We work on all aspects of the Software Development Life Cycle and consider ourselves full stack engineers. This can cover discovery, design, dev, testing, CI/CD, and monitoring. Our team collaborates throughout the workday and we flex between mob, pair and solo approaches to meet the needs of the work effort. Here are few examples of the kinds of things you’ll do: Enable marketers from around the enterprise to effectively reach out and connect with current and future customers. Work in a dynamic, cross-functional team of smart, upbeat individuals who demonstrate a start-up approach. Our work is challenging and fulfilling, and we are proud to share our products. Be part of a team of resilient change-makers who continuously seek improvement through cloud solutions, DevOps, open-source solutions, automation and much more. Understand complex technical concepts and translate them into solutions that are understandable and engaging. Leverage data to produce personalized experiences relevant to customers. Enable foundational marketing technology solutions that use data to make effective marketing possible. Qualifications: Bachelor's degree plus 6+ years related work experience or a Master's in related field plus 2+ years related work experience Skilled in backend JavaScript programming (Node.js preferred) and Python Experience building processes to support data transformation, data structures, metadata, dependency and workload management. AWS Cloud platform experience including AWS Cloud Services (S3, Glue, Athena, etc.) preferred, but open to other cloud platform experience (GCP, Heroku, etc.) Additional preferred technical experience: Familiarity with configuration of vendor platforms (Salesforce Marketing Cloud, Medallia, Sprinklr, Salesforce CRM, Google Analytics, etc.) Integration with data warehouses to generate marketing insights Advanced working SQL knowledge, including experience working with query authoring and a familiarity of a variety of databases Analytic skills relating to data pipelines, technical design, and data sets. Mentoring, teaching, and growing skill sets of others Experienced with API calls and system integrations Salary Range Information: Salary ranges below reflect targeted base salaries. Non-sales positions have the opportunity to participate in a bonus program. Sales positions are eligible for sales incentives, and in some instances a bonus plan, whereby total compensation may far exceed base salary depending on individual performance. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Salary Range: $87600 - $172800 / year Additional Information: Location Remote candidates will be considered for this position. Job level We’ll consider talent at the next level with the right experiences and skills. How we hire Once you apply, your application is hand reviewed by our talent team. Generally within a few weeks, the team makes interview selection decisions and communicates those via email. If selected, you’ll receive an email from Principal Talent Team to complete a pre-recorded interview on your own time. Be sure to check your email frequently and follow the steps shared to submit timely. Learn more about our hiring steps and find answers to frequently asked questions. Work Authorization/Sponsorship At this time, we're not considering candidates that need any type of immigration sponsorship now or in the future or those needing work authorization for this role. (This includes, but is not limited to students on F1-OPT, F1-CPT, J-1, etc.) Investment Code of Ethics For Principal Global Investors positions, you’ll need to follow an Investment Code of Ethics related to personal and business conduct as well as personal trading activities for you and members of your household. These same requirements may also apply to other positions across the organization. Experience Principal While our expertise spans the globe, we're bound by one common purpose: to foster a world where financial security is accessible to all. And our success depends on the unique experiences, backgrounds, and talents of our employees – individually and all of us together. Explore our core values, benefits and why we’re an exceptional place to grow your career. Principal is an Equal Opportunity Employer All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status. PFGRB LinkedIn Remote Hashtag : #LI-Remote"
Perl Engineer - Reference Data,Barclays,"Whippany, NJ 07981",https://www.indeed.com/rc/clk?jk=21931e59128aa3dd&fccid=057abf3fd357e717&vjs=3,"Perl Engineer Whippany, NJ As a Barclays Perl Engineer you will be a part of the Instrument and Price Master Data Management (IPMDM) global team, responsible for the development and maintenance of Enterprise Reference Data systems. Development work will incorporate a range of languages and technologies, with a particular focus on ETL technologies like Perl, Java and relational databases on Windows and Linux platforms. Barclays is one of the world's largest and most respected financial institutions, with 329 years of success, quality and innovation behind us. We've helped millions of individuals and businesses thrive, creating financial and digital solutions that the world now takes for granted. An important and growing presence in the USA, we offer careers providing endless opportunity. What will you be doing? Developing code in line with the stories that have been agreed as part of the delivery team Actively engaging in providing solutions to the stories that have been submitted Actively engaging in the delivery process and collaborate with other delivery team members to makes sure that the focus is on business value delivery Making sure that all development is in line with Barclays & IPMDM Standards Providing L3 Support as and when required across all applications Applying design and system architecture skills to ensure continual improvements in performance and stability of core Instrument and Price systems What we’re looking for: 4+ years of hands-on experience on Perl/Shell. Ideal candidate must have strong ETL feeds development background Excellent query writing and SQL skills primarily around Relational databases (MS SQL Server and Oracle DB) Good experience on .Net / Core Java background with hands-on experience on complex systems Exposure to Development tools such as: Eclipse, IntelliJ IDEA, TeamCity, Jira, GIT, Stash, Chef, Nolio Skills that will help you in the role: Exposure to Behavior Driven Development (BDD and TDD) Experience working as part of a global team, following follow-the-sun model Reference Data domain (Products & Prices) knowledge is highly desirable Experience with OpenShift, AWS and docker desirable Where will you be working? At Barclays, we are proud to be redefining the future of finance and here at Whippany we are defining the future of the workplace and the future of the way we work and live. We are creating a unique community, one of four strategic tech-enabled hubs that will redefine opportunity for everyone who works here. Whatever you do at Whippany, you’ll have every chance to build a world-class career in this world-class environment. #LI-MG2021"
Data Engineer II - REMOTE,Office Depot,"Remote in Boca Raton, FL 33496+1 location",https://www.indeed.com/rc/clk?jk=c4f063aad8cef121&fccid=18aa19122de0323c&vjs=3,"Overview Data Engineer - REMOTE Product & Technology · Role is 100% REMOTE! You can work from anywhere within the US!! Varis is a well-funded and fast-growing technology startup. Our incredible team includes top industry leaders with decades of experience. We are innovation driven, customer centric, and ready to transform Business-to-Business (B2B) Procurement with insights gleaned from data. Our culture is focused on bold vision, launching the simplest (yet still valuable) initial solution to learn, then either failing or scaling fast. We seek teammates who drive value creation, are great problem solvers, have strong interpersonal savvy, and can successfully learn on the fly! Joining us now is a ground-floor opportunity to shape our limitless future. On our team you will: see and feel the direct impact of your work; be surrounded by passionate people; learn how to be an entrepreneur; and be at the center of a highly dynamic business model with tremendous individual and collective potential. The Data Engineer is accountable for implementing methods to improve data reliability and quality. They combine raw information from different sources to create consistent and machine-readable formats. They also develop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling. He/she must conduct the analysis of raw data, developing and maintain datasets, improving data quality and efficiency around the data pipeline. We are looking for an experienced data engineer to join our team. You will use various methods to transform raw data into useful data systems. For example, you’ll create algorithms and conduct statistical analysis to provide important insights to foster product and technical adoption within and outside of Varis. Overall, you’ll strive for efficiency by aligning data systems with business goals. To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources. Data engineer skills also include familiarity with several programming languages and knowledge of learning machine methods. If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you. Primary Responsibilities: Analyze and organize raw data Build data systems and pipelines Evaluate business needs and objectives Interpret trends and patterns Conduct complex data analysis and report on results Prepare data for prescriptive and predictive modeling Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality and reliability Identify opportunities for data acquisition Develop analytical tools and programs Collaborate with data/research scientists and ontologists on several initiatives Education & Experience Level of Formal Education: Bachelor’s or Master’s degree or equivalent experience Area of Study: Data Science and or Computer Science Years of Experience: Minimum 2 -3 years’ experience in related field Type of Experience: Modeling large data sets and data repositories Experience in eCommerce, B2B, Sourcing, or Procurement environment is a plus. Language Skills: Excellent verbal and written communication skills Technical Competencies: Previous experience as a data engineer or in a similar role Technical expertise with data models, data mining, and segmentation techniques Knowledge of programming languages (e.g. Java and Python) Hands-on experience with database design (e.g., SQL, Key-Value, and Document based, etc.) Data engineering certification (e.g IBM Certified Data Engineer) is a plus Skills and Ability: Knowledge of planning, designing, and implementing a data pipelines, architecting and designing through scientific method the use of machine learning techniques, to ensure that the data science management best practices are planning, designed and implemented. Strong background in research and analysis, including the ability to evaluate source authority Solid problem solving and conceptual thinking abilities Great numerical and analytical skills Ability to work in a collaborative, fast-paced environment Comfortable in technical environments and eager to learn new systems as needed Ability to context switch between systems-level thinking and attention to minute details Time management skills, demonstrated success in handling multiple, sometimes conflicting priorities Capable of balancing quick decision-making with attention to quality and accuracy Personal Attributes: Interpersonal and leadership skills Executive level presence Maintains a positive attitude, high energy, and strong sense of urgency Ability to learn quickly and think creatively Resident expert on cutting-edge customer experience Other/Preferred: Knowledge of various eCommerce and Internet technologies The above statements are intended to describe the general nature and level of work being performed by associates assigned to this classification and are not intended to be a complete list of all required responsibilities and skills. Other duties and special projects may be assigned per business needs. Job descriptions are subject to change at any time with or without notice. Varis is wholly owned by The ODP Corporation, which is the legal employer of Varis associates. ODP is an Equal Opportunity Employer."
Data Engineer,Saarthee,"Philadelphia, PA",https://www.indeed.com/rc/clk?jk=bc9f35faaefdfd99&fccid=655c2b69b2b7d2ab&vjs=3,"Department Analytics Location Philadelphia Job Category Analytics Position Type Full-Time Position Summary: We are looking for a Data Engineer to join our growing team of data analytics experts to support and implement high-quality, data-driven decisions. We are looking for candidates who are skilled and hands-on with solving the most difficult technical aspects of data and analytics projects. We are looking for candidates who are comfortable working independently, as a team lead and client engagement managers at the same time. The Data Engineer will work closely with the leads across the Onsite and Offsite teams. Essential duties and responsibilities: Create and maintain optimal data model architecture. Collaborate with business units and engineering teams to develop strategy for long term data platform architecture. Work with key stakeholders-Executive, Product, Data and Design teams to help with technical issues and cater to their data infrastructure need and improve data models that feed business intelligence tools, increasing data accessibility and aid and enhance data-driven decision making. Implements software maintenance and testing processes to monitor data quality, make bug fixes ensuring production data is always accurate and available for key stakeholders and business processes that depend on it. Ensure existing systems are upgraded and kept up to date for smooth operations. Store, retrieve, and manipulate data and perform data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Using data along with scientific analysis and mathematical models, design, develop and modify analytics tools that utilize the data framework to provide actionable insights into key business performance metrics like sales efficiency and marketing efficiency. Works closely with a team of engineers and analysts and seek information on the project constraints. Work with business stakeholder to understand user requirements. Collaborate and coordinate with the teams to ensure viable and optimal data solutions. Design data integration frameworks with data flow diagrams and document software requirements prior to coding the integration to assemble large, complex data sets that meet functional / non-functional business requirements. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL . Develop components and sequences for making these components work together. Create maintenance and training documentation for new and existing users. Required Skills and qualifications: Strong academic record from premier institutes with bachelor’s in computer applications, Computer Science, Engineering, or closely related field. Master’s in Business Administration is an added plus Minimum 3+ years of experience in analytics delivery and management consulting working with ETL, Business Intelligence, Data Quality, Data Analytics Strong Analytical thinking and client management experience with hands-on experience in problem-solving with proficiency with standard analytics tools (e.g., R, Mathematica, Python) with broad experience in data warehouse and business intelligence tools (BI, ETL, Data Quality and RDBMS tools/platforms) Excellent understanding of data warehouses / data-marts and dimensional data models Proficient in SQL. Proficient in data analytics, reporting and integration platform like Python, Knime, Tableau Excellent client management and engagement skills. Effective presence & communication skills- both interpersonal & written and the ability and willingness to take a hands-on execution role where required to support client needs and team development Highly organized with an ability to work under tight deadlines and shifting priorities Excellent oral and written communication skills What we offer Competitive compensation packages that reward high performance Fast track career with supportive culture that facilitates 360 degrees learning Collaborative team-based environment with mentorship from the Industry leaders Comprehensive benefit package including Health Insurance About us We are one of the fastest-growing Analytics firms driven by our core desire to partner with our clients- success by delivering data-driven actionable insights through accelerated analytics. We are ranked among top 1000 in Inc 5000 2020 list of the fastest growing private companies in America. We are also on Philly top 100 list ranking at 25. Our diverse team of highly skilled consultants around the globe helps us execute the process of systematically analyzing data and finding patterns in a short turnaround time. We provide strategic guidance, business and technology solutions for clients wishing to solve their most complex challenges involving data analytics, cloud applications, big data, data discovery, and data protection."
Senior Data Engineer,Dassault Systèmes,"New York, NY",https://www.indeed.com/rc/clk?jk=37c1c55c502ac414&fccid=29d37d43c382c8fe&vjs=3,"Medidata: Powering Smarter Treatments and Healthier People Medidata is leading the digital transformation of life sciences, creating hope for millions of patients. Medidata helps generate the evidence and insights to help pharmaceutical, biotech, medical device and diagnostics companies, and academic researchers accelerate value, minimize risk, and optimize outcomes. More than one million registered users across 1,900+ customers and partners access the world’s most trusted platform for clinical development, commercial, and real-world data. Medidata, a Dassault Systèmes company, is headquartered in New York City and has offices around the world to meet the needs of its customers. Discover more at www.medidata.com and follow us @medidata. Your Mission: Member of the data engineering team responsible for data aggregation, transformation, modeling and delivery for both client usage and internal data science teams Full-stack design, development, and operation of core data capabilities like data lake, data warehouse, data marts and data pipelines Contribute to the team's roadmap and project planning process, partnering with stakeholders to develop business objectives and translate those into action Work with data architects to develop data flows and align to platform integration standards Build data flows for data acquisition, aggregation, and modeling, using both batch and streaming paradigms Consolidate/join datasets to create easily consumable, consistent, holistic information Empower other data teams, data scientists and data analysts to be as self-sufficient as possible by building core capabilities as services and developing reusable library code Ensure efficiency, quality, resiliency of the core data platform Your Competencies: Analytically minded and detail-oriented: you actually like working with data, looking for patterns and outliers, establishing data models, and finding the best answers to business & technology problems Expertise in data engineering languages such as Java, Scala, Python, SQL Data modeling experience; you've designed and implemented data marts, data warehouses or other large-scale data management systems; you have experience with Dimensional and Data Vault data modeling Experience working with cloud data warehouses such as Snowflake Computing, AWS Redshift or Azure SQL Data Warehouse Experience building ETL and data pipelines, both with traditional ETL solutions like Pentaho, Informatica, SSIS, Talend but also via code-oriented systems like Spark, Airflow or similar Cloud-oriented with strong understanding of SaaS models Experience operating in a secure networking environment, leveraging separate production support and SRE teams is a plus Excellent technical documentation and writing skills You have a bias towards automation, an Agile/Lean mindset and embrace the Devops culture Familiarity with streaming/messaging technologies like Kafka, Kinesis, Spark Streaming Familiarity with visualizing data with Tableau, Business Objects, Quicksight, PowerBI, Spotfire and similar tools Great customer focus and strong technical troubleshooting skills Proficiency in statistics and data science is a nice-to-have, and interest in learning these is even better Experience with clinical trial data is not required, but interest to learn and understand it is a must Hadoop/Spark and Graph/RDF/Ontologies experience a plus Your Education & Experience: Undergraduate or graduate degree in a technical or scientific field, such as Computer Science, Engineering, Mathematics, or similar 5+ years professional experience as a data engineer, software engineer, data analyst, data scientist, or related role Medidata is making a real difference in the lives of patients everywhere by accelerating critical drug and medical device development, enabling life-saving drugs and medical devices to get to market faster. Our products sit at the convergence of the Technology and Life Sciences industries, one of most exciting areas for global innovation. Nine of the top 10 best-selling drugs in 2017 were developed on the Medidata platform. Medidata Solutions have powered over 17,000+ clinical trials giving us the largest collection of clinical trial data in the world. With this asset, we pioneer innovative, advanced applications and intelligent data analytics, bringing an unmatched level of quality and efficiency to clinical trials enabling treatments to reach waiting patients sooner. COVID Statement Medidata requires all U.S. employees to be fully vaccinated against COVID-19 and to provide documentation of full vaccination, unless qualified for an accommodation as determined by Medidata, consistent with applicable law. Although accommodation requests will be considered (and granted where appropriate/possible), it may be determined that a candidate is unable to adequately perform the essential functions of the position without imposing an undue hardship on Medidata due to customer requirements, staffing needs, or other business reasons. Medidata Solutions, Inc. is an Equal Opportunity Employer. Medidata Solutions provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity, national origin, age, disability status, protected veteran status, or any other characteristic protected by the law. Medidata Solutions complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. Not available Equal opportunity In order to provide equal employment and advancement opportunities to all individuals, employment decisions at 3DS are based on merit, qualifications and abilities. 3DS is committed to a policy of non-discrimination and equal opportunity for all employees and qualified applicants without regard to race, color, religion, gender, sex (including pregnancy, childbirth or medical or common conditions related to pregnancy or childbirth), sexual orientation, gender identity, gender expression, marital status, familial status, national origin, ancestry, age (40 and above), disability, veteran status, military service, application for military service, genetic information, receipt of free medical care, or any other characteristic protected under applicable law. 3DS will make reasonable accommodations for qualified individuals with known disabilities, in accordance with applicable law."
Cloud Data Engineer,Cloud Reach,Remote,https://www.indeed.com/rc/clk?jk=18d52350030f6c44&fccid=c4b9045533fdc061&vjs=3,"Cloudreach is the leading multi-cloud services provider. Our mission is to help companies navigate their unique journeys to the cloud and build new foundations for future growth. We’re a team of multi-cloud natives with certifications across AWS, GCP and Azure. Businesses that work with Cloudreach adopt cutting-edge technologies to solve challenges and create new opportunities. Working exclusively on public cloud, we deliver unrivaled value for more than 1000 enterprise clients globally. Behind our services are our Cloudreachers. We pride ourselves on being the go-to destination for curious, talented, and driven people looking for unique work experiences to maximize their potential. We are passionate about asking questions, finding solutions, playing with the latest tools & technology, doing our lives' work, and having fun along the way. You can learn more about our innovative culture, global workforce, and Cloudy Values on our website. We're not content with the status quo. We're here to do things better, and then do better things. What will your role be? The purpose of a Cloud Data Engineer is to enable data scientists and analysts to gain insights into data by architecting and implementing data-driven cloud based solutions. At Cloudreach, they will be subject matter experts and will be responsible for the technical leadership for data ingestion and processing engagements. A good understanding of cloud platforms and prior experience working with big data tooling and frameworks is required. Key Responsibilities Developer Peer Contribution / Mentoring Mentorship Customer survey results Personal Development What are we looking for? Technical Leadership Has experience successfully implementing simple enterprise solutions using a vast range of data engineering technologies. Has experience deploying and using the services in a major cloud platform. Works on tasks independently with little support from senior engineers. Delivers - Significant code contributions to more complex components of ETL pipelines. Writes test, test cases, and code documentation with a high level of detail. Skill mastery in a few areas. Stakeholder Management - Has guided & influenced customer stakeholders. Manages customer expectations on project deliverables. Aware of the customers political landscape beyond the technology. Clarifies and communicates internally customer objectives. Coding - Pushes back bad code and employs ETL best practices. Community Health - Moderates community content. Organises events. Encourages respectful discussion, behaviour serves as a role model. Marketing - Lead an external facing activity: 1 blog post or 1 event (examples being partner, meetup or conference) every 6 months. Optionally responsible for the technical mentorship and guidance of a team of up to 5 people, keeping members accountable for action items on IDP, owning initiatives. (May be externally called ""Tech Lead"") Certifications - Data Specialty Pro level CSP cert. Associate CSP cert on another platform. Experience Required Typically Bachelor’s degree with a number of years of professional experience. Qualified for positions that require professional accreditation. What are our perks? Meaningful and impactful work opportunities at a pioneering, cutting edge cloud services provider People-first mentality. We know that you and your mental health & wellbeing are #1. That’s why we give you an uncapped holiday allowance (+ your birthday off!), employee assistance programs, and resources to support your mental health & wellbeing. We embrace technologies that unlock agile & flexible ways of working. We respect our people to do their work when and how they work best. Work-life blend is a priority! Our dynamic work environment enables autonomy while also promoting a sense of belonging to a global community Opportunity for growth & development. Not only will you work alongside and learn from industry thought leaders, you will also be reimbursed for function-based certifications. We’re multi-cloud and proud! An inclusive workplace where varying backgrounds, ideas, and points of view are celebrated and the individual is respected, included and empowered to bring their whole self to work Transparency in business updates & communications. Whether you’re on the senior leadership team or a brand new employee, you’re an integral part of the team and we’ll make sure you know what’s up Recognition-rich company culture where daily wins are celebrated and individuals living out our values are applauded We strive to remove barriers, eliminate discrimination and ensure equal opportunity through our transparent recruitment process. We are open to all groups of people without regard to age, disability, marital status, gender identity, race, colour, sexual orientation, religion, military status, veteran status or any other legally-protected characteristic."
Data Systems Engineer,RingCentral,Remote,https://www.indeed.com/rc/clk?jk=f23e2fd4f3d6d354&fccid=1cbb498b08d4e46a&vjs=3,"Data/Systems Engineer It’s not every day that you consider starting a new career challenge. We’re RingCentral, a global leader in cloud-based communications and collaboration software. We are fundamentally changing the nature of human interaction—giving people the freedom to connect powerfully and personally from anywhere, at any time, on any device. We’re a $1.6 billion company that’s growing at 30+% annually and we’re expanding our Data Engineering & Data Analytics Team to make sure we stay ahead of the competition. Job Overview We are looking to hire a Data Systems Engineer to join our Data Operations team with a focus on systems support and deployment. You will be part of the team that is responsible for building out the architecture for ingestion. You will take responsibility for all things related to system maintenance, application support, deployment and pipeline engineering and support. This includes learning and understanding upstream processes, pipelines and source systems. The role will work in conjunction with other cross functional teams to help derive analytics and dashboards. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. Responsibilities: Architecting, Design, Building, Supporting systems for data ingestion. Monitoring and performance tuning. Work with a cross functional team of engineers, analysts and scientists to understand business requirements. Documenting architecture, systems, and pipelines. Documenting database design including data modeling, metadata and process flow diagrams. Highly available/resilient systems experience. What we’re looking for: 4+ years Systems Administration experience 4+ years of Application Administration experience Experience with Kubernetes, Helm, Docker, Kafka, Redis, Hazelcast, Spark Programming (Java, Python, Groovy ) Has experience with ANSI SQL Has experience with NOSQL (Elastic, Clickhouse ) Ability to create and maintain data pipelines Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources Participate in on-call rotation to support data pipelines and tools Qualifications: B.S in Computer Science etc. plus 2-3 years of experience Experience with management data pipelines/big data tools: StreamSets, Orchestration Framework (Airflow, Prefect), ELK etc Strong Linux familiarity, Linux system administrator skills are a plus Experience with one of AWS/Google public clouds Programming experience (at least one): Python, Java, etc Nice to have DevOps experience: Ansible, Jenkins, Chef etc Nice to have Anomaly Detection/Machine Learning experience Nice to have Telecom background Ability to work in very diverse multicultural environment Good communication skills Good team player with self-starter ability What we offer: Comprehensive medical, dental, vision, disability, life insurance Health Savings Account (HSA), Flexible Spending Account (FSAs) and Commuter Benefits 401K match and ESPP Flexible PTO Wellness programs, including 1:1 wellness coaching through TaskHuman and meditation guidance through Headspace Paid parental leave and new parent gift boxes Pet insurance Employee Assistance Program (EAP) with counseling sessions available 24/7 Rocket Lawyer services that provide legal advice, document creation and estate planning Employee bonus referral program RingCentral’s work culture is the backbone of our success. And don’t just take our word for it: we are recognized as a Best Place to Work by Glassdoor, the Top Work Culture by Comparably and hold local BPTW awards in every major location. Bottom line: We are committed to hiring and retaining great people because we know you power our success. RingCentral offers on-site, remote and hybrid work options optimized for the ways we work and live now. About RingCentral RingCentral, Inc. (NYSE: RNG) is a leading provider of business cloud communications and contact center solutions based on its powerful Message Video Phone™ (MVP™) global platform. More flexible and cost effective than legacy on-premises PBX and video conferencing systems that it replaces, RingCentral® empowers modern mobile and distributed workforces to communicate, collaborate, and connect via any mode, any device, and any location. RingCentral is headquartered in Belmont, California, and has offices around the world. If you are hired in Colorado, the compensation range for this position is between $101,000 and $152,000 for full-time employees, in addition to eligibility for variable pay, equity, and benefits. RingCentral is an equal opportunity employer that truly values diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Data Visualization Specialist III / Data Engineer (remote),AmerisourceBergen,Remote in Pennsylvania,https://www.indeed.com/rc/clk?jk=d07569ae88472808&fccid=a6362e26eb1427c7&vjs=3,"Are you looking to make a difference in a patient’s life? At AmerisourceBergen, you will find an innovative and collaborative culture that is patient focused and dedicated to making a difference. As an organization, we are united in our responsibility to create healthier futures. Join us and Apply today! What you will be doing Data Visualization Specialists / Data Engineer's are responsible for turning abstract information from data analyses into appealing and understandable visualizations that improve business insights from the results of the analyses. They are creative thinkers who understand user interface design and apply visualizations skills such as user experience design, data visualization and graphical design. Individuals in this role understand how information is turned into knowledge and how this knowledge supports and enables key business processes. They must have a good understanding of data access requirements for business analytics and exploration. Also required are analytical skills, the ability to establish and maintain effective working relationships with team members, as well as an innate curiosity around wanting to understand business processes, business strategy and strategic business initiatives to help drive incremental business value from enterprise data assets. Works on complex, major or highly visible tasks and projects as a project team member, sometimes as a DE lead. Works on projects that may span a broad range of technologies. Expertise in multiple technical environments and possesses business knowledge that spans one or more business areas. Participates in project planning processes. Identifies project tasks and leads or assists with project timeline estimations. Works with other team members and business stakeholders to drive development of business analytics requirements. Leverages knowledge of business processes and data domain. Brings deep expertise in data visualization tools and techniques in translating business analytics needs into data visualization and semantic data access requirements. Works with data engineers to facilitate technical design of complex data sourcing, transformation and aggregation logic, ensuring business analytics requirements are met. Leverages enterprise standard tools and platforms to visualize analytics insights, typically working with and/or leading a small team. Performs knowledge transfer around using data visualizations to business stakeholders. Helps drive business stakeholder adoption of insights-driven decision making and/or business process innovation. Drives development of and adherence to data visualization standards. May provide technical direction and oversee testing of business analytics solutions. May provide technical leadership for the definition and development of test plans and system documentation. Leads testing to ensure business analytics solutions meet user specifications. Provides technical leadership, coaching and mentoring to team members. Provides technical guidance or system process expertise. Participates in POC projects and provides business analytics solutions recommendations. Conceptualize, design and develop data visualization solutions that synthesize data concepts into clear communications for key business stakeholders. Drive adoption of data and insights-driven business decision making processes and analytics-enabled business process innovation. Demonstrate a strong sense of visual design and interest in creative visualization work. Assist in developing best practices for data presentation and sharing across the organization. Demonstrate an ability to reduce data to the bare minimum of what is needed to optimally communicate a message. Demonstrate a drive to learn new tools and new ways of visualizing/displaying data and insights. Show strong team building and creative thinking skills, and a desire to “make a difference”. What your background should look like Bachelor’s degree in Programming/Systems or Computer Science or other related field. Or equivalent work experience 5-10 Years of experience with data visualization/BI tools, such as Qlik or Tableau, SQL and semantic data access mechanisms. Experience in driving analytics-enabled business process innovation. Has a broad level of understanding surrounding business information systems. Experience in leading small project teams and streams. Demonstrated ability to analyze and interpret complex problems or processes that span multiple business areas, identify and understand requirements, and develop alternate solutions. Experience designing, developing and testing business Additional Desired skillsets and Qualifications: Healthcare or managed care experience Experience with Azure Boards / Azure DevOps Experience with Jira. Experience with data mining, predictive modeling techniques and using data to drive business outcomes and decisions Experience with SAP, BW HANA, BOB, SalesForce Power BI – experience creating dashboards and reports against SQL Server databases. Data Mapping – experience mapping tabular data sets at the column level from source to target including data types and data transformations/join criteria. T-SQL knowledge including: Table schema creation Select queries – including complex join scenarios Stored procedure execution Nice to have -> experience with Azure Synapse DB (formally known as Azure SQL Data Warehouse). Nice to have -> experience with data warehouses architected in either the Kimball or Inman modeling style. Azure – ADF & ADLS: familiarity with ADF (Azure Data Factory) pipeline creation / execution and experience working with the following activities: Execute pipeline Copy data Data flow Experience with ADLS (Azure Data Lake) / Azure Storage Accounts As of August 24, 2021, AmerisourceBergen requires all U.S. team members to be fully vaccinated and show proof of completed vaccine status at time of hire. If you cannot receive the COVID-19 vaccine due to a disability/medical reason or sincerely held religious belief you will be required to follow AmerisourceBergen’s policy and process to apply for an exemption/accommodation. What AmerisourceBergen offers We offer competitive total rewards compensation. Our commitment to our associates includes benefit programs that are comprehensive, diverse and designed to meet the various needs across our associate population. Throughout our global footprint and various business units, we take a balanced approach to the benefits we offer. Many benefits are company-paid, while others are available through associate contributions. Specific benefit offerings may vary by location, position and/or business unit. Schedule Full time Affiliated Companies Affiliated Companies: AmerisourceBergen Services Corporation Equal Employment Opportunity AmerisourceBergen is committed to providing equal employment opportunity without regard to race, color, religion, sex, sexual orientation, gender identity, genetic information, national origin, age, disability, veteran status or membership in any other class protected by federal, state or local law."
Data Engineer,Cornerstone Defense,"Chantilly, VA+5 locations",https://www.indeed.com/rc/clk?jk=8308c5e1f0659ea4&fccid=c4dad3c95358e466&vjs=3,"Data Engineer Clearance: TS/SCI with ability to obtain Polygraph within reasonable period of time Location: Chantilly, VA Company Overview: Cornerstone Defense, in partnership with our military, intelligence, and civil government customers, supports U.S. operations worldwide through the use of many different types of intelligence, satellite, and cyber technologies. Cornerstone’s Intelligence Sector provides solutions to the United States Government for information collection, operations, exploitation and dissemination, and research activities. Our Team specializes in software development, cloud architecture, systems and network engineering, systems integration, agile management, as well as targeting operations and intelligence analysis. Our support to our mission customers includes cyber network operations, exploitation and defense, signals intelligence, human intelligence, and critical missions and networks. We are looking for team-members with creative talent who are ready to take on the challenge of Data Engineer to work with collaborative teams to help expand and optimize the data ingestion pipeline architecture, develop strategies for efficient ingestion, processing, storage, structuring, and access. In addition, the Data Engineer will support data analysts, data scientists, and big data engineers in identifying data sources, performing exploratory data analysis, developing data models, ensuring data cleanliness and accuracy to provide new Insider Threat behavioral insights. Roles and responsibilities potentially include: Support data science team by designing, developing and implementing scalable ETL process for disparate datasets into a Hadoop infrastructure Design, develop, implement, and maintain data ingestion process from various disparate datasets using StreamSets (experience with StreamSets not mandatory) Develop processes to identify data drift and malformed records Develop technical documentation and standard operating procedures Leads technical tasks for small teams or projects Required Experience and Qualifications: Requires a Bachelor’s degree in Systems Engineering, or a related Science, Engineering or Mathematics field. 5+ years of job-related experience, or a Master's degree plus 3 years of job-related experience. Desired Experience and Qualifications: Working knowledge of entity resolution systems Experience with Hadoop and Hive/Impala Experience with messages systems like Kafka Experience with NoSQL and/or graph databases like MongoDB or ArangoDB Any of the following databases: SQL, MongoDB, Oracle, Postgres Working experience with ETL processing and Python Working experience with data workflow products like StreamSets or NiFi Working experience with Python RESTful API services, JDBC Experience with Cloudera Data Science Workbench is a plus Understanding of pySpark Leadership experience Creative thinker Ability to multi-task Excellent use and understanding of data engineering concepts, principles, and theories Data Engineer Clearance: TS/SCI with CI Poly Chantilly, VA We are looking for team-members with creative talent who are ready to take on the challenge of Data Engineer to work with collaborative teams to help expand and optimize the data ingestion pipeline architecture, develop strategies for efficient ingestion, processing, storage, structuring, and access. In addition, the Data Engineer will support data analysts, data scientists, and big data engineers in identifying data sources, performing exploratory data analysis, developing data models, ensuring data cleanliness and accuracy to provide new Insider Threat behavioral insights. Roles and responsibilities potentially include: Support data science team by designing, developing and implementing scalable ETL process for disparate datasets into a Hadoop infrastructure Design, develop, implement, and maintain data ingestion process from various disparate datasets using StreamSets (experience with StreamSets not mandatory) Develop processes to identify data drift and malformed records Develop technical documentation and standard operating procedures Leads technical tasks for small teams or projects Required Experience and Qualifications: Requires a Bachelor’s degree in Systems Engineering, or a related Science, Engineering or Mathematics field. 5+ years of job-related experience, or a Master's degree plus 3 years of job-related experience. Desired Experience and Qualifications: Working knowledge of entity resolution systems Experience with Hadoop and Hive/Impala Experience with messages systems like Kafka Experience with NoSQL and/or graph databases like MongoDB or ArangoDB Any of the following databases: SQL, MongoDB, Oracle, Postgres Working experience with ETL processing and Python Working experience with data workflow products like StreamSets or NiFi Working experience with Python RESTful API services, JDBC Experience with Cloudera Data Science Workbench is a plus Understanding of pySpark Leadership experience Creative thinker Ability to multi-task Excellent use and understanding of data engineering concepts, principles, and theories"
Data Center Operations Engineer,Meta,"Newton County, GA+42 locations",https://www.indeed.com/rc/clk?jk=bcb5b8770a794617&fccid=ba07516c418dda52&vjs=3,"Facebook is seeking an entry-level engineer with graduate level experience looking to apply their technical skills in a fast-paced and complex environment. A working knowledge of server hardware and the desire to participate in projects at a large-scale data center is central to this role. This position will work to resolve and diagnose compute issues at scale, escalate issues, and work with remote engineering teams. Additionally, this role will support rack lifecycle processes with a focus on helping build out and support cloud scale compute and storage environments. Solid communication skills are a requirement for this role. This person should enjoy working in a fast-paced environment where adaptability and flexibility will be key to their success.The candidate should also have working knowledge and experience in at least one of the following core areas: Networking, Programming/Scripting, Hardware, or OS repair. Data Center Operations Engineer Responsibilities: Work within Facebook's ticketing system First point of contact for break fix technicians Responsible for assisting with projects (retrofits, new process details, etc.) and repairs throughout the data center Understand and debug hardware and Linux OS related issues Identify and help create documentation for the global data center knowledge base Assist with process improvements and best practices in data center operations Participate in on-call rotation (once a month on call for a week, after hours, first point of contact) Minimum Qualifications: Must obtain work authorization in the country of employment at the time of hire and maintain ongoing work authorization during employment Experience modifying and developing in Python, SQL, and/or shell scripting Currently has, or is in the process of obtaining, a Bachelor's or Master's degree in technical field, or equivalent experience/certification Knowledge of Linux and server hardware support Preferred Qualifications: Working conceptual knowledge of technologies such as HTTP, DNS, RAID, and DHCP Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
Data Analysis / Engineer,AC HOME,"Houston, TX 77036 (Sharpstown area)",https://www.indeed.com/rc/clk?jk=93352fe04543c11f&fccid=0caa8fd88f711e54&vjs=3,"We are currently seeking an experienced Real Estate Analyst in the Houston area. This position will be integral to our online platform in analyzing and validating data for use by our staff and customers alike. An eye for detail and the ability to meet deadlines and finalize work will be needed for this position. With our fast growth, the potential to be lead in a team of analysis's is in the near future. Must be honest, energetic, with a strong work ethic. Description Provide services to end-users in planning, developing and deploying real estate data online Develop custom data repositories, content indexing and workflow Configure and administer services, User Profile Services, site metadata, and Excel services Provide system administration including, but not limited to, analysis, capacity planning, integration and quality assurance Promote online solutions and facilitate those solutions; identify practices and processes that can be improved Create reports for use internally as well as for clients with internal and external data Requirements Bachelor's degree or at least 4 years of equivalent work experience 3 years of experience Solid technical aptitude and leadership Strong analytical skills Strong verbal and written communication skills Experience in the real estate industry a plus Compensation Salary based on experience and performance bonuses contingent upon project completion on time and on budget.AC HOME has exciting opportunities waiting for you! Please submit your resume to HR@achome.com."
Data Engineer (REMOTE-USA),Conga,"Remote in Broomfield, CO+1 location",https://www.indeed.com/rc/clk?jk=10d5f566683c7491&fccid=d616bef817b643e8&vjs=3,"Conga crushes complexity within an increasingly complex world. With our revenue lifecycle management solution, we transform your unique complexities for order configuration, execution, fulfillment, and contract renewal processes with a single critical insights data model that adapts to ever-changing business requirements and aligns the understanding and efforts of every team. Our approach is grounded in the Conga Way, a framework of entrepreneurial spirit and achieving together to champion our 11,000+ customers. We’re committed to our customers and to removing complexity in an increasingly complex world. Our solutions quickly adapt to changing business models so you can normalize your revenue operations. Position Description We are seeking a Data Engineer to join Conga. You will transform business information into models by engaging and partnering with business users to solicit their requirements and iteratively refine the conceptual, logical, and physical data models. Work with application developers to determine the best representation for the data that supports business processes. Design models that reduce data redundancy, streamline data movements, and improve enterprise information management. Play a Key role in Enterprise Data Analytics initiatives to develop a data driven organization with an ""enterprise perspective"" rather than from a single business perspective. You are a self-starter, possess a strong commitment to detail and can work in a rapidly changing environment. Responsibilities: Proven experiences in an enterprise environment developing relational database and good understanding of industry standard techniques for data modelling; 3rd normal form relational modelling and dimensional Design and standup up a robust data warehouse to support to support reporting & analytics for internal stakeholders and clients. Create and maintain optimal data pipeline architecture. Provide scalable solutions to manage large imports and implement operational procedures as necessary Collaborate with business units to design and implement reporting solutions Work with cross functional teams across the business to ensure Enterprise Data Analytics (EDA) deliverables continue to be improved and add value to their business stakeholders. We are looking for a candidate with… Bachelor’s in computer science or related field, and a demonstrated pursuit of related continued education. 1+ years of experience with data engineering with emphasis on data analytics and reporting Expert experience with SQL and Relational database engineering—expert-level SQL abilities Understanding of relational database design and dimensional modelling (Oracle/SQL) A sound understanding of BI best practices, relational structures, dimensional data modeling, structured query language (SQL) skills, data warehouse and reporting techniques. Expert knowledge of metadata management and related tools Proven ability to work within set timelines and update management on deviation from these estimates. Has strong interpersonal communication skills; effectively communicates in verbal and written form Bonus Skillset: Introductory experience developing database solutions Introductory knowledge of building solutions with data visualization and reporting tools such as PowerBI, Tableau, etc. In the spirit of the Conga Way, we strive to communicate openly about our compensation programs. They’re intended to be competitive, equal, fair and free of any type of discrimination, clear, and easy to understand. So, in keeping with this approach, we’re committed to delivering a generous compensation and benefits package to all colleagues worldwide. The first component of that package is compensation and, generally speaking, base pay is determined by market location for each role. The following information is provided in accordance with the Colorado Equal Pay Act. The general salary target for this position in Colorado is $110,857.00 per year. However, the base salary offered may increase (or decrease) depending on the candidate’s job-related knowledge, skills, and experience. In addition to base salary, Conganeers receive a full range of perks and benefits, including financial, medical, and dental insurance. We also fund an annual bonus program, with payout based upon annual corporate performance and individual performance. #LI-HLH #LI-Remote Conga is proud to be an Equal Opportunity Employer and provides equal employment opportunities to all employees and applicants regardless of race, color, religion, gender, gender identity, age, national origin, disability, parental or pregnancy status, marriage and civil partnership, sexual orientation, veteran status, or any other characteristic protected by law. Reasonable accommodations will be made to meet the requirements of the Americans with Disabilities Act and will be provided as requested by candidates taking part in all aspects of the selection process. All your information will be kept confidential according to EEO guidelines. Conga is not open to third party solicitation or resumes for our posted FTE positions. Resumes received from third party agencies that are unsolicited will be considered complimentary."
Sr. Engineer II - FedRAMP Data Centers (Remote),CrowdStrike,Remote,https://www.indeed.com/rc/clk?jk=e0841a6121ec0b12&fccid=64e4cdd7435d8c42&vjs=3,"#WeAreCrowdStrike and our mission is to stop breaches. As a global leader in cybersecurity, our team changed the game. Since our inception, our market leading cloud-native platform has offered unparalleled protection against the most sophisticated cyberattacks. We’re looking for people with limitless passion, a relentless focus on innovation and a fanatical commitment to the customer to join us in shaping the future of cybersecurity. Consistently recognized as a top workplace, CrowdStrike is committed to cultivating an inclusive, remote-first culture that offers people the autonomy and flexibility to balance the needs of work and life while taking their career to the next level. Interested in working for a company that sets the standard and leads with integrity? Join us on a mission that matters - one team, one fight. About the Role: This senior role will be responsible for FedRAMP related needs in data centers. Segmented responsibilities may include: FedRAMP Data Center Environments Design Interconnectivity for connecting FedRAMP GovCloud environments (AWS Govcloud) Site Deployments Maintaining Servers and Infrastructure in Data Centers Data Center Development Site Reliability and Operation This role will be the person responsible for FedRAMP process related to data centers. This role will require the candidate to periodically undergo and pass additional background and fingerprint check(s) consistent with government customer requirements. Mentoring and developing engineers, and technicians such that they can run daily operations with minimal supervision Build and lead a diverse, data center operations team, developing both the technical capabilities and leadership qualities of individual contributors. Support and contribute thought leadership to the development and implementation of business practices which support the growth and ongoing management of our global data center footprint Ability to travel as needed Qualifications: 10+ year’s experience working in critical environments Experience with FedRAMP certification and operations Experience working in a cutting edge, technical, hands-on environment and leveraging technology to manage and grow environments. Experience in personnel management, organizational leadership, people development and team growth a plus Experience in influencing and leading a diverse group of people, partners suppliers across multiple disciplines a plus Knowledge of data center power, cooling, network, structured cabling, server and storage infrastructure Leadership experience making decisions with minimal direction and prioritizing across multiple competing demands Communication and collaboration experience #LI-Remote #LI-LY1 #LI-DG1 Benefits of Working at CrowdStrike: Remote-first culture Market leader in compensation and equity awards Competitive vacation and flexible working arrangements Comprehensive and inclusive health benefits Physical and mental wellness programs Paid parental leave, including adoption A variety of professional development and mentorship opportunities Offices with stocked kitchens when you need to fuel innovation and collaboration We are committed to fostering a culture of belonging where everyone feels seen, heard, valued for who they are and empowered to succeed. Our approach to cultivating a diverse, equitable, and inclusive culture is rooted in listening, learning and collective action. By embracing the diversity of our people, we achieve our best work and fuel innovation - generating the best possible outcomes for our customers and the communities they serve. CrowdStrike is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. CrowdStrike, Inc. is committed to fair and equitable compensation practices. For applicants in Colorado the salary range is $160,524 - $267,540 + bonus + equity + benefits. A candidate’s salary is determined by various factors including, but not limited to, relevant work experience, skills, and certifications. The salary range may differ in other states. CrowdStrike participates in the E-Verify program. Notice of E-Verify Participation Right to Work"
Data Engineer,Amun 21Shares,"New York, NY",https://www.indeed.com/rc/clk?jk=8a3b64bc77faf477&fccid=dd616958bd9ddc12&vjs=3,"Amun is a leading cryptocurrency issuer which aims to make purchasing crypto more accessible, and efficient. Under its 21Shares brand, Amun is the world's largest issuer of crypto exchange-traded products (ETPs). The 21Shares suite of ETPs has simplified access to crypto for both institutional and retail investors in the traditional finance community. In a similar fashion, Amun aims to provide tokens that will make it easy for the crypto community to access sophisticated strategies that are not otherwise readily available in this space. Amun 21Shares is a team of entrepreneurs, engineers, and financial product developers who are uniquely placed to revolutionize cryptocurrency investing through the issuance of our broad range of tokens. Our goal is to make these tokens present a new paradigm in cryptocurrency investing and to facilitate their use. About the Role: We are looking for a savvy Data Engineer to join our growing team of analytics experts. This hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. Our culture is about diversity, communication, collaboration and education. We are always working together across continents, building amazing experiences and learning along the way. What You Will Be Doing: Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure through multiple data centers and AWS regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems What you need to be great in this role: 5+ years of experience in a Data Engineer role Experience with big data tools: Hadoop, Spark, Kafka, etc. Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. Experience with AWS cloud services: EC2, EMR, RDS, Redshift Experience with stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Understanding Blockchain, or at least very curious about Blockchain and willing to learn and keep at the forefront of cryptocurrency continually Experience with Financial engineering and financial data - Big advantage Our Stack: AWS infrastructure Postgresql Node backend (Typescript, feathersjs) Vue and React on the frontend Python and Golang in the mix as well This position must be based in the New York office."
UNIDATA Data Engineer II,University Corporation for Atmospheric Research,"Remote in Boulder, CO 80305",https://www.indeed.com/rc/clk?jk=44c2b532d8976692&fccid=3e0354efeed7ce44&vjs=3,"Location: Boulder, CO (eligible for a fully remote work option) Application Deadline: This position will be posted until June 30, 2022, but priority will be given to applications received by June 17, 2022. Position Term: This position is a 2-year term position Relocation: Relocation assistance is available for this position. Work Authorization: UCAR/NCAR will not sponsor a work visa (e.g., J-1, H1-B, etc.) for this position. U.S. Citizenship, Permanent Residency, or other protected status under 8 U.S.C. 1324b(a)(3) is required for this position. Salary: Hiring Range $86,816 - $108,519 Full Salary Range $86,816 - $141,075 Benefits: UCAR's rich package of employee benefits includes medical, dental, vision, education assistance, retirement, and life insurance. UCAR offers a variety of programs designed to assist with work-life balance including flexible work alternatives, paid time off and 14 weeks of paid parental leave. To learn more about our benefits, visit this site: https://www.ucar.edu/opportunities/careers/benefits Vaccination Requirement: All employees hired by UCAR must comply with UCAR’s Covid-19 Vaccination Policy and safety protocols. Where You Will Work: The Unidata program exists to serve a community of researchers and educators dedicated to advancing the frontiers of Earth System science. While we share a set of long-term goals with our community, we are keenly aware that we play a significant but supporting role in their ongoing scientific and educational endeavors. As a practical matter, we look for things we can do now to help build the future our community seeks to achieve, realizing that the goals will evolve and our approach must be flexible. We also aim to sustain and enhance a community that capitalizes on new technology and approaches to advance our understanding of the Earth System, providing community leadership and support. With these things in mind, Unidata’s mission is ""To transform the geosciences community, research, and education by providing innovative data services and tools."" What You Will Do: The Data Engineer will be working within the Unidata program as an atmospheric science data expert and consultant. Unidata is a diverse community of education and research institutions with the common goal of sharing geoscience data and the tools to access and visualize that data. For more than 30 years, the Unidata Program Center (UPC) has been providing data, software tools, and support to enhance Earth-system education and research. As a Data Engineer, you will play a vital role in serving the Unidata Community in the area of data access and support across all practical levels — information dissemination, documentation, data advocacy, cross-organization collaboration, and training. Unidata's small team environment provides for high levels of autonomy and responsibility with great opportunity to excel individually and contribute to the community's success. Funded primarily by the National Science Foundation (NSF), Unidata is one of the University Corporation for Atmospheric Research (UCAR)'s Community Programs (UCP). Responsibilities: Liaison To Data Providers: Maintain effective relationships with industry data providers, including major data centers (WMO, NASA, NOAA, ECMWF, JMA, EUMETSAT, CMC, INPE, etc.), as well as cultivating contacts and relationships with data sources in the Unidata Community. Maintain knowledge about the data available in the various Unidata Internet Data Distribution (IDD) data feeds, the entities providing the data, and identify other sources with additional data of interest to the community that might be willing to contribute.. Disseminate information about any potential changes to the IDD data feeds, the nature of the changes, and how they would impact Unidata software, the Unidata Community, and other stakeholders. Research new types of data for the community and advocate for data access from providers when needed. Facilitate any negotiations of “terms of data use” and distribution between the UPC and data providers. Participate in efforts to maintain and promote industry data standards across the Unidata Community. Maintain knowledge of public datasets hosted by cloud providers that are of potential interest to the Unidata Community Help Maintain Data Infrastructure: Maintain a fundamental knowledge of the Unidata data infrastructure and participate in its maintenance. Provide oversight, organization, and the chance to implement a standard approach to data infrastructure maintenance and operation. Understand and monitor health of the IDD data feeds and regularly examine and update configuration files as needed. Understand and contribute to satellite data ingest infrastructure (both hardware and software). Maintain data information on the Unidata website(s). Explore ways to generate data volume numbers and metrics on demand. Investigate potential new methods and services for providing data to the Unidata Community Data Liaison To The Unidata Community: Act as an advocate and point of content for data-related topics for the Unidata Community. Educate, inform, and train the Community about ways to access data via Unidata’s data servers and distribution venues (ADDE, TDS, EDEX, IDD, etc.) Maintain knowledge of the Unidata Community’s data environment and have a comprehensive understanding of the use cases for Unidata’s significant subcommunities; including knowing what data is being used, not used, or underused. Collaborate with the Unidata Community members and UPC developers to identify potential bottlenecks or issues in the Unidata data distribution processes, as well as make recommendations for improvements in Unidata data software. Disseminate pertinent data information to the Community, including upcoming opportunities or changes regarding data feeds. Provide data-related support to the community, in particular the IDD and its data feeds. Resource For UCP Developers: Maintain a high level understanding of the Unidata software stack and the types of data used within each package. Inform UPC developers of data service change notices and how the changes may impact each Unidata software package. Support developers by answering questions about data (availability, format, frequency, source), as well as provide information about the usage of the various types of data repositories and test datasets. Foster interactions with UPC staff and the Unidata Community in an effort to anticipate and estimate current and future data and software needs. Miscellaneous: Provide input on progress reports and presentations for the Unidata advisory committees. Participate and present at scientific meetings to keep up-to-speed on community needs and to communicate directly with our stakeholders. What You Need: Education and Years of Experience: Bachelor’s degree in atmospheric; or related sciences Progressive, relevant experience which is typically gained by 4 to 8years of experience with atmospheric scientific data services; Or equivalent combination of education and experience. Knowledge, Skills, and Abilities: Strong domain knowledge and expertise with atmospheric science data and datasets. Experience with geoscience data formats (e.g. netCDF, HDF, GRIB, BUFR, GeoTIFF). Ability to work in a small team environment in various roles with high levels of autonomy. Ability to organize and communicate technical material to other developers and end-users. Strong desire to continue learning new skills, tools, and concepts. Desired but not required: Experience with shell scripting or other programming languages. Experience with basic unix systems administration and/or package-management maintenance of unix servers. Experience with one or more cloud computing technology stacks (e.g. AWS, OpenStack, Google Cloud Platform, Microsoft Azure). Experience with remote data access protocols (e.g. DAP, WMS, WCS). Experience with web services, such as RESTful and RPC-based APIs Experience providing support to a scientific community. Experience with teaching or instructional training of technical topics. Applicant Notes: A cover letter is required when applying to this position. An Inclusion Statement will be required for all applicants moving forward to the interview stage. This statement should address past efforts, as well as future vision and plans to advocate for and advance diversity, equity, and inclusion in the organization and/or field of work. Please note that while the position description details both minimum requirements as well as desired skills and experience, we want to remind applicants that you do not need to have all the desired skills and experience to be considered for this role. If you have the passion for the work along with experience in a related field, you are encouraged to apply. We can provide on-the-job training for the rest. For more information about our commitment to diversity, equity, and inclusion, here is the link to the Office of Diversity, Equity & Inclusion Strategic Plan and to the ODEI landing page . A pre-employment screening is conducted in conjunction with an offer for employment. This screening may involve verifying or reviewing any of the following relevant information: restricted parties screening, employment verification, performance records of internal candidates, education verification, reference checks, verification of professional licenses, certifications, and Motor Vehicle Records. UCAR complies with the Fair Credit Reporting Act (FCRA). The University Corporation for Atmospheric Research (UCAR) is an equal opportunity/equal access/affirmative action employer that strives to develop and maintain a diverse workforce. UCAR is committed to providing equal opportunity for all employees and applicants for employment and does not discriminate on the basis of race, age, creed, color, religion, national origin or ancestry, sex, gender, disability, veteran status, genetic information, sexual orientation, gender identity or expression, or pregnancy. Whatever your intersection of identities, you are welcome at the University Corporation for Atmospheric Research (UCAR). We are committed to inclusivity and promoting an equitable environment that values and respects the uniqueness of all members of our organization."
Data Engineer,Cognite AS,"Houston, TX+1 location",https://www.indeed.com/rc/clk?jk=654737aeea5b10a2&fccid=1879b2974e0c1e47&vjs=3,"Do you see how data can be used, modeled and visualized in new ways to improve decisions in industrial engineering, but you experience that the tools and data availability is insufficient to create impact? If you want to change that, and take part in forming what the future of the industry will look like you should join our Cognite and become a part of the team responsible for delivering Cognite’s cutting edge industry solutions to our customers! As a Data Engineer, located in Houston, TX, you will design, develop and implement data infrastructure and best-in-class pipelines that collect, connect, centralize and curate data from various internal and external data sources. You will ensure that architectures support the needs of the business, and recommend ways to improve data reliability, efficiency. You are an experienced engineer with a passion for software development, hands-on in designing, implementing, and delivering features for flagship products. What You'll Do Partner with Solution Architects to understand client requirements and define queries with subject matter experts Develop custom extractors using backend technologies and languages i.e Python, Spark, Rest APIs Customize existing extractors i.e. database extractor using SQL, event streaming using Kafka and deploy using Docker Create custom data models for data discovery, mapping, and cleansing Collaborate with product development to turn customer needs into potential product offerings Prototype data visualization and dashboards Who You Are 3+ years of experience in a Data intense role Experience in O&G, Power & Utilities and/or Manufacturing is required BS or MS degree in computer science or related field Loves to code, passion for coding, and enjoys sharing that knowledge with others Strong understanding of data analysis or data science Experience working with data technologies, such as: ETL, SQL, Python Ability to work on both internal and external client-facing projects and communicate with key stakeholders Ability to travel onsite to meet with and engage with clients - we don’t build solutions in isolation. Role based in Houston, TX or (Austin, TX w/ travel to Houston) What Makes Us Great An opportunity to make an impact on the industrial future and be part of disruptive and groundbreaking global projects High level of autonomy, ability to influence decisions and to learn from mistakes Work along side a driven, engaging team with in-depth software expertise and industry experience Opportunity to join Together@Cognite for social, community, and diversity initiatives Focus on agility and speed, openness, togetherness, impact, and obligation to speak up Join a team that truly lives their values and brings their whole selves to Cognite -> watch some of our Cognite Voices Katrine Tjølsen, Petter Reistad. Perks & Benefits Competitive Compensation + 401(k) with employer matching Health, Dental, Vision & Disability Coverages with premiums fully covered for employees and all dependents Unlimited PTO + flexibility to enjoy it Paid Parental Leave Program Learning & Development Stipends Global Mobility & Exchange Program Company Paid Friday Lunch via DoorDash + Fully Stocked Fridges in the offices Cognite is a global industrial SaaS company that was established with one clear vision: to rapidly empower industrial companies with contextualized, trustworthy, and accessible data to help drive the full-scale digital transformation of asset-heavy industries around the world. Our core Industrial DataOps platform, Cognite Data Fusion™, enables industrial data and domain users to collaborate quickly and safely to develop, operationalize, and scale industrial AI solutions and applications to deliver both profitability and sustainability. Equal Opportunity Cognite is committed to creating a diverse and inclusive environment at work and is proud to be an equal opportunity employer. All qualified applicants will receive the same level of consideration for employment; everyone we hire will receive the same level of consideration for training, compensation, and promotion. We ask for gender as part of our application because we want to ensure equal assessment in the recruitment process. Your answer will help us reach this commitment! However, the question about gender is optional and your choice not to answer will not affect the assessment of your application in any way."
Data Engineer,SimulStat,Remote,https://www.indeed.com/rc/clk?jk=f705683265de9b0c&fccid=8637215ace5fab49&vjs=3,"Apply Now Long-Term, Remote FSP role The Data Engineer is responsible for the development and implementation of optimal solutions to transform, integrate, store, secure, process and update large real-world healthcare data assets for use by statistical programmers, data scientists and other data analysts. Relevant database administration experience includes: Extensive knowledge of developing data pipelines using real-world healthcare data including claims and electronic medical records. Experience with one or more of the following commercial databases: MarketScan, Optum, DRG, Flatiron, JMDC, CPRD. Experience with the OMOP data model and optimization of healthcare data for observational research or epidemiology analysis use cases. Familiarity with medical coding, such as ICD-9, ICD-10, LOINC, NDC, CPT/HCPCS, SNOMED. Familiarity with big data processing platforms including Hadoop, AWS S3 and Databricks. Experience with enterprise support models for data management, security, database programming, service delivery, performance monitoring, and user support standards. Experience with conversion of raw data in ASCII or other formats into OMOP, Parquet or others, and storage in HDFS or S3. Troubleshooting data errors and developing mitigation plans. Strong communication and documentation skills for describing issues with data and potential remedies. Experience with database tuning techniques such as normalization, indexing, and parallel processing technologies is desirable as is experience with scripting languages such as Unix shell scripts and PERL. Additional responsibilities include the following: Ensuring data are consistent across the database Minimizing redundancy across the database Checking variable values for reasonableness Develop database tools to improve database efficiency and utility Building data pipelines for access to research data Managing vendor relations and communication Basic Qualifications: Bachelor’s degree in in Computer Science, Statistics, Mathematics, Life Sciences or other relevant scientific subject. Minimum 5 years relevant data asset curation experience (description above) Extensive experience using the OMOP common data model and ETLs Excellent SAS programming skills and the ability to implement complex data step logic and SQL. Experience with ETL software Experience with real world healthcare data, such as MarketScan, Optum, PharMetrics, Medicare and/or EMR databases Preferred Qualifications: Master’s degree in Epidemiology, Biostatistics, Computer Science, or other subject with high statistical content Eight (8) or more years relevant data asset curation experience (description above) Proficiency with Python is highly desired as well as ability to implement and troubleshoot complex ETL and QC programs. Experience in a regulated environment Vendor relations management Pharmaceutical industry experience Training or experience with the Hadoop database platform and Impala or Hive SQL Experience in software development & design life cycle, ideally using Agile methodology Experience using ODBC (Open Database Connectivity) Knowledge: Computer programming with SAS, R, Python or other procedural languages Database transformation, testing, cleaning and quality control using SQL Understanding of computer operating systems, including cloud-based Databricks and UNIX Software development and design Key Competencies: Technical excellence Innovation Teamwork Problem solving Attention to detail Oral and written communication Apply Now"
Data Senior Engineer,City National Bank,"Los Angeles, CA",https://www.indeed.com/rc/clk?jk=5d84c620343518ef&fccid=55a861ecd89109ee&vjs=3,"DATA SENIOR ENGINEER - TECHNOLOGY WHAT IS THE OPPORTUNITY? The Data Engineer Senior works with department and lines of business subject matter expert (SMEs) across the enterprise to meet departmental and organizational objectives. The engineer will follow end-to-end process standards and guidelines to ensure accurate and efficient build out of data pipeline architecture within project timeframes. Technology and Innovation Division As a member of City National's Technology & Innovation group, you will drive, develop, and maintain solutions for clients and colleagues. This is an exciting time of technology advancement and innovation across the bank, particularly within our technology teams. WHAT WILL YOU DO? Function in accordance with the Software Development Life Cycle (SDLC) framework and governance processes Participate in development of test plans and perform quality assurance and testing of own work and that of peers Function in accordance with the Software Development Life Cycle (SDLC) framework and governance processes Ensure work includes necessary audit controls such as Audit, Balance and Control (ABC) Framework and security controls within all design and deliverables Document data workflows including but not limited to: functional specs, technical specs, mapping / workflow diagram, testing plans, production “run books”, training materials, etc. Accurately define and execute transformations, aggregations and other data manipulations to meet requirements Participate in development of test plans and perform quality assurance testing of own work and that of peers Identify development and data quality issues and work with senior team members and management to mitigate Conduct peer and team review sessions Assist in the creation of standards, templates and procedures for the department Contribute to the design of the data structure/data model and data flow Design and develop data workflows and mappings to extract, transform, and load data for purposes of analytics , reporting and integration WHAT DO YOU NEED TO SUCCEED Must-Have* Bachelor's Degree 5+ years of relevant experience Skills and Knowledge Advanced senior professional with wide ranging experience uses professional concepts and to resolve complex issues in creative and effective ways Perform various tasks to design and deliver data pipeline solutions with accuracy, reliability, and quality. Requires specialized depth and or breadth of expertise Compensation Starting base salary: $119,012 - $154,574 per year. Exact compensation may vary based on skills, experience, and location. This job is eligible for bonus and/or commissions. To be considered for this position you must meet at least these basic qualifications The preceding job description has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. INCLUSION AND EQUAL OPPORTUNITY EMPLOYMENT City National Bank is an equal opportunity employer committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or any other basis protected by law. ABOUT CITY NATIONAL We start with a basic premise: Business is personal. Since day one we've always gone further than the competition to help our clients, colleagues and community flourish. City National Bank was founded in 1954 by entrepreneurs for entrepreneurs and that legacy of integrity, community and unparalleled client relationships continues to drive phenomenal growth today. City National is a subsidiary of Royal Bank of Canada, one of North America’s leading diversified financial services companies. Positions based in New York City: In order to work on-site at City National Bank in New York City, you must be fully vaccinated against COVID-19, per city requirements. Shortly after your start date, you will be required to attest to your vaccination status and will be required to provide proof of vaccination. Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled"
Data Engineer,auticon,"Remote in Columbus, IN",https://www.indeed.com/rc/clk?jk=ef90b2d87fcc5dde&fccid=a5551b6a900b917f&vjs=3,"If you have an autism diagnosis and are looking for a career in tech in a great work environment, we want to hear from you. auticon is hiring Data Engineers – from junior (minimum 1 year professional experience, see skills and qualifications for specifics) to senior level professionals – to help our clients tackle fascinating and challenging data problems. We’re seeking people who are adept at building data pipelines that can source, clean, and normalize data at scale; or, create data scalable streaming applications; or, integrate systems in new or creative ways. We realize that getting and keeping a job can be challenging, so we’re on your side. We provide a professional auticon Job Coach and Technical Leader in an accommodating work environment to help you succeed. The skills and main responsibilities for this role are below, but you do not have to meet all of them to apply! The Role: Because our clients face many new challenges, our data engineers need strong creative problem-solving skills and the technical background to implement solutions. Data may be acquired from multiple sources, and this requires an understanding of data architecture principles and engineering experience to prepare this data for our client’s use cases. The ideal candidate will love automating data pipelines, cleanse and transform data, developing controls to monitor the quality of data, participating in governance, schema development, establish integration patterns, and documenting their work. Responsibilities: Stitch and normalize sparse and noisy data across various data sources Undertake pre-processing of structured and unstructured data Design, develop, implement, test, and support technical solutions in full-stack development tools and technologies Work with a team of developers with deep experience in machine learning, analytics, distributed microservices, or full stack systems Utilize programming languages like Python, Java, Scala, Ruby, or Elixir and Open Source RDBMS, streaming, messaging, or cloud-based data warehousing services Collaborate with engineering and product development teams Deliver on timeline commitments where necessary Preferred Qualifications (you do not have to meet all to apply): 1+ years of relevant professional work experience Includes: Paid and unpaid work, full-time/part-time work, freelance professional work (paid or unpaid, client or family/friend), internships Does not include: College courses or personal projects Work experience does not have to be consecutive Experience with all stages of the product development cycle especially designing, developing, and supporting a complex software solution while maintaining engineering best practices including defect tracking, design reviews, and appropriate testing Proficient in SQL and/or NoSQL Strong organizational and problem-solving skills Pragmatic, product-oriented approach Ability to work cross-functionally with minimal supervision BS in Computer Science, Electrical Engineering, Mathematics, Statistics, Physics, or similar quantitative fields. Experience with cloud environments (e.g., AWS, GCP, Azure) Experience in application development Experience in at least one scripting language (e.g., Python, Ruby, Perl, JavaScript, Shell) Experience working on streaming data applications Experience with Agile engineering practices Experience with UNIX/Linux including basic commands and shell scripting Experience with at least one DevOps technology (e.g., Ansible, Terraform, SaltStack, Kubernetes) Applicants must now and in the future be legally eligible to work in the US for any employer. auticon does not provide visa sponsorship or transfer for this opening. Apply now Please send an email to with your resume attached, briefly stating whether or not you have an autism spectrum diagnosis and what your expertise is. auticon provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training."
"Engineer, Data Engineering",Samsung Electronics,"Ridgefield Park, NJ 07660+5 locations",https://www.indeed.com/rc/clk?jk=01ce3adc9a33a79e&fccid=da3c7fed78dd1607&vjs=3,"Position Summary For decades, Samsung has been leading the charge on innovation. We see beauty in achieving excellence and our passion for change fuels our discoveries, inventions, and breakthrough technology. We believe that technology can, and should, make the world a better place, so we create new possibilities for people everywhere, push the limits of what’s possible, and constantly innovate. At Samsung Electronics America, we take pride in the creativity and diversity of our talented people – they are at the forefront of everything we do. Their skillset and mindset drive our continued success. Only the resilient and resourceful thrive in the daily dose of unexpected at Samsung. We unapologetically push to achieve unforeseen potential in everything we do, both within the workplace and at home. We fearlessly face challenges head-on, conquer the unconquerable, and are comfortable living in the uncomfortable zone. Together we make the impossible possible. Because at Samsung, we Own the Unknown. Are you ready to #OwnTheUnknown? Join us. BUSINESS UNIT LANGUAGE “Sizzle”: Role and Responsibilities The main function is to work closely with Business and other stakeholders on data analysis and reporting needs for specific projects critical to the Samsung organization. Other responsibilities may include maintaining all project management processes, including project goals, deadlines, and metrics. Specific responsibilities include: Build understanding of business and operational strategies and identify critical metrics required to support those strategies Obtain, document and analyze reporting needs and requirements for key projects through collaboration with cross-functional teams Develop and maintain dashboards to visualize data utilizing Tableau Work across functional lines to strive for and ensure consistent data quality Automate data preparation and report creation where possible Provide increased focus on analytics and emphasize on providing valuable insights to drive improvement opportunities Work with executives and other business leaders to identify opportunities and develop forecasts for future proposals Ability to handle various data sources, using data modeling work to develop reporting capabilities and valuable insights across data sources Skills and Qualifications Skillsets Required: Strong analytical and problem-solving skills, ability to digest large amounts of data from primary and secondary sources Verbal and written communication skills, attention to detail, and interpersonal skills. Excellent critical thinking skills to help solve business problems and make decisions Demonstrated ability to manage time and prioritize projects to meet deadlines Excellent attention to detail Education/Experience: Bachelor's degree in business management, economics, finance, accounting or relevant field required Strong experience with visualization solution such as Tableau, Power BI preferred Good knowledge of Microsoft Excel required Good knowledge of SQL scripting required 5+ years’ experience required Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law. COVID-19 Vaccine Mandate In order to comply with the federal vaccine mandate, Samsung Electronics America requires all employees to be fully vaccinated against COVID-19, unless a medical or religious exemption, or an exemption required under state/local law, is approved. Offers of employment are contingent upon proof that a candidate is fully vaccinated or qualifies for an exemption. More details on how to apply for an exemption are provided after the application process is complete. Reasonable Accommodations for Qualified Individuals with Disabilities During the Application Process Samsung Electronics America is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application process. If you have a disability and require a reasonable accommodation in order to participate in the application process, please contact our Reasonable Accommodation Team (855-557-3247) or SEA_Accommodations_Ext@sea.samsung.com for assistance. This number is for accommodation requests only and is not intended for general employment inquiries."
Data Engineer II,MasterCard,"San Francisco, CA+3 locations",https://www.indeed.com/rc/clk?jk=d60d60a0eaf4a2db&fccid=10b5c722d846df43&vjs=3,"Our Purpose We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a culture of inclusion for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results. Job Title Data Engineer II Have you ever wondered how do you see offers on your credit card based on your past purchase? If you wanted to find the answer do join our team. We are looking for a Data Engineer to not only build data pipelines but also extend the next generation of our data tools. As a Data Engineer, you will develop a clear sense of connection with our platform - as Data Engineering is the eyes through which they see the product. Data Engineer Responsibilities System development and maintenance activities of the team to meet service level agreements and create solutions with innovation, cost effectiveness, high quality and faster time to market. Support code versioning, and code deployments for Data Pipelines. Ensure test coverage for unit testing and support integration and performance testing. Contribute ideas to help ensure that required standards and processes are in place. Research and evaluate current and upcoming technologies and frameworks. Build data expertise and own data quality for your areas. Minimum Qualifications 2+ years of Java/Scala development experience. 2+ years of SQL experience. 1+ years of extensive experience with Spark Processing engine. 1+ years of experience with Big data tools / technologies (Hive, Impala, OOZIE, Airflow, NIFI) 1+ years experience with Data Modeling. Experience analyzing data to discover opportunities and address gaps. Experience working with cloud or on-prem Big Data platform(i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar). COVID-19 Considerations We value the safety of each member of our community because we know we’re all in this together. In many locations, which may change over time, we’ve implemented a virtual hiring process and continue to interview candidates by video or phone. In addition, in some locations, only individuals who have been fully vaccinated will be permitted inside Mastercard offices until further notice. In the US, Mastercard is a government contractor, which may legally require most Mastercard employees to be vaccinated unless a verified approved medical or religious exemption is granted. Further, we are currently making every effort towards having employees return to work in the office 2 days per week, if that makes sense for their team. Everyone must be vaccinated to enter Mastercard offices at this time. Therefore, we expect all candidates to be vaccinated or to be approved for a medical or religious accommodation prior to commencing work at Mastercard. In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly. Corporate Security Responsibility All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must: Abide by Mastercard’s security policies and practices; Ensure the confidentiality and integrity of the information being accessed; Report any suspected information security violation or breach, and Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines."
Data Engineer,wpromote,"Remote in Atlanta, GA+5 locations",https://www.indeed.com/rc/clk?jk=6c62a7b671892b1a&fccid=dd456b751b733408&vjs=3,"The Role We are looking for a Data Engineer to join and lead our growing Data Enablement team. In this role, you’ll design data engineering solutions for enterprise e-commerce, omnichannel retail, lead gen, and app-based clients with a variety of different MarTech/AdTech stacks. You’ll plan how data needs to flow across each client’s MarTech stack so the data can be used in Polaris, Wpromote’s proprietary tech platform. You’ll build data models within Polaris using BigQuery, designing them for use across Polaris reporting, apps, and media forecasting. The ideal candidate will be driven by a desire to design novel, elegant, and efficient solutions to data challenges that can then be automated and productized. They will enjoy the challenge of learning how to solve data engineering challenges with new ad platforms, mobile measurement partners, and analytics platforms our team has never seen before. At Wpromote, we believe that great work is only possible with great people. Our goal is to build a better, more inclusive work environment and support our people at every stage of their careers by prioritizing a strong work-life balance through policies like unlimited PTO, half-day Fridays year round, flexible schedules, work from anywhere options, 100% paid parental leave, and 401(k) matching. As a Best Place to Work according to both Ad Age and Glassdoor and Adweek’s Fastest Growing Digital Agency, we are moving fast to expand our teams and bring new experts into the fold to keep pushing the boundaries of what’s possible in marketing. If you reside in Colorado, please click this link to view Colorado compensation information and apply for this role. Residents of all other states are encouraged to apply to this posting. Compensation packages for employees and applicants outside Colorado may differ from the Colorado compensation information and are based on a wide array of factors unique to each candidate and location, including but not limited to skill set, years & depth of experience, education and certifications, and geographic location. This may differ in other locations due to cost of labor considerations. **This position may be performed remotely in most states within the US, with some exclusions ***This position is not eligible for immigration sponsorship #LI-JJ #LI-Remote You Will Be Mentoring and training junior Data Engineers and helping build team processes, such as QA Gathering data source, data joining, data model, and data transformation requirements from stakeholders (clients and internal teams) and working with the Reporting Solutions team to develop dashboards and Google Sheet outputs to validate data quality Managing and monitoring multiple data pipelines and ETL tasks related to multiple client data streams Assisting in the creation of a reliable and scalable infrastructure for data model builds, data set QA, and data set outputs Working with data integration managers, reporting solutions managers, client service team members, paid media channel managers, data analysts, and client-side marketing managers to understand and then execute against data transformation, data model, and inbound/outbound data pipeline requirements Experienced with one or more scripting languages (e.g. Python, R, Shell) to update or troubleshoot existing scripts for basic BI use cases (e.g. data transformations, statistical tests and analyses, process automation) You Must Have 3-4 years of experience in reporting, BI, or data engineering Advanced level Excel and Google Sheets experience Strong knowledge of database and data warehousing design and management Understanding of ETL process and data modeling experience using SQL, including Data Definition Language (DDL) and Data Manipulation Language (DML) Create and maintain documentation including requirements, design Experience reviewing existing processes and methods in order to identify possible opportunities for increasing efficiencies Solid attention to detail with the ability to debug and troubleshoot code/queries Excellent communication skills (verbal and written) to present effectively and to explain algorithms and insights to major non-technical stakeholders Curiosity to continuously learn more about programming and digital marketing Familiarity with at least one BI solution (ex: Power BI, Tableau, Data Studio, Looker, Funnel, Domo, Datorama, MicroStrategy, etc.) and willingness and ability to quickly learn and become proficient across DataStudio, Tableau, Looker, and Power BI Knowledge with at least 1 cloud platform (ex: BigQuery, Snowflake, Redshift, etc.) and willingness and ability to learn and become proficient in BQ Proficiency with at least 1 programming language (ex: Python, JavaScript, R, AppScript, etc.), preferably JavaScript or Python A collaborative mentality with the ability to work independently General business and marketing data acumen including an understanding of common marketing goals, KPIs, and tactics. Nice To Have Experience leading and managing other Data Engineers Intermediate to advanced programming skills in Python Experience creating API calls for the purposes of gathering and storing large datasets (batch or streaming)Familiarity with CRM data Familiarity with the command line program Experience with data visualization and storytelling practices Ability to generate insights from data in the form of refined tabular and graphical reports, metrics, and ad-hoc analysis Understanding of cloud solutions such as S3, BigQuery, Airflow, dbt, etc. is a plus (ex: GCP, AWS, Azure)Familiarity with Git Working experience with digital media platforms (ex: Facebook, Google Ads, The Trade Desk, etc.)Knowledge/experience in the digital marketing industry Experience and/or certification in web analytics platforms (ex: Google Analytics, Adobe Analytics, etc.) Wpromote is committed to bringing together individuals from different backgrounds and perspectives, providing employees with a safe and welcoming environment free of discrimination and harassment. We strive to create a diverse & inclusive environment where everyone can thrive, feel a sense of belonging, and do impactful work together. As an equal opportunity employer, we prohibit any unlawful discrimination against a job applicant on the basis of their race, color, religion, gender, gender identity, gender expression, sexual orientation, national origin, family or parental status, disability*, age, veteran status, or any other status protected by the laws or regulations in the locations where we operate. We respect the laws enforced by the EEOC and are dedicated to going above and beyond in fostering diversity across our workplace. Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and certain state or local laws. A reasonable accommodation is a change in the way things are normally done which will ensure an equal employment opportunity without imposing undue hardship on Wpromote. This employer participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S. If E-Verify cannot confirm that you are authorized to work, this employer is required to give you written instructions and an opportunity to contact Department of Homeland Security (DHS) or Social Security Administration (SSA) so you can begin to resolve the issue before the employer can take any action against you, including terminating your employment. Employers can only use E-Verify once you have accepted a job offer and completed the Form I-9. For more information on E Verify, or if you believe that your employer has violated its E-Verify responsibilities, please contact DHS."
Data Scientist (Machine Learning Engineer),Certilytics,United States,https://www.indeed.com/rc/clk?jk=fef59b1c069e0fc4&fccid=a6a761b598113fc6&vjs=3,"About Us Certilytics provides sophisticated predictive analytics solutions to major healthcare organizations by integrating financial, clinical, and behavioral insights. Our team represents a dynamic infusion of multidiscipline, which includes actuarial, data and behavioral scientists, IT engineers, software developers, nurse clinicians, as well as experts in public health and the health insurance industry. Certilytics has extensive experience working with a diverse set of customers including large self-insured employers, health plans, pharmacy benefit managers, government programs, care management companies and health systems. These relationships with various data providers and customers allows for rapid data ingestion, validation and enrichment as well as streamlined delivery of analytic dashboards, outputs and visualizations to our customers. Our unique approach allows for the development of the most accurate financial, clinical and behavioral models in the industry. The Role We’re looking for a well-rounded data scientist/machine learning engineer to join the Data Science team at Certilytics. At a high level you'll be responsible for designing and running experiments to bring the latest deep learning advances from the literature to our products. From a day to day perspective you will be tasked with building deep learning models and pipelines for deployment and contributing to proprietary machine learning libraries. The ideal candidate will have a strong background in multi-modal modeling, natural language processing (Seq2Seq, NMT, and/or text based classification models) and familiarity with the inner workings of recurrent and transformer neural networks. What You'll Accomplish Research new ideas, new models, and new methodologies. Develop proofs of concept and answer research questions relevant to Certilytics and our models. Build production grade deep learning pipelines. Write research-quality documentation to demonstrate the theoretical grounding of our work. Required Skills What You’ll Need Data science related programming skills as evidenced by 1-3 years of hands on experience with deep learning (Tensorflow) and scripting languages, preferably Python. You should also be familiar with Git and Markdown and possess a solid grasp of algorithms and data structures. Graduate level statistical and mathematical background via a Masters in a quantitative discipline (eg. statistics, mathematics, physics, computer science, operations research). Strong writing skills in academic-style writing. Ability to collaborate across teams and answer complex questions that arise from various teams. Ability to distill difficult concepts down to layman’s terms. Comfort with data big and small. How to stand out! You have implemented a deep learning model pipeline in production. You have published in an academic journal, conference, or similar. Domain experience in a healthcare-related industry. You have performed custom deep learning model or layer development outside of what is available in the standard library. Familiarity with cloud technologies, containers (Docker and Kubernetes), distributed computing, Kubeflow and/or Seldon. Why Certilytics! Access to one of the largest clinical datasets in the industry that includes medical claims, pharmacy claims, and laboratory data. Impactful work. We’re big enough to have the freedom to take on interesting projects, but small enough that your work is always important and highly visible within the organization. Remote friendly. The Certilytics data science team is distributed throughout the US and have regular in-person working sessions for all of those little things that are hard to accomplish over Teams. Required Experience"
Data Engineer,Dixon Group Services LLC,"Chestertown, MD 21620",https://www.indeed.com/rc/clk?jk=93a4d9832ac42642&fccid=716f52f8c157eb67&vjs=3,"Dixon is looking for a Data Engineer to join our IT Team in Chestertown, MD! The Data Engineer will identify internal and external data sources, develop and implement Extraction, Transformation, Load (ETL) solutions and assist with the collection, storage and interpretation of data to assist Dixon with business critical decisions. Responsibilities: Utilize various tools and methods to automate repeatable ETL processes using a combination of SSIS, T-SQL, Python and REST APIs. Utilize SSMS and T-SQL to develop complex queries and data sources to deliver comprehensive data sets from multiple sources. Write SQL queries and stored procedures to support internal Dixon applications. Assist Business Intelligence engineers with back end query writing. Conduct data verification/validation for team members. Performance tune ETL and report processes and queries. Develop algorithms to find insights from various data analysis techniques to include statistical analysis and Machine Learning processes. As a member of the Data team, the ideal candidate will be able to assist Database Administrators with physical DBA tasks such as backup and restore, query tuning, encryption, auditing and regular maintenance. Effectively communicate with technical and non-technical team members. Competencies: Strong T-Sql Skills and experience in developing complex queries and data sources to deliver comprehensive data sets from multiple sources Strong knowledge of Python Pandas and other related Python ETL libraries. Familiarity with Python Machine Learning libraries such as Matplotlib, SciKit-Learn, Keras and TensorFlow Highly skilled in programs such as Excel, Access, SSMS (to develop SQL queries), Tableau/Power BI (or similar), SSRS/Crystal Reports (or similar) Familiarity with TFS (or similar) and Visual Studio Familiarity with database design, ETL, and data warehousing concepts Self-motivated team player with a positive attitude, strong sense of professionalism and work ethic Customer service oriented with ability to support at all levels and collaborate to solve problems Excellent written and verbal communication skills Strong critical thinking and problem-solving skills Highly organized with strong attention to detail and ability to adapt quickly to changing priorities Demonstrated ability to learn new concepts quickly Familiarity with manufacturing and/or distribution processes preferred The above statements are intended to describe the general nature and level of work performed in this position and are not intended to be an exhaustive list of all duties, responsibilities and skills required and are subject to change. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of this position. The Dixon Group is an equal opportunity employer. It is the Company's policy and practice to recruit, hire, train, and promote individuals, as well as to administer all personnel actions, compensation and benefits, without regard to race, religion, color, sex (including pregnancy, childbirth, and related medical conditions), gender identity or expression, sexual orientation, marital status, ancestry or national origin, age, disability, family medical history or genetic information, veteran status, military service, or any other factors protected by applicable law. This policy extends to all employees and applicants and to all aspects of the employment relationship. Education Required Bachelors or better in Economics Bachelors or better in Business Admin Bachelors or better in Information Technology Bachelors or better in Mathematics Bachelors or better in Applied Mathematics Behaviors Preferred Dedicated: Devoted to a task or purpose with loyalty or integrity Detail Oriented: Capable of carrying out a given task with all details necessary to get the task done well Functional Expert: Considered a thought leader on a subject Motivations Preferred Goal Completion: Inspired to perform well by the completion of tasks Growth Opportunities: Inspired to perform well by the chance to take on more responsibility Job Security: Inspired to perform well by the knowledge that your job is safe Peer Recognition: Inspired to perform well by the praise of coworkers"
Data Engineer (Remote),Thrivent,"Remote in Minneapolis, MN+2 locations",https://www.indeed.com/rc/clk?jk=47b072e1de66766f&fccid=c40fae22b6a11e7d&vjs=3,"Summary As a Data Engineer, you will build large, scalable Data platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and are leveraging Cloud Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you! Job Description Job Duties and Responsibilities Design and build robust, scalable solutions and data pipelines to automate the ingestion, processing and delivery of all types of data: structured and unstructured, batch, and real-time streaming data Work with the team to break down complex data issues and resolve them Use analytical, programming and technical skills to ensure that data ingestion pipelines are scalable, repeatable, secure, and can serve multiple users within Acquire data from a variety of different sources, getting it in the right formats, assuring that it adheres to data quality standards, and assuring that users can get that data quickly. Build robust systems with an eye on automation and the long-term maintenance and support of the application Work directly with the product owner and end-users to constantly deliver products in a highly collaborative and agile environment Required Job Qualifications Required: Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field 3+ years of experience in Technology related field including prior lead experience At least 1-3 years of Data Engineering experience with Big Data Technologies: Apache Spark, Hadoop, DataBricks At least 1-3 years of JVM Languages such as Java or Scala Preferred: 1+ years of experience building data pipelines, CICD pipelines, and fit for purpose data stores 1+ year of experience in Cloud technologies: AWS, Azure, Google Cloud, OpenStack, Docker, Ansible, Chef or Terraform 1+ years of experience working with automated build and continuous integration systems 1+ years of experience with Linux systems Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color, sex , gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state , or federal law. This policy applies to all employees and job applicants. Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation , please let us know by sending an email to human.resources@thrivent.com or call 800-847-4836 and request Human Resources."
Junior Data Scientist/Engineer,ManTech International Corporation,"Sterling, VA 20166",https://www.indeed.com/rc/clk?jk=8b11df2943373516&fccid=578fa8376f4eec04&vjs=3,"Where applicable, confirmation that you meet customer requirements for facility access which may include proof of vaccination and/or attestation and testing, unless an accommodation has been approved. Secure our Nation, Ignite your Future For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone. ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law. If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information."
Consultant - Data Engineer,Insygnum,"Chicago, IL",https://www.indeed.com/rc/clk?jk=54707f4835fac495&fccid=ed94e1a293166c52&vjs=3,"Insygnum needs a Consultant - Data Engineer to help our clients for data analysis, data integration and data quality. Our Chicago-based team is small but growing fast and we need to complement our in-house experts who knows how to tame challenging data. This is a unique opportunity to not only work with cool technology, but also to create a new methodologies and techniques. You'll get in on the ground floor of a new company, help shape its future, and benefit directly from your work. Why work here Joining insygnum now offers several unique opportunities You will receive competitive salary, benefits, and stock options You will be working on hard, interesting problems You will help shape the culture of the company as we grow You will have the opportunity to apply your skills in a meaningful way and have a real-world impact Responsibilities You'll help design a new system for capturing, storing, analyzing, and acting on performance, security, and network data. The ideal candidate will have a solid grasp of several different database and data warehousing technologies to help architect ETL for. Technologies to be used may include some combination of relational databases (PostgreSQL, Teradata, Aster, HANA), NoSQL, Hadoop, Object-based stores, and OLAP. Specific responsibilities include: Help design an architecture for federated data stores and data fusion Help design methods for storing data in a way that facilitates extremely fast data parsing and management Implement ""glue code"" that connects middle tier components with backend components Implement data management and analytics code utilizing data architecture (e.g. map reduce) Collaborate with machine learning folks to determine how to analyze various data sets and set up methods for querying data stores Collaborate with data architects to understand the applications we integrate with and the data they produce Review requirements for new approaches to big data storage and analytics Design methods for caching, paging, and integrating real-time data with historical data stores Desired Skills and Experience Requirements Development knowledge for integrating components and contributing to core code base - Java preferred Solid understanding of database and data warehousing technologies Knowledge of SQL as well as NoSQL queries, syntax, and technologies Knowledge of big data requirements, applications, and technologies such as Hadoop Knowledge of ETL methods and approaches including triggers, named views, temporary tables, etc. Linux expertise Bonus Points Java is strongly preferred (e.g. for working with map reduce) but not ultimately a requirement if you excel in other areas Strong SQL skills are highly desirable OLAP experience Experience with ETL tools like Informatica, Boomi, Pentaho, AbIntio, Datastage, etc.,"
Data Engineer,"Medpace, Inc.","Cincinnati, OH 45227 (Madisonville area)",https://www.indeed.com/rc/clk?jk=45ba179bff05222d&fccid=dc86b41d5cdf3527&vjs=3,"Job Summary: Our corporate activities are growing rapidly, and we are currently seeking a full-time, office-based Data Engineer to join our Information Technology team. This position will work on a team to accomplish tasks and projects that are instrumental to the company’s success. If you want an exciting career where you use your previous expertise and can develop and grow your career even further, then this is the opportunity for you. Responsibilities : Utilize skills in development areas including data warehousing, business intelligence, and databases (Snowflake, ANSI SQL, SQL Server, T-SQL); Support programming/software development using Extract, Transform, and Load (ETL) and Extract, Load and Transform (ELT) tools, (dbt, Azure Data Factory, SSIS); Design, develop, enhance and support business intelligence systems primarily using Microsoft Power BI; Collect, analyze and document user requirements; Participate in software validation process through development, review, and/or execution of test plan/cases/scripts; Create software applications by following software development lifecycle process, which includes requirements gathering, design, development, testing, release, and maintenance; Communicate with team members regarding projects, development, tools, and procedures; and Provide end-user support including setup, installation, and maintenance for applications released. Qualifications : Bachelor's Degree in Computer Science or a related field; Knowledge of developing dimensional data models and awareness of the advantages and limitations of Star Schema and Snowflake schema designs; Solid ETL development, reporting knowledge based off intricate understanding of business process and measures; Knowledge of Snowflake cloud data warehouse, Fivetran data integration and dbt transformations is a bonus; Knowledge of REST API Knowledge of SQL Server database development; Knowledge of developing Business Intelligence initiatives using SQL Server stack (SSIS and Power BI), TFS/Azure DevOps; Knowledge of C#, Azure development is preferred; and Excellent analytical, written and oral communication skills. Medpace Overview : Medpace is a full-service clinical contract research organization (CRO). We provide Phase I-IV clinical development services to the biotechnology, pharmaceutical and medical device industries. Our mission is to accelerate the global development of safe and effective medical therapeutics through its scientific and disciplined approach. We leverage local regulatory and therapeutic expertise across all major areas including oncology, cardiology, metabolic disease, endocrinology, central nervous system, anti-viral and anti-infective. Headquartered in Cincinnati, Ohio, employing more than 4,000 people across almost 40 countries. Why Medpace?: When you join Medpace, you become part of a team dedicated to supporting the development of ground-breaking drugs and devices. Our employees provide hope for those living with debilitating diseases. We invite you to be a part of something that is impacting millions of people around the globe while enjoying a competitive total compensation and benefits package and internal growth opportunities. Organic Growth: Medpace is continuing to grow in all areas globally and has built an expansive research campus at its headquarters in Cincinnati, OH. In 2020, Medpace opened a new seven story building that is approximately 250,000 SQFT. In total, the headquarter's campus includes five buildings and approximately 600,000 SQFT. The company also has expanding office locations in Dallas, TX and Denver, CO. Perks ( vary by location and position ): On-site fitness center(s) Campus walking paths Company-sponsored social and wellness events Official Sponsor of FC Cincinnati Hybrid work-from-home options and flexible work schedule On-site Market Place Free and covered parking Discounts for local businesses On campus restaurants and banks coming soon Awards: Medpace historically named a Top Cincinnati Workplace by the Cincinnati Enquirer Recognized by Forbes as one of America's Best Mid-size Companies in 2021 Medpace ranks amongst top CROs for site ratings across all 10 important attributes including CRA training, preparation & organization, accessibility of staff, open communication, and ensuring timely drug availability Continually recognized with CRO Leadership Awards from Life Science Leader magazine based on expertise, quality, capabilities, reliability, and compatibility Ranked in the top 10 on the 2021 LinkedIn Top Companies list in Cincinnati What to Expect Next: A member of our recruitment team will review your qualifications and, if interested, you will be contacted for an interview. EO/AA Employer M/F/Disability/Vets"
Data Center Engineer,BluPeaks,"Alpharetta, GA",https://www.indeed.com/rc/clk?jk=23db54ee3923527f&fccid=1c969b936b7f2fa5&vjs=3,"As a Data Center Engineer you will play a key role in ensuring our customers’ core data center infrastructure effectively meets the demands of current and future industry technology trends. This position includes duties in the areas of enterprise systems design, deployment, maintenance, support, and scaling of multi-vendor data center environments covering network, compute, storage, virtualization and open-source technologies. You like solving complex business problems and finding innovative solutions. You love keeping abreast of the latest industry trends and using them to help you innovate. You have strong leadership qualities, great judgment, clear communication skills and a track record of delivering great results. Job leveling will be determined by years of relevant experience, certifications and skill set. To apply, please send your resume to hr@Blupeaks.com."
Senior Data Engineer,The Hershey Company,"Remote in Hershey, PA",https://www.indeed.com/rc/clk?jk=84330433eca9e018&fccid=e08898c7a89673c9&vjs=3,"Job Title: Senior Data Engineer Job Location: Hershey, PA This position is open to 100% remote Summary: The Enterprise Data organization drives value for Hershey by providing high-quality, well governed data to the Enterprise for analytics and decision-making. The Sr. Data Engineer will be part of an agile execution team, working with Hershey business partners, data scientists, technical engineers, and project managers to ensure engineering standards adhere to company best practice and help to deliver rapid impactful benefits. The Sr. Data Engineer will act as a trusted advisor for Hershey business partners by ensuring that data solutions meet expectations and requirements. You will work with a diverse team of business analysts, data scientists, technical engineers, data architects, and project managers to deliver outcomes aligned with our business partner’s strategy. In addition, you will work directly with the Sr. Manager of Data Engineering to ensure consistency and compliance of deliverables to frameworks and governance processes. Major Duties/Responsibilities: Data Engineering Solution Delivery: Develop and deliver high-quality data pipelines adhering to best practice, privacy, and governance principles Data Engineering Maintenance/Optimization: Work existing data pipelines and solutions to enhance its performance, quality and/or functionality. Resolve incidents escalated by support teams or business users Data Engineering Domain: Collaborate with IT and business partners to define, manage and deliver innovative Data solutions to drive growth and adoption of capabilities at Hershey Data Engineering Advocacy: Evangelize future data solutions identified by Enterprise Data leadership, including innovations such as: metadata management; data security and governance; cloud-based systems for data storage; multi-environment integration and automation of data tasks and movement Specific Job Responsibilities: Executes the strategy to deliver cloud-based intelligent systems to collect, distribute, model, and analyze disparate and diverse data assets to automate insights and drive business performance Using best practice frameworks and governance, evaluate, design, and analyze solution engineering for agile delivery Create and develop robust and secure ETL pipelines across a broad range of data-focused products, services, projects, and systems Using best practice guidance from Enterprise Data leadership, oversee the health and evolution of agile execution team engineering technologies Works closely with leaders within data engineering, data architecture, data science and domain experts, to build and maintain roadmaps against the IT strategy Partner to deliver a modern data engineering model that follows Dev/Ops principles and standards for continuous integration/ continuous delivery (CI/CD) processes Ensure reliability in data and data pipelines, enforcing governance, security, and performance Collaborate in developing best in class key performance indicators to measure the performance and quality of the data engineering teams and processes Able to articulate the holistic benefits of data engineering from a business perspective, while maintaining the relationship with business analysts, data scientists, technical engineers, and project managers Minimum knowledge, skills and abilities required to successfully perform major duties/responsibilities: Experience designing, implementing large scale data pipelines for data curation, feature engineering and machine learning across multiple environments Working knowledge of agile frameworks Ability to manage multiple priorities, meet deadlines and produce quality results under pressure Demonstrated leadership and managerial skills Strong problem solving and analytical skills Strong team player, change agent, and advocate Excellent customer service skills High energy self-starter Excellent verbal and written communication skills Minimum Education and Experience Requirements: Education: Bachelor’s in a STEM degree Master’s degree and/or related equivalent experience preferred Experience 3-5+ years of progressive experience working with data, much of which has been focused on working with cross-functional teams and enterprise-wide data management programs 3+ years of experience in building data solutions within an enterprise environment using industry standard guiding principles and practices 3+ years of leveraging data integration tools to build data pipelines e.g., Informatica, Talend, Matillion 3+ years of experience with SQL, Python, Scala and Spark languages to explore, interact and build solutions 3+ years of experience with public and private cloud solutions Advanced working knowledge and experience with relational/non-relational databases e.g., Teradata, Snowflake, Databricks, Azure Data solutions or Hadoop Experience working with machine learning and data science teams Experience building data visualizations or analytics e.g., Power BI, Tableau, SSRS, SAP Experience working in a high performing agile delivery model, aligning with Scrum Masters, Product Owners, and other execution team members to deliver rapid and impactful solutions that align to business partner strategy Excellent communication and presentation skills, with the ability to articulate new ideas and concepts to technical and non-technical partners Experience leading a project team or project function to deliver an enterprise data, application and/or ERP solution Experience with COBIT/SOX, as well as PII data in accordance with relevant laws #LI-MB1 The Hershey Company is an Equal Opportunity Employer. The policy of The Hershey Company is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's race, color, gender, age, national origin, religion, citizenship status, marital status, sexual orientation, gender identity, transgender status, physical or mental disability, protected veteran status, genetic information, pregnancy, or any other categories protected by applicable federal, state or local laws. The Hershey Company is an Equal Opportunity Employer - Minority/Female/Disabled/Protected Veterans If you require a reasonable accommodation as part of the application process, please contact the HR Service Center (askhr@hersheys.com)."
Data Engineer II (Regular Full-Time),Seattle Cancer Care Alliance,"Seattle, WA 98109 (South Lake Union area)+1 location",https://www.indeed.com/rc/clk?jk=4736f060763d91dc&fccid=bcb8a8917771192d&vjs=3,"Overview: Fred Hutchinson Cancer Center is an independent, nonprofit, unified adult cancer care and research center that is clinically integrated with UW Medicine, a world leader in clinical care, research and learning. The first National Cancer Institute-designated cancer center in the Pacific Northwest, Fred Hutch’s global leadership in bone marrow transplantation, HIV/AIDS prevention, immunotherapy, and COVID-19 vaccines has confirmed our reputation as one of the world’s leading cancer, infectious disease and biomedical research centers. Based in Seattle, Fred Hutch operates eight clinical care sites that provide medical oncology, infusion, radiation, proton therapy, and related services, and network affiliations with hospitals in five states. Together, our fully integrated research and clinical care teams seek to discover new cures for the world’s deadliest diseases and make life beyond cancer a reality. At Fred Hutch, we believe that the innovation, collaboration, and rigor that result from diversity and inclusion are critical to our mission of eliminating cancer and related diseases. We seek employees who bring different and innovative ways of seeing the world and solving problems. Fred Hutch is in pursuit of becoming an antiracist organization. We are committed to ensuring that all candidates hired share our commitment to diversity, antiracism, and inclusion. The Data Platform Team within SCCA's Information Technology Department is responsible for designing, developing, and supporting SCCA data systems and integration for both operational and analytical purposes. Under the guidance of the Data Warehouse Manager, the Data Engineer II is responsible for the development and implementation of scalable, stable, and secure solutions for data acquisition, data distribution, and workflow orchestration in SCCA's data warehouse. The role will also contribute to the maintenance and optimization of existing data pipelines from a wide variety of internal and external data sources, including partner data warehouses and repositories. They will work closely with other engineering team members, business analysts, and systems analysts to provide data solutions that support and empower internal business partners and drive enterprise analytics and data science objectives. Successful candidates will have strong engineering and communication skills as well as a strong knowledge in on-prem SQL Server data systems. Familiarity with common cloud data tools, best practices and migration strategies is a plus as well as agile development methodologies. Responsibilities: Design, develop, and support ETL/ELT processes sourcing data from various internal applications and external data repositories including our partner EPIC EMR implementations. Monitor and maintain build and release pipelines in Azure Devops using continuous development best practices. Develop and support data infrastructure primarily built with Microsoft technologies. Partner with Test Engineer in development of the QA & Test Plan, including the automated test framework Contribute to production support efforts, including the identification, resolution, and communication of bugs within our data platform. Contribute to a collaborative environment within the Data Engineering function and in partnership with stakeholders. Work on multiple projects in parallel. Qualifications: Required: High school diploma or equivalent Excellent knowledge and experience developing, performance tuning, and supporting on-prem data engineering systems including Microsoft SQL Server Strong knowledge and experience with ETL tools and various data processing techniques and best practices Some knowledge and experience with database architecture and design, coding, and administration Strong knowledge and experience with data warehousing design and concepts Some knowledge and experience in working with large and complex data sets Ability to work independently, manage competing priorities and to adapt to new and changing technologies Strong analytical, problem solving, and organizational skills Strong verbal/written communication skills, including an ability to effectively communicate using multiple methods with both technical and non-technical teams Preferred: B.Sc or M.Sc degree in quantitative field (Engineering, Computer Science, Information Systems, etc.), or commensurate professional experience Prior experience in scripting languages (Powershell, Python, or similar) Prior experience in AWS or Azure cloud data tools/technologies Experience with Cerner and/or Epic healthcare systems Familiarity with healthcare financial and/or clinical data Familiarity with HIPAA regulations and data warehousing security best practices Experience using AWS for data processing SQL Server indexing and performance tuning Familiarly with the Systems/Software Development Life Cycle Experience with Agile software development SCCA has a mandatory COVID-19 vaccination policy, and there are no exceptions for any employee who is patient-facing and/or requires access to SCCA facilities. Exceptions exist only for employees whose positions are fully remote, with no required access to campus. As a condition of employment, newly hired employees requiring access to campus must provide proof of vaccination before their first day of employment. A statement describing your commitment and contributions toward greater diversity, equity, inclusion, and antiracism in your career or that will be made through your work at Fred Hutch is requested of all finalists. Our Commitment to Diversity: We are proud to be an Equal Employment Opportunity (EEO) and Vietnam Era Veterans Readjustment Assistance Act (VEVRAA) Employer. We are committed to cultivating a workplace in which diverse perspectives and experiences are welcomed and respected. We do not discriminate on the basis of race, color, religion, creed, ancestry, national origin, sex, age, disability (physical or mental), marital or veteran status, genetic information, sexual orientation, gender identity, political ideology, or membership in any other legally protected class. We are an Affirmative Action employer. We encourage individuals with diverse backgrounds to apply and desire priority referrals of protected veterans. If due to a disability you need assistance/and or a reasonable accommodation during the application or recruiting process, please send a request to our Employee Services Center at hrops@fredhutch.org or by calling 206-667-4700."
Sr. Data Engineer,Flagstar Bank,Remote,https://www.indeed.com/rc/clk?jk=45652f1efe02fc64&fccid=6bb2d1e9f5d79675&vjs=3,"Position Title Sr. Data Engineer Location Work From Home MI Job Summary Responsible for the design, development, and execution of automated and manual data Extract, Transform, and Load (ETL), integration, and exchange processes across the enterprise. Will recommend, implement, develop and utilize innovative tools and processes to efficiently, rapidly, and securely acquire, integrate, and provision large sets of data from and to thousands of sources. Responsible for the efficient, compliant, timely, and secure acquisition, integration, provision, and exchange of the enterprise data. Job Responsibilities: Provide data integration architecture leadership across the enterprise. Develop and document technical best practices for ETL-related activities including data movement, data aggregation, data quality, and data cleansing. Work with the Data Warehousing and Business Intelligence team to design, implement, and support end-to-end data solutions across multiple platforms, environments, domains, and locations. Work with external vendors and internal business and technology staff to accurately gather and interpret requirements, specifications, and database models to determine appropriate ETL development solutions. Create, execute, and document unit test plans for ETL and data integration processes and programs. Document ETL processes, programs and solutions as per established standards. Monitor and administer automated and manual data integration and ETL jobs to verify execution and measure performance. Work with internal staff, vendors, consultants, and external partners to quickly identify and resolve data integration and ETL job issues. Assess and document the structure, quality, and compliance of data source data and coordinate with business and technology staff to identify and resolve issues. Mentor other Data Management team members in the ETL tools, programs, processes, and best practices. Ensure compliance with applicable federal, state and local laws and regulations. Complete all required compliance training. Maintain knowledge of and adhere to Flagstar's internal compliance policies and procedures. Take responsibility to keep up to date with changing regulations and policies. Job Requirements: Bachelor's Degree in Computer Science, Mathematics or related field + 7 years of development experience is preferred – OR - 10 years comparable work experience 7 years of experience designing, developing, testing, and implementing Extract, Transform and Load (ETL) solutions using enterprise ETL tools or 10 years of comparable work experience 6 years of experience developing and implementing data integration and data warehouse solutions in an Oracle 11g/12c database environment 2 years of experience working with Business Intelligence tools (IBM Cognos is preferred) 2 years of experience working in a Service- Oriented Architecture (SOA) environment 1 year of experience in 10+ TB data environment Expertise in Relational Database Management System, Data Mart and Data Warehouse design Expert-level SQL and PL/SQL development skills in a multi-tier environment Expertise in flat file formats, XML within PL/SQL, and file format conversion Strong understanding of SDLC and Agile Methodologies Strong understanding of model driven development Strong understanding of ETL best practices Proven strength in interpreting customer business needs and translating them into application and operational requirements Strong problem-solving skills and analytic skills with proven strength in applying root cause analysis Expertise and hands-on experience in designing and building technical solutions using best practices and applicable technologies; an ability to demonstrate strong coding skills Expertise in working with technical and business teams to extract and document data integration/exchange requirements Ability to exhibit a strong understanding of business process Ability to communicate verbally and in technical writing to all levels of the organization in a proactive, contextually appropriate manner Strong teamwork and interpersonal skills at all levels Dedicated to excellence in one’s work; strong organizational skills; detail-oriented and thorough Able to prioritize work by dividing time, attention and effort between current project workload and on-going support tasks Must be willing to work overtime, including weekends, when required Internal Use Only: Band E"
Data Engineer,Hexcel Corporation,"Salt Lake City, UT 84118",https://www.indeed.com/rc/clk?jk=3dcab09a9967856c&fccid=79ed928b199058bc&vjs=3,"With our strong investment in research and development and our culture of continuous improvement, Hexcel is the industry leader in the manufacturing of advance composite materials, including carbon fiber, woven reinforcements, resins, prepregs, honeycombs and additive manufactured parts. We invite you to join the Hexcel team at various manufacturing sites, sales offices and R&T centers around the globe. Become a part of the “strength within.” Hexcel is currently seeking a Data Engineer for our Salt Lake City, UT, USA location. The selected individual will be responsible for but not limited to the following obligations: Working with product owners to identify and design data solutions Engineering data pipelines to pull data from on premises and cloud data sources Create & maintain optimized data pipeline architecture Extracting data and consolidating with data lakes, data warehouse and data marts Engineering models to connect different data sources together Constructing a library of data components that can easily be reused to answer different business questions Troubleshooting and fixing production issues Qualifications: Five plus years of relevant ETL, data engineering or similar experience Bachelor’s degree or equivalent Experience with cloud data platforms required Experience with Azure SQL Server, Azure Synapse, Azure Analysis Services and Azure Data Factory highly desirable, but not essential appetite for new technologies and methodologies Strong understanding of Power BI platform and Power BI paginated Design complex data sets to meet the needs of business requirements Troubleshoot and optimize data pipelines Strong knowledge of SQL; Understanding of DAX and/or MDX a plus Experience with Databricks desirable, but not essential This position is restricted to U.S. citizens due to U.S. federal government contracts that require the employment of only persons who are U.S. citizens. Hexcel (NYSE: HXL) is a global leader in advanced composites technology, a leading producer of carbon fiber, and the world leader in honeycomb manufacturing for the commercial aerospace industry. Hexcel is an Equal Opportunity Employer of Minorities/Females/Protected Veterans/Individuals with Disabilities/Sexual Orientation/Gender Identity. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, physical or mental disability, status as protected veteran, or any other protected class."
IT - Data Engineer - 100% Remote Option,The Cincinnati Insurance Companies,"Remote in Fairfield, OH",https://www.indeed.com/rc/clk?jk=aec6eae0f1ce13fb&fccid=ea99366887d9676b&vjs=3,"IT - Data Engineer - 100% Remote Option - (2200474) US-OH-Fairfield Description Make a difference with a career in insurance At The Cincinnati Insurance Companies, we put people first and apply the Golden Rule to our daily operations. To put this into action, we’re looking for extraordinary people to join our talented team. Our service-oriented, ethical, knowledgeable, caring associates are the heart of our vision to be the best company serving independent agents. We help protect families and businesses as they work to prevent or recover from a loss. Share your talents to help us reach for continued success as we bring value to the communities we serve and demonstrate that Actions Speak Louder in Person®. If you’re ready to build productive relationships, collaborate within a diverse team, embrace challenges and develop your skills, then Cincinnati may be the place for you. We offer career opportunities where you can contribute and grow. Start your journey with us. Our IT department is currently seeking an experienced data engineer to build data pipelines that provide peace of mind for people by equipping them to make data-informed business decisions. Be ready to: develop reliable, reusable, automated and streamlined ETL code proactively identify, build and maintain relationships with business process owners and colleagues maintain accurate and consistent data outputs for the company’s financial controls and accounting systems analyze and organize raw data from multiple sources to produce requested or required data elements design table structures and ETL to build performant data solutions that are scalable in a fast growing data ecosystem create reconciliation procedures and data checks to ensure data quality build in automated audit, balancing and controls provide production support, including on-call rotation and technical assistance to end-user and IT staff lead user requirements gathering and documentation designs proactively conduct data investigations and assist business partners with complex data analysis and ad-hoc queries lead application and technical architecture analysis, design and implementation, and ensure BI product fulfills requirements lead efforts with data management and database specialists to troubleshoot and report issues design new reporting applications to ensure reporting requests can be supported by the underlying data source adhere to all metadata management and data quality standards by leading quality management reviews understand configuration dependencies and interrelationships between data warehouse and business intelligence tools and designs; troubleshoot in the area with this knowledge identify changes in scope or work effort that could result in budgetary overrun or missing of delivery date, design and implement contingency demonstrate expert problem solving capabilities Be equipped to: proven experience in designing and implementing ETL processes (preferred tools: IBM's DataStage, SQLSvr SSRS, SAS) proven experience distilling business requirements into data warehouse design artifacts such as a Facts Qualifier Matrix (FQM), source to target maps and star/snowflake schema data models preferred five or more years experience with SQL, Data Modeling and Dimensional Modeling preferred three or more years experience supporting financial close processes for the Accounting and Finance departments (i.e. month end, quarter end, year end processing) experience with Test Driven Development (TDD) preferred knowledge of developing BI dashboards (preferred tools: IBM's Cognos, Microsoft's Power BI); creating data quality scorecards and data lineage for the finance business intelligence team experience with agile teams mentor development team members in design and development of BI solutions strong team working skills, an analytical nature, self-motivated and excellent written and oral communication skills ability to comprehend complex technical and logical concepts and adapt quickly to changes ability to maintain own workflow and meet deadlines while managing parallel project deliverables with minimal direction ability to create effective visual models to enable collective understanding of processes, data flow, user interaction and others as needed prior reporting application support experience track record of successfully architecting small, medium and enterprise-scale solutions preferred three or more years of business requirements experience You’ve earned: a bachelor's degree or have equivalent experience in computer science or related discipline Enhance your talents Providing outstanding service and developing strong relationships with our independent agents are hallmarks of our company. Whether you have experience from another carrier or you’re new to the insurance industry, we promote a lifelong learning approach. Cincinnati provides you with the tools and training to be successful and to become a trusted, respected insurance professional – all while enjoying a meaningful career. Enjoy benefits and amenities Your commitment to providing strong service, sharing best practices and creating solutions that impact lives is appreciated. To increase the well-being and satisfaction of our associates, we offer a variety of benefits and amenities. Learn more about our benefits and amenities packages. Many departments at our Headquarters in Fairfield, Ohio, offer hybrid work options, empowering associates to work from home several days a week. Depending on your role and responsibilities, hybrid options may be available. Embrace a diverse team As a relationship-based organization, we welcome and value a diverse workforce. We provide equal employment opportunity to all qualified persons without regard to race; creed; color; sex, including sexual orientation, gender identity and transgender status; religion; national origin; age; disability; military service; veteran status; pregnancy; AIDS/HIV or genetic information; or any other basis prohibited by law. Learn More."
Senior Data Engineer,"NVR, Inc","Reston, VA+1 location",https://www.indeed.com/rc/clk?jk=b82626337a08c6f0&fccid=406370dc8d89c02b&vjs=3,"NVR is seeking an experienced Data Engineer to join our Data & Analytics team. As a Data Engineer you will be responsible for the day-to-day operations of systems that depend on data, ensuring data is properly processed and securely transferred to its appropriate location, in a timely manner. Processing data will include managing, manipulating, storing, and parsing data on premises and in the cloud. What’s in it for you: Be on the ground floor of our migration to the cloud. Share your knowledge; we want to learn from YOU and grow OUR skills as well. Work with a great team of analysts and engineers to provide value to the business Clearly see the impact of your work. You will be held to measurable goals that you help define so you will KNOW how the work you’ve done has an impact. Have ownership in the projects you work on. You will ultimately be responsible for their success or failure. Don’t worry, we will help you to ensure you are successful. What you will do: Complete development efforts across data pipeline to store, manage, store, and provision to data consumers Write code to ensure the performance and reliability of data extraction and processing Support continuous process automation for data ingest Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing Work with program management and engineers to implement and document complex and evolving requirements Collaborate with others as part of a cross-functional team that includes Data Analysts, Data Scientist and Business Analysts What skills and experiences are required: 5+ years of experience in data management (integration, modeling, optimization, and quality). Proficiency developing ETL processes, and performing test and validation steps Proficiency to manipulate data (SQL, SSIS, Azure Data Factory) Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats Strong understanding of cloud technologies (Azure) Strong understanding of the Data Governance Work comfortably in version control systems, such as, Git Repositories What puts you ahead of the pack: Familiarity with data visualization using Power BI, Excel, and Power Pivot, Tableau Experience with Microsoft Dynamics and Kingswaysoft Task Orchestration and Management Tools (CA Workload Automation, JIRA) Experience integrating systems through API’s About Us & Life at NVR NVR has been helping families build their happily ever after since 1948. As a Top 5 US homebuilder, we’re committed to quality and to our customers and we take pride in the nearly 500,000 new homes we have sold and built across the country. Working in the homebuilding industry is tangible and rewarding, but not every job at NVR requires a hard hat. We don’t just sell and build new homes; we also manage teams, acquire land, manufacture materials, provide mortgages to our customers, and provide corporate support to NVR’s multi-billion dollar business operations. At NVR, your desire to excel is matched by our commitment to your success and we’ll give you the tools and industry knowledge you need. Our management team is tenured and talented, nearly 80% of them promoted from within, so you’ll find mentors who can share their knowledge, provide career guidance and encourage your success. NVR also offers benefits among the best in the industry that reflect the strong commitment we have to all of our employees. Competitive Compensation Home Purchase Discount Mortgage and Settlement Services Discounts Comprehensive Health, Life and Disability Insurance 401(k) (Full-time employees are eligible to contribute immediately) Employee Stock Ownership Program Vacation and Holidays In addition to the traditional benefits, we offer all our employees stock ownership through a profit sharing trust as part of our retirement savings package. NVR has had the highest Earnings Per Share growth rate in the homebuilding industry for the past 10 years, so as we grow financially, so do you. We are an Equal Opportunity Employer. Drug Testing and Credit Check are required. Applicants must be legally entitled to work in the United States, as NVR does not provide visa sponsorships."
Data Engineer,Susquehanna International Group,"Bala-Cynwyd, PA+1 location",https://www.indeed.com/rc/clk?jk=4cc29dec78de9caa&fccid=4cd66e5617f038d8&vjs=3,"SIG is hiring a Data Engineer into our Data Technologies team. This team provides support to middle and back office application teams with all their database needs. We are looking for database developer to develop and maintain large and complex database systems using Hadoop, Oracle, Informatica, and other technologies. The ideal candidate would also have some light experience with database administration and support. As a member of this team, you will: Design, develop, and support database applications for our middle/backoffice data systems Design solutions using Hadoop, Hive, Spark technologies Maintain and support database (Oracle, MySQL, MariaDB) instances and applications in a high-transaction environment Install, configure, and upgrade database software and related products Perform routine and customary operational activities to ensure a stable database environment Provide consultation and assist other teams with the usage of reference data Become a data domain expert Design, develop, and support Linux shell scripts and Python for batch processing Provide production support off hours/weekend, when needed What we're looking for At least 5 years of experience with Hadoop development and Spark streaming data required Hands-on experience building solutions in relational databases such as Oracle, MySQL and/or MariaDB Experience with query performance tuning Experience with Python and Unix Shell scripting required Experience with Informatica would be plus Ability and flexibility to provide occasional off hour/weekend support A Bachelor's degree in Computer Science, Engineering, Mathematics, or a related discipline or its foreign equivalent. Relevant technical experience may be substituted for education SIG is not accepting unsolicited resumes from search firms. All resumes submitted by search firms to any employee at SIG via-email, the Internet or directly without a valid written search agreement will be deemed the sole property of SIG, and no fee will be paid in the event the candidate is hired by SIG. Visa sponsorship is available for this position."
Software Engineer- Data Governance,Snowflake,"San Mateo, CA 94401 (Downtown area)",https://www.indeed.com/rc/clk?jk=e3bab11c513c2ea2&fccid=fbedd6450a2f872c&vjs=3,"There is only one Data Cloud. Snowflake’s founders started from scratch and designed a data platform built for the cloud that is effective, affordable, and accessible to all data users. But it didn’t stop there. They engineered Snowflake to power the Data Cloud, where thousands of organizations unlock the value of their data with near-unlimited scale, concurrency, and performance. This is our vision: a world with endless insights to tackle the challenges and opportunities of today and reveal the possibilities of tomorrow. [ - ADD JOB DESCRIPTION ONLY - ] [ HEADER (FORMAT: HEADING 3, CAPITALIZED, BOLD) ] : [ List ] [ HEADER (FORMAT: HEADING 3, CAPITALIZED, BOLD) ] : [ List ] Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake. How do you want to make your impact?"
Senior Data Engineer,The Hershey Company,"Remote in Hershey, PA",https://www.indeed.com/rc/clk?jk=84330433eca9e018&fccid=e08898c7a89673c9&vjs=3,"Job Title: Senior Data Engineer Job Location: Hershey, PA This position is open to 100% remote Summary: The Enterprise Data organization drives value for Hershey by providing high-quality, well governed data to the Enterprise for analytics and decision-making. The Sr. Data Engineer will be part of an agile execution team, working with Hershey business partners, data scientists, technical engineers, and project managers to ensure engineering standards adhere to company best practice and help to deliver rapid impactful benefits. The Sr. Data Engineer will act as a trusted advisor for Hershey business partners by ensuring that data solutions meet expectations and requirements. You will work with a diverse team of business analysts, data scientists, technical engineers, data architects, and project managers to deliver outcomes aligned with our business partner’s strategy. In addition, you will work directly with the Sr. Manager of Data Engineering to ensure consistency and compliance of deliverables to frameworks and governance processes. Major Duties/Responsibilities: Data Engineering Solution Delivery: Develop and deliver high-quality data pipelines adhering to best practice, privacy, and governance principles Data Engineering Maintenance/Optimization: Work existing data pipelines and solutions to enhance its performance, quality and/or functionality. Resolve incidents escalated by support teams or business users Data Engineering Domain: Collaborate with IT and business partners to define, manage and deliver innovative Data solutions to drive growth and adoption of capabilities at Hershey Data Engineering Advocacy: Evangelize future data solutions identified by Enterprise Data leadership, including innovations such as: metadata management; data security and governance; cloud-based systems for data storage; multi-environment integration and automation of data tasks and movement Specific Job Responsibilities: Executes the strategy to deliver cloud-based intelligent systems to collect, distribute, model, and analyze disparate and diverse data assets to automate insights and drive business performance Using best practice frameworks and governance, evaluate, design, and analyze solution engineering for agile delivery Create and develop robust and secure ETL pipelines across a broad range of data-focused products, services, projects, and systems Using best practice guidance from Enterprise Data leadership, oversee the health and evolution of agile execution team engineering technologies Works closely with leaders within data engineering, data architecture, data science and domain experts, to build and maintain roadmaps against the IT strategy Partner to deliver a modern data engineering model that follows Dev/Ops principles and standards for continuous integration/ continuous delivery (CI/CD) processes Ensure reliability in data and data pipelines, enforcing governance, security, and performance Collaborate in developing best in class key performance indicators to measure the performance and quality of the data engineering teams and processes Able to articulate the holistic benefits of data engineering from a business perspective, while maintaining the relationship with business analysts, data scientists, technical engineers, and project managers Minimum knowledge, skills and abilities required to successfully perform major duties/responsibilities: Experience designing, implementing large scale data pipelines for data curation, feature engineering and machine learning across multiple environments Working knowledge of agile frameworks Ability to manage multiple priorities, meet deadlines and produce quality results under pressure Demonstrated leadership and managerial skills Strong problem solving and analytical skills Strong team player, change agent, and advocate Excellent customer service skills High energy self-starter Excellent verbal and written communication skills Minimum Education and Experience Requirements: Education: Bachelor’s in a STEM degree Master’s degree and/or related equivalent experience preferred Experience 3-5+ years of progressive experience working with data, much of which has been focused on working with cross-functional teams and enterprise-wide data management programs 3+ years of experience in building data solutions within an enterprise environment using industry standard guiding principles and practices 3+ years of leveraging data integration tools to build data pipelines e.g., Informatica, Talend, Matillion 3+ years of experience with SQL, Python, Scala and Spark languages to explore, interact and build solutions 3+ years of experience with public and private cloud solutions Advanced working knowledge and experience with relational/non-relational databases e.g., Teradata, Snowflake, Databricks, Azure Data solutions or Hadoop Experience working with machine learning and data science teams Experience building data visualizations or analytics e.g., Power BI, Tableau, SSRS, SAP Experience working in a high performing agile delivery model, aligning with Scrum Masters, Product Owners, and other execution team members to deliver rapid and impactful solutions that align to business partner strategy Excellent communication and presentation skills, with the ability to articulate new ideas and concepts to technical and non-technical partners Experience leading a project team or project function to deliver an enterprise data, application and/or ERP solution Experience with COBIT/SOX, as well as PII data in accordance with relevant laws #LI-MB1 The Hershey Company is an Equal Opportunity Employer. The policy of The Hershey Company is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's race, color, gender, age, national origin, religion, citizenship status, marital status, sexual orientation, gender identity, transgender status, physical or mental disability, protected veteran status, genetic information, pregnancy, or any other categories protected by applicable federal, state or local laws. The Hershey Company is an Equal Opportunity Employer - Minority/Female/Disabled/Protected Veterans If you require a reasonable accommodation as part of the application process, please contact the HR Service Center (askhr@hersheys.com)."
Data Engineer,EBSCO Information Services,Remote in Massachusetts,https://www.indeed.com/rc/clk?jk=1964038ee4e5a8cb&fccid=c0e76fdb68c333ea&vjs=3,"EBSCO Information Services (EIS) provides a complete and optimized research solution comprised of e-journals, e-books, and research databases - all combined with the most powerful discovery service to support the information needs and maximize the research experience of our end-users. Headquartered in Ipswich, MA, EIS employs more than 2,700 people worldwide, most now working hybrid or remotely. We are the leader in our field due to our cutting-edge technology, forward-thinking philosophy, and outstanding team. EIS is a company that will motivate you, inspire you, and allow you to grow. Our mission is to transform lives by providing relevant and reliable information when, where, and how people need it. We are looking for bright and creative individuals whose unique differences will allow us to achieve this inclusive mission around the world. As a data engineer, you will work on an Agile development team building, testing, deploying and maintaining ETL pipelines for Panorama , a library analytics platform. This data engineer should be a self-starter, capable of handling multiple priorities simultaneously and a desire to broaden their development skills. Primary Responsibilities: Design and implement ETL pipelines based on product owner and data analyst requirements. Support and maintain ETL pipelines deployed in production environments Participate in new technology research, design and proof of concept work that will provide direction for the enhancement of Panorama Contribute to data engineering best practices for design, coding, performance, security, deployment, maintainability and culture Work alongside other data engineers to elevate technology and provide consistency across pipeline implementations Demonstrate ownership of components from development through production Requirements: Bachelor of Science in Computer Science, Data Science, a related field of study or equivalent practical experience 1+ years Python development 1+ SQL experience 3-5 years of experience in a data related field Excellent interpersonal skills and the ability to be a self-starter A drive to identify and close process gaps, such as automating manual tasks or adding missing documentation Preferred Qualifications: Experience with cloud-based analytics technologies – AWS, Snowflake, etc. CI/CD: Jenkins SCM: Git/GitHub Virtualization: Docker Container management: Kubernetes Database model: Data vault, star schema Database modeling tool: SqlDBM Orchestration: Apache Airflow Visualization: Tableau Additional languages: Java, bash, groovy COVID VACCINATION REQUIREMENT: As directed by Executive Order 14042: Ensuring Adequate COVID Safety Protocols for Federal Contractors, all current and newly-hired EIS employees in the United States are required to be fully vaccinated by January 18, 2022 or by their date of hire. We are an equal opportunity employer and comply with all applicable federal, state, and local fair employment practices laws. We strictly prohibit and do not tolerate discrimination against employees, applicants, or any other covered persons because of race, color, sex, pregnancy status, age, national origin or ancestry, ethnicity, religion, creed, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, training, promotion, discipline, compensation, benefits, and termination of employment. We comply with the Americans with Disabilities Act (ADA), as amended by the ADA Amendments Act, and all applicable state or local law."
"Software Engineer, Data",Pinterest,"Remote in San Francisco, CA 94103+1 location",https://www.indeed.com/rc/clk?jk=0e9f450352758f8c&fccid=43014b1412e0a7b6&vjs=3,"About Pinterest: Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet. Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our PinFlex landing page to learn more. The Enterprise Data Platform team is looking for a software engineer with experience building web applications using python. You'll work on building a self service framework that will potentially become the standard to manage RBAC(Role Based Access Control) on Snowflake in the industry. This will involve researching the current RBAC architectures, understanding the current Snowflake usage patterns and then designing and building the self service framework. What you'll do: Build a self service framework to do RBAC on Snowflake. Snowflake has a very powerful RBAC system but it is almost impossible to manage the web of access relationships it creates. You will be building a self service framework that will potentially become the standard to do RBAC on Snowflake in every company. Design and implement APIs and frameworks centered around making Snowflake a truly self service solution for end users. This will be open sourced after validating it internally, so it is a unique opportunity to start a greenfield open source project. What we're looking for: Strong skills in Python. Hands-on experience in developing web applications in python. Experience in translating abstract product needs into a technical solution. Ability to design and work with multiple layers: API, data storage and architecture, data retrieval. #LI-BB1 #LI-Remote Our Commitment to Diversity: At Pinterest, our mission is to bring everyone the inspiration to create a life they love—and that includes our employees. We’re taking on the most exciting challenges of our working lives, and we succeed with a team that represents an inclusive and diverse set of identities and backgrounds. Not Specified 0"
"Data Engineer - Redwood City, CA",MOLOCO,"Redwood City, CA 94063 (Middlefield area)+1 location",https://www.indeed.com/rc/clk?jk=e4b66e2aad9ce464&fccid=27317bcae2b26fe5&vjs=3,"About MOLOCO Moloco is a machine learning company that enables businesses to unleash the power of their own data for fast, sustainable growth and performance through the advertising ecosystem. Our technology is best-in-class as we received the SMARTIES X silver award for Machine Learning and AI and were named the Cross-Industry Winner for Google Cloud Customer Awards. Moloco is in hyper-growth mode, ranked #91 among Deloitte's 2021 Fast 500, and recently certified by 91% of the company via Great Places to Work. There isn't a better time to join this innovative team in our Silicon Valley HQ or our offices in San Francisco, Seattle, London, Seoul, Singapore, China, and Tokyo. About the Data Team We are seeking exceptional Software Engineers to join us in building a state-of-the-art mobile advertising platform. We understand the value of a strong engineering team and strive to hire only the best software engineers. While tackling challenging real-world problems, you will make a positive impact on millions of mobile users in the world and grow with top-notch colleagues. Check out our case study published by Google. We use various Google Cloud Products, including Bigtable, BigQuery, and Dataflow to manage big data. MOLOCO was featured as a customer example in the Data and Analytics Platform Overview at GCP Next'18. You can check out this video for more details about the company and the product (note that the presentation took place in July 2018, and we've grown & improved so much over the past two years!). What you'll do Turn unstructured logs, messages, and events into structured data that can be utilized for analytics, machine learning, and more. Implement backend data pipelines for manipulating and managing big data. Optimize data processing pipelines with different goals including latency, cost, and throughput. Improve existing data pipelines in terms of scalability and efficiency. Design and implement fraud prevention/detection algorithms through analyzing complex time-series data. Collaborate with other engineers at MOLOCO to build the best mobile advertising platform in the world. What you'll need to succeed BS in Computer Science or related fields (MS preferred) 2+ years of hands-on industry experience in software development. Excellent software development skills and fluency in at least one programming language (preferably Java, Go, or Python). Outstanding problem-solving skills. Fluent in English (both verbal and written). Experience in Cloud/Big Data platforms (e.g., AWS, GCE, Beam, Spark, etc.) preferred. Experience in distributed computing/MapReduce strongly preferred. All offers of employment are subject to background checks prior to start date. MOLOCO will consider for employment: qualified applicants with criminal histories in manner consistent with applicable local, state, and federal laws and Fair Chance Ordinances. MOLOCO is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics."
Data Engineer,Caesars Entertainment,"Las Vegas, NV",https://www.indeed.com/rc/clk?jk=fa35b8708aac17cf&fccid=bae55ff2c5ac1fca&vjs=3,"ESSENTIAL JOB FUNCTIONS A Data Engineer is a data and technology expert supporting the broader Data Systems team. The primary responsibility of a Data Engineer is to develop, maintain, and support data ingestion pipelines. Candidates that succeed in this role have a passion for technology and innovation, and understand the business value and meaning behind the data they work with. An ideal candidate should have a proven history as a strong independent contributor that designs source to target pipelines in a cloud first environment. Responsibilities include, but may not be limited to the following: Collaborate with business users to gather requirements, write functional and technical specifications and communicate technical requirements. Develop, configure, and support complex SQL and/or ETL solutions within various computing environments and pipelines. Define new capabilities and identify opportunities for continuous improvement. Document and comment code from design to completion to assist in future understanding of solutions. Perform technical reviews of code to maintain consistent technical direction and minimize system impact on production pipeline. Ability to work with stakeholders to identify high priority items and to allocate time effectively to meet expected deadlines TECHNICAL SKILLS REQUIRED Expertise in SQL is required; Must be comfortable working with large structured and unstructured datasets, and writing complex SQL logic to achieve the desired output. Background in end-to-end data pipeline development and deployment with at least 1+ year hands-on experience with cloud platforms required. Familiarity with SQL orchestration tools like Airflow and cloud platforms like Snowflake, Google Cloud Platform, or Azure highly preferred. Hands on development experience using ETL tools and code repositories required. Experience with programming languages such as C# and Python. Experience with modern BI Reporting platforms (such as Tableau, Power BI) preferred. KNOWLEDGE AND EXPERIENCE Minimum of 3 years of full-time work experience in data field Bachelor’s degree in technical field highly preferred Candidates must have the ability to uphold and demonstrate the highest level of integrity in all situations and recognize standards required by a regulated business"
Data & Software Engineer - Delivery (19_2022),Affinity Solutions,"Remote in San Jose, CA 95113",https://www.indeed.com/rc/clk?jk=a1b1447aa54b76ff&fccid=44009c0a01dfb8f3&vjs=3,"Location: San Jose, CA (preferred); New York City, NY; or Remote Department: Engineering Hours/Shift: Full Time Reports To: SVP, Software Engineering and Enablement Affinity Solutions is the trusted partner for marketers and agencies developing and applying actionable insights to deliver personalized customer experience that increase spend and drive hypergrowth. Affinity is powered by Panorama, which is an always-on, privacy-safe platform, within a safe-haven environment. Panorama deterministically matches actual purchase data, and complementary data sets, for audience scoring and validation that drives precision marketing. We help companies go from campaigns, to moments that move at the speed of the consumer. We are looking for a self-motivated Data & Software Engineer who will bring their expertise with consumer purchase-level data and data analytics to leverage data analytics solutions embodying purchase-level data into different market segments (financial services, advertising agencies and marketing service providers, retailers and publishers, etc.), delivering maximum impact to both existing and potential customers. Responsibilities Work with product management and engineering teams to improve the features of existing products and develop new solutions for customer deliverables. Work with sales and account management teams to understand the customer requirements, develop use cases, and map them to Affinity products. Work with engineering team to expand product use and configure products for customer deliverables. Partner with sales and account management teams to explain and demonstrate data analytic solutions to existing and potential customers. Qualifications: BS in Computer Science, Information Management Systems, or related field 3+ years of experience in data integration/data engineering 3+ years of experience with SQL, noSQL, and analytics data marts on MPP databases (e.g., RedShift) 1+ years of experience with cloud platforms (e.g, AWS); Apache Spark, Hadoop, and python; scripting languages (e.g., AWK); Tableau; REST API; and EMR Experience in UNIX /Linux development and production environments Experience with Agile software development environments Very strong communication skills: written, verbal, and presentation Knowledge of data science/machine learning a plus As a full-time member of Affinity Solutions’ team, your benefits will begin on the first of the month following your date of employment, with a generous Affinity Solutions contribution for medical, dental, and vision. In addition to company paid holidays, wellness time off, other wellness benefits, and employee discounts, you will also get Affinity-paid life insurance and have the option to enroll into an Affinity-matched 401K Plan. We strongly encourage work/life balance by providing unlimited vacation days, available after 90 days from your first day as a team member."
Data Engineer,RISIRISA,"New York, NY",https://www.indeed.com/rc/clk?jk=cb6316daece026d4&fccid=570de3d15b9bbb97&vjs=3,"Location: New York, NY Department: Engineering Type: Full Time Min. Experience: Mid Level RISIRISA is looking to hire a Data Engineer to join its team in New York. You will collaborate with Data Scientists and Design Technologists to build custom, data-driven tools to help our clients in the commercial, public, and social sectors solve a wide range of complex human-scale problems spanning global development, music, health, cybersecurity, etc. Requirements Ability to wrangle and process large data files into usable formats and databases Experience designing algorithms to perform analysis and aggregation on data Experience building and deploying production-level web services Enthusiasm for learning new techniques and technologies to solve hard problems Technical skills we look for: Python SQL Java Hadoop Ecosystem (Hive, Pig, etc.) Web/API building Familiarity with Javascript and NodeJS Familiarity with Git for version control Bonus: PHP Familiarity with production deployment and administration in Linux, Amazon AWS, Heroku, etc. Django NoSQL (Mongo, etc.) PostGRES Redis C++ iOS/Android development Apply to ris@risirisa.com"
Data Science Engineer,AI Cyber Solutions,"Tampa, FL 33614",https://www.indeed.com/rc/clk?jk=4388b5af8220a44a&fccid=ced61008a535f2bb&vjs=3,"Job Description AI Cyber Solutions is looking for an enthusiastic data science engineer to take and-to-end responsibility for processing systems and large-scale databases. The candidate would be involved in developing and designing architectures and AI or ML services. Besides, you’d also test and maintain the databases and systems. As a part of your role, you may have to clean and wrangle raw data to keep it readily available for analysis. Skills Required Python, Linux OS, Pandas, Scikit-learn, and other machine learning libraries Experience in deep learning on NLP/NLU is a big plus Solid understanding of mathematical underpinnings behind Machine Learning algorithms such as Probability, Statistics, Linear Algebra. Strong Understanding of ML concepts – Probabilistic Models, Supervised and Unsupervised Learning, Neural Networks, Support Vector Machines Has hands-on knowledge on setting up Docker containerization and running application on ECS,EKS Very good exposure in setting up Analytical tools such as RStudio, MLFLOW, Databricks, Jupyter etc. Bachelors/Masters in Computer Science, Engineering, Statistic/Mathematics or relevant field; graduate degree in Data Science or another quantitative field is preferred Tasks to be Performed Work with deep data and analytics skills with strong business acumen to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results. Experience using statistical computer languages R, Python, SLQ, NoSQL databases etc. to manipulate data and draw insights from large data sets Build topic analysis, text classification, named entity recognition methods for unstructured and semi-structured data Experience with Python ML libraries; Apache Spark and Kafka. Proficiency in machine learning techniques and data mining algorithms such as Regression, Clustering, Classification, Decision trees, KNN and SVM Ability to design algorithmic implementation for performing real-time and scalable learning machines Knowledge of open source machine learning libraries like scikit-learn, TensorFlow, NLP tool as NLTK Demonstrate and Document working prototype on test datasets and real-world scenarios. Demonstrate and Document working prototypes on test datasets and real-world scenarios. You’ll utilize the latest techniques in AI, ML (including Deep Learning approaches) and NLU Build topic analysis, text classification, named entity recognition methods for unstructured and semi-structured data Develop and perform text classification using methods such as logistic regression, decision trees, SVM and maximum entropy classifiers Perform text mining, generate and test working hypotheses, prepare and analyze historical data and identify patterns Generate creative solutions (patents) and publish research results in top conferences (papers) Design and develop AI/ML services on the platform Design and Develop customer use cases and applications Innovate to come up with new solutions and improve existing solutions. Be an enthusiastic and motivated member of the team."
"Data Engineer, ICS","HMA Group Holdings, LLC.","Remote in Waukee, IA 50263",https://www.indeed.com/rc/clk?jk=1499cfa51596da60&fccid=158a54f20c7f05c3&vjs=3,"Holmes Murphy is one of the nation’s largest privately held insurance brokerage companies. It is our mission to promote health, protect wealth, and deliver peace of mind to our clients. We pride ourselves on being a place where employees love what they do, and who they do it with! In fact, we live by our purpose statement of “Caring for your unique potential is our SOUL purpose!” Offering a fast-paced work environment and vibrant company culture, and the opportunity to share your unique potential, there really is no place like Holmes! We are looking to add a Data Engineer to join our Innovative Captive Strategies team in Waukee, IA or Remote. Ideal candidates will have an innovative mindset, strong interpersonal skills, and a love of learning. This role will support Innovative Captive Strategies division and overall company vision, mission and strategy by executing tactical plans to build and mature the data strategy for ICS. Duties: Work closely with ICS Leaders and Business Partners to: Execute tactical plans to build and mature the data strategy. Builds, tests, and maintains ETL flows to support data movement into and out of the claim management system and supports ICS data in the enterprise data lake. Create, maintain, and optimize queries, views, stored procedures, and functions which support data movement. Provides operational support for the scheduled jobs including monitoring, performance tuning and debugging of data movement flows utilizing automation whenever possible. Works with the ICS data analysts and business stakeholders to ensure the quality and accuracy of the data. Assist with data cleansing through bulk changes or development of a data strategy to address any data quality findings. Knowledge, Skills, and Abilities: Experience building scalable and robust ETL dataflows which maximize configuration and reusability to support data transformation, data movement, data structures and metadata. Alteryx or Azure Data Factory preferred Hands on experience with a variety of data sources, structured and unstructured, such as delimited, fixed width, database, blob, etc. Experience with APIs and/or RPA for the collection of third-party data. Salesforce experience preferred. Experience with cloud data storage, Azure preferred. Familiarity with data governance practices and data quality. Knowledge of Insurance Industry preferred. Ability to thrive in a fast-paced, ambiguous, highly collaborative environment. Eagerness to learn independently. Ability to challenge the status quo. Excellent organizational skills and the ability to manage multiple tasks/projects simultaneously. Communication skills required. Must be able to effectively communicate strategies and designs to all levels of the company. Capable of exercising discretion in confidential matters and use independent judgment. Ability to work with various personalities and in urgent scenarios. Ability to maintain a professionalism. Must be knowledgeable of and comply with our HIPAA regulations. Qualifications: Education: Associates or Bachelor’s degree in a science, technology or engineering, or math related, or equivalent work experience. Experience: At least four years of work-related experience. Benefits: Responsible Time Off Tuition Reimbursement after 1 year of employment Fitness Reimbursement Generous Parental Leave for all New Parent Benefits 401k Profit Sharing Flexible/remote work arrangements Holmes Murphy & Associates is an Equal Opportunity Employer.`"
Data Engineer,Northern Light,"Boston, MA 02129",https://www.indeed.com/rc/clk?jk=580f099cd77a645b&fccid=d8dbf670095ed04a&vjs=3,"Job Duties/Position Description Manage the flow of data from source to user, working in a fast paced and collaborative environment. Design and create services to collect data from wherever it is published and, in any format, and prepare data for text extraction and analysis. Design and create services to build, index, and serve big data collections to users in enterprise search systems. Develop, document, test and maintain data architectures. Identify ways to improve data reliability, efficiency, and quality. Use large data sets to address business issues for customers. Deploy sophisticated analytics programs, machine learning and statistical methods. Prepare data for predictive and prescriptive modeling. Troubleshoot and solve document flow and accessibility issues and communicating findings to the Content Operations Team and Project Managers. Northern Light has been providing knowledge management solutions for competitive intelligence and market research to global enterprises for more than 15 years. We have been around for a long time, but we never stand still. Northern Light is looking for an analytical, conceptual forward thinking technical expert that will take initiative, be personally creditable, and deliver results. Minimum Requirements Bachelor’s degree in Computer Science, related technical field or equivalent practical experience including 3+ years of experience with one or more general purpose programming languages, including Perl and Python. Preferred Experience and Skills Experience in large scale data processing using traditional and distributed systems Experience designing and operating data models and data warehouses as well as experience in SQL and NoSQL database management systems Experience with a continuous integration build system Experience with Linux environments Experience with git and docker Effective project management, problem solving, analytical and troubleshooting skills Knowledge of Test-Driven Development (TDD) Understanding of secure coding standards Benefits 401(k) Health insurance Dental insurance Employee assistance program Flexible schedule Flexible spending account Paid time off Parental leave Referral program Northern Light Careers Northern Light offers the chance to work with innovative knowledge management technology applied to enterprises’ market research and competitive intelligence needs, global Customers, and the greatest team of people ever assembled. The pace is fast. The environment is smart and fun. And the culture is fanatical about customer service. Working at Northern Light Northern Light is based in the Charlestown Navy Yard right beside the USS Constitution and across the river from the TD Garden and Boston’s North End. In addition, we have a development office in Bridgetown, Barbados and individual contributors working from home in the U.S., Russia, and Ukraine. COVID-19 considerations Northern Light Boston based employees are currently all working remotely. It is preferred that this position work from our Boston (Charlestown Navy Yard) office post-pandemic but is negotiable. Northern Light provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training."
Data Engineer,MassMutual,"Boston, MA 02124 (South Dorchester area)+2 locations",https://www.indeed.com/rc/clk?jk=8413856ed452d4c0&fccid=430cffbf1c607717&vjs=3,"What great looks like in this role Our ideal Data Engineer is someone who is passionate about data. You enjoy building data projects from the ground up and are equally comfortable working with business partners to understand requirements as you are developing and delivering robust solutions that meet the highest standards. Learning new technologies and working in the cloud excite you. You are team oriented and a strong communicator. Objectives of the role Design, build and maintain complex ELT jobs that deliver business value Translate high-level business requirements into technical specs Ingest data from disparate sources into the data lake and data warehouse Cleanse and enrich data and apply adequate data quality controls Provide insight and direction to guide the future development of MassMutual’s data platform Develop re-usable tools to help streamline the delivery of new projects Collaborate closely with other developers and provide mentorship Evaluate and recommend tools, technologies, processes and reference architectures Work in an Agile development environment, attending daily stand-up meetings and delivering incremental improvements Basic Qualifications Bachelor’s degree in computer science, engineering or a related field Data: 5+ years of experience with data analytics and warehousing SQL: Deep knowledge of SQL and query optimization ELT: Good understanding of ELT methodologies and tools Troubleshooting: Experience with troubleshooting and root cause analysis to determine and remediate potential issues Communication: Excellent communication, problem solving and organizational and analytical skills Able to work independently and to provide leadership to small teams of developers Preferred Qualifications Master’s degree in computer science or engineering or a related field Cloud: Experience working in a cloud environment (e.g. AWS) Python: Hands on experience developing with Python Advanced Data Processing: Experience using data processing technologies such as Apache Spark or Kafka Workflow: Good knowledge of orchestration and scheduling tools (e.g. Apache Airflow) Reporting: Experience with data reporting (e.g. Microstrategy, Tableau, Looker) and data cataloging tools (e.g. Alation) #LI-TM1 MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran. We welcome all persons to apply. Note: Veterans are welcome to apply, regardless of their discharge status. If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need."
Software Engineer - Data Engineer,Transform Data,"San Francisco, CA+1 location",https://www.indeed.com/rc/clk?jk=4898ad0ae4b2e278&fccid=f76e054c3245755c&vjs=3,"Company Overview At Transform, we are building a metrics repository that enables businesses to capture metric definitions in a standardized, well-formatted, and organized way to streamline analysis and enable decision-making with confidence and speed. We bridge the gap between those who know the data and those who need the data by creating a trusted metrics repository with an accessible user interface and a broad set of connectors to seamlessly pipe data to downstream systems. We are backed by Index, Redpoint, Fathom, and Work Life Ventures and have years of experience working on data at Airbnb, Facebook, Slack, BlackRock, and Instagram. We’ve dedicated our careers to improving data infrastructure, from warehouses to machine learning platforms. We saw at Airbnb that a metrics repository improves both the speed and trustworthiness of data across all tools at a company. Job Overview As a data engineer at Transform, you'll work on Transform’s core product, Metrics Query Language (MQL), a metrics framework for defining, efficiently computing, storing and serving metrics to applications. You'll contribute to a wide range of initiatives, flexing abilities from data science & data engineering, to backend systems & infrastructure engineering in order to deliver products. The ideal candidate will be proactive and opinionated about the future of data engineering systems and architecture patterns. This role is self-directed with the opportunity to grow into a leadership role. What You Will Do at Transform Develop and expand functionality of Transform’s core Metrics Framework & APIs Increase performance, reliability, and visibility across multiple companies & infrastructure patterns Work with customers to identify gaps in our product, pain points in their data systems and identify novel solutions to their challenges Learn from industry leaders; build a world-class team, mentor new engineers, and develop our diverse culture What You Will Need to Be Successful Experience designing, implementing, and maintaining data engineering tool and systems Natively speak core data engineering concepts like measures, dimensions, and partitions Familiarity with large scale data processing engines & SQL-like languages Ability to independently build lasting pieces of software, with little operational overhead High-level of familiarity with Python or other data-centric languages Nice to Haves Technical leadership and/or people leadership experience Familiarity with gathering feedback and working with customers of data or tools Experience or familiarity with the following software/tools: Location San Francisco / Remote Type Full time Department Engineering"
"Data Integration Engineer, Senior",Cook Children's Health Care System,"Fort Worth, TX 76104 (Southside area)+1 location",https://www.indeed.com/rc/clk?jk=03ddb3f1389fba4e&fccid=3c26f1aad54c6446&vjs=3,"***Must be willing to relocate to the Dallas/Fort Worth area*** The Data Integration Engineer Senior is responsible for developing, innovating, testing, maintaining, installing, and deploying interoperability solutions, middleware tools and related integrated technologies for determining best-fit data interchange and data integration. This position is a seasoned information technology professional, providing proficiency in programming and technical development of integrated solutions. This position mentors and trains less experienced staff. The Data Integration Engineer Senior delivers data integration solutions across legacy, newly developed, and purchased environments. The following are key responsibilities of an integration engineer: developing system modifications and specifications; data mapping; establishing interfaces; developing and modifying code, functions, programs, routines, and stored procedures to export, transform, and load data; meeting performance parameters; resolving and escalating integration issues; recommending adjustments as objectives change; provides consulting services to application teams, vendors and/or customers regarding how to integrate information technologies into clinical and business processes; designing and evaluating new data interchange formats; improving physical design; rewriting data policy, standards, and procedures and transitioning such. Skills sets for an integration engineer include Interface Administration, Web Services, HL7, EDI, FTP, TCP/IP, etc. using an Integration Engine(s) and/or middleware tools for configuration, scripting and programming, MS SQL and SSIS. Qualifications: Bachelor degree with five (5) or more years work experience as a Programmer, Technical or Systems Analyst and at least two (2) years’ experience in integration/interface programming, relational database programming or relational database administration or... Equivalent seven (7) years’ work experience with four (4) years related to integration/interface programming, system design/analysis, database administration and/or programming, and project leadership skills. Experience in interface administration and MS SQL/SSIS required. Experience in technical applications, scripting tools, report writing tools, form development tools, and WEB development tools such as C#. Experience in project management or as a project lead. Experience in systems analysis and design required. Experience in distributed process, multi system environment and integrated network. Must be able to effectively communicate with other CCHCS leadership, department managers, employees as well as the IT managers and staff of the Information Services department. Experience in interfaces using XML or HL7 or TCP/IP or EDI or FTP required. Licensure, Registration, and/or Certification Epic Bridges certification required within 6 months from date of hire, allowing for two test retakes. INDEPC Cook Children's is an EOE/AA, Minority/Female/Disability/Veteran employer. Location: Cook Children's Health Care System · IS-Epic Schedule: Full-Time, Days"
"Data Engineer, Data to Insights Initiative (D2I)",University of Texas at Austin,"Austin, TX 78701 (Downtown area)",https://www.indeed.com/rc/clk?jk=e4883d930d034924&fccid=f7282ad3490137c7&vjs=3,"Job Posting Title: Data Engineer, Data to Insights Initiative (D2I) - Hiring Department: IQ - Information Quest - Position Open To: All Applicants - Weekly Scheduled Hours: 40 - FLSA Status: Exempt - Earliest Start Date: Immediately - Position Duration: Expected to Continue Until Dec 31, 2025 - Location: Texas - Job Details: General Notes The Data to Insights (D2I) Initiative at UT Austin is an investment to build a trusted, integrated, and scalable information infrastructure that transforms complex UT data into valued insights for data-informed decisions. As part of D2I’s leadership group, you will work with a cross-campus team using the latest cloud technologies to build a next-generation data ecosystem via the UT Data Hub. The Associate Director for Legacy Data Services will skillfully plan and oversee the migration of UT’s current legacy data capabilities to the Data Hub. The goal of all of D2I’s work is to improve the availability of trusted information and data in support of operational and decision-making needs. We believe the best ideas arise from collaborative work among colleagues from varied backgrounds and experiences. We actively seek diversity of viewpoint and perception in our student, faculty, and staff recruiting and retention practices. If you’re the type of person who loves to learn and wants to know your work has meaning, you may find your career home at UT Austin. Please note that this position is currently funded through December 31, 2025. The University of Texas at Austin provides an outstanding benefits package to staff, including: Competitive health benefits (Employee premiums covered at 100%; family premiums at 50%) Vision, dental, life, and disability insurance options Paid vacation, sick leave, and holidays Teachers Retirement System of Texas (a defined benefit retirement plan) Additional voluntary retirement programs: tax sheltered annuity 403(b) and a deferred compensation program 457(b) Flexible spending account options for medical and childcare expenses Training and conference opportunities Tuition assistance Athletic ticket discounts Access to UT Austin's libraries and museums Free rides on all UT Shuttle and Capital Metro buses with staff ID card For more details, please see: https://hr.utexas.edu/prospective/benefits and https://hr.utexas.edu/current/services/my-total-rewards This position requires you to maintain internet service and a mobile phone with voice and data plans to be used when required for work. This position provides life/work balance with typically a 40-hour work week and travel generally limited to training (e.g., conferences/courses). Purpose The Data Engineer for the UT Data Hub improves university outcomes and advances the UT mission to transform lives for the benefit of society by increasing the useability and value of institutional data. You will create complex data pipelines into UT’s cloud data ecosystem in support of academic and administrative needs. In collaboration with our team of data professionals, you will help build and run a modern data hub to enable advanced data-driven decision making for UT. You will leverage your creativity to solve complex technical problems and build effective relationships through open communication Responsibilities Data Engineering: Assist in designing and automating scalable data integration solutions between institutional data sources, including the UT mainframe, and the Amazon Web Services cloud platform Assure performance and reliability of integration processes through monitoring, performance analysis and development of automated alerting processes Participate in end to end delivery of technical projects involving design and development of data pipelines for complex datasets Work closely with business partners to design and manage data pipeline elements including load frequency, data delivery mechanisms, and transformations Ensure that data pipeline solutions align with industry best practices, and adhere to UT security guidelines Develop and maintain detailed technical documentation of data pipeline processes Collaborate with key stakeholders including enterprise data architect, data modelers, data stewards, and subject matter experts (SMEs) Other responsibilities: Participate in change management processes to coordinate and communicate team activity. Other related functions as assigned Required Qualifications BS degree in Computer Science, Information Systems, Engineering, or equivalent professional experience. One year of Data Engineering experience with Amazon Web Services. One year of experience implementing and monitoring complex data pipelines and automation of cloud-based workloads. Proficiency in one or more scripting languages and/or programming languages, preferably Python. Advanced SQL knowledge and experience working with relational databases. Demonstrated experience of developing and implementing Continuous Integration and Continuous Delivery (CI/CD) systems. Proficiency in systems analysis, design, and a solid grasp of development, quality assurance, and integration methodologies. Excellent problem solving and troubleshooting skills. Relevant education and experience may be substituted as appropriate. Preferred Qualifications Three years of experience in Data Engineering or related field. One year of experience working in a cloud-based data warehouse environment. Two years of experience building and monitoring complex data pipelines. AWS Developer and/or Solutions Architect certification. Two years of experience with Agile software development methodologies. Two years of experience with issue tracking systems (JIRA). Experience with Spark, Kafka etc., is a plus. Salary $110,000 + depending on qualifications Working Conditions May work around standard office conditions Repetitive use of a keyboard at a workstation Use of manual dexterity Location up to 100% remote at employee discretion with office work environment also an option. Majority of team is located in Austin, TX, and working remotely with infrequent in-office presence. Required Materials Resume/CV 3 work references with their contact information; at least one reference should be from a supervisor Letter of interest Important for applicants who are NOT current university employees or contingent workers: You will be prompted to submit your resume the first time you apply, then you will be provided an option to upload a new Resume for subsequent applications. Any additional Required Materials (letter of interest, references, etc.) will be uploaded in the Application Questions section; you will be able to multi-select additional files. Before submitting your online job application, ensure that ALL Required Materials have been uploaded. Once your job application has been submitted, you cannot make changes. Important for Current university employees and contingent workers: As a current university employee or contingent worker, you MUST apply within Workday by searching for Find UT Jobs. If you are a current University employee, log-in to Workday, navigate to your Worker Profile, click the Career link in the left hand navigation menu and then update the sections in your Professional Profile before you apply. This information will be pulled in to your application. The application is one page and you will be prompted to upload your resume. In addition, you must respond to the application questions presented to upload any additional Required Materials (letter of interest, references, etc.) that were noted above. - Employment Eligibility: Regular staff who have been employed in their current position for the last six continuous months are eligible for openings being recruited for through University-Wide or Open Recruiting, to include both promotional opportunities and lateral transfers. Staff who are promotion/transfer eligible may apply for positions without supervisor approval. - Retirement Plan Eligibility: The retirement plan for this position is Teacher Retirement System of Texas (TRS), subject to the position being at least 20 hours per week and at least 135 days in length. - Background Checks: A criminal history background check will be required for finalist(s) under consideration for this position. - Equal Opportunity Employer: The University of Texas at Austin, as an equal opportunity/affirmative action employer, complies with all applicable federal and state laws regarding nondiscrimination and affirmative action. The University is committed to a policy of equal opportunity for all persons and does not discriminate on the basis of race, color, national origin, age, marital status, sex, sexual orientation, gender identity, gender expression, disability, religion, or veteran status in employment, educational programs and activities, and admissions. - Pay Transparency: The University of Texas at Austin will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. - Employment Eligibility Verification: If hired, you will be required to complete the federal Employment Eligibility Verification I-9 form. You will be required to present acceptable and original documents to prove your identity and authorization to work in the United States. Documents need to be presented no later than the third day of employment. Failure to do so will result in loss of employment at the university. - E-Verify: The University of Texas at Austin use E-Verify to check the work authorization of all new hires effective May 2015. The university’s company ID number for purposes of E-Verify is 854197."
Data Analyst/Engineer,Willis Towers Watson,"Chicago, IL",https://www.indeed.com/rc/clk?jk=35bce75386b5292a&fccid=fcd059ccedda91fb&vjs=3,"We know how companies can unlock potential through effective risk management. Our clients rely on us to craft strategies to quantify, mitigate, and transfer risk, taking advantage of our specialist industry experience and unparalleled market know-how. The result is a new way of embracing risk that drives superior results. The Data Analyst/Engineer provides key analytical support leaders in finance, operations, sales and client management. This role will require efficiently cleansing and analyzing data, deriving insight, and partnering with business leaders to deliver those insights. Heavy interaction and collaboration is required with core business leadership is required to maintain consistent output and delivery of relevant information. The Role Analytic Output Development Simplify/automate data analysis workflows and modernize reporting processes Assist in requirements gathering and development of relevant reporting and analytical tools to support stakeholder needs Provide support for stakeholders with recurring as well as ad hoc reporting including contractually obligated reporting Approach tasks with an entrepreneurial mindset looking for new opportunities Provide data and feedback to management on use of systems and processes Support data integrity of systems and applications Note: Employment-based non-immigrant visa sponsorship and/or assistance is not offered for this specific job opportunity. The Requirements Bachelor’s degree required; advanced degree in computer science, finance, or analytics a plus Minimum 1 year of relevant experience with analytics and reporting systems Insurance industry knowledge a plus Experience with advanced business analytics platforms and languages including but not limited to PowerBi, Tableau, SPSS, Looker, SQL, R, Python Strong verbal and written communication skills required; ability to communicate directly with executive level audiences Proficient to expert level understanding of Microsoft Office applications Strong understanding of data and ability to distill complex raw data sets into easy-to-follow narratives Team player with collaborative interdisciplinary nature WTW may be subject to mandatory employment-related COVID-19 vaccination requirements. Therefore, to the extent any such mandates apply, you may be required to certify and provide documentation of full vaccination against COVID-19 if you are hired in the U.S. If you accept an offer from WTW and are subject to a mandate but are unable or unwilling to be vaccinated because of medical reasons or sincerely-held religious beliefs, you may request a medical or religious accommodation. If you require an accommodation, the Company will evaluate your request and work with you to identify reasonable alternatives to vaccination, if available. EEO, including disability/vets"
Associate Data Science Engineer,Gap Inc.,"San Francisco, CA 94105 (Financial District/South Beach area)",https://www.indeed.com/rc/clk?jk=9a4bd40016f27519&fccid=76644a33987f2488&vjs=3,"About Gap Inc. Our brands bridge the gaps we see in the world. Old Navy democratizes style to ensure everyone has access to quality fashion at every price point. Athleta unleashes the potential of every woman, regardless of body size, age or ethnicity. Banana Republic believes in sustainable luxury for all. And Gap inspires the world to bring individuality to modern, responsibly made essentials. This simple idea—that we all deserve to belong, and on our own terms—is core to who we are as a company and how we make decisions. Our team is made up of thousands of people across the globe who take risks, think big, and do good for our customers, communities, and the planet. Ready to learn fast, create with audacity and lead boldly? Join our team. About the Role This position will be part of the Data Science Engineering team at Gap Inc, whose primary goals include building data products and infrastructure that support analytics and data science at scale. With business users all across the company, the team works cross-functionally to ensure reports, analytics, and models are supported by a stable, efficient, and accurate back-end. What You'll Do Partner with internal customers to understand business needs and build strong relationships with key stakeholders. Develop, deploy, and support analytic data products, such as data marts, ETL’s (extract/transform/load), functions (in Python/SQL/R), and visualizations. Navigate various data sources and efficiently locate data in a complex data ecosystem. Work closely with our data scientists to ensure production models are built using a scalable back-end. Maintain and support deployed solutions and data products. Who You Are BA/BS preferred in a technical or engineering field (Master’s preferred). 1-3 years of experience in a data engineering or full-stack data scientist role. Strong understanding of relational databases and SQL. Solid programming foundations and proficiency with data related languages such as Python and R. Excellent communication skills. Ability to effectively communicate with both technical and non-technical audiences. Notice to applicants in San Francisco: Gap Inc. and its related brands will consider for employment, qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. The Fair Chance Ordinance is provided here: English Spanish Chinese Tagalog Benefits at Gap Inc. Merchandise discount for our brands: 50% off regular-priced merchandise at Old Navy, Gap, Banana Republic and Athleta, and 30% off at Outlet for all employees. One of the most competitive Paid Time Off plans in the industry.* Employees can take up to five “on the clock” hours each month to volunteer at a charity of their choice.* Extensive 401(k) plan with company matching for contributions up to four percent of an employee’s base pay.* Employee stock purchase plan.* Medical, dental, vision and life insurance.* See more of the benefits we offer. For eligible employees Gap Inc. is an equal-opportunity employer and is committed to providing a workplace free from harassment and discrimination. We are committed to recruiting, hiring, training and promoting qualified people of all backgrounds, and make all employment decisions without regard to any protected status. We have received numerous awards for our long-held commitment to equality and will continue to foster a diverse and inclusive environment of belonging. This year, we’ve been named as one of the Best Places to Work by the Human Rights Campaign for the seventeenth consecutive year and have been included in the 2021 Bloomberg Gender-Equality Index for the fourth year in a row."
Sr Software Data Engineer (REMOTE),GEICO,"Remote in Chevy Chase, MD 20815",https://www.indeed.com/rc/clk?jk=c31442a5efc93f00&fccid=71b1543b29473502&vjs=3,"GEICO's – Data Management Services department is seeking highly motivated Software Engineers who will help build and grow GEICO’s data governance capabilities. The mission is to build a program where data lineage is embedded in all aspects of the data lifecycle, in the least intrusive way possible. Qualified candidate must have a passion for software engineering, researching, and developing strategies. Qualified candidates must have the ability to plan, prioritize, initiate, execute, and work on complex projects and initiatives. The role demands attention to details, great interpersonal skills, and strong oral and written communication skills. A successful candidate must also be able to effectively communicate technical and non-technical concepts across all levels of the organization. As a Senior Software Engineer , you will provide support and services for the build, enhancement, and maintenance of our data governance management platform. You will meet regularly with the vendor to ensure high quality service delivery and maximization of product value. You will also partner and work closely with the Enterprise Data Governance team and Enterprise Data Architecture team to ensure that the platform support the needs of our data traceability initiatives. Technical Experience/Skills Required: Experience in Azure Ecosystem (Azure Data lake, Azure Data Factory, Azure Data Bricks, Azure Storage, Cosmos DB, ADO) Understanding and experience working with Microsoft Azure DevOps (work items, build/release, CICD) Understanding of Data Modeling concepts and Data Architecture (Visual Studio) Track-record of successful project delivery, building collaborative cross-functional relationships, and an ability to find creative ways to solve business problems Ability to support multiple stakeholders/projects simultaneously and work in a very fast-paced environment Possess a strong sense of ownership, responsibility, motivation, and continuous improvement Experience in Data Engineering and modern warehousing technologies such as Snowflake Understanding of code development best practices, process design and automation, security concepts, Agile concepts, tools, and technologies Knowledge on Data Ingestion/ streaming tooling such as Kafka, Spark, or similar technologies Familiarity with DevOps landscape, processes, standards, and tools Strong critical thinking, decision making, troubleshooting and problem-solving skills Excellent oral and written communication skills May be required to be on call for production support 24x7 Desired Qualifications: 3+ years of experience designing, building, optimizing, and scaling data solutions using distributed computing Experience in Safe Agile frameworks and methodologies (Atlassian, Azure DevOps), Software Development Lifecycle (SDLC) experience is a plus. Bachelor’s degree in Computer Science or related field; or equivalent work experience Strong understanding of data Ingestion, data transformation, data management, data quality, and data lineage services and technologies Experience with Metadata management tools (Microsoft Purview, Collibra, Alation, Informatica, etc.) Experience with relational database concepts / technologies (SQL, Oracle, etc.) Experience with cloud Datawarehouse Snowflake Benefits: At GEICO, we make sure you have the support and resources to leverage and develop your skills, secure your financial future, and take care of your health and well-being. GEICO continually seeks to provide a workplace where everyone can be their authentic self. To help achieve this goal, we support associate-led Employee Resource Groups that foster a true sense of community. Through GEICO’s competitive benefits offerings and various training and development opportunities, we have you covered with our Total Rewards Program* that includes: Premier Medical, Dental and Vision Insurance with no waiting period** Paid Vacation, Sick and Parental Leave 401(k) Plan with Profit Sharing Tuition Reimbursement Paid Training and Licensures Benefits may be different by location. Benefit eligibility requirements vary and may include length of service. **Coverage begins with the pay period after hire date. Must enroll in New Hire Benefits within 30 days of the date of hire for coverage to take effect. GEICO is proud to be an equal opportunity employer. We are committed to cultivating an environment where equal employment opportunities are available to all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO celebrates diversity and believes it is critical to our success. As such, we are committed to recruit, develop and retain the most talented individuals to join our team. #LI-SS3"
Data & Applications Engineer,Northeast Metro 916 Intermediate School District,"Little Canada, MN",https://www.indeed.com/rc/clk?jk=f0b8ccc338913d45&fccid=fe91c6fa5873770a&vjs=3,"JobID: 2511 Position Type: Technology/Data & Applications Engineer Date Posted: 6/13/2022 Location: Quora Education Center (Little Canada) NORTHEAST METRO 916 INTERMEDIATE SCHOOL DISTRICT VACANCY NOTICE Date Posted: June 13, 2022 Position Title: Data & Applications Engineer Assignment: Information Services Salary: $68,931.20 - $86,174.40 (salary placement dependent upon applicable experience) Benefits Package: We offer a highly competitive benefits package that includes significant contributions towards medical and dental premiums (see attached), 15 days paid vacation (increase to 20 days after 1 year of service), 13 paid holidays, 15 sick days, retirement contributions to both PERA and a 403(b), employer paid life insurance and long-term disability, Flexible Spending Accounts (FSA) and employer contributions to a post retirement Health Care Savings Plan. FTE: 1.0 (260 days) Expected Starting Date: ASAP Nature of Work: This is the third level in the Technology Series. Incumbents are responsible for planning, analyzing, designing and implementing information systems, network, server, hardware, and/or database. Responsibilities may include: designing, developing and maintaining network, application, server, database, or related solutions; troubleshooting, testing, and deploying resources; and providing advice and guidance related to updating and improving technology solutions. Typical Class Responsibilities: Conducts needs assessment to identify District and user technology needs; determines project parameters; and designs and develops new systems, applications, or database solutions; Analyzes, tests, codes, maintains, and debugs systems, applications, reports, and related technology and services; develops coding standards; processes system production requests; and manages and administers the network, backup and recovery protocols, servers, and other technology applications; Researches, diagnoses, and troubleshoots information technology issues and discovers sources of errors; assesses the performance of servers, networks, applications, or other related systems; analyzes security measures and other systems information and implements necessary solutions; Provides recommendations to assist in the planning, strategic decisions, implementation, improvements, and maintenance relative to networks, applications, infrastructure, and other technologies and systems; and provides level two consultations to technology staff for escalated issues; Maintains network and server documentation; monitors the configuration and documentation of related systems; and maintains records of related inventories. Performs other duties of a similar nature or level. Functional Specific Responsibilities: Design and Implement database solutions and models in partnership with other district data team members and district staff; Design and code custom interfaces, and data collection systems in partnership with other district data team members and district staff; Maintain and update existing custom designed database and data collection solutions (Javascript, Google Apps Script, SQL Queries), applications and scripts based on district requested changes or service provider updates/changes; Assess database implementation procedures to ensure they comply with internal and external regulations and security best practice; Create and modify reports using mostly and Google Data Studio with data sources ranging from 3rd party databases to internal applications; Respond to emergency outages of software, data systems and reports and troubleshoot the causes of the issues and find solutions. Training and Experience Requirements: 3+ years of experience and training in Computer Science, Software Engineering, Full Stack Application Design, or related fields. Knowledge Requirements: Software, hardware, and networking principles; Applicable hardware, software, and peripheral equipment; Applicable operating systems; Applicable programming languages; Systems analysis and design principles; Project management principles; Process improvement principles; Network structures; Technology troubleshooting techniques; Customer service principles; Applicable local, state, and federal laws, rules, and regulations; Recordkeeping principles; Computers and related software applications. Skill Requirements Installing, configuring, and troubleshooting technological platforms, applications, and systems; Designing, developing, and implementing applications; Identifying and interpreting customer requirements and translating into system specifications; Establishing and following procedural and technical standards; Evaluating, troubleshooting, and resolving hardware, software, network, and peripheral problems; Communicating technical information to a non-technical audience; Providing customer service; Preparing and maintaining records and reports; Operating a computer and applicable software applications; Communication and interpersonal skills as applied to interaction with coworkers, supervisor, the general public, etc. sufficient to exchange or convey information and to receive work direction. Physical Requirements : Positions in this class typically require: reaching, standing, walking, fingering, grasping, feeling, talking, hearing, seeing, and repetitive motions. Sedentary Work: Exerting up to 10 pounds of force occasionally and/or a negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects, including the human body. Sedentary work involves sitting most of the time. Walking and standing are required only occasionally . Commitment to Equity At Northeast Metro 916, equity means that everyone has access to what they need in order to learn, grow and thrive. Northeast Metro 916 will not discriminate against individuals based on race, color, creed, religion, national origin, sex, marital status, parental status, status with regard to public assistance, disability, age or sexual orientation."
Data Engineer III,Rackspace,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=0329875c392d717d&fccid=b60c9324aeb7df96&vjs=3,"Job Profile Summary Applies data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources. Creates data collection frameworks for structured and unstructured data. Develops and maintains infrastructure systems (e.g., data warehouses, data lakes) including data access APIs. Prepares and manipulates data using Hadoop or equivalent MapReduce platform. Responsible for adhering to company security policies and procedures and any other relevant policies and standards as directed. Career Level Summary Requires in-depth conceptual and practical knowledge in own job discipline and basic knowledge of related job disciplines. Solves complex problems. Works independently, receives minimal guidance. May lead projects or project steps within a broader project or may have accountability for on-going activities or objectives. Acts as a resource for colleagues with less experience. Level at which career may stabilize for many years or until retirement. Critical Competencies Serves as an expert in the efficient and effective gathering and organization of data. Experienced in cloud migration/building data pipelines on Cloud using Python and pushing data to BigQuery Utilizes a strategic approach to plan for the use of complex data to create synergies across teams. Selects appropriate analytical models and tools to analyze big data sets, develop business recommendations and support decision-making. Develops and shares expert knowledge of customer's organization structure (e.g., geographies, business units), operations and business processes, and how they support the customer's strategic objectives, in order to identify customer needs Identifies customer’s key decision makers and leverages an understanding of their unique perspectives and priorities when building relationships Maintains thorough knowledge of customer’s industry, including key market and economic factors impacting business performance, as well as competitive landscape, in order to assist in creating effective customer solutions Demonstrates an understanding of complex offerings and tailors solutions to meet the unique needs of the customer. Demonstrates advanced understanding of products, technologies, offerings, etc. and coaches other colleagues in building their knowledge. Leverages knowledge of competitors’ products and services as well as their strengths and weaknesses to compare choices. Key Responsibilities Other Incidental tasks related to the job, as necessary. Build Pipelines reading data from different sources like Postgress, Oracle into google cloud using Airflow and Bigquery Build complex ETL code Build complex SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL Work on Data and Analytics Tools in the Cloud Develop code using Python, Scala, R languages Work with technologies such as Spark, Hadoop, Kafka, etc. Build complex Data Engineering workflows Work with team to solve a variety of problems using machine learning techniques, and implement cloud-based solutions for customers Create complex data solutions and build data pipelines Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates Capture and share industry best practices amongst the community Attend and present valuable information at Industry Events Knowledge Basic conceptual knowledge on cloud Data platform Services and solutions. Knowledge on ETL /ELT data pipelines on Cloud Knowledge of building ETL /ELT data pipelines on Cloud: participate in code reviews, active player in building cloud data solutions hadoop ecosystem, RDBMS, DW/DM, learn from deep architectural discussions Skills Devises new methods and procedures for collecting data; performs complex data analyses and presents findings on the underlying principles, reasons or facts. Utilizes knowledge and experience to perform data and database management responsibilities on multiple systems and to assist with policy and procedure development. Demonstrates proper techniques for preparing and filing complex regulatory correspondence in an organized and concise format, sending documents to regulatory agencies as requested. Education Bachelor's or Masters Degree in Computer science, Information Systems or related technical degree required Certifications Cloud certifications such as GCP Professional Data Engineer or Microsoft Data / AI certifications. Experience 5 – 7 years of experience in the field of role required. Physical Demands General office environment: no special physical demands required. May require long periods of sitting and viewing a computer monitor. Schedule flexibility to include working weekends and/or evenings and holidays as required by the business for 24/7 operations. Must be able to lift 50 lbs over-head. Travel Occasional domestic/international travel, less than 50% Disclaimer The above information has been designed to indicate the general nature and level of work performed by employees in this classification. It is not designed to contain or to be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of the employee assigned to this job. The following information is required by the Colorado Equal Pay Transparency Act and applies only to individuals working in the state of Colorado. The anticipated starting pay range of Colorado applicants for this role is $81 ,600 –$105,800. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, licenses and certifications, and specific work location. Information on benefits offered is here About Rackspace Technology We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future. More on Rackspace Technology Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know."
"Cloud, BI, Data Engineer","JPMorgan Chase Bank, N.A.","Jersey City, NJ+9 locations",https://www.indeed.com/rc/clk?jk=5096d6dbb2884283&fccid=aaf3b433897ea465&vjs=3,"As an experienced member of our CIB Technology Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally. This role requires a wide variety of strengths and capabilities, including: BS/BA degree or equivalent experience. 5+ years of experience in Cloud Technologies (e.g. AWS/Azure/Google Cloud). Experience in designing BI solutions on large datasets with a hands on experience on modern data visualization tools (e.g. Tableau, Amazon Redshift). 3+ years of experience with AWS Redshift / AWS Glue and or equivalent on AWS.. 5+ years of programming experience (at least 2 Java, Python, C#). Proficient and knowledge about data warehousing concepts. Understanding data and query optimization, query profiling, and query performance monitoring tools and techniques. Knowledge on database design techniques and experience on working with extremely large data volumes at scale. Knowledge of architecture, design and business processes including data cataloging, metadata management, data API development etc. Ability to work independently with the business counterparts. Solid understanding of development using SCRUM and Agile practices. JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management. We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs. The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment. As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law. Equal Opportunity Employer/Disability/Veterans"
Data Engineer,Surya Systems,+4 locationsRemote,https://www.indeed.com/rc/clk?jk=d37fc152f05c9c46&fccid=af1cebb7f11ae180&vjs=3,"Overview Position: Data Engineer Location: REMOTE Duration: 12 Months As a Data Engineer you will build curated datasets and make them accessible to our partner teams by writing at scale production data pipelines. Your work will enable the decision-makers across the service operations organization to bring together insights and support our operations strategy and customer experience. In this role you will: Design, develop, and launch extremely efficient and reliable data pipelines to move data and to provide intuitive analytics to our partner teams. Make data more discoverable and easy to use for Data Scientists and Analysts across the service operations organization Collaborate with other engineers and Data Scientists to discover the best solutions. Diagnose and solve issues in our existing data pipelines and envision and build their successors.Qualifications Qualifications: Good understanding of one or more of the following: Python, Scala, or Java Strong understanding of SQL Broad knowledge of the data infrastructure ecosystem Experience with Hadoop or other MapReduce-based architectures Experience working with large data volumes Experience in building Data Warehouses and data modeling. Experience with any of the following is a plus: BigQuery, Presto, or Hive Thanks & Regards... G Naveen Kumar Email : ************* Desk : 215-344-2345 Surya Systems, Inc"
SUMMER / FALL 2022 CO-OP – SOFTWARE DEVELOPER / DATA ENGINEE...,Ellington Management Group,"Old Greenwich, CT",https://www.indeed.com/rc/clk?jk=4cce6d233072c60a&fccid=aa0b9b1e26a22f05&vjs=3,"SUMMER / FALL 2022 CO-OP – SOFTWARE DEVELOPER / DATA ENGINEER Ellington Management Group is looking for Summer / Fall Co-Ops with exceptional programming and analytical skills. As a Co-Op, you will be responsible for the following: Work with Python / Selenium / (or equivalent scripting tool) to automate the retrieval of data from various websites. The Co-op will be involved in programming the tool to generate a script file that will be executed by a service to automate the extraction / retrieval of data. Work with our existing web applications by adding new functionality / refactoring existing controls. Work with existing monitoring frameworks to improve data flow quality and consistency. The Co-op’s tasks will involve learning existing data flows, writing various SQL scripts to check data consistency, and interact with existing monitoring frameworks. Assist in various coding refactoring and documentation tasks. General Qualifications: 3.0 Overall GPA The applicant should be a matriculated college student or recent grad studying Computer Science, Computer Engineering, Information Technology, Management Information Systems, or related Relevant programming and/or database exposure a plus Demonstrated skills in analyzing, formulating, trouble-shooting, and synthesizing data Knowledge of C#, Python, SQL, Service Oriented Architecture with Web front-ends (Single-Page-Application frameworks) About Ellington Ellington Management Group, LLC was founded in December 1994 and includes a family of registered investment advisers, (together “Ellington”). Ellington currently has approximately $13 billion of assets under management in hedge funds and similar accounts. Ellington’s core strategies include its credit strategies, its prepayment and related relative value strategies, and its systematic strategies. Ellington is known for its highly analytical approach to portfolio construction and risk management, including extensive proprietary models that we believe provides us with a distinct competitive advantage over other market participants. Ellington manages funds and private accounts for both U.S. and non-U.S. investors, including major pension funds, foundations, commercial and private banks, family offices, insurance companies, and funds of funds. Ellington employs over 160 people at its offices in New York City, Old Greenwich, Connecticut and London, England. More information regarding Ellington can be found at www.ellington.com. Ellington Management Group is an Equal Opportunity Employer. Ellington's policy is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age or any other characteristic protected by applicable law."
"Data Science Engineer, AV Behavior Test",NVIDIA,"Santa Clara, CA",https://www.indeed.com/rc/clk?jk=5fbd3756ac4ccb4f&fccid=c267f29f0f85e8b8&vjs=3,"The Automotive Vehicles team is searching for a creative and experienced Data Science Engineer or Analyst to help us bring NVIDIA's autonomous vehicle solution out to the world. You will participate in a focused effort to develop and productize ground-breaking solutions that will redefine the world of transportation and the growing field of self-driving cars. You will work with hardworking and dedicated multi-functional engineering development teams across various vehicle subsystems to integrate their work into our AV SW platform, while achieving or exceeding all meaningful NVIDIA and automotive standards & guidelines. You'll find the work is exciting, fun, and relevant. We have deadlines, customers, and competition. What you will be doing: Develop statistical test methods for understanding the impact of recent software changes on different aspects of autonomous driving. Prototype & pilot new/improved processes to reduce noise and de-bias simulation and road data of our AVs. Develop metrics and ML models to quantify drive performance, identify patterns and attribute those to sub-systems. Prototype tools to identify gaps in the systems, identify genuine changes in simulation or road drives and improve speed and effectiveness of testing and release processes. Build novel diagnosis and monitoring systems (ML- or heuristic-based) to reduce manual time spent in diagnosis and root-causing. Build insights and dashboards that allow others to understand and continuously iterate on software performance for all levels and stages of development and testing. What we need to see: BS (or equivalent experience), MS, or PhD in Engineering or Science field. 3+ years of experience in data science or analytics Substantial experience with Python/C++ and SQL in a software driven environment. Familiarity with ML development Experience working with large datasets, SQL and Python or C++. Strong leadership and interpersonal skills, with the ability to drive alignment across large organizations. Ways to stand out from the crowd: Background with autonomous vehicles and/or machine learning. Experience with start-ups and/or early-stage products. The Colorado Equal Pay for Equal Work Act requires that NVIDIA provide the compensation range and benefits offered for this position if performed in Colorado. The base salary range for this position in Colorado is $190,800.00 - 262,350.00 USD. NVIDIA also offers a comprehensive benefits package. We provide health care coverage, dental and vision, 401(K), including company matching and after tax contributions, Employee Stock Purchase Program (ESPP), Employee Assistance Program (EAP), company paid holidays, paid sick leave, vacation leave, professional time off, life and disability protection. Employees in eligible sales and positions may also be eligible for commission. Base pay is based on market location and may vary based on factors including experience, skills, education, and other job-related reasons. NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law. #deeplearning"
Senior Software Engineer - Big Data Technologies,Visa,"Foster City, CA+2 locations",https://www.indeed.com/rc/clk?jk=cc3e9c68fd710b67&fccid=a3f737e511d9fc8c&vjs=3,"Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description We are developing and executing a shared strategic vision for Loyalty & Marketing Services platforms and products that enable Visa to be the world-leading data-driven payments company. As a Sr. Software Engineer, you will be part of world-class team of Engineers to define, drive and execute on this vision. We are looking for a self-motivated individual with software engineering skills and expertise with Java and Big Data technologies. The candidate will be extensively involved in hands-on activities including POCs, design, development, testing, and documentation. Candidate must be flexible and willing to switch tasks based on team s needs. Primary responsibilities will include: Design and develop mission-critical systems, delivering high-availability and performance Work on development of new products and enhancements to existing systems iteratively by building quick POCs and converting ideas into real products Work closely with architects, business, and technical stakeholders to develop high quality products and services that meet business requirements and expectations while applying the latest available tools and technology Follow best practices for software development, and deliver high quality work on tight schedules Identify opportunities for further enhancements and refinements to standards and processes Mentor junior team members, develop departmental procedures and best practices standards Help coordinate Continuous Integration activities, testing automation frameworks, and other related items in addition to contributing core product code Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner Will delegate and review others engineers work on small projects Most important qualities for the candidate are: Academics : Bachelor or Master s degree in Computer Science or related field Leadership : Leading solutions and working with teams to achieve it. Curiosity : A desire to seek clarity of requirements and why tasks are done a certain way Creativity : The ability to take a list of needs and insights and come up with other innovative ideas. Strategic focus: Skill to understand big picture and stay focused on task to achieve goals Attention to detail: The capability to perform any research systematically and accurately Strong work ethic: The innate drive to do work extremely well Enthusiasm: A passion to understand people and deliver better products and services to them Qualifications Basic Qualifications: 2 or more years of work experience with a Bachelor Degree or an Advanced Degree (e.g. Masters, MBA, JD, MD, or PhD). Preferred Qualifications: Java and Big Data technologies like Hive, Hadoop, and Spark 3 or more years of work experience with a Bachelor Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) Understanding and working experience with shell scripting Knowledge and working experience on Git/Stash, Ant, Maven, Jenkins and Jira Experience with database technologies like DB2, Oracle, SQL Server Knowledge of Unix/Linux Strong foundation in computer science, with strong competencies in data structures, algorithms and software design optimized for building highly distributed and parallelized systems Experience with Agile & DevOps methodologies Excellent analytical and problem-solving skills with a strong automation mindset Ability to handle multiple competing priorities in a fast-paced environment Good written and verbal communication skills. Ability to effectively communicate the logic and implementation plan to team members & managers Quick learner, self-starter, detailed and thorough Additional Information Visa has adopted a COVID-19 vaccination policy to safeguard the health and well-being of our employees and visitors. As a condition of employment, all employees based in the U.S. are required to be fully vaccinated for COVID-19, unless a reasonable accommodation is approved or as otherwise required by law. Work Hours: Varies upon the needs of the department. Travel Requirements: This position requires travel 5-10% of the time. Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers. Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code."
Data Engineer - Integrations,Nuna,"Remote in San Francisco, CA 94123",https://www.indeed.com/rc/clk?jk=6fc287896dcec65d&fccid=3cb3ba377c877a98&vjs=3,"At Nuna, our mission is to make high-quality healthcare affordable and accessible for everyone. We are dedicated to tackling one of our nation's biggest problems with ingenuity, creativity, and a keen moral compass. Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why. Nuna partners with healthcare payers, including government agencies and health plans, to turn data into learnings and information into meaning. YOUR TEAM Data Engineering is at the core of Nuna's promise to deliver exceptional and actionable data insights to our clients. We are responsible for the scalable comprehension, ingestion, cleaning, and deploying of client data on schedule - think of us as the heart muscle that pumps data throughout Nuna. And because quality and consistency are our hallmarks, we're more than a little obsessed with detail and process. YOUR IMPACT Data Engineering is a cross-functional team that supports Nuna's Enterprise Product Suite. We untangle messy and complex healthcare data and enable our Data Science and Analytics teams to perform and deliver exceptional analytics to our clients. YOUR OPPORTUNITIES Map, extract, transform and load data from source to target through multiple stages Perform data quality assessment, measurement, and reporting Collaborate with product managers, data scientists, data analysts and engineers to define user requirements and database design specifications for our clients' needs. Analyze data feed requirements received from vendors, translate business requirements into technical design specifications. Build out new API and functionality for data ingress/egress with our customers systems. Use your knowledge of SQL to perform data analysis based on business requirements and data profiling reports. Maintain and ensure monthly data updates are delivered on-time to our customers Serve as a technical resource in resolving client issues related to database or other data issues Work closely with client-facing teams Work directly with clients and lead client calls when needed Construction and automation of data pipelines YOU BRING Ability to use SQL for developing robust and scalable ETL pipelines. Experience working with Python for API integrations and pipeline automation. Experience working with data, preferably healthcare data, and databases. Experience with data quality processes, data quality checks, validations, data quality metrics definition and measurement. Ability to construct and debug complex SQL queries. Ability to operate with cross-functional teams (e.g., implementation managers, data science, engineers, etc.). Strong communication and teamwork skills. BA/BS in statistics, math, data science, or computer science (or related field) BONUSES Healthcare experience is preferred. Demonstrated track record working with data warehouse and ETL architectures and concepts plus. Experience with cloud infrastructure (AWS, Azure, GCP) is preferred. Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status."
Data Engineer,Jefferson Center for Mental Health,"Wheat Ridge, CO 80033",https://www.indeed.com/rc/clk?jk=2752bf584aeaca6e&fccid=69871352d3aa5bc3&vjs=3,"Overview: COVID-19 Vaccination or an approved medical or religious exemption is required for employment with Jefferson Center for Mental Health. Newly hired employees must be fully vaccinated (Received final dose of an authorized COVID-19 vaccine regimen) and provide proof, or have an approved medical or religious exemption, prior to their first day of employment. Information on how to request an exemption will be provided at the time of offer. At Jefferson Center, it is our policy and our mission to be inclusive and mindful of the diversity of everyone who comes through our doors. We are passionate about building a community where mental health matters and equitable care is accessible to all races, ethnicities, abilities, socioeconomic statuses, ages, sexual orientations, gender expressions, religions, cultures, and languages. This position will play a key role in modernizing our organization’s data infrastructure. Primarily responsible for building the new infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources with the focus on our major transactional systems. Responsibilities: Essential Duties: Design and implement cloud and hybrid data solutions that meet business requirements using industry best practices Ensure all solutions exhibit high levels of performance, security, scalability, maintainability, and appropriate reusability and reliability upon deployment Perform ETL, ELT operations and administration of data and systems securely and in accordance with enterprise data governance standards Create and maintain optimal data pipeline architecture to ensure high service availability Create scripts and programs to automate data operations Continuously evaluate and improve the existing data infrastructure framework with new and existing technologies Develop and implement key components as needed to guarantee the fidelity and performance of the data architecture Maintain current and accurate documentation of the data architecture and environment Resolve issues, as needed, for current data operations Actively utilize our internal communication, tracking, and monitoring tool Other Duties: Maintain a positive working relationship with team members and other departments Maintain continuous learning Attend relevant trainings as required Maintain a good attendance record Actively participate in relevant work groups Attend team meetings Other related duties as assigned by department management This position is a hybrid position with the expectation that up to 20% of the work could be onsite at an office location. This is subject to change due to COVID-19 and/or other relevant circumstances. Staff are held accountable for all duties of this job. This job description is not intended to be an exhaustive list of all duties, responsibilities, or qualifications associated with the job. Qualifications: Required Qualifications: Bachelor’s degree or higher in computer science, software engineering, data engineering, or related discipline with three years or more of relevant work experience. Technical work experience may be considered equivalent to a technical degree. Logical and efficient, with keen attention to detail Ability to work independently and work well with others Advanced working knowledge of T-SQL Experience working with SQL Server relational databases Familiarity with building and optimizing data pipelines Experience with object-oriented languages such as Java, Python, JavaScript, C#, etc. Experience with REST APIs and SOAP APIs Willingness to adapt traditional data tool experience to Azure Preferred Qualifications: Strong understanding of data warehouse, data governance, and data management concepts, approaches, and tools Strong understanding of relational and non-relational databases Experience with cloud-based technologies Experience with Azure data tools Experience with SSIS Familiarity with InterSystems Cache database Experience working in a HIPAA-compliant environment Experience with Agile development Salary & Benefits: Grade 18 $86,000 to $113,300 Salary is determined based on years of total relevant experience. Salary is based on 1.0 FTE (full time equivalent) or 40 hours per week. Less than 40 hours/week will be prorated and adjusted to the appropriate FTE. Benefits Include: Flexible work schedule and remote work options Medical (Kaiser or Cigna), Delta Dental, and EyeMed Vision insurance plans Life, LTD/STD, and malpractice insurance paid by Jefferson Center 401(k) plan with matching employer contribution and 403(b) option 15% Wellness Discount on medical insurance plans for participating employees 1 Paid Wellness Hour per week (based on FTE) Health Insurance Reimbursement up to $125 per month Generous Paid Time Off plus 13 paid holidays per year Employees with 1 year of service are eligible for Supplemental Parental Leave up to 60 hours (based on FTE) Extended Paid Bereavement Leave up to 20 days Trauma Informed Care Leave Tuition Reimbursement after one year of employment Public Service Loan Forgiveness and Colorado Health Services Corps loan repayment plan options for participating employees."
Entry Level Mission Data Engineer,"Torch Technologies, Inc.","Shalimar, FL 32579",https://www.indeed.com/rc/clk?jk=ada966f162be9365&fccid=b0df153a019c5ca2&vjs=3,"Job Description: Torch Technologies, an employee owned company, has engineering opportunities on the beautiful Gulf Coast of Florida. Sugar white beaches and aquamarine water await. Work on cutting-edge technology related to armament acquisition and testing. Torch Technologies has been voted one of the best workplaces by Forbes magazine and the Association of Mechanical Engineers. You now have the opportunity to work with 21st century technology while living in paradise. Apply now to make a career with Torch Technologies a reality. The successful candidate will assist the 350th Spectrum Warfare Wing (350 SWW) at Eglin AFB, Florida, which is the technical focal point for all Electronic Warfare (EW) support of warfighter systems for the Combat Air Forces (CAF). The mission of the 350 SWW is to develop and test Mission Data (MD) to defeat enemy radar and infrared guided missile systems, thus enhancing aircrew and aircraft survivability in combat. This mission includes operational EW testing, MD development/validation/verification, force development evaluation execution and facilitating foreign materiel exploitation. The successful candidate will conduct appropriate EW research, MD development and MD testing. The successful candidate will support EW system programming/reprogramming, work with EW system engineers to coordinate programming/reprogramming requirements, prepare validation and verification test plans, and organize and participate in MD configuration control boards. The successful candidate will assist with the collection, recording, and post-test analysis of data generated during MD testing. The successful candidate may be required to travel. Job Requirements: Role Requirements Candidates must have at least a Bachelors' degree in a technical/engineering discipline with up to three years of experience in an engineering capacity. They must also have a demonstrated ability to recognize and analyze problems, conduct research, summarize results, and make appropriate recommendations. Applicants must have a working knowledge of computer systems and an understanding of Windows-based personal computers and Microsoft Office software and possess the ability to communicate effectively both orally and written. Highly desirable (but not required) attributes include a current active Secret security clearance and previous experience in RF integration, EM spectrum management, antenna design, and digital signal processing. Also desired (but not required) is knowledge of EW weapons systems development, test and evaluation, and systems engineering. Candidates without and active Secret security clearance must be a US Citizen able to obtain and maintain a Secret clearance. Preferred Skills Knowledge, skills and attributes associated with this position(s) include: EW and the electromagnetic (EM) spectrum, computer software, threat warning, radio frequency (RF) jammers, electro-optical/infrared (EO/IR) jammers, expendables, threat analysis, foreign/US/radar/weapon systems, airborne EW computer software, avionics, systems integration, electronics engineering concepts, principles and practices applicable to a broad range of engineering assignments. Candidates must be analytical, methodical and detail-oriented. This position is located at Eglin Air Force Base, Florida."
Python Data Engineer,Larsen & Toubro Infotech Limited,"Hoboken, NJ",https://www.indeed.com/rc/clk?jk=31dd8276e899d0d8&fccid=42bfc5a97647daf5&vjs=3,"The python developer will help in developing and maintaining various software projects. Responsibilities include writing and testing code, debugging programs, and integrating applications with third-party libraries and services. A familiarity with server-side logic and REST-API design is a plus. Requirements and Skills: Experience working with Python tools and frameworks. Knowledge of SQL to be able to integrate an application with a database. Good problem-solving skills. Nearest Major Market: New York City Nearest Secondary Market: Newark Job Segment: Testing, Database, SQL, Engineer, Technology, Engineering"
Data Engineer,Cerner Corporation,Remote in Missouri,https://www.indeed.com/rc/clk?jk=d4af73c6e249c6fa&fccid=95fa2b94b684ec6b&vjs=3,"Cerner Enviza aims to accelerate the discovery, development, and delivery of extraordinary insights and therapies to improve everyday health for all people globally. By combining decades of healthcare innovation, life sciences knowledge, and collaborative research, Cerner Enviza provides data-driven solutions and expertise that helps bring remarkable clarity to life sciences and healthcare’s most important decisions. Within the Cerner Enviza group, Cerner is looking for an experienced Data Engineer to join the team. As a Data Engineer, your primary responsibility will be developing and maintaining Cerner Enviza data products. Additional responsibilities include activating modern data platform capabilities such as a data catalog on top of the data. Both the data products and the supporting capabilities will provide Cerner Enviza clinical researchers access to the tools needed to deliver unique healthcare insights for our life sciences clients. If you love data and health care IT, apply today to Cerner's growing life sciences organization! Working Environment Hybrid or Remote This position offers a Hybrid or Remote working environment. Meaning if you live within a metro area of a Cerner office, you will split working time between a Cerner office and remote. If you are not within a metro area of a Cerner office, you can live and work in your current geographical location and work primarily remote. #LI-Hybrid #Remote Back to Description Cerner Jobs and Careers Engineering & Technology Innovation occurs everywhere but maybe you are also looking for a purpose. Nothing is more impactful than improving the health of others. Develop cutting edge technologies that have real meaning. Additional Information Working Environment Hybrid or Remote Relocation Assistance Available for this Job: No Qualifications Basic Qualifications 6 years total combined related work experience and completed higher education, including: 1-year software engineering work experience 5 years additional work experience directly related to the duties of the job and/or completed higher education, including: Bachelor's degree in Computer Science, Computer Engineering, Software Engineering, Information Systems, or related field Preferred Qualifications Master's degree Expectations Willing to work additional or irregular hours as needed and allowed by local regulations Work in accordance with corporate and organizational security policies and procedures, understand personal role in safeguarding corporate and client assets, and take appropriate action to prevent and report any compromises of security within scope of position Perform other responsibilities as assigned Must currently reside within 60 miles of a virtually approved city Applicants for U.S. based positions with Cerner Corporation must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire. Visa sponsorship is not available for this position. As a condition of employment, all US-based employees must be fully vaccinated against COVID-19 unless a medical or religious exemption is approved. Some Cerner positions may be obligated to comply with additional client-facing requirements and occupational health requests, including but not limited to, an immunization set, an annual flu shot, an annual TB screen, an updated background check, and/or an updated drug screen. Cerner is a place where people are encouraged to innovate with confidence and focus on what is important – people’s health and the care they receive. We are transforming health care by developing tools and technologies that make it more efficient for care providers and patients to navigate the complexity of our health. From single offices to entire countries, Cerner solutions are licensed at more than 25,000 facilities in over 35 countries. Cerner’s policy is to provide equal opportunity to all people without regard to race, color, religion, national origin, ancestry, marital status, veteran status, age, disability, pregnancy, genetic information, citizenship status, sex, sexual orientation, gender identity or any other legally protected category. Cerner is proud to be a drug-free workplace."
Data Engineer (Remote),"Knowesis, Inc.",Remote in United States,https://www.indeed.com/rc/clk?jk=5b532f2b98121add&fccid=87dc0c4bdcdb1ffe&vjs=3,"Knowesis is seeking a Data Engineer. The Data Engineer will be responsible for translating business requirements and methodologies into code sets to extract and process data. This includes establishing configuration control and executing scheduled jobs and ad-hoc data requests. Work may also include evaluating new data sets, integrating and blending data, and maintaining analytic products (views, cubes, reports, and Business Data Extracts). Critical to this role is a technical and functional understanding of the MHS data. This position requires a Public Trust clearance and requires U.S. Citizenship (applicants without proof of U.S. citizenship will not be considered due to the position's security clearance requirement). Duties and responsibilities include but are not limited to: Import, clean, and prepare very large data sets for advanced data manipulation and statistical analysis, Operate in consultation with colleagues and program staff to provide data extraction, data mining, and curation. Provide consultation and assistance to supported units to identify opportunities and methods for capturing data relating to MHS programs and initiatives, Prepare reports and presentations that accurately convey data trends and associated analyses, Enter and analyze and curate data within government systems. Additional Requirements: The successful candidate must not be subject to employment restrictions from a former employer (such as a non-compete) that would prevent the candidate from performing the job responsibilities as described. COVID-19 Due to the COVID-19 Pandemic, Knowesis requires all employees to be fully vaccinated as a condition of employment. An employee is considered fully vaccinated two weeks after receiving the second dose of a two-dose COVID-19 vaccine or one week after receiving a single-dose COVID-19 vaccine. All newly hired employees will be required to provide proof of vaccination. Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities Knowesis will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c) Experience Required Experience analyzing direct care MHS data and understanding of corporate data repositories. Experience with the DHA data and the AVHE MIP, Amazon Red Shift, cloud environments, and reporting applications. Three years, or more, of data mining and curation experience in academic, social services, government, healthcare, or laboratory setting. Excellent communication skills and highly detail-oriented and organized. Proficiency with Data Management and Data Mining disciplines. Must have advanced proficiency with MS SQL, MS Server, SSIS Packaging, Python, Business Objects, Tableau Desktop, Prep Builder, and data modeling tools, etc. Advanced proficiency with the suite of Microsoft Office programs, including Word, Excel, Project, and Access. Preferred Data Management Body of Knowledge or Data Management Professional certifications. Education Required Bachelors or better in Science/Mathematics or related field"
Data Engineer,nate,"New York, NY+1 location",https://www.indeed.com/company/NATE/jobs/Data-Engineer-33823318765f012a?fccid=005eb48a845c0651&vjs=3,"about nate: The world's only universal shopping app. nate is a venture-backed, intelligent automation, social shopping and payments startup, with offices in New York and London. nate just closed its series A round, raising 38MM from Renegade, Forerunner Ventures, Coatue and Canaan, among others.nate was created based on the principle of ""humans inspire, machines execute."" It guides our team to create a product and company that is truly consumer and privacy first, and that will play a part in online shopping solutions from moment of inspiration to purchase.The nate team is a special one. Check out nate.tech/careers to take a closer peak at our principles and company experience. You can expect a culture that is very dynamic, open, and a team that is highly passionate about what we do. Sounds like something you'd fit in with? Apply. about the role: nate is looking for a Data Engineer to help develop and maintain data platforms and tools that everyone can rely on. You will play a pivotal role in our ability to sustainably and efficiently analyze data across the organization.It means working with a team of motivated individuals who are as passionate about the future of commerce and artificial intelligence as we are. And it also means being an equity-holder, a doer, a risk-taker, a leader and an example to others. what you'll do: Architect, develop, and manage data products across the organization like data transformation tooling and Customer Data Platform pipelines Partner with analysts, engineers, data scientists and business stakeholders to build out capabilities that make an impact across the entire organization Use your expertise in data modeling to design, build and maintain our analytics data warehouse that provides clean, accurate, and robust data sets to be leveraged for reporting and analytics Develop centralized source of truth data sets to encourage a democratized, data-driven culture Contribute meaningful insights and feedback to our team processes Growth mindset Be passionate about continuous learning and knowledge sharing about you: 2-3+ years of professional/industry experience Excellent knowledge of SQL, data modeling, and patterns Strong project management and organizational skills Experience designing and implementing data solutions for various business challenges Familiarity with Customer Data Platforms (Segment, mParticle) and integrations Experience delivering data products from conception to delivery and with the infrastructure that supports their underlying processes finally, some perks! Absolute work title freedom Fully paid health benefits Professional Growth Fridays Wellness, education, and family planning stipends Weekly massage sessions Team building trips Global events and conferences Fully stocked fridge and pantry in office (coffee, tea, fruit, snacks, drinks, you name it) Weekly catered lunch Unlimited vacation days plus paid bank holidays and volunteer days Competitive compensation including equity! nate is an equal opportunities employer. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion, or belief. We make recruiting decisions based on your experience, skills and personality. We believe that employing a diverse workforce is the right thing to do and is central to our success. Job Type: Full-time"
"Software Development Engineer - Snowball, Data Center Techno...","Amazon Web Services, Inc.","Seattle, WA+20 locations",https://www.indeed.com/rc/clk?jk=08945abb299e966b&fccid=5cc0cdc6dbb121cc&vjs=3,"Programming experience with at least one software programming language. 1+ years of experience in software development Job summary We are building hybrid-edge cloud services for the most demanding industries with some of the most challenging use cases that are deployed world-wide. Are you interested in designing and building the next generation Snow device shipping and fulfillment services that are highly resilience, scalable and tolerant to hardware failures (reliable) ? If so, come join us as a Software Development Engineer! AWS Snow Family are highly secure, petabyte-scale data transport and edge computing products that are used to collect, process, and move large amounts of data to AWS from on-premises and remote locations. Processing and moving enterprise size data at remote locations and workflows to the cloud quickly, securely, and cost-effectively is a huge challenge for many customers and we are eagerly looking for innovative leaders to embark on the journey to build the best hybrid-edge solutions that scale without limits and deliver bar-raising customer experience in all environments and under all conditions. We need your passion, innovative ideas, and creativity to help take the service to new heights. This is an opportunity to shape the future of hybrid-edge cloud computing. Our mission is to transform the way the world builds their hybrid and edge cloud computing solutions. As an entry level developer on the team, you will solve straightforward problems, seeking input and guidance from team members and contribute to all aspects of the software development life-cycle. You will design and develop secure, reliable, scalable, and high-performance on-device software that helps expand the Snow edge compute and data transfer business. You will also contribute to cloud-based software to prepare devices for use. You measure and identify areas of improvement in our frameworks, tools, processes and strive to make them better. You will own the new features from inception through development and release. We are constantly evaluating our success metrics and are obsessed with identifying new ways to measure our solution’s effectiveness and how to improve them. Work/Life Balance - Our team puts a high value on work-life balance. On-Call Responsibility - This position involves on-call responsibilities, typically for one week in every eight. We don’t like getting paged in the middle of the night or on the weekend, so we work to ensure that our products are exceeding customer expectations. When we do get paged, we work together to resolve the issue and ensure that root cause is addressed systemically. Mentorship and Career Growth - Our team is dedicated to supporting new team members. Our team has a broad mix of experience levels and Amazon tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our SDEs and other Snow members truly enjoy mentoring and on-boarding new SDE members through one-on-one mentoring and thorough, but kind, doc reviews. We care about your career growth. We try to assign projects and tasks based on what will help each team member develop into a better-rounded SDE and enable them to take on more complex features and services in the future. Inclusive Team Culture - Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. Come join a smart, innovative team that’s obsessed with serving its customers and is having fun doing so in a start-up-like environment! Key job responsibilities Develops, tests, and deploys software. Delivers high-quality, correct production code, by automating testing and deployments. Be part of an oncall rotation. Contributes to team planning and design discussions. A day in the life We have two week sprints. During the sprint planning everyone gets their assignment from the backlog. We also have our daily stand-up call, where everyone share what has been done the day before, what they will work on today and if they need any help from anybody. We end the sprint with a retrospective session where we reflect on things that worked well and things to improve. Depending on the scope and complexity of the features, the team members has to write a design document, and team review and approve it before development starts. About the team Our mission is to automate any manual operation needed to fulfill a customer orders to get devices ready for customers as soon as possible. We focus on the software needed to prepare a Snow device to be used by a customer. Once is the device is ready we shipped to the customer via a carrier like UPS. Our Data Center Technology software is based on workflows, runs on the cloud and interacts with the Snow devices via different methods, like bash scripts. AWS native cloud application development Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Data Engineer (AWS/Pyspark),Dealer Inspire,"Remote in Chicago, IL+2 locations",https://www.indeed.com/rc/clk?jk=0610c48bf8159b5b&fccid=ec154f83e2139ed2&vjs=3,"ABOUT US: Dealer Inspire (DI) is a leading disruptor in the automotive industry through our innovative culture, legendary service, and kick-ass website, technology, and marketing solutions. Our mission is to future-proof local dealerships by building the essential, mobile-first platform that makes automotive retail faster, easier, and smarter for both shoppers and dealers. Headquartered in Naperville, IL, our team of nearly 600 work friends are spread across the United States and Canada, pushing the boundaries and getting **** done every day, together. DI offers an inclusive environment that celebrates collaboration and thinking differently to solve the challenges our clients face. Our shared success continues to lead to rapid growth and positive change, which opens up opportunities to advance your career to the next level by working with passionate, creative people across skill sets. If you want to be challenged, learn every day, and work as a team with some of the best in the industry, we want to meet you. Apply today! Dealer Inspire is a CARS brand. CARS includes the following brands: Cars.com, Dealer Inspire, DealerRater, FUEL, and CreditIQ. Want to learn more? Check us out here! ABOUT THE ROLE: Data is the driver for our future at Cars. We're searching for a collaborative, analytical, and innovative engineer to build scalable and highly performant platforms, systems and tools to enable innovations with data. If you are passionate about building large scale systems and data driven products, we want to hear from you. Responsibilities Include: Build data pipelines and deriving insights out of the data using advanced analytic techniques, streaming and machine learning at scale Work within a dynamic, forward thinking team environment where you will design, develop, and maintain mission-critical, highly visible Big Data and Machine Learning applications Build, deploy and support data pipelines and ML models into production. Work in close partnership with other Engineering teams, including Data Science, & cross-functional teams, such as Product Management & Product Design Opportunity to mentor others on the team and share your knowledge across the Cars.com organization Required Skills Ability to develop Spark jobs to cleanse/enrich/process large amounts of data. Ability to develop jobs to read from various source systems such as kafka, databases,API's,files etc. Experience with tuning Spark jobs for efficient performance including execution time of the job, execution memory, etc. Sound understanding of various file formats and compression techniques. Experience with source code management systems such as Github and developing CI/CD pipelines with tools such as Jenkins for data. Ability to understand deeply the entire architecture for a major part of the business and be able to articulate the scaling and reliability limits of that area; design, develop and debug at an enterprise level and design and estimate at a cross-project level. Ability to mentor developers and lead projects of medium to high complexity. Excellent communication and collaboration skills. Required Experience Data Engineering | 1-2 years of designing & developing complex applications at enterprise scale; specifically Python, Pyspark and/or Scala. Big Data Ecosystem | 2 years of hands-on, professional experience with tools and platforms like Spark, EMR, Kafka. AWS Cloud | 1+ years of professional experience in developing Big Data applications in the cloud, specifically AWS. Bachelor's degree in Computer Science or Engineering or related field Preferred: Experience with developing REST APIs. Experience in deploying ML models into production and integrating them into production applications for use. Understanding of Machine Learning products. Experience with developing real time data analytics using Spark Streaming, Kafka, etc. #LI-KO1 #LI-Remote We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Data Engineer,Match Group,"Dallas, TX 75231 (Northeast Dallas area)",https://www.indeed.com/rc/clk?jk=12e8114c67a9c7ee&fccid=47feb0effe4ed4f2&vjs=3,"Data Engineers are key to the success of Match Group. Not only will you help power the love lives of millions of people, but you will play a critical part in the functioning of every brand at Match Group (Match, Tinder, Hinge, Okcupid, PlentyofFish, BLK, and others), with stakeholders ranging from customer experience to marketing to leadership. We're located in Dallas, TX, and seeking a DFW based engineer to join us. We work from the office 1 day per week (free catered lunches are provided). See you soon! How you’ll make an impact: Work with our Engineering teams to ensure data is flowing accurately through data creation to our presentation layers Become an advocate for the Data Engineering team by developing and championing Data Engineering practices with the team and with the company at large Improve our Data Engineering stack through containerization, data modeling, developing our ETL pipelines, and building scalable/reliable solutions Work with stakeholders and translate their needs and expectations into action items and deliverables Lead infrastructure initiatives, from design to implementation to delivery Support existing on-prem infrastructure and help expand our processes into the cloud (AWS) We could be a match if you bring: Prior Airflow and/or Python experience is required Expertise in SQL, Data Modeling, and Python Used Redshift, Airflow, Spectrum and relational database like SQL Server Capability to drive initiatives and articulate their value to Engineering and other stakeholders Experience delivering data products from conception to delivery Good communication skills (written/verbal) Passionate about designing elegant ETL pipelines 3+ years of professional/industry experience Our team culture: Authenticity: Share your genuine thoughts and opinions directly Courage: Invite and deeply consider challenges and criticism Empathy: Be empathetic, communitarian and trustworthy What's the team like? Our BI team is a service organization that delivers reporting solutions to the entire Match Group enterprise The BI team is responsible for architecting and engineering new data systems and reporting to help facilitate business decision-making We're located in Dallas, TX, and seeking a DFW based engineer to join us. We work from the office 1 day per week (free catered lunches are provided). See you soon! #LI-CH1 #LI-CENTRAL Why Match Group? Our mission is simple – to help people find love and happiness! We love our employees too – here are some examples how: Annual training budget for each employee 100% employer match on 401k contributions Specific COVID-19 allowance for home office set-up Matched giving to qualified organizations 100% paid Parental Leave for up to 20 weeks Happy Hours and Company events At Match Group, we represent a collection of unique brands - but we all focus together on the health and safety of all of our employees. That's why we require that employees are fully-vaccinated when in person at any US office or company-sponsored fun. If you need to talk through this in-person vaccine requirement, our People team can work with you through our accommodations review process. We are proud to be an equal opportunity employer and we value the rich dynamics that diversity brings to our company. We do not discriminate on the basis of race, religion, color, creed, national origin, ancestry, disability, marital status, age, sexual orientation, sex (including pregnancy and sexual harassment), gender identity or expression, uniformed service or veteran status, genetic information, or any other legally protected characteristic. Period."
"Analyst, Data Engineer",Revantage Corporate Services,"Chicago, IL 60606 (The Loop area)+1 location",https://www.indeed.com/rc/clk?jk=8603a8b7946435d7&fccid=e021daaf63a65096&vjs=3,"Overview: Who We Are Revantage is a Blackstone Company that provides a highly skilled employee base, best-in-class processes, and state-of-the-art technology to multiple Blackstone real estate portfolio companies. Sectors include Hospitality, Industrial, Multi-Family, Office, Retail, Senior Housing, and Manufactured Homes. Revantage, headquartered in Chicago, is one of three global offices that includes Revantage Asia and Revantage Europe. What We Value: Our Culture Creating a culture that inspires change and momentum requires the right team. We know what it takes to lead an industry, and are looking for leaders who seek constant growth, want to excel, and continuously improve upon themselves and the industry. The culture at Revantage is built on our shared core values and commitment to be: Achievers – We expect high standards for ourselves and enable the success of our teams Enthusiasts – We face challenges with optimism and believe anything is possible Leaders – We commit to continuously improve our performance Learners – We learn from our challenges and successes Partners – We deliver value and positive impact to our partners Why This Role Is Valuable We are seeking an Analyst, Data Engineer to join Revantage North America’s Data Engineering team. This role is charged with developing a unified, modular, composable, and generalized data platform that integrates with dozens of data sources and source systems, ensures data quality, models, and then exposes the data in various forms for consumption by other teams and platforms. As part of the Revantage Product department, you’ll be a key part of a passionate team of Software Engineers, Product Managers, Designers, and Data Specialists that aims to develop the industry’s leading real estate data platform. We are looking for a seasoned software engineer who has experience with data infrastructure, ETL systems, reporting environments, or machine learning pipelines. Responsibilities: How You Add Value Design, develop, launch, and maintain data pipelines to move and transform data to enable downstream consumption and insights Collaborate with other data engineers, analysts, product managers, and customers to implement technical solutions to business problems Participate in regular product lifecycle activities Diagnose and solve issues in existing data pipelines, and use learnings to build their successors Qualifications: What You Bring To The Role Required: Recent graduates with STEM B.S., M.S., or comparable experience Basic programming skills (Python, Java, C#, Go, SQL etc.) Familiarity with SQL and databases Passion for solving real business problems with data-driven solutions Teamwork attitude Aptitude to learn fast Experience with Cloud technologies a plus (Azure, AWS, GCP) Perks for You Competitive salary, overall compensation and 401(k) Work-life balance offerings include: Remote work policy Productivity Hours – weekly meeting-free work time Bi-weekly Summer Fridays In-house and external learning & development opportunities Generous health insurance and wellness benefits EEO Statement Our company is proud to be an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. Our employment decisions are based on individual qualifications, job requirements and business needs without regard to race, color, marital status, sex, sexual orientation, gender identity and/or expression, age, religion, disability, citizenship status, national origin, pregnancy, veteran status and or any other legally protected characteristics. We are committed to providing reasonable accommodations, if you need an accommodation to complete the application process, please email talent@revantage.com. #LI-Remote #LI-IG1"
Data Engineer,Geo Owl,"Fort Bragg, NC",https://www.indeed.com/rc/clk?jk=287784e5dc8f8cfc&fccid=be4bf56cd785b400&vjs=3,"Geo Owl is currently looking for a Data Engineer to support our USASOC contract opportunity. To be qualified, you need at least 5 years of relevant experience and meet the requirements listed below. If interested, apply now, or contact one of our recruiters. Location: Fort Bragg, NC Clearance: TS/SCI Requirements: Must meet all the requirements listed below. 5+ years of experience in one or more of the following: business analysis, army special operations intelligence, and/or information management/knowledge management. 5+ years of experience supporting the United States Military, preferably SOF elements. BA/BS degree from an accredited university or former officer, NCO, or warrant officer with military experience or intelligence/knowledge management background. 5+ years of experience with Single Page Application Development and client-side coding, including Jscript React, Angular, Aurelia, Vue, Ajax, JSON, or REST, such as OData, HTML, or CSS 5+ years of experience with two or more of the following: C#, Python, PHP, or Java. Knowledge of database architecture and data transformations. Benefits: Health Insurance (Geo Owl pays 80%+ of the premium). 401k matching. Dental, Vision, and other supplemental insurance plans available. Company-paid short-term and long-term disability and life insurance. Peer-to-Peer spot bonuses. 120 hours of PTO per year plus federal holidays. Joining the Geo Owl Team | What to Expect At Geo Owl, we highly value our team members. We offer challenging but rewarding opportunities for those who want to work hard to provide a great experience for the customer and strive to reach their professional goals. As a member of the Geo Owl family, you will be working alongside people who share this work ethic and are aiming to be the best partner for our customer. We are all proud to be a part of this company and we want you to be too. Our Mission · Provide high quality solutions to our mission partners in the United States through our expert analysts. · Be recognized as the best at what we do by our customers. · Be a team our team members are proud and excited to be a part of. · Continually strive for excellence and seek to tackle the most difficult challenges our industry has to offer. About Us Geo Owl is a premiere provider of Full-Motion Video (FMV), Geospatial, ISR, Intelligence and IT services to the Department of Defense and Intelligence Community. We are vitalized by our engaged team of professionals that truly value each other and the important missions we support. Equal Opportunities Geo Owl is an equal opportunity employer and does not discriminate on the basis of race, color, religion, creed, sex, age, sexual orientation, national origin, disability, marital status, military status, genetic predisposition, or any other basis protected by law. To stay up to date about new career opportunities: us on Instagram"
Data Engineer,RX Saving Solution,"Remote in Overland Park, KS",https://www.indeed.com/rc/clk?jk=b6e47febc0ba320a&fccid=dd616958bd9ddc12&vjs=3,"Here at Rx Savings Solutions, we are driven to make a difference in the pharmaceutical industry by exposing cost-savings analytics to our members. We take pride knowing that the work we do can greatly impact the lives of our customers. We currently have an opportunity for an experienced Data Engineer to join our growing Data Ingestion team! The ideal candidate will have ETL tool experience (i.e. Talend, Informatica, SSIS or Datastage), experience with general purpose programming languages such as Python or Java, and general knowledge of database internals, data modeling and data architecture. This role will assist in planning, designing, and documenting technical requirements for data flows between disparate operational systems and our data warehouse. The Data Engineer will be assisting in end-to-end development of the ETL process as well as data analytics. This team member will analyze and review business requirement documents, complex object and data models. Check out what our CTO shares about the personal growth opportunities and impactful work as an Engineer on our team: https://www.youtube.com/watch?v=52P-A-pZYw4 Our office is located in the Kansas City area, however, we offer hybrid and remote work options. Education Bachelor’s degree or greater in Computer Science or related experience Requirements 2+ years experience in ETL Tools (Talend is a plus) 2+ years experience in SQL queries Build data pipelines to Ingest and automate files provided by customers using the ETL tool Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using primarily ETL tool Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency Knowledge of Structured and Unstructured data Strong analytical skills and attention to detail. Ability to communicate with stakeholders of different backgrounds and skill levels. Understanding of BI concepts and be familiar with relational or multi-dimensional modeling. Demonstrated one or more of the four development areas of Data Management: Integration, Modeling, Analytics, Reporting. Highly-motivated, self-directed and flexible. Investigate and resolve data related issues and provide support and troubleshooting expertise. A great attitude with a passion for supporting your team and offering creative solutions. Willingness and enthusiasm to learn new skills and techniques. Understanding of RDBMS best practices. Nice to have... Experience with Agile and Scrum methodologies. Knowledge of Java or JavaScript Good to have hands on experience on AWS Services – S3, Cloudwatch, EC2 Experience with Databricks #LI-DM1 #LI-Remote"
Senior Data Engineer,Built Technologies,"Remote in Nashville, TN 37211",https://www.indeed.com/rc/clk?jk=aea0a059bd5f9b67&fccid=e87902195236c825&vjs=3,"Built is a growth-stage company at the intersection of FinTech and PropTech. We are on a mission to change the way the world gets built with technology and services that streamline the $1.3T U.S. construction industry. We strive to empower lenders, owners, builders, and vendors with innovative software, payment products & services that enable participants to manage risk, maximize productivity and collaboration to ensure better cost management as capital flows into and throughout the construction industry. Founded in 2015, Built now serves more than 140 of the top financial institutions in the US and Canada, including 35+ of the top 100 US construction lenders. In addition to our recent $125M Series D funding and $1.5B valuation, we’re proud to have been named one of Forbes’ Top 100 Startup Employers in America for 2021. Bringing on the “best talent in the world” is at the forefront of our continued growth trajectory—and we want you to be part of it. Built’s Insights team is hard at work on the product features that enable our clients and customers to get the most out of their data within Built. This includes data warehousing, in-app reporting, secure scheduled report delivery, and ad-hoc report generation where necessary. In addition to client needs, the Insights team is also instrumental in helping Built make sense of all of its internal data, allowing internal stakeholders to make informed, data-driven product decisions. Built is looking for an experienced Sr. Data Engineer to help organize and manage existing data resources, implement new technologies and tooling to advance our data analysis platform, as well as help drive scalable data sharing practices. You will own data environments, integrate with new technologies, and oversee the development of new processes that support teams across the entire organization. You will gather requirements through direct interaction with the product team, business partners, and software development teams. You will help steer the direction of our constantly evolving system to enable scale and deliver quality for our clients, both internal and external. The ideal candidate will have outstanding communication skills, proven data infrastructure design and implementation capabilities, strong business acumen, and an innate drive to deliver results. You will be a self-starter, comfortable with ambiguity and will enjoy working in a fast-paced dynamic environment. In this role, you will: Assist in the collection, organization, and availability of data at Built Work with stakeholders to deliver data visualization, exploration, and reporting solutions for internal and external customers Ensure that data curation and collections processes are performing as expected for current and future reporting needs Help design internal metrics that provide observability into the data collection and transformation processes Work with teammates to ensure standard engineering processes are followed Actively seek opportunities to mentor teammates and be mentored by your teammates Work with principal engineers and other teams to move larger engineering initiatives forward Act as the example to which other engineers aspire to become professionally and culturally Basic Qualifications: A desire to work in a collaborative, intellectually curious environment Bachelor’s degree in Computer Science, Engineering, Mathematics, or equivalent 5+ years of Data Warehouse experience Coding proficiency in at least one modern programming language (Python, Javascript, etc.) Experience with cloud hardware provisioning, forecasting usage, and managing to a budget Experience with Linux/UNIX Proven track record of sharing outcomes through written communication, including an ability to effectively communicate with both business and technical teams Preferred Qualifications: Experience working with AWS with a strong understanding of their offerings (Athena, PostgreSQL, MySQL, Kinesis, Redshift, Lambda, S3, EC2, etc.) Experience with Big Data Technologies Experience with security standards like symmetric and asymmetric encryption, virtual private clouds, IP whitelisting, LDAP authentication, and other methods Strong interpersonal skills and the ability to communicate complex technology solutions to senior leadership, gain alignment, and drive progress Data Lakes (particularly AWS Glue, S3, and Athena) Integration Platforms (particularly Celigo or SnapLogic) Data Pipeline/ETL tools (particularly Luigi, Airflow, and Glue) Our Perks The rare opportunity to radically disrupt an industry Competitive benefits including uncapped vacation; health, dental & vision insurance; and 401k Holistic compensation package including base salary, bonus, and equity Flexible Hours Learning grants to support your professional development Our company is made up of passionate people who are driven in a variety of disciplines—and each of them bring their unique perspective to everything they do. Creating a safe and inclusive workplace is critical to the success of our company and of our employees, so it’s our aim to recruit, hire and promote without bias against race, color, religion, sex, sexual orientation, gender identity, marital status, veteran status or any other status protected by applicable law. As we learn and as we grow, we’re committed to ensuring that these ideals are at the forefront of everything we do."
Data Engineer-Services Technology,Dell Technologies,"Austin, TX+4 locations",https://www.indeed.com/rc/clk?jk=74e93d549c7cba85&fccid=dd09fe3b43125016&vjs=3,"Data Engineer USA Remote We are looking for a savvy Data Engineer to join our growing team of analytics experts. As a member of the team you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. You must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of services products and data initiatives. What you’ll achieve As a Data Engineer, you will be responsible for managing and organizing data, while also building solutions to determine trends and inconsistencies that will impact business goals. You will be working with different teams within Dell on customer facing reporting / web applications. You will: Create and maintain optimal data pipeline architecture and assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and big data technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiencies and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader and to strive for greater functionality in our data systems. Take the first step towards your dream career Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role: Essential Requirements 8+ years experience and Bachelors/Master in Computer Science/Engineering or equivalent relevant experience Strong expertise with object oriented/object function scripting languages: Python, Java, Scala etc. Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) and familiarity with a variety of databases (i.e., relational SQL and NoSQL databases including Postgres, MSSQL, Teradata, and Azure) Experience with big data tools: Hadoop, Spark, Kafka. Experience with cloud services: PCF, Kubernetes. Comfortable working in Linux Env, building shell scripts and using GIT for source control versioning. Desirable Requirements Experience with Java/Scala. Experience building REST API’s using FAST API/Django frameworks. Here’s our story; now tell us yours Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress. What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life - while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more. We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today. You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here. Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Employment Opportunity Policy here"
Senior Data Engineer (Remote),pulseData,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=793cc61e331f02a7&fccid=2c23f29fcd5c78da&vjs=3,"Join us as we pursue our vision to eliminate preventable sickness and transform kidney care using AI and data! At pulseData, we provide value-based healthcare organizations and their care teams a patented data intelligence platform that helps deliver better care at less cost. As a company, we leverage data science and machine learning for Hospitals and Healthcare companies, to identify patients at risk of costly and avoidable medical outcomes. You will become a member of pulseData's engineering team in this role. You will be developing, deploying, and maintaining our product pipeline and working in an environment of growth and collaboration. The Role: You'll be developing, deploying, and maintaining our production pipeline. You'll be ensuring product deliverables are executed effectively on a regular basis. You'll be interacting with 3rd party client APIs to deliver outputs. You'll be growing your skillset in a diverse and challenging environment that offers the latest technologies. Your Background: A quantitative degree. 4-6 years of experience as a Data Engineer. Experience in SPARK and ideally python (pandas). A growth mindset with the ability to work autonomously and with teammates remotely. Experience working on healthcare data is a plus! The Perks: Competitive base + bonus + equity. A remote working environment - we work eastern working hours. Top tier benefits include medical, dental, and vision insurance - 85% of which is covered by pulseData. Unlimited PTO - so you can stay at your best year round! Fun gym discounts, a 401k, and a new laptop + equipment. Company offsite adventures throughout the US each year. Tons of room for growth and the ability to learn new things."
Data Engineer,Level,"Remote in New York, NY 10013",https://www.indeed.com/rc/clk?jk=4ea6e46594f77b7e&fccid=bc25fff2757c98b2&vjs=3,"At Level, we believe using your benefits should be as easy as buying a cup of coffee. We're unlocking the full value of compensation by rebuilding benefits as a simple payments experience — fast, flexible, and transparent. Our mission is to empower people to build better financial futures, and we're accomplishing that by transforming the status quo of benefits. Level is a B2B2C fintech company comprised of a diverse team from industry-leading companies like Square, Oscar, Google, Uber, and Airbnb. Together, we're creating a new payments tech stack to help employers offer more accessible and personalized benefits for their teams — and this is just the beginning. At Level, collaboration is our superpower. By leveraging each other's strengths and curiosity, we've been able to build a best-in-class product, culture, and business. Plus, our employee benefits are so awesome that we let our customers buy them too. What You'll Do: Develop data pipelines to ingest data from multiple sources and intelligently deal with the complexities of real-world data Manage large datasets with multiple business constraints and online/offline use-cases Refine Level's data model to cleanly represent the complex insurance ecosystem Drive the strategy and build a best-in-class data platform to measure and increase member and provider engagement Make it easier to consume market centric data sets to gain relevant insights Collaborate with internal product, marketing, network and operation teams to use insights to measure product performance Establish scalable delivery models to accelerate the go-to-market for the new products and services Provide clarity in prioritization of projects Provide leadership to develop commercially viable architecture roadmaps, solutions and business-IT landscape aligned with our strategy Contribute to the data strategy by collaborating with cross-divisional team members Who You Are: 5+ years of experience in data engineering and warehousing Experience with multiple database technologies (e.g., BigQuery, Postgres, Elasticsearch), strong proficiency in SQL, and a deep understanding of database design and organization Experience working on data-intensive problems and tackling common data challenges (cleaning, deduplication, and entity resolution) Experience working with confidential and highly sensitive information Familiar with distributed computing frameworks such as Spark and Beam Familiar with workflow managers (e.g. Airflow, Prefect) Familiar with event-driven architectures and systems (e.g., Kafka, RabbitMQ) Experience in a large matrix-style organization where your team collaborates and integrates with other teams across the organization Experience within a fast-paced B2B environment Comfortable architecting solutions with modern cloud infrastructure (AWS, GCP) Willingness to ask questions and learn about complex problem domains in order to craft solutions that best serve the needs of enterprise customers. Our technologies These are some of the technologies we use today. You don't need to be familiar with all of these—many people on our team learned them with us. During our interview process, you're welcome to use any language you're most comfortable with. AWS, Google Cloud Platform BigQuery, Postgres, MySQL dbt (data build tool) Kubernetes Golang, Python Protobuf / gRPC ElasticSearch React / React Native, Typescript What We Offer: Competitive salary and equity Remote first, with an office in NYC as an option to come in 100% paid medical for you and 80% for your dependents, 100% covered dental and vision through Level for you and your dependents Flexible paid time off: take the time you need when you need it! Plus, get up to 10 days of paid sick leave per year Fully paid parental leave: up to 14 weeks for primary and 8 weeks for secondary caregivers Food, wellness, and office funds via our own Level product Quarterly company sponsored events Internal learning and development programs Have the chance to work at a leading innovator and trailblazer in the world of benefits and payment Level is proud to be an Equal Opportunity Employer. We celebrate diversity and are committed to creating a welcoming and inclusive environment for all. Please apply to this role if you feel you are a good fit, regardless of your race, color, religion, gender identity, sex, sexual preference, sexual identity, pregnancy, national origin, ancestry, citizenship, age, marital status, physical disability, mental disability, medical condition, military status, or any other perceived limiting factor. We welcome applicants from all walks of life. E-Verify Program Participant: Level participates in the Department of Homeland Security U.S. Citizenship and Immigration Services' E-Verify program (For U.S. based applicants and employees only). Please click below to learn more about the E-Verify program: E-Verify Notice (bilingual) Right to Work Notice (English) / (Spanish)"
Data Engineer,auticon,"Remote in Columbus, IN",https://www.indeed.com/rc/clk?jk=ef90b2d87fcc5dde&fccid=a5551b6a900b917f&vjs=3,"If you have an autism diagnosis and are looking for a career in tech in a great work environment, we want to hear from you. auticon is hiring Data Engineers – from junior (minimum 1 year professional experience, see skills and qualifications for specifics) to senior level professionals – to help our clients tackle fascinating and challenging data problems. We’re seeking people who are adept at building data pipelines that can source, clean, and normalize data at scale; or, create data scalable streaming applications; or, integrate systems in new or creative ways. We realize that getting and keeping a job can be challenging, so we’re on your side. We provide a professional auticon Job Coach and Technical Leader in an accommodating work environment to help you succeed. The skills and main responsibilities for this role are below, but you do not have to meet all of them to apply! The Role: Because our clients face many new challenges, our data engineers need strong creative problem-solving skills and the technical background to implement solutions. Data may be acquired from multiple sources, and this requires an understanding of data architecture principles and engineering experience to prepare this data for our client’s use cases. The ideal candidate will love automating data pipelines, cleanse and transform data, developing controls to monitor the quality of data, participating in governance, schema development, establish integration patterns, and documenting their work. Responsibilities: Stitch and normalize sparse and noisy data across various data sources Undertake pre-processing of structured and unstructured data Design, develop, implement, test, and support technical solutions in full-stack development tools and technologies Work with a team of developers with deep experience in machine learning, analytics, distributed microservices, or full stack systems Utilize programming languages like Python, Java, Scala, Ruby, or Elixir and Open Source RDBMS, streaming, messaging, or cloud-based data warehousing services Collaborate with engineering and product development teams Deliver on timeline commitments where necessary Preferred Qualifications (you do not have to meet all to apply): 1+ years of relevant professional work experience Includes: Paid and unpaid work, full-time/part-time work, freelance professional work (paid or unpaid, client or family/friend), internships Does not include: College courses or personal projects Work experience does not have to be consecutive Experience with all stages of the product development cycle especially designing, developing, and supporting a complex software solution while maintaining engineering best practices including defect tracking, design reviews, and appropriate testing Proficient in SQL and/or NoSQL Strong organizational and problem-solving skills Pragmatic, product-oriented approach Ability to work cross-functionally with minimal supervision BS in Computer Science, Electrical Engineering, Mathematics, Statistics, Physics, or similar quantitative fields. Experience with cloud environments (e.g., AWS, GCP, Azure) Experience in application development Experience in at least one scripting language (e.g., Python, Ruby, Perl, JavaScript, Shell) Experience working on streaming data applications Experience with Agile engineering practices Experience with UNIX/Linux including basic commands and shell scripting Experience with at least one DevOps technology (e.g., Ansible, Terraform, SaltStack, Kubernetes) Applicants must now and in the future be legally eligible to work in the US for any employer. auticon does not provide visa sponsorship or transfer for this opening. Apply now Please send an email to with your resume attached, briefly stating whether or not you have an autism spectrum diagnosis and what your expertise is. auticon provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training."
Data Engineer,Acuity INC,"Remote in Reston, VA 20190",https://www.indeed.com/rc/clk?jk=bad374eabb1a4d6e&fccid=0fd566442f67eb18&vjs=3,"Overview: Acuity is looking for a Data Engineer to join our Engineering Team. In this position, you will apply your skills in data warehousing to pioneer cloud and data services with our clients. You will use cloud and data technologies to deliver exciting IT & data driven capabilities. Responsibilities: Engineer, build and maintain scalable automated data pipelines. Build cloud data solutions and provide domain perspective on storage, big data platform services, serverless architecture, RDBMS, DW/DM, NoSQL databases and security. Deploy, automate, maintain and manage cloud-based production system, to ensure the availability, performance, scalability and security of productions systems. Implement best practices in management of data, including master data, reference data, metadata, data quality and lineage. Support regular and ad-hoc data querying and analysis to understand customer behaviors. Qualifications: BA or BS degree in CS, Information Systems, or related field. Experience developing and deploying ETL pipelines using Apache Spark and/or Databricks Experience in SQL and/or Spark SQL Familiarity with Informatica a plus Familiarity with Java a plus Knowledge of dimensional models in data warehouses Experience working on loading data to the Star Schema Preferred Qualification Knowledge of and experience with automated testing Knowledge and experience of deployment of Spark Notebooks Clearance Requirement: Must be US Citizen with an ability to obtain and maintain US Suitability About Acuity Inc. Acuity is a leading management and technology consulting firm that specializes in serving the federal government. Our innovative, collaborative and rewarding work environment has earned repeat honors from the Washington Business Journal’s Best Places to Work and SmartCEO Corporate Culture awards. We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law."
Data Engineer,Robert Charles Lesser,"Remote in Denver, CO",https://www.indeed.com/rc/clk?jk=bfe94a3cb54a2b9e&fccid=1f74f40f248cbecf&vjs=3,"Data Engineer Fully remote with options for hybrid/full-time on site work in offices located in: Denver, Los Angeles, Bethesda, Orlando, New York, and Austin. Are you interested in building state of the art analytics products to create advanced products from the ground up? We are in the process of migrating to the cloud to boost our ability to effectively empower our data analyses and build custom modeling software. RCLCO is looking for a Data Engineer (DE) to join the Innovation, Data & Analytics team. This team member will work cross functionally with app developers, data analysts, consultants, and data scientists to build scalable architecture for both reporting and advanced analytics. The DE will work as a database administrator and cloud developer to generate schemas and automate the ETL process. The DE will create analytical data structures, such as OLAP cubes, for quick and easy data access from Excel, Power BI, Python, R, etc. The DE will work with data scientists to enhance data flow to models and aid in the feature engineering process. RCLCO, a national leader in providing strategic economic guidance to the real estate industry. Founded in 1967, RCLCO is a pioneer in bridging market and financial feasibility, consumer research, and industry intelligence. Our professionals are widely respected for their ability to assess economic and market directions, and to translate these trends into project concepts and financial guidance. Key duties include: Participate in the building of current data products and solutions Develop the ability to use our current visualization tools as well as define and create new ones Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Work with stakeholders to assist with data-related technical issues and support their data needs Minimum Technical qualifications: Experience running production cloud systems Security, monitoring, diagnostics, deployment strategy Strong DevOps methodology Understanding of GIS and spatial data analysis Storage data types and spatially indexed data structures At least 2 years of experience working on data pipelines Technical knowledge with at least 2 years of experience in most of the following: Database architecture and design in SQL Data warehouse architecture and design, specifically OLAP ETL processes utilizing DAG in a framework (Airflow, Luigi, etc.) Linux command line (simple commands) Cloud architecture, data storage and pipelines AWS, GCP, or Azure Cloud tools: File storage, ETL, serverless, database Programming technology Must have: Python, SQL Nice to have: R Experience in Developing and supporting large scale geospatial pipelines Other Qualifications: Basic understanding of the real estate industry or economics Bachelor’s degree in engineering, economics, finance, or other quantitative field Ability to work independently and hit deadlines Ability to communicate complex technical topics in an easily digestible manner RCLCO is proud to have created an environment of advocacy, support, and opportunity for its team members. The right applicant will enjoy an attractive benefits package, competitive compensation, the chance to work with the ""best minds in real estate,"" and a career-focused, long-term, growth-oriented position. This position is full-time. Position is based within the United States, preferably near one of our offices, with flexibility to be remote. * * * - Equal Opportunity Employer - RCLCO is an EEO Employer who celebrates diversity - Drug-Free Workplace -"
Senior Data Engineer,GOAT Group,Remote,https://www.indeed.com/rc/clk?jk=16ae0a4c16470a94&fccid=0af53f836936abde&vjs=3,"At GOAT Group, the Engineering team is an integral part of our dynamic company. By joining the team, your skills will be front and center, working alongside other passionate individuals to solve problems and build software. From launching compelling new consumer experiences, tackling global logistics challenges to scaling infrastructure to facilitate our rapid growth – technology is essential to driving our vision forward. The work you do will change the way the world shops, while also empowering entrepreneurs, including individual sellers, brands and boutiques. The Data Engineering team is responsible for building and maintaining data solutions that deliver value to our internal and external stakeholders. We are part of the Data Platform team here at GOAT and work closely with Data Scientists, Data Analysts, and the broader Engineering team to deliver data needs. We are looking to add an innovative engineer with a strong sense of ownership, who is able to work both independently and as part of a team. In this role you will: Lead architectural designs and build reliable data pipelines that move data at scale Collaborate with internal stakeholders to deliver data needs that drive critical business decisions at GOAT Optimize data storage and data modeling for efficient data retrieval and transformation across large datasets Move essential data pipelines from batch to real-time setup Address process improvements, automate manual processes, and drive changes to stay close with big data advancements We are looking for: 5+ years of industry experience Proficiency with SQL and Python or Go Proficiency in data warehousing and data modeling Proficiency building batch and real-time data pipelines in production Experience with data orchestration tools like Airflow or Luigi Experience with AWS or another cloud platform Bonus if you have experience with streaming tools: Kafka, Flink, and Materialize or similar Bonus if you have experience with data compliance regulations such as GDPR and CCPA Bonus if you have experience monitoring for data quality and integrityBonus if you are familiar with Data Visualization tools like Mode, Looker, or Tableau GOAT is the global platform for the greatest products from the past, present and future. Since its founding in 2015, GOAT has become the leading and most trusted sneaker marketplace in the world. Through its unique positioning between the primary and resale markets, the company offers styles across various time periods on its digital platforms and in its retail locations, while delivering products to over 30 million members across 170 countries. The company is backed by strategic investor Foot Locker, Inc. as well as some of the leading names in venture capital including D1 Capital Partners, Accel, Andreessen Horowitz, Index Ventures, Matrix Partners, Upfront Ventures, Webb Investment Network and Y Combinator. We encourage you to apply even if you feel unsure about whether you meet every single requirement. We look for people who are passionate about what we do, not just those who check off all the boxes."
Data Engineer-Remote USA,America At Work,Remote,https://www.indeed.com/rc/clk?jk=0a21de55da4fb3f1&fccid=82c7fe98611d2d88&vjs=3,"Are you tired of not having your recommendations and suggestions implemented? Do you feel that you are not part of the team that is driving business forward? Have your personal and professional growth curve started to flatten out? If the answer is yes to any of these questions, maybe is time to look for a better career, not just another job. If you have at degree in Computer Information System, Computer Science, or relevant degree and at least 3 years’ experience and want to be part of a strong team; let’s talk!! THE SKILLS SET NEEDED Bachelor’s degree in Computer Information System, Computer Science or relevant degree required. Minimum of 3 years of experience required. SQL, Microsoft SQL experience required. Proficient with Excel required. Azure Synapse Experience preferred. Azure Data Factory preferred."
ML Data Collection and Data Science Engineer (TDG),Apple,"Cupertino, CA+4 locations",https://www.indeed.com/rc/clk?jk=59ecdbb5acd3ccb6&fccid=c1099851e9794854&vjs=3,"Summary Posted: May 16, 2022 Role Number: 200380146 Do you want to push the limits of the best Augmented Reality platform in the world? Apple's Technology Development Group (TDG) delivers algorithms that drive revolutionary Apple products, including the augmented reality (AR) platform ARKit to create ground-breaking new products. In this position, you will have the opportunity to be part of our extraordinary data team to discover and build solutions to previously-unsolved challenges and push the state of the art in AR algorithms that will change the way people experience the world! We are looking for a driven Machine Learning Data Collection Engineer that enjoys getting into the details to collect valuable data that feeds our machine learning models. As a member of the fast-paced data team, you have the rewarding opportunity to shape upcoming products that will delight and inspire millions of people every day. To succeed within this role, you should have shown experience in several of the following areas: Key Qualifications Ability to define/design/develop data collection efforts that focus on the end-to-end user experience, including anticipating potential failure modes, edge cases, and anomalies Proficiency in programming languages including Python, C++, or similar Capacity to multitask and manage several projects in parallel while meeting deadlines and providing access to clients and partners Problem solving & critical thinking capacities, thinking outside the box in order to gain in speed, efficiency, and quality. Excellent project management, communication, interpersonal, analytical, and organizational skills Experience with industrial software development, a plus Experience with CVML, a plus Description As a Machine Learning Data Collection Engineer, you'll be collaborating with multi-functional teams to work on CVML data collection projects, from collecting data collection requirements, designing protocols, testing software and hardwares, executing data collection, to analyzing and curating collected data. Your job responsibilities will include -Contribute to the design of CVML data collection, including hardware, software, user interface specifications, and collection protocols. -Define, implement, maintain SW and HW solutions to test data collection hardware, software and protocols. -Design, implement and maintain SW platforms to monitor date life cycle -Work with CVML engineers to design and implement data evaluation and curation process -Analyze data and build data analysis tools -Collaborate with multi-functional teams including algorithm, hardware, software, product design, project management, legal, procurement, security, logistics and vendors to define and deliver necessary study elements -Write technical documents including study instructions, operating procedures and training documents for study personnel -Drive process improvements across the organization to continuously improve the way we work Education & Experience B.S., M.S., or Ph.D. in Computer Science, Computer Engineering, or equivalent practical experience. Additional Requirements"
Data Ops Engineer Sr/Intermediate,University of Michigan,"Ann Arbor, MI 48109+2 locations",https://www.indeed.com/rc/clk?jk=abbacff006eddc60&fccid=46c847dc877cedc2&vjs=3,"How to Apply A cover letter is required for consideration for this position and should be attached as the first page of your resume. The cover letter should address your specific interest in the position and outline skills and experience that directly relate to this position Summary Are you wicked smart? Are you a tinkerer at heart who likes to work on the cutting edge and push the bounds of what is possible? The Weil Institute for Critical Care Research and Innovation, within Michigan Medicine’s Department of Emergency Medicine, is in search of a Senior DataOps Engineer to join our DataOps team to help build next-generation tooling, using industry best practices, to develop real-time data pipelines, integrate machine learning models into University of Michigan’s EHR system, and monitor the performance of our predictive analytics. This position offers a unique opportunity to work hand-in-hand with our Data Science team and clinical collaborators, within the school and other institutes, to help them get the data they need to build their models and to get those models into a production environment and into the hands of clinicians. Unlike traditional research teams, the Weil Institute is focused on operating like a startup and getting products to market in order to ensure that our work can benefit patients sooner rather than later. As a member of the DataOps team, you will be responsible for managing data pipelines for large sets of PHI data including data extraction, transformation, cataloging, monitoring, integrity, administration, and security. These sets of data include structured EHR data, waveforms from bedside monitors, radiological images, clinician notes (NLP), ventilator data, as well as all supporting data sets and any future data sets that may be required. In addition to this, you will be working collaboratively with other members of the team to build out frameworks and infrastructure to support the needs of each of our data pipelines with as much automation as possible. Success in this role requires an ambitious and self-motivated individual capable of identifying areas for improvement, designing solutions, and prioritizing work to ensure that we are meeting our goals. This often involves learning new languages, technologies, and skills in order to ensure that we are delivering the best solutions possible. An inquisitive individual with a strong desire for continuous improvement and always taking the next best step is a strong fit at the Weil Institute. Who We Are The Weil Institute Overview The Weil Institute at the University of Michigan is one of the world’s first comprehensive research enterprises devoted to transforming critical care medicine by accelerating science and moving it from bench to bedside. To do this, the Weil Institute brings together integrative teams of world-class U-M scientists, clinicians, and engineers with industry partners and funding sources to develop and deploy cutting-edge solutions that elevate the care, outcomes, and quality of life of critically ill and injured patients and their families. Responsibilities* Build and improve tooling to automate data pulls Transform ad-hoc data pulls into real-time pipelines Administer infrastructure to support data and applications Implement monitoring solutions to ensure data integrity and pipelines are operational Build and integrate data cataloging into pipelines to ensure data security and enable future automation Communicate clearly and consult with our multi-disciplinary team of scientists, developers, and clinicians Actively participating in discussions and decisions made by the team. We rely on each other and hold each other accountable Determine and document requirements Estimate and adjust stories and sprints Investigate new technologies and share with the team Required Qualifications* DataOps Engineer Senior requirements: The Weil Institute DataOps Engineer Senior must have a bachelor’s degree in Engineering, Computer Science, Applied Mathematics, Statistics, or Data Analytics or equivalent experience with a minimum of 5 years of progressive software development experience in a data-driven environment. DataOps Engineer Intermediate requirements: The Weil Institute DataOps Engineer Intermediate must have a bachelor’s degree in Engineering, Computer Science, Applied Mathematics, Statistics, or Data Analytics or equivalent experience with a minimum of 2 years of progressive software development experience in a data-driven environment. In additional to the above requirements, candidates must also possess the following qualifications:: Proficiency using relevant tools (Python, SQL, Docker) Experience working in a Unix environment Familiarity with ML concepts (supervised learning and deep learning) Knowledge of commonly used software development concepts such as unit testing, git, publish-subscribe architecture, CI/CD, and REST interfaces Ability to manage multiple projects and assignments with a high level of autonomy and accountability for results Willingness to learn and quickly adjust to new tools and systems Capable of converting ambiguous problem statements into concrete project requirements Excellent verbal and written communication skills including the ability to communicate effectively and professionally with colleagues and stakeholders. Ability to understand and explain technical concepts to non-technical stakeholders Desired Qualifications* Preferred Qualifications: Familiarity with Kubernetes Familiarity with RabbitMQ Familiarity or experience with commonly used data science packages including numpy, pandas, scikit-learn, and tensorflow. Experience working with big data Experience developing CI/CD pipelines Experience working with PHI Epic certification for working in Clarity Underfill Statement This position may be underfilled at a lower classification depending on the qualifications of the selected candidate. Additional Information The Department of Emergency Medicine at Michigan Medicine is committed to creating an environment that is welcoming to all. We strive to value the unique contributions of individuals, and support a culture of inclusivity among our employees, learners and larger community. This includes supporting the development of a diverse workforce across identities such as race, ethnicity, national origin, sexual orientation, gender identity, age, citizenship, marital status, religion, language, disability, and Veteran status. We are proud to be an equal opportunity and an affirmative action employer. Background Screening Michigan Medicine conducts background screening and pre-employment drug testing on job candidates upon acceptance of a contingent job offer and may use a third party administrator to conduct background screenings. Background screenings are performed in compliance with the Fair Credit Report Act. Pre-employment drug testing applies to all selected candidates, including new or additional faculty and staff appointments, as well as transfers from other U-M campuses. Application Deadline Job openings are posted for a minimum of seven calendar days. The review and selection process may begin as early as the eighth day after posting. This opening may be removed from posting boards and filled anytime after the minimum posting period has ended. U-M EEO/AA Statement The University of Michigan is an equal opportunity/affirmative action employer. U-M COVID-19 Vaccination Policy COVID-19 vaccinations, including boosters when eligible, are required for all University of Michigan students, faculty and staff across all campuses, including Michigan Medicine. This includes those working remotely. More information on this new policy is available on the Campus Blueprint website or the UM-Dearborn and UM-Flint websites. Job Opening ID 216960 Working Title Data Ops Engineer Sr/Intermediate Job Title Data Architect Senior Work Location Ann Arbor Campus Ann Arbor, MI Full/Part Time Full-Time Regular/Temporary Regular FLSA Status Exempt Organizational Group Medical School Department MM Emergency Med Critical Care Posting Begin/End Date 6/09/2022 - 6/23/2022 Career Interest Information Technology"
Junior/Mid-level Software Engineer - Data Engineering,The Trade Desk,"Irvine, CA 92618 (Irvine Health and Science Complex area)",https://www.indeed.com/rc/clk?jk=f50102f65d8c7d73&fccid=4899a85209d20142&vjs=3,"The Trade Desk is a global technology company with a mission to create a better, more open Internet for everyone through principled, intelligent advertising. Handling over 600 billion queries per day (more than 100X the query volume of search globally), our platform operates at unprecedented scale. We have also built something even stronger and more valuable: an award-winning culture based on trust, empathy, collaboration, and ownership. By working together across typical dividing lines, we are better as a team than any of us could be apart. Do you have a passion for solving hard problems at scale? Are you eager to join a trust-based, globally-connected team, where your contributions will make a meaningful difference? Come and see why Fortune Magazine consistently ranks The Trade Desk among best small-medium sized workplaces globally. About the Role: Our Data Engineering Software Engineers are end-to-end owners. You will participate actively in all aspects of designing, building, and delivering data products for our clients. You will work with petabyte-scale data challenges, large-scale distributed systems coordinating thousands of servers in cloud and physical data centers around the world, machine learning, and advanced visualizations – to name a few. You will work with data processing pipelines, ML pipelines, data processing automation, data governance, data visualization, data quality, data privacy, data warehousing. Our Software Engineers work with a variety of platforms and technologies, such as Docker, Kubernetes, Gitlab, Bamboo, AWS, Azure, Scala, Spark, SQL Server, and Vertica. Who We Are Looking For: You understand engineering and computer science fundamentals. At our scale, many off-the-shelf techniques and existing technologies (open source and enterprise) simply don't work. You are able to work from first principles to evaluate solutions and adapt them to a unique environment. You are passionate about data engineering. You'll work at petabyte-scale with SQL, ETL, data modeling, and technologies similar to Spark, Scala, C#, Java, etc.. You are a creative thinker, not bound by ""the way things have always been done"". What you know is less important than how well you learn and innovate. We don't need engineers who know all the answers; we need engineers who can invent the answers no one has thought of yet, to the questions yet to be asked. What We Care About: What and how you can contribute is what’s important to us. Our consideration is not limited by the kind of education you have or the specific technologies you have experience with. Variety of technical challenge is one of the best things about working at The Trade Desk as an engineer, but we do not expect you to know every technology we use when you start. What we care about is that you can learn quickly and solve complex problems using the best tools for the job. Our culture runs much deeper than just having fun together (though, we do that well too...) – the people we want on our team are trust-builders, generous givers, scrappy problem solvers, and gritty pursuers of excellence. Does this sound like you? If so, we welcome your application and the chance to meet you. #LI-RE1 Our Compensation and Benefits (for Colorado residents only) Base Compensation Range: $95,800 - $191,600 In accordance with Colorado law, the range provided is The Trade Desk’s reasonable estimate of the base compensation for this role. The actual amount may be higher or lower, based on non-discriminatory factors such as experience, knowledge, skills and abilities. The Trade Desk also offers a competitive benefits package. Click here to learn more. The Trade Desk does not accept unsolicited resumes from search firm recruiters. Fees will not be paid in the event a candidate submitted by a recruiter without an agreement in place is hired; such resumes will be deemed the sole property of The Trade Desk. The Trade Desk is an equal opportunity employer. All aspects of employment will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law."
"Building Automation Engineer, Data Center Design",Facebook App,Remote,https://www.indeed.com/rc/clk?jk=4d4f0bf45447ad76&fccid=ba07516c418dda52&vjs=3,"Facebook is seeking a Building Automation Engineer experienced in the design and construction of Critical Facilities to become part of our Data Center Engineering team. Our data centers are the foundation upon which our software operates. Building and operating reliable and efficient data centers is essential to support the growth of Facebook. The Data Center Engineering team collaborates with all key stakeholders to ensure engineering and design of our data centers incorporate considerations from micro-levels (servers and IT equipment design requirements) to macro-levels (mechanical cooling and power distribution options) to ensure maximum efficiency and reliability of our compute infrastructure.The ideal candidate will have a strong background in all aspects of Building Automation. A thorough understanding of mechanical systems, electrical systems and IP networking is strongly desired. This person shall be detail-oriented, possess strong organizational skills, and be a self-starter that can excel with little direction. Building Automation Engineer, Data Center Design Responsibilities: Lead new project control engineering design, quality approval, process control, product evaluation, vendor proposals, evaluate product reliability, automated testing, software, research and development. Responsible for controls systems strategies, design, specifications, programming, simulation, testing as well as vendor and commissioning oversight. Lead development and initiate standards and methods for processes, control logic and sequences, testing, evaluation, and integration. Review BMS change management and provide feedback. Collaborate with multiple teams across different disciplines. Drive project schedules while working closely with design and construction to ensure milestones and completion dates are on track. Develop facility and vendor commissioning tests and standards for BAS project training close out efforts. Travel to datacenter sites for engineering studies, mechanical systems audits, startup testing, and full commissioning, as required. Travel to various equipment and bench testing design working sessions. Respond on an as-needed basis to emergencies. Minimum Qualifications: 6+ years of experience with control system design, development and management. Experience working simultaneously on multiple projects, in a team or independently. Experience in thermodynamics and psychometrics. Experience with electrical systems and schematics: low voltage and high voltage. Experience in BACnet protocol to include IP, ETH and MS/TP. Experience in Modbus protocol to include TCP, and RTU. Experience establishing working relationships and resolve interpersonal conflicts. Experience with Networking Server/Client Workstations. AutoCAD and VISIO experience. Preferred Qualifications: Experience with managing projects and project teams. Experience in BAS DDC and PLC programming language. N+ certification. Datacenter/Critical Facilities experience. IT and server hardware experience. DCIM experience. Schneider Electric PLC/Unity Pro experience. Citect SCADA experience. OPC UA experience. Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
Senior Data Engineer (Remote),Ganit,Remote,https://www.indeed.com/rc/clk?jk=ad2395c1cbf50332&fccid=a84170b5a8a8d5cc&vjs=3,"Must be able to write quality code and build secure, highly available systems. Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc with the guidance. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Monitoring performance and advising any necessary infrastructure changes. Defining data retention policies. Implementing the ETL process and optimal data pipeline architecture Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Create design documents that describe the functionality, capacity, architecture, and process. Develop, test, and implement data solutions based on finalized design documents. Work with data and analytics experts to strive for greater functionality in our data systems. Proactively identify potential production issues and recommend and implement solutions Skillsets: Good understanding of optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Proficient understanding of distributed computing principles Experience in working with batch processing/ real-time systems using various open-source technologies like NoSQL, Spark, Pig, Hive, Apache Airflow. Implemented complex projects dealing with the considerable data size (PB). Optimization techniques (performance, scalability, monitoring, etc.) Experience with integration of data from multiple data sources Experience with NoSQL databases, such as HBase, Cassandra, MongoDB, etc., Knowledge of various ETL techniques and frameworks, such as Flume Experience with various messaging systems, such as Kafka or RabbitMQ Good understanding of Lambda Architecture, along with its advantages and drawbacks Creation of DAGs for data engineering Expert at Python /Scala programming, especially for data engineering/ ETL purposes"
Senior Data Engineer,DocSend,Remote,https://www.indeed.com/rc/clk?jk=da0f72e4a8a2a486&fccid=8df30f4fbd5e2288&vjs=3,"Company Description Dropbox is a leading global collaboration platform that's transforming the way people work together, from the smallest business to the largest enterprise. With more than 500 million registered users across more than 180 countries, our mission is to design a more enlightened way of working. From our headquarters in San Francisco to eight dedicated Studios and a worldwide team of employees who choose where they work best, our Virtual First approach is leading the way into the future of work. Team Description Our Product team advocates for our users and our business, setting the vision for our growing family of products. We use data, research, strategy, and empathy to guide multidisciplinary teams toward a common goal, balancing diverse perspectives and empowering our teams to do great work. As we scale globally, there’s plenty of space for you to grow alongside us and simplify life for millions of people around the world in team that always focuses on we, not I, and creates delightful products that are worthy of trust. Role Description In this role you will build very large, scalable platforms using cutting edge data technologies. This is not a “maintain existing platform” or “make minor tweaks to current code base” kind of role. We are effectively building from the ground up and plan to leverage the most recent Big Data technologies. If you enjoy building new things without being constrained by technical debt, this is the job for you! Responsibilities You will help define company data assets (data model), spark, sparkSQL and hiveSQL jobs to populate data models You will help define and design data integrations, data quality frameworks and design and evaluate open source/vendor tools for data lineage You will work closely with Dropbox business units and engineering teams to develop strategy for long term Data Platform architecture Requirements BS degree in Computer Science or related technical field involving coding (e.g., physics or mathematics), or equivalent technical experience 4+ years of Python or Java development experience 4+ years of SQL experience (No-SQL experience is a plus) 4+ years of experience with schema design and dimensional data modeling Proven ability in regards to managing and communicating data warehouse plans to internal clients. Experience designing, building and maintaining data processing systems Experience working with either a Map Reduce or a MPP system on any size/scale Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work. A big part of that effort is our support for members and allies of internal groups like Asians at Dropbox, BlackDropboxers, Latinx, Pridebox (LGBTQ), Vets at Dropbox, Women at Dropbox, ATX Diversity (based in Austin, Texas) and the Dropbox Empowerment Network (based in Dublin, Ireland). Benefits and Perks Generous company paid individual medical, dental, & vision insurance coverage 401k + company match Market competitive total compensation package Free Dropbox space for your friends and family Wellness Reimbursement Generous vacation policy 11 company paid holidays Volunteer time off Company sponsored tech talks (technology and other relevant professional topics)"
Big Data Engineer,Group Delphi,"Remote in Pittsburgh, PA+1 location",https://www.indeed.com/company/Group-Delphi/jobs/Big-Data-Engineer-983ea8c8f97cd9ee?fccid=95a60db115e76460&vjs=3,"Job Title : Big Data Engineer (Contract) - Job# 3713 Location : Remote Job Description :This job is responsible for designing and engineering data solutions for the enterprise and, working closely with business, analytic and IT stakeholders, assists with the development and maintenance of these solutions. This includes coding data ingestion pipelines, transformations and delivery programs/logic for people and systems to access data for operational and/or analytic needs. Responsibilities Work with internal and external platforms and systems to connect and align on data sourcing, flow, structure, and subject matter expertise. Work with business stakeholders and strategic partners to implement and support operational and analytic platforms. Design and build production data pipelines from data ingestion to consumption within a hybrid big data architecture, using Cloud Native solutions, Java and Python. Migrate data from legacy systems including Hadoop, Oracle, Teradata, or DB Required: Strong technical orientation with at least a high level understanding of Oracle , DB2 Teradata , relational databases, MS Excel, and Informatica BDM , Hadoop and Hive (or similar ETL tools). Strong scripting / programming with UNIX, Python is required. Strong SQL experience with the ability to develop, tune and debug complex SQL applications is required About Delphi-USDelphi-US is a national recruiting firm based in Newport, Rhode Island. We specialize in IT, Engineering and Professional Staffing services for premier corporations and a multitude of industries across the United States. We are the Peacemakers In The Talent War – bringing the best and brightest talent to Employers of Choice, enabling critical project success, fostering progressive employment relationships, and promoting competitive advantages for our Clients and the Talent Marketplace we serve. Delphi accomplishes this with a proprietary skill-based and cultural matching process that results in higher qualified submissions along with increased interviews and offer rates. You’ll find our team is highly experienced, friendly, professional and ready to advocate on your behalf, armed with industry trends, and an understanding of employer expectations. Job Type: Contract"
Data Center Engineer,RK,"Aurora, CO 80011 (Norfolk Glen area)",https://www.indeed.com/rc/clk?jk=7c3438d55507c217&fccid=c5a265d640300828&vjs=3,"RK Mission Critical provides custom-engineered modular solutions for the data and telecom industries. We’re a single source solutions provider that can handle complex and high-volume projects. We listen carefully to customer needs and have the experience to develop solutions that others can’t or won’t. The peRKs: RK Contributions Four medical plans with HSA and FSA options for you and your family 401(k) plan with company match that is 100% immediately vested Dental and vision insurance Short-term and long-term disability plans available after one year Company provided life insurance and AD&D with options for supplemental buy-ups. Paid time off and holidays Weekly pay In-house Programs Career development training for all levels through RK University Wellness coaching offering exercise planning, gym discounts, health screenings, program incentives up to $2,100 a year, and more. Fun company and team building events, and volunteering opportunities. Partnership Programs Confidential counseling for personal issues, financial advice and more Discounts on entertainment including amusement park tickets, restaurant specials and more Additional discount on product and services for life's necessities such as phone, internet and work apparel What you’ll be working on: Development and maintenance of 3D models, bill of materials, and relevant drawing packages in accordance with RKMC standards, Customer specifications, and regulatory requirements. Uphold RK Mission Critical documentation and design & development standards and practices as well as product/customer specifications. Actively participate in drawing reviews for input of manufacturability. Coordinate feedback with Production. Collaborate with subject matter experts to approve submittals for engineered items. Ensure all flow-down requirements from the project are met by vendors/sub-contracts. Work directly with a Project Manager to communicate RFIs, approve design or scope changes, and validate design intent per the project contract/ product specifications. Become a subject matter expert in Data Center design and construction, including but not limited to: UL 2755, equipment selections, and specification review. Investigate design changes to produce Engineering Change Notices (ECNs) to the RKMC team to ensure training and communication. What is expected of a Data Center Engineer: Bachelor’s degree in Engineering or related field and approximately 5 years of experience. Experience in data center or modular building design favorably considered. Firm knowledge of Microsoft Suite products including Teams, Planner, and Excel. Strong computer literacy and organizational skills required. Firm knowledge of 3D manufacturing CAD software (preferably Autodesk Inventor) and detailed manufacturing drawing creation. Works in conjunction with Engineering leadership and Project Manager to execute an RK Mission Critical Data Center. Reports to the Engineering Manager. How you make Safety your top priority: Comply with all company policies and procedures. All employees are accountable for safety and health and are empowered to stop work if an unsafe condition is present. Employees should immediately notify their supervisor so that the hazard may be corrected. RK Mechanical employees and subcontractors are required to implement and maintain all safety and health systems practices including the training requirements of RK Mechanical Orientation, shop specific orientation, CPR/First Aid/AED/Bloodborne Pathogens, Hazard Identification and Reporting, and OSHA 10 Local Awards: Denver Business Journal #1 Denver-Area Mechanical Contractor 2014- Present #6 Fastest Growing Denver Area Private Company: X-Large, 2019 #7 Denver-Area Corporate Foundation, 2020 #7 Denver-Area Manufacturing Firm, 2020 #14 Denver-Area Healthiest Employers, 2020 #16 Largest Denver-Area Private Employer, 2020 #22 Denver-Area Private-Sector Employer, 2020 #23 Denver-Area Corporate Philanthropists, 2020 ColoradoBiz Magazine #8 Top 200 Private Companies List, 2020 Associated Builders and Contractors (ABC) - Rocky Mountain 1st Place Specialty Contractor Award of Excellence- Ascent Union Station 2nd Place Specialty Contractor Award of Merit- Pike Peak National Cemetery Accredited Quality Contractor (AQC) “Platinum Level” Company in STEP Safety Management System Platinum level ratings or higher from the ABC STEP program for nine of the past twelve consecutive years Colorado Manufacturing Awards RK Mission Critical- CMA Building and Construction Manufacturer of the Year Colorado Workforce Development Council 2020 Colorado Apprenticeship Program of the Year, Employer National Awards: Engineering News Record 2020 ENR Mountain States Specialty Contractor of the Year 2019 Colorado Project of the Year Winner- Gaylord Rockies 2020 Office/Retail/Mixed-Use, Award of Merit: Financial House 2020 Cultural/Worship, Award of Merit: Denver Art Museum Sie Welcome Center Top 40 and highest ranked Mechanical Firm in Colorado on ENRs Top 50 Firms in Mechanical, 2020 #8 Top 20 Firms in Sheet Metal, 2020 #19 Top 20 Firms in Steel Erection, 2020 #95 ENRs “The Top 600 Specialty Contractors”, 2020 Associated Builders and Contractors #16 Top 200 Performers, 2020 #2 Top 20 Plumbing/HVAC Contractors, 2020 #5 Top 30 Electrical Contractors, 2020 America Heart Association Gold Level Employer"
Big Data Engineer- 100% Remote,Alight,"Remote in Chicago, IL 60601",https://www.indeed.com/rc/clk?jk=7781e979fc3735ac&fccid=c35833abe06c86e0&vjs=3,"About Alight Solutions With an unwavering belief that a company's success starts with its people, Alight Solutions is a leading cloud-based provider of integrated digital human capital and business solutions. Leveraging proprietary AI and data analytics, Alight optimizes business process as a service (BPaaS) to deliver superior outcomes for employees and employers across a comprehensive portfolio of services. Alight allows employees to enrich their health, wealth and work while enabling global organizations to achieve a high-performance culture. Alight's 15,000 dedicated colleagues serve more than 30 million employees and family members. Learn how Alight helps organizations of all sizes, including over 70% of the Fortune 100 at alight.com We are proud to announce that Alight certified as a Great Place to Work for fourth consecutive year! https://bit.ly/3rcaE9y In 2021 we were also named a Best Place to Work by Parents@Work, earned a perfect score on the Human Right Campaign Foundation’s Corporate Equality Index and was listed among the top 100 companies for remote workers by Flexjobs. Click here https://bit.ly/3qGTguq to learn more about what makes Alight a great place to work! The Big Data Engineer must be able to design, build and maintain enterprise level data pipelines utilizing the public cloud (AWS or Azure) based data ingestion services or ETL/ELT tools available within the big data ecosystem. The engineer will work closely with data analysts, data scientists, and database and systems administrators to create data & analytical solutions. This position is embedded within Alight's Retiree Health Solutions’ Data Science team with additional support/mentorship from Enterprise Architecture. Responsibilities include the following: Design, build, deployment, of ETL/ELT data pipelines within big data ecosystems (currently using Streamsets/IICS, Impala, Hue, Spark, Python, and Cloudera) to populate cloud-based infrastructure (currently using AWS). Develop technical design, and ETL specification documents Perform complex parallel loads, cluster batch execution and dependency creation using jobs/topologies/workflows. Convert existing SQL stored procedures for optimal execution in Streamsets/IICS. Work with web service targets, XML/JSON Sources and Restful APIs. Manage, monitor and fine tune Hadoop cluster architecture (HDFS) jobs for performance, security and resource management. Create detailed designs and POCs to enable new workloads and technical capabilities on the Platform. Work with the platform and infrastructure engineers to implement these capabilities in production. Coordinate with Enterprise Analytics to manage workloads and enable workload optimization including resource allocation and scheduling across multiple tenants to fulfill SLAs. Document new/existing pipelines and datasets. Participate in planning activities with Data Science and Enterprise Architecture teams. Required Skills: Minimum 4 years of experience in ETL/ELT Technologies (e.g., StreamSets/Informatica (IICS particularly), Talend). Expert level hands-on skills on Spark, and Python programming Minimum of 2 years of hands-on experience with big data technologies (e.g. Hadoop, Spark, Hive) deployed in the public cloud (preferably in AWS or Azure). Minimum 4 years of experience in data model, technical metadata, creating data objects, data warehouse and DataMart designs Minimum 4 years of experience in any of database technologies SQL Server, Oracle, Postgres, MySQL. Strong exposure working with relation databases DB2, Oracle & SQL Server including complex SQL constructs and DDL generation. Preferred Skills AWS or Azure certification strongly preferred Experience with AWS Kinesis, Firehouse, or Confluent strongly preferred. Experience with Cloudera Manager, Navigator, and Data Science Workbench. Exposure to data cataloging products like Alation or Collibra. Exposure to data security tools, and technologies. Experience with BI reporting tools like PowerBI, and Tableau With a competitive total rewards package, continuing education and training, and tremendous potential with a growing global organization, Alight is the perfect place to put your passion to work. Background Check Required By applying for a position with Alight, you understand that, should you be made an offer, it will be contingent on your undergoing and successfully completing a background check consistent with Alight’s employment policies. Background checks may include some or all of the following based on the nature of the position: SSN/SIN validation, education verification, employment verification, and criminal check, search against global sanctions and government watch lists, fingerprint verification, credit check, and/or drug test. You will be notified during the hiring process which checks are required by the position. Additionally, an active security clearance or the ability to obtain one may be required for this role. Equal Employment Opportunity Alight is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, ancestry, national origin, physical or mental disability, veteran or military status, or any other legally protected characteristics or conduct covered by federal, state or local law. In addition, Alight takes affirmative action to ensure that applicants are employed, and that employees are treated during employment, without regard to their race, color, religion, sex, sexual orientation, gender identity, protected veteran status, or national origin. Reasonable Accommodations Alight provides reasonable accommodations to the known limitations of otherwise qualified employees and applicants for employment with disabilities, sincerely held religious beliefs, practices and observances, unless doing so would result in an undue hardship. Applicants for employment may request a reasonable accommodation/modification by contacting his/her recruiter. Diversity Statement At Alight, we believe that diversity should be visible, valued, and sustained throughout the organization. Alight provides equal treatment and employment opportunities to all employees and applicants for employment without regard to any protected status or other protected characteristic. Authorization to Work in the United States Applicants for [employment/this position] in the United States must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Alight. RHS_2022 #LI-Remote We offer you a competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization. Colorado Equal Pay for Equal Work Act Statement. Please note, offers are being determined on an individual basis. Alight takes into consideration the candidate’s experience, education, certification/credentials, market data and internal equity. The estimated minimum salary for this role is $100,000.00/year (full-time). In addition to the base salary, this position may be bonus eligible. For specific benefit details, please visit this URL: https://bit.ly/Alight-Benefits DISCLAIMER: Nothing in this job description restricts management's right to assign or reassign duties and responsibilities of this job to other entities; including but not limited to subsidiaries, partners, or purchasers of Alight business units. Alight Solutions provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, genetic information, pregnancy, childbirth or related medical condition, veteran, marital, parental, citizenship, or domestic partner status, or any other status protected by applicable national, federal, state or local law. Alight Solutions is committed to a diverse workforce and is an affirmative action employer."
Data Engineer,Weir Group,"Fort Worth, TX",https://www.indeed.com/rc/clk?jk=ae8d622ec555395c&fccid=8137be09b3b9a5db&vjs=3,"Business Need / Purpose of Role: The Division is currently busy with a multiyear deployment of a modern Data & Analytics programme. As the programme scales up to include data from sources other than SAP the following challenges need to be overcome: There needs to be a clear strategy and programme to govern key data alignment and quality in order to ensure it is useful for both business units and the division The Division needs to design a common data model to describe the overall data structure and ensure everyone is using the same language The Division needs to design and optimize the architecture of its data stored in various systems, including Azure Synapse. The Division needs to design and build data pipelines to ingest non-SAP ERP supply chain data into SAP BW/4HANA The Division needs to design and build data pipelines to ingest non-ERP data into Azure Synapse (e.g. Salesforce, etc) Key Responsibilities and Specific Accountabilities: Design and implement and maintain Big data pipelines to extract and transform structured, semi structured and unstructured data from various sources and turn them into clean curated data products Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Engineer and implement data architectures to improve the performance of data pipelines (speed, reliability and cost) Work alongside analytics application developers and data architects to implement end to end analytics solutions focused on Business needs Work to maintain and improve ‘DataOps’ processes needed to ensure new data products are correctly deployed and maintained This role will be focused on data engineering tasks specific to our various information system platforms (SAP, Salesforce, 42Q, Market Data) Those role will be focused on Data Engineering work in Azure Synapse Education and Experience Bachelor of science degree in a science, engineering or information systems field Experience 5 years’ experience in a Data Engineering / Analytics role Experience with modern Data Warehouse platforms (AWS, Google Big Query, Snowflake etc.). Ideal if there is experience with Azure cloud services / Azure Synapse and SAP BW/4HANA Experience with building and maintain complex data pipelines, including batch and streaming analytics Skills and Qualifications Advanced working SQL/TSQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases Experience with Apache Spark is a plus Experience with Azure Data Studio and Microsoft SQL Server Management Studio) Language Skills: Ability to read, analyze, and interpret general business periodicals, professional journals, technical procedures, or governmental regulations. Ability to write reports, business correspondence, and procedure manuals. Ability to effectively present information and respond to questions from groups of managers, clients, customers, and the general public. Mathematical: Ability to calculate figures and amounts such as discounts, interest, commissions, proportions, percentages, area, circumference, and volume. Ability to apply concepts of basic algebra and geometry. Reasoning Ability: Ability to define problems, collect data, establish facts, and draw valid conclusions. Ability to interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables. Other Knowledge, Skills and Abilities: Proactive and project orientated Ability to effectively communicate and influence others Certificates, Licenses, Registrations: Analytics certification in any major cloud platform is a plus. Examples include Azure Data Engineer, Google Could Digital Leader, AWS Data Analytics specialty Physical Demands: Office work Work Environment: 80% of the time the work will be office based in once location, with occasional travel to offsite events 2-3 times per year"
Data Warehouse Engineer II | Remote,Cardinal Financial,Remote,https://www.indeed.com/rc/clk?jk=dd18e34f57fe95ed&fccid=0b613f0fbef54ac6&vjs=3,"Who We Are: Cardinal Financial is a nationwide direct mortgage lender that focuses on creating solutions for our borrowers, partners, and employees—to provide the very best experience. We are genuine and hard-working individuals who are not scared to improve and intentionally push beyond what is considered “good enough.” Looking to join a company that values its people, innovates and expands on its proprietary technology, and is growing at a ridiculous rate?! Apply below! Who We Need: The Data Warehouse Engineer II is responsible for maintaining, expanding and improving the data warehouse and surrounding systems and processes What You Will Do: Design ETLs for data sources that can automatically run and reliably maintain data in the data warehouse Make improvements to the processes and scripts surrounding the data warehouse and ETLs as directed for performance, reliability and ease of maintenance Trace possible data discrepancies through any report/external logic, data transformations and the source of the data to identify the root cause of the issue Collaborate with stakeholders to ensure the established data definitions match their expectations Uphold data security and data governance best practises Collaborate with greater engineering team in an agile environment Manage your tasks completely, including prioritization, working with stakeholders for design and specs, communicating status to all, completing the work, and documenting what you've done Participate in code reviews and daily interactions to ensure our warehouse meets our high standards. We mix up the review teams so you'll get exposed to the whole system What You Need: Bachelor’s degree in Computer Science, Data Science or related field or equivalent experience 3-7 years experience designing, creating and maintaining ETLs moving data into a data warehouse You communicate well whether you’re getting specs from a stakeholder, writing those specs, explaining a design to your colleagues, or patiently helping a user Knowledge of data warehouse design and best practises (e.g. star schemas) Familiarity with python scripts to automatically interact with databases Ability to understand and untangle complex business rules and data structure You love having agency in your work and finding new ways to be better. Learning, creation, change and thoughtful debate are things you enjoy You’re comfortable working in a team where each of us has a huge impact and we depend on each other to get things done Familiarity and experience with any of the following: Shell scripts, AWS Step Functions, Jenkins, Pentaho, Looker, Git, BigQuery What We Offer: Strength, Stability, and Vision. Great compensation package. Opportunity for career growth. A commitment to be a relevant market leader - we are aiming for the top! Octane, our engineered proprietary technology that is transforming the mortgage industry. An empowered culture where your ideas are important and your voice matters. Full Benefits, beginning the first day of the month following your start date, including – Medical, Dental, Vision, Life, Disability Insurance, and much more. Generous paid time off package that also includes all major holidays. 401K w/ 50% match - Beginning the 1st of the month following 30 days of employment. Cardinal Financial is an Equal Opportunity Employer. We respect and aim to empower individuals and support the diverse cultures, perspectives, skills, and experiences within our workforce. The expected base salary for this position ranges from one hundred and four thousand, four hundred & ninety-nine dollars to one hundred thirty-five thousand, eight hundred & forty-nine dollars, determined based on the applicant's experience, skillset, education, training, certificates, and licenses. #LI-DP1"
Test Data Management Engineer,General Motors,"Austin, TX",https://www.indeed.com/rc/clk?jk=3cc8d341ebff55ee&fccid=116680a29a847a70&vjs=3,"Job Description This is a Hybrid position within our IT Organization. The role will allow employees to work offsite but will also require onsite work based on business needs. The selected candidate will be expected to commute to the innovation center to which they are assigned as their primary GM facility. Relocation may be provided."" For all external applicants, we are targeting a start date on or after January 10th 2022 for this position. In recent years, GM Information Technology has successfully executed the largest IT transformation in the history of the automotive industry, fully insourcing what once was a nearly completely outsourced IT function. Today GM IT is a dynamic and fast paced organization that designs, develops and maintains all IT infrastructure, applications and solutions enabling GM's global operations. From designing and building the next generation of electric and other vehicles to developing a world-class GM experience for our dealers and customers, GM IT is driving real change in the most iconic automaker on the planet. Our team delivers unique enterprise-wide IT solutions in cutting-edge technologies such as mobility, telematics, mission-critical business systems, supercomputing, cloud, vehicle engineering and real-time computing. We offer challenging positions for passionate professionals looking to advance their careers and be a part of an IT organization focused on innovation, speed and business value. The TDM Engineer, is a technical expert in analysis, design, coding and debugging of TDM provisioning solutions using TDM methodologies and commercial TDM products like IBM Optim. Required to perform Test Data Management functions of Data Setup on existing applications, developing methods for day-to-day data provisioning, build frameworks for Data Mining and Data Reservation, architect TDM (Test Data Management) solutions for data provisioning for Domain and Enterprise wide applications including Data Discovery, Data Masking and Data Subset and architect Gold Copy databases and Data Stores for quick data provisioning. RESPONSIBILITIES: Data model analysis of large databases Create subset plan and build subset queries for large databases Sensitive data analysis for PHI, PCI & PII data for large databases Build Data Masking Rules and Seed lists Develop and Build Data Subset, Data Masking and Data Generation jobs using IBM Optim Build custom code as needed to support TDM solution Build and maintain Gold copy databases REQUIREMENTS: 5+ Years of experience as TDM Engineer or ETL Developer Extensive knowledge of SQL, test data design and test data management tools with a proven history of providing effective test data solutions Experience with data masking / obfuscation Experience in integrating with DevOps Experience with any commercial TDM tool like Informatica TDM or IBM Optim or Talend TDM or Delphix or FileAID EX or CA TDM Proficient in Java, UNIX Shell Scripting & Windows Scripting Knowledge of relational database design, programming and information retrieval techniques; Solid experience in writing complex SQL queries, insert/update statements Expertise on Oracle, SQL Server, DB2 PREFERRED: Experience with IBM Optim Additional Job Description PREFERRED: Experience with IBM Optim 5+ Years' experience The successful candidate will play a key role in expanding and modernizing test data management framework and processes and will be accountable for designing, building, and implementing TDM solutions About GM Our vision is a world with Zero Crashes, Zero Emissions and Zero Congestion and we embrace the responsibility to lead the change that will make our world better, safer and more equitable for all. Why Join Us We aspire to be the most inclusive company in the world. We believe we all must make a choice every day - individually and collectively - to drive meaningful change through our words, our deeds and our culture. Our Work Appropriately philosophy supports our foundation of inclusion and provides employees the flexibility to work where they can have the greatest impact on achieving our goals, dependent on role needs. Every day, we want every employee, no matter their background, ethnicity, preferences, or location, to feel they belong to one General Motors team. Benefits Overview The goal of the General Motors total rewards program is to support the health and well-being of you and your family. Our comprehensive compensation plan incudes, the following benefits, in addition to many others: Paid time off including vacation days, holidays, and parental leave for mothers, fathers and adoptive parents; Healthcare (including a triple tax advantaged health savings account and wellness incentive), dental, vision and life insurance plans to cover you and your family; Company and matching contributions to 401K savings plan to help you save for retirement; Global recognition program for peers and leaders to recognize and be recognized for results and behaviors that reflect our company values; Tuition assistance and student loan refinancing; Discount on GM vehicles for you, your family and friends. Diversity Information General Motors is committed to being a workplace that is not only free of discrimination, but one that genuinely fosters inclusion and belonging. We strongly believe that workforce diversity creates an environment in which our employees can thrive and develop better products for our customers. We understand and embrace the variety through which people gain experiences whether through professional, personal, educational, or volunteer opportunities.GM is proud to be an equal opportunity employer. We encourage interested candidates to review the key responsibilities and qualifications and apply for any positions that match your skills and capabilities. Equal Employment Opportunity Statements The policy of General Motors is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity/expression or veteran status. Additionally, General Motors is committed to being an Equal Employment Opportunity (EEO) Employer and offers opportunities to all job seekers including individuals with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, email us atCareers.Accommodations@GM.com. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying."
Sr. Software Engineer ( Azure Data Engineer ),"Vizient, Inc.","Irving, TX 75062 (Las Colinas Urban Center area)",https://www.indeed.com/rc/clk?jk=9fd1cf45a4c7b58a&fccid=ab22e7c357e67bd4&vjs=3,"When you’re the best, we’re the best. We instill an environment where employees feel engaged, satisfied and able to contribute their unique skills and talents. We provide extensive opportunities for personal and professional development, building both employee competence and organizational capability to fuel exceptional performance now and in the future. Responsibilities: Partners with developers, administrators, and other roles responsible for implementing solutions on Azure. Implements and manages the operational aspects of cloud-native and hybrid data platform solutions built with Microsoft SQL Server and Microsoft Azure. Uses a variety of methods and tools to perform day-to-day operations, including applying knowledge of using T-SQL for administrative management purposes. Recommend and Implement automation for day-to-day operations. Advise stakeholders translating business requirements into secure, scalable, and reliable cloud solutions. Provide Infrastructure as code support for Azure databases and DevOps. Designing and implementing solutions that run on Microsoft Azure, including aspects like compute, network, storage, and security. Work with product teams and cloud administrators to implement solutions. Technical Requirements: Must have subject matter expertise in designing cloud and hybrid solutions that run on Microsoft Azure, including compute, network, storage, monitoring, and security. Experience with planning and implementing data platform resources in Azure. Experience implementing Azure monitor, Azure SQL Analytics, and other monitoring solutions for Azure resources. Plan and implement a High Availability and Disaster Recovery (HADR) environment in Azure and On-Prem SQL like Availability groups, readable secondary etc. Provide recommendations on access management solution including RBAC policies, access reviews, role assignments, Privileged Identity Management (PIM), Azure AD Identity Protection. Recommend a solution for cost management and cost reporting Recovery solutions for Azure hybrid and on-premises workloads that meets recovery objectives (RTO, RLO, RPO) Experience with solutioning Azure Backup management, data archiving and retention, application, and workload redundancy, including compute, database, and storage; auto scaling. Ability to assess and interpret on-premises servers, data, and applications for migration Implement solution for migration of very large databases. Experience with Azure Synapse, Datalake. Experience working with migrating data (Storage Migration Service, Azure Data Box, Azure File Sync-based migration to hybrid file serve Ability to recommend an orchestration solution for deployment and maintenance of applications, including ARM templates, Azure Automation, Azure Pipelines, Logic Apps, or Azure Functions Typescript and Pulumi experience a must. Mongo DB and MYSQL is good to have. Ability to work independently as well as part of a team with minimal direction. Estimated Hiring Range: $102,400.00 - $152,200.00 This position is also incentive eligible. Vizient has a comprehensive benefits plan! Please view our benefits here: http://www.vizientinc.com/about-us/careers Equal Opportunity Employer: Females/Minorities/Veterans/Individuals with Disabilities The Company is committed to equal employment opportunity to all employees and applicants without regard to race, religion, color, gender identity, ethnicity, age, national origin, sexual orientation, disability status, veteran status or any other category protected by applicable law."
Mid Analytics Data Engineer,EX2 Outcoding,Remote in United States,https://www.indeed.com/rc/clk?jk=d8f1d2238d7005f2&fccid=c2dcb40d7ba23298&vjs=3,"We are looking for an Mid Analytics/Data Engineer: What you’ll need: 3+ years’ experience as an analytics engineer, data analysts, or similar role. Is familiar with or excited by modern data tools. Experience with Athena, Glue and QuickSight. Experience with CDK. Experience with SQL. Has a strong understanding of data quality testing. Has excellent time management, prioritization, and accountability over their work. Knowledge in data lakes. This will be considered a plus Experience with AWS technologies. A background in SaaS and an understanding of typical SaaS business metrics. What you’ll do: Build & maintain high quality datasets and provide reliable access to the rest of the business. You'll be the go-to analytics specialist, helping to bridge the gap between business needs and the data models needed to support them. Help define our overall data strategy, from raw data to finished reports and the data made available We offer: to our internal tools. About our client: Our client offers a seamless and intuitive virtual event platform coupled with our expertise in virtual, in- person & hybrid event production and management. About us: EX² Outcoding is a premier solution provider of a broad range of outsourcing services, combining proven expertise in technology and project execution for companies searching for high-quality software development solutions. We specialize not only in delivering the best technical solution but also in enhancing that solution creatively by working closely with stakeholders to understand the business context. #LI-GG1 #LI-REMOTE Location Latin America, . Department Recruiting Employment Type Full-Time Minimum Experience Mid-level"
Software Engineer - All levels - Data Platforms,f5,"San Jose, CA",https://www.indeed.com/rc/clk?jk=254ad3dfd212e228&fccid=093a18bf96b31ae1&vjs=3,"Come work at a place where innovation and teamwork come together to support the most exciting missions in the world! About AI and Data Team at F5 F5 (NASDAQ: FFIV) is a multi-cloud application security and delivery company that enables our customers—which include the world’s largest enterprises, financial institutions, service providers, and governments—to bring extraordinary digital experiences to life. For more information, go to f5.com . You can also follow @F5 on Twitter or visit us on LinkedIn and Facebook for more information about F5, its partners, and technologies. As the AI and Data product group at F5, our mission is to build a world-class data platform, data and privacy practices, and tools. Position Summary As a software engineer on F5’s AI and Data Platforms team -Big F5 Data Platforms, you will be solving unique and challenging problems in our cloud-based data system, which handles Exabyte-scale data collecting, stream processing, storage, query, and visualization in near real-time. At AI and Data product group, you will work with exceptional team members, use groundbreaking technologies, and solve world-class engineering challenges. Responsibilities Design and develop F5’s cloud-based data systems to process Exabyte-scale data in near real-time. Research new technologies for more efficient and scalable data collection, processing, storage, and retrieval. Design and implement tools and methodologies to ensure data integrity and build out our data system health monitoring solutions. Collaborate with the product team, other engineering teams, and the operations team to design/implement/maintain cross-functional data systems for F5’s growing core business needs. Required Qualifications Bachelor's degree (or above) in Computer Science or related fields. Proficient in one of the following languages: Java, C++, Go Proficient in SQL. Effectively communicate with clarity and conciseness both in written and verbal forms. Desired Qualifications Proficient in Python, Rust, C Working experience with one of the public cloud systems: GCP, AWS, or Azure. Working experience with Pub/Sub related technologies like GCP PubSub, Kafka, Pulsar etc. Working experience with streaming (or micro-batching) data processing platforms like GCP Dataflow, Apache Flink, Apache Spark, etc. Working experience with both relational databases and NoSQL databases. Working experience with data processing programming models like Apache Beam, etc. Working experience with data warehouse technologies like GCP BigQuery, AWS Redshift, Azure Synapse, Snowflake, Apache Druid, Clickhouse, etc. Working experience with OpenTelemetry. Expertise in Petabyte-to-Exabyte-scale data processing frameworks. F5 is an equal opportunity employer and we embrace diversity #li-gj1 The Job Description is intended to be a general representation of the responsibilities and requirements of the job. However, the description may not be all-inclusive, and responsibilities and requirements are subject to change. Please note that F5 only contacts candidates through F5 email address (ending with @f5.com) or auto email notification from Yello/Workday (ending with f5.com or @myworkday.com). Equal Employment Opportunity It is the policy of F5 to provide equal employment opportunities to all employees and employment applicants without regard to unlawful considerations of race, religion, color, national origin, sex, sexual orientation, gender identity or expression, age, sensory, physical, or mental disability, marital status, veteran or military status, genetic information, or any other classification protected by applicable local, state, or federal laws. This policy applies to all aspects of employment, including, but not limited to, hiring, job assignment, compensation, promotion, benefits, training, discipline, and termination. Reasonable accommodation is available for qualified individuals with disabilities, upon request."
BIG DATA ENGINEER,Tabiya Technology,"Chevy Chase, MD",https://www.indeed.com/rc/clk?jk=92299d1a6c69b872&fccid=70c0f95ed8774eb3&vjs=3,"Job Overview Short Description Big Data Engineer (Hadoop Java or Spark) Eastern Technology World Wide Solutions, Inc. (VOSB) – Chevy Chase, MD Duration: 2 years+ contract (nice and stable) PHONE and Skype H1B, GC and Citizens Must Speak Well Required SKILLS are in bold. Detailed Description Location: Chevy Chase, MD Duration: 2 years+ contract (nice and stable) PHONE and Skype H1B, GC and Citizens Must Speak Well Required SKILLS are in bold. Minimum Requirements 3 years of hands-on experience in the Hadoop ecosystem (HDFS, YARN, MapReduce, Oozie, AND Hive) 1 year of hands-on experience in Spark core AND Spark SQL 5 years of hands-on programming experience in either core Java OR Spark 3 years of hands-on experience in Data Warehousing AND Data Marts AND Data/Dimensional Modeling AND ETL 1 years of hands-on experience in HBase OR Cassandra OR any other NoSQL DB Understanding of Distributed computing design patterns AND algorithms AND data structures AND security protocols Desired Skills Understanding of Kafka AND Spark Streaming Experience in any one of the ETL tools such as Talend, Kettle, Informatica OR Ab Initio Exposure to Hadoop OR NoSQL performance optimization and benchmarking using tools such as HiBench OR YCSB Experience in performance monitoring tools such as Ganglia OR Nagios OR Splunk OR DynaTrace Experience on continuous build and test process using tools such as Maven AND Jenkins Certification in HortonWorks OR Cloudera preferred- not required but strongly desired Murray Newcomb Technical Laison Eastern Technology World Wide Solutions, Inc. a Certified Veteran Owned Small Business. Unlike so much of the competition, I have a degree in CS and 35 years of UNIX/LINUX experience and might be more technical then most the recruiters you work with. 703-501-8395 www.etwws.com Job Type: Contract Salary: $55.00 to $60.00 /hour Application Questions You have requested that Indeed ask candidates the following questions: How many years of Data Warehousing and Big Data Marts and Data/Dimensional experience do you have? How many years of Hadaoop (HDFS, YARN, MapReduce, Oozie, and Hive) experience do you have? How many years of HBase or Cassandra or any other NoSQL DB experience do you have? How many years of Java and or Spark experience do you have? How many years of Spark core and Spark SQL experience do you have? Have you completed the following level of education: Bachelor's? Are you in Chevy Chase, MD? Are you authorized to work in the following country: United States? Do you have the following license or certification: read that as certifications - HortonWorks or Coludera?"
Lead Data Engineer,"Chick-fil-A, Inc.","Atlanta, GA 30349+3 locations",https://www.indeed.com/rc/clk?jk=c9f9a8727b5e06ae&fccid=ff1746cf19c4661b&vjs=3,"Overview: As a Lead Data Engineer, you will be responsible for leading significant role-specific data governance integration project work as a part of our larger Enterprise Analytics team in support of major analytics technology tools. Our Lead Data Engineer will typically leverage and implement pre-defined analytics infrastructure on projects of moderate to advanced technical complexity, focusing on developing solutions that ultimately provide visibility to analytics assets and improve the quality of outcomes through monitoring. They must be able to quickly develop mastery of the needed subject across a specific line of business for which they are responsible. Our Lead Data Engineers typically work with some latitude for action or decisions on specific projects, solutions, or technical issues. They may represent EA in internal conversations and may assist with the selection or oversight of outside vendor partners. Successful candidates for this role must have strong technology and data analysis skills, a solid understanding of database technology and data use within analytic platforms, and they must have strong programming skills with SQL and/or Python. We expect Lead Data Engineers to have the capacity for fluency and competency in both the technology language of IT and the analyst language of departmental analysts. They will need to be fast learners with a keen eye for detail, systems thinking, and process design. They must be team players who work steadfastly to create impactful change. This is a professional track role. Responsibilities: The person who fills this role will be expected to do the following as a part of their regular work responsibilities: Works with business stakeholders and IT to translate business logic into scalable data and analytic solutions. Exercises creative problem solving in identifying technical solutions to the integration between data governance systems and analytics tools. Develops data governance pipelines for integrating Informatica with Tableau/ThoughtSpot/Alteryx/Databases for general business consumption, typically leveraging existing patterns as available for specific project execution and building pipelines with scalability in mind. Implements tool, data, and analytics best practices for specific project execution and advises analytics users on such best practices when relevant Leverages tools efficiently, understanding technology server and database performance limitations. Leverages cloud compute resources efficiently. Performs ad-hoc analysis as necessary to support specific project work. Drives projects to success and enables others to own the impact. Minimum Qualifications: 3-5 years experience Bachelor's Degree in MIS, Decision Sciences, Engineering, Business Analytics, Computer Science or other similar fields Has strong analytical and data modeling skills Has a solid understanding of database technology Has experience with AWS or similar Is familiar with distributed compute Has a solid understanding of analytic platform data use Has strong programming skills in SQL and/or Python Has the skill to partner with cross-functional teams using strong written and verbal communication Fast learner and proven problem solver Keen eye for system thinking and process design, especially with respect to scalability and automation Keen eye for detail and thoughtful investigation of data Has a steadfast focus on creating impactful change Preferred Qualifications: 3-5 years experience Master's Degree in MIS, Decision Sciences, Engineering, Business Analytics, Computer Science or other similar fields Has some experience using the AWS big data technology stack Has moderate experience with Alteryx or similar ETL platforms Has some experience implementing data governance principles Minimum Years of Experience: 3 Travel Requirements: 10% Required Level of Education: Bachelor's Degree Preferred Level of Education: Masters Degree Major/Concentration: MIS, Decision Sciences, Engineering, Business Analytics, Computer Science or other similar fields"
Data Engineer,Entera,"Remote in New York, NY 10013",https://www.indeed.com/rc/clk?jk=1667f42ab2278a44&fccid=c8e07f37dc242ad2&vjs=3,"About Entera: We are a venture backed real estate technology company with the leading SaaS + Services platform for residential investors. Powered by machine-learning and 100% online, Entera's end-to-end residential real estate platform modernizes the real estate buying process to help our clients access and evaluate more properties, scale their operations, make data-driven investment decisions, and win more often. Many of the largest real estate investors in the world use Entera's marketplace daily. Entera's annual transaction run rate is over $3.6B across 24 markets since its launch in 2018. Entera has raised $40M of venture capital from some of the most established & trusted firms in the world. The company is headquartered in New York City, New York and Houston, Texas. The Role As a Data Engineer, you'll contribute to our best-in-class data pipeline and data-driven culture. You'll work with multi-discipline experts with hard-science backgrounds in a tight knit team to deliver on our efforts around data curation and management. You'll work with modern ETL frameworks to prepare data for exposure to both our internal business users and customers via BI tools, internal APIs, and custom built services. Within our team, you'll be able to further develop your skills and work with a team of experts to deliver on massive improvements to our data pipeline and associated systems. What You'll Do: Use Python and SQL to improve upon a best-in-class data pipeline and develop our workflows Contribute to cloud-first services that support our analysis, reporting, and metrics collection efforts Make high-level data architecture decisions to meet our rapidly scaling business needs Support development processes with maintenance of CI/CD pipelines Deliver on detailed specifications for business intelligence and reporting needs Work with product and engineering in cross-functional teams to deliver on iterative improvements to our systems Build end-to-end data pipelines and create software components to tie together all pipeline stages, from data extraction, to loading, transformation, and exposure to downstream systems Write custom ETL processes in Python and SQL to load data into our data warehouse (Snowflake), export data to / sync with other systems, and generate new datasets Maintain ETL software dependencies in Docker Manage configuration and access to our data-related cloud resources and data warehouse using Terraform Help to define and improve our internal standards for style, maintainability, and best practices for a high-scale data infrastructure Contribute to and further develop our data-driven culture Who You Are: MS or PhD in Computer Science, Mathematics, Statistics, Physics, Economics, or similar hard-science 3-4+ years hands-on experience in Data Engineering at growing product-driven tech companies Proficiency in AWS cloud services Advanced capabilities in Python and SQL Production experience with Airflow, Prefect, or similar workflow orchestration frameworks Experience with Snowflake or similar data warehousing technologies Basic knowledge of / experience with Linux command line environments and Bash scripting Software development background (strong familiarity with version control systems, CI/CD, testing, system design) Strong analytical and problem solving skills Nice to have: Understanding of dbt or similar data transformation frameworks Understanding of Spark Entera is proud to be an equal opportunity employer (EEO) that celebrates difference and diversity. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We are committed to building an inclusive work environment where all employees feel a sense of belonging and respect. If there is anything we can do to ensure you have a comfortable and positive interview experience, please let us know."
Data Analytics Engineer,GrayMatter,+1 locationRemote,https://www.indeed.com/rc/clk?jk=725f3cbe29df77fb&fccid=480c3acd21f04c67&vjs=3,"At GrayMatter, our goal is to transform operations and empower people. As digital transformations in every industry are underway, we partner with some of the largest companies in the world to help harness their data and use it to work smarter. After all, the industry is buzzing with talk of how to leverage the power of Big Data, the Internet of Things (IoT) and the Industrial Internet. We provide innovative, data-driven technology solutions for the industry’s most complex problems. Our customers lean on us to protect and connect their critical assets with their people, so every operator is empowered to be the best operator. And that’s where you come in. GrayMatter is dedicated to creating a team that has the best talent our industries have to offer. Our organizational cultures express a team-oriented environment, and encourages a successful future with vast learning opportunities. Our team understands that our core values are critical to our success and make our company stand above the rest. Accountability, Integrity, Respect, Innovation and Teamwork make up our DNA. Everyday, our team is doing amazing things such as: Protecting the nation’s water supply Improving US manufacturing operations Monitoring the nation’s power and oil & gas production Keeping our critical infrastructure safe from cyber attacks Can you see yourself doing this every day? Joining our team means being a part of a culture that lives by its core values. Our goal is to make a difference where it counts. GrayMatter is an Inc. 5000 Fastest Growing Private Company for 6 years in a row, an Inc. Best Workplaces recipient, as well as a Pittsburgh Technology Council Tech 50 and Pittsburgh Business Times Fast 50 award winning company We're looking for a Data Analytics Engineer with an application development and data science background! This position involves project-based customer facing work to help our clients solve their specific industry challenges through collecting and analyzing data. This position will focus on managing specialized work efficiently, with confidence and competence. The position requires above average attention to details, concern for the exact correctness of work, and strong commitment to tasks completed on time. The person in this position will take work seriously, has a strong sense of duty, and is disciplined. The position will generally be task oriented, requiring someone with a conservative, careful, and cautious approach to work. General Job Duties: Data engineering, data science, and application development based on client and project needs Data Engineering - includes (not limited to) design, implementation and testing of data storage and management models, data pipelines (ingestion, processing stages), and security. This includes both local SQL and Historian databases as well as cloud ingest strategies. Data Science - includes (not limited to) design and implementation of analytics for quality prediction, downtime prevention, energy optimization, and associated reporting and visualization. Application Development - includes (not limited to) the development and testing of Microsoft Azure resources, PowerBI, and/or React-based web applications Designing, developing and implementing solutions to resolve customer issues Consulting with and training end users on new applications Assisting in project development and planning Performing onsite pilots, testing and demos Providing technical assistance to the sales team Knowledge, Skills and Experience Needed: Bachelor’s Degree in an applicable field (Software engineering, computer science, etc.) or Associate’s Degree with 4 years’ experience. Minimum of 2 years of relevant working experience: Experience with coding languages C#, Java, Python Experience with SQL Server Experience with interfacing with REST APIs Basic knowledge of Azure cloud Experience with data pipeline design, Windows application development, and/or machine learning concepts is a plus. Excellent level of general computer technology knowledge, from gSuite and MS Office to TCP/IP configurations and more. Acute attention to detail and process Strong ability to solve problems and research solutions Excellent customer service attitude Willing and able to travel"
Data Center Civil Engineer,"Amazon Data Services, Inc.","Dublin, OH 43016+1 location",https://www.indeed.com/rc/clk?jk=4645e3d21aa806d2&fccid=fe2d21eef233e94a&vjs=3,"· Professional Engineering License, or plan for achieving licensure within 12 months of start date. · 5+ years professional experience in commercial, warehouse, and/or industrial site-civil design experience. Job summary Amazon Web Services (AWS) is seeking a Data Center Civil Engineer to join its design team in Dublin, OH. As a Data Center Civil Engineer at AWS, you will lead Civil Engineering designs for Amazon Data Centers. You will be part of a highly creative and efficient design team comprised of Architects, Engineers, and Designers tasked with solving problems and challenging the status quo. As a subject matter expert, you will have a direct impact on the design of prototypical Data Center sites, provide technical design guidance and vendor oversight, solve large-scale implementation issues, and build a strong understanding of site design and program requirements. Amazon’s Data Centers are industry leading examples of innovation in the areas of space utilization, energy efficiency, and cost effectiveness. We are known for our speed to market and reliability. This role sits within Americas Design Engineering team responsible for the design and operation of critical Data Center facilities located throughout North and South America. Our Design Team is on the forefront of creating and delivering the most innovative products to our customers; and are known for being a diverse and upbeat team that is changing the face of Cloud Computing. We continue to grow and are looking for motivated team members that can support our speed to market, raise the bar, and have a desire for professional growth and continuous learning. Amazon’s work environment is unique in every aspect and offers an exceptional opportunity for the right candidate. At Amazon we highly support continued learning opportunities and focus on continued employee development. Key job responsibilities · Manage our external civil design consultants through the Data Center design and construction process. · Review designs for site layout, grading, power substations, storm water, utilities, and pavement. · Coordinate with internal and external MEP design engineers. · Effectively communicate design standards to internal and external project partners. · Communicate conceptual designs and create/maintain project documentation before, during, and after construction. · Develop and maintain design standards, design prototypes, and template specifications related to site design for Data Centers and supporting infrastructure. · Coordinate with AWS Due Diligence and Real Estate teams to determine site selection criteria and review Due Diligence reports. · Create, review, and release design RFPs for various projects, including DCs and special program facilities. · Manage multiple fast paced projects simultaneously. Foresee and manage internal Technical Program Manager’s (TPM’s) expectation regarding project-specific cost and schedules variables. · Lead initiatives aimed at improving cost, quality, schedule, and consistency · Travel for site assessments, internal design meetings, construction review, and interfacing with authorities having jurisdiction. Anticipated travel is approximately 25%. ABET accredited BS in Civil Engineering 2+ years’ experience in civil design for Data Centers or Telecom facilities with working knowledge of land use and land development conventional practices. Ability to utilize scheduling software to depict land-use approval critical path dependency activities Knowledge of mission critical equipment and systems, design process, pre-construction requirements and the construction process Direct experience with design or construction administration of a variety of electrical distribution systems ranging from low voltage to high voltage. Proficiency in building codes, regulations, and standards including IBC and ASCE. Demonstrated ability to evaluate the design and constructability of site design by third-party consultants. Demonstrated ability to manage multiple fast paced projects simultaneously. Excellent communication skills and attention to detail. Motivated, dependable, and capable of working with some oversight. Ability to travel internationally Proficient in AutoCAD, Bluebeam, and MS Office Suite software. Professional experience demonstrating Amazon’s Leadership Principles in action. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Data Analytics Engineer,Scientific American,"New York, NY 10017 (Midtown area)",https://www.indeed.com/rc/clk?jk=26ac8e794bb1e921&fccid=d22d3aaf5cb69f00&vjs=3,"Scientific American, the longest continuously published magazine in the U.S., has been bringing its readers unique insights about developments in science and technology since 1845. Scientific American has 3.5 million print and tablet readers worldwide, more than 7.5 million visitors on ScientificAmerican.com, and appears in 13 translated editions, which are read in more than 30 countries. .sfpanel .content {padding: 0 40px !important;} Springer Nature is seeking a Data Analytics Engineer for its New York based Scientific American Team. The team develops new data products for the research community. This is an exciting opportunity for the Data Analytics Engineer, expanding from strong foundations to build new solutions and services. We are looking for someone who is able to deliver solutions and work independently, with support from the wider team where necessary. As a Data Analytics Engineer, you will be responsible for ensuring continuous flow of data with minimum latency between data sources. You will be developing, testing and deploying data pipelines into the production environment. You’ll be responsible for implementation of Google Analytics 4 server side tracking, following the existing solution that will be provided. You’ll be analyzing big data from very highly trafficked websites and content. You will provide actionable analysis and insight into the behavior of users. Driving change that improves their experience with SpingerNature and our customers, contributing to our purpose to advance discovery with some of the most interesting datasets available. You’ll be working in close partnership with data analysts, scientists and engineers and researchers from Springer Nature. You’ll be working with the latest data and analytics technologies including graph databases, Google Analytics, Google Tag Manager, BigQuery, Looker and Plotly Dash as well as previewing solutions from Google and other partners. Role responsibilities will include: Build streaming/batch Data pipelines for extraction/loading/transforming data between various data sources at scale in different formats. Work closely with Data Scientists /Analysts to understand the requirements and develop the data solutions in line with the business requirements. Maintain the current cloud infrastructure and help onboard the new applications. Developing sophisticated segmentation, analysis and dashboards that support Springer Nature and its customers to advance discovery. Implementing cutting edge analytics and data science solutions in partnership with the wider teams Consulting with stakeholders throughout the business to shape and implement solutions in support of business objectives. Play a key role in shaping solutions, creating the right governance and safety checks to maintain tracking accuracy. Role requirements: BA degree with a strong analytical/quantitative background Minimum of 3 - 4 years experience in the field or equivalent experience (e.g. Data Science, Statistics, Mathematics, Econometrics, Physics, Computer Science etc.) Strong working knowledge of SQL, Google Analytics, Google Tag Manager and Python Excellent problem solving capabilities Knowledge of Machine Learning concepts is beneficial but not essential as training will be provided Prior experience with schema designing data modeling Familiarity with Google Cloud products (BigQuery, Colab, Data Studio, Looker, Dataform, Google Analytics) or other cloud data platforms is beneficial but not essential Well organized and accurate with good time management If you are an internal candidate please inform your line manager. We offer a comprehensive benefits package that includes: Medical, Dental and Vision Life and AD&D 401(k) Flexible Spending Accounts Transit Accounts Tuition Assistance Summer Hours Springer Nature is an Equal Opportunity Employer that complies with the laws and regulations set forth in the following “Equal Employment Opportunity Is The Law” poster: http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf. For information about our Research Editorial and Publishing career opportunities please visit the new Springer Nature E&P website at www.springernature.com/editorial-and-publishing-jobs. Springer Nature is a leading global research, educational and professional publisher, home to an array of respected and trusted brands providing quality content through a range of innovative products and services. Springer Nature is the world’s largest academic book publisher, publisher of the world’s highest impact journals and a pioneer in the field of open research. The company numbers almost 13,000 staff in over 50 countries and has a turnover of approximately EUR 1.5 billion. Springer Nature was formed in 2015 through the merger of Nature Publishing Group, Palgrave Macmillan, Macmillan Education and Springer Science+Business Media. At Springer Nature we value the diversity of our teams. We recognize the many benefits of a diverse workforce with equitable opportunities for everyone. We strive for an inclusive workplace that empowers all our colleagues to thrive. Our search for the best talent fully encompasses and embraces these values and principles."
Data Engineer,Zonar Systems,"Tukwila, WA",https://www.indeed.com/rc/clk?jk=dfa4974660167cd9&fccid=3d51e7e4c3c6759e&vjs=3,"One of Seattle’s top technology companies, Zonar Systems is seeking a highly capable Data Engineer. As part of the Zonar Business Technology organization, the IT Data Engineer is primarily responsible for owning, maintaining, and optimizing our SQL-based Zonar data warehouse platform and related operational functions. This platform aggregates data associated with Zonar business operations and related data sets and is utilized by numerous departments across Zonar Systems for internal decision support and to deliver customer-facing reporting and analysis. This position will own the data warehouse architecture, databases both cloud and on prem, SQL table structures, and related stored procedures. This position will also directly contribute to the support and monitoring of related data processing routines and operations of the related technology stack. This role also supports the broader data footprint managed within our Business Technology group and works closely with the Data Analytics team in providing data mining and data analysis support for requests from the business as well and other initiatives. The person who fills this role will also be the driving force to help ensure ongoing data integrity of our datasets and identify, develop, and support related data integrity monitoring solutions. . WHAT YOU WILL DO Develops and maintains scalable data pipeline architecture and datasets of varying size and complexity. Maintains and provides oversight on data warehouse structure, processes, and related operations. Implements and maintains processes and systems to monitor data quality, timeliness, and availability of data within the Zonar Data Warehouse. Collaborates with Analytics, the broader Business Technology organization, and other business teams to improve data models that feed the data warehouse and related business intelligence tools. Contributes to identification and owns deployment of database schema changes and related table updates specific to the Zonar data warehouse and other databases managed within Business Technology. Supports and monitors data processing and delivery mechanisms to ensure data/reports are available within our Power BI and SSRS platforms. Identifies on-going optimization opportunities relating to database infrastructure and database design that supports scalability and supportability. Identifies and recommends enhanced data collection procedures that support data integrity and relevancy of data sets. Builds and maintains SSIS packages as needed. Monitors data warehouse operations across our DEV, TEST, and PROD server stack Develops and operationalizes related data standards, quality, and security/access across assigned data sets. Assesses the quality and impact of new data sources and data gathering techniques. ADDITIONAL RESPONSIBILITIES AND DUTIES Works with team members or stakeholders to assist with data-related technical issues Collaborates and consults with the Data Analytics team and other internal teams in support of ad-hoc analysis efforts or requests. Follows all company policies and procedures Upholds Zonar’s Quality Policy and Objectives Performs all other duties as required Overtime as required WHAT YOU WILL BRING TO THE TEAM Excellent written and verbal communication skills. Can effectively communicate ideas and results in narrative form Ability to perform root cause analysis on internal and external datasets and processes to answer specific business questions and identify opportunities for improvement. Ability to identify and recommend operational improvements to data collection routines. Ability to design, build, and maintain operational databases Ability to build and maintain ETL routines that process data from source systems such as CRM, ERP, or like business systems (both on-prem and cloud-based solutions) Ability to effectively build/present analysis using data visualization tools such as PowerBI, Tableau, or like tools. Ability to triage/troubleshoot data storage systems or related technical platform issues Ability to leverage tools such as R, Python, and SQL to import, process, summarize, and analyze data. Ability to understand various data structures and common methods in data transformation Ability to apply a strong business sense and logic skills to balance data-driven decisions with intuition Ability to operate independently, manage competing priorities, multi-task, and resolve conflicts Ability to manage complex datasets, including querying, aggregation, analysis, and visualization Knowledge of machine learning techniques and algorithms Bachelor’s degree in a quantitative field, such as Computer Science, Statistics, or Applied Mathematics or combination of professional certification (e.g., Google Certified Professional-Data-Engineer certification or like certification) and 5+ years related experience WHAT SETS YOU APART 5+ years of data engineering experience 3+ years of data or business analysis experience preferably within in a technology focused company Advanced knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Hands-on experience with SQL database architecture and design. Experience with data transfer and connectivity tools such as cData, Kingswaysoft or like ETL/ELT tools Experience with scripting languages such as Python or Java required Experience with statistical computing solutions such as R or like solutions required Experience with various machine learning/statistical modeling data analysis tools and techniques a plus ABOUT US Founded in 2001—and acquired by Continental AG in 2016—Zonar has pioneered smart fleet management solutions throughout pupil, commercial construction, mass transit and over-the-road trucking industries. Zonar’s mission is to enhance the safety, performance, and success of our customers by transforming the delivery of innovative insights for commercial fleets around the world. Zonar achieves this by helping fleets of all sizes maximize the use of their assets with solutions dedicated to improving compliance, efficiency, maintenance, ridership visibility, safety, and tracking. Cloud-based services with open APIs drive Zonar's smart fleet solutions by making it easy for fleet owners and managers to stay connected to their fleets and drivers and operators to dispatch. Headquartered in Seattle and part of the Continental family, Zonar also has a Technology Development Center in downtown Seattle and a distribution center outside of Atlanta."
Data Engineer,Home Depot / THD,"Atlanta, GA 30301+1 location",https://www.indeed.com/rc/clk?jk=42d88b979108f58b&fccid=82e58e9861d48566&vjs=3,"Position Purpose: Data Engineer map source system data to warehouse models. In addition, develop and test ETL processes, define and capture metadata and rules associated with ETL processes, adapt ETL processes to accommodate changes in source systems and new business user requirements and to demonstrate work ethic that motivates and encourages others on their team. BI Data Engineers are encouraged to bring fresh ideas, new perspectives, and an eagerness to learn new technologies. Responsible for the scripts required to extract, transform, clean, and move data and metadata so they can be loaded into the appropriate data mart. Map source system data to data mart models. Experience with column-oriented databases (e.g, Big Query). Creating views in BQ Work with business requirements to identify and understand source data systems. Helping with solution design and architecture. Major Tasks, Responsibilities and Key Accountabilities 20%- Implement a real time streaming data ingestion and processing pipeline using Google Data flow (Apache Beam) 20%- Interface with business intelligence analysts and others in IT (i.e. data engineers, architects, WebOps) in frequent whiteboard sessions to discuss the design, implementation, and testing of data pipelines 20%- Maintain data architecture standards and ETL/ELT best practices consistent with a column oriented data store in an analytic use case 20%- Active and engaged participation in the Scrum delivery process 20%- Support solutions in production Nature and Scope Position Reports to Manager This position has 0 direct reports Environmental Job Requirements Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable. Minimum Qualifications Must be eighteen years of age or older. Must be legally permitted to work in the United States. Education Required - The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job. Years of Relevant Work Experience - 3 years Certificates/Licenses - Physical Job Requirements - Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles. Additional Qualifications - Preferred Qualifications Familiarity with Agile methodologies Experience with data warehousing and dimensional modeling Experience in building real time streaming data ingestion and processing pipeline Experience with data processing tools (e.g. Hadoop, Spark, Data flow, etc.) Experience building ETL/ELT pipelines Experience with column-oriented databases (e.g Redhift, Big Query, Vertica) Ability to effectively communicate with technical and non-technical audiences Strong programming ability Success in a highly dynamic environment and ability to shift priorities with agility Ability to act independently with minimal supervision Willingness to explore and implement new ideas and technologies Experience working directly with subject matter experts in both business and technology domains Experience with data science technologies (optional) Familiarity with Contact Center Data Management Knowledge of Python or equivalent programming languages and ETL products This information indicates the general nature and level of work performed by associates in this role. It is not designed to contain a comprehensive inventory of all duties, responsibilities, and qualifications required of associates assigned to this role. This description super cedes any previous or undated descriptions for this role. Management has the right to add or change the duties of the position at any time."
Principal Data Engineer,Noodle,"Remote in Tulsa, OK 74114+14 locations",https://www.indeed.com/rc/clk?jk=fbd71192aeb84429&fccid=2fa3aafd0cd164bc&vjs=3,"Principal Data Engineer Online education is no longer a novel or niche idea. It is the fastest-growing segment in higher education, accounting for 20% of all enrollees and 35% of graduate-level certificates and degrees. It's also getting increasingly competitive, as more and better programs are launched each semester. Universities need to go online quickly, economically, and elegantly, creating programs that students can't wait to tell their friends about and that their professors want to teach. Noodle helps universities bring programs online with flexibility, transparency, alignment, efficiency, and joy. That's why more top universities chose us last year than all other online program managers combined. We are a passionate team of technologists, educators, and experts. Online learning has the potential to transform higher education; if you’re interested in being part of that journey, keep reading! Reports to: Chief Technology Officer (Russ Tarafdar) As our Principal Data Engineer you will: Directly train and manage junior engineers, assisting with day to day duties as needed as well as providing mentorship and career development advice. Define organization-level engineering policies. Develop programs and resources to promote engineering best practices, improve team cohesiveness, and increase the engineering team’s visibility within the company Make key technology decisions and provide implementation and improvement recommendations to team leads and engineers. Independently audit and develop initiatives to address deficiencies in Noodle’s technology products and processes Lead development of core engineering software products Mentor junior engineers, assisting with day to day duties as needed as well as providing technical and career development advice. Work to improve overall software quality by implementing and leading code review, automated testing, continuous integration, and other QA best practices. Assist in high level technology design and project planning. You have: At least 10+ years Python development experience Strong experience with Python data analysis libraries (such as pandas, numpy) Strong relational database and SQL skills Experience with AWS AppSync Experience in agile software development methodologies and best practices At least 4 years experience working with AWS technologies Preferred additional qualifications: Familiarity with Apache Airflow or similar scheduling tools Experience with AWS Appsync Working with various IDP and Okta integration Experience managing infrastructure as code using AWS CDK or similar tools Automated testing and data quality assurance experience At Noodle, we hire people who will help us change the future of online education. Even if you don't think you check off every bullet point on this list, we still encourage you to apply! We value both current experience and future potential. Meet the team! Noodle Benefits: Work from our beautiful NYC office! OR Work from the comfort of your home office! Great compensation package! 401K + match, bonus potential, and equity opportunities Tools you need on us! Mac is our computer of choice Our insurance plan offers medical, dental, vision, short- and long-term disability coverage, plus supplementals for all employees and dependents 12 weeks paid Parental Leave Pre-tax commuter benefits 3 weeks paid vacation + 10 paid holidays + paid sick leave Monthly Gym stipend and Membership to premium medical services like Eden Health Monthly mobile connectivity stipend Access to mental health services like Ginger and Talkspace Annual education stipend for lifelong learning Growth - we pride ourselves on creating environments where employees can be themselves and grow within and around the company Noodle is committed to creating a welcoming and inclusive workplace for everyone. We value and celebrate our differences because those differences are what make our team shine. We hire great people from different backgrounds, not just because it's the right thing to do, but because it makes us stronger as a whole. Women, people of color, LGBTQIA2S+ individuals, and members of other underrepresented groups are strongly encouraged to apply. Noodle is an equal opportunity employer and does not discriminate against candidates on the basis of race, ethnicity, religion, sex, gender, sexual orientation, gender identity, disability status, or veteran status. Noodle won Built In NYC’s 100 Best Places to Work, Best Midsize Companies, and Best Perks & Benefits 2021, and 2022 and was named one of Crain’s 100 best places to work in NYC in 2021. #LI-Remote"
Sr. Software Engineer – Data Warehousing,Nike,"Beaverton, OR",https://www.indeed.com/rc/clk?jk=4e086222d06eae2a&fccid=2c62e4de04b8f952&vjs=3,"Become a Part of the NIKE, Inc. Team NIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game. NIKE is a technology company. From our flagship website and five-star mobile apps to developing products, managing big data and providing leading edge engineering and systems support, our teams at NIKE Global Technology exist to revolutionize the future at the confluence of tech and sport. We invest and develop advances in technology and employ the most creative people in the world, and then give them the support to constantly innovate, iterate and serve consumers more directly and personally. Our teams are innovative, diverse, multidisciplinary and collaborative, taking technology into the future and bringing the world with it. We’re passionate about Nike and all the Swoosh represents: limitless drive, innovation, creativity, and possibilities for collaboration. We focus relentlessly on talent and are always looking for ways to encourage growth. We are inspired by the Nike legends who built an empire rethinking product and service, and we seek to bring that level of innovation to our technologies. Our vision is to build and deliver extraordinary Enterprise Platforms, services, and products directly to athletes* around the world. If you have a body, you’re an athlete. Who we are looking for We’re hiring a Senior Software Engineer with talent and persistence who can demonstrate their existing skills and learn new ones. You should have extensive experience in many of the specific technical skills we’re looking for and be expert enough to help ramp up others quickly. We are building and supporting petabyte-class solutions that consume fast moving streams from eCommerce, retail, and partner channels to power the critical decisions that drive our business. As a Sr. Software Engineer, you will be a key part of Nike’s Digital Transformation initiative through Nike’s Data Technology Foundation capabilities helping deliver efficient and reliable data discovery, data access, data warehousing and advanced computing platforms. Our capabilities look to simplify customer experiences while driving enhanced compliance and reduced risk. What you will be working on Be a great teammate on an agile/SCRUM team that sets and meets aggressive goals Provide thorough customer engagement for escalated issues and business use cases Leverage expert development skills and solid design skills to deliver reliable, scalable, performant solutions with modern tooling, data structures and algorithms Who you will be working with Partner with Product Owners, Engineering Managers and Principal Engineers to deliver solutions that enable Nike's digital transformation Your peer team of Software Engineers on a myriad of topics and projects Mentor new and less experienced developers to advance their proficiency What you bring Bachelor’s degree or higher in related field or relevant combination of education, experience and training 5+ years’ developing software systems that operate at scale 3+ years’ experience with RDBMS systems 2+ years’ developing software solutions w/ Python 2+ years’ developing Platforms on a commercial cloud 2+ years with modern CI/CD pipeline patterns (Git) In depth experience with AWS technologies Ideal technical skills (you should have experience with several of the following): Experience integrating COTS and open source to create petabyte scale solutions RDBMS Snowflake / Teradata Python Amazon AWS / S3 / Linux / IAAS Airflow Okta / IAM integration / Unified Access Tableau / Cognos / DOMO Apache Ranger / Privacera Starburst Autosys Terraform Distributed systems Nike requires all applicants for this position to be vaccinated for COVID-19 as a condition of hire, unless otherwise required by law. As an equal opportunity employer, Nike will make accommodations to individuals who cannot be vaccinated in accordance with applicable law. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world. NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability."
Data Engineer #1222,MeridianLink,Remote in United States,https://www.indeed.com/rc/clk?jk=4f8d6e383fc52316&fccid=4d9f2f5d89f22011&vjs=3,"Data Engineer UNITED STATES / RESEARCH & DEVELOPMENT – 810 - DEVELOPERS / FULL-TIME APPLY FOR THIS JOB Data Engineer JOB SUMMARY We are looking for an accomplished Data Engineer to join our quickly growing Analytics team. The hire will be responsible for expanding and improving our data and data pipeline architecture, as well as optimizing data flow and MDM for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data pipelines to support our next generation of products and data initiatives. RESPONSIBILITIES Design, develop, and operate large scale data pipelines to support internal and external consumers Improve and automate internal processes Integrate data sources to meet business requirements Write robust, maintainable, well documented code QUALIFICATIONS 4+ years professional Data Engineering and Data warehousing experience Extremely strong implementation experience in Python, Spark, Azure Databricks, Delta Lake, and Databricks Data Warehouse. SQL development knowledge – Stored procedures, triggers, jobs, indexes, partitioning etc. Be able to write/debug complex SQL queries Azure Data factory ETL/ELT and Data-warehousing techniques and best practices Experience with MS-SQL server and Databricks Data warehouse. Knowledge of being able to work with a variety of Ingestion patterns such as API/SQL servers etc. Experience with cloud infrastructure (Azure strongly preferred) Implementation experience with various data modelling techniques Implementation experience working with a BI visualization tool (Sisense is a plus) Experience with CI/CD tools (Preferred Gitlab, Jenkins) Pluses for experience with UI development frameworks such as java script, Django, REACT etc. Experience working in a fast-paced product environment, with an attitude of getting the job done with the least amount of tech debt Prior Financial industry experience a plus. Be able to navigate ambiguity and pivot based on business priorities with ease. Strong communication, negotiating and estimating skills. MeridianLink has a wonderful culture where people value the work they do and appreciate each other for their contributions. We develop our employees so they can grow professionally by preferring to promote from within. We have an open door policy with direct access to executives; we want to hear your ideas and what you think. Our company believes that to be productive in the long term, we must have a genuine work-life balance. We understand that employees have families and full lives outside of the office. To that end, we honor their personal commitments. MeridianLink is an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, sex, age, national origin, disability or any other characteristic protected by applicable law. MeridianLink runs a comprehensive background check, credit check and drug test as part of our offer process. #LI-REMOTE"
Principal Clinical Data Engineer - SQL Required,Parexel,United States,https://www.indeed.com/rc/clk?jk=f9dd44b6b0f1aeea&fccid=a2ce486f2a6b8708&vjs=3,"Parexel is looking for a Principal Clinical Data Engineer to join us! We are looking to extend our Clinical Data Engineer group in US. The Principal Clinical Data Engineer will be recognized as a subject matter expert, providing technical support and expert advice to internal and external sponsors. In addition, the Principal Data Engineer will fill the lead role on projects; liaise with sponsors, Data Management Leads and other functional areas as required. The ideal candidate will have experience working with SAS, SQL and supporting a Data Management organization to develop reports or dashboards for data cleaning purposes. The candidate should be progressive and adapt to and lead a new Data Management Workbench platform. The candidate is expected to utilize their SQL and BI skills to cleanse data. Qualifications Qualifications: Bachelor’s degree (or equivalent) in a relevant science discipline is preferred or equivalent work experience. Experience and expertise in SAS Programming Experience and expertise in SQL EEO Disclaimer Parexel is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to legally protected status, which in the US includes race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status."
Data Engineer (remote),LinQuest Corporation,"Remote in Beavercreek, OH 45431",https://www.indeed.com/rc/clk?jk=ec4d965c84237b16&fccid=a9f4c88b2ec65781&vjs=3,"LinQuest is seeking a Data Engineer to join our team. This position can be remote but candidates near Dayton, OH, are preferred. US Citizenship and the ability to obtain a DoD Secret security clearance is required. As a Data Engineer, you will have the opportunity to work with unstructured and structured data, develop databases, build data pipelines, and find innovative solutions to complex data problems. Candidates must be comfortable across the spectrum of data management functions ranging from data modeling, database design and development, ETL/ELT design and development, as well as familiarity with metadata management, data quality, and data management techniques. Efforts will include frameworks to support data discovery, data science, and analytics. Expected to possess a strong work ethic and solid leadership skills. Required Skills: Strong analytical and problem-solving skills with hands on experience working with databases. Must have the ability and motivation to self-teach in order to stay current with leading best practices in the database industry. Candidates must be able to tackle difficult problems but be willing to seek help and guidance when needed. Expected to understand data modeling techniques and best practices, have strong SQL programming skills and have a good understanding of data design and development best practices. Candidates should have a strong understanding of data stores to support search, applications, and data science. Must be able to tackle difficult problems specifically working with unstructured textual data. Expected to have data exploration, analysis and wrangling skills. Applicants must have the ability to quickly learn new software applications, open source, and COTS products across a wide spectrum of database disciplines and possess a working knowledge of, including but not limited to, the following concepts: Data Management Functions Data and Agile Modeling Data Wrangling/Extract, Transform, and Load (ETL/ELT) Data Architectures Data Pipelines Data Discovery & Search Required Experience: Bachelor’s Degree in computer science, engineering, or related field At least 3 years of professional experience translating complex data requirements into well designed solutions Experience working with both structured and unstructured databases Experience manipulating data with Python Experience with Agile A Secret Clearance, or US Citizenship and the ability to obtain a Secret clearance Benefits: LinQuest offers comprehensive and competitive benefit offerings to our team members to include medical, dental, vision, retirement, paid time off, company paid life insurance, and more! For additional information please visit: https://www.linquest.com/careers/our-benefits COVID-19 Compliance Guidelines: As a federal contractor, all LinQuest team members may be required to comply with Executive Order 14042- Ensuring Adequate COVID Safety Protocols for Federal Contractors, which may include mandatory vaccination and ability to provide proof of vaccination status prior to start of employment. Additionally, team members are expected to comply with all safety protocols related to mask wearing and physical distancing while in covered contractor workplaces. If applicable, prospective or new employees may seek an exemption to the vaccination requirement through LinQuest Human Resources and must have an approved exemption prior to the start of their employment. Education Required Bachelors or better in Computer Science or related field Licenses & Certifications Required Ability to Obtain Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Center Safety Engineer,"Amazon Data Services, Inc.","Santa Clara, CA 94085",https://www.indeed.com/rc/clk?jk=74833a6a62306083&fccid=fe2d21eef233e94a&vjs=3,"Minimum four year college degree in a health and safety, physical science, or related field. 3 or more years of field health and safety experience in general industry or construction. 1 or more years of experience designing, revising, and implementing health and safety processes and procedural documentation. Job summary Overview: Join the world class safety culture at Amazon Web Services (AWS) and be part of supporting the largest cloud computing infrastructure team as a Regional Safety Engineer. As the Regional Safety Engineer you will own the Health and Safety function of your respective area. You will be responsible for improving the health and safety of our data centers, advancing safety culture, and protecting our employees. Each day you will work with our data center engineers, the people who make the cloud go. They are working with electrical switching equipment, large scale air handling mechanical systems, and critical IT gear. You will work closely with experts in security, construction, operations, logistics, compliance, corporate counsel, and human resources to further the global health safety program. You will partner with employees as well as contractors to achieve health and safety goals and improve our already strong safety culture. As AWS increases data capacity you will partner with construction managers to ensure risks are identified and mitigated prior to live operations. You will work in a fast-paced environment where our operations are rapidly changing, advocating safe changes in the face of new infrastructure, new tools, and new products/processes. Responsibilities: Implement health and safety standards, policies and practices including but not limited to; safety management systems, training, risk assessments, assist with industrial hygiene assessments, and applicable safety regulations. Conduct health and safety audits of data centers and active construction sites to ensure compliance with health and safety requirements as well as life safety requirements Ensure compliance and implementation of global health and safety programs that exceed regulatory requirements. Develop health and safety plans for on-site emergencies, business continuity, and other unique events. Maintain adequate safety record keeping and data integrity. Perform data trend analysis to present to cluster leadership to support business and safety initiatives. Consult and partner with the AWS compliance team for interpretations and guidance. Identify risks and partner with Operations to remediate via the hierarchy of controls. Daily interactions with our customers delivering health and safety guidance. Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. Experience supporting technical groups such as IT, Engineering, and Operations. Experience supporting physical plant operations including electrical and mechanical systems CSP or CIH certification. Working knowledge of the NFPA70E Standard and experience providing safety guidance for those working on medium voltage electrical systems. Experience with detailed hazard recognition and preparation of written assessments/proactive remedies. Knowledge of applicable region specific federal, state, and local health and safety regulations (OSHA and NFPA standards). High ethical standards with proven ability to handle highly confidential and sensitive information; excellent judgment, discretion and diplomacy. Self-directed and driven to deliver with quality. Excellent written and verbal communication skills, including presenting information to leadership within AWS. Excellent problem solving skills; self driven to develop quick, scrappy control measures. Strong proficiency in Microsoft Word, Excel, Outlook and aptitude for learning additional software tools. Ability to develop and implement department goals and strategies. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Data Engineer,Dremio,"Remote in Santa Clara, CA",https://www.indeed.com/rc/clk?jk=e66bda1888a0921c&fccid=93b8410ffb6f1701&vjs=3,"Be Part of Building the Future Dremio is the SQL Lakehouse company, enabling companies to leverage open data architectures. Dremio's SQL Lakehouse Platform simplifies data engineering and eliminates the need to copy and move data to proprietary data warehouses or create cubes, aggregation tables and BI extracts, providing flexibility and control for data architects and data engineers, and self-service for data consumers. Founded in 2015, Dremio is headquartered in Santa Clara, CA. Investors include Cisco Investments, Insight Partners, Lightspeed Venture Partners, Norwest Venture Partners, Redpoint Ventures, and Sapphire Ventures. For more information, visit www.dremio.com. Connect with Dremio on GitHub, LinkedIn, Twitter, and Facebook. If you, like us, say ""bring it on"" to exciting challenges that really do change the world, we have endless opportunities where you can make your mark. About the role Dremio's development leaders ensure that Dremio Cloud & our Data Lake value-add for the industry is enhanced with scalable, resilient solutions with uptime & performance that matches SLAs. Dremio is growing quickly and building cloud infrastructure, SaaS & services that enable developer velocity will have an immediate and visible impact on Dremio's success. You will be enabling data-driven decision making and customer engagement by creating a self-service semantic layer for the product and sales teams to leverage. What you'll be doing Creating and maintaining a data lake of customer and product usage metrics, which will be used to derive insights to drive product and growth strategies. Design and implement workflows for ingestion and transformation for various data sources (S3, GCS, Google Analytics). Optimize the retrieval of structured and unstructured data to make it actionable in real time. Help develop a strategy for a long term data architecture, which will allow Dremio to make effective data-driven decisions to optimize the customer's experience. Develop and maintain scalable and reliable data pipelines to support gradual increases in data volume and complexity. Collaborate with the Product Management and Engineering teams to incorporate new use cases and sources of data What we're looking for 5+ years of experience as a data engineer in a SaaS environment Strong logical and analytical skills Deep understanding of data lakes and relational databases Knowledge of data formats such as JSON and Parquet Experience with Apache Spark, Python libraries such as Pandas for data manipulation Experience with AWS and GCP Experience with ETL/ELT tools Experience working with data projects and ensuring the highest levels of data integrity and quality. You can scope, schedule, and resource complex projects in collaboration with other partners such as Product and Engineering. Experience working with CI/CD pipelines, DevOps and delivering quality in a fast paced environment. Familiarity with BI and data science tools such as Tableau, Superset, Jupyter. Excellent communication skills with both technical and non-technical audiences. Bonus points if you have Experience with Apache Iceberg What we offer Medical, dental and vision insurance 401(k) Plan Short term / long term disability and life insurance Pre-IPO stock options Flexible PTO 16 hours of volunteer time off 12 company paid holidays, including Juneteenth Remote work options Monthly ""Get Stuff Done"" (GSD) Days Paid parental leave Employee Assistance Program (EAP) Company-sponsored wellness programs including Aaptiv, Headspace, Physera and Ginger Quarterly swag surprise **Certain benefits are only allowed to full-time Dremio employees and may not be the same across all locations. #LI-KL1 #LI-Remote What we value At Dremio, we hold ourselves to high standards when it comes to People, Thinking, and Action. Our Gnarlies (that's what we call our employees) communicate with clarity, drive accountability, and are respectful towards each other. We confront brutal facts and focus on results while operating with a sense of urgency and building a ""flywheel"". People who like to jump in and drive momentum will thrive in our #GnarlyLife. Dremio is an equal opportunity employer supporting workforce diversity. We do not discriminate on the basis of race, religion, color, national origin, gender identity, sexual orientation, age, marital status, protected veteran status, disability status, or any other unlawful factor. Dremio is committed to providing any necessary accommodations for individuals with disabilities within our application and interview process. To request accommodation due to a disability, please inform your recruiter. Dremio has policies in place to protect the personal information that employees and applicants disclose to us. Please click here to review the privacy notice."
Data Engineer,Kodeva,"San Jose, CA",https://www.indeed.com/rc/clk?jk=b3e347f47d9e17f8&fccid=32d71ee27593fcf4&vjs=3,"Location: San Jose CA Duration: 12 Months Job Description : Profile should have more than 8years of experience Hands on experience in designing and executing projects on Google Cloud Platform features like App Engine, Compute, storage, Big Query, Data Proc, Data Flow. Strong Programming Skills in R, Python or Spark. Strong Knowledge on Data Engineering, Simulation and Modelling concepts Proficiency in handling the billions of structured or unstructured transactional data. Proficiency in modeling techniques such linear regression, logistic regression, GLM Knowledge on machine learning techniques such as Decision Trees, xgboost, random forest, PCA etc. Knowledge on unsupervised Machine learning techniques such as Clustering, Segmentation Strong knowledge on Data Manipulation and transformation Knowledge on data loading to GCP services like big query, cloud storage. Knowledge in Hadoop, HIVE and Pig languages. Good communication skills."
Data Engineer,Brave,"Remote in San Francisco, CA",https://www.indeed.com/rc/clk?jk=fc573e4b221c34f0&fccid=9e961d35e88738f2&vjs=3,"Data Engineer About Brave Brave is on a mission to protect the human right to privacy online. We've built a free web browser that blocks creepy ads and trackers by default, a private search engine with a truly independent index, a browser-native crypto wallet, and a private ad network (opt-in!) that directly rewards you for your attention. And we're just getting started. Already 50 million people have switched to Brave for a faster, more private web. Millions more switch every month. The internet is a sea of ads, hackers, and echo chambers. Big Tech makes huge profits off our data, and tells us what's true and what's not. Brave is fighting back. Join us! Summary Brave Ads is Brave's global private ad network, redesigned from the ground up to reward users while enforcing the highest standards of user privacy. The Brave Ads team works to ensure that marketers, both large and small, receive the information they need to make the most of their campaign dollars, without sacrificing strict user privacy. We are looking for a great data engineer who can help us maintain and improve our growing data pipeline, and help create additional data products and cubes that can drive the business forward. Requirements Experience with Python or similar language Experience with SQL, Postgres, and building analytics queries Experience with complex data flow/analytics infrastructure, e.g. Kakfa, Kinesis, Redshift and large scale data problems Experience with OLAP and data visualization Comfortable working in an open source setting A passion for helping protect users' privacy and security Written and verbal communication skills in English Proven record of getting things done Nice to haves Experience with ad-tech / marketing tech ecosystem Working at Brave Industry-leader in privacy, with a research and engineering team that's innovating everyday to keep people safer online and beat Big Tech Highly competitive salaries & benefits, and generous home-office stipends Fully remote team (no office, no commute) Welcoming, humble, ridiculously smart teammates, and a truly flat org structure Opportunity to get in early at a hyper-growth company, and revolutionize the web Oh, and did we mention Brendan, our CEO & co-founder, invented JavaScript? Check us out LinkedIn | Glassdoor | brave.com"
"Data Engineer - Redwood City, CA",MOLOCO,"Redwood City, CA 94063 (Middlefield area)+1 location",https://www.indeed.com/rc/clk?jk=e4b66e2aad9ce464&fccid=27317bcae2b26fe5&vjs=3,"About MOLOCO Moloco is a machine learning company that enables businesses to unleash the power of their own data for fast, sustainable growth and performance through the advertising ecosystem. Our technology is best-in-class as we received the SMARTIES X silver award for Machine Learning and AI and were named the Cross-Industry Winner for Google Cloud Customer Awards. Moloco is in hyper-growth mode, ranked #91 among Deloitte's 2021 Fast 500, and recently certified by 91% of the company via Great Places to Work. There isn't a better time to join this innovative team in our Silicon Valley HQ or our offices in San Francisco, Seattle, London, Seoul, Singapore, China, and Tokyo. About the Data Team We are seeking exceptional Software Engineers to join us in building a state-of-the-art mobile advertising platform. We understand the value of a strong engineering team and strive to hire only the best software engineers. While tackling challenging real-world problems, you will make a positive impact on millions of mobile users in the world and grow with top-notch colleagues. Check out our case study published by Google. We use various Google Cloud Products, including Bigtable, BigQuery, and Dataflow to manage big data. MOLOCO was featured as a customer example in the Data and Analytics Platform Overview at GCP Next'18. You can check out this video for more details about the company and the product (note that the presentation took place in July 2018, and we've grown & improved so much over the past two years!). What you'll do Turn unstructured logs, messages, and events into structured data that can be utilized for analytics, machine learning, and more. Implement backend data pipelines for manipulating and managing big data. Optimize data processing pipelines with different goals including latency, cost, and throughput. Improve existing data pipelines in terms of scalability and efficiency. Design and implement fraud prevention/detection algorithms through analyzing complex time-series data. Collaborate with other engineers at MOLOCO to build the best mobile advertising platform in the world. What you'll need to succeed BS in Computer Science or related fields (MS preferred) 2+ years of hands-on industry experience in software development. Excellent software development skills and fluency in at least one programming language (preferably Java, Go, or Python). Outstanding problem-solving skills. Fluent in English (both verbal and written). Experience in Cloud/Big Data platforms (e.g., AWS, GCE, Beam, Spark, etc.) preferred. Experience in distributed computing/MapReduce strongly preferred. All offers of employment are subject to background checks prior to start date. MOLOCO will consider for employment: qualified applicants with criminal histories in manner consistent with applicable local, state, and federal laws and Fair Chance Ordinances. MOLOCO is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics."
Senior Mechanical Engineer Data Centers,McKinstry,"Remote in Seattle, WA",https://www.indeed.com/rc/clk?jk=875e163055015223&fccid=69b64ba4e5c499e7&vjs=3,"At McKinstry, we’re proud to be a diverse and passionate group of innovators and problem-solvers, builders and engineers, mentors and students. We believe the world needs curious, forward-thinking, solutions-oriented people who want to make our planet better. We are committed to strengthening our diversity through recruiting, developing, and retaining professionals from all backgrounds, and we believe that promoting diversity, equity, and inclusivity is an integral component of our continuing quest To Build a Thriving Planet. If you are looking to leave a purposeful mark on the world, then McKinstry is the place for you. Here's where you come in: We are currently seeking a Senior Mechanical Engineer to join our team as a member of our growing Engineering and Design division located in Seattle, Washington. Engineers at McKinstry are unsurpassed in their ability to combine innovative problem solving with common sense design applications. Because of our design, build, operate, and maintain (DBOM) process, McKinstry engineers concern themselves not just with the construction of a building, but how it will operate over its entire lifetime. Every design choice is made toward one goal – delivering high performance buildings that ensure occupant comfort and safety, keep energy/operating costs low, maximize client profitability, and protect the environment. You're great at: Department and Team Management Delegates and manages project engineering staff. Coordinates with internal design and construction teams. Identifies resource needs to meet project deadlines. Supervises, trains, and mentors project and lead engineers. Conducts quarterly goal plan reviews. Exercises global decision making by considering other departments within the company such as project management, sales and estimating, accounting, purchasing, etc. Project Management Documents project correspondence, issues, decisions and directions. Applies and coaches McKinstry Engineering standards and procedures. Provides engineering analysis to support sales and early design efforts. Defines, communicates, and manages scope, design intent, and design process for direct supervisor review. Identifies and responds to changes in scope, schedule, budget, or expectations. Demonstrates understanding of overall project objectives and employs creative problem solving to achieve objectives within budget and resources. Prepares, negotiates, and manages design budget and coordinates invoicing. Coordinates with construction and estimating teams to reduce project costs. Coordinates with external clients and stakeholders. Design Demonstrated mastery and able to fully lead a team in delivering mechanical systems design, including calculations, airside systems, piping systems, equipment selection and multi-discipline coordination. Overall responsible for delivering designs to customers by reviewing and providing feedback on engineering calculations and design drawings for design intent, quality, precision, constructability, and construction costs. Guides coordination with internal and external team members. Identifies opportunities for process and technology improvements. Investigates, evaluates, and troubleshoots existing systems. Drives system selection, energy modeling, green building certification, and preconstruction collaboration. Presents options and facilitates decisions for design direction, system selection, energy conservation, and cost savings strategies. Serves as Engineer of Record (Stamping Engineer). Customer Relations Attends early meetings with external customers and stakeholders. Represents McKinstry in the community and develops new potential work. Enhances department and company reputation by generating opportunities to demonstrate leadership in industry and/or regulatory groups, or the public forum Develops and maintains relationships with customers and upper management. What we would like to see from you: Bachelor’s degree in engineering required or equivalent work experience required. P.E. registration is required. Twelve (12) years of experience in mechanical design, engineering or related field preferred. Advanced knowledge of Microsoft Office Suite and Microsoft Teams. Working knowledge of AutoCAD and Revit required. Working knowledge of whole building energy analysis results required. Working knowledge of Total Cost of Ownership and or Life Cycle Cost Analysis required. Demonstrated public speaking experience preferred. Experience in managing a design team is required. LEED accreditation preferred. Why McKinstry: Transformational change requires bold action. We must decarbonize our buildings and energy assets to combat climate change. We must tackle the affordability crisis by innovating waste out of our supply chain and dramatically cutting costs through improved productivity. We must deliver equitable outcomes to ensure healthy, high-performing buildings for all. People represent our most valued asset. By investing in our employees, we are also investing in the ongoing success of our company. We pride ourselves on offering a comprehensive, PeopleFirst benefits package to promote health and wellness, enhance work/life balance and ensure long-term stability for our employees and their families. Some of these benefits include: Competitive pay backed by 401(k) and profit-sharing plans. Comprehensive medical, prescription drugs, vision, and dental. Up to 16 weeks of paid parental leave. Adoption and IVF assistance. Paid time off. McKinstry University training and development. McKinstry wellness programs and on-site gyms. Community service and employee-directed charitable giving. The pay range for this position in Colorado is $103,050 - $185,130 per year; however, base pay offered may vary depending on job-related knowledge, skills, and experience. A bonus may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. The McKinstry group of companies are equal opportunity employers. We are committed to providing equal employment opportunities to all employees and qualified applicants without regard to sex, gender identity, sexual orientation, age, race, color, creed, marital status, national origin, disability, veteran status, genetic information or any other basis protected by law. This policy applies to all terms and conditions of employment including, but not limited to employment, advancement, assignment, and training. This commitment to Equal Employment Opportunity is made equally as a social responsibility and as an economic and business necessity. McKinstry is a drug-free workplace. Employment is contingent upon successfully passing a pre-employment drug and alcohol test, complying with the requirements of the Immigration Reform and Control Act and a Confidentiality Agreement, in addition to successful outcomes of background and reference checks. #LI-MA1 #LI-Hybrid #LI-Remote"
Data Integration Engineer - Data Warehouse,Texas Health Resources,"Remote in Arlington, TX 76011",https://www.indeed.com/rc/clk?jk=f5e1e7967e153b2a&fccid=47c7346c8483e993&vjs=3,"Data Integration Engineer II Are you looking for a rewarding career with family-friendly hours and top-notch benefits? We are looking for a qualified Data Integration Engineer II like you to join our Texas Health family. Position Highlights: Work location: Texas Health Resources System Services; Arlington, TX – 95% remote position. Must live in the DFW, Texas area Department: Data Warehouse Work hours: Full Time (40 Hours); Day Shift; Monday – Friday, 08:00 AM – 5:00 PM Position works remotely 4 days per week At Texas Health Resources, our mission is “to improve the health of the people in the communities we serve”. We are one of the largest faith-based, nonprofit health systems in the United States with a team of more than 23,000 employees of wholly owned/operated facilities plus 2,200 employees of consolidated joint ventures in the greater Dallas Fort Worth area. Our career growth and professional development opportunities are top-notch and our benefits are equally outstanding. Join our award-winning Texas Health family and become a part of a team that is improving the health of our communities daily. You belong here. Qualifications: Education: Bachelor’s Degree in Business Administration, Information Science, Computer Science, Computer Engineering, Information Technology, or relevant field required. Experience: 3 Year working as an Data Integration Engineer or Data Integration Production Support Engineer with a Bachelor's degree required combined with: Continuous experience developing ETL with IBM Infosphere Data Stage (may consider those with 3 years of Informatica experience) Continuous experience using Teradata Database (may consider those with 3 years of Oracle or SQL Server experience) Continuous experience developing SQL and able to demonstrate advanced queries, create tables, views, indexes, joins Experience developing Unix scrips and integration with enterprise scheduling tools required And, Experience working in healthcare or related field preferred. Skills: Proficient with interviewing and gathering business requirements, definition and design of data source and data flows, data quality analysis, and working with the data architect on the development of logical data models. Proficient using Infosphere/DataStage, equivalent data integration software, or API software (such as Mulesoft) Proficient with relational databases and using SQL to query, create tables, views, indexes, joins. Proficient using Unix and applicable scripting/scheduling tools. Experience with the SDLC, ITSM and privacy and security concepts. Able to take on multiple projects concurrently and manage changes in scope along the way. Strong communication and interpersonal skills with focus on concise, cohesive, critical HRO focused communication with vendors, business users, and executives. Demonstrated ability to work on multi-disciplined project teams to consistent rapid delivery while driving an aggressive schedule, identifying all impacts and proposing resolutions. Position Responsibilities: The Data Integration Engineer II is self-motivated individual responsible for the design, development, and support of data integration solutions. Partners with internal business units, analysts, vendors, and key stakeholders to understand their information requirements to independently design, develop and implement data integration solutions that support our platforms resiliency, stability, and supportability; using a variety of ETL, API and database technologies. Their work will support business decisions, and could span across multiple areas such as consumer experience, clinical quality, hospital operations, supply chain, finance, etc. In addition to the required qualifications, a successful Data Integration Engineer II will: Collaborate with business, analysts, and SMEs to rapidly develop, refine, or test data integration solutions using Infosphere Datastage, SQL, Quality Center, UFT, FastTrack, or other technologies. With minimal guidance, work with business sponsors, SMEs and application teams to understand the business requirements; analyze and assess availability, quality, and lineage of source system data. Design, map data from source to target and develop/test data integration solutions that meet business needs. Collaborate with business, analysts, BI team, application teams and other stakeholders to design testing strategies to support development of data integration solutions that are fully integrated into the Enterprise Data Warehouse. Support production Data Warehouse applications to manage source system changes, optimize applications and ensure availability, accuracy, security, and acceptable performance Comply with THR information security and privacy policies and Data Integration development, testing, and design standards and best practices. Follow data governance requirements and documentation including but not limited to business definitions, technical definition, and may function as data SME. Develops interrelationships among partners and customers and analysts who have similar information needs and manages those relationships to assure effective solutions. Why Texas Health? As a Texas Health Data Integration Engineer II, you’ll enjoy top-notch benefits including 401(k) with match, paid time off, competitive health insurance choices, healthcare and dependent care spending account options, wellness programs to keep you and your family healthy, tuition reimbursement, a student loan repayment program and more. At Texas Health, our people make this a great place to work every day. Our inclusive, supportive, people-first, excellence-driven culture make Texas Health Resources a great place to work. Here are a few of our recent awards: 2021 FORTUNE Magazine’s “100 Best Companies to Work For®” (7th year in a row) Becker's Healthcare ""150 Great Places to Work in Healthcare"" (4 years running) “America’s Best Employers for Diversity” list by Forbes A “100 Best Workplaces for Millennials"" by Fortune and Great Place to Work® Additional perks of being a Data Integration Engineer II: Gain a sense of accomplishment by contributing in a teamwork environment. Receive excellent mentorship, comprehensive training and dedicated leadership resources. Enjoy opportunities for growth. Explore our Texas Health careers site for info like Benefits, Job Listings by Category, recent Awards we’ve won and more. Do you still have questions or concerns? Feel free to email your questions to recruitment@texashealth.org."
Senior-Big Data Engineer,AT&T,"El Segundo, CA 90245",https://www.indeed.com/rc/clk?jk=28228fe17d916ec2&fccid=25b5166547bbf543&vjs=3,"Develop the necessary enablers and data platform in the Big Data Lake Environment and has the responsibility of maintaining its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment. Support the standardization, customization and ad-hoc data analysis, and will develop the mechanisms to ingest, analyze, validate, normalize and clean data. Implement statistical data quality procedures on new data sources, and by applying rigorous iterative data analytics, supports Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing, anonymizing and governance of data. Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques. Contribute through proven technical expertise. Utilize knowledge with relational dimensional modeling and a solid understanding of modeling with structured and unstructured data on Hadoop and cloud platforms including AWS, Azure, SQL, Databricks, Snowflake, Palantir, Erwin/Visio and other data modeling software. Ability to build data models for structured and unstructured data. Optimize the database/table structure to improve query performance and dashboard performance. Normalize the Big Data datasets and build data transformations using ETL or ELT tools. Build automations to replace manual/ ad-hoc processes built on legacy On-Premises servers to transform the processes in cloud systems. Requires a Bachelor’s degree, or foreign equivalent degree in Information Technology or Computer Science, and 5 years of progressive, post-baccalaureate experience in the job offered, or 5 years of progressive, postbaccalaureate experience developing the necessary enablers and data platform in the Big Data Lake Environment and has the responsibility of maintaining its integrity during the life cycle phases; working with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing, anonymizing and governance of data; developing and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques; contributing through proven technical expertise; utilizing knowledge with relational dimensional modeling and a solid understanding of modeling with structured and unstructured data on Hadoop and cloud platforms including AWS, Azure, SQL, Databricks, Snowflake, Palantir, Erwin/Visio and other data modeling software; ability to build data models for structured and unstructured data; and normalizing the Big Data datasets and build data transformations using ETL or ELT tools. AT&T is an Affirmative Action/Equal Opportunity Employer, and we are committed to hiring a diverse and talented workforce. EOE/AA/M/F/D/V *np*"
"Data Engineer, Reporting",PlugShare,"Los Angeles, CA 90064",https://www.indeed.com/rc/clk?jk=dacee6e0c2ae84cb&fccid=a1e2458ea38781b8&vjs=3,"About PlugShare: PlugShare, a wholly owned subsidiary of EVgo, is home to the largest community of EV drivers in the world, with a community of over 3MM EV drivers who rely on us to plan their journeys and public charging stops. Every day, drivers add more station locations, constantly making the app more comprehensive and accurate. From within the app., users check-in when they charge, sharing tips, comments, reviews and photos of their charging experiences. Drivers, automakers, utilities, and the rest of the EV community rely on our comprehensive public charging dataset to power their navigation systems and guide their decision-making. We amplify the voice of the driver through PlugInsights, the world’s largest survey research panel of EV owners and leasers, and developed Pay with PlugShare (PWPS), a mobile payment platform enabling seamless and reliable payment for multiple charging networks through a single app. We also provide in-app and web advertising and digital marketing services to give brands and marketers access to the largest EV driver audience. Position Summary: We are seeking a Data Engineer, Reporting to join the PlugShare team. This is a great opportunity to work in the exciting, growing electric vehicle market. The ideal candidate has a deep understanding of SQL and supreme analytical skills. Beyond data queries and visualizations, many projects will focus on improving data quality. The person in this role will have a large level of ownership over our tooling and ETL processes. Responsibilities: Build, deploy and maintain ETLs to pull data out from all third-party systems Write complex SQL queries and provide easily queryable datasets in the form of Tableau extracts and database views Work with engineering teams and cross-functionally to build to improve data consumption, data integrity and automation Use SQL to query, manipulate and transform data consumed and exposed SQL Performance & Tuning Perform ETL to blend data sources through manual and automated processes Develop and maintain technical specification documentation for data flows and reports/dashboards. Manage and investigate data errors and work to improve Partner with teams to understand data requirements for analysis and reporting tools. Create Reports and Dashboard/Visualizations Develop and maintain technical specification documentation for data flows and reports/dashboards (Tableau), aggregating data from multiple data sources Review and verify data and reports for accuracy. Required Skills and Experience: BS/BA in Technical Field, Computer Science, Mathematics, Statistics, or equivalent experience. 3+ years of experience coding in SQL Some experience working in Python preferred Experience building ETLs against various sources, including REST endpoints Experience working in cloud environments (AWS, GCP) Experience in building and enhancing data pipelines Familiar with reporting tools (Tableau, PowerBI, QlikView, etc.); we use Tableau Employees are required to provide documentation of COVID 19 vaccination."
Data Engineer,ByteDance,"Mountain View, CA+3 locations",https://www.indeed.com/rc/clk?jk=e22ea0e9480d762e&fccid=74fbc768a4e5bece&vjs=3,"About ByteDance Founded in 2012, ByteDance is a technology company operating a range of content platforms that inform, educate, entertain and inspire people across languages, cultures and geographies. With a suite of more than a dozen products, including TikTok, Douyin, Toutiao, Helo and Resso, ByteDance now has a portfolio of applications available in over 150 markets and 75 languages. What You'll Do Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis); Design and implement reliable, scalable, robust and extensible big data systems that support core products and business; Establish solid design and best engineering practice for engineers as well as non-technical people. Who We're Looking For BS or MS degree in Computer Science or related technical field or equivalent practical experience; Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.); Experience with performing data analysis, data ingestion and data integration; Experience with ETL(Extraction, Transformation & Loading) and architecting data systems; Experience with schema design, data modeling and SQL queries; Passionate and self-motivated about technologies in the Big Data area."
Snowflake Developer or Data Engineer,Kaizen Technologies,"San Jose, CA",https://www.indeed.com/rc/clk?jk=3f73462455320b6b&fccid=c1edd7669511bab9&vjs=3,"Required Skills : Snowflake Job Description : Position: Snowflake Developer or Data Engineer Location: San Jose - CA Duration: Contract Job Description: 1.Job title COGNIZANT IS LOOKING FOR SNOWFLAKE DEVELOPER / DATA ENGINEER 2. Job summary The Snowflake Senior Developer must have at least 6 to 9 years of experience. Required Experience and Skills: - At least two years of experience in Snowflake development - Highly proficient at SQL development. - Significant experience in Python development/DBT/ETL. - Current SnowPro Certification Preferable (Not mandatory). - Airflow (not mandatory) 3.Experience 8to10yrs 4.Required Skills Technical Skills- SQL Developer, Snowflake, Apache Airflow Domain Skills- 5.Nice to have skills Technical Ski 3.Experience 11to14yrs 4.Required Skills Technical Skills- SQL Developer, Snowflake, Apache Airflow Domain Skills- 5.Nice to have skills Technical Skills- Domain Skills- 6.Technology Data Management 7.Shift Day 8.Roles & Responsibilities 2000 Chars The Snowflake Senior Developer must have at least 6 to 9 years of experience. Required Experience and Skills: - At least two years of experience in Snowflake development - Highly proficient at SQL development. - Significant experience in Python development/DBT/ETL. - Current SnowPro Certification Preferable (Not mandatory). - Airflow (not mandatory) 3. Experience 8to10yrs 4. Required Skills Technical Skills- SQL Developer, Snowflake, Apache Airflow Domain Skills- 5. Nice to have skills Technical Skills- Domain Skills- 6.Technology Data Management 7.Shift Day 9 AM - 7 PM EST 8.Roles & Responsibilities Must have experience developing the different layers within Snowflake Staging Integrated and DM and performing data transformations between the different layers. - Must be able to perform batch and incremental loads within Snowflake using ETL tools Snow Pipe Streams and Tasks. - Must have very strong SQL experience. - In-depth knowledge of Cloud services. - Experience in databases like Oracle, RDS, Redshift, SQL Server. - Hands-on experience with Snowflake utilities such as SnowSQL, Snow Pipe. - AWS Experience - Agile experience 9. Job Location Primary: USCASNJC01-San Jose - CA USA, CLT Alternate: 10. Job Type 60CW00 Business Associate 11. Demand Requires Travel? N 12. Certification (s) Required NA"
Data Engineer,Dogtopia Enterprises LLC,"Phoenix, AZ 85016 (Camelback East area)+1 location",https://www.indeed.com/rc/clk?jk=fe088e61be17decc&fccid=1aefe49c1434cc94&vjs=3,"WHO IS DOGTOPIA? At Dogtopia, we have a passion for caring for dogs. Happy, healthy pups are at the heart of who we are. We have created a loving brand with what dogs want and need in mind. We are a franchise system of Dog Daycares with more than 183 locations in the United States and Canada. DOGTOPIA’S NOBLE CAUSE To enhance the JOY of DOG parenthood and Enable dogs to positively change our world. Our DOGTOPIA-ISMS The rules by we, as Dogtopians live by are: We LOVE life unconditionally like a dog We STAY loyal to our pack We CHASE the absolute highest standards of safety We PLAY to our full potential We TREAT every day like it’s the most exciting day ever Dogtopia is in need an experienced leader that can oversee and manage data sources across multiple environments. This role will work closely within all aspects of our business to build strong relationships, cultivate communication channels, and understand the data needs of the organization. This role has responsibility for data quality, data rationalization, and data classification. WHAT WILL YOU DO? o Maintain overall responsibility for the information needs of the organization. o Create and maintain data models and structures. o Work with corporate develop, store operations, and other departments to summarize and aggregate data in various environments. o Work with IT Leadership to create a long-term data strategy. o Develop data governance practices and processes including data classification and usage standards. o Other duties as assigned Requirements Required Education and/or Experience: BA/BS or higher education in Information Technology, Computer Science or a field directly applicable to this role is preferred. Hard Skills/Qualifications: Project Management: Must be proactive, highly motivated and collaborative. Ability to successfully manage multiple projects simultaneously with an eye for detail. Exceptional organizational, time management and prioritization skills. Strong problem solving, customer service and analytical skills Proven experience as a data analyst, data architect, data scientist, or back-end developer well versed in data. Experience with MySQL databases required Experience with MongoDB preferred Experience with creation of data reports and dashboards in PowerBI Thorough knowledge of data principles Soft Skills/Qualifications Problem-solving aptitude Ability to present data findings and explain data structure in business terms Strong business acumen Physical Demands: Some lifting (up to 30 lbs.). Long hours on computer keyboard. Prolonged periods of standing and/or walking."
Data Engineer,Arcadia.io,"Remote in Pittsburgh, PA",https://www.indeed.com/rc/clk?jk=37d4fd7669aedd47&fccid=f74a07f61f1a7daa&vjs=3,"Based on the evolving situation with Covid–19 we are mostly remote, this includes the hiring process. We are in the process of moving to a hybrid of onsite and remote with some positions remaining 100% remote. Why This Role Is Important To Arcadia This position is part of the Arcadia Data Engineering team, we are responsible for the onboarding, enhancement, and support of data feed integrations between Client Claim and Clinical data mgmt. platforms and our Healthcare Solution Platform. Our customers are top Healthcare providers and payers, and we help them integrate their internal systems with our analytic platform. The Data Engineering team is responsible for the data architecture that drives the partnership with customers and other internal organizations to drive success through adoption of cutting edge analytic solutions that leverage new age technologies and best practices. Our Data Engineers require both SQL Database knowledge and design , along with multiple programing languages . As a Data Engineer, you will drive the successful development of solution architecture and the completion of data pipeline connectors that automate the flow of data between client Claim and Clinical data platforms and our analytic health solution platform. Your efforts will be critical to driving the long-term partnership between Arcadia and our customers. What Success Looks Like: In 3 months Learn the different areas of the data connector life cycle, while having a working knowledge of the technical stacks , storage platforms , data models , and Dev. Cycle Work within Data Engineering Scrum team Set to work on new ingestion pipelines with full bandwidth available (as formal training will end) In 6 months Properly contribute to scrum ceremonies and ceremonies within the dev cycles while successfully updating status and progress in Jira Work on higher level enhancement requests and ingestion pipelines Ability to Deliver Data related Reviews to clients and other departments regarding code quality and test cases. Set your own personal vision of development and career aspirations and set a working path forward with leadership to work on how we can help you attain those goals In 12 months Developing a range of data pipelines with varying complexity Work with Product, Engineering or Implementation to build out tools for better data integration Pick an SME (Subject Matter Expert) path for what excites you the most Working on standardized data connector development What You'll Be Doing Design and documentation of connectors / ingestion pipelines Build and Unit testing of delivery connectors / ingestion pipelines Support of our processes in partaking in peer code reviews , sprint planning , product grooming , maintaining Jira tasks and peer test reviews You will be expected to contribute to multiple implementations simultaneously, which will include both new customer setup as well as support and enhancements for existing customers. The expectations of the day to day of an engineer is as follows: Delivery Responsible for delivery of work on expected timelines. Able to identify risk to project success and communicate to leadership Works mostly independently on delivery w/decreasing involvement from engineering and more senior team members Consistently deliver increasing connectors of increasing quality with ""lessons learned"" incorporated into next project Able to apply critical thinking and problem solving skills to propose solutions for complex problems within day to day work Technical Domain Knowledge: Working and growing knowledge of new tech stack with less focus on finding efficiency in the technology and greater focus on understanding use of it. Developing ability to understand technical issues and communicate potential solutions to team members or engineering team Business Domain Knowledge: Developing working knowledge of the business of healthcare data and how it interacts within the Arcadia products Understanding of shared value contracts that our customers are in and how data is impacted by them Developing knowledge of industry data expected values such as PMPM by LOBs, MM trends, etc. Communication Skills: Developing internal and external professional communication skills including presentation of issues using appropriate industry vocabulary Team Projects: Responsible for contributing to the advancement of team processes and internal What You’ll Bring Experience Level 2-5 years post-grad with relevant industry experience or graduate level Degree. TECH As a data engineer you will be expected to problem solve some basic coding issues and enhancements with frameworks that are built in Spark Scala, while also leveraging technical skills to partake in idea sessions on process improvement and POC design of how to carry out a solution. SQL: 2-4 year (Preferred) Spark: 1-2 years (Preferred) NoSQL Databases: 1-2 years (Preferred) Database Architecture: 2-3 years (Preferred) Cloud Architecture: 1-2 years (Preferred) DATA As a data engineer you will be expected to problem solve some basic data analysis issues and work the data to create analytic enhancements. Healthcare Data: 2-4 years (Preferred) Healthcare Analytics: 1-3 years (Preferred) What You'll Get Chance to be surrounded by a team of extremely talented and dedicated individuals driven to succeed Be a part of a mission driven company that is transforming the healthcare industry by changing the way patients receive care A flexible, remote friendly company with personality and heart Employee driven programs and initiatives for personal and professional development Be a member of the Arcadian and Barkadian Community About Arcadia Arcadia.io helps innovative healthcare systems and health plans around the country transform healthcare to reduce cost while improving patient health. We do this by aggregating massive amounts of clinical and claims data, applying algorithms to identify opportunities to provide better patient care, and making those opportunities actionable by physicians at the point of care in near-real time. We are passionate about helping our customers drive meaningful outcomes. We are growing fast and have emerged as the market leader in the highly competitive population health management software and value-based care services markets, and we have been recognized by industry analysts KLAS, IDC, Forrester and Chilmark for our leadership. For a better sense of our brand and products, please explore our website, our online resources, and our interactive Data Gallery. This position is responsible for following all Security policies and procedures in order to protect all PHI under Arcadia's custodianship as well as Arcadia Intellectual Properties. For any security-specific roles, the responsibilities would be further defined by the hiring manager."
Data Engineer (remote),LinQuest Corporation,"Remote in Beavercreek, OH 45431",https://www.indeed.com/rc/clk?jk=ec4d965c84237b16&fccid=a9f4c88b2ec65781&vjs=3,"LinQuest is seeking a Data Engineer to join our team. This position can be remote but candidates near Dayton, OH, are preferred. US Citizenship and the ability to obtain a DoD Secret security clearance is required. As a Data Engineer, you will have the opportunity to work with unstructured and structured data, develop databases, build data pipelines, and find innovative solutions to complex data problems. Candidates must be comfortable across the spectrum of data management functions ranging from data modeling, database design and development, ETL/ELT design and development, as well as familiarity with metadata management, data quality, and data management techniques. Efforts will include frameworks to support data discovery, data science, and analytics. Expected to possess a strong work ethic and solid leadership skills. Required Skills: Strong analytical and problem-solving skills with hands on experience working with databases. Must have the ability and motivation to self-teach in order to stay current with leading best practices in the database industry. Candidates must be able to tackle difficult problems but be willing to seek help and guidance when needed. Expected to understand data modeling techniques and best practices, have strong SQL programming skills and have a good understanding of data design and development best practices. Candidates should have a strong understanding of data stores to support search, applications, and data science. Must be able to tackle difficult problems specifically working with unstructured textual data. Expected to have data exploration, analysis and wrangling skills. Applicants must have the ability to quickly learn new software applications, open source, and COTS products across a wide spectrum of database disciplines and possess a working knowledge of, including but not limited to, the following concepts: Data Management Functions Data and Agile Modeling Data Wrangling/Extract, Transform, and Load (ETL/ELT) Data Architectures Data Pipelines Data Discovery & Search Required Experience: Bachelor’s Degree in computer science, engineering, or related field At least 3 years of professional experience translating complex data requirements into well designed solutions Experience working with both structured and unstructured databases Experience manipulating data with Python Experience with Agile A Secret Clearance, or US Citizenship and the ability to obtain a Secret clearance Benefits: LinQuest offers comprehensive and competitive benefit offerings to our team members to include medical, dental, vision, retirement, paid time off, company paid life insurance, and more! For additional information please visit: https://www.linquest.com/careers/our-benefits COVID-19 Compliance Guidelines: As a federal contractor, all LinQuest team members may be required to comply with Executive Order 14042- Ensuring Adequate COVID Safety Protocols for Federal Contractors, which may include mandatory vaccination and ability to provide proof of vaccination status prior to start of employment. Additionally, team members are expected to comply with all safety protocols related to mask wearing and physical distancing while in covered contractor workplaces. If applicable, prospective or new employees may seek an exemption to the vaccination requirement through LinQuest Human Resources and must have an approved exemption prior to the start of their employment. Education Required Bachelors or better in Computer Science or related field Licenses & Certifications Required Ability to Obtain Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Engineer,GEI Consultants Inc,"Remote in Woburn, MA 01801",https://www.indeed.com/rc/clk?jk=e407702db753919e&fccid=908bc786b906bc2f&vjs=3,"Hello. We are GEI. Some of the world s most pressing problems – from climate change to sustainable development, to critical infrastructure and the future of our energy supply – need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow. We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients most complex challenges. With more than 40 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry. Employee-owned. Employee-focused. As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs – we are Client-Centered, Curious, Collaborative, and Community Minded – which support our focus on sustainability, safety, diversity, equity and inclusion. Your role at GEI. Job Description GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment. Essential Responsibilities & Duties: ETL of data from a wide variety of sources Database and Data Warehouse design/expansion/backup & recovery Index management and optimization Support data sources for Tableau Server and ArcGIS Stored procedure development and maintenance Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases Troubleshoot SSIS package permission issues related to execute-as/data source read/write access SQL Agent Job development and monitoring Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS Develop test plans, implementation plans, and project timelines for various data engineering projects Define, prioritize, communicate, and foster shared understanding of project objectives and scope Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product Team with all staff necessary to complete assignments Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements Other duties as assigned Minimum Qualifications: 3+ years of experience in a position performing similar data engineering tasks Proven record of ability to design, manage, and support MS SQL Server and Azure databases Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R Bachelor's Degree, from an accredited college or university MS SQL Server/Azure certification preferred Ability to develop project plans and meet deadlines Self-starter with attention to detail and stakeholder needs Able to critically analyze and solve problems of a complex nature Excellent Communication skills Able to work on multiple projects of moderate complexity simultaneously and independently Proficient in organization and time management skills Familiarity with engineering, environmental science, and/or chemistry subject matter preferred. Able to work effectively in GEI s partnership model, including a team environment, building rapport and relationships. GEI is open to filling this position at any of our offices nationwide but is primarily targeting office locations in the Eastern Time Zone. The position can be considered for either part-time or full-time remote work. Physical Job Requirements Sedentary X Light Medium Other Activity Level Throughout Workday Physical Activity Requirements Occasional (0-35% of day) Frequent (33-66% of day) Continuous (67-100% of day) Not Applicable Sitting X Standing X Walking X Climbing X Lifting (floor to waist level) (in pounds) X Lifting (waist level and above) (in pounds) X Carrying objects X Push/pull X Twisting X Bending X Reaching forward X Reaching overhead X Squat/kneel/crawl X Wrist position deviation X Pinching/fine motor skills X Keyboard use/repetitive motion X Taste or smell (taste=never) X Talk or hear X Accurate 20/40 Very Accurate 20/20 Not Applicable Near Vision X Far Vision X Yes No Not Applicable Color Vision (ability to identify and distinguish colors) X Sensory Requirements Minimal Moderate Accurate Not Applicable Depth perception X Hearing X Environmental Requirements Occupational Exposure Risk Potential Reasonably Anticipated Not Anticipated Blood borne pathogens X Chemical X Airborne communicable diseases X Extreme temperatures X Radiation X Uneven surfaces or elevations X Extreme noise levels X Dust/particular matter X Other (exposure risks): Usual workday hours: X 8 10 12 Other work hours GEI is an AA/equal opportunity employer, including disabled and veterans."
Data Engineer - Artificial Intelligence & Machine Learning,Schneider Electric,"Andover, MA 01810",https://www.indeed.com/rc/clk?jk=761085a2afee842d&fccid=8dc4399ddb463d4a&vjs=3,"Schneider Electric has an opportunity for a Data Engineer - Artificial Intelligence & Machine Learning i n our Andover, MA location. Schneider Electric creates connected technologies that reshape industries, transform cities and enrich lives. Our 135,000+ employees thrive in more than 100 countries. From the simplest of switches to complex operational systems, our technology, software and services improve the way our customers manage and automate their operations. Help us deliver solutions that ensure Life Is On everywhere, for everyone and at every moment. http://www.youtube.com/watch?v=YtExntUe89c Great people make Schneider Electric a great company. Does working with data on a day to day basis excite you? Are you interested in building robust data architecture to identify data patterns and optimise data consumption for our customers, who will forecast and predict what actions to undertake based on data? If this is what excites you, then you’ll love working in our intelligent automation team. Schneider Digital is leading the digital transformation of Schneider Electric by building highly available, massive scalable digital platform for the enterprise. We are looking for a savvy Data Engineer to join our growing team of AI and machine learning experts. You will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. AI@SEHub The Data Engineer will support our software engineers, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. Responsibilities Create and maintain optimal data pipeline architecture; assemble large, complex data sets that meet functional / non-functional requirements design and build production data pipelines from ingestion to consumption within a big data architecture Build the necessary datamarts, data warehouse required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Create necessary preprocessing and postprocessing for various forms of data for training/ retraining and inference ingestions as required Create data visualization and business intelligence tools for stakeholders and data scientists for necessary business/ solution insights Identify, design, and implement internal process improvements: automating manual data processes, optimizing data delivery, etc. Ensure our data is separated and secure across national boundaries through multiple data centers and AWS regions Qualifications We know skills and competencies show up in many different ways and can be based on your life experience. If you do no t necessarily meet all the requirements that are listed, we still encourage you to apply for the position . You should have a bachelors or master’s degree in computer science, Information Technology or other quantitative fields You should have at least 5 years working as a data engineer in supporting large data transformation initiatives related to machine learning, with experience in building and optimizing ‘big data’ pipelines and data sets Strong analytic skills related to working with unstructured datasets. Experience with big data tools: Hadoop, Spark, Kafka, etc. Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc. Experience with AWS cloud services: EC2, EMR, RDS, Redshift and familiarity with various log formats from AWS. Experience with stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, C++, etc. Schneider Electric offers a robust benefits package to support our employees such as flexible work arrangements, paid family leave, 401(k)+ match, and more. Click here to find out more about working with us: http://se.com/us/careers . We seek out and reward people for putting the customer first, being disruptive to the status quo, embracing different perspectives, continuously learning, and acting like owners. We’re recognized around the world for welcoming people as they are. We create an inclusive culture where all forms of diversity are seen as a real value for the company. See what our people have to say about working for Schneider Electric. https://youtu.be/C7sogZ_oQYg AI@SEHub Let us learn about you! Apply today. You must submit an online application to be considered for any position with us. This position will be posted until filled. As a federal government contractor, all Schneider Electric U.S. employees (including U.S. territories and Puerto Rico) must be fully vaccinated against COVID-19, subject to federal laws. It is the policy of Schneider Electric to provide equal employment and advancement opportunities in the areas of recruiting, hiring, training, transferring, and promoting all qualified individuals regardless of race, religion, color, gender, disability, national origin, ancestry, age, military status, sexual orientation, marital status, or any other legally protected characteristic or conduct. Concerning agencies: Schneider Electric does not accept unsolicited resumes and will not be responsible for fees related to such. Schneider Electric is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Primary Location : US-Massachusetts-Andover Schedule : Full-time Unposting Date : Ongoing"
Senior Data Engineer,Juul Labs,"Remote in San Francisco, CA+1 location",https://www.indeed.com/rc/clk?jk=82a4ca1a9f7f64fc&fccid=6e0a19936820440f&vjs=3,"THE COMPANY: Juul Labs' mission is to impact the lives of the world's one billion adult smokers by eliminating combustible cigarettes. We have the opportunity to address one of the world's most intractable challenges through a commitment to exceptional quality, research, design, and innovation. Backed by leading technology investors, we are committed to the same excellence when it comes to hiring great talent. We are a diverse team that is united by this common purpose and we are hiring the world's best engineers, scientists, designers, product managers, operations experts, and customer service and business professionals. If the opportunity to build your career at one of the fastest growing companies is compelling, read on for more details. ROLE AND RESPONSIBILITIES: Leverage Python to design robust, reusable and scalable data solutions and data pipeline frameworks to automate the ingestion, processing and delivery of both structured and unstructured data. Drive development of large-scale data engineering projects. Create data pipelines in airflow, DBT and the general suite of Google Cloud Platform .Build, manage, and support data models. Ensure data quality with data tests in Monte Carlo and Datafold. Comfortable working in a scrum agile environment using Jira. Partner with Data Scientists, Data Engineers and Business Analysts to build configurable, scalable, and robust data processing infrastructure Work closely with our sales, operations, research, and finance teams on data storage, retrieval, and analysis Develop new systems and toolsto enable stakeholders to consume and understand data more intuitively Create and establish design standards and assurance processes to ensure compatibility and operability of data connections, flows and storage requirements Validate model transformationsfor data integrity (source/target tables values and counts are expected, ensurance of proper data cleansing) Keep Juul on the cutting edge of data technology Our Data Stack: Airflow, Fivetran Google Cloud Platform -GCP (BigQuery, Storage, Dataflow, Pub/Sub, Cloud Functions/Run, Vertex AI, Cloud Build) DBT Monte Carlo, Datafold Tableau PERSONAL AND PROFESSIONAL QUALIFICATIONS: 4+ years of data engineering or software engineering experience witha focus on data Prior knowledge in code development using Python to process large-scale datasets and workflows Have used python libraries and packages (pandas, pyarrow) in conjunction with the Google Cloud Platform (BigQuery, Storage, Pub/Sub) Knowledgeof bash/shell and orchestration tools (e.g. Airflow), is preferred. Experience with version control (Git) and containers (Docker) Skilled in analytical SQL in support of data modeling and manipulating multiple data formats EDUCATION: Preferred masters degree in Computer Science, Engineering, Math, or equivalent experience JUUL LABS PERKS & BENEFITS: A place to grow your career. We'll help you set big goals - and exceed them People. Work with talented, committed and supportive teammates Equity and performance bonuses. Every employee is a stakeholder in our success Boundless snacks and drinks Cell phone subsidy, commuter benefits and discounts on JUUL products Excellent medical, dental and vision benefits #LI-Remote Juul Labs is proud to be an equal opportunity employer and is committed to creating a diverse and inclusive work environment for all employees and job applicants, without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status. We will consider for employment qualified applicants with arrest and conviction records, pursuant to the San Francisco Fair Chance Ordinance. Juul Labs also complies with the employment eligibility verification requirements of the Immigration and Nationality Act. All applicants must have authorization to work for Juul Labs in the US."
Data Engineer,Ally Financial,"Hybrid remote in Charlotte, NC 28202+1 location",https://www.indeed.com/rc/clk?jk=fd78d56f205ba8a6&fccid=f8c85b296194776f&vjs=3,"General information Career area Technology Work Location(s) 601 S. Tryon Street, Charlotte, NC Remote? No Ref # 12573 Posted Date Thursday, May 12, 2022 Working time Full-time Ally and Your Career Ally Financial only succeeds when its people do - and that’s more than some cliché people put on job postings. We live this stuff! We see our people as, well, people - with interests, families, friends, dreams, and causes that are all important to them. Our focus is on the health and safety of our teammates as well as work-life balance and diversity and inclusion. From generous benefits to a variety of employee resource groups, we strive to build paths that encourage employees to stretch themselves professionally. We want to help you grow, develop, and learn new things. You’re constantly evolving, so shouldn’t your opportunities be, too? The Opportunity At Ally, you get a startup feel, but experience the benefits of a company that’s worked out the kinks and is fulfilling its purpose. We’re always evolving and see that as a good thing. From owning our work to seeing its impact in the real world, our team is relentless in finding new ways technology can help make experiences better and help people. We are problem solvers, we value diverse thinking, we support one another, and we challenge ourselves to think bigger in the journey to deliver customer-obsessed tech solutions. As a Data Engineer at Ally, you’ll work closely with agile teams to build high quality data pipelines and drive analytic solutions. These solutions allow us to generate insights and make data-driven decisions in real-time and drive impact immediately The Work Itself Think outside of the box on a daily basis to promote data-driven decision making through the capture of data and development of innovative solutions Implement, test, and develop a portfolio of best-in-class data tools that contribute directly to the success of Ally’s strategic, technical, and business initiatives Collaborate with business partners and drive the management, refinement, and utilization of data models and tools Actively problem solve to and seek out information to keep the team on track and voice opinions on the most effective way forward The Skills You Bring 3+ years of experience in data warehousing, modeling principles/methods including conceptual, logical & physical Data Models. Deep understanding of different modeling patterns including Data Vault, Dimensional Star-Schema, 3NF, etc. 3+ years of experience creating views, tables, and stored procedures Bachelor's degree in computer science, information systems or relevant field of study preferred Experience in data wrangling, translating/mapping relational data models into XML, JSON Schemas and vise-versa. Proficient in querying skills on traditional relational and no-sql databases Working understanding of AWS services, including but not limited to, EC2, S3, Lambda, AWS CLI, AWS databases, Terraform etc Preferred experience with NiFi and Snowflake Desire to work within a diverse group of people and passion for challenging the status quo Strong work ethic and drive with an enthusiasm for owning your work and driving development How We'll Have Your Back Ally's compensation program offers market-competitive base pay and pay-for-performance incentives (bonuses) based on achieving personal and company goals. But Ally’s total compensation – or total rewards – extends beyond your paycheck and is designed to support and enrich your personal and professional life, including: Time Away: competitive holiday and flexible paid-time-off, including time off for volunteering and voting. Planning for the Future: plan for the near and long term with an industry-leading 401K retirement savings plan with matching and company contributions, student loan and 529 educational assistance programs, tuition reimbursement, and other financial well-being programs. Supporting your Health & Well-being: flexible health and insurance options including dental and vision, pre-tax Health Savings Account with employer contributions and a total well-being program that helps you and your family stay on track physically, socially, emotionally, and financially. Building a Family: adoption, surrogacy, and fertility support as well as parental and caregiver leave, back-up child and adult/elder day care program and childcare discounts. Work-Life Integration: other benefits including LifeMatters® Employee Assistance Program, subsidized and discounted Weight Watchers® program and other employee discount programs. Who We Are: Ally Financial is a customer-centric, leading digital financial services company with passionate customer service and innovative financial solutions. We are relentlessly focused on ""Doing it Right"" and being a trusted financial-services provider to our consumer, commercial, and corporate customers. For more information, visit www.ally.com. Ally is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity or expression, pregnancy status, marital status, military or veteran status, genetic disposition or any other reason protected by law. Where permitted by applicable law, must have received or be willing to receive the COVID-19 vaccine by date of hire to be considered, if not currently employed by Ally. We are committed to working with and providing reasonable accommodation to applicants with physical or mental disabilities. For accommodation requests, email us at work@ally.com. Ally will not discriminate against any qualified individual who is capable of performing the essential functions of the job with or without reasonable accommodation. #LI-Hybrid"
Data Engineer/Developer,Byte Systems,"Reston, VA",https://www.indeed.com/rc/clk?jk=3904048ab4eed158&fccid=76f9e09af8745420&vjs=3,"The Sponsor applies technical resources to accelerate the timely, reliable, and secure delivery of open source data, information, and insights. The Sponsor requires support to maintain and enhance an existing big data exploitation platform. The Contractor will work within an agile team environment. Work will include creating Amazon Web Services (AWS)-based resources; writing, testing, and debugging custom application code; administering database services; and performing data cleaning, formatting, and other forms of data management. The Team shall work closely with the Sponsors product owner and program manager to deliver user stories necessary to realize product vision. The Team shall coordinate with multiple entities, including mission partners, to ensure tools meet defined requirements. The Team shall apply an agile approach to software development consistent with the Sponsors project management and software development frameworks with a focus on demonstrating and delivering releasable software every iteration. The Team shall create and maintain JWICS-accessible resources within the Sponsors Amazon Web Services (AWS) Cloud environment. The Team shall ensure all security vulnerabilities are addressed as appropriate by severity and maintain security accreditation, including maintaining plan of action for vulnerability remediation. The Team shall maintain all source code in Sponsor-wide, remote Git repository. The Team shall apply industry best practices (such as, but not specifically Test Driven Development) for ensuring custom application code is comprehensively tested. The Team shall administer and maintain relational and non-relational transactional database systems within the application security boundary. The Team shall perform data cleaning and formatting for ingested data ensuring they meet quality and content management standards.CERTS MUST be a US Citizen with a U.S. Government clearance - Intel with Polygraph NOTE: Must have an active TS-SCI with poly. No sponsorships or upgrades are available. Submissions without this requirement will not be considered. H1-B holders will not be considered. Benefits: 5 week paid vacation + 10 gov't holidays 15% contribution to 401k LTD, STD disability and life insurance Paid health, dental, and vision for employee and family. $5000 annual training expense reimbursement Computer purchase plan"
Data Engineer,Bunge,"Hybrid remote in Chesterfield, MO 63017",https://www.indeed.com/rc/clk?jk=1d70170fd614ea85&fccid=894ee0a88fc215e2&vjs=3,"Location : St. Louis MO, BAL - GASPAR, Warsaw Mathematical Institute City : Chesterfield State : Missouri (US-MO) Country : United States (US) Requisition Number : 22540 Bunge has an exciting opportunity available for a Data Engineer. In this role you will be part of a global team working on challenging, meaningful projects impacting core business activities. Since 1818, Bunge has been connecting farmers to consumers to deliver essential food, feed, and fuel to the world. Looking to the future, our ambition is to continuously reinvent ourselves, leveraging data to be at the forefront of analytics, technology and talent to accomplish our purpose in a better, faster and simpler way. Bunge is committed to operating and thriving in the digital world – creating world class agile teams where teammates are empowered and encouraged to collaborate and test and learn to succeed. **This position can be located in Chesterfield, MO, Gaspar, Brazil or Warsaw, Switzerland At Bunge, people don’t just come here to work, they come here to grow – solving challenges that directly impact the world with a diverse team of thinkers and doers. Bunge offers a strong compensation and benefits package, generous paid time off program, flexible work arrangements, and opportunity to progress. Our hybrid work environment provides a balance of in office and remote work. Most importantly, in all we do we live our values: Act as One Team by fostering inclusion, collaboration, and respect Drive for Excellence by being agile, innovative and efficient Do What's Right by acting safely, ethically, and sustainably Overview: Data Engineer will work closely with a multidisciplinary Agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from the organization's connected data, enabling the organization to advance the data-driven decision-making capabilities of the organization's enterprise. This role requires deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows. They are an Agile learner, possess strong problem-solving skills, work as part of a technical, cross functional analytics team, and want to solve complex data problems and deliver the insights to enable analytics strategy. At Bunge, you will be at the forefront of leveraging data analytics and technology to feed and fuel the world in a better, faster, and simpler way. Responsibilities: Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals Solve complex data problems to deliver insights that helps the organization's business to achieve their goals Create data products for analytics and data scientist team members to improve their productivity Advise, consult, mentor and coach other data and analytic professionals on data standards and practices Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve the organization's productivity as a team Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives. Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics Qualifications/Requirements: Bachelor’s degree required; Computer Science, MIS, or Engineering preferred 5 years of experience working in data engineering or architecture role, 7+ preferred (3 years with 5 preferred for junior role) Expertise in SQL and data analysis and experience with at least one programming language (Python or Scala preferred) Experience developing and maintaining data warehouses in big data solutions Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred) Database development experience using Hadoop or BigQuery and experience with a variety of relational, NoSQL, and cloud database technologies Worked with BI tools such as Tableau, Power BI, Looker, Shiny Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data. Big Data Development experience using Hive, Impala, Spark and familiarity with Kafka (Preferred) Familiarity with the Linux operating system (Preferred) Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics Passionate about Agile software processes, data-driven development, reliability, and experimentation Experience working on a collaborative Agile product team Self-motivated with strong problem-solving and learning skills Flexibility to changes in work direction as the project develops Excellent communication, listening, and influencing skills Demonstrated strong number sense, intellectually curious and willing to adjust position based on additional information Strong work ethic; ability to work at an abstract level and gain consensus #LI-LC1 Bunge (NYSE: BG) is a world leader in sourcing, processing and supplying oilseed and grain products and ingredients. Founded in 1818, Bunge’s expansive network feeds and fuels a growing world, creating sustainable products and opportunities for more than 70,000 farmers and the consumers they serve across the globe. The company is headquartered in St. Louis, Missouri and has 25,000 employees worldwide who stand behind more than 350 port terminals, oilseed processing plants, grain facilities, and food and ingredient production and packaging facilities around the world. Bunge is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, transgender status, national origin, citizenship, age, disability or military or veteran status, or any other legally protected status. Bunge is an Equal Opportunity Employer. Minorities/Women/Veterans/Disabled"
Data Engineer III - Data Science - Remote,C.H. Robinson,"Remote in Eden Prairie, MN 55347+9 locations",https://www.indeed.com/rc/clk?jk=ec81e4e4360034d3&fccid=090a7d416d718609&vjs=3,"Enter the introduction paragraph(s). Responsibilities: Enter responsibility Enter responsibility Required Qualifications: Enter qualification Enter qualification Preferred Qualifications: Enter preferred qualification Enter preferred qualification Equal Opportunity and Affirmative Action Employer C.H. Robinson is proud to be an Equal Opportunity and Affirmative Action employer. We believe in equality for all and celebrate the diversity of our employees, customers and communities. We believe this increases creativity and innovation, drives business growth and enables engaged and thriving teams. We’re committed to providing an inclusive environment, free from harassment and discrimination, where all employees feel welcomed, valued and respected. Affirmative Action Employer/EOE/M/F/Disabled/Veteran Benefits Your Health, Wealth and Self Your total wellbeing is the foundation of our business, and our benefits support your financial, family and personal goals. We provide the top-tier benefits that matter to you most, including: Two medical plans (including a High Deductible Health Plan) Prescription drug coverage Enhanced Fertility benefits Flexible Spending Accounts Health Savings Account (including employer contribution) Dental and Vision Basic and Supplemental Life Insurance Short-Term and Long-Term Disability Paid and floating holidays Paid time off (PTO) Paid parental leave Paid time off to volunteer in your community Charitable Giving Match Program 401(k) with 6% company matching Employee Stock Purchase Plan Plus a broad range of career development, networking, and team-building opportunities Dig in to our full list of benefits on OUR CULTURE page. Why Do You Belong at C.H. Robinson? Standing out among the world’s largest logistics platforms, C.H. Robinson solves logistics problems for companies across the globe and across industries, from the simple to the most complex. For 100+ years, our global suite of services has innovated trade to seamlessly deliver the products and goods that drive the world’s economy. With 19 million shipments annually for 105,000 customers, our people and technology literally move the world. As a FORTUNE 200 company, FORTUNE has also named C.H. Robinson one of the World’s Most Admired Companies 2022. Headquartered in Eden Prairie, Minnesota, we are proud to be recognized as one of LinkedIn’s Top Companies in Minneapolis-St. Paul 2021. And we’re not stopping there… Join us as we collaborate, innovate, and work as one global team to make life better and more sustainable for our customers, communities, and world."
Data Engineer,Etiometry,"Boston, MA 02210 (South Boston area)",https://www.indeed.com/rc/clk?jk=8cd4ab4037cbbc26&fccid=1a05818d5afcce89&vjs=3,"Company Summary Etiometry is the market leader in predictive analytics for the Intensive Care Unit. Our system leverages real time patient data to provide clinicians with actionable information that improves care for the most vulnerable patients. In use at some of the best medical institutions across three continents, the Etiometry Platform has a proven track record in improving patients’ outcomes while reducing hospital costs. By joining our company, you will be at the forefront of clinical innovation, working with a passionate team of engineers with the common mission of changing the delivery of healthcare. You will become an integral part of a dynamic team whose work will directly impact the long-term success of the company and will provide great career development opportunities. Position Summary We are currently seeking a Data Engineer who will be responsible for storing application data and generating reports that provide business and clinical insights. Your role will be to merge application data from multiple sources into a database that can support robust reporting workflows. Additionally, you will interface with report stakeholders to design new & improved reporting capabilities. Responsibilities Design, implement, and support a scalable database solution to store application data Develop and support scalable extract, transform, and load (ETL) workflows for application data Mine data and generate reports for end users Collaborate with internal & external stakeholders to design and implement requirements for new reporting Basic Qualifications BS in computer science, systems engineering, or a similar technical field with relevant work experience. Strong understanding of CS fundamentals in software architecture, data structures, and algorithms. 2+ years of experience working with Python as a primary development language with an emphasis on data management and processing. Comfortable manipulating large data sets in different formats Experience developing automatic reports using Tableau or a similar data visualization software An understanding of data model design, database schemas, and optimizing database applications. A breadth of understanding of database technologies including both relational and non-relational solutions. Comfortable deploying software in a Unix-based environment and using job scheduling tools like cron. Proven ability to contribute to emerging or cross-disciplinary fields. Desired Qualifications Experience with Agile software development methodologies, and continuous integration and delivery. Experience producing software for a clinical setting that utilizes clinical patient data, e.g., labs, physiologic signals, and administrative data. Experience with version control software, preferably Git. An understanding of clinical (or any data-driven) research from a data aggregation and methodologies standpoint (study design, subject protections, and statistical analysis). Experience with infrastructure and application security including encryption at rest and in transit and basic user authentication schemes. Contact Us If you are interested in this opportunity, please email careers@etiometry.com with your resume."
Senior Data Engineer,Mavrck,"Denver, CO+1 location",https://www.indeed.com/rc/clk?jk=54e714437cb934e5&fccid=25b9f85ac7a01eb0&vjs=3,"Mavrck is the all-in-one, advanced influencer marketing platform enabling enterprise consumer brands to harness the power of social proof that consumers trust today. Marketers use Mavrck to discover and collaborate with influencers to create trusted content at scale. Mavrck is the #1 influencer marketing platform for the Enterprise on software review site G2, and was also named a “Leader” in Forrester’s evaluation, The Forrester New Wave™: Influencer Marketing Solutions, Q2 2020. In order to be the leading all-in-one advanced influencer marketing platform, Mavrck analyzes billions of assets to derive relevant information for our clients in a feasible time and cost. By being an early member of Mavrck’s Data Engineering team, you will have ample opportunity to work on many aspects of Mavrck’s Data Engineering platform. Day to day responsibilities include the architecture, execution, deployment and maintenance of: DataStores HBase, MySQL, Hadoop Search Technologies Solr, ElasticSearch Processing Pipelines YARN, Kafka, Spark API Provisioning & Deployments JVM ( Kotlin ) Kubernetes Data Analytics / Business Intelligence Roll Our Own ~ ad-hoc data request fulfillments Data Science ( Green Fields ) NLP Image Processing Modeling Machine Learning This role will offer the opportunity to work on the entire data stack! We don’t expect the candidate to have experience in all areas of our stack, but require a willingness and drive to learn. Curiosity and hustle is part of the DNA that makes up Mavrck’s squad and learning and building are natural consequences of that. Be a part of a creative group that solves challenging problems and has fun doing it! Mavrck is committed to building an inclusive, supportive place for you to do the best and most rewarding work of your career. If you identify with any of the following, we encourage you to apply! Required : Experience w/ JVM Technologies ( Java, Kotlin ) Experience w/ Web Technologies ( HTTP ) Experience w/ SQL & NoSQL Technologies ( ex: MySQL, HBase, Mongo, Redis) Experience w/ Search Technologies ( Solr / ElasticSearch ) Experience w/ Processing Pipelines ( YARN, Kafka, Spark ) Experience w/ Hadoop & YARN Required : An analytical mindset Some perks of being on our Squad include... Remote Work: We acknowledge (now more than ever) that you do not need to be in an office or at a desk to be successful! Unlimited PTO: To further support freedom and flexibility, we want you to take the time off when you want or need it to best recharge! Flex-Fridays: Summer Fridays are year long at Mavrck. Catch up on emails on Friday afternoons or start your weekend early - the time is yours! Paid Parental Leave: Take up to 12 weeks paid leave when a little one joins the family! Ongoing Learning: Growth is a big reason people join Mavrck and a core tenet of our culture, so we provide access to a variety of Learning and Development options, like online courses or coaching - and support you pursuing ones that you are passionate about! We Care: 401k, Health, Dental, Vision, Long Term and Short Term disability are part of a comprehensive benefits package Fun, Pet-Friendly Environment: When we’re in the office, music, jeans and t-shirts are the norm - and office dogs!! Yummy Food: Healthy snacks are always provided, and each Wednesday we enjoy catered lunches as a team. Mavrck is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires accommodation, please let us know by completing the form below."
Data Engineer 3,The Ohio State University,"Columbus, OH 43212 (West Campus area)",https://www.indeed.com/rc/clk?jk=89bc9d8c1a55bfed&fccid=eaf322a714584ea6&vjs=3,"Job Description Works as part of a team to help manage the data collection process for the International Data Evaluation Center (IDEC) & multiple related projects which design, collect & analyze data from project participants; works with engineering team to design software architecture and develop customizable software solutions using SQL, .NET framework, or other software packages; manages internal client registration process; assists Director of IT and Operations in administrating and maintaining MS SQL database, including backing up and restoring data, auditing security, monitoring performance, implementing database schema changes; manages internal and external projects, including gathering project requirements, working with staff to determine project responsibilities and setting goals and timelines; reviews and recommends new technology, assists in preparation of requests for proposals for external vendors and evaluates bids; provides advanced technical support by telephone and e-mail for end users; participates in production meetings and provides training; oversees quality assurance projects; prepares training material for internal and external clients; Responsible for oversight & maintenance of the established technology environment to ensure adherence to established internal control structures and University and EHE Office of Information Technology polices & procedures. This should include, but not limited to, appropriate segregation of duties in the processing of all technology, infrastructure, security, and maintenance activities; other duties as assigned. 70% - Software design, development, testing, maintenance, and implementation. 15% - Manage virtual server environment administration and maintenance 10% - Helpdesk support 5% - Administrative and other duties Position has a dual solid reporting line relationship to the EHE Office of Information Technology, and as such is required to participate in all standard OIT meetings & events and fully participate in the strategic direction of the College technology plan. Position has dotted reporting line to CIO, College of Education and Human Ecology Minimum Education Required Bachelor's Level Degree or equivalent combination of education and experience with a Major in computer & information science Required Qualifications Experience coding using .NET Framework & source code management; familiarization with XML technologies; experience managing MS SQL Server; experience writing SQL queries; excellent customer service skills; knowledge of quality assurance practices & project management skills; experience working with & modifying complex software packages such as SharePoint; familiarity working in a Windows environment; experience working as part of a team; data manipulation skills. DESIRED: Experience with virtualization, either VMware or Microsoft Virtual Server; .NET Framework development skills; some experience with statistical packages such as SPSS or SAS Target Salary Range: $79,000 - $85,000 Regular 40 First Shift"
Data Engineer (Remote),HP,"Remote in Spring, TX 77389+5 locations",https://www.indeed.com/rc/clk?jk=81638f2d5ef73e6f&fccid=c8eabfdb4fcf2d28&vjs=3,"We are looking for a talented Spark Data Engineer, to join a great team at HP! In this role, you'll bring advanced subject matter knowledge to solve complex business issues, and we'll look to your Spark data engineering subject matter expertise! In this role, you will frequently contribute to the development of new ideas and methods. You will also get to work on complex, interesting problems, where analysis of situations or data requires an in-depth evaluation of multiple factors. We'd love for you to provide expertise to functional project teams, and you may also participate in cross-functional initiatives. Responsibilities Designs limited enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured/unstructured data. Ability to work as a Big Data Engineer as an individual contributor or team player. Mines data using modern tools and programming languages. Analyzes design and determines coding, programming, and integration activities required based on specific objectives and established project guidelines. Executes and writes portions of testing plans, protocols, and documentation for assigned portion of application; identifies and debugs issues with code and suggests changes or improvements. Participates as a member of a project team of other data science professionals to develop reliable, cost effective and high-quality solutions for assigned data system, model, or component. Collaborates and communicates with project team regarding project progress and issue resolution. Knowledge & Skills Hands-on experience on Big Data frameworks like Spark, Hive using Scala or Python AWS services – Redshift, Athena, EMR, DocumentDB, S3 Basic knowledge of AI & Data Science Exposure to CI/CD pipeline & Github. Experience in ETL, Data Lake and Data warehouse pipeline. Experience using statistics, mathematics, algorithms and programming languages to solve big data challenges. Fluent in structured and unstructured data, its management, and modern data transformation methodologies. Ability to define and create complex models to pull valuable insights, predictions and innovation from data. Effectively and creatively tell stories and create visualizations to describe and communicate data insights. Strong analytical and problem-solving skills. Excellent written and verbal communication skills; mastery in English and local language. Ability to effectively communicate data insights and negotiate options at senior management levels. Scope & Impact Collaborates with peers, junior engineers, data scientists and project team. Typically partners with high-level Individual Contributors and Managers. Supports projects requiring data engineering solutions expertise. Education & Experience Bachelor's or Master's degree in Computer Science, Information Systems, Engineering, or equivalent. Typically 2-4 years’ experience. (This position allows 100% remote work, from any location in the United States. Applicants must be currently authorized to work in the United States on a full-time basis now and in the future) Where legally permitted, an offer of employment is conditional upon you providing proof that you are fully vaccinated against COVID-19 (as defined by the CDC) as of your first day of employment. HP is an equal opportunity employer: https://tbcdn.talentbrew.com/company/3544/v1_0/PDFs/HP%20Inc%20EEO%20Policy%20Statement%202017_Final_signed.pdf HP offers a comprehensive benefits package, including: Dental insurance Disability insurance Employee assistance program Flexible schedule Flexible spending account Health insurance Life insurance In accordance with Colorado statute, the estimated range of compensation for this job in that location, at the time of this posting, is $90-110,000. This position may be eligible for incentive pay, for openings where this is applicable. #LI-POST About HP You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you. So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference. HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere. Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are. From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!"
Big Data Engineer - Opportunity for Working Remotely Palo Al...,VMware,"Remote in Palo Alto, CA+51 locations",https://www.indeed.com/rc/clk?jk=6d105629661240f7&fccid=c762a27145bd166e&vjs=3,"The Elevator Pitch: Why will you enjoy this new opportunity? You want to be a part of an innovative company of 35000+ people working in 50+ locations worldwide and committed to building a community where great people want to work long term by living our values of passion, innovation, execution, teamwork, active learning and giving back. If you are ready to accelerate, innovate and lead, join us as we challenge constraints and problem solve for tomorrow today. You are highly motivated and would love to be part of VMware Data Engineering team working to solve complex business problems and bring digital transformations What is primary need, technical challenge, and/or problem you will be responsible for? VMware Data Engineering team is seeking a highly motivated, experienced Data Engineer within the IT Data Engineering and Analytics group. This position is responsible for hands on development work on all aspects of Data Engineer, data provisioning, modeling, performance tuning and optimization. The candidate will work closely with both Enterprise and Solution Architecture teams to translate the Business/Functional requirements into technical specifications that drive Hadoop/HANA/BI solutions to the meet functional requirements. Success in the Role: What are the performance goals over the first 6-12 months you will work toward completing? Within the first few months you will spend time learning VMware’s coding standards, products, and increasing you know how of the technology landscape around data. We want you to be curious, learning both from team members and individual study. You will collaborate with other team members and participate in architecture reviews. You will closely work with other data product owners/engineers towards taking ownership of few existing artifacts within the data landscape. You will be required to help in troubleshooting any upcoming production defects and perform production support. You will also work on delivering specific enhancements in an agile delivery model What type of work will you be doing? What assignments, requirements, or skills will you be performing on a regular basis? You will work in a fast paced and agile work environment. You will communicate and engage with a range of stakeholders. You will be responsible for hands on development work building scalable Data engineering pipelines and other data engineering/modelling work using one or more of Python, Kafka, Hadoop/Hive, Presto etc. You will have to query data using SQL or other techniques. Excellent SQL & Analytical SQL functions knowledge will be needed Understanding of SAP HANA and Knowledge of Data Integration Platforms - Informatica PowerCenter, SAP BODS, SDI, SLT (is desired but not mandatory) and will help you in understanding existing landscape You will be owner of specific modules. You will collaborate with other team members on improving dev practices, do peer code reviews and provide production support What is the leadership like for this role? What is the structure and culture of the team like? This role reports to a Senior Manager for IT Data Engineering and Analytics. IT Data Engineering and Analytics team is spread across VMware offices in Bangalore, Chennai, Palo Alto(USA) , Austin(USA) , Cork(Ireland), Beijing(China) and Costa Rica The team is headed by Director, IT Data Engineering and Analytics based in Palo Alto What are the benefits and perks of working at VMware? You and your loved ones will be supported with a competitive and comprehensive benefits package. Below are some highlights, or you can view the complete benefits package by visiting www.benefits.vmware.com. Employee Stock Purchase Plan Medical Coverage, Retirement, and Parental Leave Plans for All Family Types Generous Time Off Programs 40 hours of paid time to volunteer in your community Rethink's Neurodiversity program to support parents raising children with learning or behavior challenges, or developmental disabilities Financial contributions to your ongoing development (conference participation, trainings, course work, etc.) Healthy and local inspired snacks in all our on-site pantries ""This job opportunity is NOT eligible for employment-based immigration sponsorship by VMware"". The position is eligible for JoinCIO tag referral campaign This job may require the candidate to travel and/or work from a facility that requires full vaccination prior to entry. Category : Engineering and Technology Subcategory: Software Engineering Experience: Manager and Professional Full Time/ Part Time: Full Time Posted Date: 2022-05-23 VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape what’s possible today at http://careers.vmware.com. Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law."
Data Engineer,American Chemical Society,"Columbus, OH 43202 (Clintonville area)",https://www.indeed.com/rc/clk?jk=e7056a8f6c86efce&fccid=aa2c3da9385f84b6&vjs=3,"Job Description CAS uses unparalleled scientific content, specialized technology and unmatched human expertise to help R&D organizations across Commercial, Government and Academic sectors create groundbreaking innovations that benefit the world. As the Scientific Information Solutions Division of the American Chemical Society, CAS manages the largest curated reservoir of scientific knowledge, and for 115 years, has helped innovators mine, assess and apply that information to keep businesses thriving. The CAS team is global, diverse, endlessly curious and strives to make actionable scientific insights accessible to innovators worldwide. CAS is currently seeking a Data Engineer. This position will be located in our headquarters in Columbus, Ohio. Data engineers are responsible for supporting ingestion and transformation pipelines that handle data for analytical or operational uses across broad business areas and enterprise data domains. The data engineer often works as a dedicated member of support teams, focused on providing production stability for data processing workflows that will be used by analytics groups and data scientists who are interrogating information for predictive analytics, machine learning and data mining purposes. Duties Delivers data engineering expertise for ingestion and transformation pipelines that handle data for analytical or operational uses across wide variety of business needs and enterprise data domains. Ensures production stability for data processing workflows used by analytics groups and data scientists who are interrogating information for predictive analytics, machine learning and data mining purposes. Defines structure, integrates, governs, stores, describes, models, and maintains data in the enterprise for accuracy and usage while maintaining current state Safeguards best practices of data architecture including accountability, governance, and requirements. Perform other duties as assigned Qualifications Bachelor’s degree in Computer Science or similar discipline. Experience across a broad range of modern data science and analytics tools (e.g., SQL, Hadoop, Spark, Python, R) 3+ years’ experience in Large Big Data Development and Deployment Automation in Private/Public cloud preferably on AWS Hands on experience in big data environments such as (Cloudera or Hortonworks) Experience with DevOps, Continuous Integration and Continuous Delivery (Maven, Jenkins, Stash, Ansible, Docker) Experience with programming in Scala, Spark, Python, JavaScript and Java, as well as Unix shell skills Defines structure, integrates, governs, stores, describes, models, and maintains data in the enterprise for accuracy and usage while maintaining current state Support policies and procedures enforced by the data governance committee to ensure best practices of data architecture including accountability, governance, and requirements Experience working with XML Experience building Data Ingestion on the cloud (using tools like Glue) Understanding of principles, best practices and trade-offs of schema design for both Relational and NoSQL database systems Solid understanding of Big Data NoSQL databases/technologies (MarkLogic, Hbase, Hive, Spark, MongoDB) Strong written and verbal communication skills. Ability to travel as required Desired, but not required: Knowledge and experience in chemistry, drug discovery/development, or medical related industry CAS offers a competitive salary and comprehensive benefits package, including a generous vacation plan, medical, dental, vision insurance plans, and employee savings and retirement plans. Candidates for this position must be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future. EEO/Minority/Female/Disabled/Veteran"
Data Engineer,South Metro Fire Rescue,"Centennial, CO 80112",https://www.indeed.com/rc/clk?jk=217704c8b87e6f68&fccid=7c375d97844c93c4&vjs=3,"IT SYSTEMS - DATA ENGINEER Open Until Filled Reports To: DevOps/GIS Manager Division/Bureau: Support Service FLSA Classification: Exempt Grade: 16 South Metro Fire Rescue (SMFR) is currently accepting internal and external applications for Data Engineer. The ideal candidate will have senior-level experience as a Systems Administrator and knowledge and/or experience in Systems Integration. ** All candidates interested in applying are required to submit a resume and cover letter.** GENERAL POSITION SUMMARY This position is responsible for assisting with the implementation and maintenance of South Metro Fire Rescue’s enterprise-wide data management solution which is used for analytics and reporting. The includes the analysis, design, development, testing, implementation, and maintenance of the data warehouse solution and interfaces. The position will focus on delivering secure and reliable integrations that can be used by the organization to deliver high quality, complex, and timely data to all business units. Works closely with other members of the Data Analytics team to help improve South Metro’s ability to import and process data in a more scalable fashion. Serves as a liaison between SMFR’s product owners and enterprise data analytics team. ESSENTIAL DUTIES AND RESPONSIBILITIES (The following statements are illustrative of the duties and responsibilities of the position and do not list every duty that may be required of the employee for this position. The District retains the right to change the duties and responsibilities of the position at any time without notice.) Support the design, build and execution of post source system extraction, data lake ingestion and business transformation. Develop quality framework to ensure delivery of high-quality data and analyses to stakeholders. Implement development best practices, version control and deployment strategies to ensure product quality, agility, and recoverability. Work with internal customers to understanding the business requirements and implementing data solutions. Coordinate implementation with 3rd party contractors. Implement new functionality to existing applications to support business needs. Work with data analysts to identify business processes and propose new applications. Provide integration development and maintenance and support existing integration workflows and APIs. Contribute to the overall integration platform, enhancing processing speed, and error handling. Assess and develop long-term strategic goals for production databases in conjunction with data owners and Division/Bureau managers. Create models for data interoperability between on-prem and cloud-based solutions. Monitor, optimize and allocate physical data storage for database systems and respond to and resolve data access and performance issues. Monitor database system details within the database, including stored procedures and execution time, and implement efficiency improvements. Plan and coordinate data sharing, migration between systems. Develop, implement, and maintain change control and testing processes for modifications to databases. Design and implement redundant systems, policies, and procedures for disaster recovery and data archiving to ensure effective protection and integrity of data assets. Establish appropriate SMFR end-user database and business applications access control levels. Continually strive to improve the efficiency and usability of SMFR’s solutions, leveraging ongoing research and understanding of business needs. Always maintains a positive customer service attitude with the public, agency members, co-workers, and supervisors. Contributes to and supports the mission, vision and values of the Bureau and South Metro Fire Rescue. May be required to be on-call, remain on duty after shift-end and respond to emergency situations at any time. Performs other related assignments, as needed, or directed. MINIMUM QUALIFICATIONS EDUCATION, EXPERIENCE, LICENSES & CERTIFICATIONS (An equivalent combination of education, training, and experience that demonstrates the ability to perform the duties of the position is qualifying.) Bachelor’s degree in Computer Science or related field; or equivalent supplemented by advanced technical training in a related technology field. Five years of experience with Microsoft SQL Server database administration or an equivalent combination of education, training, and experience. A minimum of three years of experience with Microsoft Azure (or similar) and other business Software as a service (SAAS) solution. Minimum of 5 years’ experience with Microsoft SQL Server 2012 or higher. Minimum of 5 years’ IT operation experience with strong understanding of database structures, theories, principles, and practices, database tuning and troubleshooting and business application support. Possess and maintain a valid Colorado Driver’s license. Possess and maintain an acceptable driving record in accordance with the SMFR’s Driving Records Policy. Must obtain CPR certification within one (1) year of hire. NECESSARY KNOWLEDGE, SKILLS AND ABILITIES Experience with data warehouse technical architectures, ETL/ELT reporting/analytic tools and scripting. Experience with Azure services including, Data-pipeline and other big data technologies. Experience with scripting (Python experience is a strong plus). Experience with data processing flowcharting techniques. Windows operating system and hardware experience to include basic administration of a server including service packs and hot fixes. General knowledge of networking to include IP, DNS, Load Balancing. Relies on experience and judgment to plan and accomplish goals. Works with project stakeholders daily. Knowledge of applicable data privacy practices and laws. Outstanding organizational skills with the ability to prioritize tasks and manage projects from concept to production; must be able to work independently with minimal supervision. Strong understanding of the organization’s goals and objectives. Also, remains familiar with South Metro’s standard concepts, practices, and procedures. Excellent written, verbal, and interpersonal communication skills; including the ability to present ideas in both business-friendly and user-friendly language. Ability to brainstorm with others, thrive in a collaborative and productive team environment, multi-task and quickly adapt to change. Excellent customer service skills with demonstrated professional demeanor. Demonstrated interpersonal skills to establish and maintain effective working relationships with department member, co-workers, supervisors, citizens, community contacts, elected officials, members of other governmental agencies. Able to establish and maintain cooperative working relationships both within and outside SMFR, exercise good judgment in representing SMFR to external personnel and agencies. Commitment to personal and professional growth by studying state-of-the-art development tools, programming techniques, and computing equipment; participating in educational opportunities; maintaining personal networks; participating in professional organizations. SUPERVISION RECEIVED Work is performed under general oversight and guidance from the DevOps/GIS Manager. SUPERVISION EXERCISED Supervise project members as assigned. EQUIPMENT and SYSTEMS Requires frequent use of personal computer, including various software packages, database and spreadsheet programs, District automobiles, calculator, telephones, mobile computers, copy machines, cameras, printers, uninterruptable power supplies, network equipment, tools, and other general office equipment. PHYSICAL DEMANDS While performing the duties of this job, the employee is regularly required to perform climbing, balancing, stooping, kneeling, crouching, crawling, reaching, standing, walking, pushing, pulling, lifting, fingering, grasping, feeling, talking, hearing, seeing and repetitive motions. Medium Work: Exerting up to 50 pounds of force occasionally, and/or up to 20 pounds of force frequently, and/or up to 10 pounds of force constantly to move objects. Specific vision abilities required by this job include close and distance vision acuity and the ability to adjust his or her focus, allowing a broad field of vision. Visual and fine/gross motor skills enabling the safe operation of a vehicle during normal as well as hazardous weather situations. WORK ENVIRONMENT AND GENERAL INFORMATION The primary responsibilities of this job are performed in a climate-controlled office environment. The noise level in the work environment is usually moderate. BENEFITS South Metro Fire Rescue’s compensation philosophy is designed to attract and retain highly skilled and motivated employees. As such, SMFR’s compensation is more than base pay. All regular fulltime SMFR employees enjoy a total compensation package including: base wages, leave accruals, medical, dental, vision and life insurance employer paid premiums, Retiree Health Savings, Death & Disability and employer paid pension contributions as well as a positive work culture including a robust Fitness, Wellness and Rehabilitation Program, educational opportunities and support, job security and other positive non-monetary values which are intended to collectively position SMFR as an employer of choice in its geographic area. SMFR recognizes that being an employer of choice has different meaning to different people depending on what elements a person highly values. But SMFR's overall goal is to be a great place to work."
Data Engineer,Zonar Systems,"Tukwila, WA",https://www.indeed.com/rc/clk?jk=dfa4974660167cd9&fccid=3d51e7e4c3c6759e&vjs=3,"One of Seattle’s top technology companies, Zonar Systems is seeking a highly capable Data Engineer. As part of the Zonar Business Technology organization, the IT Data Engineer is primarily responsible for owning, maintaining, and optimizing our SQL-based Zonar data warehouse platform and related operational functions. This platform aggregates data associated with Zonar business operations and related data sets and is utilized by numerous departments across Zonar Systems for internal decision support and to deliver customer-facing reporting and analysis. This position will own the data warehouse architecture, databases both cloud and on prem, SQL table structures, and related stored procedures. This position will also directly contribute to the support and monitoring of related data processing routines and operations of the related technology stack. This role also supports the broader data footprint managed within our Business Technology group and works closely with the Data Analytics team in providing data mining and data analysis support for requests from the business as well and other initiatives. The person who fills this role will also be the driving force to help ensure ongoing data integrity of our datasets and identify, develop, and support related data integrity monitoring solutions. . WHAT YOU WILL DO Develops and maintains scalable data pipeline architecture and datasets of varying size and complexity. Maintains and provides oversight on data warehouse structure, processes, and related operations. Implements and maintains processes and systems to monitor data quality, timeliness, and availability of data within the Zonar Data Warehouse. Collaborates with Analytics, the broader Business Technology organization, and other business teams to improve data models that feed the data warehouse and related business intelligence tools. Contributes to identification and owns deployment of database schema changes and related table updates specific to the Zonar data warehouse and other databases managed within Business Technology. Supports and monitors data processing and delivery mechanisms to ensure data/reports are available within our Power BI and SSRS platforms. Identifies on-going optimization opportunities relating to database infrastructure and database design that supports scalability and supportability. Identifies and recommends enhanced data collection procedures that support data integrity and relevancy of data sets. Builds and maintains SSIS packages as needed. Monitors data warehouse operations across our DEV, TEST, and PROD server stack Develops and operationalizes related data standards, quality, and security/access across assigned data sets. Assesses the quality and impact of new data sources and data gathering techniques. ADDITIONAL RESPONSIBILITIES AND DUTIES Works with team members or stakeholders to assist with data-related technical issues Collaborates and consults with the Data Analytics team and other internal teams in support of ad-hoc analysis efforts or requests. Follows all company policies and procedures Upholds Zonar’s Quality Policy and Objectives Performs all other duties as required Overtime as required WHAT YOU WILL BRING TO THE TEAM Excellent written and verbal communication skills. Can effectively communicate ideas and results in narrative form Ability to perform root cause analysis on internal and external datasets and processes to answer specific business questions and identify opportunities for improvement. Ability to identify and recommend operational improvements to data collection routines. Ability to design, build, and maintain operational databases Ability to build and maintain ETL routines that process data from source systems such as CRM, ERP, or like business systems (both on-prem and cloud-based solutions) Ability to effectively build/present analysis using data visualization tools such as PowerBI, Tableau, or like tools. Ability to triage/troubleshoot data storage systems or related technical platform issues Ability to leverage tools such as R, Python, and SQL to import, process, summarize, and analyze data. Ability to understand various data structures and common methods in data transformation Ability to apply a strong business sense and logic skills to balance data-driven decisions with intuition Ability to operate independently, manage competing priorities, multi-task, and resolve conflicts Ability to manage complex datasets, including querying, aggregation, analysis, and visualization Knowledge of machine learning techniques and algorithms Bachelor’s degree in a quantitative field, such as Computer Science, Statistics, or Applied Mathematics or combination of professional certification (e.g., Google Certified Professional-Data-Engineer certification or like certification) and 5+ years related experience WHAT SETS YOU APART 5+ years of data engineering experience 3+ years of data or business analysis experience preferably within in a technology focused company Advanced knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Hands-on experience with SQL database architecture and design. Experience with data transfer and connectivity tools such as cData, Kingswaysoft or like ETL/ELT tools Experience with scripting languages such as Python or Java required Experience with statistical computing solutions such as R or like solutions required Experience with various machine learning/statistical modeling data analysis tools and techniques a plus ABOUT US Founded in 2001—and acquired by Continental AG in 2016—Zonar has pioneered smart fleet management solutions throughout pupil, commercial construction, mass transit and over-the-road trucking industries. Zonar’s mission is to enhance the safety, performance, and success of our customers by transforming the delivery of innovative insights for commercial fleets around the world. Zonar achieves this by helping fleets of all sizes maximize the use of their assets with solutions dedicated to improving compliance, efficiency, maintenance, ridership visibility, safety, and tracking. Cloud-based services with open APIs drive Zonar's smart fleet solutions by making it easy for fleet owners and managers to stay connected to their fleets and drivers and operators to dispatch. Headquartered in Seattle and part of the Continental family, Zonar also has a Technology Development Center in downtown Seattle and a distribution center outside of Atlanta."
Data Engineer,"Zoom Video Communications, Inc.","Remote in San Francisco Bay Area, CA+3 locations",https://www.indeed.com/rc/clk?jk=ade55034cb47590d&fccid=e32d933c26e873c8&vjs=3,"Work Styles at Zoom In most cases, you will have the opportunity to choose your preferred working location from the following options when you join Zoom: in-person, hybrid or remote. Visit this page for more information about Zoom's Workstyles . About Us Zoomies help people stay connected so they can get more done together. We set out to build the best video product for the enterprise, and today help people communicate better with products like Zoom Contact Center, Zoom Phone, Zoom Events, Zoom Apps, Zoom Rooms, and Zoom Webinar. We’re problem-solvers, working at a fast pace to design solutions with our customers and users in mind. Here, you’ll work across teams to deliver impactful projects that are changing the way people communicate and enjoy opportunities to advance your career in a diverse, inclusive environment. Zoomies help the world connect — and deliver happiness while doing it. We set out to build the best video conferencing product for the enterprise, and today help people communicate better with products like Zoom Phone, Zoom Rooms, Zoom Video Webinars, Zoom Apps, and OnZoom. We’re problem-solvers and self-starters, working at a fast pace to design solutions with our customers and users in mind. Here, you’ll work across teams to dig deep into impactful projects that are changing the way people communicate, and enjoy opportunities to advance your career in a diverse, inclusive environment. The Data Science team lies at the foundation of Zoom’s success - you'll be working cross-functionally with teams of engineers, scientists, marketers, and product professionals on some of the most critical projects in the company - whether it's exploratory research to predict user behavior, or running experiments to optimize untapped areas of growth, or developing machine learning models that deliver “happiness” to our users more consistently and at scale. If you are passionate about data engineering and looking to join a fun and fast-moving team, we’d love to meet you! Our team is taking Zoom's data culture to the next level by integrating predictive models into our infrastructure, and we are looking for someone like you to help us get there! This role is based in most places in the US. Responsibilities Partner with architecture and other senior leads to address the data needs of our rapidly-growing business. Join a group of passionate people committed to delivering “happiness” to our users and to each other Partner with data scientists, sales, marketing, operation, and product teams to build and deploy machine learning models that unlock growth Build custom integrations between cloud-based systems using APIs Solve complex business problems using efficient design patterns and clean code in any array of languages (across several languages such as Java, Python, Scala and or SQL), transform raw data sources into easily accessible models. Design, build, and launch new data models that provide intuitive analytics to the team Build data expertise and own data quality for the pipelines you create Design solutions that integrate customer data into a seamless ecosystem that respects data privacy standards and regulations across the globe. Learn, laugh and grow into the best engineer of your life. Requirements Bachelor's/Masters degree in Computer Science, Management of Information Systems, or equivalent experience 3+ years of relevant software engineering experience (Python, Scala and Java) in a data-focused role Prior experience shipping scalable data solutions in the cloud (AWS, Azure, GCP) and database technologies such as Snowflake, Redshift, SQL/NoSQL and or columnar databases Experience in solving complex data processing and storage challenges through scalable, fault-tolerant architecture Experience in designing and building highly scalable and reliable data pipelines (Airflow, Python, columnar datastores). Passionate about data engineering, analytics, distributed systems and solving complex data problems. Passion for creating data infrastructure technologies from scratch using the right tools for the job We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. Zoom is proud to be an equal opportunity workplace and is an affirmative action employer. All your information will be kept confidential according to EEO guidelines. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records and any qualified applicants requiring reasonable accommodations in accordance with the law. If you need any assistance or accommodations due to a medical condition, or if you need assistance accessing our website or completing the application process, please let us know by emailing us at careers@zoom.us . Colorado Salary Range or On Target Earnings: Minimum: $97,920.00 USD Maximum : $181,170.00 USD In addition to the base salary and/or OTE listed, Zoom has a Total Direct Compensation philosophy that takes into consideration base salary, bonus and equity value. Information about Zoom’s benefits is here . Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. We also have a location based compensation structure; there may be a different range for candidates in other locations. Zoom requires all U.S. employees who will work in person at a Zoom office, attend in-person Zoom meetings or have in-person customer meetings to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law. Explore Zoom: Hear from our leadership team Browse Awards and Employee Reviews on Comparably Visit our Blog Zoom with us! Find us on social at the links below and on Instagram View more jobs, sign up for job alerts and join our talent community. Visit the Zoom careers site . #LI-Remote"
Senior Data Engineer,Skupos,"Remote in Denver, CO 80202",https://www.indeed.com/rc/clk?jk=0790de1e1f0735e1&fccid=52fe920cf8502d06&vjs=3,"Company. What we are building: Skupos drives revenue growth across all segments of the convenience retail industry through technology that connects both retailers and brands to their shoppers. With a focus on independent stores and small chains which make up nearly 80% of the market, the Skupos platform enables both retailers and brands to compete through better understanding and serving their customers. Founded in 2016, a growing network of 14,000+ customers across all 50 states rely on Skupos to boost sales volume and increase their customer base. Role. An overview of the opportunity: At Skupos, data is everything. Our data integrates the forgotten, fragmented world of mom-and-pop corner with the glitzy, gigantic world of CPG conglomerates. With tens of millions daily transactions, Skupos is looking for a data engineer to wrangle and tame our data flows, expand and optimize our data and data pipeline architecture. Team. The team and our people: This role will be part of the Data Platform team, the core functional team building our data products. The team works closely with the Data Infrastructure, Product and BI teams. Responsibilities. Your responsibilities will include: Building and maintaining the data and reporting layers for customer facing products. Collaborate closely with Data Infrastructure and Analytics teams to build complex data pipelines to deliver CICD complete deployment, move data cross - platforms including real time systems. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Work with the Data Infrastructure team to build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies. Create data tools, analytical datasets for Data Analytics and Machine Learning teams that assist them in building and optimizing our product Maintain and deliver continuous improvement of core projects through automation and process enhancement Work with all data teams and consumers to strive for greater functionality in our data systems Partner with engineers, product managers, and data scientists to breakdown data requirements, analyze source data sets, address data quality issues and effectively build and automate ETL pipelines at scale. Partner with ML engineers, data infrastructure team to define and own Data engineering tools, products and processes in place and define/set SLAs for each. Have deep understanding of existing data integration challenges and solutions with optimal ETL solutions and querying techniques Experience and Skills. Candidates should have: Bachelor's degree or equivalent, ideally in a technical or quantitative field (advanced degree is a plus). 4-6+ years of experience working with SQL Advanced with proficiency with Python, Java, or Scala in a production environment 1-3 years of experience building and optimizing large-scale data pipelines, architectures and data sets. Recent experience (2+ years) with a modern data warehouse (e.g., Snowflake, BigQuery, Redshift, Pentaho) Experience with data warehousing architecture and understanding of data modeling concepts and best practices (e.g., normalization/denormalization). Production experience with Spark Familiarity with stream-processing platforms and message-queues (e.g. Flink, Hadoop, Kafka) is a plus Salary is based on experience and location. Salary range based on Denver Market: $140,000 - $155,000. Benefits. What we offer: Competitive salary Medical, dental, and vision insurance 401(k) retirement savings plan Discretionary time off (DTO) Wellness stipend And more! A Note on Covid... We are fortunate to continue to grow during this unfortunate time. Our top priority is to ensure the health and safety of both our current and future Skupeeps. As of July, our physical office spaces have reopened on a voluntary basis. Our Skuad members are allowed onsite if they are fully vaccinated (2 weeks past final vaccine dose). That being said, we will continue to manage our interview process virtually, don't be surprised if children or pets make an appearance. We deeply care about you as our candidate, so let the People Team know if there's anything we can do to make your interview process go more smoothly - we are in your corner!"
Data Engineer III,Rackspace,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=0329875c392d717d&fccid=b60c9324aeb7df96&vjs=3,"Job Profile Summary Applies data extraction, transformation and loading techniques in order to connect large data sets from a variety of sources. Creates data collection frameworks for structured and unstructured data. Develops and maintains infrastructure systems (e.g., data warehouses, data lakes) including data access APIs. Prepares and manipulates data using Hadoop or equivalent MapReduce platform. Responsible for adhering to company security policies and procedures and any other relevant policies and standards as directed. Career Level Summary Requires in-depth conceptual and practical knowledge in own job discipline and basic knowledge of related job disciplines. Solves complex problems. Works independently, receives minimal guidance. May lead projects or project steps within a broader project or may have accountability for on-going activities or objectives. Acts as a resource for colleagues with less experience. Level at which career may stabilize for many years or until retirement. Critical Competencies Serves as an expert in the efficient and effective gathering and organization of data. Experienced in cloud migration/building data pipelines on Cloud using Python and pushing data to BigQuery Utilizes a strategic approach to plan for the use of complex data to create synergies across teams. Selects appropriate analytical models and tools to analyze big data sets, develop business recommendations and support decision-making. Develops and shares expert knowledge of customer's organization structure (e.g., geographies, business units), operations and business processes, and how they support the customer's strategic objectives, in order to identify customer needs Identifies customer’s key decision makers and leverages an understanding of their unique perspectives and priorities when building relationships Maintains thorough knowledge of customer’s industry, including key market and economic factors impacting business performance, as well as competitive landscape, in order to assist in creating effective customer solutions Demonstrates an understanding of complex offerings and tailors solutions to meet the unique needs of the customer. Demonstrates advanced understanding of products, technologies, offerings, etc. and coaches other colleagues in building their knowledge. Leverages knowledge of competitors’ products and services as well as their strengths and weaknesses to compare choices. Key Responsibilities Other Incidental tasks related to the job, as necessary. Build Pipelines reading data from different sources like Postgress, Oracle into google cloud using Airflow and Bigquery Build complex ETL code Build complex SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL Work on Data and Analytics Tools in the Cloud Develop code using Python, Scala, R languages Work with technologies such as Spark, Hadoop, Kafka, etc. Build complex Data Engineering workflows Work with team to solve a variety of problems using machine learning techniques, and implement cloud-based solutions for customers Create complex data solutions and build data pipelines Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates Capture and share industry best practices amongst the community Attend and present valuable information at Industry Events Knowledge Basic conceptual knowledge on cloud Data platform Services and solutions. Knowledge on ETL /ELT data pipelines on Cloud Knowledge of building ETL /ELT data pipelines on Cloud: participate in code reviews, active player in building cloud data solutions hadoop ecosystem, RDBMS, DW/DM, learn from deep architectural discussions Skills Devises new methods and procedures for collecting data; performs complex data analyses and presents findings on the underlying principles, reasons or facts. Utilizes knowledge and experience to perform data and database management responsibilities on multiple systems and to assist with policy and procedure development. Demonstrates proper techniques for preparing and filing complex regulatory correspondence in an organized and concise format, sending documents to regulatory agencies as requested. Education Bachelor's or Masters Degree in Computer science, Information Systems or related technical degree required Certifications Cloud certifications such as GCP Professional Data Engineer or Microsoft Data / AI certifications. Experience 5 – 7 years of experience in the field of role required. Physical Demands General office environment: no special physical demands required. May require long periods of sitting and viewing a computer monitor. Schedule flexibility to include working weekends and/or evenings and holidays as required by the business for 24/7 operations. Must be able to lift 50 lbs over-head. Travel Occasional domestic/international travel, less than 50% Disclaimer The above information has been designed to indicate the general nature and level of work performed by employees in this classification. It is not designed to contain or to be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of the employee assigned to this job. The following information is required by the Colorado Equal Pay Transparency Act and applies only to individuals working in the state of Colorado. The anticipated starting pay range of Colorado applicants for this role is $81 ,600 –$105,800. Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, licenses and certifications, and specific work location. Information on benefits offered is here About Rackspace Technology We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future. More on Rackspace Technology Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know."
Data Integration Engineer,The Orvis Company,+1 locationRemote,https://www.indeed.com/rc/clk?jk=93cee5992ba16886&fccid=8f6d03f4be47dc58&vjs=3,"As a Data Engineer on our Orvis Technology team, you will support data delivery for new and existing applications. The role is a part of a team responsible for both maintaining and building data integrations for critical Orvis systems. You will work with an impactful and highly motivated team of product owners, engineers, program managers, and architects. You will be responsible for combining technical expertise with best practices and standards to align solutions with business strategy. You will present and communicate to all levels of the organization, participate in development, and ensure the overall solution is appropriate. We are looking for talented people who align with Orvis’ Mission and demonstrate our Core Values in your interactions with customers and team members. Responsibilities Technical knowledge of Enterprise Application Integration, Micro Services architecture, API Architecture including familiarity with Integration Patterns (Messaging, Routing, Data Transformation etc.) Daily hands-on responsibilities to code, test and stage applications and application interfaces consistent with established practices and standards. Responsible for security, performance, manageability, quality, scalability, and consistency of integration architecture across systems Analyze, design, and implement integrations for on-premises and cloud solutions Be a team player and a thought partner to steer the collective technology team to success Able to work with Program Managers, provide information for leadership updates and successfully collaborate to deliver finished products Conduct unit, system and user acceptance testing to ensure quality implementations. Qualifications 2+ years' experience with design and maintenance of enterprise data solutions including expertise in developing complex SQL, stored procedures, functions and data transformations 2+ years of Database Management and Administration experience 2+ years of experience with Microsoft SQL Server Integration Services Strong experience architecting, implementing, and supporting enterprise-grade SOAP and REST web services with a variety of data formats (e.g. JSON, XML, CSV) Experience with one or more cloud/SaaS solutions for ERP, CRM, e-Commerce, or mobile a plus (e.g., Salesforce, NetSuite/Oracle, Manhattan Associates) Demonstrate knowledge of on-premises/cloud-based infrastructures, SDLC pipelines, and deployments/configurations and definition/evangelism of best practices/standards Strong knowledge of SAFe and solid track record working in an Agile setting Demonstrate a working knowledge of one or more platforms (XML, Java, C#, VB, SQL, .Net). The ability to code, test and stage functional products in these environments is a plus. Sense of humor and desire to have fun while building amazing things About Orvis We are a family-owned, international multichannel retailer, and we are proud of our culture, in which associates deliver world-class customer service, and exceptional products & learning opportunities. We are passionate, curious, and approachable. Our team members enjoy teaching, mentoring, and solving problems. We love to develop and share our equipment, apparel, and expertise to create deeper connections and authentic experiences. We are the most-trusted lifestyle brand rooted in the innovation of fly-fishing and wing shooting. Everything we make, offer, or share flows from generations of curiosity on the water, in the field, and around the fire. The natural world is at the core of our passions and our business. We know the power that outdoor experiences provide and live for the anticipation it brings. And we must preserve these places for future generations. This is why we commit 5% of pre-tax profits to protecting what we love. We know our people are our most valuable asset. We empower our team members to take care of the customer and exceed expectations. To be at their best, we also recognize that our team members need time to recharge and connect with nature. We believe in ensuring our teams have great work/life balance and offer a comprehensive benefits package including: Medical, vison, and dental coverage Employer-matched 401(k) savings plan Paid time off and holiday pay Parental leave Generous associate discount, including discount opportunities with other brands"
Data Engineer,EKIN Solutions,"Herndon, VA 20171",https://www.indeed.com/rc/clk?jk=23dee12fe27745db&fccid=6fd27b81ba0b10f4&vjs=3,"Master’s or equivalent in Computer Science, Information Systems Technology, or Computer Engineering + 1 year of experience or Bachelor’s + 5 years of post -Baccalaureate progressive experience in Database Application Development (Ref#2)"
Remote Hadoop Big Data Engineer,IBM,"Remote in New York, NY 10001",https://www.indeed.com/rc/clk?jk=a6c810c1538af47a&fccid=de71a49b535e21cb&vjs=3,"Introduction At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk. Your Role and Responsibilities Duties of Remote Hadoop Big Data Engineer: Liase directly with users along with application teams to service requests and troubleshoot issues as they arise with regards to query / cluster performance. Review the environment along with Cloudera and make recommendations for improvements / enhancements Manage user queries / requests Execute projects in the book of work (OS upgrades / adding new data nodes to the cluster / etc) Analyze / make recommendations to improve cluster performance. Agree with app teams and incorporate into the book of work. Operate as part of the Specialized Infrastructure Unix team. Required Technical and Professional Expertise Required Experience for Hadoop Big Data Engineer: Expertise with Cloudera Manager (Hadoop) 3+ years engineering Hadoop Good knowledge of Apache Impala / Hive / Spark 2+ years with Linux systems administration duties and good knowledge of Linux fundamentals (preferably Red Hat Enterprise Linux) Preferred Technical and Professional Expertise Additional Desired Experience of Remote Hadoop Big Data Engineer: Any experience with Spark, Pyspark, Python Any Client facing/consulting experience Previous IBM project experience About Business Unit IBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet. This job requires you to provide your COVID-19 vaccination status with supporting documentation, where legally permissible. Your Life @ IBM Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities. Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone. It's time to define your career. About IBM IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world. Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world. Location Statement IBM offers a wide range of resources for eligible IBMers to thrive both inside and outside of work. In addition to a competitive benefits program consisting of medical and life insurance, retirement plans, and time off, eligible employees may also have access to: 12 weeks of paid parental bonding leave. Family care options are also available to support eligible employees during COVID-19. World-class training and educational resources on our personalized, AI-driven learning platform. IBM's learning culture supports your restless attitude to grow your skills and build the depth and scale of knowledge needed to achieve your career goals. Well-being programs to support mental and physical health. Financial programs that empower you to plan, save, and manage your money (including expert financial counseling, 401(k), IBM stock discount, etc.). Select educational reimbursement opportunities. Diverse and inclusive employee resource groups where you can network and connect with IBMers across the globe. Giving and volunteer programs to benefit charitable organizations and local communities. Discounts on retail products, services, and experiences. We consider qualified applicants with criminal histories, consistent with applicable law. IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship. Being You @ IBM IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
Senior Software Engineer/Software Engineer - Data & Analytic...,Liberty Mutual Insurance,+1 locationRemote,https://www.indeed.com/rc/clk?jk=218c0e00169bd300&fccid=f33a9750898d12d4&vjs=3,"At Liberty Mutual, technology isn't just a part of our business, it's what drives us forward. We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as an Agile team within a Fortune 100 company, we are on the front edge of an IT transformation for how people work and deliver solutions. Our Data & Analytics Engineering is actively searching for a highly productive member of a distributed, dynamic agile team to serve as a technical expert in analysis, design, coding, and testing innovative data reporting solutions and analytics. This position will support the Business Intelligence community in Global Retail Markets (GRM). Job Summary: In this role you will work collaboratively on an agile team to develop and enhance complex systems and/or software from user stories and technical/architectural specifications. You will analyze complex technical system problems and create innovative solutions that exceed customer expectations. This is a fast-paced environment providing rapid delivery for our business partners. You will be working in a highly collaborative environment that values speed and quality, with a strong desire to drive change and foster a positive work environment as we continue our agile transformation journey. You will have the opportunity to help lead this change with us as we grow this culture, mindset and capability. Note: This is a range posting, candidates will be considered at the Engineer and Senior Engineer level. In this role you will: Work in a dynamic and exciting agile environment with Engineers, Scrum Masters, and Product Owners to develop creative data-driven solutions that meet business and technical initiatives Improve speed to market by focusing on current Business Intelligence needs as well as building out the long-term strategic data solutions using AWS, Java, Python, Lambda, as well as other modern data technologies Provision, install, and support vendor software packages in a cloud environment, including Microstrategy, Denodo, and PowerBI. Leverage development skills to build and support configuration as code, building secure deployment pipelines to AWS. Demonstrate open minded and collaborative approach to creating innovative technical solutions Analyze data and technical system problems to design and implement effective, flexible solutions Handle end-to-end development, including coding, testing, and debugging during each cycle Develop automated tests for multiple scopes (Unit, System, Integration, Regression) Mentor new and junior developers Identify and recommend appropriate continuous improvement opportunities Bachelor's or Master's degree in technical or business discipline or equivalent experience, technical degree preferred Experience developing back end, data warehouse technology solutions Experience with AWS (such as S3, Snowflake, Athena, EMR) Experience with UI/UX design thinking Extensive knowledge of IT concepts, strategies, methodologies. Experience working with agile methodologies (Scrum, Kanban, XP) and cross-functional teams (Product Owners, Scrum Masters, Developers, Test Engineers) Versed in diverse technologies and new technical architecture principles and concepts Demonstrates leadership and active pursuit of optimizing CI/CD process and tools, testing frameworks and practices Must be proactive, demonstrate initiative, and be a logical thinker Must be team oriented with strong collaboration, prioritization, and adaptability skills required Additional Qualifications: Understanding of Cloud / Hybrid data architecture concepts Understanding of insurance industry and products Excited by trying new technology and learning new tools At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That's why we provide an environment focused on openness, inclusion, trust and respect. Here, you'll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession. We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more, please visit https://www.libertymutualgroup.com/about-lm/careers/benefits Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG's Insider Pro and Computerworld's 2020 list. We have been named by Forbes as one of America's Best Employers for Women and one of America's Best Employers for New Graduates—as well as one of America's Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusion Liberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran's status, pregnancy, genetic information or on any basis prohibited by federal, state or local law. 17"
ML Platform Data Engineer- Big Data,"Zoom Video Communications, Inc.","Remote in San Francisco Bay Area, CA",https://www.indeed.com/rc/clk?jk=b8046dd9f3334eb4&fccid=e32d933c26e873c8&vjs=3,"Work Styles at Zoom In most cases, you will have the opportunity to choose your preferred working location from the following options when you join Zoom: in-person, hybrid or remote. Visit this page for more information about Zoom's Workstyles . About Us Zoomies help people stay connected so they can get more done together. We set out to build the best video product for the enterprise, and today help people communicate better with products like Zoom Contact Center, Zoom Phone, Zoom Events, Zoom Apps, Zoom Rooms, and Zoom Webinar. We’re problem-solvers, working at a fast pace to design solutions with our customers and users in mind. Here, you’ll work across teams to deliver impactful projects that are changing the way people communicate and enjoy opportunities to advance your career in a diverse, inclusive environment. About the Team As Zoom grows and expands, so do the data science and machine learning pipelines that are currently running independently of each other. As we create a Centralized Data Science and Machine Learning Platform, there's a need to ingest and model data into the Platform for easy access, exploration, and analysis. You will help us standardize data models and data pipelines across multiple ML pipelines, bringing robustness, scalability, and maintainability. About the Role Design and build data models for optimal storage and retrieval and to meet business requirements. Participate in design discussions about new features and ensure real-time technology integrates seamlessly with other pieces of the platform Work collaboratively with engineering, data science and analytics teams Apply software engineering principles to create reliable, automated data solutions to solve critical business needs Coach and mentor engineers to help scale up the engineering organization Evaluate and advocate for modern technologies to accelerate delivery and improve engineering efficiency Participate in an on-call rotation About You A deep understanding of SQL and data pipelines Proficiency in DBT, Airflow, and cloud data warehouses such as Snowflake, Delta Lake, and Redshift Expertise in Python or equivalent programming language [GoLang, Java, C++, etc.] 5+ years of experience in AWS, Databricks, Spark, Hadoop, the ELK stack, Kafka etc. 5+ years of experience with reliability engineering specifically in areas such as data quality, data observability and incident management. You enjoy making sense of chaos and data We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. Zoom is proud to be an equal opportunity workplace and is an affirmative action employer. All your information will be kept confidential according to EEO guidelines. We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records and any qualified applicants requiring reasonable accommodations in accordance with the law. If you need any assistance or accommodations due to a medical condition, or if you need assistance accessing our website or completing the application process, please let us know by emailing us at careers@zoom.us . Zoom requires all U.S. employees who will work in person at a Zoom office, attend in-person Zoom meetings or have in-person customer meetings to be fully vaccinated. Zoom will consider requests for reasonable accommodations for religious or medical reasons as required under applicable law. At Zoom, we care about our employees, their families, and their well-being. As part of our award-winning workplace culture and commitment to delivering happiness, our benefits program offers a variety of perks, benefits, and options to help employees maintain their physical, mental, emotional, and financial health; support work-life balance; and contribute to their community in meaningful ways. To view our benefits, click here . Explore Zoom: Hear from our leadership team Browse Awards and Employee Reviews on Comparably Visit our Blog Zoom with us! Find us on social at the links below and on Instagram View more jobs, sign up for job alerts and join our talent community. Visit the Zoom careers site . #LI-Remote"
AWS Data Engineer,Beta Search,"New York, NY",https://www.indeed.com/rc/clk?jk=28de92daf2b5a29a&fccid=393bb9b22cc16ac8&vjs=3,"Job Category: Information Technology Job Type: Full Time Job Location: New York As our Data Engineer you will be responsible for delivery of data solutions supporting analytic and reporting efforts. Specifically, the position will focus on the creation of data pipelines to optimize the architecture, design, governance, and movement to support self-service BI as well as performing statistical analysis, correlations, etc. Responsibilities include leading, defining, designing, building, testing and maintenance of the AWS data architecture, including ingestion of data from S3 (Hadoop) across various source types – Parquet, csv, text, etc. Responsible for the architecture of the transformation and integration layers utilizing various ETL tools and Redshift to create optimal structures to support centralized usage across BU and analytics. Responsible for helping propagate knowledge across this space to other team members and help to promote standards and best practice definition. You Have Deep understanding of AWS data architecture, design, data modeling, and optimization of data solutions to support analytics and BI solutions requiring very fast query resolution Experience designing solutions across disparate structures utilizing Redshift and other AWS tools and services Ability to collaborate with multiple stakeholders, develop business requirements and design data solutions across the AWS environment Problem anticipation, problem solving and issue resolution skills Ability to influence organizational change Strong interpersonal and communication skills with the ability to proactively build and leverage relationships internally and externally An outstanding ability to communicate and share ideas across the organization Ability to manage multiple tasks to deliver according to schedule and priority Bachelor’s degree in Business, Technology or equivalent Demonstrated successful business analysis, design and development of data solutions, or equivalent combination of education and experience in data solution architecture, design, and solution delivery Multiple years of interaction with business and technology partners to collect and translate business needs into service deliverables Experience with Data Visualization and Business Intelligence tools Extensive development of data solutions across disparate sources – Hadoop, Hive, Microsoft SQL, Redshift, etc. You Will Focus on data architecture, design, and delivery of data solutions across the AWS environment Design, implement, and ensure data solutions are built, maintained, and updated based on established business requirements Collaborate with leadership to provide meaningful and credible feedback on data architecture, design, and delivery Work autonomously, in team settings and in partnership with management to review data design and solutions Identify information needed, sources, and use tools to deliver optimal solutions per the use case Partner with IT, Database Administrators, and business owners to ensure all data/data sources needed for reporting and analytics are defined and incorporated into the appropriate data solution Develop, implement, communicate, and maintain automated processes adhering to the deployment and support standards Develop data quality metrics that identify gaps and ensures compliance with standards across the enterprise Lead analysis, estimation, planning and implementation of data solutions Serve as a liaison with functional groups around data and BI. Lead planning and execution of multiple, simultaneous initiatives Conduct business data analysis and design to support effective report development and business decisions Leverage external best in class reporting solutions to support data needs Understand the data ecosystem to support placing data in the correct infrastructure Create the processes to show where and how data should be moved / aggregated once it is landed from source systems into the data lake environment (S3) Create the design and models for combing data across sources for efficient query patterns from BI and analytics Ensure governance standards are followed Review ongoing performance of existing assets and modify if needed Fast-track the use of Redshift and other AWS tools & services across the data lake environment"
Data Engineer,Loudoun County School District,"Hybrid remote in Ashburn, VA 20148",https://www.indeed.com/rc/clk?jk=0a61e42c703e7bb9&fccid=5eef5771ce4fadb1&vjs=3,"Position Overview The Data Engineer is a member of the Data Science & Digital Solutions team and is responsible for providing technical support for the big data environment. The Data Engineer is available to assist the Data Architects to provide production databases that offer the highest reliability and performance possible. The Data Engineer is challenged to work with data base architecture, data intergrations and system operations to help achieve a state-of-the-art environment that meets current and future needs. The Data Engineer will work with various groups within Digital Innovation to provide technical guidance during all phases of the development process. Roles and Responsibilities Supports data-operations for LCPS production applications Works with the team to design, build, maintain and administer database environments; works with multiple large clustered and non-clustered environments Ensures optimal performance of the database environment; identifies, troubleshoots and resolves issues Is the subject matter expert for projects and initiatives that require data integrations Assembles large, complex data sets that meet business requirements Maintains high quality documentation that follows all phases of the development cycle Develops and maintains databases, tables, stored procedures, views and other database objects within SQL Server Builds the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL or other technology Develops and maintains SSIS packages Builds clean logic to support LCPS reporting and analytic tools Works cross-functionally with other departments to understand and document requirements for new or changed data processes Remains current with emerging technologies and suggests adoption of new products or processes when appropriate Continues to learn and stay current on all aspects of SQL Server Qualifications Bachelor’s Degree in Information Technology Microsoft Certified SQL Server DBA or Developer preferred Strong understanding of database structures, theories, principles, and practices SQL Knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience with data management and data processing flowcharting techniques Knowledge of reporting and query tools and practices; experience with SSRS or Qlik a plus Technical documentation skills Self-motivated and directed, with keen attention to detail Able to prioritize and execute tasks in a high-pressure environment Good interpersonal, written, and oral communication skills Physical Requirements While performing the duties of this job, the employee is regularly talking, expressing or exchanging ideas by means of the spoken word. The employee must convey detailed or important spoken instructions to other workers accurately, loudly, or quickly. The employee must possess normal cognitive abilities including the ability to learn, recall and apply certain practices and policies. Frequently sitting and/or remaining in a stationary position for long periods of time. Exerting up to 25 pounds of force occasionally and/or negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects. Telework Disclosure Employees who perform the responsibilities of the above position have been identified as having the potential to telework. Telework is defined as completing one's duties and responsibilities at a site other than one's assigned duty location. In order to be eligible for telework privileges, an employee must have demonstrated consistent, positive performance and have the support and approval of their direct supervisor. In addition, these employees must have reliable high-speed internet and a designated workspace that allows them privacy while completing sensitive and confidential work. Employees who are non-exempt and are teleworking will work their required scheduled hours and gain approval from their supervisor if they work more than 8 hours a day or more than 40 hours in a workweek. Teleworking privileges can be amended, changed, or revoked based upon the performance of the employee, as well as the needs of Loudoun County Public Schools. FLSA Status: Exempt Months/Days/Hours: 12 months, 248 days, 8 hours per day Reports to: Supervisor, Data Science & Digital Solutions Telework Eligible: Yes"
Data Engineer II,Pacific Life,"Remote in Newport Beach, CA 92660",https://www.indeed.com/rc/clk?jk=82d97d1240836e76&fccid=97bfb79867bd9b23&vjs=3,"Job Description: Pacific Life is investing in bright, agile and diverse talent to contribute to our mission of innovating our business and creating a superior customer experience. We’re actively seeking a talented Data Engineer to join our Data Management Team in Newport Beach, CA; This role can be on-site or 100% remote. As a Data Engineer, you’ll play a key role in Pacific Life’s growth and long-term success by designing and building data pipelines for the RSD Cloud data platform. You will fill a new role that sits on a team of 7 people in the Retirement Solutions division. Your colleagues will include Data Architects and Data Engineers. How you will make an impact: Work with business systems analyst to understand the business requirements for the projects in data management team Build automated data pipelines for the division's cloud based data platform Work using new tools and technologies to integrate data from various sources and formats and make it available for various needs/use cases /downstream applications including BI reports and dashboards The experience you will bring: 2+ years of experience as a Data Engineer SQL (complex queries) and Python are required from school or prior work experience. Proficient in ETL/ELT is preferred but not required Strong communication, team work and interpersonal skills BS Degree: IT, Computer Science, Data Science, Statistics or equivalent experience What will make you stand out: Experience with Snowflake, Matillion , Power BI or Tableau Angle and Scrum experience Data Engineer Certificate from AWS/Google/Azure You belong at Pacific Life At Pacific Life we are committed to a culture of belonging, a space where all employees are empowered to be authentic. One way we cultivate an inclusive culture is through our employee connection groups. The purpose of these employee- led groups is to offer a place to build community, connection, camaraderie, and a sense of belonging. Each group can be active in education, advocacy, recruitment, and community building throughout our organization. Learn more about our employee connection groups at https://www.pacificlife.com/home/corporate-responsibility/diversity-equity-inclusion.html . Want to learn more about life at Pacific Life? Take an inside look at our company culture: Instagram.com/ lifeatpacificlife . #LI-DD1 #LI-Remote How We Help You Succeed: We’re fostering a culture of shared values across our company by providing generous compensation and comprehensive benefits that allow our employees to find fulfillment and security in personal life and career alike. These include: Competitive Salary and Benefits Work-Life Balance & Flexible Scheduling Medical, dental, and vision as part our commitment to investing in the health and wellbeing of our employees Two retirement savings plans: 401k savings plan with company match and Company Retirement Contribution (company-paid) Generous PTO and holiday pay Warm Colleagues & Inspiring Culture EEO Statement: Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company."
Data Center Engineer (Infrastructure Operations),Henry Ford Health System,"Rochester Hills, MI 48307",https://www.indeed.com/rc/clk?jk=cae18bb37b2b0ca9&fccid=fcee73a6346b7a5b&vjs=3,"As a Data Center Engineer this position will be responsible for performing a wide range of complex technical work within the primary data center as well as smaller remote computer rooms, MDFs, and IDFs throughout the organization. He or she will follow standard procedures to perform duties related to data center cabling, server installation and decommission, and basic power/cooling configuration and maintenance. They will also perform routine data center maintenance including room and cabinet cleanings, server migration and consolidation. This position may include off shift hours, weekends, and holidays and some travel between HFHS locations. PRINCIPAL DUTIES AND RESPONSIBILITIES: Implement changes, moves, adds, decommissions, or updates in IT rooms Process visitors to the Data Center to safeguard the integrity of data/equipment Review and approve changes to the environment following established Change Management standards and practices Maintain inventory of spare computer parts and network cables Create/print cable labels for supporting IT teams Create formal recommendations for process improvements Writes, maintains, and publishes operational documentation Other duties as required to maintain the HFHS Data Center complex REQUIRED JOB REQUIREMENTS: High School Diploma or GED required 5+ years of IT experience Ability to occasionally work nights, weekends, and holidays Prepared to work at multiple HFHS facilities as needed PREFERRED JOB REQUIREMENTS: Associates Degree (IT related field) Extensive knowledge of all types of IT equipment Cable management best practices including use of tracing devices Equipment rack layout/design/assembly/configuration Configure and code devices such as PDUs, CRACs, and ATS IT equipment installation and decommission Proficient in MS Office products including VISIO ITIL certification Overview Under the leadership of President and CEO Wright L. Lassiter, III, Henry Ford Health is a $6 billion integrated health system comprised of six hospitals, a health plan, and 250+ sites including medical centers, walk-in and urgent care clinics, pharmacy, eye care facilities and other healthcare retail. Established in 1915 by auto industry pioneer Henry Ford, the health system now has 32,000 employees and remains home to the 1,900-member Henry Ford Medical Group, one of the nation’s oldest physician groups. An additional 2,200 physicians are also affiliated with the health system through the Henry Ford Physician Network. Henry Ford is also one of the region’s major academic medical centers, receiving between $90-$100 million in annual research funding and remaining Michigan’s fourth largest NIH-funded institution. Also an active participant in medical education and training, the health system has trained nearly 40% of physicians currently practicing in the state and also provides education and training for other health professionals including nurses, pharmacists, radiology and respiratory technicians. visit HenryFord.com. Benefits Whether it's offering a new medical option, helping you make healthier lifestyle choices or making the employee enrollment selection experience easier, it's all about choice. Henry Ford Health has a new approach for its employee benefits program - My Choice Rewards. My Choice Rewards is a program as diverse as the people it serves. There are dozens of options for all of our employees including compensation, benefits, work/life balance and learning - options that enhance your career and add value to your personal life. As an employee you are provided access to Retirement Programs, an Employee Assistance Program (Henry Ford Enhanced), Tuition Reimbursement, Paid Time Off, Employee Health and Wellness, and a whole host of other benefits and services. Employee's classified as contingent status are not eligible for benefits. Equal Employment Opportunity/Affirmative Action Employer Equal Employment Opportunity / Affirmative Action Employer Henry Ford Health is committed to the hiring, advancement and fair treatment of all individuals without regard to race, color, creed, religion, age, sex, national origin, disability, veteran status, size, height, weight, marital status, family status, gender identity, sexual orientation, and genetic information, or any other protected status in accordance with applicable federal and state laws."
Data Engineer,KUBRA,"Phoenix, AZ+1 location",https://www.indeed.com/rc/clk?jk=5bc0ed37c9d0a5fc&fccid=e9b27079d156f5be&vjs=3,"Overview: KUBRA is in growth mode and currently seeking a Data Engineer to join our Data Analytics Team! As a Data Engineer, you will be working on designing and maintaining our data Infrastructure and ETL processes under the direction of the Team Lead, or Senior Data Engineer. The best part? You will also get the opportunity to collaborate with an amazing BI Analysts team to provide BI Analysis as a secondary focus! KUBRA's hiring efforts will continue during the COVID-19 pandemic. Any face-to-face stages of our interview process will be virtual via video conference. What you get to do every day: Design, build, and maintain data infrastructure, ETL processes, and data pipelines Assist the BI Analyst to manage client reporting requirements. Build Data models and assist the BI Analyst to offer data driven insights. Foster an environment that emphasizes trust, open communication, creative thinking, and cohesive team effort. Migrate on-premise data systems to AWS cloud and maintain existing SSIS packages. Design data models and automate manual processes. Maintain SQL Server and AWS data infrastructure. Work with the product Technical Writer to create technical documentation related to data infrastructure and processes. What kind of person should you be?: Excellent written and verbal communication skills and an ability to maintain a high degree of professionalism in all client communications. Ability to influence others, build relationships, manage conflicts, and handle negotiations. Excellent organization, time management, problem-solving, and analytical skills. Proactive mindset and ability to work independently in a fast-paced environment focused on results. Ability to handle pressure. What skills do you need?: Minimum of 3 to 4 years of cloud experience on any of the major cloud platforms preferably AWS. Hands on Knowledge of Data Modeling, Warehousing and BI Reporting Tools Demonstrable experience with one or more of SQL, R, Python, Spark, or Kafka. Preferable to have experience with one or more of BI tools, Databricks, Snowflake/Redshift, DBT. Experience with handling streaming data is an asset. What can you expect from us?: Award-winning culture that fosters growth, diversity and inclusion for all Paid day off for your birthday Access to LinkedIn learning courses Continued education with our education reimbursement program Flexible schedules Two paid days for volunteer opportunities Well-Being Days! KUBRA is a fast-growing company that delivers customer communications solutions to some of the largest utility, insurance, and government entities across North America. KUBRA offers billing and payments, mapping, mobile apps, proactive communications, and artificial intelligence solutions for customers. With more than 1.5 billion customer interactions annually, KUBRA services reach over 40% of households in the U.S. and Canada. KUBRA is an operating subsidiary of Hearst. Our office is small enough to allow creative individuals to flourish, yet large enough to provide long-term stability. We place a tremendous amount of responsibility on our team members to be productive, focused and self-motivated. We offer a casual work environment, competitive compensation and a stellar benefits program. KUBRA is an equal opportunity employer dedicated to building an inclusive and diverse workforce. We will provide accommodations during the recruitment process upon request by emailing the recruitment-team@kubra.com. Information received relating to accommodation will be addressed confidentially. We thank all applicants for their interest; however, only candidates under consideration will be contacted."
Senior Data Research Engineer - SPG,Apple,"Cupertino, CA+1 location",https://www.indeed.com/rc/clk?jk=7f75563dbcd4bc10&fccid=c1099851e9794854&vjs=3,"Summary Posted: May 5, 2022 Role Number: 200376285 The Autonomous System’s Perception Data team is in search of a curious and innovative team player who is passionate about data and all its facets and its importance for advancing Machine Learning. Our data team is responsible for all aspects of generating massive multimodal datasets. Join Apple and help us leave the world better than we found it! Data is vastly becoming one of the most important, if not the most important, area of focus for improving ML performance. The Autonomous System’s Sense Data team’s purpose is to increase the quality, variety, and usefulness of data available to our models. We are responsible for acquiring, processing, annotating and managing the data for our project. People in our team directly work with ML researchers and engineers, as well as other teams (Infrastructure, Operations, etc) to make sure we are always delivering value and keeping our models improving. Key Qualifications Strong software engineering skills, including being fluent in Python. Attention to detail and creative problem-solving: Do you dig into the data to troubleshoot a problem? Interest and / or experience in data engineering and data pipelines. You have 2+ years of hands-on experience building reliable, scalable Data Pipelines with Python in a scalable cloud environment (AWS, etc). Familiarity with some of the following: Postgres, Presto, REST API development, Spark, cloud development, numpy, pandas, to name a few. Strong technical communication (both written and verbal), prioritization, and time management skills. Strong interpersonal skills to work both with your team and others. Experience with data quality assessment and monitoring a plus. Experience with human annotation / labeling a plus. Description You will be a core contributor on the development of our annotation data pipeline, as well as spearheading innovative approaches to improving different aspects of our data. You will work closely with other teams to understand their needs and propose ways to address them, translating them into data products, workflows and services. Example responsibilities include: • Build and improve scalable and robust data pipelines. • Move annotation capabilities toward a self-service paradigm. • Integrate services with existing visualization and exploration tools. • Experiment with the performance gains when using different hypotheses in annotation tasks. • Automatically assess quality of annotations based on models. Education & Experience Additional Requirements"
Data Engineer,Go2Andaman,"New York, NY",https://www.indeed.com/rc/clk?jk=d10a19e7cb3c0d0e&fccid=b1af618c86e7cee6&vjs=3,"About Us: We're on a mission to make it possible for every person, team, and company to be able to tailor their software to solve any problem and take on any challenge. Computers may be our most powerful tools, but most of us can't build or modify the software we use on them every day. At Notion, we want to change this with focus, design, and craft. We've been working on this together since 2016, and have customers like Pixar, Mitsubishi, Figma, Plaid, Match Group, and thousands more on this journey with us. Today, we're growing fast and excited for new teammates to join us who are the best at what they do. We're passionate about building a company as diverse and creative as the millions of people Notion reaches worldwide. About The Role: Since the launch of Notion, the company has been on a mission to make toolmaking ubiquitous - from wikis to documents, notes, tasks, databases, etc. A strong product intuition and focus on users have helped the company achieve adoption across businesses of all sizes. Today, millions of users rely on Notion's building blocks to get their work done. As Notion continues to grow quickly, there is a unique opportunity to build the foundations of data and help the product and company reach their full potential. This is where you come in — to design and build reliable, trusted and timely datasets that accelerate the decision-making process of key product and business functions. You will have a strong impact on the roadmap and the growth trajectory of the company. What You'll Achieve: You'll define the processes and ETL infrastructure to transform and make data readily available across the company You'll build core datasets to serve as unique sources of truth for product and business functions (product, marketing, sales, finance, customer experience, data science, business operations, IT, engineering) You'll partner with data scientists and other internal stakeholders to understand their needs and then design, build and monitor pipelines that meet today's requirements but can gracefully scale with our growing data size You'll implement automated workflows that lower manual/operational cost for stakeholders, define and uphold SLAs for timely delivery of data, move the company closer to democratizing data and a self-serve model (query exploration, dashboards, data catalog, data discovery) Skills You'll Need to Bring: You are a self-starter and continuously gather and synthesize high-impact needs from business partners, design and implementing the appropriate technical solutions, and effectively communicating about deliverables, timelines and tradeoffs You've spent 3+ years as a data engineer building core datasets and supporting business verticals as needed. You are passionate about analytics use cases, data models and solving complex data problems You have hands-on experience shipping scalable data solutions in the cloud (e.g AWS, GCP, Azure), across multiple data stores (e.g Snowflake, Redshift, Hive, SQL/NoSQL, columnar storage formats) and methodologies (e.g dimensional modeling, data marts, star/snowflake schemas) You are an SQL expert. You intimately understand aggregation functions, window functions, UDFs, self-joins, partitioning and clustering approaches to run correct and highly-performant queries You are highly comfortable with object-oriented programming paradigms (e.g Python, Java, Scala) Nice to Haves: You have worked at a fast-growing start-up, a SaaS company or are eager to contribute in such an environment (being a current Notion user would be great!) You have hands-on experience in designing and building highly scalable and reliable data pipelines using BigData stack (e.g Airflow, DBT, Spark, Hive, Parquet/ORC, Protobuf/Thrift, etc) Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Notion. Notion is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Notion considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Notion is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation made due to a disability, please let your recruiter know."
Data Engineer,Lippert,"Elkhart, IN 46514",https://www.indeed.com/rc/clk?jk=7f29dc76e461a78c&fccid=1176ae707a2cad83&vjs=3,"Overview: Who We Are: Lippert is a leading, global manufacturer and supplier of highly engineered products and customized solutions, dedicated to shaping, growing and bettering the RV, marine, automotive, commercial vehicle and building products industries. We combine our strategic manufacturing capabilities with the power of our winning team culture to deliver unrivaled customer service, award-winning innovation, and premium products to all of our customers. Why We are Different: At Lippert, Everyone Matters. This is not just a tagline or empty promise; it is who we are. We have intentionally created a culture that values and celebrates our team members’ unique and varied backgrounds, perspectives, and experiences. We strive to give our team members a deeper sense of purpose at work, and we continue to build a better work environment by aligning our cultural and business strategies with the needs of our team members. What You will Get: A unique, inclusive and supportive company culture. Comprehensive benefit offerings including medical, dental, vision, 401k with employer match, vacation, and more! Fair and competitive compensation. Career development and mentoring and opportunities to grow. Holiday, personal and vacation days. Summary/Objective The Data Engineer documents, supports, and automates the cloud data warehouse for Lippert Components. The candidate should have experience with ELT/ETL and dimensional modeling. The candidate must be able to work in a dynamic and rapidly expanding environment. Essential Functions Create data pipelines Create data models using a star or snowflake architecture Perform hands-on coaching to peers Excellence in communication as a liaison with vendors and other Data Services personnel to resolve issues Strong desire to document and automate common tasks Document key responsibilities Act as support escalation Troubleshoot problems and quickly resolve issues Supervisory Responsibility This position has no supervisory responsibility. Physical Demands While performing the duties of this job, the employee is regularly required to stand, walk, use hands to handle, feel, or reach. This position is not very active when it comes to movement and requires a lot of typing and sitting in a chair. Position Type/Expected Hours of Work This is a full-time salary position and the expected work hours are 40 hours per week, Monday through Friday. Travel There is minimal to no travel with this position. Competencies You're compassionate and trustworthy, and set high standards You're not afraid to ask questions and you are open to constructive criticism You're self-driven and take ownership of your work You're enthusiastic and adapt to change well Ability to communicate (written and verbal) clearly, concisely and effectively Requirements At least 2 years of experience building ELT or ETL pipelines At least 2 years of experience with SQL At least 2 years of experience with dimensional modeling Public cloud experience (AWS, Microsoft Azure) Strong customer-facing written and oral communication skills Experience troubleshooting and configuring data pipelines Manages daily requests from business operations Customer service based - An ability to be flexible and use different approaches in different situations Excellent communication - Being able to convey information to other employees clearly and simply Strong technical writing ability Strong attention to detail 3+ years of experience in an enterprise IT environment Multiple office locations - some travel may be required What'll Make you Special Experience with cloud data warehouses Experience with Dynamics365 for Finance and Operations or DynamicsAX Experience with Kimball or Immon data warehouse architecture Experience with PowerBI Experience with Azure DevOps Experience with Databricks Work Authorization/Security Clearance Must be able to pass EVerify. Possession of a valid driver’s license Other Duties Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice. Pay Group : AAP/EEO Statement: Lippert provides equal employment opportunity to all team members and applicants without regard to race, color, religion, sex, sexual orientation, gender identity, pregnancy, national origin, ancestry, age, genetic information, disability, citizen status, veteran status, military service, marital status or any other legally protected category as established by federal, state, or local law. This policy governs all employment decisions, including recruitment, hiring, job assignment, compensation, training, promotion, discipline, transfer, leave-of-absence, access to benefits, layoff, recall, termination and other personnel matters. All employment and personnel-related decisions are based solely upon legitimate, job-related factors, such as skill, ability, past performance, and length of service with Lippert. Lippert’s strong commitment to equal employment opportunity requires a commitment by each individual team member. Compliance with the letter and spirit of this policy is required of all team members. Violations of this policy should be immediately reported to your leader or to any member of leadership. Team members who violate this policy will be subject to disciplinary action, up to and including termination of employment."
Senior Data Engineer,Federal Reserve Bank of Richmond,"Richmond, VA 23219 (Central Office area)",https://www.indeed.com/rc/clk?jk=d6d4d15800b01b13&fccid=43edc7b6bca2ac93&vjs=3,"Company Federal Reserve Bank of Richmond When you join the Federal Reserve—the nation's central bank—you’ll play a key role, collaborating with leading tech professionals to strengthen and protect our economic, financial and payments systems. We dedicate more than $1 billion to technology each year to support the Federal Reserve and our economy, and we’re building a dynamic and diverse team for our future. Bring your passion and expertise, and we’ll provide the opportunities that will challenge you and propel your growth—along with a wide range of benefits and perks that support your health, wealth, and life. In addition to competitive compensation, we offer a comprehensive benefits package that includes tuition assistance, generous paid time off, top-notch health care benefits, child and family care leave, professional development opportunities, a 401(k) match, pension, and more. All brought together in a flexible work environment where you can truly find balance. About the Opportunity The Enterprise Data Services has an immediate opening for a Data Engineer position reporting to Manager-IT-Technology. The Federal Reserve System’s provides a Cloudera Data Analytics environment for business lines in the Federal Reserve System. We work with state-of-the-art technologies that are part of the next generation data ecosystem, which includes services used for data storage, processing, integration, and data analytics. A high-level goal of this position is to manage and administer the infrastructure for the product environment. Ensure integration of current on-prem solution can migration to a Cloud-based solution for Data Analytics. As a Data Engineer, you will be accountable for availability and management of the enterprise environment that meets business needs. As part of the National IT team, our Data Analytics team works with multiple business lines and IT groups from Federal Reserve System districts. You will have an opportunity to showcase your critical thinking and technical skills across many disciplines and across the Federal Reserve System. This role will be instrumental in shaping the direction of enterprise data. What You Will Do: Provide Day-to-day support to a large Cloudera Data Analytics Environment Execute environmental Security processes and procedures es to ensure proper provisioning occurs Provide standard ITIL framework activities around Change, Incident, Problem, Release Management and Security Engage in Agile ceremonies that manage the workload of the environment Participate in a 24x7 on-call rotation as needed Provide insight and expertise to planning events Provide guidance on business solution development in the data space and cloud technologies Work independently with minimal supervision Qualifications: Bachelor’s degree in Computer Science, Management Information Systems, Computer Engineering preferred, or related field or equivalent work experience Hands-on experience with Cloudera, Hadoop, Horton Works, Impala, Yarn, Kafka Seven or more years of experience in administering data analytics/linux/unix based, large-scale solutions in an enterprise Must have a strong background or demonstrate sufficient knowledge of networking and security Hands on experience in one or more languages such as Python, Shell Scripting, etc. Strong background in data structures, networking, performance, and scalability. Experience with Agile methodologies and able to work in an Agile manner is preferred Other Requirements and Considerations: A requirement of this position is that the employee must be fully vaccinated against COVID-19; individuals who are unable to be vaccinated due to a medical condition or sincerely held religious belief may request an accommodation from the Bank. Candidates should review the Bank’s Employee Code of Conduct to ensure compliance with conflict of interest rules and personal investment restrictions. If you need assistance or an accommodation due to a disability, please notify rich.recruitment@rich.frb.org. Sponsorship is not available for this role. The selected candidate will be subject to a government security investigation and must meet eligibility requirements for access to classified information. Eligibility for this specific position requires U.S. Citizenship or three or more years of Permanent Resident (Green Card) status The hiring range is 116,280 – 150,000 annually. For candidates outside of Richmond, VA, listing hiring salary ranges may be adjusted based on your geographic location. Discover the Reason Why So Many People Love It Here! A requirement of this position is that the employee must be fully vaccinated against COVID-19; individuals who are unable to be vaccinated due to a medical condition or sincerely held religious belief may request an accommodation from the Bank When you join Federal Reserve’s National IT organization, not only will you find a challenging and purposeful career, you’ll also have access to a wide range of benefits and perks that support your health and wealth, including: Great medical benefits Pension and 401(k) with employer match Generous paid time off Tuition reimbursement Employee resource networks Paid volunteer leave Flexible work options Onsite amenities that make working here fun The Federal Reserve Bank of Richmond provides equal opportunity to all individuals without regard to race, sex, color, religion, gender identity or expression, sexual orientation, national origin, age, disability, or genetic information. Full Time / Part Time Full time Regular / Temporary Regular Job Exempt (Yes / No) Yes Job Category Information Technology Work Shift First (United States of America) The Federal Reserve Banks believe that diversity and inclusion among our employees is critical to our success as an organization, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. The Federal Reserve Banks are committed to equal employment opportunity for employees and job applicants in compliance with applicable law and to an environment where employees are valued for their differences. Privacy Notice"
Data Center Civil Engineer,Google,"New York, NY (Chelsea area)",https://www.indeed.com/rc/clk?jk=5fa04960fab798a7&fccid=a5b4499d9e91a5c6&vjs=3,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: New York, NY, USA; Reston, VA, USA; Sunnyvale, CA, USA. Minimum qualifications: Bachelor's degree in Civil Engineering or equivalent practical experience 10 years of experience in civil or site engineering 5 years of experience with data centers or construction Preferred qualifications: Master's degree Engineer license Knowledge of site layout, grading, drainage, infrastructure, erosion, and sediment control Knowledge of civil engineering principles, practices, and related technical areas Knowledge of water/wastewater design, hydraulic modeling, and industry construction means and methods Ability to work in a team/collaborative environment, and communicate technical issues effectively in written and verbal forms About the job Our thirst for technology is a part of everything we do. The Data Center Engineering team takes the physical design of our data centers into the future. Our lab mirrors a research and development department - cutting-edge strategies are born, tested and tested again. Along with a team of great minds, you take on complex topics like how we use power or how to run state-of-the-art, environmentally-friendly facilities. You're a visionary who optimizes for efficiencies and never stops seeking improvements - even small changes that can make a huge impact. You generate ideas, communicate recommendations to senior-level executives and drive implementation alongside facilities technicians. With your technical expertise, you ensure compliance with codes and standards, develop infrastructure improvements and serve as an expert in your specialty (e.g., cooling, electrical). Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible. Responsibilities Provide civil engineering expertise for design-related activities in connection with data center sites or projects. Serve as our in-house consultant, advisor, and authorized representative through all phases of projects. Provide engineering guidance and reviews of civil engineering works associated with site layout and data center building design. Help develop civil engineering guidelines and direction for design standards. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form."
Data Engineer,Royal Bank of Canada,"Raleigh, NC 27617 (Central area)",https://www.indeed.com/rc/clk?jk=ab0ac5c515563757&fccid=537b899e30af3338&vjs=3,"Come Work with Us! At RBC, our culture is deeply supportive and rich in opportunity and reward. You will help our clients thrive and our communities prosper, empowered by a spirit of shared purpose. Whether you’re helping clients find new opportunities, developing new technology, or providing expert advice to internal partners, you will be doing work that matters in the world, in an environment built on teamwork, service, responsibility, diversity, and integrity. Job Title Data Engineer Job Description Employer Website Job Posting Data Engineer, RBC Bank (Georgia), National Association, Raleigh, NC: Design and develop software applications and process to support data collection, data transport, data storage, data architecture, and data quality. Leverage data modelling, data APIs, ETL data tools, and database systems to improve data quality, create pipelines for aggregation, dissemination, and enrichment of data for data science, data analysis, and reporting. Help establish tools to aggregate, cleanse, transform and ingest data from various sources. Enrich and disseminate data to environments to be modelled and analyzed. Assist migration of existing data aggregation ETL techniques to new data pipelines. Operationalize streaming data flows and setup streaming data processors. Setup pipeline tools for scalability and monitoring. Collaborate with data scientists to prototype and operationalize machine learning models. Full time employment, Monday – Friday, 40 hours per week. MINIMUM REQUIREMENTS: Master’s degree in Computer Science, Information Technology, Computer Engineering, or a related field, and 1 year of experience designing and developing software applications and processes to support data management. Must also have 1 year of experience in each of the following: Utilizing Apache Kafka and Kafka Connect to setup data pipelines; Utilizing Java or Python; Running and optimizing SQL queries on MS SQL server and MySQL/MariaDB; Utilizing NoSQL database, including MongoDB, Cassandra, or HBase; Producing and consuming REST services; Utilizing CI/CD tools, including Jenkins, UCD, or Ansible Utilizing Git repositories GitHub or BitBucket BI reporting using Tableau; Bash scripting; and Utilizing Kubernetes or Docker. Up to 15% international and domestic travel required. TO APPLY: Please click “Apply Now” Button Job Summary Address: Raleigh, North Carolina, United States of America City: USA-NC-RALEIGH Country: United States of America Work hours/week: 40 Employment Type: Platform: Personal and Commercial Banking Job Type: Regular Pay Type: Salaried Posted Date: 2022-04-29-07:00 Application Deadline: 2022-07-12-07:00 Inclusion and Equal Opportunity Employment At RBC, we embrace diversity and inclusion for innovation and growth. We are committed to building inclusive teams and an equitable workplace for our employees to bring their true selves to work. We are taking actions to tackle issues of inequity and systemic bias to support our diverse talent, clients and communities. We also strive to provide an accessible candidate experience for our prospective employees with different abilities. Please let us know if you need any accommodations during the recruitment process. Join our Talent Community Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you. Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at rbc.com/careers."
Senior Data Manager (Data Engineer),Indiana University,"Indianapolis, IN 46202 (Downtown area)",https://www.indeed.com/rc/clk?jk=77df2441ae9502da&fccid=8b8af8e5cb513470&vjs=3,"Department DEPT BIOSTATISTICS & HEALTH DA (IN-BSAT-IUINA) Department Information Department of Biostatistics and Health Data Science Job Summary General Responsibilities: Performs data management tasks, including experienced data modeling, conversion, de-duplication, migration, and identification and repair of data quality issues. Designs, develops, and implements custom data systems and reconciliation tools, processes, rules, solutions etc. to validate data, match/merge, and upload batch lists. Creates and tunes complex stored procedures and queries for data management and extraction. Designs and builds out technical software mechanisms to accommodate multiple integrations accurately based on complex rules and custom solutions. Ensures documentation and security standards/protocols are recognized and followed. Provides experienced troubleshooting and problem analysis/resolution for data related issues; performs experienced scripting and modifications of application and products for corrective action. Researches and stays up-to-date with data engineering best practices and approaches; stays abreast of latest security threats and risks to proactively address potential exposures. Qualifications EDUCATION Required Bachelor's degree Preferred Degree in computer science, information science, or a related field WORK EXPERIENCE Required 2 years of data management, engineering, or related experience Preferred 3 years of clinical research data management experience. Experience in Linux working environment and on high-performance computing systems Combinations of related education and experience may be considered. SKILLS Required Proficient communication skills Maintains a high degree of professionalism Demonstrated time management and priority setting skills Demonstrates a high commitment to quality Possesses flexibility to work in a fast paced, dynamic environment Seeks to acquire knowledge in area of specialty Highly thorough and dependable Demonstrates a high level of accuracy, even under pressure Preferred Knowledge designing and implementing data management systems of omics data (genomics, proteomics, etc.) Intermediate level R/Python and SQL programming Familiar with bioinformatics data processing and analysis workflows Knowledge of Good Clinical Data Management Practices Research experience in real-world evidence biomedical research data (electronic medical records, medical claims, etc.) Working Conditions / Demands This role requires the ability to effectively communicate and to operate a computer and other standard office productivity equipment. The position involves sedentary work as well as periods of time moving around an office environment and the campus. The person in this role must be able to perform the essential functions with or without an accommodation. Work Location Indianapolis, Indiana Job Classification Career Level: Career FLSA: Exempt Job Function: Information Technology Job Family: Data Analysis & Engineering Click here to learn more about Indiana University's Job Framework. Posting Disclaimer Due to the COVID-19 pandemic, there may be differences in the working conditions as advertised in our standard job postings (e.g., the ability to travel from one campus to another, etc.). If you are invited for an interview, please discuss your questions or concerns regarding the working conditions at that time. This posting is scheduled to close at 11:59 pm EST on the advertised Close Date. This posting may be closed at any time at the discretion of the University, but will remain open for a minimum of 5 business days. To guarantee full consideration, please submit your application within 5 business days of the Posted Date. If you wish to include a cover letter, you may include it with your resume when uploading attachments. New employees will be provided with information regarding Indiana University's COVID-19 vaccine policy, which includes the opportunity to request an exemption. To learn more, view our COVID-19 vaccine information page. Equal Employment Opportunity Indiana University is an equal employment and affirmative action employer and a provider of ADA services. All qualified applicants will receive consideration for employment based on individual qualifications. Indiana University prohibits discrimination based on age, ethnicity, color, race, religion, sex, sexual orientation, gender identity or expression, genetic information, marital status, national origin, disability status or protected veteran status. Indiana University does not discriminate on the basis of sex in its educational programs and activities, including employment and admission, as required by Title IX. Questions or complaints regarding Title IX may be referred to the U.S. Department of Education Office for Civil Rights or the university Title IX Coordinator. See Indiana University’s Notice of Non-Discrimination here which includes contact information. Campus Safety and Security The Annual Security and Fire Safety Report, containing policy statements, crime and fire statistics for all Indiana University campuses, is available online. You may also request a physical copy by emailing IU Public Safety at iups@iu.edu or by visiting IUPD. Contact Us Request Support Telephone: 812-856-1234"
Data Engineer,Uline,"Pleasant Prairie, WI+2 locations",https://www.indeed.com/rc/clk?jk=2f64e9b5a1b7d6e6&fccid=2f680121eef7890a&vjs=3,"Data Engineer Corporate Headquarters 12575 Uline Drive, Pleasant Prairie, WI 53158 Uncover your full potential in a collaborative environment where you'll design, develop and deliver custom solutions to big challenges. And you'll be doing it for a proven industry leader that runs one of the largest e-commerce sites in the U.S. Better together than apart. This position is on-site, and we are looking for good people who share our passion. Position Responsibilities As part of Uline's data analytics engineering team, work closely with business customers in the development of our new enterprise analytics platform. Leverage industry-leading integration and analytics tools to build a modern data warehouse that is accurate, reliable, high performing and easily accessible to our business departments. Be responsible for the full life cycle of development, from requirements gathering through ETL coding and report/dashboard design and creation. Work with business users to establish reporting and analytic requirements. Translate business requirements into ETL and report specifications. Provide technical and business knowledge support to the team. Compile ad-hoc data and report requests. Minimum Requirements Bachelor's degree in IT or related major. 5+ years related experience. Excellent knowledge of data design, SQL and data warehousing. Knowledge of IBM Cognos BI a plus. Strong knowledge of Microsoft BI technology (SSRS, SSIS, SSAS). Available for travel to Uline's domestic and international branches. Benefits Complete insurance coverage that includes medical, dental, vision and more. 401(k) with 5% employer match. Paid holidays and generous paid time off. Bonus programs include annual performance, sales goals and profit sharing. Employee Perks On-site café with executive chefs and seasonal dinner-to-go options. First-class fitness center with complimentary personal trainers. Over four miles of beautifully maintained walking trails. About Uline Uline is North America's leading distributor of shipping, industrial and packaging materials. We're a family-owned company known for incredible service, quality products and same-day shipping of our huge in-stock inventory. With over 8,500 employees across 12 locations, it's time you joined Uline. Uline is proud to operate as a drug-free workplace. All new hires must complete a pre-employment hair follicle drug screening. Unfortunately, Uline is unable to offer US work sponsorship at this time. EEO/AA Employer/Vet/Disabled #LI-KK2 #CORP (#IN-PPIT) Our employees make the difference and we are committed to offering exceptional benefits and perks! Explore Uline.jobs to learn more!"
Data Engineer,Gainwell Technologies LLC,Texas+2 locations,https://www.indeed.com/rc/clk?jk=89b071904b9e3de4&fccid=515bac75241f15a3&vjs=3,"About Us At Gainwell, we are passionate about helping those most vulnerable get access to high-quality, affordable healthcare. We harness the power of technology to help our clients improve the health and well-being of the members they serve. We believe nothing is impossible when you bring together people who care deeply about making healthcare work better for everyone. Join us and build your career with an inclusive team that thrives on finding innovative solutions to some of healthcare’s biggest challenges. Job Description Essential Job Functions Responsible for discussing data extraction needs with each individual account and ensuring that data extracted meets the needs of the GIO application in order to process it Responsible for validating that data ingested by connectors created by Java/Kafka Developers is ingested correctly and makes sense from a business perspective Familiarity with SQL is important in order to query GIO(T-K) to ensure data quality is high. Experience with design and documentation of ETL pipelines preferred. Works with the account teams to ensure that after initial data is ingested that data being displayed in the application appears appropriate and explores any anomalies that may exist Requirements/Qualifications: Design and document data pipelines/transformations required for each unique account connector An ability to learn and understand the GIO(TK) data schema and how data is processed by TK in order to ensure that data designs developed work well with product. An ability to interact with and understand data extraction pipelines created by Gainwell account teams to suggest changes to them to meet product requirement needs."
MUSA - 4209 - Data Engineer,MomentoUSA,"Temporarily Remote in Crotona Park, NY+12 locations",https://www.indeed.com/rc/clk?jk=e125de3bd2731474&fccid=89868b834f0322a8&vjs=3,"Overview Momento USA is a global technology consulting, talent acquisition and creative development firm that addresses clients most pressing needs and challenges. We currently looking for Data Engineer for a client based out in Remote. Please see the job description below for your reference. Requisition Note (13038249) Req Open This requisition will close to new submittals 72 hours from the date and time released (4/12 @ 4pmET). As discussed on the requisition call, below are the requirements that will be used to screen resumes. As a reminder, candidates will initially be screened on the required skills, using the information outlined in the work experience. If there are more candidates meeting the required qualifications than the work director has requested to see, candidates will then be put through an additional screening against the differentiating factor. **Required: Minimum four-year College or University degree in Software or Data Engineering, Computer Science, Mathematics, Physics, or Engineering. Master's degree preferred with exposure to Statistics. Looking for independent thinkers with proven 3 years industry (internship experience will not be accepted) experience with development of IT solutions, database systems, Data ETL, SQL, and C#/C++ proficiency. Ability to manipulate, process, and interact with data repositories. Working experience with .NET program development is a plus (not required). **Desired Skills: Candidate must be comfortable reaching out and collaborate with process partners from around the world. Candidates must have excellent English communication skills and be able to effectively solve complex problems. Attention to detail is critical. **remote position, preferred local to Peoria area or willing to relocate Job Title & ID #: Data Engineer 3 (13038249) Pay rate: $60/hr C2C Duration: 12 month(s) Location: Peoria IL 61629- Remote initially Position: 1 Max Submissions: 2 Start date: 5/2/22 Job Descriptions: Summary: The main function of a data engineer is to ensure that the data assets of an organization are supported by an architecture that supports the organization in achieving its strategic goal. A typical data engineer is responsible for setting enterprise standards for databases, data integration, and the means to get to the data. Job Responsibilities: Test programs or databases, correct errors and make necessary modifications. Modify existing databases and database management systems. Work as part of a project team to coordinate database development and determine project scope and limitations. Write and code logical and physical database descriptions and specify identifiers of database to management system. Review project requests describing database user needs to estimate time and cost required to accomplish project. Skills: Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. Ability to work independently and manage one’s time. Basic mentoring skills necessary to provide support and constructive performance feedback. Knowledge of logical data modeling and physical data modeling. Knowledge of computer software, such as SQL, Visual Basic, Oracle, etc. Education/Experience: Associate's degree in computer programming or a relevant field required. Bachelor's degree preferred. 5-7 years experience required. RESPONSIBILITES: Job responsibilities include development of data models and data intake solutions for corporate capacity planning system and interacting with other corporate databases (Oracle, PostgreSQL, Snowflake, Db2) using SQL while ensuring data integrity. Position will require close collaboration with capacity planning team as well as active collaboration with data owners and IT staff company-wide. EDUCATION REQUIREMENT: Minimum four year College or University degree in Software or Data Engineering, Computer Science, Mathematics, Physics, or Engineering. Master's degree preferred with exposure to Statistics. TYPICAL DAY: Core hours 9am-3pm Central time, otherwise flexible work hours. Remote work location possible but eventual co-location to Peoria, IL desired. TECHNICAL SKILLS REQUIRED: Looking for independent thinkers with proven 3 years industry (internship experience will not be accepted) experience with development of IT solutions, database systems, Data ETL, SQL, and C#/C++ proficiency. Ability to manipulate, process, and interact with data repositories. Working experience with .NET program development is a plus (not required). SOFT SKILLS: Candidate must be comfortable reaching out and collaborate with process partners from around the world. Candidates must have excellent English communication skills and be able to effectively solve complex problems. Attention to detail is critical. Schedule: 8:00am to 5:00pm Travel: None Onsite Interview Required? No Interview availability: Remote/Onsite: Remote - Full Time Momento USA is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. Thanks and Regards, Ibraheem M. Momento USA | Exceeding Customer Expectations… 440 Benigno Blvd, Unit #A 2nd Floor. Bellmawr, NJ 08031 Direct: 856-452-8848/ Desk: 856-456-1805 X 1019 / Fax: (866) 605-1171 Email: ibraheem@momentousa.com Web: www.MomentoUSA.com Minority Certified by SWAM One of the fastest growing company in NJ Awarded fastest growing Asian American business by Diversitybusiness.com E-verified Company Note: Momento USA is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status."
"Data Engineer, Chief Technology Office",NYC Careers,"Manhattan, NY 10007 (Financial District area)+1 location",https://www.indeed.com/rc/clk?jk=bd95ce5683cd1a4b&fccid=f97367b3ac9546b1&vjs=3,"**Interested applicants who meet the preferred requirements and hold another permanent civil service title are strongly encouraged to apply** The Mayor's Office of Contract Services (MOCS) is a New York City oversight and service agency that manages procurement citywide, from planning and release of agency solicitations to payment of vendors. Annually, agencies procure billions in products and services from a diverse pool of vendors that represent various industries. MOCS therefore aims to ensure that the procurement process remains fair, transparent, efficient and cost-effective. MOCS makes it easier to do business through use of end-to-end technology tools, increases transparency by publication of enriched data and hosting public hearings, and strengthens procurement operations by providing direct assistance and resources to all stakeholders. MOCS also partners with agencies and vendors to identify areas for policy reform, resulting in ongoing process improvement to reduce administrative burdens and increase the positive impact of services on communities. The MOCS Director serves as the City Chief Procurement Officer. MOCS team members operate in a collaborative, service-oriented environment, where flexibility and ability to achieve results are valued. All managers lead teams and/or lines of service, assuming increasing levels of responsibility for the organization’s success. Managers align daily operations to the agency’s strategic priorities, engage stakeholders in planning, and drive performance using well-defined success metrics, along with effective people and project management strategies (including but not limited to the assignment of work, maintenance of performance standards, maintaining baseline staff knowledge and professional development). All managers are expected to deliver timely and quality work products and services, participate in ongoing improvement activities, proactively deepen their knowledge of procurement and government operations. Managers must serve as principal ambassadors for the organization and are expected to handle confidential matters, promote established priorities, deescalate conflict, and proactively escalate issues along with proposed solutions. The Data Engineer will report to the Assistant Director of Enterprise Data Services in the Technology Strategy division, Office of the CTO. The successful candidate will focus on ensuring the successful implementation of our MOCS data warehouse and PASSPort solutions. This position requires a detailed-oriented, hands-on contributor who will work closely with MOCS business and BI teams on the analysis and design of database and system solutions. Assignment and Current Responsibilities: Collaborate with the other members of the integration team in the design, implementation and documentation of solutions for daily issues/support, release management, and new projects Assist in architecting, mapping, developing, and testing data movement to data warehouses (AWS Redshift and SQL Server), with emphasis on the data pipeline processes Develop, document, and execute SQL/stored procedures/server scripts as needed to support data pipelines Determine ELT/ETL requirements and assist with production, setup, and execution of migrations Work closely with BI and PASSPort teams on data pipelines including analysis and design of integration solutions, data and reporting needs of internal and external stakeholders, and enhancements Support lightweight solutions and microservice integrations in AWS and Windows environments Support automated deployment, testing and system assurance. Identify and resolve data, technical issues and mediate business impact Collect requirements, design, build and test reports and dashboards across applications and programs Perform ad hoc analysis as required Ongoing professional development to strengthen skills and increase knowledge in relevant areas of procurement, technology, government operations, public policy and people and change management. Understand issues affecting relevant stakeholder groups, including but not limited to covered city agencies, Minority and Women-owned Business Enterprises (M/WBEs), nonprofits, etc. Special projects, as assigned. Minimum Qual Requirements 1. Graduation from an accredited college with a baccalaureate degree; or 2. Graduation from an accredited community college plus two years of experience with administrative, analytic, coordinative, supervisory or liaison responsibilities; or 3. A four-year high school diploma or its educational equivalent plus four years of experience as described in “2” above; or 4. A satisfactory equivalent combination of education and experience. Preferred Skills Demonstrate competency and/or history of consistent quality performance in the following areas of responsibility. Excellent writing and communication skills. Knowledge and interest in computer systems and the latest technologies. Familiar with AWS ecosystem including S3, Redshift databases, Lamda, EC2, AWS Step Functions and necessary supporting infrastructure, The ability to learn new technologies quickly. Ability to write complex procedures using SQL (i.e. T-SQL, PL/pgSQL, etc.). Experience in generic object-oriented languages preferred (especially Python but also C#, Java, etc.) Experience in scripting languages (i.e. Bash, PowerShell, etc.). Experience in ELT/ETL tools (e.g. AWS Glue, Matillion, SSIS, Informatica, etc.) . Knowledge of testing tools and techniques and executing test scripts to test data pipeline performance and data integrity. Robust understanding of system assurance standards and justification. Understanding of data governance frameworks. Excellent analytical, organization, presentation and facilitation skills; ability to handle multiple tasks under tight deadlines. Knowledge of New York City’s data share platforms and procurement systems is a plus including Open Data (DOITT’s DataShare) PASSPort, FMS, PIP, APT. Working knowledge of database back-end systems (i.e. AWS Redshift, SQL Server, Oracle, PostgreSQL). Familiarity with Data Warehouse concept (Kimball), fact tables, slowly changing dimensions types. Hands-on experience with version control (i.e. GitHub, BitBucket or AWS CodeCommit). Familiarity with testing and deployment automation. Knowledge of AWS-based solutions (e.g. CodeDeploy) is a plus. User requirements analysis. Ability to multi-task and handle diverse responsibilities. Experience writing technical documentation. Additional Information To best serve the City we represent, MOCS seeks individuals from a variety of backgrounds who can bring different perspectives to contribute to the work of the office. MOCS also seeks candidates who want to contribute to a work environment that values teamwork, inclusion and respect. As a current or prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. Please review the following notice to see if you may be eligible for programs and how to apply: https://www1.nyc.gov/assets/mocs/downloads/pdf/2022.04.06_final_SLDNotice_CityEmployeesJobApplicants.pdf. For additional student loan information, please visit https://www1.nyc.gov/site/dca/consumers/Student-Loans.page. To Apply External Applicants, please go to www.nyc.gov/jobs and search for Job ID#: 531048. Current City Employees, please go to www.nyc.gov/ess and search for Job ID#: 531048. Mayor’s Office of Contract Services is an equal opportunity employer. Mayor’s Office of Contract Services recognizes the unique skills and strengths gained through military service. Veterans and service members of the U.S. Armed Forces are strongly encouraged to apply. Special accommodations provided to applicants with disabilities. Please contact MOCS Disability Service Facilitator at disabilityaffairs@mocs.nyc.gov or 212-298-0734 only to request an accommodation. No other phone calls or personal inquiries permitted. For technical assistance, please use the following supported browsers: Chrome 35 and above, Firefox 24 and above, Internet Explorer 9 and above, and Safari 6 and above. If you encounter any errors, please clear your cache (web browser history). For instructions, please visit https://a127-jobs.nyc.gov/psc/nycjobs/EMPLOYEE/HRMS/c/HRS_HRAM_FL.HRS_CG_SEARCH_FL.GBL?Page=NYC_EHIRE_HELP_FL&Action=U&. When navigating this website, you should use only the links and navigational buttons within the pages. Using your web browser’s BACK, FORWARD or REFRESH buttons may cause loss of data or lead to unintentional log outs. Work Location 255 Greenwich Street, 9th floor New York, NY 10007 Residency Requirement New York City residency is generally required within 90 days of appointment. However, City Employees in certain titles who have worked for the City for 2 continuous years may also be eligible to reside in Nassau, Suffolk, Putnam, Westchester, Rockland, or Orange County. To determine if the residency requirement applies to you, please discuss with the agency representative at the time of interview. See DCAS Directive No. 2020-2 (https://www1.nyc.gov/assets/dcas/downloads/pdf/agencies/directive_2020_2.pdf) regarding residency requirement during the COVID-19 emergency."
Data Scientist / Data Engineer,SEVEN,"Marshall, TX 75672",https://www.indeed.com/rc/clk?jk=ae2fad598ffe3650&fccid=3cde71f7f4b78fd8&vjs=3,"Job Description SEVEN Networks develops innovative mobile software solutions that help wireless carriers, mobile device manufacturers, application developers, and end users understand, analyze and optimize the wireless traffic between mobile devices and the cloud. We are looking for a team-oriented Data Scientist or Data Engineer to turn the vast amounts of data collected by SEVEN mobile applications and external data sources into actionable insights for customers of the analytics services, ecosystem partners, and for internal use. This job will be based at our Marshall, Texas headquarters. Responsibilities: Overall responsibility for creating insights from internal and external data sources Provide insight into SEVEN product management and executive team on key performance indicators and improvement opportunities of SEVEN products and users at the marketplace Provide analytics and insights on user behavior, network performance, and mobile application performance to respective customers and ecosystem partners Drive and design improvements to SEVEN mobile products to incorporate data collection that allows continuously better insights Drive and design improvements to SEVEN analytics products from data collection to data frameworks, processing, dashboards and presentation Work with customers and customer support in troubleshooting as a subject matter expert in mobile analytics Qualifications: 2+ years of relevant experience in analysis and statistics, and corresponding analytics engineering skills Technical or Scientific Master’s degree is required with strong background in mathematics. Ph.D. or other advanced degrees are desirable Experience in SQL, R, Python for analytics, combining data from multiple sources, experience in cleaning up data before jumping to conclusions Excellent verbal, written and visual presentation skills Demonstrated ability and curiosity to find and explain stories and insights from the granular data, connecting the data to real-world benefits Experience in business intelligence packages is preferred Experience in Hadoop is preferred Passion for mobile applications and smartphones Job Information Industry Technology City Marshall State/Province Texas Country United States Zip/Postal Code 75672"
Senior Data Engineer,JBS Custom Software Solutions,"Chadds Ford, PA 19317",https://www.indeed.com/rc/clk?jk=befd3270a832ec36&fccid=f1025429adfb97fc&vjs=3,"JBS is looking for someone experienced with strong knowledge of data modeling and SQL experience Required Skills 3+ years of experience with one or more BI tools (Tableau, Qlik, Power BI) Hands on experience with AWS services Experience with AWS QuickSight Data bricks experience (Python, Spark, PySpark) Proven abilities to take initiative and be innovative Strong analytical and problem-solving skills in translating business requirements and problems into innovative technical solutions Experience with writing complex SQL queries Strong knowledge of data analysis and visualization Strong knowledge of ETL and data modeling Strong experience with debugging and issue resolution Experience on working with Clients/Product owners on requirement collection and user experience improvement. Working with business analysts on document requirements and solutions and other developers to curate data for reports Ability to create quick prototypes and proof of concepts Ability to work in an agile, collaborative environment, take imitative on developing Stories for BI and Analytics needs Experience in using Agile collaboration tools like Jira, Confluence Nice To Have Cloud Technologies such as Redshift, RDS, S3, glue, lambda Logical Maths Data Visualization Tools (Microstrategy, Power BI, Looker) Benefits This is a full-time W2 employee position with the following benefits: Competitive base salary Paid overtime Generous PTO policy, company holidays 401k with company match Health, Dental, Life, LTD As an equal opportunity employer, JBS does not discriminate in hiring or terms and conditions of employment on the basis of any federal, state, or locally protected class. JBS only hires individuals authorized for employment in the United States on a W2 basis."
Data Engineer,The RMR Group,"Newton, MA 02458 (Nonantum area)",https://www.indeed.com/rc/clk?jk=5fbe72eea0e88e4b&fccid=b61d60f5433a7b3a&vjs=3,"Overview: The Data Engineer will play a pivotal role in operationalizing the most-urgent data and analytics initiatives for The RMR Group’s business initiatives. The bulk of the data engineer’s work would be building, managing, and optimizing data pipelines and then moving these data pipelines effectively into production for key data and analytics consumers. Data engineers also need to guarantee compliance with data governance and data security requirements while creating, improving and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse, and vastly improved time-to-solution for The RMR Group’s data and analytics initiatives. This role will require both creative and collaborative working with IT and the wider business. It will involve evangelizing effective data management practices and promoting a better understanding of data and analytics. The data engineer will also be tasked with working with key business stakeholders, IT experts, and commercial real estate experts to plan and deliver optimal analytics and data science solutions. Responsibilities: Serve as a key contributor to identify, evaluate, and execute the development and implementation of data infrastructure. Perform analysis on large datasets to make and implement recommendations for maximizing customer experience Assists in the design and implementation of relational databases and structures as needed Works collaboratively with Application development teams throughout the product development process, to ensure optimal usage of SQL Server for storage and transaction processing Build data pipelines with Microsoft SQL Server Business Intelligence stack including relational databases, data cubes (tabular/multidimensional), SQL Reporting, Power BI, and other tools as needed. Managed data pipelines consist of a series of stages through which data flows. These data pipelines must be created, maintained, and optimized as workloads move from development to production for specific use cases. Architecting, creating, and maintaining data pipelines will be the primary responsibility of the data engineer. Writes, refines, and optimizes T-SQL code for maximum performance, reliability, and maintainability Participates in developing cutting-edge storage design structures and data processing flows Creates documentation for both new and existing code Drive automation through effective metadata management: The data engineer will be responsible for using innovative and modern tools, techniques, and architectures to partially or completely automate the most common, repeatable, and tedious data preparation and integration tasks to minimize manual and error-prone processes and improve productivity. The data engineer will also need to assist with renovating the data management infrastructure to drive automation in data integration and management. Collaborate across departments: The data engineer will need strong collaboration skills to work with varied stakeholders within the organization. In particular, the data engineer will work in close relationship with business experts in refining their data requirements for various data and analytics initiatives and their data consumption requirements. Educate and train: The data engineer should be curious and knowledgeable about new data initiatives and how to address them. This includes applying their data and/or domain understanding in addressing new data requirements. They will also be responsible for proposing appropriate (and innovative) data ingestion, preparation, integration, and operationalization techniques in optimally addressing these data requirements. The data engineer will be required to train counterparts in these data pipelining and preparation techniques, which make it easier for them to integrate and consume the data they need for their use cases. Participate in ensuring compliance and governance during data use: It will be the responsibility of the data engineer to ensure that the data users and consumers use the data provisioned to them responsibly through data governance and compliance initiatives. Become a data and analytics evangelist: The data engineer will be considered a blend of data and analytics “evangelist,” “data guru” and “fixer.” This role will promote the available data and analytics capabilities and expertise to business unit leaders and educate them in leveraging these capabilities in achieving their business goals. Participate in logic and technical design, peer code reviews, unit testing, and documentation of code developed. Participate in agile development teams, including interacting with both business analysts and end-users to come up with well-performing and scalable solutions. Qualifications: Bachelor's degree in Computer science, statistics, applied mathematics, data management, information systems, information science, or a related quantitative field or equivalent work experience is required. 5+ years of experience developing SQL/T-SQL including, Single-row and Multi-row functions, complex joins, Common Table Expressions (CTEs), Procedures, Packages, ETL jobs, and Data linages in ADF. Strong ability to design, build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata, and workload management. The ability to work with both IT and business in integrating analytics and data science output into business processes and workflows. Strong experience with popular database programming languages including SQL for relational databases and knowledge of upcoming NoSQL/Hadoop oriented databases like MongoDB, Cosmos DB, others for nonrelational databases. Strong experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures, and integrated datasets using traditional data integration technologies. These should include ETL/ELT, data replication/CDC, message-oriented data movement, and API design. Strong experience in working with and optimizing existing ETL processes and data integration and data preparation flows and helping to move them in production. Experience working with popular data discovery, analytics, and BI software tools like Power BI, Tableau, Alteryx, and others. Experience with the Microsoft SQL Server Business Intelligence stack (SSAS, SSIS, SSRS), and Excel/Power Query Ability to apply DevOps principles to data pipelines to improve the communication, integration, reuse, and automation of data flows between data managers and consumers across an organization Commercial real estate industry knowledge or previous experience would be a plus. Experience with agile and lean development methodologies (SCRUM/Lean). Must be a self-starter with excellent problem-solving skills and excellent written/verbal communication skills. Knowledge and experience with cloud data management and analytics with Microsoft Azure or Amazon AWS are strongly preferred. Excellent interpersonal and organizational skills. RMR considers the safety of its employees a top priority. As part of this commitment, RMR requires all new employees to be fully vaccinated against COVID-19. Qualified candidates who are offered the opportunity to join RMR will be required to provide proof of vaccination prior to the first day of work. Applicants who need additional information concerning RMR’s vaccination policy should contact Diane Proctor, Vice President, Human Resources at Dproctor@rmrgroup.com Company Overview: The RMR Group (Nasdaq: RMR) is a leading U.S. alternative asset management company, unique for its focus on commercial real estate (CRE) and related businesses. RMR’s vertical integration is supported by nearly 600 real estate professionals in over 30 offices nationwide who manage over $33 billion in assets under management and leverage 35 years of institutional experience in buying, selling, financing and operating CRE. RMR benefits from a scalable platform, a deep and experienced management team and a diversity of direct real estate strategies across its clients. RMR’s mission is to create long term value for our clients by managing their investments and assets “like we own it” – an approach that consistently and repeatedly generates opportunities for all our employees, investors and stakeholders. We are guided by six core values: Integrity at Our Core. Perform Passionately and Effectively. Inspired Thinking. Like We Own It. Power of We. Mutual Respect. RMR has been rated a Top Place to Work by The Boston Globe and GlobeSt.com, and has been recognized by the U.S. Environmental Protection Agency (EPA), the Building Owners and Managers Association (BOMA) International and the Institute of Real Estate Management (IREM), among others (listed here), as a CRE industry leader. Visit our website to learn more about what makes The RMR Group a rewarding place to build a career. Follow RMR on LinkedIn and on Twitter @The_RMR_Group. The RMR Group is an equal opportunity employer. Qualified applications will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click here . If you’d like more information on your EEO rights under the law, please click here ."
"Software Engineer, Ingestion and Data Processing",Splunk,"San Diego, CA 92103+12 locations",https://www.indeed.com/rc/clk?jk=934061344ac795ec&fccid=aef928e89977f7f0&vjs=3,"Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and seek to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun and most importantly to each other’s success. Learn more about Splunk careers and how you can become a part of our journey! Role: Ingestion and Data Processing team is a dynamic technology group with a mission to be the primary data processing path for any type of data transformation and routing activity in near real-time. If you possess a passion for extraordinary technology and embrace the challenge of working at the frontier of what is possible in the industry today, then this position is for you. We are building state-of-the-art capabilities, real-time messaging and streaming systems, support tools, and automation instrumentation that will greatly impact how our customers successfully use data to improve their businesses performance, scalability, profitability, and market strategies. We have two teams in rapid growth: Stream Processing Service (SPS) is built on top of Apache Flink, is a stream processing platform that allows customers to define stream processing pipelines without lower-level programming languages. SPS includes the ingestion, routing, and processing of unbounded data sets and reduces the time-to-insights from days to near-real-time. SPS is a critical component to enable our customers and their data to transition seamlessly to the cloud. Messaging as a Service (Maas) is based on Apache Pulsar and provides a streaming event store for multiple sources arriving into Splunk Cloud. MaaS is a streaming message store that allows consumers to store, partition, and consume streaming events with high throughput and low latency. It aims to be the event streaming backbone for Splunk Cloud and is integral to the Data Processing ecosystem similar to the interaction between RAM and CPUs in computers. In this role, you will Own and be accountable for the design and development of multiple features in the ultra-high performance system, processing massive amounts of data Pay extra attention to non-functional requirements (Performance, Scalability, Reliability, High Availability etc.) Be a role model that ensures the team is following Agile software development and quality standards Regularly lead design and code reviews, and participate in architecture discussions Help team estimate development work, often across a multiple sprint timelines Understand the business use cases and contribute to product direction by prototyping innovative ideas See opportunities for engineering improvements or directions, and evangelize these successfully Receive guidance from principal engineers in their area on thinking beyond their current product features and more towards overall product architecture Participate in customer engagements & partner concerns and drive overall resolution Build healthy relationships with multi-functional teams Work with product manager to influence product feature definition Requirements: To be a successful candidate, you have: Expertise on two or more mainstream programming languages, such as Go or Java Expertise on developing and working with thoughtfully designed HTTP APIs, such as REST or GraphQL Expertise on test-driven development, developing different levels of automated tests, such as unit test, functional test, integration test, system test, or performance / load test Proficient with CI/CD, such as Jenkins, GitLab CI, or Bitbucket pipeline Proficient with modern version control system, such as Git Proficient with development on multiple operating systems, such as Linux or Unix Able to learn new technologies quickly Capable of coordinating and coaching the junior members in the team Bachelor’s degree in Computer Science, Computer Engineering or equivalent Plus: Not required, and would be good to have: Experience with cloud technologies, such as AWS, Azure, or GCP. Ideally with certifications Experience with container technologies, such as Docker. Ideally with container orchestration such as Kubernetes or Docker Swarm Experience with stream processing platform, such as Flink, Spark or equivalent Experience with messaging system, such as Apache Pulsar, Kafka or equivalent Experience with leading or contributing to open source projects What We Offer You: A constant stream of new things for you to learn. We're always expanding into new areas, bringing in open source projects and contributing back, and exploring new technologies. A set of exceptionally talented and dedicated peers, all the way from engineering and QA to product management and customer support. Growth and mentorship. We believe in growing engineers through ownership and leadership opportunities. We also believe mentors help both sides of the equation. A stable, collaborative and supportive work environment. We don't expect people to work 12-hour days. We want you to have a successful time outside of work too. Want to work from home sometimes? No problem. We trust our colleagues to be responsible with their time and dedication, and believe that balance helps cultivate an extraordinary environment. We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records. (Colorado only*) Minimum base salary of $95,000.00. You may also be eligible for incentive pay + equity + benefits.*Note: Disclosure per sb19-085 (8-5-201 et seq)."
Data Engineer,Tesseract,"Remote in Palo Alto, CA",https://www.indeed.com/rc/clk?jk=9ded7d34e411413f&fccid=eabcaabe7c00e7e8&vjs=3,"Who We Are Tesseract's mission is to democratize healthcare delivery to everyone on a global scale. We are reinventing medical devices to leverage the health information in the human eye and championing a new era of healthcare by creating portable, affordable, easy to use, connected devices for early disease detection and monitoring. Tesseract is well-funded and recently raised a series B round of $80M. We are part of 4Catalyzer - a rapidly growing health-tech incubator founded by Dr. Jonathan Rothberg, an award-winning scientist and highly successful serial entrepreneur. Our 4Catalyzer sister companies include Butterfly Network, the first whole-body Ultrasound-on-ChipTM, and Hyperfine, the first FDA-cleared portable MRI. We are fostering a culture of technical excellence and positive teamwork to solve real-world problems that help improve healthcare for billions of people around the world. Joining Tesseract is the opportunity to redesign the future of healthcare through the power of technology. Join us on this journey to maximize global impact, motivated by the idea that our products will change lives, including the ones of people you love. What We Live By Patients First: We are driven to make products that will improve people's lives. Data-Driven: We search for the best solutions: objective, backed by data, and optimized for speed, simplicity and scale. Team-Oriented: We collaborate with and support each other every step of the way. What You Will Be Doing Tesseract Health is looking for an experienced Data Engineer to lead the development of our clinical data infrastructure, which will help us develop industry-leading disease prediction applications. This engineer is someone who is passionate about the cloud, data infrastructure, and the ""pipes"" that allow information to flow between services. As a Data Engineer at Tesseract, you will create the infrastructure for Tesseract Health to be able to ingest medical data in a regulatory compliant way, structure it, and work easily with it across our systems As part of our team, your core responsibilities will be to: Become the owner and subject matter expert for data engineering at Tesseract. Design systems to solve problems across data ingestion, data access, EHR integration, and backend system design. Drive the development of Tesseract Health's EHR integration for patient information and work orders. Create a seamless integration between Tesseract Health and existing office workflows. Create the architecture for our ML team to work with retinal images, transforming data and annotations into structured and versioned datasets. Develop solutions to streamline data sharing with partners and 3rd parties, including de-identification of data. Work with a talented team of software engineers with skills in full-stack development and machine learning. Support new feature development, and design scalable systems to help us bring our groundbreaking medical device to market. What We Are Looking For Baseline Skills, Experiences, & Attributes 3+ years experience in backend engineering, data engineering, or related field Experience designing APIs (REST, GraphQL) and developing data pipelines using state-of-the-art tooling (ex. Airflow, dbt, Snowflake) Strong understanding of cloud infrastructure with Amazon Web Services (AWS), including serverless architecture (Lambda) and infrastructure-as-code (ex. CloudFormation, Terraform, CDK) Knowledge of SQL and NoSQL databases, including relevant AWS tooling (Redshift, Aurora, DynamoDB, Glacier) Experience working in production software development with Python Experience creating cross-team agreement on engineering solutions and architecture decisions Preferred Qualifications Experience with Electronic Health Record integration, including Redox Engine or Epic Experience working with medical image data, especially DICOM, for production and regulated clinical applications. Experience with Picture Archiving and Communication Systems (PACS) and DICOM image viewers Experience working with image annotations / labels for training ML models High-level knowledge of machine learning, computer vision, and model development Experience with data privacy, HIPAA, PHI / PII deidentification, and role-based access controls What We Offer Fully covered medical insurance plan, and dental & vision coverage (as a health-tech company, we place great worth on our team's well-being) Competitive salaried compensation (you should feel appropriately valued and excited to join us) Equity (employees are important and should have a stake in our success) Pre-tax commuter benefits (let's make your commute costs more reasonable) Free onsite meals + kitchen stocked with snacks (sponsored brain fuel) While we would love to see you face to face everyday, we are flexible and open to people being remote. We will always have opportunities to meet your coworkers off the screen at one of our many team outings. (no pressure though) 401k plan (everyone should be encouraged to save for their retirement adventures) The opportunity to build a revolutionary healthcare product and save millions of lives! For this role, we provide visa assistance for qualified candidates. Tesseract does not accept agency resumes. Tesseract is an E-Verify and equal opportunity employer regardless of race, color, ancestry, religion, gender, national origin, sexual orientation, age, citizenship, marital status, disability or Veteran status. All your information will be kept confidential according to EEO guidelines. #LI-Remote"
Big Data Engineer,harbinger-systems,United States+1 location,https://www.indeed.com/rc/clk?jk=d3fbf3de634dc3eb&fccid=030ece1ae7a221a1&vjs=3,"Date: 14-Jun-2022 Location: US Company: harbinger Position: Data Engineer Experience: 4-6 years Mode: Full Time Mode: Full Time/Permannet Job Description: a. Skill set: Java Spring Batch / SQL / Amazon RedShift / Processing of large data set 1. 4+ years of overall experience 2. 2+ years of experience in ETL and Data Warehousing / Big Data. 3. 2+ years of experience in Java (Nice to have) 4. 2+ years of experience in SQL a. Project: 1. Build and maintain ETL jobs 2. Maintain data lake built on Amazon RedShift. About Harbinger Harbinger is a three-decade young Global Software Services and Product company, headquartered in Pune, India. We build software products for our customers in the domains of HR Tech, Health Tech, Content and Learning Tech. These are exciting times at Harbinger! Powered by an ambitious growth plan built on Innovation, Engineering Excellence and Customer centricity, Harbinger is on a journey of constant reinvention, making the most of upcoming technology and business trends. Agility, Professionalism, People Development, and Meritocracy are the foundation of our culture that pivots on trust, transparency, and continuous learning. We are proud to be a diverse and inclusive organization and an equal opportunity employer. We thrive on an employee-centric work environment, that is not only dynamic and fast-paced, but also focuses on personal and professional development. An open culture, a friendly environment, opportunities to grow under the mentorship of talented seniors and technically sound colleagues, flexible work from home options, a host of employee benefits, and an opportunity to work on cutting edge technologies are some of the things you can expect to experience in Harbinger."
Sr Data Engineer,Gannett,"Remote in McLean, VA 22107+2 locations",https://www.indeed.com/rc/clk?jk=f531dd5be6599e6f&fccid=1230acb7e56c6df5&vjs=3,"Gannett Co., Inc. (NYSE: GCI) is a subscription-led and digitally focused media and marketing solutions company committed to empowering communities to thrive. With an unmatched reach at the national and local level, Gannett touches the lives of millions with our Pulitzer-Prize winning content, consumer experiences and benefits, and advertiser products and services. Our current portfolio of media assets includes USA TODAY, local media organizations in 46 states in the U.S., and Newsquest, a wholly owned subsidiary operating in the United Kingdom with more than 120 local news media brands. Gannett also owns the digital marketing services companies ReachLocal, Inc., UpCurve, Inc., and WordStream, Inc., which are marketed under the LOCALiQ brand, and runs the largest media-owned events business in the U.S., USA TODAY NETWORK Ventures. To connect with us, visit www.gannett.com. Sr Data Engineer Position Summary Our Senior Data Engineer is responsible for ETL pipelines in the Gannett Enterprise Data Platform. You create resilient, scalable data pipelines that help our product, business and marketing teams innovate while understanding key performance & business metrics. The ideal candidate is excited to work with large diverse datasets and with a diverse team. The Data Engineering team is part of Gannett’s Enterprise Data Management organization. Our charter is to build, support, and govern an enterprise data platform with reliability, accessibility, and quality as key tenets. The Senior Data Engineer is a direct report to the Data Engineering Director. Responsibilities Build, maintain and optimize data pipelines for our Enterprise Data Platform using Google Cloud Platform technologies. Ingest new data sources from initial discovery & data architecture, through ETL authoring, operationalizing using Dataflow, Airflow (Cloud Composer) DAGs, and post launch lifecycle. Research and test new big-data technologies and tools. Advanced SQL queries, and modeling. Help drive the roadmap of the Data Engineering team and Gannett’s Enterprise Data Platform. Engage vendors with required features to meet business needs. Leverage the full value out our vendor integrations and APIs. Optimize BigQuery and ETL resources to decrease spend & increase performance. Help guide team of engineers on best practices, standards, and toolsets to author ETL Engineering pipelines Minimum Qualifications Bachelor’s degree in data science, computer science or similar majors with a GPA of at least 3.0 or equivalent experience 5+ years of experience in Data Engineering 5+ years of experience in at least one OOP language, preferably Python Deep SQL knowledge / experience Experience in complex pipeline task management (i.e., Airflow and Beam) Experience with Github Desired Qualifications Google Cloud Platform tools or equivalent platform experience using tools s/a BigQuery, Dataflow / Apache Beam, Cloud Composer / Airflow, Apache Spark, Pub/Sub Experience in Apache Beam Experience with Scala Experience with Scalr/Terraform Experience with CI/CD #LI-DM1 #LI-Remote Gan.Corporate Gannett Co., Inc. is a proud equal opportunity employer committed to building and maintaining a diverse workforce. As such, we will consider all qualified applicants for employment and do not discriminate in connection with employment decisions on the basis of an applicant or employee’s race, color, national origin, ethnicity, ancestry, citizenship status, sex, gender, gender identity, gender expression, religion, age, marital status, personal appearance (including height and weight), sexual orientation, family responsibilities, physical or mental disability, medical condition, pregnancy status (including childbirth, breastfeeding or related medical conditions), education, genetic characteristics or information, political affiliation, military or veteran status or other classifications protected by applicable federal, state and local laws in the jurisdictions where Gannett employs employees. In addition, Gannett Co., Inc. will provide applicants who require a reasonable accommodation, as a result of an applicant’s disability or religion, to complete this employment application and/or any other process in connection with an individuals’ application for employment with Gannett Co., Inc. Applicants who require such accommodation should contact Gannett Co., Inc.’s Recruitment Department at Recruit@gannett.com."
Data Engineer,Aegion Corporation,"Indianapolis, IN 46077+5 locations",https://www.indeed.com/rc/clk?jk=d510d574e11218ed&fccid=a533a1eb2195c01e&vjs=3,"Overview: FULLY REMOTE Aegion Corporation and its family of companies shield and protect the world’s infrastructure from degradation and corrosion with a variety of technologies and services. With operations in multiple countries across the world, a career at Aegion will provide challenging and innovative opportunities with a company that is a technology leader in their industry. Aegion’s IT organization includes a team of exceptionally talented individuals responsible for supporting Aegion’s growing global businesses. The IT organization is team-oriented and forward thinking with multiple opportunities to develop an array of new business capabilities and technological skills. Aegion’s BI Team is looking for experienced Analytics professionals with the ability to develop our Enterprise Data Warehouse and Analytics environment. Our Data Operations Team supports the global functions of our business across all divisions of the enterprise. As a member of the Data Operations team, team members will have the opportunity to perform end-to-end development to include requirements gathering and analysis, data modeling, ETL development, design and tuning, semantic layer design, report, and dashboard creation as well as migration and administration activities. Responsibilities: The successful candidate will demonstrate a passion for delivering data analytics to all levels of an organization, flexibility, team-player attitude, excellent communication skills, and will be driven by curiosity without the fear of failure. The IT organization offers a challenging environment focused on teamwork and delivering value added solutions for the organization. We consistently strive to attract and retain intelligent, creative, energetic, and fun employees with a focus on building exceptional teams. Typical responsibilities and skills of this position include: Design and develop analytics solutions: Develop reports and dashboards Assist in monitoring and optimizing the analytics environment Provide support and education to analytics consumers and power users Use your creativity and experience to model and build an Enterprise Data Warehouse Create ETL, Semantic Layer and Data Warehouse modeling standards Develop semantic layer and metadata repositories Perform ETL, Semantic Layer and Reporting migrations Create, enhance, and tune stored procedures Execute throughout all phases of an analytics implementation Communicate with business leaders at all levels of the organization and translate business requirements into successful data warehouse & analytic solutions. jobsnow Qualifications: Must have a minimum 3 to 5 years of experience in a business analytics position within an IT department Must have a minimum of three years delivering Power BI solutions and hands on experience with DAX, Power Query and the Power BI Service Must have a minimum three to five years developing data warehouse solutions to include DDL creation, source to target mapping, hands on ETL experience, and working knowledge relational data warehouse modeling to include star and snowflake schemas Must have an understanding of modern reporting strategies including dashboard creation and how to tell a data story with actionable analytics Four-year college degree in Computer Science, Information Management, specialized training, or equivalent work experience Strong analytical, critical thinking and problem-solving capabilities Solid understanding of Agile Scrum project management methodologies We offer a Competitive Salary with Career Growth Opportunities and a Full Benefits Package including Medical, Dental and Vision Insurance, Matching 401k, Tuition Assistance, Paid Time Off, and much more. Aegion is an Equal Opportunity Employer. Equal opportunity is a sound and just concept to which Aegion is firmly bound. Aegion will not engage in discrimination against, or harassment of, any person employed or seeking employment with Aegion on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, non-disqualifying disability, status as a protected veteran or other characteristics protected by law. VEVRAA compliant – priority referral Protected Veterans requested"
Data Engineer II,EMC Insurance,Remote,https://www.indeed.com/rc/clk?jk=476daef725bbc5d2&fccid=1ab6847930ce296b&vjs=3,"At EMC, you'll put your skills to good use as an important member of our team. You can count on gaining valuable experience while contributing to the company's success. EMC strives to hire and retain the best people by engaging, developing and rewarding employees. This position is open to remote work from home anywhere in the United States Summary: Develops and maintains moderately complex automated ETL pipeline architecture using assigned tools and programming languages. Leads small projects or supports larger initiatives as part of a team and partners with users to understand business requirements. Develops data objects for business analytics using data modeling techniques. Develops and maintains data warehouse and landing zone metadata, data catalog, and user documentation for internal business customers. Essential Functions: Develops, tests, and maintains pipeline architecture and infrastructure: Develops and maintains moderately complex automated ETL pipeline architecture using assigned tools and programming languages Develops and maintains moderately complex automated ETL monitoring and alarming solutions using assigned languages and services Implements and supports reporting and analytics infrastructure for internal business customers using AWS services Develops, tests, and deploys code using internal software development toolsets, including the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalogs and data queries Maintains legacy data solutions to ensure functionality until replaced with new technology Data analysis: Leads small projects or supports larger initiatives as part of a team Partners with users to understand business requirements Collaborates with team on conceptualizing and developing new data solutions to meet the business requirements Researches, performs analysis and proposes effective solutions related to systems development and enhancements Reviews potential adjustments or modifications for impacts on other programs Collaborates with business areas to develop solutions in the legacy systems to meet business requirements Data modeling: Develops data objects for business analytics using data modeling techniques Develops and optimizes data warehouse and landing zone tables using best practices for data definition language (DDL), physical and logical tables, data partitioning, compression and parallelization Education & Experience: Bachelor’s degree, preferably in a computer related field or equivalent relevant experience Two years of data integration development experience, or related experience Candidates meeting the below requirements may be eligible for other levels: Bachelor’s degree, preferably in a computer related field or equivalent relevant experience Five years of data integration development experience, or related experience Knowledge, Skills & Abilities: Good SQL knowledge and experience working with relational databases Good analytic skills to work with unstructured datasets Good knowledge of applicable programming languages, such as Python Working knowledge of AWS cloud services such as S3, Glue, Athena, Cloudwatch and Lambda preferred Knowledge of Informatica preferred Knowledge of Snowflake preferred Strong ability to build processes supporting data transformation, data structures, metadata, dependency and workload management Good ability to manipulate, process and extract value from large disconnected datasets Strong verbal and written communication skills Strong attention to detail, organizational and multi-tasking skills required with the ability to adapt to changing priorities Ability to maintain confidentiality Per the Colorado Equal Pay for Equal Work Act, the hiring range for this position for Colorado-based team members is $75,000 - $95,500. Our employment practices are in accord with the laws which prohibit discrimination due to race, color, creed, sex, sexual orientation, gender identity, genetic information, religion, age, national origin or ancestry, physical or mental disability, medical condition, veteran status, citizenship status, marital status or any other consideration made unlawful by federal, state, or local laws. All of our locations are tobacco free including in company vehicles. To learn more about why you’re gonna love it here, watch the video below."
Data Engineer,PSCU,"Remote in Saint Petersburg, FL 33716",https://www.indeed.com/rc/clk?jk=6145449e2cdf7003&fccid=5c11854828d83cbf&vjs=3,"Join the people helping people. For people drawn to serving others through their work, PSCU is a place to thrive, as we serve our credit union members best by taking care of each other first. If you want to help shape an industry, challenge yourself, and invest in your own future, this is the place for you. PSCU is a highly accessible environment where you’re empowered to think on your feet, work from your heart, and discover the very best version of your professional and personal self. “Our Momentum. Your Moment.” This application is the first step in seizing your moment. Design and construct enterprise-wide data and information architecture to support business intelligence and data warehouse efforts. Architect and implement data warehouse and data mart concepts, and design and oversee strategies for data loads, metadata, repository, and business intelligence security and performance. Partner with department and enterprise-wide leadership to prioritize data and information requirements and help determine strategic direction of data warehouse efforts. Responsible for the following tasks: in-depth experience in developing, analyzing complex SQL and solving complex data problems for continuous business support; in-depth experience in Data Governance, MDM solutions, including integration, sourcing, data services, de-duplication, and data archiving for projects; partnering with department and enterprise-wide leadership to understand and prioritize data and information requirements and determine strategic direction for data warehouse efforts; overseeing enterprise-wide data/information architecture and design; leading business analysis, data acquisition, access, analysis, and action; leading continuous improvement efforts to enhance performance and provide increased business intelligence functionality; architecting and implementing data warehouse and data mart concepts; architecting data modeling solutions; architecting ETL processes using data integration tools, scripts, and stored procedures to extract data from multiple systems, applications, and other sources, and loading data into enterprise data warehouse; leading enterprise projects through all phases of System Development Life Cycle (SDLC) and/or agile process; and performing other duties as assigned. REQUIREMENTS: Bachelor’s degree or foreign equivalent in Computer Science, Engineering, or a related field. Six years of experience in a related technical field using the following tools and technologies required: ETL/ELT, SQL, SSIS, Informatica 10.2.0, SAP Data Services 12.x/13.x/14.x, SAP Business Objects, Qliksense, Erwin, Python, SQL, Shell Scripting, SAS Enterprise Guide 7.13, Teradata 15/16, Oracle, SQL Server, MySQL, and Mongo DB. Must have legal authority to work in the U.S. EEOE. Pay Equity PSCU is committed to pay equity and a competitive benefits package. The typical annual hiring range for this position based on relevant experience and internal equity is: $83,500.00 to $122,433.33 *Note: T he amount shown is based on full time annual salary and would be prorated based on role. In addition this position is eligible for an incentive plan, based on performance. Benefits At PSCU, everything we do recognizes the fact that our employees are our most important asset. That’s why we are committed to a work/life integration that goes above and beyond to ensure that you have quality time at home with your family and/or to pursue outside interests and aspirations. We back this up with generous PTO, the opportunity to work remotely, flexible scheduling, and a management team that understands how to adjust when the unexpected curveballs of life happen. Check out the comprehensive benefits PSCU has to offer that further solidifies our reputation as a company that just “gets it” when it comes to balancing life’s planned and unplanned events while equipping you with all the tools for growth. PSCU offers: Beautiful, state-of-the-art campuses Endless opportunities for advancement Competitive wages Generous paid time off and paid holidays Our benefits package includes: Medical with telemedicine, no-cost diabetes supply program, and expert medical opinion services Dental and Vision Basic and Optional Life Insurance Company Paid Disability Insurance 401 k (with employer match) Health Savings Accounts (HSA) with company provided contributions Flexible Spending Accounts (FSA) Supplemental Insurance Legal Plan Pet Insurance Adoption Assistance Plan Mental Health and Well-being: Employee Assistance Program (EAP) Mental health and Well-being: Virtual mental health support and resources Tuition Reimbursement Wellness program Back-up child care program Benefits are subject to generally applicable eligibility, waiting period, contribution, and other requirements and conditions. If this position requires you, now or in the future, to perform your function or report onsite at a PSCU location or travel on behalf of PSCU, entry procedure and Covid protocols are in place that will require your adherence as a condition of employment. PSCU manages these procedures and protocols requiring your use of third party digital applications, in compliance with federal, state, and local laws. Please Note: For roles with certain levels of travel and/or company car usage, PSCU will require a completed Motor Vehicle Record Check , valid driver's license, and proof of insurance at time of hire and annually. All applications are reviewed by an AIRS Certified Diversity and Inclusion Recruiter. Learn more about our commitment to Diversity, Equity, and Inclusion HERE! As a matter of operational management limitations and business administrative process parameters, remote position assignments at PSCU are geographically restricted to where PSCU currently operates. As a result, we are unable to proceed with applications from those state residents. Applicants are encouraged to apply for other available opportunities for which they qualify. PSCU is an Equal Opportunity Employer. We consider applicants without regard to race, color, religion, age, national origin, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, marital status, veteran status, disability, genetic information, citizenship status , or membership in any other group protected by federal, state or local law. PSCU is an Equal Opportunity Employer that complies with the laws and regulations set forth in the following ""EEO is the Law"" Poster and the ""EEO is the Law"" Poster Supplement . PSCU will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the legal duty to furnish information. For positions based out of our Phoenix, Arizona location, PSCU is an E-Verify Employer. Please click here for the E-Verify Poster in English or Spanish . For information regarding your Right To Work, please click here for English or Spanish . As an ongoing commitment to reasonably accommodate individuals with disabilities, PSCU has established alternative methods to complete the application process. Disabled applicants needing assistance are encouraged to submit resumes via our careers page submission button If further assistance is required."
Senior Mechanical Engineer Data Centers,McKinstry,"Remote in Seattle, WA",https://www.indeed.com/rc/clk?jk=875e163055015223&fccid=69b64ba4e5c499e7&vjs=3,"At McKinstry, we’re proud to be a diverse and passionate group of innovators and problem-solvers, builders and engineers, mentors and students. We believe the world needs curious, forward-thinking, solutions-oriented people who want to make our planet better. We are committed to strengthening our diversity through recruiting, developing, and retaining professionals from all backgrounds, and we believe that promoting diversity, equity, and inclusivity is an integral component of our continuing quest To Build a Thriving Planet. If you are looking to leave a purposeful mark on the world, then McKinstry is the place for you. Here's where you come in: We are currently seeking a Senior Mechanical Engineer to join our team as a member of our growing Engineering and Design division located in Seattle, Washington. Engineers at McKinstry are unsurpassed in their ability to combine innovative problem solving with common sense design applications. Because of our design, build, operate, and maintain (DBOM) process, McKinstry engineers concern themselves not just with the construction of a building, but how it will operate over its entire lifetime. Every design choice is made toward one goal – delivering high performance buildings that ensure occupant comfort and safety, keep energy/operating costs low, maximize client profitability, and protect the environment. You're great at: Department and Team Management Delegates and manages project engineering staff. Coordinates with internal design and construction teams. Identifies resource needs to meet project deadlines. Supervises, trains, and mentors project and lead engineers. Conducts quarterly goal plan reviews. Exercises global decision making by considering other departments within the company such as project management, sales and estimating, accounting, purchasing, etc. Project Management Documents project correspondence, issues, decisions and directions. Applies and coaches McKinstry Engineering standards and procedures. Provides engineering analysis to support sales and early design efforts. Defines, communicates, and manages scope, design intent, and design process for direct supervisor review. Identifies and responds to changes in scope, schedule, budget, or expectations. Demonstrates understanding of overall project objectives and employs creative problem solving to achieve objectives within budget and resources. Prepares, negotiates, and manages design budget and coordinates invoicing. Coordinates with construction and estimating teams to reduce project costs. Coordinates with external clients and stakeholders. Design Demonstrated mastery and able to fully lead a team in delivering mechanical systems design, including calculations, airside systems, piping systems, equipment selection and multi-discipline coordination. Overall responsible for delivering designs to customers by reviewing and providing feedback on engineering calculations and design drawings for design intent, quality, precision, constructability, and construction costs. Guides coordination with internal and external team members. Identifies opportunities for process and technology improvements. Investigates, evaluates, and troubleshoots existing systems. Drives system selection, energy modeling, green building certification, and preconstruction collaboration. Presents options and facilitates decisions for design direction, system selection, energy conservation, and cost savings strategies. Serves as Engineer of Record (Stamping Engineer). Customer Relations Attends early meetings with external customers and stakeholders. Represents McKinstry in the community and develops new potential work. Enhances department and company reputation by generating opportunities to demonstrate leadership in industry and/or regulatory groups, or the public forum Develops and maintains relationships with customers and upper management. What we would like to see from you: Bachelor’s degree in engineering required or equivalent work experience required. P.E. registration is required. Twelve (12) years of experience in mechanical design, engineering or related field preferred. Advanced knowledge of Microsoft Office Suite and Microsoft Teams. Working knowledge of AutoCAD and Revit required. Working knowledge of whole building energy analysis results required. Working knowledge of Total Cost of Ownership and or Life Cycle Cost Analysis required. Demonstrated public speaking experience preferred. Experience in managing a design team is required. LEED accreditation preferred. Why McKinstry: Transformational change requires bold action. We must decarbonize our buildings and energy assets to combat climate change. We must tackle the affordability crisis by innovating waste out of our supply chain and dramatically cutting costs through improved productivity. We must deliver equitable outcomes to ensure healthy, high-performing buildings for all. People represent our most valued asset. By investing in our employees, we are also investing in the ongoing success of our company. We pride ourselves on offering a comprehensive, PeopleFirst benefits package to promote health and wellness, enhance work/life balance and ensure long-term stability for our employees and their families. Some of these benefits include: Competitive pay backed by 401(k) and profit-sharing plans. Comprehensive medical, prescription drugs, vision, and dental. Up to 16 weeks of paid parental leave. Adoption and IVF assistance. Paid time off. McKinstry University training and development. McKinstry wellness programs and on-site gyms. Community service and employee-directed charitable giving. The pay range for this position in Colorado is $103,050 - $185,130 per year; however, base pay offered may vary depending on job-related knowledge, skills, and experience. A bonus may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. The McKinstry group of companies are equal opportunity employers. We are committed to providing equal employment opportunities to all employees and qualified applicants without regard to sex, gender identity, sexual orientation, age, race, color, creed, marital status, national origin, disability, veteran status, genetic information or any other basis protected by law. This policy applies to all terms and conditions of employment including, but not limited to employment, advancement, assignment, and training. This commitment to Equal Employment Opportunity is made equally as a social responsibility and as an economic and business necessity. McKinstry is a drug-free workplace. Employment is contingent upon successfully passing a pre-employment drug and alcohol test, complying with the requirements of the Immigration Reform and Control Act and a Confidentiality Agreement, in addition to successful outcomes of background and reference checks. #LI-MA1 #LI-Hybrid #LI-Remote"
Data Communications Engineer – III,GTA Telecom,"San Francisco, CA",https://www.indeed.com/rc/clk?jk=f6575681aa2ac72d&fccid=9fab3c5e1c32bced&vjs=3,"Apply Now Looking for a Data Communications Engineer – III for San Francisco, CA. What you will be doing as a Data Communications Engineer – III: This member will be a network and technology expert that will be focused in the areas of 5G and Mobile Edge Compute. This member of technical staff will be responsible for managing the standalone IT network and 4G/5G infrastructure and mobile edge cloud environments for a test and development lab program. This is a technical position focused on supporting the development of technology solutions, testing and incubation of new platforms and the product engineering of greenlit projects. In this role, the candidate will work with internal technology and product groups and external partners to support the development of new solutions. He/She will be responsible for the architecture design and deployment of new 4G/5G and MEC platforms and features and will work very closely with Device testing, Product engineering, Business groups and peer TPD teams. The candidate will be a member of a small team of Sr. Network engineers who manage remote lab access, configure and manage virtual environments to support projects, monitor and troubleshoot problems, and make recommendations on how to streamline development with internal and external partners. What you will bring to the table as a Data Communications Engineer – III: BA in IT/EE or Computer Engineering LOGISTICS The ideal candidate needs to have a strong technical background with experience in wireless and wireline networks, hands on integration experience with MEC/Cloud/IT. Experience working in a customer facing environment Expert understanding of computer technologies and architectures including O/S 3D Printing Experience What you didn’t know about us: Competitive salary Health, Dental and Vision Benefits Short/Long Term Disability and Critical Care/Illness Protection Life Insurance and Retirement Plans Employee Assistance Program With this position, you will get the opportunity to work with our game changing clients and further advance your already valuable experience in the telecom industry! We are Connectors. We thrive on ‘quality over quantity’ and put in the work building strong relationships. We create connections, discover qualities, uncover skills, and place people with accuracy. We are your true partner! We are Collaborators. You’ll be working with a wholly-owned subsidiary of Kelly and part of the Kelly Telecom division. It allows us to be as nimble and fiercely competitive as a startup while having the backing of a multibillion dollar publicly traded company which has been in business for 75 years. With direct access to hiring managers, services don’t stop at standard recruiting processes. We use our expertise to improve your application skills and provide ongoing career support. We give 24/7 Support. We are in this together. We provide around the clock availability, competitive employee benefits, and continuously check-in to make sure things are going smoothly. Check out our Glassdoor page! Kelly Telecom is an equal opportunity employer and will consider all applications without regard to race, genetic information, sex, age, color, religion, national origin, veteran status, disability, or any other characteristic protected by law. For more information click Equal Employment Opportunity is the law. You should know: Your safety matters! Vaccination against COVID-19 may be a requirement for this job in compliance with current client and governmental policies. A recruiter will confirm and share more details with you during the interview process."
"Data Engineer, Creator Services",SoundCloud Inc.,"Los Angeles, CA",https://www.indeed.com/rc/clk?jk=02c6c4b616e2e73b&fccid=d94fec9b74d09e05&vjs=3,"SoundCloud is a next-generation music entertainment company powered by an ecosystem of artists, fans, and thriving communities. As one of the world’s most influential cultural platforms, SoundCloud holds a singular market position as both a music-streaming service with the largest catalog of music, and an artist services and distribution business to help artists grow long-term, successful careers. We're looking for an engineer to join our Creator Insights team in Los Angeles, New York or Berlin. At SoundCloud we care about creators. We enable them to engage with their audience by visualizing insights and getting paid accordingly. We deliver accurate reporting to our partners in a timely manner. You are passionate about building efficient data pipelines, with a solid background in SQL, Python and Scala. You would actively contribute to simplifying the visibility of revenue and provide helpful insights for internal and external users. You will also help us to improve our reporting infrastructure based on Airflow/BigQuery. You are a self-directed learner, team-player and passionate about software development. You are able to build and voice your opinion, and you're open to receiving feedback and learning from it. About us: We are a multinational company with offices in the US (New York and Los Angeles), Germany (Berlin), and the UK (London) We provide a flexible work culture that offers the opportunity to collaborate and connect in person at our offices as well as accommodating work from home We are deeply committed to ensuring diversity, equity and inclusion at all levels of our organization and fostering a community where everyone’s voice, perspective and experience is respected and heard We believe a strong team is made by investing in employees through mentorship, workshops and enrichment opportunities Benefits: Comprehensive health benefits including medical, dental, and vision plans, as well as mental health resources Robust 401k program Employee Stock Ownership Plan Generous professional development allowance Interested in a gym membership, photography course or book? We have a Creativity and Wellness benefit! Flexible vacation and public holiday policy where you can take up to 35 days of PTO annually 16 paid weeks for all parents (birthing and non-birthing), regardless of gender, to welcome newborns, adopted and foster children Various snacks, goodies, and 2 free lunches weekly when at the office Diversity, Equity and Inclusion at SoundCloud SoundCloud is for everyone. Diversity and open expression are fundamental to our organization. With this foundation, we aim to build a social platform and global community for everyone to create, discover, and share sounds. We acknowledge the challenges in our industry and strive to develop an inclusive culture where individual contributions are valued. We are dedicated to creating an inclusive environment for everyone, regardless of gender identity, sexual orientation, race, ethnicity, migration background, national origin, age, disability status, or care-giver status. At SoundCloud you can find your community or elevate your allyship by joining a Diversity Resource Group (groups focused on people of color, LGBTQIA+ folks, and women). You may also participate in inclusive workshops, contribute to our Cultural Moments series, select organizations for the SoundCloud Community Fund to support, and more!"
"Data Automation Engineer, Private Equity Data Venture",Bain & Company,"Chicago, IL+1 location",https://www.indeed.com/rc/clk?jk=5e0d3bf87bd88af4&fccid=48270b2eee62c2c6&vjs=3,"ABOUT US Bain & Company is a global consultancy that helps the world’s most ambitious change makers define the future. Across 63 offices in 38 countries, we work alongside our clients as one team with a shared ambition to achieve extraordinary results, outperform the competition, and redefine industries. We complement our tailored, integrated expertise with a vibrant ecosystem of digital innovators to deliver better, faster, and more enduring outcomes. Our 10-year commitment to invest more than $1 billion in pro bono services brings our talent, expertise, and insight to organizations tackling today’s urgent challenges in education, racial equity, social justice, economic development, and the environment. We earned a gold rating from EcoVadis, the leading platform for environmental, social, and ethical performance ratings for global supply chains, putting us in the top 2% of all companies. Since our founding in 1973, we have measured our success by the success of our clients, and we proudly maintain the highest level of client advocacy in the industry. WHO YOU'LL WORK WITH This role will report into Director, Technology - Private Equity Data Ventures and will work with Bain’s Private Equity Group (PEG) Data Ventures team. Bain’s Private Equity Group (PEG) is the leading consulting partner to the private equity industry and its key stakeholders, with a global practice more than three times larger than any competitor. Our network of more than 1,000 experienced professionals serves private equity and institutional investor clients across the investment life cycle, from deal generation and due diligence to portfolio value creation and exit planning. PEG Data Ventures team’s mission is to build ventures that serve Bain clients, teams, and the broader institutional investor space with proprietary software and data products. The organization drives development, commercialization, and day-to-day running of Bain’s proprietary datasets, data and software businesses. WHAT YOU'LL DO We are developing a suite of data and software ventures to transform how the private equity industry, one of the less digitalized industries historically, obtains and consumes data to generate key investment insights. As one of the early members of the team for this venture portfolio, you will be at the forefront of technological, business model, and delivery model innovation as we build and expand this platform to variety of use cases to transform the institutional investing space globally. The work will require you to deeply understand the needs of a highly sophisticated customer base and address those needs by building solutions that incorporates big data, analytics, and Bain’s proprietary IP. As the Automation Associate you will develop ready to use working software of analytical modules to deliver differentiated insights to Bain’s case teams, clients, all the while developing a library of Bain IP and driving efficiency in delivering to our customers. You will work closely with PEG and PEG Data Ventures leadership and Next Gen technology teams to bring these new ideas to life. This is an opportunity to build a data and software venture from ground up. You will play a key part in defining our culture, ways of working, processes, and more. As you perform and develop in this role, you will receive opportunities to grow within the current role, focus on specific domains, or different products in the future. ESSENTIAL FUNCTIONS Module Development 80% Develop high functioning working prototypes of analytical modules to serve our Private Equity teams to deliver diligence cases that leverages alternative data and automation Build end to end automated workflows to source high-value high-frequency alternative data sources (e.g. web traffic, transaction data, geospatial data, etc.) and convert them into consumable slides for immediate use Build automated analysis pipeline covering data sourcing, validation, aggregation, and storage for use in end deliverables; Implementing and maintaining these analysis pipelines, ensuring data integrity, correctness and clarity Automate slide outputs and excel data, confirming to Bain standards, as part of the automated workflow Partner closely with business and technical stakeholders to refine product requirements, build prototype products, lead testing and iteration, and launch to production Research and develop scalable automation capabilities and methodologies to help drive incremental efficiencies to reports and insights generation workflow IP and Documentation 10% Build and maintain technical documentation, tied with business requirements Ensure and adopt standard software development best practices Build expertise and working knowledge in specific alternative data sources, understand and document gaps Support and Management 10% Provide support for questions from the case teams and clients while helping address issues and roadblocks Support technical teams in migrating the working prototype solution to production Ongoing reporting and management of initiative specific progress and updates ABOUT YOU Education Required Bachelor’s degree from a recognized university Preferred Degree from an analytical field or computer science Experience Required 2-4+years of experience in a software engineer role that includes data analyst and web development Preferred Experience in Private Equity Consulting or Financial Services industry Knowledge, Skills, and Abilities Required Passion for automation and innovation Significant Experience with Python Development Experience with: Using python to handle and manipulate data (e.g. Pandas) Using SQL for reading/writing data Reading/parsing/writing JSON Deploying projects to GitHub Cloud storage and/or app deployment, using AWS and/or Azure REST APIs Building Data Pipelines Demonstrated autonomy and strong project management skills A self-starter with an entrepreneurial flare Strong communication skills, and ability to work effectively with others at Bain or outside vendors Experience with Lean, Agile, and/or ""Fail Fast"" approach to product development Preferred Ability to rapidly absorb, interpret, and apply technical concepts Alteryx, Microsoft VBA, PowerAutomate and/or PowerApps, or other RPA product Basic literacy in Javascript and HTML Experience working in start-ups and other entrepreneurial environment WHAT MAKES US A GREAT PLACE TO WORK We are proud to be [1] consistently recognized as one of the world's best places to work, a champion of diversity and a model of social responsibility. We are currently ranked #3 on Glassdoor's Best Places to Work list, and we have maintained a spot in the top four on Glassdoor's list for the last 13 years. We believe that diversity, inclusion and collaboration is key to building extraordinary teams. We hire people with exceptional talents, abilities and potential, then create an environment where you can become the best version of yourself and thrive both professionally and personally. We are publicly recognized by external parties such as Fortune, Vault, Mogul, Working Mother, Glassdoor and the Human Rights Campaign for being a great place to work for [2] diversity and inclusion, [3] women, [4] LGBTQ and parents. References Visible links 1. https://www.bain.com/about/diversity-inclusion/ 2. https://www.bain.com/about/diversity-inclusion/ 3. https://www.bain.com/about/diversity-inclusion/ 4. https://www.bain.com/about/diversity-inclusion/"
Data Engineer II,Away Travel,"Remote in San Francisco, CA+2 locations",https://www.indeed.com/rc/clk?jk=d754925ccc9cd951&fccid=06305b44abdc1b42&vjs=3,"Away is a global lifestyle brand with a mission to transform travel through products and content that inspire people to get away more. In support of our mission, we are seeking a Senior Data Engineer to join our Engineering team. Want to help us transform the travel experience? The ideal candidate will be interested in building scalable data pipelines, ELT processes, supporting our ERP and POS implementation and other critical projects. You will report to the Senior Manager, Data Engineering and report into our New York City office with the option to work remotely. As a company that values diversity, equity, and inclusion, Away seeks individuals of all backgrounds and experiences to apply for this opportunity. We’re creating an environment where everyone can thrive. Our customers are global and diverse, so we’re building a team that is too. Through initiatives like our employee resource groups, Anti-racism training and bias prevention initiatives, we’re building the cultural foundation that gives people the emotional and physical space to bring their authentic selves to work. What you'll do: Build, own and operate scalable data pipelines and related data warehouse for our e-commerce platform, ERP, 3PLs and our 3rd party services supporting our business requirements Collaborate with talented designers, product managers, and fellow engineers to build and plan reliable and robust systems Mentor other engineers in the team and guide them through code reviews and other process improvements Implement systems to catch bugs and monitor data quality, ensuring our production data is always accurate and available for key stakeholders and business processes that depend on it Push and refine our technology, data structures, and creative practices Who you are: Minimum 5+ years of professional data engineering experience Minimum 4+ year experience building data pipelines using Python Minimum 4+ years experience with distributed data storage systems/formats & data stores such as Snowflake, Redshift or other Big data systems Minimum 2+ years experience in building data pipelines to stream messages with good exposure to handling failure scenarios Must have in-depth understanding of relational databases, including SQL Must have experience working with IPaasS such as Boomi, Mulesoft, etc. Must have experience working with Airflow DAGs Basic understanding of Linux/Unix commands required Experience working and processing large datasets, and techniques for working with data in volume effectively Experience working with batch processing/real-time systems Experience with ERPs or implementation, preferred Experience with Heroku is preferred Have worked with a major cloud provider such as AWS or Azure Exposure to Continuous Integration/Continuous Deployment (CI/CD) & Test Driven Development preferred Ability to work independently and come up with thoughts to improve processes Team player with a “no task is too small” attitude Enjoys working in a fast-paced and ever-changing environment Passionate about transforming travel (but that’s a given!) You’ll love working at Away because: We travel. We encourage you to take time to recharge outside of the office. You’ll have generous PTO to explore new places and access to Away products to ensure your travels are seamless. And once you’re here for three years, you’ll earn a sabbatical and a bonus to take a well-deserved trip. We’re not just employees. We’re people. We offer insurance coverage (health, vision, and dental), tax savings plans for retirement, dependent care, commuter benefits, generous and inclusive parental leave, and a kitchen stocked with organic snacks and coffee. We’ll invest in your career. Our company’s growing quickly, and we’ll give you the opportunity to do the same. You’ll have access to a number of professional development opportunities so that you can keep up with the company’s evolving needs. We’re creating an environment where everyone can thrive. Our customers are global and diverse, so we’re building a team that is, too. Through initiatives like our employee resource groups, our new office in downtown Manhattan, and more, we’re building the cultural foundation that gives people the emotional and physical space to bring their best selves to work. We offer competitive compensation packages. We deeply value the talent our team brings to the table, and believe that fair and equitable total compensation packages are part of our commitment to everyone who works here. And so much more…! You can bring your dog to work. We organize ways to give back to our local communities. About Away: Away is a global lifestyle brand with a mission to transform travel through products and content that inspire people to get away more. The company launched in 2016 with one perfectly designed carry-on and has since expanded to offer an array of luggage and travel essentials built for the modern traveler. Headquartered in New York City, with teams in London and Toronto, Away currently ships products to over 35 countries around the world. Away has been named one of Fast Company’s “World’s Most Innovative Companies” and has been recognized on TIME’s list of “Best Inventions.” To learn more, visit awaytravel.com. EEO Statement: Away is dedicated to hiring a diverse workplace that celebrates an inclusive culture and a sense of belonging. As an equal opportunity employer, we do not discriminate based on race, color, religion, sex (including pregnancy, gender identity, gender expression, and sexual orientation), national origin, age, veteran status, genetic information or disability. Away is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or accommodation due to a disability, you may contact us at talent@awaytravel.com."
Data Engineer,Capitol Federal,"Topeka, KS 66603 (Downtown area)",https://www.indeed.com/rc/clk?jk=e7f1f99d1015edf6&fccid=b9a2440fa83afd9d&vjs=3,"Role The Data Engineer assists in setting overall development roadmap and standards for the Bank and helps evaluate and architect the use of data solutions, using industry best practices. This position works as part of a collaborative team to design, code, and implement data solutions to support internal business requirements or external customers and vendors. An innovative mindset and an ability to translate complex business scenarios into a technical solution is required. This position performs a variety of tasks under general supervision. The position reports directly to an IT manager and requires regular, predictable and timely attendance at work to meet department workload demands. Essential Duties & Responsibilities Develop Code in ETL tools, for the extraction, transformation, and loading of data from source systems to the data warehouse. Designs and constructs operational data stores (generic DW), data lakes (raw data), and data marts (dimensions around types of data). Designs key and indexing schemes and designs partitioning. Identifying, designing and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes. Building with analytical tools to provide actionable insights into key business performance metrics including operational efficiency. Working with stakeholders including data, design, product and others to assist them with data-related technical issues. Creates data catalogs for data structures. Assist management with evaluating and accepting new projects by providing cost estimates, application analysis and recommendations based on application and project experience. Meet with decision makers, systems owners, end users and business analysts to define business requirements and systems goals, and identify and resolve business data issues. Responsible for setting development standards and practices. Manage and maintain responsibility for assigned projects. Assist employees in solving routine data, system software, hardware, and procedure problems. Regularly evaluate existing development footprint and identify areas to improve software. Evaluate industry best practices to determine fit within the Bank’s infrastructure. Assist with periodic testing and implementation of contingency plans to ensure availability of data in case of system failure. Follow internal project management methodology by adhering to documentation and production change control processes when implementing application enhancements and maintenance to ensure a stable production environment. Perform other duties as assigned. Participate in proactive team efforts to achieve departmental and company goals. Must comply with current applicable laws, regulations and bank policies and procedures. Comply with all safety policies, practices and procedures. Report all unsafe activities to supervisor and/or Human Resources. Requirements Bachelor’s degree in Computer Science, Information Systems, or another related field preferred. Seven or more years experience with ETL tools (SSIS). Seven or more years experience in a Data Warehouse (DWH) environment with data integration/ETL of large and complex data sets. Experience with visualization tools (Power BI, SSRS, and Crystal reports). Understanding of modern development tools and platforms (Azure Data Factory, Azure Analysis Services, Azure Synapse, Snowflake, and Snowpipe). Technical proficiency with SQL and relational databases. Expertise in performance tuning and scaling Microsoft SQL databases. Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases. Creative thinking, with the ability to evaluate a business scenario and design user-friendly, low maintenance software solutions. Excellent written, oral, and interpersonal communication skills. A significant level of trust, credibility and diplomacy is required. In-depth dialogues, conversations and explanations with customers, direct and indirect reports and outside vendors can be of a sensitive and/or highly confidential nature. Communications may involve motivating, influencing, and/or advising others on matters of significance. The ability to work in a team environment and motivate or influence others is a critical part of the job, requiring a significant level of diplomacy, influence and trust."
Senior Data Scientist/Machine Learning Engineer,Salesforce,+11 locationsRemote,https://www.indeed.com/rc/clk?jk=0c63fce94ae5e117&fccid=4027cfd917e1ee29&vjs=3,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts. Job Category Products and Technology Job Details LOCATION: We are open to Fully Remote, Flex (1-3 days/week in the office), or Office-Based (4-5 days/week in office) work arrangements. Salesforce, the Customer Success Platform and world's #1 CRM, empowers companies to connect with their customers in a whole new way. We are the fastest growing of the top 10 enterprise software companies, the World’s Most Innovative Company according to Forbes, and one of Fortune’s 100 Best Companies to Work For six years running. The growth, innovation, and Aloha spirit of Salesforce are driven by our incredible employees who thrive on delivering success for our customers while also finding time to give back through our 1/1/1 model, which leverages 1% of our time, equity, and product to improve communities around the world. Salesforce is a team sport, and we play to win. Join us! Department Overview: Data Science Apps (DSA) The Data Science Apps (DSA) team, which sits within the broader Data Intelligence organization, is a family of hard-working technologists with backgrounds ranging from Artificial Intelligence to Finance. What connects us all is a shared curiosity for how to drive product strategy with data, a passion for getting the job done, and a balanced disregard for constraints. The DSA team, composed of machine learning professionals, works with analysts, engineers, designers, executives, product managers, marketers, customer success, and sales team members across all Cloud businesses to build ML-driven decision making data products that enable our stakeholders to affect the bottom line and tackle critical business problems. If you were to join us, you would: Work closely with a talented team of machine learning professionals on a wide range of problems including forecasting important business metrics such as sales and capacity, churn and propensity modeling to retain and grow our customer base, clustering and classification using both structured and unstructured data, and more! Help create high-visibility data products and decision-making tools for Salesforce’s leaders. Lead the charge on taking our core products to the next level in terms of engineering maturity and architecture. Refine and develop new data data science products, workflows, tools, and automation. Build tools to monitor data pipeline performance, data quality and models in production. Establish best practices with coding standards, workflows, tools, and product automation. Review and maintain existing tool-set and codebase (pipelines, models, algorithms); continue to improve existing tools and create new ones. Scale the operations of the data science team by building automation and libraries. Peer review code and participate in architecture design and reviews. Be part of a team and company that truly cares about your wellbeing and knows how to have fun - both during and after work! Examples of attributes we value: 4+ years of industry experience and a passion for designing, analyzing and deploying machine learning-based solutions. Experience working as part of a data team working with mature data science products. Proven track record in building software and data products using modern development lifecycle methodologies: CI/CD, QA, and Agile Methodologies. Applied experience designing, building and optimizing data pipelines, architectures and data sets. Experience deploying, monitoring and maintaining data science products in cloud environments such as AWS or Microsoft Azure. Good understanding of Machine Learning methods and Statistics, including ML project lifecycle and associated challenges at each stage of development. Proficient at writing good quality, well-documented and tested, scalable code - Python preferred. Experience with tools like mlFlow, Airflow, Docker and Cloud Platforms such as AWS/GCP is ideal. Solid understanding of data transformations and analytics functions using tools/languages like Pandas, Sklearn, SQL and Spark. Strong communication skills and ability to interface well with other engineers, data scientists and product managers. Passion, curiosity, solutions focus and independence. In school, or graduated within the last 24 months? Please visit FutureForce for opportunities For Colorado-based roles: Minimum annual salary of $82,400. You may also be offered a bonus, restricted stock units, and benefits. More details about our company benefits can be found at the following link: https://www.getsalesforcebenefits.com/ . You can find other info there as well- including wellbeing reimbursement, generous parental leave, adoption assistance, fertility benefits, and more. Visit for the full breakdown! *LI-Y Accommodations If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form . Posting Statement At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at Salesforce and explore our benefits. Salesforce.com and Salesforce.org are Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce.com and Salesforce.org do not accept unsolicited headhunter and agency resumes. Salesforce.com and Salesforce.org will not pay any third-party agency or company that does not have a signed agreement with Salesforce.com or Salesforce.org . Salesforce welcomes all. Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records."
Data Engineer,Base-2 Solutions,"Norfolk, VA+2 locations",https://www.indeed.com/company/Base--2-Solutions/jobs/Data-Engineer-44906f2f02750974?fccid=c5169cdc426972d4&vjs=3,"Required Security Clearance:Top Secret/SCI City:Norfolk State/Territory:Virginia Travel:None Potential for Teleworking:No Schedule:Full Time DoD 8570 IAT Requirement:IAT II (Security+, CySA+, CCNA Security, GICSP, GSEC, SSCP) DoD 8570 IAM Requirement:None DoD 8570 IASAE Requirement:IASAE I (CASP+, CISSP (or Associate), CSSLP) DoD CSSP Requirement:CSSP Infrastructure Support (CySA+, CEH, GICSP, SSCP) Job DescriptionWorks with customers to plan and implement complex Zero Trust customer solutions. Serves as technical expert on executive-level project teams providing technical direction, interpretation, and alternatives. Candidate needs to be an expert in the design and deployment of complex data architectures with 13+ years of systems engineering experience. Familiar with Zero Trust (ZT) architectures in addition to zero trust best practices. Familiar and experience with ZT vendor products and solutions such as SOAR, Identity, SIEM. Works with customers to plan and implement complex Zero Trust customer solutions. Experience with development and implementing data standards, data tagging, data formats. Experience with implementing complex database, data warehouse, or data analytics solutions. Performs highly specialized and technical tasks associated with the most current and cutting-edge technologies May serve as a technical consultant to a project or projects dealing with area of technical expertise Coordinates with contract management and Government personnel to ensure the problems have been properly defined and the solutions satisfy customer needs Performs complex system development, design, modeling, analysis, integration, and sustainment of systems for new or existing computer systems within an Enterprise. Developing and implementing testing strategies and documenting results. Providing system/equipment/specialized training and technical guidance. Serves as liaison with clients, participating in meetings to ensure client needs are met. Provides guidance and work leadership to less-experienced staff. Communicates with customers and teammates clearly and concisely. Maintains current knowledge of relevant technology as assigned and may have supervisory responsibilities. Developing documentation on new or existing systems. Linux experience desired Desired Certifications Amazon Web Services (AWS) Certified Data Analytics – Specialty Data Science Council of America (DASCA) Associate Big Data Engineer Data Science Council of America (DASCA) Senior Big Data Engineer Google Professional Data Engineer Microsoft Certified: Azure Data Engineer Associate Job Type: Full-time"
Data Engineer,"Navstar, Inc.","Reston, VA+1 location",https://www.indeed.com/company/Navstar/jobs/Data-Engineer-8d9686d687c967a5?fccid=a970d33814d584c4&vjs=3,"Would you like to perform rewarding work while contributing to the success of an established, growing company? Navstar is an award-winning organization that has a proven track record of successfully providing IT services and solutions both as a prime and sub-contractor on mission focused IT programs. Our employees are integral players in support of mission-critical programs focused on our National Security.Role Description: Process collection data to move, unpack, decrypt, decode, store, tag and disseminate. Create application programming interfaces (APIs) to package and disseminate data to mission partners. Create access control mechanism to access collection data. Implement standard interfaces, formats and application processes. Pull or receive command and control files. Build data models and analytics to support mission needs. Implement and document RESTful API structures that communicate across data management components to include user interface, data flow, data ingestion, monitoring and dissemination. Required Skills and Qualifications: To be eligible for this position you must hold an active TS/SCI clearance with Polygraph. Minimum of 2 years of experience (within the last 5 years) in data engineering and Bachelor’s degree or higher in the field of computer science, information systems, engineering, mathematics, or other related scientific or technical discipline. Demonstrated experience building data products in Apache Avro. Demonstrated experience in using Nifi. Demonstrated experience with ActiveMQ. Demonstrated experience deploying the complete DevOps Lifecyle including integration of build pipelines, automated deployments, and compliance scanning using test driven development. COVID-19 Considerations: Full vaccination against COVID-19, and compliance with the Company’s vaccination verification procedures, is required for this position, unless the individual is legally entitled to a reasonable accommodation for medical or religious reasons.About NavstarFor 20 years Navstar has provided high-quality Innovative Technology Services and Solutions throughout the Intelligence Community. We would not have achieved the success we have without the best AllStar team; this is not just a place to work, Navstar is a community. At Navstar everything we do revolves around listening to both our customers and employees, delivering the results they expect, and being a trusted partner as both a prime and subcontractor. We have proven track record of successfully providing innovative technology services and solutions on highly mission-focused programs; all while enjoying what we do at the same time. Security is our priority; together, we will make the nation a safer place.Benefits at Navstar Highly Competitive Health Care Premiums, including 100% employer paid for employee Flexible Spending Accounts for Medical and Dependent Care Generous PTO and Federal Holiday Paid Leave Employer Paid STD/LTD Employer Paid Life Insurance 401K plan and Employer Match Referral and Opportunity Referral Programs Professional Development Assistance Navstar Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or veteran status. Job Type: Full-time"
Data Engineer (AWS/Pyspark),Dealer Inspire,"Remote in Chicago, IL+2 locations",https://www.indeed.com/rc/clk?jk=0610c48bf8159b5b&fccid=ec154f83e2139ed2&vjs=3,"ABOUT US: Dealer Inspire (DI) is a leading disruptor in the automotive industry through our innovative culture, legendary service, and kick-ass website, technology, and marketing solutions. Our mission is to future-proof local dealerships by building the essential, mobile-first platform that makes automotive retail faster, easier, and smarter for both shoppers and dealers. Headquartered in Naperville, IL, our team of nearly 600 work friends are spread across the United States and Canada, pushing the boundaries and getting **** done every day, together. DI offers an inclusive environment that celebrates collaboration and thinking differently to solve the challenges our clients face. Our shared success continues to lead to rapid growth and positive change, which opens up opportunities to advance your career to the next level by working with passionate, creative people across skill sets. If you want to be challenged, learn every day, and work as a team with some of the best in the industry, we want to meet you. Apply today! Dealer Inspire is a CARS brand. CARS includes the following brands: Cars.com, Dealer Inspire, DealerRater, FUEL, and CreditIQ. Want to learn more? Check us out here! ABOUT THE ROLE: Data is the driver for our future at Cars. We're searching for a collaborative, analytical, and innovative engineer to build scalable and highly performant platforms, systems and tools to enable innovations with data. If you are passionate about building large scale systems and data driven products, we want to hear from you. Responsibilities Include: Build data pipelines and deriving insights out of the data using advanced analytic techniques, streaming and machine learning at scale Work within a dynamic, forward thinking team environment where you will design, develop, and maintain mission-critical, highly visible Big Data and Machine Learning applications Build, deploy and support data pipelines and ML models into production. Work in close partnership with other Engineering teams, including Data Science, & cross-functional teams, such as Product Management & Product Design Opportunity to mentor others on the team and share your knowledge across the Cars.com organization Required Skills Ability to develop Spark jobs to cleanse/enrich/process large amounts of data. Ability to develop jobs to read from various source systems such as kafka, databases,API's,files etc. Experience with tuning Spark jobs for efficient performance including execution time of the job, execution memory, etc. Sound understanding of various file formats and compression techniques. Experience with source code management systems such as Github and developing CI/CD pipelines with tools such as Jenkins for data. Ability to understand deeply the entire architecture for a major part of the business and be able to articulate the scaling and reliability limits of that area; design, develop and debug at an enterprise level and design and estimate at a cross-project level. Ability to mentor developers and lead projects of medium to high complexity. Excellent communication and collaboration skills. Required Experience Data Engineering | 1-2 years of designing & developing complex applications at enterprise scale; specifically Python, Pyspark and/or Scala. Big Data Ecosystem | 2 years of hands-on, professional experience with tools and platforms like Spark, EMR, Kafka. AWS Cloud | 1+ years of professional experience in developing Big Data applications in the cloud, specifically AWS. Bachelor's degree in Computer Science or Engineering or related field Preferred: Experience with developing REST APIs. Experience in deploying ML models into production and integrating them into production applications for use. Understanding of Machine Learning products. Experience with developing real time data analytics using Spark Streaming, Kafka, etc. #LI-KO1 #LI-Remote We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Data Engineer,Nuvento systems,Remote,https://www.indeed.com/rc/clk?jk=7d7654e3fd020976&fccid=035c4866a9cc42e8&vjs=3,"Location- WFH, 3-5 years, Full Time / Permanent 5+ years of experience in ETL with at least 3 years in AWS redshift / Glue platform and SQL RDS implementation exp Job Description: A good exposure in AWS Glue is a must Structure analytical solution to address business objectives and problem solving Translate stated or implied client needs into researchable hypotheses Technical Experience Hands-on experience in implementation of ETL solutions Must possess complete hands-on experience in anyone RDBMS such as AWS Redshift and Oracle Strong knowledge on SQL and procedural languages such as T-SQL, PL/SQL etc. Hands-on experience on anyone of the ETL tools such as AWS Glue Hand-on experience with AWS Glue Hand-on experience with Spark, PySpark Hands-on experience in Query Tuning, Performance Tuning for large scale ETL solutions Must have good understanding of relational dimension and modelling Exposure to designing / modeling tool such as ERWin/ERStudio, VISIO, Power Designer Fair knowledge on DW Design skills Apply Now"
"Engineer, Data Center",Kaiser Permanente,"Silver Spring, MD 20910",https://www.indeed.com/rc/clk?jk=083b207903115f41&fccid=48ecd526e3aa3225&vjs=3,"Assume the responsibility to properly operate and correctly maintain all plant and engineering equipment (electrical and mechanical) as assigned, within the Data Center, to ensure continuous availability, and delivery of required engineering services. This position consistently supports compliance and Kaiser Permanente's Code of Conduct by adhering to federal, state and local laws and regulations, accreditation and licenser requirements and Kaiser Permanente's policies and procedures. In addition to defined technical requirements, accountable for consistently demonstrating service behaviors and principles defined by the Kaiser Permanente Service Quality Credo, the KP Mission as well as specific departmental/organizational initiatives. Also accountable for consistently demonstrating the knowledge, skills, abilities, and behaviors necessary to provide superior and culturally sensitive service to each other, to our members, and to purchasers, contracted providers and vendors. Essential Responsibilities: Perform hands-on operation and maintenance of all Data Center building engineering-related equipment and systems, which include, but are not limited to: Mechanical (HVAC, chillers, boilers, Computer Room AC Units, pumps, strainers, controls, water treatment, etc.); Electrical (UPS, PDUs, generators, switchgear, etc); Plumbing (condensate, fuel oil, etc.); Building Automation and Control Systems (BAS, BMS, etc.); Fire/Life Safety (alarms, suppression, etc). Operate Building Automation and Control Systems. Operate computer based control and monitoring system, as well as PC based systems for tracking of operations and maintenance activities. Perform all work in accordance with Data Center Engineering Policies and Procedures, with special emphasis on work in designated critical areas, and demonstrate Critical Awareness in all work activities. Carry out routine Data Center Preventive Maintenance as directed on all equipment specified. Perform required Data Center Corrective Maintenance as directed on all equipment specified. Conduct Data Center facility/building rounds as scheduled. Promptly report all equipment/system anomalies noted while in the Data Center. Immediately report any hazardous materials encountered or unsafe work practices observed. Maintain logs, record readings, document equipment histories, and prepare other engineering-related documentation. Store, maintain and use Critical Spare Parts and general-use parts in accordance with prescribed policy. Perform services as directed in Project related work. Provide access/escort service to subcontractors working in engineering areas as required. Use all tools and equipment properly as designed and in a safe manner. Participate in all training programs provided. Actively take part in all emergency drills and scenario exercises as directed. Respond quickly and appropriately to all emergencies occurring in the Data Center. Work independently or with other team members as directed. Report any accidents encountered, either to self or others. Conduct all work in a professional manner and respond courteously to all client requests. Work weekend/evening shifts as required. Write, or assist in writing, documents related to the operation, maintenance and repairs of said equipment and systems. The documentation includes, but is not limited to, Critical Facility Work Authorization (CFWA), Methods of Procedure (MOP), Standard Operating Procedure (SOP), and Emergency Operating Procedure (EOP). Operating Engineers will carry out maintenance/operations tasks as assigned by management and submit accompanying documentation in a timely manner. Documentation includes but is not limited to when work was completed, how long the work took to complete, anomalies encountered, repairs made, parts used, etc. Take all required and mandated training in order to maintain required certifications and licenses per the State of Maryland. Performs other duties, within their field, as assigned by immediate supervisor. Basic Qualifications: Experience Minimum eight (8) years of experience in critical, high availability Data Centers and/or Hub Medical Centers required. Education High School Diploma or equivalent combination of education, training, and experience is required. Demonstrated experience with heating, cooling, plumbing and electrical systems. In-depth knowledge of Life Safety codes on Federal, State and Local levels required. Ability to work independently and in a professional manner. License, Certification, Registration State of Maryland first class Stationary Engineer license and Universal CFC or equivalent licensing from DC/VA required. Additional Requirements: Ability to read and interpret blueprints, schematic drawings and technical manuals required. Knowledge of equipment and systems described above including electrical repairs and maintenance required. Attained CFC Certification required. Is current or willing to become member of IUOE required. Preferred Qualifications: Completion of four-year apprentice program or have journeyman status in electrical/mechanical crafts. Documented and completed course work in electrical systems fundamentals, UPS Systems, generators, chillers systems, building automation and control systems. PrimaryLocation : Maryland,Silver Spring,Silver Spring Data Center HoursPerWeek : 40 Shift : Night Workdays : Tue, Wed, Thu, Fri, Sat WorkingHoursStart : 10:00 PM WorkingHoursEnd : 06:30 AM Job Schedule : Full-time Job Type : Standard Employee Status : Regular Employee Group/Union Affiliation : M41|IUOE|Local 99 Job Level : Individual Contributor Job Category : Facility Services & Materials Management Department : Silver Spring Data Center - ITO IPS DCO FM SSDC - 1808 Travel : No Kaiser Permanente is an equal opportunity employer committed to a diverse and inclusive workforce. Applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy), age, sexual orientation, national origin, marital status, parental status, ancestry, disability, gender identity, veteran status, genetic information, other distinguishing characteristics of diversity and inclusion, or any other protected status."
"Field Data Engineer (Oxnard, CA)",L3Harris Technologies,"Oxnard, CA",https://www.indeed.com/rc/clk?jk=2b8753eca2546017&fccid=6c6be4ac01722b08&vjs=3,"Description: Job Title: Field Data Engineer Job Code: FDP2 Job Location: Oxnard, CA We are an international business unit with a startup culture looking for an experienced data engineer. Superior communication skill and demonstrated technical subject-matter expertise are essential. You will join an elite team of engineers and operators who are charged with developing the Navy’s unmanned vessels. A Data Engineer will architect, organize, and archive real-world data and data structures from unmanned vessels. A highly qualified candidate will also be able to build tools, test, analyze, and model the data for interpretation by other key engineers and researchers. This position will provide lifecycle support for innovative hardware and software systems and applications that support the maximal utiliztion of Unmanned Surface Vessel (USV) data Responsibilities Architect the data management pipeline Organize the data into useful structures and databases Develop archiving solutions that can be utilized to scale to n vessels and compare same or similar data across vessels Build tools to manipulate the data Analyze data through visualization techniques Model data for interpretation by other key engineers and researchers Oversee all field-deployed systems and the harvesting of their data Identify and emplace processes to streamline field support, driving improvement in information and technology flow to internal and external stakeholders alike Serve as technical lead for training other Field Support engineers in assisting the Data Management, collaboratively delivering content to ensure knowledge transfer Develop plans and designs for modifications and enhancements Implement new requirements and architecture changes Update and maintain documentation for the data management system Participate in multi-functional teams and manage work through JIRA Verifying, and updating as necessary, in-house system and network documentation for remote site configurations during field services engagements, and ensuring those updates and feedback are delivered to the respective O&M teams for awareness and action. Qualifications U.S. Citizenship required Bachelor's degree or equivalent experience in information technology, computer science, computer engineering or a related field Scripting or programming skills (Python, Bash, Data Science Frameworks) Understanding of technical, operational, and management issues related to data design, development, and deployment at scale Experience working in a Linux environment"
Diagnostic Data Analysis – Senior Engineer (REMOTE),Cummins Inc.,"Remote in Columbus, IN",https://www.indeed.com/rc/clk?jk=524846ac75c8bbba&fccid=36ccedc5bfdf19b1&vjs=3,"Diagnostic Data Analysis – Senior Engineer (REMOTE) Description We are looking for a talented Diagnostic Data Analysis – Senior Engineer to join our team specializing in Engineering for our Corporate Organization in your U.S. remote home office. This role is 100% remote with periodic travel post-pandemic. In this role, you will make an impact in the following ways: Supports On Board Diagnostic calibration tuning process by assisting calibration tuners in setting up parameters for data logging, uploading, and managing OBD data on SQL database, and providing access to the data through a web-based GUI. Applies basic knowledge of engineering principles and practices to assigned tasks to develop and support OBD tuning and validation work Applies basic knowledge of statistical tools to analyze OBD data from engineering and fleet validation test vehicles Develops and maintains various apps and tools using Matlab, R, Python and other statistical programming languages for fault code analysis, OBD capability analysis, diagnostic decision tracking, fault configuration, and data quality checks. Qualifications To be successful in this role you will need the following: Bachelor’s in Engineering preferred. Electrical, Mechanical, or Data Science disciplines preferred. Programming experience in at least one language is required Knowledge and experience in SQL, Matlab, Python, R-Shiny programming is preferred Compensation and Benefits Base salary rate commensurate with experience. Additional benefits vary between locations and include options such as our 401(k) Retirement Savings Plan, Cash Balance Pension Plan, Medical/Dental/Life Insurance, Health Savings Account, Domestic Partners Coverage and a full complement of personal and professional benefits. Base salary range:$62,400 - $90,000 Please note that the salary range provided is a good faith estimate on the applicable range. The final salary offer will be determined after taking into account relevant factors, including a candidate’s qualifications and experience, where appropriate. Additional benefits vary between locations and include options such as our 401(k) Retirement Savings Plan, Cash Balance Pension Plan, Medical/Dental/Life Insurance, Health Savings Account, Domestic Partners Coverage and a full complement of personal and professional benefits. Cummins and E-verify At Cummins, we are an equal opportunity and affirmative action employer dedicated to diversity in the workplace. Our policy is to provide equal employment opportunities to all qualified persons without regard to race, gender, color, disability, national origin, age, religion, union affiliation, sexual orientation, veteran status, citizenship, gender identity and/or expression, or other status protected by law. Cummins validates right to work using E-Verify. Cummins will provide the Social Security Administration (SSA) and, if necessary, the Department of Homeland Security (DHS), with information from each new employee’s Form I-9 to confirm work authorization. Job ENGINEERING Primary Location United States-Indiana-Columbus-US, IN, Columbus, Corporate Office Building Job Type Experienced - Exempt / Office Recruitment Job Type Exempt - Experienced Job Posting May 25, 2022, 5:28:42 PM Unposting Date Ongoing Organization Corporate Req ID: 220003RR"
Data Warehouse Engineer,The Trade Desk,"San Jose, CA 95113 (Downtown area)",https://www.indeed.com/rc/clk?jk=0c89c74284f94a99&fccid=4899a85209d20142&vjs=3,"The Trade Desk is a global technology company with a mission to create a better, more open Internet for everyone through principled, intelligent advertising. Handling over 600 billion queries per day (more than 100X the query volume of search globally), our platform operates at unprecedented scale. We have also built something even stronger and more valuable: an award-winning culture based on trust, empathy, collaboration, and ownership. By working together across typical dividing lines, we are better as a team than any of us could be apart. Do you have a passion for solving hard problems at scale? Are you eager to join a trust-based, globally-connected team, where your contributions will make a meaningful difference? Come and see why Fortune Magazine consistently ranks The Trade Desk among best small-medium sized workplaces globally. ABOUT THE ROLE: With integrations into every major advertising exchange, we handle well over 4 trillion requests every month and growing – that's more page views and queries than Facebook, Google Search, and Google's entire network of websites combined – all serviced in single-digit-ms response times. Are you interested in working with big data? Do you want to push the edges of scale and responsiveness? It doesn't get much bigger or faster than this! We are looking to hire a Big Data Database Engineer to join our engineering team to build out our data-driven platform and support database related activities. You enjoy investigating database problems, performance issues, and evaluating/influencing MPP database use cases to ensure optimal performance on the platform. WHAT YOU'LL DO: Designing, developing, and supporting features and functionality that leverage our MPP databases. Provide day-to-day support and maintenance for the MPP databases that are part of our platform. This includes, but is not limited to: administration, analysis, support, proactive monitoring, troubleshooting, recoverability, security, installation, and design. Investigating potential problems and issues raised by users Monitoring database events and continuously optimizing system performance through troubleshooting and tuning Automate reactive procedures and promote rapid response to database issues Maintaining database configurations in compliance with established best practices Designing and implementing systems, policies, and procedures for backup and disaster recovery Monitoring ongoing capacity and implement design and architecture changes as needed to improve global availability Installing upgrades and patches to existing database servers Designing and developing database code as needed Reviewing and establishing database migration patterns and weekly release scripts Participating in on-call rotations WHAT YOU HAVE: 5+ years of Database Administration experience supporting mission critical relational databases Considerable experience and knowledge of on-premise MPP databases, like Vertica, Teradata, or Netezza. Vertica experience is a huge plus. Equivalent experience with other SQL technologies like Redshift or Snowflake, or even open source may be acceptable alternatives for the right candidate. Proficiency with OLAP Database Environments running on Linux Full systems lifecycle experience (from requirements to delivery) of database projects Experience designing, building, installing, configuring, supporting, and maintaining high-volume, large database systems Top-notch troubleshooting and analytical problem-solving skills Experience with database design and management aspects for various compliance programs, such as Sarbanes-Oxley or PCI, is a big plus Excellent written and verbal communication skills, with a demonstrated ability to document complex technical problems Ability to work effectively in a team environment, as well as independently with limited supervision #LI-RE1 The Trade Desk does not accept unsolicited resumes from search firm recruiters. Fees will not be paid in the event a candidate submitted by a recruiter without an agreement in place is hired; such resumes will be deemed the sole property of The Trade Desk. The Trade Desk is an equal opportunity employer. All aspects of employment will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law."
Data Systems Engineer,RingCentral,Remote,https://www.indeed.com/rc/clk?jk=f23e2fd4f3d6d354&fccid=1cbb498b08d4e46a&vjs=3,"Data/Systems Engineer It’s not every day that you consider starting a new career challenge. We’re RingCentral, a global leader in cloud-based communications and collaboration software. We are fundamentally changing the nature of human interaction—giving people the freedom to connect powerfully and personally from anywhere, at any time, on any device. We’re a $1.6 billion company that’s growing at 30+% annually and we’re expanding our Data Engineering & Data Analytics Team to make sure we stay ahead of the competition. Job Overview We are looking to hire a Data Systems Engineer to join our Data Operations team with a focus on systems support and deployment. You will be part of the team that is responsible for building out the architecture for ingestion. You will take responsibility for all things related to system maintenance, application support, deployment and pipeline engineering and support. This includes learning and understanding upstream processes, pipelines and source systems. The role will work in conjunction with other cross functional teams to help derive analytics and dashboards. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. Responsibilities: Architecting, Design, Building, Supporting systems for data ingestion. Monitoring and performance tuning. Work with a cross functional team of engineers, analysts and scientists to understand business requirements. Documenting architecture, systems, and pipelines. Documenting database design including data modeling, metadata and process flow diagrams. Highly available/resilient systems experience. What we’re looking for: 4+ years Systems Administration experience 4+ years of Application Administration experience Experience with Kubernetes, Helm, Docker, Kafka, Redis, Hazelcast, Spark Programming (Java, Python, Groovy ) Has experience with ANSI SQL Has experience with NOSQL (Elastic, Clickhouse ) Ability to create and maintain data pipelines Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources Participate in on-call rotation to support data pipelines and tools Qualifications: B.S in Computer Science etc. plus 2-3 years of experience Experience with management data pipelines/big data tools: StreamSets, Orchestration Framework (Airflow, Prefect), ELK etc Strong Linux familiarity, Linux system administrator skills are a plus Experience with one of AWS/Google public clouds Programming experience (at least one): Python, Java, etc Nice to have DevOps experience: Ansible, Jenkins, Chef etc Nice to have Anomaly Detection/Machine Learning experience Nice to have Telecom background Ability to work in very diverse multicultural environment Good communication skills Good team player with self-starter ability What we offer: Comprehensive medical, dental, vision, disability, life insurance Health Savings Account (HSA), Flexible Spending Account (FSAs) and Commuter Benefits 401K match and ESPP Flexible PTO Wellness programs, including 1:1 wellness coaching through TaskHuman and meditation guidance through Headspace Paid parental leave and new parent gift boxes Pet insurance Employee Assistance Program (EAP) with counseling sessions available 24/7 Rocket Lawyer services that provide legal advice, document creation and estate planning Employee bonus referral program RingCentral’s work culture is the backbone of our success. And don’t just take our word for it: we are recognized as a Best Place to Work by Glassdoor, the Top Work Culture by Comparably and hold local BPTW awards in every major location. Bottom line: We are committed to hiring and retaining great people because we know you power our success. RingCentral offers on-site, remote and hybrid work options optimized for the ways we work and live now. About RingCentral RingCentral, Inc. (NYSE: RNG) is a leading provider of business cloud communications and contact center solutions based on its powerful Message Video Phone™ (MVP™) global platform. More flexible and cost effective than legacy on-premises PBX and video conferencing systems that it replaces, RingCentral® empowers modern mobile and distributed workforces to communicate, collaborate, and connect via any mode, any device, and any location. RingCentral is headquartered in Belmont, California, and has offices around the world. If you are hired in Colorado, the compensation range for this position is between $101,000 and $152,000 for full-time employees, in addition to eligibility for variable pay, equity, and benefits. RingCentral is an equal opportunity employer that truly values diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Data Engineer,MilliporeSigma,"Carlsbad, CA 92011 (North Beach area)",https://www.indeed.com/rc/clk?jk=ab624763411a6dc1&fccid=88cfae2b9c504af5&vjs=3,"What we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity. We believe that it drives excellence, innovation, and human progress. We care about our customers, patients, and our rich mix of people. This diversity strengthens our ability to lead in science and technology. We are committed to creating access and opportunities for all and empower you to fulfil your ambitions. Our diverse businesses offer various career moves to seek new horizons. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to bring their curiosity to life! Curious? Chat with one of our curious minds on our interactive Q&A platform and catch a glimpse of our people, values, and culture. You can also apply and find more information at https://jobs.vibrantm.com If you would like to know more about what diversity, equity, and inclusion means to us, please visit https://www.emdgroup.com/en/company/press-positions.html If you are a resident of a Connecticut or Colorado, you are eligible to receive additional information about the compensation and benefits, which we will provide upon request. You may contact 855 444 5678 from 8:00am to 5:30pm ET Monday through Friday, for assistance. Your Role: As a key materials supplier to the semiconductor industry, we are facing ever more complex and dynamic manufacturing and supply chain challenges. How do we manage the complexities of our manufacturing systems effectively? Data! To take our operations to the next level, putting our data to work is key. As Data Engineer in our Manufacturing Intelligence team, you will develop cutting-edge big data solutions to streamline operations and provide the highest levels of quality to our customers in the semiconductor industry. Design and deliver digital solutions using big data tools to help groups like supply chain, quality, and operations improve manufacturing planning and logistics, process monitoring and control, and root-cause investigation. Develop robust, automated end-to-end data pipelines to feed downstream analytics and data science use cases. Collaborate with operational teams to understand and prioritize user requirements, formulate clear development roadmaps, perform testing and validation, and deploy digital solutions aimed at improving quality, increasing labor efficiency, and/or maximizing production capacity. Own and improve existing solutions, and act as the technical point of contact for users. Manage change control processes and communication with local business groups impacted by solutions to ensure alignment between all parties and proper documentation. Who You Are: Minimum Qualifications: Bachelor's degree in science, technology, engineering, mathematics, or computer science 2+ years of industry experience in a data engineering, data science, or data analytics function 2+ years of experience in data engineering and pipeline development using Python, Spark, and/or SQL 1+ years of experience with data visualization and dashboard design in Tableau 1+ years of experience with SAP or other ERP systems Preferred Qualifications: Proficient using Python to perform data engineering, statistical modeling, and data visualization with libraries such as pandas, numpy, pyspark, scikit-learn, matplotlib, and seaborn. Experience using SAP or other ERP systems (Quattro, S/4HANA) Experience using Palantir Foundry and/or Alteryx analytics platforms. Experience using applied statistics to control and improve manufacturing operations. Ability to grasp complex data architectures quickly and independently. Capable of driving decision-making using data and visualization. Strong organizational and planning skills with attention to detail. Excellent communication skills to explain solutions to non-technical business users. RSRMS The Company is an Equal Employment Opportunity employer. No employee or applicant for employment will be discriminated against on the basis of race, color, religion, age, sex, sexual orientation, national origin, ancestry, disability, military or veteran status, genetic information, gender identity, transgender status, marital status, or any other classification protected by applicable federal, state, or local law. This policy of Equal Employment Opportunity applies to all policies and programs relating to recruitment and hiring, promotion, compensation, benefits, discipline, termination, and all other terms and conditions of employment. Any applicant or employee who believes they have been discriminated against by the Company or anyone acting on behalf of the Company must report any concerns to their Human Resources Business Partner, Legal, or Compliance immediately. The Company will not retaliate against any individual because they made a good faith report of discrimination. As an employee of the Company, you will be required to comply with all of the Company's COVID-19 safety protocols and policies. The organization has currently suspended enforcement of its COVID-19 Vaccination Policy, but that policy may be reinstated by the Company in its discretion. Job Requisition ID: 242768 Location: Carlsbad Career Level: C - Professional (1-3 years) Working time model: full-time North America Disclosure The Company is committed to accessibility in its workplaces, including during the job application process. Applicants who may require accommodation during the application process should speak with our Candidate Services team at 844-655-6466 from 8:00am to 5:30pm ET Monday through Friday. If you are a resident of a Connecticut or Colorado, you are eligible to receive additional information about the compensation and benefits, which we will provide upon request. You may contact 855 444 5678 from 8:00am to 5:30pm ET Monday through Friday, for assistance. Notice on Fraudulent Job Offers Unfortunately, we are aware of third parties that pretend to represent our company offering unauthorized employment opportunities. If you think a fraudulent source is offering you a job, please have a look at the following information . Job Segment: ERP, Computer Science, Database, Semiconductor, Developer, Technology, Science"
Data QA and Analytics Engineer,HealthVerity,+1 locationRemote,https://www.indeed.com/rc/clk?jk=7d7bb2fcc76a014e&fccid=6b1be984647e492b&vjs=3,"How you will help You'll ensure that our clients have the highest quality of data to make their everyday decisions. As a Data Quality and Analytics Engineer, it will be your responsibility to troubleshoot and resolve complex data quality issues. Our team will also rely on you for your expertise with healthcare data and your strong SQL skills. What you will do Analyze all vendor data assets and correct complex data anomalies Provide guidance and support during the vendor on-boarding process which includes data ingestion, normalization, and QC activities Provide expertise on all healthcare data types: medical claims transactions (e.g. 837 and 835), pharmacy claims (NCPDP D.0), EMR/EHR, lab transactions, and other emerging data assets Provide Quality Assurance for new Data Source mapping and normalization SQL produced by Data Architect. Develop repeatable testing routines to expedite QA that can also be used to closely monitor the recurring ingestion for ongoing QC. Develops and maintains trend analysis for longer term, historical quality control. Perform analytics against healthcare data using SQL based programming tools You are … A data geek with enviable SQL skills and a passionate sense of ownership A self-starter who enjoys working in a small, rapidly changing, fast paced environment Confident enough to course correct a process or team when required Methodical, executing through several approaches to determine the best fit Energized by learning even if outside the scope of day-to-day responsibilities Comfortable working on several different tasks throughout your workday Desired skills and experience 4+ years’ experience in the healthcare data industry, preferably in a consulting or analytic based environment Proficient in programming against large data assets with a working knowledge of SQL, preferably also knowledgeable in SAS and/or R Ability to gather requirements, test strategies, design deliverables Subject matter expertise in a wide variety of healthcare data assets Knowledge of the healthcare industry and analytics utilized by pharmaceutical marketing teams Proven analytical, evaluative, and problem-solving abilities Skilled teaching and instruction capability Extensive experience working in a team-oriented, collaborative environment About HealthVerity At HealthVerity we are actively solving some of the greatest challenges in healthcare through innovative technology and data solutions. Our customers and partners including pharmaceutical manufacturers, payers and government organizations look to HealthVerity to partner on their most complicated use cases, leveraging our transformative technologies and real-world data infrastructure. The HealthVerity IPGE platform, based on the foundational elements of Identity, Privacy, Governance and Exchange, enables the discovery of RWD across the broadest healthcare data ecosystem, the building of more complete and accurate patient journeys and the ability to power best-in-class analytics and applications with flexibility and ease. To learn more about the HealthVerity IPGE platform, visit www.healthverity.com. Why you'll love working here We are making a difference – Our technology is at the forefront of some of the biggest healthcare challenges in the world. We are one team – Our people define our culture and always will. We take time out to celebrate each other at the end of every week through company-wide shout outs, and acknowledge the value that each of us adds towards our greater mission. Come share all you have to offer. We are learners – Every team member is continually learning, no matter if we've been in a role for one year or much longer. We are committed to learning and implementing what is best for our clients, partners, and each other. Benefits & Perks Compensation: competitive base salary & annual bonus opportunity (for non-commissioned roles) Benefits: comprehensive benefits with coverage on Day 1, medical, dental, vision, 401k, stock options Flexible location: our HQ is in Philadelphia with 50% of the team distributed across 25+ states Generous PTO: Take time off as needed, targeted at 4 weeks per year, including vacation, personal and sick time, plus paid maternity and paternity leave. Comprehensive and individualized onboarding: mentorship program, departmental talks, and a library of resources are available beginning day 1 for each new team member to minimize the stress of starting a new job Professional development: biweekly 1:1s, hands-on leadership that is goal-and growth-oriented for each team member, and an annual budget to support professional development pursuits HealthVerity is an equal opportunity employer devoted to inclusion in the workplace. We believe incorporating different ideas, perspectives and backgrounds make us stronger and encourages an environment where ageism, racism, sexism, ableism, homophobia, transphobia or any other form of discrimination are not tolerated. At HealthVerity, we’re working towards an innovative and connected future for healthcare data and believe the future is better together. We can only do that if everyone has a seat at the table. Read our Equity Inclusion and Diversity Statement. If you require a reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to careers@healthverity.com HealthVerity offers in-office and remote options, so you can work from anywhere within the US! #LI-Remote"
Data Engineer,Research Foundation of The City University of New...,"New York, NY",https://www.indeed.com/rc/clk?jk=f878c509c603ac1c&fccid=667ba717ce627077&vjs=3,"General Description The Data Collaborative for Justice (DCJ): The Data Collaborative for Justice is a research organization launched at John Jay College of Criminal Justice in 2013. The DCJ has partnered with state and local agencies in New York to publish reports on various criminal justice topics, and expanded portfolio of analyses, evaluation, and partnerships around the nation. The DCJ also provides technical assistance to the Mayor’s Office of Criminal Justice of New York City to process administrative data for criminal justice research, including data analysis, data engineering and data product development. This position is for the technical assistance project. The DCJ operates under the Research Foundation City University of New York (RF). The Mayor’s Office of Criminal Justice: The Mayor’s Office of Criminal Justice (MOCJ) advises the Mayor of the City of New York on criminal justice policy. MOCJ develops and implements strategies to reduce crime and incarceration and to promote fairness and legitimacy. MOCJ works with law enforcement, city agencies, non-profits, foundations and others to implement data-driven strategies that address current crime conditions, prevent offending, and build strong neighborhoods that ensure enduring safety. The office draws on various disciplines, such as, behavioral economics to “nudge” conduct and machine learning to develop reliable predictive analytics, to ensure effective results. Position: DCJ is seeking a Data Engineer to primarily assist with the technical assistance provided to MOCJ. The position will primarily work with the Data and Technology group and the Executive Director of Information Technology. The Data Engineer will assist in managing and supporting the agency’s data platform and data pipelines and addressing new needs as they arrive. The Data Engineer will also participate in the implementation of the City’s new data exchange platform. Work will include migrating existing data pipelines and development of new procedures. The candidate is expected to work independently, possess a variety of analytic and data management skills and be actively involved in the full life cycle of data management including acquisition, processing, quality assurance/quality control, documenting and cataloging. Other Duties Responsibilities: The Data Engineer’s responsibilities include, but are not limited to: Maintain and support the agency’s data platform and data pipelines; Develop new data pipelines in collaboration with agency business owners; Work with technologies and platforms including Redshift, Snowflake, Tableau, SnapLogic, Informatica Python, R and SQL. Ensure agency compliance with all relevant data security and privacy policies; Develop and oversee quality assurance/quality control procedures; Develop processes to automate testing and deployment of code, and Document all processes and procedures; Qualifications Core Competencies: Ability to secure any necessary security clearances; Ability to monitor and evaluate the work of others, consistent with RF policies and contracts; Ability to communicate effectively with technical and program staff about research techniques, applications, practices, etc. important to the field of inquiry; Knowledge of policies regarding intellectual property, use of facilities and equipment, allocation of time and materials to project costs, and utilization of IT resources, and Knowledge of protocols for safe conduct of research, including but not limited to the study of human subjects and establishment of safety reporting procedures. Qualifications: The successful candidate must be highly organized, pays close attention to detail, is results-driven, is flexible and is overall a problem-solver and self-starter. In addition, the preferred candidate should possess the following: Bachelor’s Degree and a minimum of 3 years of experience. Knowledge of the principles, practices, and methods of data management and curation. Knowledge of data structures, formats, metadata and cataloging standards, and database technologies. Programming proficiency in Python and an understanding of R. Demonstrated experience with the aforementioned tools. Experience managing data and automating data pipelines; Data visualization and presentation experience a plus; Experience with geospatial data and technologies is a plus. Ability to balance competing priorities, complex situations, and tight deadlines. Ability to work independently in a fast-paced environment. Ability works comfortably with a wide variety of people at different levels within and outside the organization. Well organized with strong communication skills. Salary: $80,000 - $120, 000, depends on experience. To Apply: Please go to www.rfcuny.org. Under “About RF” there is a link for “Careers.” Please choose John Jay College of Criminal Justice to find the position. For Additional Information, See: the DCJ website https://datacollaborativeforjustice.org/ and the MOCJ website http://www1.nyc.gov/site/criminaljustice/index.page"
Data Builds Sustainment Engineer,LOCKHEED MARTIN CORPORATION,"Trumbull, CT 06611",https://www.indeed.com/rc/clk?jk=173be6abd3eac21e&fccid=aeb15e43a6800b9d&vjs=3,"COVID-19 continues to significantly impact our employees, families and communities. With employee health and safety as our top priority, and as a federal contractor, Lockheed Martin is taking action to address the increased risk and uncertainty COVID-19 variants pose in the workplace and ensuring we meet our commitments to national security. To uphold safety for all employees, we will continue to request vaccination status for all Lockheed Martin employees including new hires. All current and newly hired employees are required to follow onsite safety measures based upon the COVID-19 Community Level at the specific work location. Description:We are seeking a Sustainment Engineer to join the Information Systems & Innovation (IS&I) organization who will be responsible for managing the data builds in support of the IETMs (Interactive Electronic Technical Manual) for various Commercial, Military and International customers. The successful candidate will also be responsible for preparing, testing and delivering an IETM installation package to the customer as well as ensuring all web hosted IETMs have the latest data content. Summary of Role: Produce project schedule, coordinate with the Program manager to deliver the latest IETM to the customer Interact with the Technical Publications department to perform data builds and post to a Works In Progress server for QA review. Package the approved data set with the IETM software application for data integration and software delivery Update internal and external web hosted IETM servers with the latest approved data sets. Develop, test and deploy incremental temporary revision packages (TREVs) to externally facing web hosted IETM servers. Work with DevOps engineer to create the IETM software installation packages Support all data build issues related to the project Document and resolve IETM related customer issues Keep pace with enabling technologies and provide input to technology insertion plans Produce technical presentations in support of program reviews Create executive-level status reports Support the creation and update of “How To” / standard operating procedures. Participate in project related meetings Provide project related delivery and quality artifacts after delivery has been made Submit Weekly project Status Reports Work with project Lead to gather, analyze, and document technical requirements Work with Technical Lead to align technical/business objectives with products Collaborate with internal Cyber Security staff to resolve technical data issues Create automation scripts (Batch, PowerShell) to optimize data build pipelines Prepare test plans, test descriptions, test cases Collect metrics related to quality and performance. Basic Qualifications: Degree in Computer Science, Systems Engineering or equivalent work experience MS Office Proficiency (Excel, Word, PowerPoint, Project, Visio, Timeline) Detail oriented, technically inclined and team oriented Willingness to learn existing processes and make improvements. Clear, concise writing skills Ability to effectively work with internal & external customers Ability to work independently and work with limited direction to accomplish project goals Desired Skills: Experience with any of the following scripting languages: Batch, PowerShell, PHP, Phyton, PERL Familiarity with DevOps processes Familiarity with Systems Security Engineering and Cyber Security principles Familiarity with Technical Publications legacy mil standard data specs and/or S1000D Knowledge of installation packaging software: Tarma, Installshield Software user interface design a plus Familiarity with IETM applications a plus Aircraft maintenance experience a plus Familiarity with Scripting languages Familiarity with data and/or application builds and installer creation Familiarity with updating software on servers through RDP (Remote Desktop Protocol) BASIC QUALIFICATIONS: job.Qualifications Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about. As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories. EXPERIENCE LEVEL: Experienced Professional"
Data Engineer II,Memorial Sloan Kettering Cancer Center,"New York, NY 10017 (Turtle Bay area)",https://www.indeed.com/rc/clk?jk=9e905c338e50e866&fccid=1320c50b75f44505&vjs=3,"Company Overview: At Memorial Sloan Kettering (MSK), we’re not only changing the way we treat cancer, but also the way the world thinks about it. By working together and pushing forward with innovation and discovery, we’re driving excellence and improving outcomes. We’re treating cancer, one patient at a time. Join us and make a difference every day. In compliance with applicable New York and New Jersey State regulatory authorities, COVID-19 vaccination (2 doses of either the Pfizer or Moderna vaccine or one dose of the Johnson & Johnson vaccine) is mandatory for all MSK employees, contingent workers, and volunteers. Exceptions are permitted for those employees who request and receive an approved medical or fully remote exemption. Staff working at a MSK New Jersey location must be up to date with COVID-19 vaccination, which includes having completed the primary COVID-19 vaccination series and booster once eligible as mandated by New Jersey State. All New Jersey staff not yet eligible for a booster must receive a booster within 3 weeks of becoming eligible as a condition of continued employment at MSK. Note: Individuals are eligible to receive a COVID-19 booster five months after receiving the second dose of either the Pfizer or Moderna vaccine or two months after the J&J vaccine. Job Description: Are you passionate about technology? Do you want to play a key role in redefining the future of cancer care? We Are: We are seeking a Data Engineer II to join MSK’s Digital Pathology team as we meet the challenge of converting pathology from an analog to a digital practice. You will create pipelines to consolidate and deliver vital data that will drive research and analytics focused on improving patient care. You are a highly skilled data engineer who is comfortable working with large volumes of data. You can design and develop complex solutions using modern practices and technologies. You are an eager, self-starting learner who can quickly pick up new technologies. You Will: Engineer infrastructure and tools to deliver critical data to downstream systems and industry partners Design and build backend integrations using various technologies and taking a creative approach when working with legacy systems. Engineer features of the data platform that will help ensure quality and robustness. Collaborate in an agile team with Product Owners, Scrum Masters, System Architects, other Development Teams and Users. Participate in full SAFe and Agile development life cycle including analysis, design, built and release of data pipelines. You Are: Proficient in relational database schema and query design Proficient in using scripting languages such as Python, bash, and R Proficient with industry standard tools for ETL design and administration (i.e. Data Stage) Familiar with linux environments and server administration Experience using Docker, Kubernetes or similar container technologies and setting up CI/CD pipelines is a plus. Experience designing RESTful APIs is a plus. Experience and familiarity with Cloud providers (AWS, Azure) is a plus. Benefits Competitive compensation packages | Sick Time |Generous Vacation+ 12 holidays to recharge & refuel| Internal Career Mobility & Performance Consulting | Medical, Dental, Vision, FSA & Dependent Care|403b Retirement Savings Plan Match|Tuition Reimbursement |Parental Leave & Adoption Assistance |Commuter Spending Account |Fitness Discounts &Wellness Program | Resource Networks| Life Insurance & Disability | Remote Flexibility We believe in communication, openness, and thinking beyond your 8-hour day @ MSK. It’s important to us that you have a sense of impact, community, and work/life balance to be and feel your best. #LI-Remote Closing: MSK is an equal opportunity and affirmative action employer committed to diversity and inclusion in all aspects of recruiting and employment. All qualified individuals are encouraged to apply and will receive consideration without regard to race, color, gender, gender identity or expression, sexual orientation, national origin, age, religion, creed, disability, veteran status or any other factor which cannot lawfully be used as a basis for an employment decision. Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment."
Data Engineer,GE Gas Power,"Remote in Atlanta, GA 30339",https://www.indeed.com/rc/clk?jk=0345fc61bc90e4ed&fccid=38e057261a434f79&vjs=3,"Job Description Summary The Monitoring & Diagnostics Requisition & Sustaining organization is looking for a Senior Sustaining Engineer for Analytics Support. This position will be responsible for supporting the current M&D Analytics & Data Infrastructure. Position will include owning and maintaining system configurations and databases, providing analytics platform troubleshooting support, and driving improvement initiatives. Job Description Roles and Responsibilities Own and improve analytic health metrics for the platform. Establishing processes and metrics necessary to support the platform. Leverage expertise to affect long term system improvements to maintain and improve analytic health and work with the analytics & development teams to implement the necessary changes. Responsible for troubleshooting Python package deployments. Work within established procedures to develop, test, implement, and maintain deployment Pipelines, and Airflow DAGs. Demonstrate your knowledge and experience by troubleshooting and solving critical issues that may involve many systems and platforms, within a complex infrastructure. Required Qualifications B.S. or M.S. degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position Demonstrated experience with AWS Cloud Service and understanding of virtualization Demonstrated experience with Python Experience with Splunk Experience in system performance monitoring, analysis, and tuning Experience working in an independent and highly matrix environment, coordinating across multiple sites, functions, and time zones Must know MS Visio, Excel, Outlook, and Word applications Desired Characteristics Prefer experience with Search services fundamentals and troubleshooting for key streaming services like Kafka / Kinesis Prefer experience and knowledge of Jenkins, Airflow, Python, Genie and Aurora Prefer Automation experience using DevOps concepts such as Digital.ai release and deploy Prefer experience using observability tools like Dynatrace Foundational knowledge of databases and Structured Query Language (SQL) Experience with Tableau Excellent troubleshooting, analytical and critical thinking Skills Strong oral and written communication skills; Strong interpersonal and leadership skills Capable of switching between tasks based on priority and be able to communicate priority & urgency to global team Green Belt or Black Belt Certification, or Lean/Company equivalent Experience working in a global environment Additional Information GE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law. GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable). As a federal government contractor, GE may in the future be required to have U.S. employees fully vaccinated against COVID-19. Some GE customers currently have vaccination mandates that may apply to GE employees. Relocation Assistance Provided: No #LI-Remote - This is a remote position"
Data Scientist and Computer Engineer,Finastra,"Atlanta, GA",https://www.indeed.com/rc/clk?jk=e404834d6b634ca9&fccid=1f9d0530a51ff611&vjs=3,"Data Scientist/Machine Learning Engineer About: Finastra has opened its global innovation lab for new talents and is looking for an exceptional data scientist to join our Innovation Lab. This team is responsible for performing research and development with regards to artificial intelligence and developing innovative applications from ideation to demo-able products. You should be passionate about digging through data, looking for insights, uncovering trends, making forecasts, and communicating the results. You will collaborate with a multidisciplinary team of software developers, product managers, and engineers all over the world to tackle interesting problems in a wide variety of financial domains. Responsibilities: Analyze large, complex data sets and develop predictive models and analytical insights Research the latest machine learning methods, forecasting techniques, and optimization methods and apply them in practice Create data pipelines ranging from data collection to preprocessing to feature generation Be a highly motivated, self-starter who is passionate about technology and solving problems in a creative manner Work with multidisciplinary teams ranging from UI/UX designers to product managers to software engineers all over the world Soft Skills: A go-getter who can take ideas and bring them to life Ability to fail fast and obtain quick wins Passion to succeed and takes pride in their work Ability to work independently as well as work effectively with a team Qualifications: Bachelors/Masters/PHD in a quantitative discipline such as Computer Science, Mathematics, Statistics, or Operations Research Experience with a scripting language such as python Development experience with data analysis libraries such as numpy and pandas Understanding of Machine Learning principles and familiarity with libraries such as sklearn Experience using deep learning frameworks such as tensorflow, pytorch, MXnet, or keras Applied experience with machine learning on large datasets Experience collecting, preprocessing, and generating features for machine learning models Demonstrated skill in selecting the right statistical tools for a data analysis problem Full-stack development is a plus ************************************************************************************************************* The above statements describe the general nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, duties, and skills required. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform the essential job functions. If you need assistance or an accommodation due to disability please contact your recruitment partner. *************************************************************************************************************"
Data Engineer - Dataworks - All Levels (Remote),FedEx Services,"Remote in Memphis, TN+1 location",https://www.indeed.com/rc/clk?jk=ba129ecc0b06f6a8&fccid=2ae04b97d8829e58&vjs=3,"Company: FedEx Services Job Title: Data Engineer - Dataworks - All Levels (Remote) Job Requisition Number: RC481202 Category: Information Technology Pay Type: Exempt Locations: Memphis, Tennessee 38120 United States Remote United States Colorado Residents Only – Compensation: Monthly Salary $6908.82 - $14524.25 The estimate displayed represents the typical salary range or starting rate of candidates hired in Colorado. Factors that may be used to determine your actual salary may include your specific skills, your work location, how many years of experience you have, and comparison to other employees already in this role. This information is provided to applicants in accordance to the Colorado Equal Pay for Equal Work Act. Duties for this role include but not limited to: supporting the design, build, test and maintain data pipelines at big data scale. Assists with updating data from multiple data sources. Work on batch processing of collected data and match its format to the stored data, make sure that the data is ready to be processed and analyzed. Assisting with keeping the ecosystem and the pipeline optimized and efficient, troubleshooting standard performance, data related problems and provide L3 support. Implementing parsers, validators, transformers and correlators to reformat, update and enhance the data. Provides recommendations to highly complex problems. Providing guidance to those in less senior positions. Additional Job Details: Data Engineers play a pivotal role within Dataworks, focused on creating and driving engineering innovation within Dataworks, helping define and build the Dataworks organization and facilitate the delivery of key business initiatives. S/he acts as a “universal translator” between IT, business, software engineers and data scientists, collaborating with these multi-disciplinary teams. Data Engineers will contribute to the creation of and adherence to technical standards for data engineering, including the selection and refinements of foundational technical components. S/he will work on those aspects of the Dataworks platform that govern the ingestion, transformation, and pipelining of data assets, both to end users within FedEx and into data products and services that may be externally facing. Day-to-day, s/he will be deeply involved in code reviews and large-scale deployments. Essential Job Duties & Responsibilities: Understanding in depth both the business and technical problems Dataworks aims to solve Building tools, platforms and pipelines to enable teams to clearly and cleanly analyze data, build models and drive decisions Scaling up from “laptop-scale” to “cluster scale” problems, in terms of both infrastructure and problem structure and technique Delivering tangible value very rapidly, collaborating with diverse teams of varying backgrounds and disciplines Codifying best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases Interacting with senior technologists from the broader enterprise and outside of FedEx (partner ecosystems and customers) to create synergies and ensure smooth deployments to downstream operational systems Skill/Knowledge Considered a plus: Technical background in computer science, software engineering, database systems, distributed systems Familiarity/fluency with distributed and cloud environments and a deep understanding of how to balance computational considerations with theoretical properties Detailed knowledge of the Microsoft Azure tooling for large-scale data engineering efforts and deployments is highly preferred Experience with designing and deploying large scale technical solutions, which deliver tangible, ongoing value Direct experience having built and deployed robust, complex production systems that implement modern, data scientific methods at scale Ability to context-switch, to provide support to dispersed teams which may need an “expert hacker” to unblock an especially challenging technical obstacle, and to work through problems as they are still being defined Demonstrated ability to deliver technical projects with a team, often working under tight time constraints to deliver value An ‘engineering’ mindset, willing to make rapid, pragmatic decisions to improve performance, accelerate progress or magnify impact Comfort with working with distributed teams on code-based deliverables, using version control systems and code reviews Ability to conduct data analysis, investigation, and lineage studies to document and enhance data quality and access Use of agile and devops practices for project and software management including continuous integration and continuous delivery Demonstrated expertise working with some of the following common languages and tools: Spark (Scala and PySpark), HDFS, Kafka and other high-volume data tools SQL and NoSQL storage tools, such as MySQL, Postgres, Cassandra, MongoDB and ElasticSearch Pandas, Scikit-Learn, Matplotlib, TensorFlow, Jupyter and other Python data tools Minimum Qualifications: Data Engineer II : Bachelor's Degree in Computer Science, Information Systems, a related quantitative field such as Engineering or Mathematics or equivalent formal training or work experience. Two (2) years equivalent work experience in measurement and analysis, quantitative business problem solving, simulation development and/or predictive analytics. Strong knowledge in data engineering and machine learning frameworks including design, development and implementation of highly complex systems and data pipelines. Strong knowledge in Information Systems including design, development and implementation of large batch or online transaction-based systems. Strong understanding of the transportation industry, competitors, and evolving technologies. Experience as a member of multi-functional project teams. Strong oral and written communication skills. A related advanced degree may offset the related experience requirements. Data Engineer III: Bachelor’s Degree in Information Systems, Computer Science or a quantitative discipline such as Mathematics or Engineering and/or equivalent formal training or work experience. Five (5) years equivalent work experience in measurement and analysis, quantitative business problem solving, simulation development and/or predictive analytics. Extensive knowledge in data engineering and machine learning frameworks including design, development and implementation of highly complex systems and data pipelines. Extensive knowledge in Information Systems including design, development and implementation of large batch or online transaction-based systems. Strong understanding of the transportation industry, competitors, and evolving technologies. Experience providing leadership in a general planning or consulting setting. Experience as a senior member of multi-functional project teams. Strong oral and written communication skills. A related advanced degree may offset the related experience requirements. Data Engineer Advisor: Bachelor’s Degree in Information Systems, Computer Science, or a quantitative discipline such as Mathematics or Engineering and/or equivalent formal training or work experience. Seven (7) years equivalent work experience in measurement and analysis, quantitative business problem solving, simulation development and/or predictive analytics. Extensive knowledge in data engineering and machine learning frameworks including design, development and implementation of highly complex systems and data pipelines. Extensive knowledge in Information Systems including design, development and implementation of large batch or online transaction-based systems. Strong understanding of the transportation industry, competitors, and evolving technologies. Experience providing leadership in a general planning or consulting setting. Experience as a leader or a senior member of multi-function project teams. Strong oral and written communication skills. A related advanced degree may offset the related experience requirements. Domicile / Relocation Information: This position can be domiciled anywhere in the United States. The ability to work remotely within the United States may be available based on business need. Relocation assistance may be available based on business need. Application Criteria / Deadline: Upload current copy of Resume (Microsoft Word or PDF format only) and answer job screening questionnaire. Notice: Sponsorship for this position is not available. Employee Benefits: Medical, dental, and vision insurance; paid Life and AD&D insurance; tuition reimbursement; paid sick leave; paid parental leave, paid vacation, and additional paid time off; geographic pay ranges; 401K with Company match and incentive bonus potential; sales incentive compensation for selling roles. FedEx. Where now meets next. Our vision is to be the earth's most engaged advocates of connected commerce where open borders, new markets and fair, sustainable practices are the norm for the billions of personal supply chains being managed every day in our always on, mobile-first world. We stand for ease, access and opportunity. We lead purposeful innovation, champion entrepreneurs, advocate free trade and empower humans and their place in the era of autonomy and AI. We fight for our customers, a more sustainable planet and an ethical playing field. FedEx inspires its more than 570,000 team members to remain focused on safety, the highest ethical and professional standards and the needs of their customers and communities. FedEx is committed to connecting people and possibilities around the world responsibly and resourcefully, with a goal to achieve carbon-neutral operations by 2040. FedEx has been recognized on many different lists both for business success and for being a great employer: Fortune ""World’s Most Admired Companies"" – 2021 Forbes ""Best Employers for Diversity"" - 2021 LinkedIn ""Top 100 Companies"" - 2021 TIME ""100 Most Influential Companies"" - 2021 World HRD Congress ""Best Gender Equality Workplace"" – 2021 InsiderPro ComputerWorld ""Best Places to Work for IT"" – 2021 FedEx Services is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, national origin, age, genetics disability, or protected Veteran status. FedEx Services does not discriminate against qualified individuals with disabilities in regard to job application procedures, hiring, and other terms and conditions of employment. Further, FedEx Services is prepared to make reasonable accommodations for the known physical or mental limitations of an otherwise qualified applicant or employee to enable the applicant or employee to be considered for the desired position, to perform the essential functions of the position in question, or to enjoy equal benefits and privileges of employment as are enjoyed by other similarly situated employees without disabilities, unless the accommodation will impose an undue hardship. If a reasonable accommodation is needed, please contact recruitmentsupport@fedex.com."
Data Analyst Engineer,Honda Dev. and Mfg. of Am LLC,"Marysville, OH",https://www.indeed.com/rc/clk?jk=cd058f19b30598ef&fccid=cee887bafa195ef4&vjs=3,"Data Analyst Engineer ( Job Number: HAM00046T ) Honda Dev. and Mfg. of Am LLC Description Honda has a clear vision for the future in 2030, and it’s a joyful one. We are looking for people with the individual skills, courage, persistence, and dreams that will help us reach our future-focused goals. We are seeking diversity of thought and experience to drive innovation and help us make fully informed decisions. In this role, you will be responsible for enhancing the utilization of data driven analytics to drive characteristics changes. Position includes identification, planning and implementing system improvements utilizing applied analytics from proof-of-concept to production. The position will work conjunction with the Delivery category to generate new data driven value in the areas of continues improvement, project scoping, design. At Honda, our associates take pride in their responsibilities. A typical day for a Data Analyst Engineer will include: Translate business inquiries and challenges into data-driven solutions with the support of data engineers, scientists, and IT (defining scope & requirements). Build and implement models based on requirements provided by business team by writing code / macros within excel or python and creating visuals through Tableau to identify quickly turn data into decision criteria. Develop standard procedures and best practices for data analytics projects. Mentor associates in analytics tools and projects. Advises and coaches leaders on how to adopt new ideologies to transform outcomes. Supports development of business-side standards and procedures for data governance and management. We are looking for qualified people with diverse backgrounds and experiences, open minds, and a disciplined work ethic. To bring the future to Honda as a Data Analyst Engineer you must have: Qualifications Bachelor's degree in Data Analytics, Data Science, MIS, Industrial System Engineering; or equivalent relevant experience. Minimum two years experience. Minimum two years analytics/project lead experience. Knowledge and Skills Proficient in at least one data visualization tool or library. Project Management skills Programming and computer skills. Ability to multi-task, prioritize and meet deadlines. Strong Verbal and Visual Communication skills Proficient Project Management Skills Self-motivated with the ability to think freely and generate new ideas Additional Position Information Average overtime hoursof 5-8 per week, potential for off shift - work B shift and weekends. Open office environment, with occasion work from home capability based on current COVID guidelines. Potential for limited travel. Total Rewards Competitive Base Pay Medical, Dental, Vision Remote Work Opportunities Bonus Program 401K Program Honda Product Programs Company Car Program **Add additional Total Rewards Info. When applicable i.e. sign-on bonus, relocation, starting hourly rate or salary, etc. Honda is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status, or any other protected factor."
Data Engineers,ANALYTOS,"Austin, TX",https://www.indeed.com/rc/clk?jk=6c7fde820395515f&fccid=9a4f13cfc6042a6a&vjs=3,"Qualifications: BSc IT , MSC IT , MCA Experience : 0 to 2 years A good data engineer is has extensive knowledge on databases and best engineering practices. These include handling and logging errors, monitoring the system, building human-fault-tolerant pipelines, understanding what is necessary to scale up, addressing continuous integration, knowledge of database administration, maintaining data cleaning, and ensuring a deterministic pipeline. Job Description The Core Data Engineer - Analyst will: Lead the discussion around Hadoop Clusters and our Big Data technology platform. Lead the discussion around monitoring and control of our data warehouse systems Work as a part of a cross-functional team to ensure data is flowing from transaction systems, logs, etc. into our processing pipelines Work with Data Scientists to ensure demands are met for data analysis Ensure task queues are processing jobs efficiently at scale Work with Architecture to diagnose complex software systems and discuss security and performance concerns early in the process Lead research on emerging technologies Lead troubleshooting efforts, but not be solely responsible for them Train and mentor other engineering team members around service discovery, configuration management, and provisioning technology Managing Infrastructure like Laptops / Desktops / Servers in case of any issues. Required Skills You thrive in an informal work environment with flexible hours but inflexible deadlines. You have displayed an aptitude for picking up new skills and approaches and are eager to broaden your knowledge of the use and analysis of data to solve real-world problems. You are willing to engage in continuing education through both formal and informal studies to further develop your skills. Analytical thinker and problem solver. Desired Skills Relevant work experience in managing Windows / Linux distributions, patching, updating in a large scale environment Relevant work experience setting up Tableau or other visualization tools Experience working with Hadoop, MapReduce, HBase, ZooKeeper, and other relevant technology Coding/Scripting ability in Bash + Ruby, Python, Scala, or Java Experience scaling API environments such as Apache, Nginx, Node/Express, Ruby/Sinatra Experience working with distributed systems and partitioning of data Good Communication Skills. For applying for these positions email your resume on careers@analytos.com"
"Associate Engineer, Data II",ABBVIE,"Lake County, IL",https://www.indeed.com/rc/clk?jk=30abb0c4de42fad1&fccid=a3b51ece17c02aae&vjs=3,"We are looking for smart, ambitious, problem solvers who want to start a career in Data Engineering and help AbbVie make a remarkable impact on peoples’ lives. This role will work in a collaborative and Agile environment to design and build data centric solutions. The solutions aim to help compliantly educate physicians on AbbVie’s approved products to help them make the most informed treatment decision for patients. This will involve combining multiple internal and external data sets. The Data Engineer will work collaboratively, as part of an Agile team, with Data Scientists, Data Analysts, Marketing, and other business functions to imagine, design, build, and enhance the models. The work will be fast paced, dynamic, and afford many learning opportunities. The Data Engineer will be responsible to on-board, consolidate, cleanse, and structure data for efficient use in reports and analytical applications. Bachelors Degree To be successful, candidates must be efficient in programming languages like Java, Python, R, and SQL. They must also understand and be able to apply data lake and relational database concepts. There is also an opportunity to learn and work with other, cloud, based technologies like AWS, SnowFlake, Informatica, and more."
Data Engineer,Spencer's,"Egg Harbor Township, NJ 08234",https://www.indeed.com/rc/clk?jk=2a9b038f6bcbdd80&fccid=135b0099b9e802a0&vjs=3,"Overview Come work with us at Spencer's & Spirit Halloween, where you'll be working with the best and brightest colleagues as you help us deliver the most fun experience and product possible to our guests. We're fast-paced and take our work seriously, but we always have a good laugh at the end of the day. Walk through our stores or the halls of our corporate office and you'll see firsthand that we're laidback and irreverent. We're firm believers in being true to YOU, so tattoos and piercings are as common as watercooler convos. Whether it's critiquing our new exclusive costumes or quality testing newly implemented software technology, our teams understand the importance of working collaboratively to challenge status quo and achieve our goals. We keep pushing ourselves to go above and beyond and are looking for top talent to become a part of our team! We offer the following benefits: 30% discount on merchandise competitive salary career advancement Bonus opportunity an excellent benefits package including Vacation/Sick/Holiday pay, Medical/Dental/Disability/Life and AD&D insurance & 401k. Responsibilities Data Engineer to optimize our data integration at scale. Inside our Data Integration team, you will be designing pipelines and warehouses to model data from multiple sources that will allow us to derive business insight. Using Azure and other open-source technologies, such as Azure Data Factory and PySpark, you will design and build our next-generation ETL pipelines and data models. Build data pipelines and python-based ETL tools for acquiring, processing, and delivering data Develop data models and schemas in our data warehouse that enable performant, intuitive analysis Handle the challenges that come with managing terabytes of data Collaborate with business leaders and analysts to define key metrics and build reporting to monitor and understand company performance Develop the server applications and APIs that are used by our Data Team Qualifications Bachelor’s degree or higher in Computer Science, Computer Engineering, Information Technology or related field Fluent in several programming languages such as Python, R, or Scala 6+ years of work experience in building ETL pipelines in production data processing and analysis Experience designing SQL tables, choosing indexes, tuning queries, and optimizations across different functional environments. Hands-on experience writing complex SQL queries and using a BI tool Experience with data lakes and designing and maintaining data solutions using Spark and Azure serverless services such as ADF Familiarity with data ingestion APIs, data sharing technologies, and warehouse infrastructure and development Proof of vaccination for COVID-19 required for employment, reasonable accommodations considered for medical, pregnancy or sincerely held religious beliefs."
"Research Software Engineer, Data Science",Dana-Farber Cancer Institute,"Remote in Boston, MA 02215",https://www.indeed.com/rc/clk?jk=56cb6905da174ef3&fccid=31a15643b156b0a5&vjs=3,"Job ID: 29995 Location: 450 Brookline Ave, Boston, MA 02215 Category: IT/Informatics Employment Type: Full time Work Location: Full Remote: 4-5 days remote/wk Overview The Department of Data Science at the Dana Farber Cancer Institute (DFCI) seeks candidates with a strong R programming background. As part of the department's mission to collaborate with basic biologists and clinical researchers to better understand cancer and improve treatment, our department develops new statistical methods and data analysis pipelines and implements these as R packages or shiny dashboards. We need help extending and improving these, as well as training our students, postdoctoral faculty and collaborators in best practices and new developments related to R. We are seeking a software engineer to help with these challenges. The department chair will help prioritizing projects and compartmentalize them into manageable units. The successful candidate will have a unique opportunity to work in an exceptional collaborative environment with experts in a wide range of areas including clinical trials, cancer genetics, immunology, epigenetics, machine learning, Bayesian methods, and alignment algorithms. There is room for growth in this position as the career ladder permits promotion to levels that lead groups of other software engineers. We offer salaries that are competitive with the biotech industry. Remote work is a possibility. Located in Boston and the surrounding communities, Dana-Farber Cancer Institute is a leader in life changing breakthroughs in cancer research and patient care. We are united in our mission of conquering cancer, HIV/AIDS and related diseases. We strive to create an inclusive, diverse, and equitable environment where we provide compassionate and comprehensive care to patients of all backgrounds, and design programs to promote public health particularly among high-risk and underserved populations. We conduct groundbreaking research that advances treatment, we educate tomorrow's physician/researchers, and we work with amazing partners, including other Harvard Medical School-affiliated hospitals. Responsibilities Work with center technical and research staff to develop tools that directly help researchers put their ideas into production. Maintain and improve shiny apps Train SAS users to use dplyr or data.table Iteratively develop software in collaboration with a world-leading team of researchers Use test-driven-development and continuous integration to ensure that the new code is reliable Document the software from a user and developer perspective As this is part of multiple ongoing collaborations, the nature of the work will depend on your strengths and experiences; this is an exciting opportunity to be involved in work with direct real-world impact and leverage our department’s expertise to build skills in a number of areas from high-performance computing/GPU acceleration, implementation of machine learning algorithms, computational biology pipelines, matrix operations on sparse data, among others. Qualifications Minimum Education: Successful completion of a coding training/coursework, software certificate program, or similar; or current enrollment in a bachelor’s degree program in Computer Science, Software Engineering, or a related field. Minimum Experience: 0 years of professional experience required Demonstrable experience in R, C, C++, Python, and Unix. Familiar with version control (e.g. git) and standard development practice tools and be able to write modular, maintainable and testable code. A high level of communication skills is essential to be able to elicit complex requirements from, and convey complex requirements to, groups with differing technical backgrounds. At Dana-Farber Cancer Institute, we work every day to create an innovative, caring, and inclusive environment where every patient, family, and staff member feels they belong. As relentless as we are in our mission to reduce the burden of cancer for all, we are equally committed to diversifying our faculty and staff. Cancer knows no boundaries and when it comes to hiring the most dedicated and diverse professionals, neither do we. If working in this kind of organization inspires you, we encourage you to apply."
Data Engineer,Great American Insurance Group,"Cincinnati, OH+1 location",https://www.indeed.com/rc/clk?jk=bdd4cd6d6c4a7204&fccid=11e7471668f88afd&vjs=3,"Be Here. Be Great. Working for a leader in the insurance industry means opportunity for you. Great American Insurance Group’s member companies are subsidiaries of American Financial Group, a Fortune 500 company. We combine a ""small company"" culture where your ideas will be heard with ""big company"" expertise to help you succeed. With over 30 specialty property and casualty operations and a variety of financial services, there are always opportunities here to learn and grow. Great American Insurance Group is seeking a Senior Data Developer/Analyst. This role will help influence and define the strategy, roadmap, and implementation of Great American’s digital experience platforms. This individual will partner with business units, shared services, and technology stakeholders and organizations to identify opportunities to deliver digital experience technology that will enable business transformation and drive efficiency and optimization across the organization and the entire insurance value chain. Essential Job Functions and Responsibilities Formulates and defines system scope and objectives through research and fact-finding to develop or modify moderately complex information systems: Prepares detailed design specifications from which programs will be written. Designs, codes, tests, debugs, documents, and maintains application programs. Consults with users or other IT Professionals to resolve issues with programs. Contributes to the development of project plans and timelines. Provides estimates for planned work. Maintains and develops business knowledge and customer relationships. May have responsibility for performance and coaching of staff and may have a participatory role in decisions regarding talent selection, development, and performance management for direct reports. Performs other duties as assigned. Job Requirements Education: Bachelor’s Degree or equivalent experience. Field of Study: Computer Science, Information Technology or a related discipline. Experience: 5 to 7 years of related experience. This job is non-exempt in California and Washington Business Unit: Property & Casualty IT Services Number of Positions: 1"
Applications ETL / Data Engineer,"JPMorgan Chase Bank, N.A.","Columbus, OH",https://www.indeed.com/rc/clk?jk=e14ac8dad445374b&fccid=aaf3b433897ea465&vjs=3,"As an experienced member of our BBIT MIS Software Engineering Group, we look first and foremost for people who are passionate about solving business problems through innovation & engineering practices. You will be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally .NET / SSIS Engineer: Proficiency in general-purpose programming languages such as C# & .NET. Strong working experience developing SQL queries and creating stored procedures. Experience with batch scheduling tools like Control-M and ETL tools like SSIS. Hands-On experience creating HTTPS/Restful Web Services. Advanced knowledge of application, data and infrastructure architecture disciplines. Current experience building and deploying web-based UI/API applications on modern web technology stacks, example: ASP.NET MVC Core. Strong working knowledge of database concepts and SQL Server (or related tools). Experience with unit testing tools NUnit and automated testing tools (Cucumber, selenium, JMeter). Working experience with application servers such as IIS. Knowledge of industry-wide technology trends and best practices. Ability to work in large, collaborative teams to achieve organizational goal. DevOps experience with tools (Jenkins, GIT or BitBucket, etc.). Understanding of software skills such as business analysis, development, maintenance, and software improvement. Experience with Agile software development methodologies. Knowledge on using public and private clouds such as AWS, Azure and Cloud Foundry (nice to have). Familiarity with JPMC-specific technology tools such as AIM, BluePrint, AppFit etc. (nice to have). Key Personal Attributes: Seeks out opportunities for continuous improvement Strong written and verbal communication skills Team player Bright and enthusiastic self-starter Excellent analytical and problem-solving skills Ability to thrive in a high pressure, mission-critical environment JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management. We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs. The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the ""WELL Health-Safety Rating"" for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment. As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm's current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm's vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law. Equal Opportunity Employer/Disability/Veterans"
"Integration Data Engineer, Quality Assurance",Texas Health Resources,"Arlington, TX 76011 (North area)",https://www.indeed.com/rc/clk?jk=f8c6e6a29472a3e8&fccid=47c7346c8483e993&vjs=3,"Integration Data Engineer, QA Are you looking for a rewarding career with family-friendly hours and top-notch benefits? We are looking for a qualified Integration Data Engineer QA like you to join our Texas Health family. Position Highlights: Work location: Texas Health Resources System Services; Arlington, TX – Required to live in the DFW area. Department: Data Warehouse Work hours: Full Time (40 Hours); Day Shift; Monday – Friday, 08:00 AM – 5:00 PM Position works remotely 4 days per week At Texas Health Resources, our mission is “to improve the health of the people in the communities we serve”. We are one of the largest faith-based, nonprofit health systems in the United States with a team of more than 23,000 employees of wholly owned/operated facilities plus 2,200 employees of consolidated joint ventures in the greater Dallas Fort Worth area. Our career growth and professional development opportunities are top-notch, and our benefits are equally outstanding. Join our award-winning Texas Health family and become a part of a team that is improving the health of our communities daily. You belong here. Qualifications: Education: Bachelor’s Degree in Business Administration, Information Science, Computer Science, Computer Engineering, Information Technology, or relevant field required. Experience: 3 years’ experience working as a Quality Assurance Engineer Required Combined with the following experience required: continuous experience developing SQL and able to demonstrate advanced queries, create tables, views, indexes, and joins required And, 1 year working in a healthcare or related field preferred. Experience with backend testing preferred. Skills: Experience with Quality Assurance testing methodologies and procedures. Experience using HP Quality Center and UFT or equivalent Quality Assurance software. Experience with database testing using SQL to query, create tables, views, indexes, joins, user defined functions, and stored procedures. Knowledge of the SDLC, ITSM and privacy and security concepts. Able to take on multiple projects concurrently and manage changes in scope along the way. Strong communication and interpersonal skills. Position Responsibilities: The Quality Assurance Engineer is self-motivated individual responsible for the development of testing strategies, plans, cases, and validation script to support testing of data integration solutions. They work with internal business units, analysts, and key stakeholders to understand their information requirements to provide testing strategies, plans, cases, and validation scripts using a variety of QA and Database technologies. Their work will support business decisions, and could span across multiple areas such as consumer experience, clinical quality, hospital operations, supply chain, finance, etc In addition to the required qualifications, a successful Data Integration Engineer II will: Develop complex SQL scripts to test results of database ETL processes using SQL commands including: JOIN, WHERE, CREATE, MINUS, UNION, functions such as: MAX, MIN, AVG. Ability to join 5-7 tables with numerous filter criteria to validate ETL results. Create temporary tables for comparing data or excluding duplicates. Collaborate with business, analysts, BI team, ETL team, and SMEs to design efficient testing strategies to support development of data integration solutions using HP Quality Center, UFT, FastTrack, SQL, or other technologies. Execute on automating testing processes. With minimal guidance, work with business sponsors, SMES and application teams to understand the business requirements; review business and technical specifications; design and document testing strategies, plans, cases, and validation scripts needed to confirm proper availability and quality of source system data. Design and develop testing solutions that confirm the business needs are met Collaborate with business, analysts, BI team, application teams and other stakeholders to design testing strategies to support development of data integration solutions that are fully integrated into the Enterprise Data Warehouse and support Business Intelligence testing needs. Collaborate on the support of Quality Assurance tools/applications to manage system changes and ensure availability, accuracy, security, and optimal performance. Comply with THR information security and privacy policies, ITSM processes and Quality Assurance development and design standards and best practices. Follow data governance requirements and documentation including but not limited to business definitions and technical definition. Develops interrelationships among partners and customers and analysts who have similar information needs and manages those relationships to assure effective solutions. Mentor and train business stakeholders, analysts and information consumers on data, business intelligence-related technology and information assets. Why Texas Health? As a Texas Health Data Integration Engineer II, you’ll enjoy top-notch benefits including 401(k) with match, paid time off, competitive health insurance choices, healthcare and dependent care spending account options, wellness programs to keep you and your family healthy, tuition reimbursement, a student loan repayment program and more. At Texas Health, our people make this a great place to work every day. Our inclusive, supportive, people-first, excellence-driven culture make Texas Health Resources a great place to work. Here are a few of our recent awards: 2021 FORTUNE Magazine’s “100 Best Companies to Work For®” (7th year in a row) Becker's Healthcare ""150 Great Places to Work in Healthcare"" (4 years running) “America’s Best Employers for Diversity” list by Forbes A “100 Best Workplaces for Millennials"" by Fortune and Great Place to Work® Additional perks of being a Data Integration Engineer II: Gain a sense of accomplishment by contributing in a teamwork environment. Receive excellent mentorship, comprehensive training and dedicated leadership resources. Enjoy opportunities for growth. Explore our Texas Health careers site for info like Benefits, Job Listings by Category, recent Awards we’ve won and more. Do you still have questions or concerns? Feel free to email your questions to recruitment@texashealth.org."
ENT Data Engineer,Envision Healthcare,"Nashville, TN 37215 (Green Hills area)",https://www.indeed.com/rc/clk?jk=1e940989144b644d&fccid=d1b4d6d5b00a5c73&vjs=3,"Overview: Envision Healthcare is a leading national medical group that delivers physician and advanced practice provider services, primarily in the areas of emergency and hospitalist medicine, anesthesiology, radiology/teleradiology, and neonatology to more than 1,800 clinical departments in healthcare facilities in 45 states and the District of Columbia. We are seeing significant change in healthcare: shifting care models, evolving access points of care, emerging technologies, and lasting impacts as a result of COVID-19. We have a profound opportunity to transform healthcare by leading the change through our strong national footprint and the differentiated, high-quality care we provide. Together, we can improve outcomes and make healthcare more affordable for millions of people. We have an exciting opportunity available for an experienced Data Engineer on our team based in Nashville, TN. This can be a fullly remote position and person can be based in any of the Envision locations or remotely anywhere in the U.S. The Enterprise Data Engineer – Cube Developer, is a hands-on individual contributor role, responsible for creating and maintaining the enterprise Cubes and semantic layers by designing and implementing robust OLAP solutions conforming to the enterprise data foundation architecture and guidelines. In this exciting position, you will be part of a team that is modernizing our enterprise data platform and services with cloud native technologies. Responsibilities: Design, develop and maintain enterprise/commercial grade OLAP solutions Creating SSAS cubes and user defined calculated cube measures and DAX expressions Writing SQL quires on SQL Server and columnar databases Writing DAX queries and MDX queries Deployment and maintenance of large and complex multi-dimensional and tabular cubes Perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement Participate in POCs and design of future state architecture Qualifications: Understanding and hands on experience developing and deploying enterprise grade OLAP solutions. Hands experience in full life cycle of SSAS Tabular cubes design, development, deployment and maintenance Knowledge in writing SQL quires on SQL Server and columnar databases Experience designing and developing in any of the reporting tools like SSRS, Tableau, PowerBI etc. Experience writing DAX queries and MDX queries Bachelor's Degree from four-year college or university and 5 or more years of related experience; or equivalent combination of education and experience 5 years of experience, with a heavy emphasis in data and analytics Healthcare Knowledge and Experience preferred To perform this job successfully, an individual should have knowledge of: Microsoft Office Suite, Window, Linux Trains, coaches, and mentors team What’s in it for you? Way more than just a paycheck. Our culture is centered around people – both the patients we treat and the clinicians we support. We also offer: A comprehensive, flexible benefits package including “basics” like medical, vision, and dental coverage on day one as well as a 401(k) savings program with company match, discounts and resources to meet your and your family’s needs both now and in the future. Leadership development programs to help you grow your skills and career. If you are ready to join an exciting, progressive company and have a strong work ethic, join our team of experts! Envision Healthcare uses E-Verify to confirm the employment eligibility of all newly hired employees. To learn more about E-Verify, including your rights and responsibilities, please visit www.dhs.gov/E-Verify Envision Healthcare is an Equal Opportunity Employer. #LI-DK1"
Data Engineer,Berkley,"Urbandale, IA 50322+1 location",https://www.indeed.com/rc/clk?jk=f4977c34c3687196&fccid=8e547279469474b7&vjs=3,"Company Details: Berkley Technology Services (BTS) is a dynamic company committed to providing world class IT services. We offer a unique culture, enabling our team members to be on the cutting edge of technology while delivering high quality solutions. We are looking for outstanding individuals who will bring unique perspectives, insight and innovation to our teams. BTS, a member company of W. R. Berkley Corporation, has facilities located in Des Moines, Iowa and Wilmington, Delaware. Our functions include working with various third parties to develop, integrate, and support insurance systems of WRBC's operating units. BTS strives to provide these functions in a holistic manner including helpdesk support, system connectivity, and operational support. Additional responsibilities include coordinating communications regarding best practices in the use of our supported systems and researching new technology. At BTS, there are opportunities associated with being a part of an established and empowering corporation while maintaining a positive personal working environment. Additionally, we provide a competitive compensation and benefits package including a casual dress code. BTS is constantly growing and expanding to meet the changing demands of one of the most successful insurance organizations in the world. Visit us at berkley-bts.com to learn more information. Responsibilities: This position will be providing data development at a moderately complex level such as ETL, cube creation, adhoc and management reporting, dashboard and data extract creation. This individual will work within a team environment that provides data resource development and support for several companies. They will be responsible for analyzing, designing and coding solutions for rapidly growing companies supporting the property & casualty insurance industry. Demonstrates a robust understanding of all business data processes/processing for a system and the related data structures Can produce significant new system functionality and defect resolution with minimal direction Creates design specifications that demonstrate an understanding of most interfacing systems and supported business processes (have understanding business processes down to the developer/analyst) Routinely proposes improvements to a data process and/or structure to improve supportability or usability Can perform adequate peer review on any changes in the system Can be consulted to provide recommendations to solve business issues based on experience and knowledge of current technology Will be required to communicate with employees primarily up to the mid-level within both company and client companies May provide mentorship to others May begin to develop sphere of influence with other teams Will be required to communicate and coordinate within the team May be responsible for on-call rotation (which does not include overnight support) Some travel required up to 20% Qualifications: Bachelor’s degree with emphasis in related field or equivalent experience. 5 – 10 yrs - reasonable single system / single technology knowledge 5 + yrs SQL experience (queries, stored procedures, functions) Must have demonstrated the capability of meeting the key accountabilities, or have the ability to learn/perform them A self-motivated individual with a passion for success Needs to be able to determine how changes impact customer and other systems Excellent communication and organizational skills Ability to work in a fast-paced team environment. Ability to quickly adapt and learn new technologies Ability to work independently Strong customer and business focus Must be fully vaccinated and remain fully vaccinated against COVID-19. *, unless prohibited by law. May occasionally lift and/or move up to 10 pounds. The Company is an equal employment opportunity employer. Vision abilities required by this job include close vision and ability to adjust focus. Ability to sit at a desk and work on a computer for extended periods of time. Additional Requirements: *Per the CDC, fully vaccinated means at least 2 weeks after (1) a second dose in a 2-dose series, or (2) a single-dose vaccine, and this status and definition applies to COVID-19 vaccines currently authorized for emergency use or approved by the U.S. Food and Drug Administration."
Data Governance Cloud Engineer,Global Payments,"Plano, TX 75024",https://www.indeed.com/rc/clk?jk=0cf1e011952d1254&fccid=601d247dd15a77e6&vjs=3,"Every day, Global Payments makes it possible for millions of people to move money between buyers and sellers using our payments solutions for credit, debit, prepaid and merchant services. Our worldwide team helps over 3 million companies, more than 1,300 financial institutions and over 600 million cardholders grow with confidence and achieve amazing results. We are driven by our passion for success and we are proud to deliver best-in-class payment technology and software solutions. Join our dynamic team and make your mark on the payments technology landscape of tomorrow. SUMMARY: The Data Governance Cloud Engineer role is an exciting opportunity to bring about data driven transformation and drive execution of enterprise-wide, governance and management of data assets. As a member of the centralized, enterprise-wide Data Asset Management & Enablement (DAM&E) program, the Data Governance Cloud Engineer is responsible for the design, development, configuration, implementation, and maintenance of GCP and AWS cloud environments that host a suite of Informatica data management technology products (Informatica Axon, Enterprise Data Catalog, Data Quality, and Data Privacy Management). These technologies enable coordination and execution of data asset management activities and drive adoption of GPN’s data asset management framework. As such, the Data Governance Cloud Engineer is a visible role across the enterprise, engaging with various technology, architecture, cloud, and security teams to implement and deliver cloud-based functionality, accessibility, availability, resiliency, and connectivity key to the DAM&E program. The Data Governance Cloud Engineer will also serve as the Federated Architect for the DAM&E program, focused on deepening governance by fostering collaboration and information sharing between Enterprise Architecture and delivery teams across the organization. As the Federated Architect for the DAM&E program, the Data Governance Cloud Engineer is responsible for the alignment and implementation of enterprise guidance within deployed GCP and AWS cloud environments. This includes engaging Enterprise Architecture and other governing groups to define, evolve, and manage deviations from the architectural guidance put forth by the Enterprise Architecture team. The ideal candidate will have deep design, build, and deployment experience within GCP and AWS cloud environments hosting enterprise-level applications, preferably in a Financial Services / Technology environment. JOB DUTIES & RESPONSIBILITIES: Responsible for planning, implementation, and growth of the GCP and AWS cloud infrastructure utilized by the DAM&E program to host a suite of Informatica data governance applications. Build, release, lead, and maintain the configuration of all development and production systems, including management/implementation of continuous integration/continuous delivery (CI/CD) activities, deployment project code repositories, pipelines, and server-based technologies. Work alongside Enterprise Architecture, Security Architecture, and Cloud Engineering teams to design, develop, and implement cloud native systems, scalable cloud services, network connectivity, and APIs to support Informatica application use cases and business needs. Ensure necessary system security by implementing server hardening standards, gold images, patches, and integrations with enterprise software, applications, and agents. Review new/deprecated GCP and AWS technology options and vendor products, recommend process and architecture improvements, and implement enhancements to deployed environments. Design and build High Availability processes and disaster recovery environments, including buildouts, site setup, maintenance, and support, to ensure environment resiliency. Configure and maintain backups, transfers, and synchronization processes between GCP, AWS, and associated disaster recovery environments. Serve as a Federated Architect for the DAM&E program, ensuring Enterprise Architecture standards and reference architectures are applied to GCP and AWS environments, connectivity solutions, and third party vendors/products. Maintain Architecture, Design, and Build (ADB) documentation as part of GPN’s Architecture Review Committee (ARC) process for DAM&E’s GCP and AWS environments. Ensure GCP and AWS current state architectures are maintained/updated to meet compliance requirements (e.g., PCI, Security, Legal, etc.), are aligned with the Enterprise Reference Architecture, and implement the security controls mapped to the reference architecture. Review functional and non-functional requirements that drive GCP and AWS solution design and ensure that solution architecture and design is aligned with target Enterprise Reference Architectures and Design Principles. Ensure GCP and AWS environment builds meet the requirements defined in the Technical Business Continuity RPO/RTO Standard and align with the Business Resiliency Group’s (BRG) criticality rating. Identify and communicate risks regarding solution deviations from Enterprise Architecture standards and reference architecture, engaging the Enterprise Architecture team and relevant governance groups as needed. QUALIFICATIONS: 6+ years of experience with implementation, migrations, and upgrades in an GCP, AWS, or Azure Cloud environment (GCP and AWS highly preferred). 3+ years of experience developing full stack solutions and utilizing software build and Continuous Integration & Continuous Deployment (CI/CD) tools, such as GitHub, Jenkins, AWS Code Deploy, and AWS Code pipeline. 3+ years of experience working with cloud deployment (Terraform, CloudFormation, Chef, Ansible) and cloud scripting languages (Python, Node.js). 3+ years of experience in application development background using object-oriented programming languages (Java, .NET, C#), as well as modern API development (Go and Gin Web Framework). Previous exposure to cloud serverless solutions (S3, CloudFront, API Gateway, Lambda Functions, ElastiCache, SQS, MQ). Previous exposure to cloud services and networking infrastructure (Shared VPC, VPC networks/firewalls/routes, Cloud NAT gateways/routers, VPN gateways/tunnels, load balancers, EC2, EBS, EFS, SG, NACL). Experience working with cloud database services (RDS, Cloud SQL, DynamoDB, DocumentDB). Experienced in developing, deploying, and debugging cloud-based applications using API Gateway, Cloud Functions, AWS CLI, and Cloud Shell. Experienced in working on DevOps/Agile operations process and tools area (code review, unit test automation, Service, Incident and Change Management). Experience in cloud infrastructure, integration, and cloud server provisioning, as well as disaster recovery planning, design, and implementation. Experience with containerization (Docker, Kubernetes, AWS EKS, AWS ECS, Fargate). Strong problem solving and troubleshooting skills. Strong verbal and written communication skills, including ability to generate technical specification documentation to communicate design and build options. Bachelor's degree in Computer Science, Engineering, Management Information Systems, or equivalent education or work experience. Prior experience working in Financial Services and/or Financial Technology organizations is highly desired. Global Payments Inc. is an equal opportunity employer. Global Payments provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex (including pregnancy), national origin, ancestry, age, marital status, sexual orientation, gender identity or expression, disability, veteran status, genetic information or any other basis protected by law. Those applicants requiring reasonable accommodation to the application and/or interview process should notify a representative of the Human Resources Department."
Senior Data Engineer,National Restaurant Association Solution,"Chicago, IL 60606 (Loop area)",https://www.indeed.com/rc/clk?jk=bdd34ac9ba131b9b&fccid=dd616958bd9ddc12&vjs=3,"The National Restaurant Association and National Restaurant Association Educational Foundation are proud to be part of a highly respected industry, providing hospitality, opportunity and quality of life. Much like the industry we represent, we have a dynamic, diverse and inclusive culture, grounded in trust, hospitality, collaboration and innovation. These are the core values that inspire our work, and what we’re looking for in an experienced Senior Data Engineer, who will be responsible for the health and welfare of all corporate database environments both on-premise and cloud. Data is core to our ability to deliver outstanding services, products and advocacy for the industry. As Senior Data Engineer, you will be integral to initiating, evaluating and influencing projects, both large and small, that provide the data perspective of the entire organization. Reporting to the Senior Manager, Data Services, the Senior Data Engineer, is also responsible for the creation, maintenance and architecture of database designs, coordination of system upgrades, and providing guidance/mentoring to junior and senior data staff. Working as part of our Database Services team, the Senior Data Engineer will be a key collaborator with colleagues across Project Management and Application Development, as well as with business partners, to ensure projects are delivered on time and within budget. Ideal candidates bring proven experience in data modeling, data integration and data analysis. Position requires a highly analytical and forward-thinking leader, with strong communication and problem-solving abilities. Responsibilities: Design and implement effective and scalable database solutions to store and retrieve organization data. Responsible for the architecture, modeling, design, development, testing, implementation, and maintenance of the data integration/ETL, procedures and structures which populate and grow our databases, data marts and tables. Provide direction to fellow data integration developers on solution design and implementation. Develop data flows that can leverage both on premise and cloud architectures. Partner with stakeholders including the business teams and architecture teams to assist with data-related technical issues and support data infrastructure needs. Monitor system performance by performing regular tests, troubleshooting, and integrating new features. Guide and coach staff members on standards, guidelines, best practices, and adherence to set standards. Manage requests, scheduling, and support for production reports. Work with Business Units to ensure accuracy of data and reports Ensure data compatibility and compliance to appropriate regulations across all platforms. Provide input into and drafts IT policies and procedures as applicable. Work as a manager and an independent contributor, dealing with scheduled activities and unforeseen problems and circumstances. Requirements: Essential Technical Skills/Experience: Bachelor’s degree in Information Systems, Computer Science, Data Processing or equivalent knowledge and/or work experience. Master’s Degree in related field is preferred. Minimum (5) years database administration experience with Microsoft SQL Server. Minimum (5+) years data warehousing experience preferably utilizing the Microsoft BI Stack. Experience with NetSuite and Workato highly desirable. Experience with Monitoring, Performance Tuning, Security, and Configuration of SQL Server environments 2008 R2, 2012 & 2019. Experience in Azure SQL and Power BI. Experience in Azure Synapse Analytics a plus. Experience with high availability and backup/recovery solutions (i.e. Clustering, Log Shipping, Replication, AG, Backup/Recovery, etc.) Significant experience in the use of the T-SQL Language and stored procedures, triggers, SSIS, SSRS, and data modeling. Manage the support of multiple application systems and their databases. Define requirements, perform analysis and support application programming, testing and implementation tasks using T-SQL, Analysis Services, Reporting Services and SSIS. Must be able to use project management skills to coordinate and manage tasks with users, IT Infrastructure and IT Analysis and Development units. Experience working in an Agile environment (Scrum, Lean, Kanban) is a plus. Essential Skills/Knowledge: Ability to persuasively communicate complex concepts and programs across technical and non-technical audiences. Excellent organizational, problem-solving and time management skills. Exceptional analytical and critical thinking skills. Strong interpersonal and diplomacy skills. Knowledge and experience in all phases of the development life cycle. Strong technical aptitude. Ability to work as part of a team and to work independently; a self-initiator, versatile and assumes risk with responsibility. Ability to maintain confidentiality of work records. Significant business and stakeholder relationship building experience. Highly developed communication skills including facilitation, presentation, and documentation. We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, or national origin, age, disability status, genetic information and testing, family and medical leave, protected veteran status, or any other characteristic protected by law. We strongly encourage women, people of color, people with disabilities and veterans to apply for our job openings. This commitment supports our policy of developing and capitalizing on the abilities of all our team members, as well as selecting, developing and promoting those who are best qualified. Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data / Software Engineer,Prolific Machines,"San Francisco, CA",https://www.indeed.com/rc/clk?jk=389e73bf24b0aba6&fccid=dd616958bd9ddc12&vjs=3,"Mission Statement: Prolific Machines exists to accelerate the transition to sustainable animal agriculture. Animal agriculture is wreaking havoc on the planet and its inhabitants. Deforestation, greenhouse gas emissions, excessive water and land usage, pathogen creation, and toxic runoffs are just some of the problems it creates - not to mention the ethical concerns. With the global demand for meat set to double by 2050, we urgently need to create an alternative that is as tasty, as nutritious, and as affordable as the meat we all know and love. At Prolific Machines, we're making this a reality. We are a well funded (post Series A, $30M+ raised) biotech startup that has been operating in stealth mode for the last 12 months. We believe we have the only viable solution to grow cell based meat at a price point which is competitive with factory farming. We are looking for mission-driven, skilled, and kind individuals to help us create a more sustainable, healthy, and tasty future. Diversity: We value diverse people, perspectives, and knowledge. To this end, we aim to foster a sense of belonging that enables everyone to bring their whole, authentic self to work everyday. We are committed to growing a diverse and inclusive team that encompasses all types of people. We believe this can only be achieved by acknowledging the ancestral, historic, and current systemic and communal inequities. We are looking for a Software / Data Engineer who can: Design, develop, and support our core data pipeline - Image and biological data Solve automation problems - data acquisition and system control Design and develop software platform / UI - R&D support and Product Development With skills and experience in: Python fluency (and competency in multiple languages) Big Data, scalable systems, databases, IoT, and cloud platforms (GCP) Image processing and bioinformatics Some frontend development - ReactJS This position description likely contains skills you already have as well as skills you would learn in the role. These are not requirements, so if you think you would do a great job at this role then you should apply regardless of whether you fit the above criteria. Start Date & Location: The San Francisco Bay Area, starting within the next 4 months. Compensation: Competitive salary (bi-weekly payments), significant stock options (subject to vesting), performance-based bonus, and free lunch and drinks every day! Benefits: Outstanding Health, Vision & Dental Insurance (including full spouse coverage), 401k plan with employer contributions, coverage of visa and relocation costs, at least one all expenses paid team holiday per year, fully flexible work hours, and unlimited vacation days. Evaluation: In lieu of the traditional application process of a CV and cover letter, we would rather give you an opportunity to tell us about yourself on your own terms by answering the below three questions. How you answer these is up to you: in words (narrative or otherwise), video, or visually. However, we do ask that it is concise (e.g less than 200 words for written answers). If applying by video or visually please send your application to jobs@prolific-machines.com."
Data Analytics Data Engineer III,FM Global,"Johnston, RI 02919+1 location",https://www.indeed.com/rc/clk?jk=8c3772e2c808303d&fccid=b000a8bfa0ce3df8&vjs=3,"Overview: FM Global is a leading property insurer of the world's largest businesses, providing more than one-third of FORTUNE 1000-size companies with engineering-based risk management and property insurance solutions. FM Global helps clients maintain continuity in their business operations by drawing upon state-of-the-art loss-prevention engineering and research; risk management skills and support services; tailored risk transfer capabilities; and superior financial strength. To do so, we rely on a dynamic, culturally diverse group of employees, working in more than 100 countries, in a variety of challenging roles. Responsibilities: The Data Engineer III is responsible for analysis, data modeling, data collection, data integration, and preparation of data for consumption. This role is also responsible for creating and managing data infrastructure, data pipeline design, implementation and data verification. Along with the team, the Data Engineer III is responsible for ensuring the highest standards of data quality, security and compliance. Additionally, the Data Engineer III will implement methods to improve data reliability and quality, combine raw information from different sources to create consistent data sets. This position will be essential to moving the Enterprise Analytics SQL database (EA) to Azure Synapse Analytics in the coming year. The Data Engineer III is the third level position in the Data Engineer job family. Those holding this position are typically assigned to work on integrated project teams for medium to large projects and be the lead for small to medium projects. The Data Engineer III must also be able to work independently. Data Acquisition Possess and continually grow knowledge of structured and unstructured data sources within each product journey (Underwriting and Risk; Client Service, Sales and Marketing; Claims; Account and Location Engineering) as well as emerging data sources (purchased data sets; external data; etc.). Partner with Product Owners, developers, Solution Architects, Enterprise Architects, Business Analysts, Data Engineers, Data Analysts, Data Scientists, and others to understand data and reporting needs. Develop solutions using data modeling techniques and using technologies such as Azure Synapse Analytics, SQL Server database; SSIS; C#, Azure Data Factory, and others as required. Validate solutions are accurate through detailed and disciplined testing methodologies. Ensure tables and views are designed for data integrity, efficiency and performance, and are easy to comprehend. Move and Store Data Design and maintenance of data flow, infrastructure pipelines, ETL/ELT, structured and unstructured data movement and storage solutions Design data models and data flows into and out of Data Analytics databases Understand and design data relationships between business and data subject areas Follow standards for naming conventions, code documentation and code review. Support Data Exploration and Transformation Needs Conduct data cleansing and support other team members with data cleansing tasks if needed Conduct data profiling to identify data anomalies and resolve issues Complete data preparation tasks Identify, design, and implement internal process improvements such as but not limited to automating manual processes, optimizing data delivery, redesigning infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Azure and SQL. Support users and production jobs Manage and address operational data issues by establishing workarounds and/or bringing in multi-functional teams to solve the issues in a timely manner Support developers, data analysts and data scientists who need to work with data in the appropriate data base(s) Analyze and assess reported data quality issues, conduct root cause analysis Consult dba(s) and other technology infrastructure team members on configuration and maintenance of platform Monitor system performance and look for opportunities for optimization Monitor data storage capacity Address production issues quickly, with appropriate validation and deployment steps Provide concise and professional communication to users, management and teammates Participate in effective execution of team priorities Able to solve complex problems with on-time delivery Identify work tasks and capture them in the team backlog Organize known tasks, prioritize work as needed Able to resolve colliding priorities and advances as needed Provides production support Network with product teams to keep abreast of database changes as well as business process changes which result in data interpretation changes Familiarity with 3rd Normal Form and Dimensional (Inmon/Kimball) database theory Qualifications: ETL/ELT design required Design/build/maintain data warehouse database(s) for analytical use Skilled with database clustering Familiarity with Azure cloud applications Familiarity with SQL database and massively parallel processing (mpp) platforms Prefer 4 year/Bachelor’s Degree or Master's Degree in Computer Science, Information Technology, Computer Engineering, or equivalent experience! We offer our employees a wide range of benefits including career long learning opportunities, tuition reimbursement, 401 (k), pension, flexible schedules, rich health and well-being programs, generous time off allowances, volunteer days and so much more! FM Global is an Equal Opportunity Employer and is committed to attracting, developing, and retaining a diverse workforce. Please note that all FM Global visitors, including external candidates interviewing for open positions will be required to be vaccinated and should be prepared to provide proof of vaccination. #LI-MY1"
Staff Data Infrastructure Engineer,Databricks,"Remote in San Francisco, CA 94105+1 location",https://www.indeed.com/rc/clk?jk=d85d5d3e9ca1308d&fccid=3d0f7ba22a49432f&vjs=3,"While candidates in the listed locations are encouraged for this role, we are open to remote candidates in other locations. As a Senior Data Infrastructure Engineer on the security data infrastructure team you will help build data infrastructure for the security team. You will build reliable, large-scale, multi-geo data pipelines to support detecting threats (internal and external threats) in Databricks systems, incident response forensics analysis and periodic compliance audits. You will build and deploy data pipelines in multi cloud (AWS, Azure and GCP) environments to process data and logs from external SaaS systems The impact you will have: Architect and build data pipelines to collect telemetry and logs from millions of virtual machines running in the cloud (AWS, Azure and GCP). Design the base ETL framework that can be used by all pipelines developed in the security team. Partner with security engineers, detection engineers and incident response engineers to build bronze, silver, gold quality data sets to meet detection, forensics and compliance needs. Develop best practices and standards that can be used by data engineers in the security team to build, optimize and maintain data pipelines. Build tools to detect, improve data quality and monitor data pipeline performance. Perform on-call rotation to support any production issues or troubleshooting production jobs. What we look for: 5+ years of experience in software or data engineering. 3+ years of experience in programming with python, scala or SQL. (preference for python) 3+ years of experience in building data pipelines using Spark or dataframes. 2+ years of experience in AWS, Azure or GCP. Comfortable in exploring new tech or finding creative ways to solve problems. Experience in security engineering or detection engineering. BS in Computer Science/Engineering/Information Systems or equivalent experience Benefits Comprehensive health coverage including medical, dental, and vision 401(k) Plan Equity awards Flexible time off Paid parental leave Family Planning Gym reimbursement Annual personal development fund Work headphones reimbursement Employee Assistance Program (EAP) Business travel accident insurance Mental wellness resources About Databricks Databricks is the data and AI company. More than 7,000 organizations worldwide — including Comcast, Condé Nast, H&M, and over 40% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems."
Data Warehouse Engineer,The Trade Desk,"San Jose, CA 95113 (Downtown area)",https://www.indeed.com/rc/clk?jk=0c89c74284f94a99&fccid=4899a85209d20142&vjs=3,"The Trade Desk is a global technology company with a mission to create a better, more open Internet for everyone through principled, intelligent advertising. Handling over 600 billion queries per day (more than 100X the query volume of search globally), our platform operates at unprecedented scale. We have also built something even stronger and more valuable: an award-winning culture based on trust, empathy, collaboration, and ownership. By working together across typical dividing lines, we are better as a team than any of us could be apart. Do you have a passion for solving hard problems at scale? Are you eager to join a trust-based, globally-connected team, where your contributions will make a meaningful difference? Come and see why Fortune Magazine consistently ranks The Trade Desk among best small-medium sized workplaces globally. ABOUT THE ROLE: With integrations into every major advertising exchange, we handle well over 4 trillion requests every month and growing – that's more page views and queries than Facebook, Google Search, and Google's entire network of websites combined – all serviced in single-digit-ms response times. Are you interested in working with big data? Do you want to push the edges of scale and responsiveness? It doesn't get much bigger or faster than this! We are looking to hire a Big Data Database Engineer to join our engineering team to build out our data-driven platform and support database related activities. You enjoy investigating database problems, performance issues, and evaluating/influencing MPP database use cases to ensure optimal performance on the platform. WHAT YOU'LL DO: Designing, developing, and supporting features and functionality that leverage our MPP databases. Provide day-to-day support and maintenance for the MPP databases that are part of our platform. This includes, but is not limited to: administration, analysis, support, proactive monitoring, troubleshooting, recoverability, security, installation, and design. Investigating potential problems and issues raised by users Monitoring database events and continuously optimizing system performance through troubleshooting and tuning Automate reactive procedures and promote rapid response to database issues Maintaining database configurations in compliance with established best practices Designing and implementing systems, policies, and procedures for backup and disaster recovery Monitoring ongoing capacity and implement design and architecture changes as needed to improve global availability Installing upgrades and patches to existing database servers Designing and developing database code as needed Reviewing and establishing database migration patterns and weekly release scripts Participating in on-call rotations WHAT YOU HAVE: 5+ years of Database Administration experience supporting mission critical relational databases Considerable experience and knowledge of on-premise MPP databases, like Vertica, Teradata, or Netezza. Vertica experience is a huge plus. Equivalent experience with other SQL technologies like Redshift or Snowflake, or even open source may be acceptable alternatives for the right candidate. Proficiency with OLAP Database Environments running on Linux Full systems lifecycle experience (from requirements to delivery) of database projects Experience designing, building, installing, configuring, supporting, and maintaining high-volume, large database systems Top-notch troubleshooting and analytical problem-solving skills Experience with database design and management aspects for various compliance programs, such as Sarbanes-Oxley or PCI, is a big plus Excellent written and verbal communication skills, with a demonstrated ability to document complex technical problems Ability to work effectively in a team environment, as well as independently with limited supervision #LI-RE1 The Trade Desk does not accept unsolicited resumes from search firm recruiters. Fees will not be paid in the event a candidate submitted by a recruiter without an agreement in place is hired; such resumes will be deemed the sole property of The Trade Desk. The Trade Desk is an equal opportunity employer. All aspects of employment will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law."
Data Engineer,C2S Techs,"Bellevue, WA+1 location",https://www.indeed.com/rc/clk?jk=cd236620957703ea&fccid=6fd7583c6ae9d675&vjs=3,"Overview Job title: Data Engineer Job duties: Strong understanding of BI areas. Ability to work in large, complex development BI projects including the proactive identification of issues and coordination of resolutions. Expertise in T-SQL, DW Concepts, Tabular Cube. Must have strong experience with Azure – Azure Data Lake / Azure Data Factory. Experience with Azure Data Bricks, and Synapse will be a big plus. Experience with Power BI Strong Analytical and troubleshooting skills Excellent coding and debugging skills. Able to work independently to implement a solution with minimal guidance. Ability to communicate with Businesses and developers accordingly. Strong communication skills in both written and spoken English. Working knowledge of Cosmos / Big Data Platforms (Azure, Data bricks) is recommended. Excellent communication skills and the ability to work under continual deadline constraints are necessary Responsibilities Work on complex BI ecosystems and design / develop solutions based on SQL SSIS, Azure Data bricks, SQL SSAS Design and develop PL / SQL procedures / ETL jobs with optimized processing time Communicate design, requirements, feature set, functionality, usability, and limitations of the subsystem to the team and/or development lead or manager. Participate in Business Requirements and Functional Requirements meetings, identify gaps in requirements and drive discussion around appropriate solutions. Design and code high-quality database solutions within a fast-paced sprint release cycle Proficiency in creating visualizations/reports/dashboards based on business requirements Manage errors gracefully. Document code and work completed. Conduct thorough unit testing of code and document the unit test cases. Conduct appropriate performance testing to ensure all solutions will meet SLAs and performance criteria. Provide support as needed throughout the Test and User Acceptance Testing phases. Create Technical Design Specification documentation that clearly articulates the design and code being implemented. Provide client communication as appropriate to the project. Be able to translate technical specifications into finished programs and systems and also have a thorough understanding of developing solutions to handle large volume data sets that are typical with BI solutions. Assist in architectural design reviews and ensure technology stack selection is relevant Ensure development and testing follow industry standards Degree Requirement: This position requires, at a minimum, a bachelor’s degree in computer science, computer information systems, information technology or a combination of education and experience equating to the U.S. equivalent of a Bachelor's degree in one of the aforementioned subjects. Work Schedule: Full Time, 40 Hours/Week"
Data Integration Engineer,Atlas Labs,Remote,https://www.indeed.com/rc/clk?jk=4a1b49fa21af3e4a&fccid=ad2fc6503a8fa97f&vjs=3,"No Patient Left Behind At Atlas Health, we are on a mission to connect patients with the best philanthropic medical financial aid programs available. We save and improve lives by empowering hospitals and health systems to match, enroll, and collect from over 20,000 patient assistance and health equity programs through Atlas Navigator, our end-to-end AI-powered patient advocacy solution. Patients access and afford the care they need, and health systems secure reimbursement for care delivered. Our people make a difference in patients’ lives every day. We are a dedicated, collaborative team that values radical transparency, accountability, continuous learning, thoughtful execution, and enjoying the journey. If you want to make an impact on the future of healthcare today, join us! Atlas Health is seeking a Data Integration Engineer to join our company. In this role, you will contribute to our post-sales data integration between the hospital system and Atlas. We have been given a challenge to close 125 new deals for this year and implement half of the deals this year. We are looking for a person with high integrity, strong work ethics, intelligent, and a team player to join our fast moving team. Initially, you will be tasked with the responsibility and authority to start engaging the hospital IT team and work with them to enable the flow of data from the hospital systems into Atlas. You will be supported by our senior team members to ensure your success. You shall advocate for simple solutions and designs over complex ones, knowing when to move fast and how to complete tasks correctly. You will be required to take extra caution in handling data to protect the privacy of our patient health information. All work must meet HIPAA standards for confidentiality and compliance. You are expected to conduct yourself at the most professional level and to be a team player. We value open communication to be very important and expect you to communicate well with both internal and external team members. You shall champion the creation of Domain Driven Design and testing to continuously improve our system. Data Integration Engineer Responsibilities: Complete data integration projects within 20 days from the kick-off. Continuously help improve our code base, processes and culture. Analyze incoming data making sure it is compliant with our specification. Communicate and work through issues with the team. Assist in building out our data warehouse platform. Guard and protect the data. One week of support rotating between team members. Mentor junior members. Other duties shall be assigned. Data Integration Engineer Requirements: Education Requirements: BS in Computer Science or related technical field involving coding (e.g., physics or mathematics), or equivalent technical experience Professional Experience Requirements: 7+ years of software development experience. Healthcare & security experience preferred. Expert-level knowledge of SQL Expert-level knowledge of Python or broad coding experience with many languages Expert-level knowledge of database models and storage; relational and non-relational Experience with Data warehousing and BI reporting Experience with Linux/Unix tools, Python, Docker, Git Experience with cloud platform Mature and responsibility to be trusted with the data and work autonomy. Have built large scale data applications. Mindset of getting things done over perfection with delays. Staying focused on tasks at hand ensuring these are completed in orderly fashion. Benefits: We offer a comprehensive benefit plan for our U.S. based employees which includes: Health, dental and vision insurance 401K Flexible time off Paid Holidays Why Join Our Team: Because you’re motivated by a combination of success, working alongside amazing team players, continuous learning, and have a passion for helping clients and patients. Atlas helps people access essential medical treatment, and avoid financial ruin from medical debt. You want to be part of the journey and play a key role in the organization’s success. Atlas values diversity of all kinds, and we’re committed to building a diverse and inclusive workplace where we learn from each other. We are an equal opportunity employer and welcome people of all different backgrounds, experiences, abilities, and perspectives."
Data Engineer,Federal Reserve Bank of New York,"Hybrid remote in New York, NY",https://www.indeed.com/rc/clk?jk=497f7c28cc440455&fccid=2c6850e24c8a2811&vjs=3,"Company Federal Reserve Bank of New York Working at the Federal Reserve Bank of New York positions you at the center of the financial world with a unique perspective on national and international markets and economies. You will work in an environment with a diverse group of experienced professionals to foster and support the safety, soundness, and vitality of our economic and financial systems. The Bank believes in work flexibility to balance the demands of work and life while also connecting and collaborating with our colleagues in person. Employees can expect to be in the office a couple of days per week as needed for meetings and team collaboration and should live within a commutable distance. What we do: The Data and Analytics chapter in the Technology Group builds data products that provide the organization with analytical capabilities in support of its mission. Reporting to the chapter lead for Data and Analytics, you will be part of a diverse, dynamic, and agile squad that enables rapid, repeatable, and resilient self-service analytics capabilities for the enterprise. This includes Data Preparation, ETL, Data Integration, RESTful analytical apps, Visualization/BI, and Surveys. Your role as an Data Engineer (Alteryx, Cloudera, Tableau, AWS): Develop and maintain workflows using Alteryx with wide-ranging source and target configurations in a customer facing role Wireframe, design and build Tableau dashboards with advanced features in a customer facing role Migrate on-premise data management solutions to AWS cloud only as well as hybrid configuration. Advice, design, tune and optimize Alteryx flows build by customers and deploy to gallery Display strong understanding of Cloudera’s SQL processing solutions Research, troubleshoot and recommend solutions to complex data integration problems. Mature analytics self-service adoption through active contributions towards community of practices, center of excellence and other forums. Deep understanding of interoperability between current and future platforms. (Alteryx, Tableau, AWS, etc.) Ability to articulate where the strengths and weaknesses are for each of our platforms to the end users What we are looking for: Technologist with background in data engineering with hands on experience in Alteryx, Tableau, Hadoop, Hive, Impala, AWS Data services Experience with Python in data engineering or application development Expertise in data wrangling, data integration, and visualization Knowledge of data architecture and data management best practices Experience implementing and maturing an analytics self-service model Collaborative working style to support larger team goals and outcomes Experience with relational databases and SQL-based technologies such as Oracle, Microsoft SQL Server or MySQL Experience with data catalog tools like Collibra Touchstone Behaviors set clear expectations for leading with impact at every stage of our careers and aspire to achieve in our continued growth and development. Communicate Authentically: Empathetically engage one another with direct and transparent dialogue and listening. Actively discuss viewpoints with respect and compassion in a timely and candid manner, taking into account verbal and nonverbal cues. Ask questions, learn from each other, and share information widely to move the Bank's work forward. Collaborate Inclusively: Inspire a diverse and inclusive environment that empowers others to contribute meaningfully. Intentionally bring a diverse set of people together to achieve positive business results. Drive Progress: Grow and adapt to changing priorities in the Bank. Experiment with new concepts and take appropriate risk to drive innovation. Remain curious and action oriented, navigating through ambiguity and uncertainty to drive outcomes. Develop Others: Equitably champion, mentor, and develop others to grow professionally. Demonstrate vulnerability and empathy to create a trusted environment. Take Ownership: Establish an environment of action and excellence by holding self and others accountable to execute to the highest standard. Benefits: Our organization offers benefits that are the best fit for you at every stage of your career: Fully paid Pension plan and 401k with Generous Match Comprehensive Insurance Plans (Medical, Dental and Vision including Flexible Spending Accounts and HSA) Subsidized Public Transportation Program Tuition Assistance Program Onsite Fitness & Wellness Center And more Please note that the position requires access to confidential supervisory information and/or FOMC information, which is limited to ""Protected Individuals"" as defined in the U.S. federal immigration law. Protected Individuals include, but are not limited to, U.S. citizens, U.S. nationals, and U.S. permanent residents who either are not yet eligible to apply for naturalization or who have applied for naturalization within the requisite timeframe. Candidates who are permanent residents may be eligible for the information access required for this position if they sign a declaration of intent to become a U.S. citizen and pursue a path to citizenship and meet other eligibility requirements. In addition, all candidates must undergo an enhanced background check, comply with all applicable information handling rules, and will be tested for all controlled substances prohibited by federal law, to include marijuana. The Federal Reserve Bank of New York is committed to a diverse workforce and to providing equal employment opportunity to all persons without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, age, genetic information, disability, or military service. The successful candidate must be fully vaccinated against COVID-19, and receive a booster shot within 30 days of being eligible to do so, unless the Bank grants an exemption based on a medical condition or sincerely held religious belief. This is not necessarily an exhaustive list of all responsibilities, duties, performance standards or requirements, efforts, skills or working conditions associated with the job. While this is intended to be an accurate reflection of the current job, management reserves the right to revise the job or to require that other or different tasks be performed when circumstances change. Full Time / Part Time Full time Regular / Temporary Regular Job Exempt (Yes / No) Yes Job Category Information Technology Work Shift First (United States of America) The Federal Reserve Banks believe that diversity and inclusion among our employees is critical to our success as an organization, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. The Federal Reserve Banks are committed to equal employment opportunity for employees and job applicants in compliance with applicable law and to an environment where employees are valued for their differences. Privacy Notice"
"Sr. Security Engineer, Data Processing (Remote)",CrowdStrike,Remote,https://www.indeed.com/rc/clk?jk=de5fdaf0b133ca9f&fccid=64e4cdd7435d8c42&vjs=3,"#WeAreCrowdStrike and our mission is to stop breaches. As a global leader in cybersecurity, our team changed the game. Since our inception, our market leading cloud-native platform has offered unparalleled protection against the most sophisticated cyberattacks. We’re looking for people with limitless passion, a relentless focus on innovation and a fanatical commitment to the customer to join us in shaping the future of cybersecurity. Consistently recognized as a top workplace, CrowdStrike is committed to cultivating an inclusive, remote-first culture that offers people the autonomy and flexibility to balance the needs of work and life while taking their career to the next level. Interested in working for a company that sets the standard and leads with integrity? Join us on a mission that matters - one team, one fight. About the Role: Develop software to integrate a variety of vendor security tools into Falcon XDR Automate processes using Python and assist in infrastructure projects Unify separate datasets to provide customers greater visibility of their security environments Drive development of parsers and scalable data ingestion strategies Develop UI enhancements for large-scale applications in CrowdStrike’s Falcon platform using Splunk and JavaScript Configure a wide variety of security applications to assist development efforts Constantly re-evaluate our product to improve architecture, user experience, performance, and stability. Brainstorm and design collaboratively with members across multiple teams. Be an energetic ""self-starter"" with the ability to take ownership and accountability for deliverables. Respond to a changing threat landscape, rapidly prototyping tools which provide customers greater visibility into their environments You'll use… Humio Query Language and backend knowledge Splunk/SPL dashboarding and backend knowledge HTML/CSS/JavaScript Vue Basic Windows and Linux administration Python scripting Regex parsing knowledge AWS Services (S3, SQS, IAM, EC2, etc.) Git Atlassian SDLC tools You will also have exposure to …. Golang Chef VMWare Kafka Grafana SaaS security products across various domains Experience with SIEM solutions What You'll Need: Ability to work across various backend technology stacks to create secure data ingestion pipelines Excellent communication skills, especially working with cross functional teams Experience administering Humio and/or Splunk Previous roles as a Security Analyst or SIEM Engineer Strong knowledge of Splunk search processing language (SPL), reporting, dashboards, and search acceleration techniques Experience scripting with the Splunk REST API and regular expressions. Knowledge of data ingestion, field extraction, and post-ingestion processing Python scripting for automation Windows and Linux systems administration Highly Desirable Skills: Working knowledge of Humio Experience with developing Splunk apps for clustered deployment Golang Previous roles using core AWS Services (S3, Lambda, EC2, IAM, etc.) Background administering security products such as firewalls, email appliances, NDR tools, etc. #LI-NT1 #LI-Remote Benefits of Working at CrowdStrike: Remote-first culture Market leader in compensation and equity awards Competitive vacation and flexible working arrangements Comprehensive and inclusive health benefits Physical and mental wellness programs Paid parental leave, including adoption A variety of professional development and mentorship opportunities Offices with stocked kitchens when you need to fuel innovation and collaboration We are committed to fostering a culture of belonging where everyone feels seen, heard, valued for who they are and empowered to succeed. Our approach to cultivating a diverse, equitable, and inclusive culture is rooted in listening, learning and collective action. By embracing the diversity of our people, we achieve our best work and fuel innovation - generating the best possible outcomes for our customers and the communities they serve. CrowdStrike is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex including sexual orientation and gender identity, national origin, disability, protected veteran status, or any other characteristic protected by applicable federal, state, or local law. CrowdStrike, Inc. is committed to fair and equitable compensation practices. For applicants in Colorado the salary range is $133,770 - $222,950 + bonus + equity + benefits. A candidate’s salary is determined by various factors including, but not limited to, relevant work experience, skills, and certifications. The salary range may differ in other states. CrowdStrike participates in the E-Verify program. Notice of E-Verify Participation Right to Work"
Senior Data Engineer,Pentasia,Remote,https://www.indeed.com/rc/clk?jk=1803f7eb92fb7fc9&fccid=9b480523593ed115&vjs=3,"Pentasia’s client, a Game Development Company in the iGaming industry, is hiring a hands-on Senior Data Engineer with a passion for data to work alongside other talented engineers. This is a remote role within Europe. You will work with your team members to deliver elegant solutions and troubleshoot difficult problems. You will get to work with massive data sets and apply the latest data technologies on a fast, leading-edge platform. Role: Solve challenging technical problems within highly distributed event driven environments Handle server-side development of distributed applications Develop pipelines for the client’s Data Platform Write clear, efficient, tested code Contributing to code reviews and solution design Contribute to evolution of standards and design patterns Continuous improvement of the tools and processes used by the team Skills & Qualifications; Strong experience with Java / Python Ideally experience with: SQL and Scala Kafka, Google Pub/Sub, CDC, Dataflow, Airflow DB2, BigQuery, BigTable, Mongodb, Couchdb Cloud Platform: Google, AWS Track record of developing technology to enable large scale data processing Agile software design principles and build processes Excellent organisation, communication and interpersonal skills Ability to work both collaboratively and with limited supervision Can deliver results within set deadlines Apply for the Senior Data Engineer role at Pentasia."
"Product Success, Data Engineer",Datavant,"Remote in Austin, TX",https://www.indeed.com/rc/clk?jk=bb5b4d5ec47205ea&fccid=7a310f14def4cec8&vjs=3,"Datavant is a rapidly growing healthcare technology company with a mission to connect the world's health data. By eliminating data silos in the healthcare industry, we aim to unlock opportunities to accelerate medical research, and help organizations design better ways to facilitate access, affordability, and quality of care leading to better patient outcomes. By joining Datavant today, you're stepping onto a highly collaborative, fully remote team that is passionate about creating transformative change in healthcare. We look for people who are smart, nice and get things done. We invest in our people and believe in hiring for high-potential and humble individuals who can rapidly grow their responsibilities as the company scales. Datavant is a distributed, remote-first team (no office locations) and we empower Datavanters to shape their working environment in a way that suits their needs - learn more here! As a member of the Data Operations team, you'll own a wide range of customer-related data work, including end-to-end client queries, scripting ad-hoc workflows, and automating processes wherever possible. You'll also work closely with the Product Success, Engineering, Product, and Data Science teams to improve our product and build tools that will help each department make data driven decisions. Your work will be critical to growing our business and solidifying ourselves as the market leaders in health data connectivity. You Will: Own all non-productized data workflows, querying Snowflake databases to support customer and internal requests, and supporting design of scalable processes that automate repeated tasks. Work closely with the Product team to provide feedback on new and existing features, surface opportunities for automation of existing processes, and help guide the product roadmap. Guide clients in preparing and onboarding their datasets to the Datavant Portal, own end to end fulfillment of client requests, data extracts, and generate aggregate statistics. Conduct internal research to scope and develop reporting dashboards used by each department to inform data driven decisions. Query customer data to perform novel analytics that are published to blogs, whitepapers, and academic publications/conferences to illustrate the value of our sources in analytics Identify team areas for growth and own process improvement to help shape the future of the Data Ops team What You Will Bring to the Table: Background in computer science and/or healthcare Familiarity with health data or desire to learn Experience working with large datasets & data pipelines Extremely strong SQL skills, Python a plus Comfortable with cloud services and building dashboards Comfortable with working from the command line High-organization and able to handle quick turnaround times with multiple stakeholders Driven, entrepreneurial, startup-ready We are committed to building a diverse team of Datavanters who are smart, nice, and get things done where every Datavanter is empowered to bring their authentic self to their work. We are all responsible for stewarding a high-performance culture in which all Datavanters belong and thrive. We are proud to be an equal opportunity employer and welcome applications from people of all backgrounds and experiences. At the end of this application, you will find a set of voluntary demographic questions. If you choose to respond, your responses will be used to help us identify areas of improvement in our recruitment process. We can only see aggregate responses and are unable to view individual responses. In fact, we aren't even able to see if you've responded or not! Responding is your choice and it will not be used in any way in our hiring process."
Software Engineer I (NoSQL Data Stores),Disney Media & Entertainment Distribution,"Seattle, WA+1 location",https://www.indeed.com/rc/clk?jk=98e3d8031840120c&fccid=c3092a91bcb42ca9&vjs=3,"Disney Media & Entertainment Distribution (DMED) brings together the Company’s best-in-class product, technology, and commercialization teams together into one global organization. DMED is responsible for the P&L management and all distribution, network and engineering operations, sales, advertising, data, and certain key technology functions worldwide for the Company's content engines. DMED also manages operations of the Company's streaming services including Disney+, Hulu, ESPN+ and Disney+ HotStar; and domestic broadcast and cable television networks. DMED Technology creates products, platforms, and innovations for the DMED Segment and The Walt Disney Company by driving the strategic development and use of technology, building scalable systems and products to empower our businesses and engage consumers. With global scale, local presence, and deep technological excellence, DMED Technology helps DMED and The Walt Disney Company optimize technology, platforms, and resources, while bringing creative ideas to life and creating industry-shaping approaches. The individual in this position will join the Engineering Services Infrastructure Data Stores team in an exciting and fast-paced environment where they will help build and maintain highly available NoSQL database systems operating across multiple cloud and physical locations. These systems help to power some of DMED’s largest consumer facing systems including fantasy games, personalization, and messaging. We’re looking for an individual who can apply software engineering principles to database engineering and administration to build processes and automation to help deliver infrastructure faster, safer, more consistently and with the right level of observability required to operate at scale. Responsibilities : Responsible for building, deploying, and ensuring all DMED database infrastructure is available 24/7/365. Leverage software development and automation to design, modernize, and deliver database infrastructure. Analyze, design, and deploy fault-tolerant, distributed, and highly available database infrastructure. Proactively plan and implement infrastructure changes through capacity forecasting, software release cycles, and right sizing. Provide database expertise through performance tuning, troubleshooting and administration. Develop, enhance, and adhere to engineering and administration standards. Develop automation and tooling to increase operational efficiency while ensuring system reliability and security. Build infrastructure and systems for scalability, resiliency, availability, and recovery though infrastructure as code and configuration management. Provide relevant insights of data store infrastructure through metrics, monitoring, and alerting. Maintain thorough and well-written documentation. Participate in live event support and on-call rotation. Basic Qualifications : 0-2 years of related work experience with NoSQL database systems such as Cassandra, MongoDB, Redis, DocumentDB, DynamoDB, and Cosmos DB. Experience working in Agile software development. Experience with source control management tools (Git, GitLab, GitHub). Intermediate to advanced level of expertise in one or more programming languages such as Python, Java, or Go. Experience running, deploying, and maintaining production cloud infrastructure in Amazon Web Services. General understanding and experience with Linux operating system, network, and containers. Experience with infrastructure as code (Terraform, CloudFormation). Excellent verbal and written communication skills. Preferred Qualifications: Experience operating within a database reliability engineering (DRE) and/or systems reliability engineering (SRE) role. Experience building a proper path to production leveraging multiple lifecycles, testing, integration, and CI/CD pipelines. Experience running, deploying, and maintaining production cloud infrastructure in Azure and GCP. Experience with configuration management (Ansible, Chef). Required Education : Bachelor's degree in Computer Science or related field, or equivalent training or work experience."
Data Engineer - Remote,PatientPoint,"Remote in Cincinnati, OH 45236+1 location",https://www.indeed.com/rc/clk?jk=cb0b4211105d8f84&fccid=3a2aae3e210f8d0e&vjs=3,"Position: Senior Data Engineer Location: Remote in Cincinnati, OH, Chicago, IL, New York City, NY, or Nashville, TN About PatientPoint PatientPoint® is the patient engagement platform more providers trust. Our innovative, tech-enabled solutions create more effective doctor-patient interactions and deliver high value for patients, providers and healthcare sponsors. Through our nearly 140k unique healthcare provider relationships, PatientPoint’s solutions impact roughly 750 million patient visits each year, further advancing our mission of making every doctor-patient engagement better®. Learn more at patientpoint.com. What We Offer We know you bring your whole self to work every day. That is why we are committed to providing modernized benefits and cultural perks to our teammates. We offer: competitive compensation, comprehensive and affordable benefits, flex time off to rest and charge, where applicable, a hybrid work model, mental & emotional wellness resources and coaching, 401K and more. Job Description The Data Engineer is responsible for developing architecture data models to support data visualization, business intelligence, and data science. As a data expert, the Data Warehouse Architect will gather requirements from business stakeholders and build and deploy advanced SQL queries. This position will work directly with business leaders, team members, and IT leadership to provide agile data delivery to support business decisions. Primary Duties: Translate business requirements into a star schema data model and validate results with business representatives Solve and model complex business requirements using SQL Collaborate on a team with infrastructure, BI report development, and business analyst resources, and clearly communicate solutions to both technical and non-technical team members Uses an understanding of Data Warehouse best practices, relational structures, dimensional data modeling, structured query language (SQL) skills, data warehouse, and reporting techniques to make decisions Design, develop, enhance and support data infrastructure including data lake and data warehouse structures primarily using Snowflake and Fivetran. Communicate with team members regarding projects, development, tools, and procedures Minimum Qualifications: Bachelor's Degree in Computer Science or a related field 5+ years of professional experience Advanced SQL query writing experience required Hands-on experience in relational and multi-dimensional data modeling, including multiple source systems from databases and flat file Experience implementing complex stored procedures and standard DWH and ETL concepts Preferred Qualifications: Knowledge of developing dimensional data models and awareness of the advantages and limitations of Star Schema and Snowflake schema designs preferred Understanding of Kimball Data Warehousing design principles is preferred Knowledge of Python, GitHub, Airflow preferred Build/Design data pipeline using Python/Snowflake/Airflow preferred Experience implementing data quality initiatives such as test harnesses, monitoring, and auditing features on data preferred Experience with AWS data storage and management technologies such as S3 Essential SAFe experience helpful PatientPoint requires its employees to be fully vaccinated (as defined by the CDC) against COVID-19, where allowable under the law, unless they are approved for a reasonable accommodation based on their qualifying disability/medical condition, or sincerely-held religious beliefs that prevent them from being vaccinated. #LI-Remote"
Data Engineer,DPR Construction,"Washington, DC 20002 (NoMa area)",https://www.indeed.com/rc/clk?jk=6d0313df72c642f1&fccid=7da80e6d4430aa40&vjs=3,"Job Description DPR is looking for an experienced Data Engineer to join our Data Solutions team and tackle exciting and impactful business problems in the domain of Construction. This position will be part of a team that uses AI, ML, modern Data Engineering techniques to bring efficiencies in the construction life cycle. Ideal candidates need to have a strong curiosity about data, and a proven track record of successfully applying analytics, data engineering techniques. This an outstanding opportunity to apply your skills and have a direct impact on the Construction Industry. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. Responsibilities Responsibilities include solutions implementation from cloud-first thinking using Agile, Scrum, Dev-Ops, Data Ops. Work with the business to understand Data Engineering needs and offer solutions. Evaluate business needs and objectives Create and maintain optimal data pipeline architecture. Assemble data sets that meet functional / non-functional business requirements. Build analytics models that utilize the data pipeline to provide actionable insights into the construction lifecycle. Maintain data pipelines and support enhancements based on business requirements and requests. Design and implement process improvements like automating manual processes, optimizing data pipeline from source to consumption, scale the data infrastructure, etc. Support software developers, database architects, data analysts, and data scientists on data initiatives and ensure that the data delivery architecture is consistent throughout ongoing projects. Expand and optimize data and data pipeline architecture, as well as optimize data flow and collection for cross-functional teams. Work with stakeholders, cross-functional business groups, Data and Software teams to assist with data- related technical issues and support their data needs. Develop data models for analytics and data scientists and them in building and optimizing data. Position Requirements 2+ years experience as a software/data engineer in a fast-paced, technical, problem-solving environment. Experience with ETL or ELT or building custom data pipelines. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Strong analytic skills related to working with unstructured datasets. Strong project management and organizational skills. Experience with Data Modeling and BI tools like Power BI, Looker Experience with SQL, JSON and XML, LookML Knowledge of API’s, REST, GraphQL. Bonus Points for Experience with Cloud Data Warehouse technologies. Knowledge and understanding of AWS and Azure data ecosystem. Experience with programming languages like Python. DPR has been nationally recognized for its strong company culture, based on a well-defined purpose “We Exist to Build Great Things,” and four core values: integrity, enjoyment, uniqueness and ever forward. A flat, title-less organization that empowers people at all levels to make decisions, DPR ranked on FORTUNE’s “100 Best Companies to Work For” list for five consecutive years. For more information, visit http://www.dpr.com ."
Data Warehouse Engineer,"Analysis Group, Inc.","Boston, MA 02199 (Back Bay area)",https://www.indeed.com/rc/clk?jk=48cd649f13710f8d&fccid=0fc0821efa996180&vjs=3,"Overview: Make an impact at Analysis Group, where we provide our clients with thoughtful, pragmatic solutions to their most challenging business and litigation problems. Analysis Group is one of the largest international economics consulting firms, with more than 1,000 professionals across 14 offices in North America, Europe, and Asia. Since 1981, we have provided expertise in economics, finance, health care analytics, and strategy to top law firms, Fortune Global 500 companies, and government agencies worldwide. Our internal experts, together with our network of affiliated experts from academia, industry, and government, offer our clients exceptional breadth and depth of expertise. The Data Warehouse Engineer will join the Business Intelligence team and will be responsible for optimizing Analysis Group’s data warehouse, ETL processes and tabular models using industry standard best practices. The Data Warehouse Engineer will ensure all warehouse data is accurate and resolve any data issues. This role requires a deep understanding of data modeling and integration practices to efficiently ingest, transform, and provision data across various sources into an organized and unified view. Essential Job Functions and Responsibilities: Design, code, test, and deploy new data warehouse and tabular model features. Design and implement ETL procedures for intake of data from both internal and external sources, using star schema and Kimball Design Methodology. Provide guidance on data modelling best practices for the warehouse and tabular models. Carry out monitoring, tuning, and database and SSAS performance analysis. Troubleshoot production support issues. Ensure that the established standards are followed for application architecture, development, documentation and deployment. Work with the team to evaluate business needs and priorities, liaise with key business partners and address team needs related to data systems and management. Provide guidance on best practices for Business Intelligence data architecture. Qualifications: Bachelor’s degree preferred. Concentration in computer science or related subjects preferred. Minimum 5 years of substantive relevant experience required. An ideal candidate will have 5-8 years of substantive relevant experience. Extensive experience in database management and data warehouse design required. Extensive experience with SQL Server and SSAS (Tabular) databases required Strong analytic skills related to working with complex datasets required Expertise in designing, validating, and implementing projects across the hybrid infrastructure (On-cloud to On-Premise and vice versa) preferred Experience with visualization tools like Power BI preferred C# experience for complex ETL processes (pulling data from web apis, etc.) preferred Experience with DAX preferred Experience with Thompson Reuters Elite 3E preferred Strong analytical and organizational skills. Strong interpersonal, oral, and written communication skills. Excellent attention to detail. Able to effectively work independently and as part of a team. An inclusive and growth-oriented mindset, strong interpersonal skills, and an ability to work across differences. Eligible candidates must be authorized to work in the United States without sponsorship or restriction, now and in the future. Analysis Group embraces diversity and equal opportunity in a deep and meaningful way. We are committed to building teams that represent a variety of backgrounds, perspectives, and skills. The more inclusive we are, the better our work will be. We provide equal opportunities across all sexual orientations, gender identities and expressions, races, colors, ethnicities, mental and physical abilities and characteristics, ages, socioeconomic statuses, and religions, and we encourage candidates of all backgrounds to apply. Other Information: Nothing in this Job Description restricts Analysis Group, Inc.’s right to assign or reassign duties and responsibilities to this position at any time. This position is at will, which means that it can be terminated by the employee holding the position or by Analysis Group, Inc. at any time, with or without cause or notice. Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities. The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. Â: Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities. Please view Equal Employment Opportunity Posters provided by OFCCP here. The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Engineer (Remote),Blue Cross Blue Shield of Louisiana,"Remote in Baton Rouge, LA 70806+1 location",https://www.indeed.com/rc/clk?jk=99b15193977bf24f&fccid=4f8f5d6678a5792a&vjs=3,"We take great strides to ensure our employees have the resources to live well, be healthy, continue learning, develop skills, grow professionally and serve our local communities. We invite you to apply for a career with Blue Cross. Please note that effective Jan. 4, 2022, Blue Cross and Blue Shield of Louisiana implemented a policy requiring any employee who enters any of our offices or who interacts in person with anyone for company business purposes to be fully vaccinated for COVID 19, unless legally entitled to a reasonable accommodation related to religious or medical exemptions. At this time, that policy is suspended and vaccination is not required to enter our facilities. Please note this is subject to change at any point in time to ensure compliance with company policy or government mandates and certain client facing roles may have separate protocols. Residency in or relocation to Louisiana is preferred for all positions. POSITION PURPOSE : This position develops data integration solutions using data integration tools or other means based upon the direction determined by the agile team’s technical lead and in association with the Lead Data Engineers, Principal Data Engineers, and functional manager. This position complies with all laws and regulations associated with duties and responsibilities. NATURE AND SCOPE : This position reports to the Manager of Enterprise Information Management ACTIVITIES OF DIRECT REPORTS: This position has no direct reports. NECESSARY CONTACTS: To do this job effectively the incumbent has to be in contact with: All levels of BCBSLA personnel and outside vendors QUALIFICATIONS : EDUCATION: Bachelor’s Degree in Computer Science or related field required. Four years of related experience can be used in lieu of a degree. Advanced degree or certification preferred. Requires knowledge in areas such as data mart, data warehouse, or data lake development, ETL/ELT data integration patterns, web and cloud-oriented systems integration and communication-based systems, languages such as C#, Python or Java. Additional training for integration tools used will be supplied. Must have a minimum of two years of professional information technology experience to include experience with deployment and support of data integration or API solutions. Experience in one of the following areas is required: Support of a data warehousing, data mart, data lake, and/or business intelligence environment ETL/ELT development background with Informatica PowerCenter, DataStage, SSIS, or Azure Data Factory Development experience with Teradata, Oracle, SQL Server, Data Lake, or Sybase repositories Other programming language such as C#, Python, PL/SQL, SparkSQL, NoSQL Shared API for web or cloud applications development background Big Data technologies such as Hadoop, Spark, Artificial Intelligence (AI), Machine Learning (ML), Natural Language Processing (NLP) Experience in the following areas is preferred: BI tools or reporting experience with SSAS, SSRS, BOE, and/or Tableau Project Management Experience Healthcare Payer experience Experience working in an agile development methodology DevOps experience (automation of code or workflow through release pipeline) Data warehousing development lifecycle The following skills are required: Ability to independently design, develop and debug basic ETL/ELT or API solutions based on business requirements with feedback from the team’s technical lead Ability to independently evaluate the test results of others Ability to become self-sufficient with integration tools Ability to independently create basic integrations to build dimensional databases, data marts, data lake, and cubes with feedback from the team’s technical lead Strong analytical, problem-solving and decision-making skills along with the ability to react quickly to changing requirements due to product limitation or driven by enterprise need Ability to independently develop Unit Test Plans and Test Data with feedback from the team’s technical lead Ability to resolve the issues found in workflows, mappings, stored procedures, and data pipelines Develop basic system and integration test plans Ability to execute test plans and document results and discrepancies with feedback from the team’s technical lead Ability to write SQL queries using subqueries Strong knowledge of SQL data types and functions Very good communication and writing skills with an attention to detail ACCOUNTABILITES & ESSENTIAL FUNCTIONS : Analyzes data integration requirements and create integration solutions that support the application development efforts. Modifies and implements database integration solutions to support business requirements. Ensures capture of data integration metadata, lineage, and catalog through configuration and parameterization Develops, executes and evaluates data quality test plans such that the results and quality of the data assure compliance with corporate expectations. Provides basic guidance on the data integration processes and procedures to Associate Data Engineers and other team members. Follows the software development life-cycle as required to ensure that the company meets regulatory requirements. Participates in the development of strategies for data acquisition, archive recovery, and database/data lake implementation. Supports the management of data migrations/conversions and troubleshooting data processing issues. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable Accommodations may be made to enable individual with disabilities to perform the essential functions. Job duties are performed in a normal and clean office environment with normal noise levels. Work is predominately done while sitting or standing. The ability to comprehend, document, calculate, visualize, and analyze are all required. An Equal Opportunity Employer All BCBSLA EMPLOYEES please apply through Workday Careers. PLEASE USE A WEB BROWSER OTHER THAN INTERNET EXPLORER IF YOU ENCOUNTER ISSUES (CHROME, FIREFOX, SAFARI) Additional Information Please be sure to monitor your email frequently for communications you may receive during the recruiting process. Due to the high volume of applications we receive, only those most qualified will be contacted. To monitor the status of your application, please visit the ""My Applications"" section in the Candidate Home section of your Workday account. If you are an individual with a disability and require a reasonable accommodation to complete an application, please contact recruiting@bcbsla.com for assistance. In support of our mission to improve the health and lives of Louisianians, Blue Cross encourages the good health of its employees and visitors. We want to ensure that our employees have a work environment that will optimize personal health and well-being. Due to the acknowledged hazards from exposure to environmental tobacco smoke, and in order to promote good health, our company properties are smoke and tobacco free. Blue Cross and Blue Shield of Louisiana performs background and pre-employment drug screening after an offer has been extended and prior to hire for all positions. As part of this process records may be verified and information checked with agencies including but not limited to the Social Security Administration, criminal courts, federal, state, and county repositories of criminal records, Department of Motor Vehicles and credit bureaus. Pursuant with sec 1033 of the Violent Crime Control and Law Enforcement Act of 1994, individuals who have been convicted of a felony crime involving dishonesty or breach of trust are prohibited from working in the insurance industry unless they obtain written consent from their state insurance commissioner. Additionally, Blue Cross and Blue Shield of Louisiana is a Drug Free Workplace. A pre-employment drug screen will be required and any offer is contingent upon satisfactory drug testing results. JOB CATEGORY: Data Analytics/Warehousing, & Business Intelligence"
Senior Data Center Engineer: Experienced,Jane Street,"New York, NY",https://www.indeed.com/rc/clk?jk=50ad048b206d15c1&fccid=0e38ef958e252f1e&vjs=3,"About the Position We are looking for an experienced Data Center Engineer to perform rack and stack work in our regional data centers and to serve as a support resource to our Network Engineering, Software Engineering, and Systems Administration teams. In this hands-on position, you’ll travel between data centers to install, configure, and monitor new and existing equipment. This will often require you to design plants for new equipment deployments and to measure, install, dress, and label copper and fiber cabling. On any given day, there may be several logistical tasks to coordinate across locations, including the shipping and receiving of our server, network, and telecommunications equipment. You’ll also maintain inventory for our cabling, optics, and network equipment. Clear communication and strong interpersonal skills will prove valuable as you collaborate with Senior Network Engineers and Senior System Administrators to troubleshoot issues. You’ll also be expected to supervise vendors when they are in the data center doing work. Our data centers house the technology and equipment that support our daily work. You’ll play an important role in maintaining the highest standard of security, organization, documentation, safety, cleanliness, and supplies at each data center location. About You 5+ years of experience working in a colocation environment with strong knowledge of data center best practices and cabling methodology Self-starter who is motivated to work independently Motivated to improve processes where possible Knowledgeable in networking and Linux Experience in low-latency environments preferred Able to lift up to 50 pounds and climb ladders to install cabling and equipment Able to work evening hours and occasional weekends (usual hours are from 12pm-9pm) Basic Bash scripting experience and familiarity with Dell, Cisco, Arista, Ciena, Corning, and/or Ortronics products are preferred Ability to terminate copper/fiber cabling, test and troubleshoot fiber connectivity, and upgrade code of networking devices, server firmware, and BIOS settings are preferred Has access to reliable transportation on a daily basis for personal transportation between Jane Street locations across the metro NYC region, which are not necessarily served by public transportation Fluency in English required"
Data Engineer II,Blue Cross and Blue Shield of Kansas City,Remote,https://www.indeed.com/rc/clk?jk=cd705ff932bef5c4&fccid=a1208edcf19bb616&vjs=3,"Are you interested in learning about healthcare professions and the latest healthcare innovations in the KC area? Become part of an organization that is dedicated to making a difference in both your career and community. Job Description Summary : The Data Engineer II works collaboratively to mine and evaluate internal and external data to create insights, solutions, and visualizations for strategic Blue KC analytical priorities. This individual will develop a deep understanding of analytical technologies in order to enable Blue KC to create valuable models and insights for both internal and external stakeholders. Job Description Designs and implements the data pipelines and transformations necessary for our new development. Ensures quality and accuracy of data used by performing data quality measurement and analysis. Works closely with application developers, architects, and engineers to ensure that we produce high-quality code and infrastructure. Maintains the high quality of our data pipelines in production, ensuring data quality and performance. Stays current with rapidly developing data technologies and tools. Shares knowledge with other Blue KC resources. Develops strategies, standards, and best practices for data ingestion and integration Minimum Qualifications Bachelor’s degree in Computer Science, Computer Engineering, Information Systems. or related field, or an equivalent combination of education, training, and experience. 3+ years’ experience in ETL or ELT utilizing enterprise tools (DataStage, Informatica IICS, Matillion, others). 3+ years of SQL development. Experience with DLM and Enterprise Platforms for managing data movement. Basic understanding of insurance industry (including claims processes, how attribution works, and the core business concepts of insurance). Highly technical with hands-on experience using Python, or JVM language (Java, Scala, Clojure, or Kotlin). Experience implementing, managing, and developing in Apache Airflow or other orchestration tools. Experience implementing data solutions in a major cloud provider (Azure, AWS or GCP). Experience with semi-structured formats (Avro, Parquet, ORC, YAML, JSON, or XML). Experience with MDM Implementation Experience with MDM Tools (Informatica, Profisee, or similar) Preferred Qualifications Experience with Scrum and Agile development practices Experience implementing Kafka, Schema Registry and Kafka Streaming and/or Spark Streaming. Experience with Microsoft Azure. Experience with Apache Airflow and Celery. Experience with Docker, Kubernetes and Terraform. Experience with Snowflake or Synapse. Experience with Informatica IDQ, EDC, IICS, and Axon Experience with Scala, Python and Java. Experience with NodeJS and React. Experience with Azure Data Lake Storage Gen2."
Data Engineer-Remote USA,America At Work,Remote,https://www.indeed.com/rc/clk?jk=0a21de55da4fb3f1&fccid=82c7fe98611d2d88&vjs=3,"Are you tired of not having your recommendations and suggestions implemented? Do you feel that you are not part of the team that is driving business forward? Have your personal and professional growth curve started to flatten out? If the answer is yes to any of these questions, maybe is time to look for a better career, not just another job. If you have at degree in Computer Information System, Computer Science, or relevant degree and at least 3 years’ experience and want to be part of a strong team; let’s talk!! THE SKILLS SET NEEDED Bachelor’s degree in Computer Information System, Computer Science or relevant degree required. Minimum of 3 years of experience required. SQL, Microsoft SQL experience required. Proficient with Excel required. Azure Synapse Experience preferred. Azure Data Factory preferred."
"Software Engineer, Data",CBOE,United States,https://www.indeed.com/rc/clk?jk=4203c13382304036&fccid=538508a696477a24&vjs=3,"Job Description Cboe Data and Access Solutions division is looking for a Reference Data Software Engineer who strives to build highly scalable, performant and robust systems that help clients benefit from our comprehensive market data sets and analytics. We own some of the largest financial data sets in the world and are looking for programmers that enjoy tackling the challenges that come with real time streaming data and large historical databases. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, optimizing data flow and collection for cross functional teams, and supporting data quality investigations and troubleshooting for myriad real-time streaming and historical data sets. The candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and automating workflows. The right candidate will be excited by the prospect of optimizing our company’s data architecture to support our next generation of products and data initiatives. This hire will design, implement, and extend reference data and security master functionality for Cboe’s systems. Implement automated tests and ensure system quality and performance. Help with production operations as needed. Responsibilities Design, implement, and extend reference data and security master software functionality. Strong SQL and relational database knowledge or ability to quickly learn. Strong understanding of ETL techniques. Working domain knowledge of financial securities and derivatives products. Working knowledge in programming language(s) used by the team (Java, C#, scripting languages). Working Linux and Windows knowledge. Ability to implement features with necessary performance and/or scaling characteristics. Implement automated unit and integration tests Help with production operations. Ensure features are correctly implemented in certification and production environments. Plan team sprints and participate in periodic team meetings. Participate in peer code reviews. Participate in requirements gathering and analysis. Requirements 1-5 years of experience in financial markets Bachelors or equivalent work experience The Cboe Experience Whether you are just beginning your career or are a senior-level professional, working at Cboe will offer you countless opportunities to develop skills, make an impact through meaningful contributions, and gain rich experiences at an accelerated pace. By working collaboratively with smart, genuine and hardworking colleagues, you will build enduring relationships through frequent collaboration that will serve you well throughout your career, regardless of your chosen path. And, along your exceptional career journey at Cboe you’ll receive amazing benefits and robust rewards. Equal Employment Opportunity We're proud to be an equal opportunity employer - and celebrate our associates' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. #LI-CP1 Cboe Global Markets is an Equal Opportunity Employer. For more information, please click the following links: Equal Employment Opportunity is The Law (in English) Equal Employment Opportunity is The Law (in Spanish) Equal Employment Opportunity is The Law (Supplement) E-Verify Participation Poster (English & Spanish) Right to Work Poster (English) Right to Work Poster (Spanish)"
Data Engineer,Fisker Inc,Remote,https://www.indeed.com/rc/clk?jk=c4fa8b1a6b7404b8&fccid=38c354bb9b09f488&vjs=3,"About Fisker Inc. California-based Fisker Inc. is revolutionizing the automotive industry by developing the most emotionally desirable and eco-friendly electric vehicles on Earth. Passionately driven by a vision of a clean future for all, the company is on a mission to become the No. 1 e-mobility service provider with the world’s most sustainable vehicles. To learn more, visit www.FiskerInc.com – and enjoy exclusive content across Fisker’s social media channels: Facebook , Instagram , Twitter , YouTube and LinkedIn . Download the revolutionary new Fisker mobile app from the App Store or Google Play store. We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. Job Responsibilities: Conduct requirement analysis and design source to target mappings Architect, Design, develop and unit test data pipelines in Azure Data Factory and Databricks or similar technologies Build CI/CD pipelines for data integration Assist in building data model & architecture for various layers in the data lake / data warehouse (snowflake etc.) Responsible for the design, development, implementation, and support of critical enterprise E2E Business Intelligence ETL solutions Provide technical guidance to other internal and external teams Assess current processes, recommend, and implement approaches to efficiently handle increasing volumes of data Document and communicate technical specifications to ensure that proper and optimized techniques, queries, data standards, and final outputs are understood and incorporated into data and analytics processes Participate in business analysis activities to gather required reporting and dashboard requirements Handle the product's or project's conception, translate business requirements, design initial technical specifications, and develop data solutions Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Design and develop reports and dashboards with data from potentially multiple data sources Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure and/or AWS ‘big data’ technologies. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Keep our data separated and secure across national boundaries through multiple data centers and Cloud regions. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems. Qualifications: 4+ years of experience Candidate should have good understanding of ETL concepts and Expertise and hands on experience in Azure Data Factory, Azure Data Lake Storage and Data bricks or similar technologies Hands on experience of working on cloud database tools like Azure SQL Database, Azure Synapse Strong SQL writing skills and good understanding of Data Lake and Data Warehousing concepts including data modeling Knowledge of Azure DevOps and agile methodology desirable Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Strong project management and organizational skills. Good communication and interpersonal skills 5+ years’ experience in ETL, Data Engineering, or BI fields with concentration on data transformations Familiar with Data Visualization standard methodologies BS in Computer Science, Engineering or a related technical role or equivalent experience Fisker Inc. is an Equal Opportunity Employer; employment at Fisker Inc. is governed based on merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status. Applicants wishing to view a copy of Fisker Inc.’s Affirmative Action Plan for veterans and individuals with disabilities, or applicants requiring reasonable accommodation to the application/interview process should notify the Human Resources Department #LI-SM1 #LI-REMOTE"
Data Engineer,"Take-Two Interactive Software, Inc.","New York, NY+1 location",https://www.indeed.com/rc/clk?jk=cfb8491b4ac7c4ca&fccid=2dda8667d8de78d8&vjs=3,"Who We Are: Take-Two develops and publishes some of the world's biggest games. Our Rockstar label creates Grand Theft Auto and Red Dead Redemption, two of the most critically acclaimed gaming franchises in history. Our 2K label creates games like NBA 2K, WWE 2K, Bioshock, Borderlands, Evolve, XCOM and the beloved Sid Meier's Civilization. Our Private Division label publishes Kerbal Space Program, Ancestors and The Outer Worlds. While our offices (physical and virtual) are casual and inviting, we are deeply committed to our core tenets of creativity, innovation and efficiency, and individual and team development opportunities. Our industry and business are continually evolving and fast-paced, providing numerous opportunities to learn and hone your skills. We work hard, but we also like to have fun, and believe that we provide a great place to come to work each day to pursue your passions. The Challenge: Take-Two Interactive is looking for a passionate, solution-oriented Data Engineer to join the team in building the next generation reporting and analytics platform. The ideal candidate is a strong Python developer who has experience building APIs and pipelines to support integrations of internal and external applications. The ideal candidate relishes working with large volumes and diverse types of data, enjoys the challenge of highly complex technical contexts, and, above all else, is convinced in the value of data for better decision-making. The Data Engineer will support and collaborate with architects, data analysts and data scientists and will ensure efficient data delivery architecture is consistent throughout ongoing projects. They must be proactive and comfortable supporting the data needs of multiple teams. He/she is a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoys working in a fast-paced environment. What you will take on Provide thought leadership and collaborate with other team members to continue to scale our architecture, taking into account the needs of today while remaining flexible enough to evolve for the needs of tomorrow Participate in all phases of SDLC - requirements, design, and development through testing, deployment, maintenance and support. Develop and manage stable, scalable data pipelines that cleanse, structure and integrate disparate big data sets into a readable and accessible format for end user analyses and targeting using stream and batch processing architectures. Maintain API based ETL/ELT processes from multi source raw data collection to reporting/visualization. Collaborate with Data Scientists to implement advanced analytics algorithms that exploit our rich data sets for statistical analysis, prediction, clustering and machine learning Develop data quality framework to ensure delivery of high-quality data and analyses to stakeholders. Develop and support continuous integrations build and deployment processes which use Jenkins, Docker, Git, etc. Define and implement monitoring and alerting policies for data solutions. What you bring 2+ years of professional experience in Python. 2+ years of hands-on experience in using advanced SQL queries (analytical functions), experience in writing and optimizing highly efficient SQL queries. Experience integrating with 3rd party APIs. Experience with building out an ETL pipeline. Experience of working in AWS environment highly desirable. Comfort in working with business customers to gather requirements and gain a deep understanding of varied datasets. Experienced in testing and monitoring data for anomalies and rectifying them. Knowledge of software coding practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations. Bachelor's degree or equivalent in an engineering or technical field such as Computer Science, Information Systems, Statistics, Engineering, or similar What We Offer You: Great Company Culture. Ranked as one of the most creative and innovative places to work, creativity, innovation, efficiency, diversity and philanthropy are among the core tenets of our organization and are integral drivers of our continued success. Growth: As a global entertainment company, we pride ourselves on creating environments where employees are encouraged to be themselves, to be inquisitive and collaborative and to grow within and around the company. Work Hard, Play Hard. Our employees bond, blow-off steam, and flex some creative muscles – through corporate boot camp classes, company parties, game release events, monthly socials, and team challenges. Benefits. Medical (HSA & FSA), dental, vision, 401(k) with company match, employee stock purchase plan, commuter benefits, in-house wellness program, broad learning & development opportunities, a charitable giving platform with company match and more! Perks. Fitness allowance, employee discount programs, free games & events, stocked pantries and the ability to earn up to $500+ per year for taking care of yourself and more! Take-Two Interactive Software, Inc. (""T2"") is proud to be an equal opportunity employer, which means we are committed to creating and celebrating diverse thoughts, cultures, and backgrounds throughout our organization. Employment at T2 is based on substantive ability, objective qualifications, and work ethic – not an individual's race, creed, color, religion, sex or gender, gender identity or expression, sexual orientation, national origin or ancestry, alienage or citizenship status, physical or mental disability, pregnancy, age, genetic information, veteran status, marital status, status as a victim of domestic violence or sex offenses, reproductive health decision, or any other characteristics protected by applicable law."
Data Engineer,Sanofi US,"Bridgewater, NJ+8 locations",https://www.indeed.com/rc/clk?jk=7034a933619a39f7&fccid=5d3ed74ca4598964&vjs=3,"JOB OVERVIEW: We are looking for a Data Engineer to join our digital data team in the data architecture operation and governance team to build and operationalize data pipelines necessary for the enterprise data and analytics and insights initiatives, following industry standard practices and tools. The bulk of the work would be in building, managing, and optimizing data pipelines and then moving them effectively into production for key data and analytics consumers like business/data analysts, data scientists or any persona that needs curated data for data and analytics use cases across the enterprise. In addition, guarantee compliance with data governance and data security requirements while creating, improving, and operationalizing these integrated and reusable data pipelines. The data engineer will be the key interface in operationalizing data and analytics on behalf of the business unit(s) and organizational outcomes. RESPONSIBILITIES: Must work with business team to understand requirements, and translate them into technical needs Gather and organize large and complex data assets, perform relevant analysis Ensure the quality of the data in coordination with Data Analysts and Data Scientists (peer validation) Propose and implement relevant data models for each business cases Optimize data models and workflows Communicate results and findings in a structured way Partner with Product Owner and Data Analysts to prioritize the pipeline implementation plan Partner with Data Analysts and Data scientists to design pipelines relevant for business requirements Leverage existing or create new “standard pipelines” within Sanofi to bring value through business use cases Ensure best practices in data manipulation are enforced end-to-end Actively contribute to Data governance community BASIC QUALIFICATIONS: Bachelor’s Degree in Science, Engineering, or Information Management. 3+ years working with data models and ETL functions Experience in the bio/pharmaceutical industry is a plus Fluent in English TECHNICAL SKILLS: Good knowledge of AWS/Cloud Computing (Knowledge of Azure or GCP a plus) Working knowledge of SQL and Python (Familiarity with other scripting languages a plus) Experience in ELT and ETL functions (via IICS, Databricks, Glue etc.) Good understanding of cloud database technologies Experience working with database models and query tuning SOFT SKILLS: Pragmatic and capable of solving complex issues Ability to understand business needs Good communication Push innovative solutions Service-oriented, flexible & team player Self-motivated, take initiative Attention to detail & technical intuition As a healthcare company and a vaccine manufacturer, Sanofi has an important responsibility to protect individual and public health. All US based roles require individuals to be fully vaccinated against COVID-19 as part of your job responsibilities. Sanofi Inc. and its U.S. affiliates are Equal Opportunity and Affirmative Action employers committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race; color; creed; religion; national origin; age; ancestry; nationality; marital, domestic partnership or civil union status; sex, gender, gender identity or expression; affectional or sexual orientation; disability; veteran or military status or liability for military status; domestic violence victim status; atypical cellular or blood trait; genetic information (including the refusal to submit to genetic testing) or any other characteristic protected by law. #GD-SA #LI-SA PDN At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all."
Data Engineer,Kearney & Company,"Arlington, VA",https://www.indeed.com/rc/clk?jk=c028ee42ffb9819e&fccid=19f28dc2839e6f4f&vjs=3,"Overview: Exclusively focused on the Government, Kearney & Company provides financial services, including auditing, consulting, and technology services. Our commitment to our employees and clients as well as to dedication and trust, critical values to our Firm, have led to Kearney’s recognition as one of the leading accounting firms in the country. Based on our employees’ feedback, we are also consistently rated a Best Place to Work. Employment at Kearney means a flexible, collaborative, and open-minded work environment. We hope it is your “first easy decision.” Learn more at www.kearneyco.com/careers. COVID Policy: Prospective and/or new Kearney team members will be required to comply with any Federal, State, or local guidance related to COVID-19. Although Kearney’s company policy does not mandate vaccinations at this time, Kearney will follow all guidance, which is subject to change. Client site requirements, if different or stricter, will take precedence over Kearney policy. Vaccination status must be submitted prior to first day of employment. Prospective or new team members may seek a religious or medical exemption to any current guidance applicable to Kearney that mandates vaccination during the Onboarding process. Additional questions may be directed to the Director of Human Resources (covid-19@kearneyco.com / 703-931-5600). Responsibilities: Kearney and Company is currently seeking a Data Engineer to join our Alexandria, VA team. The Data Engineer will develop pipelines for data acquisition and ingestion, enabling detailed data analytics using industry leading tools and capabilities. You will be part of a customer focused team developing productive working relationships with client personnel, delivering capabilities for the Department of Defense through agile methodology. Some on-site client support is required for this position. Responsibilities: Create and update data pipelines and conduct data ingesting operations Query, discover, export, and connect dashboards/analytic models to data provided by DoD stakeholders Develop and translate functional data requirements to assemble datasets and program related business logic Ensure the data catalog is updated with metadata related to new data being ingested. Maintain relationships and communicate with key client personnel to understand business operations, processes, and functions Develop and run reconciliation scripts to support customer data and use cases Adhere to management’s Agile Development process, including using JIRA and Slack daily Present progress to senior stakeholders Balance multiple projects concurrently Qualifications: Required Qualifications: BA, BS or BBA degree in mathematics, engineering, computer science, or related area Must have at least an active secret clearance Prior experience as a data engineer, data architect, or data scientist Experience with using Databricks to perform data transformations or modeling (including Databricks SQL and Delta Lake) Intermediate knowledge of SQL and Python Experience working with Accounting and Financial Management Data Experience independently evaluating controls over security processes, infrastructure, network, applications and databases Preferred Qualifications: Data engineer or data architect certification: Amazon Web Services (AWS) Certified Data Analytics – Specialty, or other related designation preferred Experience with StreamSets Understanding of DoD Financial Management Systems Experience with PySpark Experience with bash scripting Experience with ini/cfg configuration files EEO Notice: Applicants have rights under Federal Employment Laws EEO Notice Work location is subject to change based on client requirements. Kearney & Company is an Equal Opportunity Employer and will consider all qualified applicants without regard to race, color, creed, genetic information, religion, national origin, ethnicity, gender; gender identity, sexual orientation, pregnancy, childbirth or related medical condition, age, disability or handicap, servicemember status, relationship or association with a protected veteran, and any other category protected by Federal, state, or local law. Click here to learn more. If you would like to request a reasonable accommodation, regarding accessibility of our website, a modification or adjustment of the job application or interview process due to a disability, please call 703-236-2391 or email accommodations@kearneyco.com. Please be advised that this contact information is for accommodation requests only and cannot be used to inquire about the status of an application. Family and Medical Leave Act (FMLA) FMLA is designed to help employees balance their work and family responsibilities by allowing them to take reasonable unpaid leave for certain family and medical reasons. Kearney & Company provides eligible employees with up to 12 weeks of unpaid, job-protected leave per year. Military family leave is available for up to 26 weeks under FMLA. Click here to learn more. Employee Polygraph Protection Act (EPPA) The EPPA prohibits most private employers from using lie detector tests either for pre-employment screening or during the course of employment. Kearney & Company adheres all provisions of the EPPA. Click here to learn more."
Sr Data Engineer,Express,"Columbus, OH 43230",https://www.indeed.com/rc/clk?jk=63f8566e69f2a270&fccid=0fa1d6f1f7b2b6a5&vjs=3,"Overview: Grounded in versatility and powered by a styling community, Express is a modern, multichannel apparel and accessories brand whose purpose is to Create Confidence & Inspire Self-Expression. Launched in 1980 with the idea that style, quality and value should all be found in one place, Express has been a part of some of the most important and culture-defining fashion trends. The Express Edit design philosophy ensures that the brand is always ‘of the now’ so people can get dressed for every day and any occasion knowing that Express can help them look the way they want to look and feel the way they want to feel. The Company operates over 500 retail and outlet stores in the United States and Puerto Rico, the express.com online store and the Express mobile app. Express, Inc. is comprised of the brands Express and UpWest, and is traded on the NYSE under the symbol EXPR. For more information, please visit www.express.com. Responsibilities: Express has an exciting opportunity for a curious, motivated, forward thinking, analytical software senior data engineer to join and shape the future of the Enterprise Data team for the Enterprise Data department. The Sr. Data Engineer will work on developing exciting solutions on a day-to-day basis. Through developing these solutions, you will help drive foundational transformation in the Enterprise Data organization. Responsibilities: Learning agility – growth mindset and eager to explore the unknown and learn new concepts Develops, tests, debugs and implements new/existing data solutions, which includes technologies such as Python, Scala, Spark and other technologies Immediate response to critical batch interruptions and production incidents to quickly identify and mitigate issues, with follow up to automate with self-healing code Participation in an on-call rotation to deliver 24/7 system uptime and immediate issue mitigation as the first line of defense against system interruptions, including escalation to second line support as appropriate Passionate about problem solving – relentless, enthusiastic pursuit of solutions to challenges ranging from basic day to day incidents to complex, multi-system, integrated puzzles involving code and data components Spreading a culture of collaboration, modern automation thinking, and a solution-oriented mindset Partnering with data and application development teams to identify opportunities for process refinement and standards improvement Building data solutions with Scala, SQL, BASH, and other technologies Monitors, analyzes, reports and troubleshoots the existing big data platform Work with your supervisor and business partners on identifying priority, dependencies, and conflict resolution First-tier support for enterprise data and marketing technology including production job monitoring and troubleshooting Triage of production issues including mitigation of incidents, data collisions, and job failures Creation and execution of runbooks to resolve issues Escalation to second-tier support for complex issues as needed Identification of candidate processes to automate and improve Cross-team collaboration including technical data and applications teams Championing Data Integrity as a culture and educating developers on processes to build support within the department Identification of and advocacy for resolution of accumulated technical debt Document ETL processes and flows. Required Experience: Bachelor's Degree in IT or an equivalent combination of course work and experience 3-5 years of experience working in/with software development 3-5 years of experience with Hive, BigQuery, Scala, Spark, Python, Java, Enterprise Scheduling tools 3-5 years of experience with Cloud Computing 3-5 years of experience with *nix environments including scripting and system administration 3-5 years of experience working SQL or NoSQL databases including writing and debugging complex queries Outstanding analytical skills and passionate about problem solving with a positive attitude Familiarity with data needs, integration and governance across a global organization at a meta-data level Familiarity with the areas and concepts in Master Data Management, Data Warehousing, Analytics, ERP, and CRM Embraces both change and challenge as opportunity – views complexity as puzzle games and enjoys troubleshooting multi-variate problems Dependable and reliable for production support rotations including on-call duties and 24-7 support of critical enterprise jobs and data flows Experience with enterprise workload automation and job scheduling tools such as Control-M, JAMS, CA Workload Automation, Tidal Enterprise Scheduler, or similar Excels in a fast-paced environment, comfortable navigating through ambiguity, thrives under pressure Ability to multitask and manage multiple priorities effectively Retail industry experience preferred but not required Hands-on experience with cloud computing, preferably Google Cloud Platform Familiarity with repository/build/deployment tools Critical Skills & Attributes: Excels in a fast-paced environment, comfortable navigating through ambiguity, thrives under pressure Ability to multitask and manage multiple priorities effectively Outstanding analytical skills and passionate about problem solving with a positive attitude Embraces both change and challenge as opportunity – views complexity as puzzle games and enjoys troubleshooting multi-variate problems Dependable and reliable for production support rotations including on-call duties and 24-7 support of critical enterprise jobs and data flows Closing: As an equal opportunity employer, Express does not discriminate in hiring or terms and conditions of employment on the basis of any federal, state, or locally protected class. Express only hires individuals authorized for employment in the United States. Notification to Agencies: Please note that Express does not accept unsolicited resumes or calls from third-party recruiters or employment agencies. In the absence of a signed Master Service Agreement and approval from HR to submit resumes for a specific requisition, Express will not consider or approve payment to any third-parties for hires made."
Data Engineer,AllianceChicago,"Chicago, IL 60654 (River North area)",https://www.indeed.com/rc/clk?jk=27c670baf217fcf0&fccid=f856f2ece3a525f4&vjs=3,"Job Title: Data Engineer Job Title: Deputy Director/Chief Informatics Officer Location: Chicago Location: Yes Level/Salary Range: DOE Level/Salary Range: Exempt HR Contact: Claudria Hurt Posting Date: 5/23/2022 External Posting URL: Applications Accepted By: Email: careers@alliancechicago.org or Fax: 312.274.0069 Subject Line: Data Engineer Job Description: Position Overview: Responsible for building out and migrating the AllianceChicago data warehouse to the Health Catalyst platform, and then expanding and maintaining the warehouse. This position has primary responsibility for the extraction of health information from diverse clinical and business sources and its transformation into objects in a standardized data model. These objects will be the primary source for quality and performance reporting activities for AllianceChicago, its members, stakeholders and user community or primary care delivery sites. The platform also supports research and grant reporting needs, queries for public health surveillance, and other deliverables. The data extraction work involves design, construction, and maintenance of modules using the Health Catalyst toolset. The work provides the data for analysists and presentation specialists working in Power BI, SQL, SSRS, Excel and Health Catalyst presentation tools, and benefits from familiarity with these technologies. Overall the position contributes to the design, build, testing, and maintenance of the AllianceChicago’s data warehouse. Essential Duties: Overseeing the initial load to Health Catalyst data lake, a process that will be staffed by Health Catalyst Working with AllianceChicago subject matter experts to design the rules to transform data lake data into standardized models of health data (Health Catalysts DOS environment) including encounters, problems, screenings, interventions, tests, and medications Acquiring from Health Catalyst the knowledge to implement the design of the data model Manage the transition and go-live from the current data warehouse environment based on Microsoft APS/PDW and SSIS extraction to the Health Catalyst environment Maintenance of the extract and transformation process Supports Alliance SQL query analysts, report writers and Alliance partners who perform data analysis from the DOS model or the data lake Works with query writers and report designers to resolves data issues with current reports. Is a member of the Alliance Data Warehouse team, and works collaboratively with its members and other stakeholders Oversees bringing new source systems into the Catalyst’s Data Operating System Ability to dig into the data and understand business logic within the source system data Perform data validation tests to ensure extractions and transformations are true to the source Required Skills: Intermediate to advanced level in Structured Query Language (SQL) Experience working with EMR\EHR systems and an understanding of the healthcare clinical domain Exposure to Extract, Transform and Load (ETL) concepts and processes Excellent analytical and troubleshooting skills Working knowledge of database principles, processes, technologies and tools Other Requirements: Flexibility and ability to work with individuals of diverse backgrounds and educational levels Ability to function in a collaborative and collegial environment as a team player. Ability to coordinate and communicate effectively with other team members Ability to generate trust and build alliances with coworkers Self-motivated; comfortable working under general direction Strong sense of customer service to consistently and effectively address client needs Ability to work in variety of settings Detail oriented; highly organized; ability to prioritize and set expectations Strong technical writing skills and written communications skills Strong Analytical skills Ability to work independently to organize work in a manner that ensures accuracy and efficiency Familiarity with agile development process. Education: Bachelor Level preparation in computer, mathematical, information sciences or equivalent training – Master Level Preferred Experience/Years: At least three years of experience with Microsoft SQL Server 2008 or higher including SSIS and SSAS, and familiarity with the MS BI stack. Familiarity with other data, analytic and reporting tools 5-8 years of experience in computer science or information science related field Experience with Relational Databases and data mining Computer simulation and modeling of workflows a plus Working Conditions: General office setting, extensive telephone and desk work at computer terminal May be required to lift, carry, bend, reach and stand with parcels up to 25 lbs. Will work in a close multidisciplinary team environment May interface with clients in various settings and may be working during on-site visits in clinical environments where medical equipment, chemicals and where communicable diseases and certain pathogens are present. ORGANIZATIONAL OVERVIEW: Founded by four partner Community Health Centers in 1997, AllianceChicago’s three core areas of focus are Health Care Collaboration, Health Information Technology, and Health Research & Education. AllianceChicago supports the use of HIT to improve quality, efficiency, and access to services in a national network of community Safety Net health care organizations. The mission of AllianceChicago is to improve personal, community, and public health through innovative collaboration. ADA Statement: The Americans with Disabilities Act prohibits discrimination and ensures equal opportunity for persons with disabilities in employment, state and local government services, public accommodations, commercial facilities, and transportation. It also mandates the establishment of TDD/telephone relay services. EEO Statement: AllianceChicago believes that all applicants and employees are entitled to equal employment opportunities and maintains a policy of non‐discrimination with respect to religion, color, sex, sexual orientation, national origin, age, veteran status, marital status, physical or mental disability, or any other legally protected class in accordance with applicable law, except where a bona fide occupational qualification exists. AllianceChicago will comply with all phases of employment including, but not limited to, hiring practices, transfers, promotions, benefits, discipline, and discharge. Disclaimer: The above statements are intended to describe the general nature and level of work being performed by employees assigned to this position. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel as qualified."
Data Engineer,Doximity,"Remote in Augusta, GA+1 location",https://www.indeed.com/rc/clk?jk=c4887df533bb44a4&fccid=cc9f04eed69b86b2&vjs=3,"Doximity is transforming the healthcare industry. Join our mission to help every physician be more productive and provide better care for their patients. As medicine's largest network in the United States, there's an elevated level of responsibility in everything we do. We don't take that responsibility lightly and are committed to building diverse teams with an inclusive culture that can make a direct impact on the healthcare system. One of Doximity's core values is stretching ourselves. Even if you don't check off all the boxes below we encourage you to apply. Doximity is full of exceptional people who bring their own unique experiences to work everyday and make us all better for it! This role can be filled in our San Francisco headquarters OR remotely in the U.S. About you You have professional experience developing data processing, enrichment, transformation, and integration solutions. You are fluent in Python and SQL. You are no stranger to data warehousing and designing data models. You are foremost an engineer, making you passionate for high code quality, automated testing, design patterns, and other engineering best practices. You care deeply about the data being generated. You study the data and extract insights from it before you process it. You are user experience and product focused. You build solutions while thinking about the impact it has on our users and enhances the product. You are able to work within an existing data architecture finding gaps in it and enhancing it to ensure solutions are fault tolerant, scalable, and easy to iterate upon. You have the ability to self-manage, prioritize, and deliver functional solutions. You can see a project from end-to-end, from idea generation, planning, execution through delivering. You agree that concise and effective written and verbal communication is a must for a successful team. Here's How You Will Make an Impact Collaborate with product managers, data analysts, and machine learning engineers to develop pipelines and ETL tasks in order to facilitate the extraction of insights. Build, maintain, and scale data pipelines that empower Doximity's products. Establish data architecture processes and practices that can be scheduled, automated, replicated and serve as standards for other teams to leverage. Work alongside others in planning and carrying out the implementation of solutions that are focused on enhancing products, leading one or two projects at any given time. About Us Explore our stack We have over 500 private repositories in Github containing our pipelines, our own internal multi-functional tools, and open-source projects We have worked as a distributed team for a long time; we're currently about 65% distributed Find out more information on the Doximity engineering blog Our company core values Our recruiting process Our product development cycle Our on-boarding & mentorship process Benefits & Perks Generous time off policy Comprehensive benefits including medical, vision, dental, Life/ADD, 401k, flex spending accounts, commuter benefits, equipment budget, educational resources and conference access Family support and planning benefits Stock incentives .. and much more! For a full list, see our career page More info on Doximity For the past decade, it's been our mission to help every physician be more productive so they can provide better care for their patients. We believe that when doctors are connected, the healthcare system works better and patients benefit. Doximity enables our verified clinician members to collaborate with colleagues, stay up-to-date with the latest medical news and research, manage their careers, and conduct virtual patient visits. Today, Doximity is the leading digital platform for U.S. medical professionals, with over 80% of physicians, 50% of all nurse practitioners and physician assistants, and 90% of graduating medical students as members. Joining Doximity means being part of an incredibly talented and humble team passionate about improving inefficiencies in our $4.3 trillion U.S. healthcare system. We are a team of doers who solve problems everyday by treating obstacles like an adventure, and we love creating technology that has a real, meaningful impact on people's lives. Doxers are committed to working towards a more equitable world both within and beyond our office walls. This starts by fostering an inclusive and diverse work environment where differences are valued and all employees are encouraged to bring their full, authentic selves to work daily. To learn more about our team, culture, and users, check out our careers page, company blog, and engineering blog. We're growing fast, and there's plenty of opportunity for you to make an impact—join us! For more information, visit Doximity.com. ____________________________________________ EEOC Statement Doximity is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law."
Backend Data Software Engineer,NetApp,"Atlanta, GA",https://www.indeed.com/rc/clk?jk=f2da928820531acc&fccid=77cec2f25f9bd7ed&vjs=3,"Job Summary Responsible for delivering an enterprise class NetApp software product. Software Engineer thrives as part of a high-performance team tasked with finding creative solutions to the most profound data challenges customers face. Wielding cutting-edge technologies, you help create new products and services that bring NetApp’s data fabric to every application, anywhere. Job Requirements Deliver reliable, innovative storage and data management products. Develops, modifies, and executes automated software test plans. Analyzes and writes test standards and procedures. Maintains documentation of results Works closely with development engineers in feature development and resolution of problems. Analyze problems and apply to proper test tools and methods to create opportunities to contribute clean code Improve productivity by refactoring and improving existing tools and workflows. Education IC - Typically requires a minimum of 8 years of related experience.Mgr & Exec - Typically requires a minimum of 6 years of related experience."
"The Carter Center: Data Engineer, IT",Emory University,"Temporarily Remote in Atlanta, GA 30307+1 location",https://www.indeed.com/rc/clk?jk=4ef0f466c5215456&fccid=efe5e2d22a1d29e5&vjs=3,"Discover Your Career at Emory University: Emory University is a leading research university that fosters excellence and attracts world-class talent to innovate today and prepare leaders for the future. We welcome candidates who can contribute to the diversity and excellence of our academic community. Description: The Carter Center is a 501(c)(3), not-for-profit, nongovernmental organization founded in 1982 in Atlanta, GA, by former U.S. President Jimmy Carter and his wife, Rosalynn, in partnership with Emory University. The Center has helped to improve millions of lives in more than 80 countries by waging peace, fighting disease, and building hope. The Carter Center is guided by a fundamental commitment to human rights and the alleviation of human suffering. It seeks to prevent and resolve conflicts, enhance freedom and democracy, and improve health. The Carter Center collaborates with other organizations, public and private, in carrying out its mission around the world. Current information about the Center’s many programs and activities are available at The Carter Center. DESCRIPTION: The Data Engineer is responsible for architecting, building, and maintaining the Azure-based data and analytics platforms at The Carter Center (TCC). Works with TCC staff to elicit requirements, analyze raw data sources and, using code and tools, build analytical databases and operationalize the stream of data from the raw data sources to these databases. Supports global staff with their analytical needs. FORMAL JOB DESCRIPTION: Remains up-to-date on new data features of Azure as they become available. Continuously reviews, analyzes, monitors, and improves the data environment, its performance, and security. May assist with training of global staff. Prepares documentation and diagrams of the environment to ensure records of work are maintained. May be responsible for supervising contractors or interns. Ensures compliance with all organizational policies and procedures. Maintains professional growth and development of self by identifying educational/training programs, professional organizations, activities, and resources to maintain knowledge of national trends and to promote leading edge expertise. Performs related responsibilities as required. MINIMUM QUALIFICATIONS: A bachelor's degree in computer science, information systems, or related field and four years of technical applications or IT experience, OR an equivalent combination of education, training, and experience. PREFERRED QUALIFICATIONS: Prefer a strong understanding of Microsoft Data ecosystem (DataBricks, DataFactory, Data Lakes, etc.). Experience with a variety of SQL databases. Demonstrated competency with PowerBI and ArcGIS. Demonstrated competency with data modeling and SQL. Experience with R or Python. Experience with managing projects. Experience with non-relational (graph) databases is a plus. Experience with machine learning is a plus. Applicant must be currently authorized to work in the United States for any employer. NOTE: This role will be granted the opportunity to work from home temporarily during the COVID-19 pandemic, with intent to return to an Emory University location in the future. Emory reserves the right to change remote work status with notice to employee. #LI-EMORY002 Emory Supports a Diverse and Inclusive Culture: To ensure the safety of our campus community, the COVID-19 vaccine is required. For more information on the University and Hospital policies and potential exemptions, please see our website. Emory University is dedicated to providing equal opportunities and equal access to all individuals regardless of race, color, religion, ethnic or national origin, gender, genetic information, age, disability, sexual orientation, gender identity, gender expression, and veteran's status. Emory University does not discriminate in admissions, educational programs, or employment on the basis of any factor stated above or prohibited under applicable law. Students, faculty, and staff are assured of participation in University programs and in the use of facilities without such discrimination. Emory University complies with Executive Order 11246, as amended, Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veteran's Readjustment Assistance Act, and applicable executive orders, federal and state regulations regarding nondiscrimination, equal opportunity and affirmative action. Emory University is committed to achieving a diverse workforce through application of its affirmative action, equal opportunity and nondiscrimination policy in all aspects of employment including recruitment, hiring, promotions, transfers, discipline, terminations, wage and salary administration, benefits, and training. Inquiries regarding this policy should be directed to the Emory University Department of Equity and Inclusion, 201 Dowman Drive, Administration Building, Atlanta, GA 30322. Emory University is committed to providing reasonable accommodations to qualified individuals with disabilities upon request. To request this document in an alternate format or to request a reasonable accommodation, please contact the Department of Accessibility Services at 404-727-9877 (V) | 404-712-2049 (TDD). Please note that one week advance notice is preferred."
Senior Data Engineer,Lytx,"San Diego, CA",https://www.indeed.com/rc/clk?jk=787a77c1cca95d3e&fccid=9dc9353c3df3e327&vjs=3,"Summary of Duties: Provide senior-level contributions to the development teams responsible for implementing mission critical data applications. Participate in the full software development lifecycle (requirements, design, code, unit test, deployment, sustaining). Develop and manage steaming data pipelines used for training and developing machine learning models. Participate in the research, design, and testing of next generation data engine platforms. Develop and guide long-term strategy for data pipelines and persistent data storage. Evaluate and recommend database infrastructure and tools including cloud technologies. Build integrated and automated data pipelines using the Hadoop Ecosystem (Spark, Kafka, Hive, Yarn, Oozie). Develop efficient and effective T-SQL to extract, transform, and load data from source systems. Process documentation and data flow diagraming. Mentor and coach junior engineers, software developers, and data analysts. Qualifications: Position requires a Bachelor’s degree in Computer Science, Information Technology, or a closely related field of study plus five (5) years experience in the job offered or as a Data Engineer, Software Engineer, Technical Lead, Programmer Analyst, or related role in Data Engineering or Software Development. Position requires five (5) years of experience in Data Engineering or Software Development. Three (3) years of experience with the following: Apache Hadoop Ecosystem; MS SQL Server or other RDBMS. Significant experience with Spark, Kafka, Nifi, and other streaming data tools. Strong knowledge of the Hadoop Ecosystem including HDFS, MapReduce, Sqoop, Yarn, Hive, and Oozie. Solid understanding of T-SQL and ETL programming including SQL Server Integration Services (SSIS). Extensive knowledge of common data warehousing technologies and techniques. Familiarity with the following: Java programming; cloud data offerings (AWS, GCP, Snowflake); Greenplum. #LI-DNI Innovation Lives Here You go all in no matter what you do, and so do we. At Lytx, we’re powered by cutting-edge technology and Happy People. You want your work to make a positive impact in the world, and that’s what we do. Join our diverse team of hungry, humble and capable people united to make a difference. Together, we help save lives on our roadways. Find out how good it feels to be a part of an inclusive, collaborative team. We’re committed to delivering an environment where everyone feels valued, included and supported to do their best work and share their voices. Lytx, Inc. is proud to be an equal opportunity/affirmative action employer and maintains a drug-free workplace. We’re committed to attracting, retaining and maximizing the performance of a diverse and inclusive workforce. EOE/M/F/Disabled/Vet."
"Product Success, Data Engineer",Datavant,"Remote in Austin, TX",https://www.indeed.com/rc/clk?jk=bb5b4d5ec47205ea&fccid=7a310f14def4cec8&vjs=3,"Datavant is a rapidly growing healthcare technology company with a mission to connect the world's health data. By eliminating data silos in the healthcare industry, we aim to unlock opportunities to accelerate medical research, and help organizations design better ways to facilitate access, affordability, and quality of care leading to better patient outcomes. By joining Datavant today, you're stepping onto a highly collaborative, fully remote team that is passionate about creating transformative change in healthcare. We look for people who are smart, nice and get things done. We invest in our people and believe in hiring for high-potential and humble individuals who can rapidly grow their responsibilities as the company scales. Datavant is a distributed, remote-first team (no office locations) and we empower Datavanters to shape their working environment in a way that suits their needs - learn more here! As a member of the Data Operations team, you'll own a wide range of customer-related data work, including end-to-end client queries, scripting ad-hoc workflows, and automating processes wherever possible. You'll also work closely with the Product Success, Engineering, Product, and Data Science teams to improve our product and build tools that will help each department make data driven decisions. Your work will be critical to growing our business and solidifying ourselves as the market leaders in health data connectivity. You Will: Own all non-productized data workflows, querying Snowflake databases to support customer and internal requests, and supporting design of scalable processes that automate repeated tasks. Work closely with the Product team to provide feedback on new and existing features, surface opportunities for automation of existing processes, and help guide the product roadmap. Guide clients in preparing and onboarding their datasets to the Datavant Portal, own end to end fulfillment of client requests, data extracts, and generate aggregate statistics. Conduct internal research to scope and develop reporting dashboards used by each department to inform data driven decisions. Query customer data to perform novel analytics that are published to blogs, whitepapers, and academic publications/conferences to illustrate the value of our sources in analytics Identify team areas for growth and own process improvement to help shape the future of the Data Ops team What You Will Bring to the Table: Background in computer science and/or healthcare Familiarity with health data or desire to learn Experience working with large datasets & data pipelines Extremely strong SQL skills, Python a plus Comfortable with cloud services and building dashboards Comfortable with working from the command line High-organization and able to handle quick turnaround times with multiple stakeholders Driven, entrepreneurial, startup-ready We are committed to building a diverse team of Datavanters who are smart, nice, and get things done where every Datavanter is empowered to bring their authentic self to their work. We are all responsible for stewarding a high-performance culture in which all Datavanters belong and thrive. We are proud to be an equal opportunity employer and welcome applications from people of all backgrounds and experiences. At the end of this application, you will find a set of voluntary demographic questions. If you choose to respond, your responses will be used to help us identify areas of improvement in our recruitment process. We can only see aggregate responses and are unable to view individual responses. In fact, we aren't even able to see if you've responded or not! Responding is your choice and it will not be used in any way in our hiring process."
Data Engineer - Digital Services,Siemens,"Chicago, IL+12 locations",https://www.indeed.com/rc/clk?jk=abf9559592c2c425&fccid=ea6bb53f0b18b8f2&vjs=3,"Who we are | Our culture: Siemens Smart Infrastructure (SI) is shaping the market for intelligent, adaptive infrastructure for today and the future. It addresses the pressing challenges of urbanization and climate change by connecting energy systems, buildings, and industries. SI provides customers with a comprehensive end-to-end portfolio from a single source – with products, systems, solutions, and services from the point of power generation all the way to consumption. With an increasingly digitalized ecosystem, it helps customers thrive and communities progress while contributing toward protecting the planet. SI creates environments that care. Siemens Smart Infrastructure has its global headquarters in Zug, Switzerland, and has around 71,000 employees worldwide What does a Data Engineer do, you ask? Buildings generate almost 40% of global CO2 emissions worldwide and at Siemens SI we aim to change this by dramatically reducing the energy use and maintenance costs of buildings. To achieve this at scale, we need to deal with high volumes of data coming from diverse IoT environments. We seek a dedicated and enthusiastic data engineer to join a global team with a data and machine learning focus. You will design and deploy pipelines to deliver the data needed for machine learning models and connect the results to consuming applications. You will collaborate with other development teams and domain experts to ensure the right data is flowing to the right place. We foster an ownership culture, in which every employee takes personal responsibility for our company's success. We trust and empower our leaders to act as owners, advise their teams, and innovate to succeed. We communicate openly and honestly to learn from our failures and celebrate our successes. We recognize individual and team achievements frequently. We invest in our team members, offering a wide variety of internal and external development opportunities. Responsibilities: Define data requirements from IoT sources and other applications. Negotiate interfaces between applications. Design and deploy data pipelines and other data infrastructure. Monitor, maintain, and update deployed pipelines. Optimize data tools and automate data science workflows. Ability to travel globally for this position. Lives and promotes Siemens Values. Qualifications: Bachelor’s degree or Master’s degree required, PhD preferred 3+ of hands-on experience in working with data at scale Clear communication skills and ability to define technical requirements Programming (Java, C#, Python, etc.) Infrastructure as code (AWS) Distributed computing (Spark) Streaming data (Kafka) SQL REST / OpenAPI Docker Git CI/CD Additionally, knowledge of building automation and HVAC systems would be an advantage. Join us! Together we can build a better future for our world. We’ve got quite a lot to offer. How about you? Benefits: Competitive salary based on qualifications Health, dental, and vision plans with options Competitive paid time off plan, holidays, and floating holidays Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, creed, religion, ancestry, national origin, sex, sexual orientation, gender identity, age, marital status, family responsibilities, pregnancy, genetic information, domestic partner status, disability, weight, height or AIDS/HIV status, protected veteran or military status, other categories protected by federal, state, or local law, and regardless of whether the qualified applicants are individuals with disabilities. Organization: Smart Infrastructure Company: Siemens Industry, Inc. Experience Level: Experienced Professional Job Type: Full-time Equal Employment Opportunity Statement Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law. EEO is the Law Applicants and employees are protected under Federal law from discrimination. To learn more, Click here. Pay Transparency Non-Discrimination Provision Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here. California Privacy Notice California residents have the right to receive additional notices about their personal information. To learn more, click here."
"Data Engineer, Zoro",Zoro Tools,Illinois+1 location,https://www.indeed.com/rc/clk?jk=298f3f4cbb005490&fccid=80bd79d813274903&vjs=3,"Company Summary: Zoro offers millions and millions of products — an endless aisle with everything you need to run your business. We offer fast and free shipping, no-hassle returns, and exceptional customer service. We’ve grown quickly in a short time and are continuing to do so while aggressively growing our revenue. We are excited to be a part of an award-winning culture — we have been named a Great Place to Work for multiple years in a row, among other local and national accolades. We think Zoro is a pretty amazing place to work and grow, and think you will too! Primary Function: As a Data Engineer at Zoro you will be involved in designing and building cloud native data pipelines on a scrum squad. You will be responsible for collaborating with stakeholders on work items to deliver tested, documented, and efficient data pipelines. Your day to day activities will include participating in: cadence meetings. technical debt working sessions. pairing sessions. master data management initiatives. data pipeline support. Duties and Responsibilities: Follow software craftsmanship and Zoro norms to design, develop, document, deploy, and maintain data pipelines. Collect, analyze, and profile various batch and streaming data sources. Participate in master data management efforts within the squad and tribe. Participate in guild and chapter meetings. Collaborate with stakeholders to groom ideas into small, independent, and testable work items. Collaborate with DataOps to automate code analysis, testing, building, and deploying. Collaborate with the squad and tribe to groom technical debt. Qualifications: Strong experience with RDBMS, No-SQL DBs, data modeling, and ETL/ELT processes. Strong experience with Python and SQL, with focus on data manipulation and analysis. Strong experience with building, deploying, and maintaining data pipelines. Strong experience with sourcing and profiling highly variable data. Strong experience in software craftsmanship, behavior-driven development (BDD), and unit testing. Strong people skills, must be able to form strong, meaningful, and lasting collaborative relationships. Moderate experience with collaborating on scrum squads with preference for experience with Large Scale Scrum (LeSS). Moderate experience with cloud infrastructure services with preference for experience with Google Cloud Platform (GCP). Moderate experience with MongoDB, BigQuery, Jira, Git, Kubernetes, Jenkins, Terraform, GCP Deployment Manager, Apache Airflow, Apache Beam, and Apache Spark. Bachelor's degree in Computer Science, Applied Mathematics, Engineering, or other technology related field. An equivalent of this educational requirement in working experience is also acceptable. Zoro Values and Inclusive Culture: We share a commitment to our Zoro values – Win & Lose Together (We prefer winning!), Take Ownership, We Are Transparent, and Aspire to be Customer-Obsessed. Everything we do at Zoro is centered around delighting our customers. It's a natural extension of our company culture and how we care for each other. We believe when we act in ways that are consistent with these values, we can solve any technical challenge that lies ahead of us. As a Zoro employee, you can expect to work with smart, energetic people, learn something every day, and be valued for your perspective. Zoro is dedicated to fostering an environment where people of all backgrounds and beliefs are represented, and all team members can be confident that their experiences and perspectives are valued. Zoro aims to empower all employees to learn about, raise awareness, and promote diversity and inclusion through all of our workplace interactions. Zoro is a place where everyone can learn, grow and thrive. We recognize the courage and effort it takes to apply for your next opportunity. We also recognize that there is rarely such a thing as a perfect candidate. Even if you do not meet every qualification, we still encourage you to apply - we do not want to miss out on meeting the next person who could emerge as a key contributor to our business and culture. Zoro is an Equal Opportunity Workplace and an Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status."
Data Engineer (Remote),Integrated Data Services Inc.,Remote,https://www.indeed.com/rc/clk?jk=5bbe44860fcdab5e&fccid=b76b036af0110be7&vjs=3,"Company Overview: Integrated Data Services (IDS) is a leading provider of custom software products and Government financial management services. IDS was founded in 1997 in El Segundo, CA, and since that time has seen tremendous growth and success. Currently IDS has offices supporting customers nationwide. By providing customers with fast, efficient and reliable information systems and support services, IDS has become a preferred provider of financial and programmatic systems, services, and solutions across a wide variety of government agencies. Position Description: IDS is seeking a Data Engineer with expertise in data modeling, data warehousing, data governance, data integration, data analytics and data visualizations. This position will support, enhance and streamline existing data integration processes. This position will architect how structured and unstructured data will be stored, consumed, integrated and reported by different systems across internal and external data sources. This position will work towards building an enterprise model, a central dictionary of common business vocabulary, define approach & principles for data quality management, master data management, data integration, data security/access and data archiving & retention. In this role the person is also expected to be well versed in creating/maintaining/reverse engineering data models that enable the understanding and documentation of data standards, metadata and entity & domain relationships and the flow of data across business applications. We are looking for an ambitious self-starter with proven technical and analytical capabilities and the tenacity to develop ideas independently and thrive in a fast-paced environment. This role is for a technologist who loves to roll up their sleeves, dive in, and tackle any problem with speed and precision. Responsibilities include, but are not limited to, the following: Engineer and implement extract, transform and load (ETL) processes using Talend and PL/SQL. Define the strategy and architecture required to integrate data across multiple systems, improve the existing data warehouse architecture and support our transition to AWS. Implement and optimize physical database design to support performance, scaling, security, backup, and disaster recovery requirements. Uses industry and domain best practices and methodologies to implement Data Governance, Master Data Management (MDM), Business Intelligence and Data Analytics. Creates and enforces technology-specific guidelines, standards, policies and procedures Work closely with application developers and data analysts to design and optimize data access, query, reporting, and analysis strategies. Lead, Mentors, coaches and educates team members in standard processes, policies and procedures related to a specific technology. Communicates with the Product Management and development teams to raise issues and identify potential barriers in a timely fashion. Knowledge and Skills: At least 5 years of experience as a data engineer or architect. At least 5 years of experience developing ETL or ELT solutions. At least 5 years of experience with Oracle SQL and PL/SQL. Experience with Data Governance and Master Data Management (MDM) concepts and tooling Experience with data modeling tools in creating medium to large-scale enterprise logical data models using normalization techniques Experience in Business Intelligence (BI) and Data Warehouse enterprise platforms Experience with Department of Defense (DoD) finance, contracting, acquisition or logistics systems. Ability to interface effectively with team members from all functional disciplines. Exceptional problem-solving skills and the ability to rapidly analyze complex technology and business scenarios. Experience working with Talend Data Integration desired. Experience with Qlik Sense desired Experience with AWS and Amazon S3 desired. Experience with MS Office (Word, Excel, PowerPoint), Atlassian JIRA and Confluence desired. Applicants selected for employment may be subject to a Federal background investigation and may need to meet additional eligibility requirements for access to classified information or materials. Education and Work Experience: This position requires a minimum of a Bachelor's degree from an accredited college or university in business management, engineering, computer science, mathematics, accounting, economics or other related discipline. Experience in lieu of education may be considered if the individual has seven (7) or more years of relevant experience. Physical & Mental Qualifications: Must be able to sit, type, hear, see, and speak for extended periods of time. Must consistently work and type on a computer for prolonged periods of time. Must be able to able to communicate accurate information and ideas so others will understand. Must be able to lift/carry at least 15 lbs. May be required to move about inside an office to access file cabinets, office supplies, etc. Security Clearance: Applicants selected for employment may be subject to a Federal background investigation and must meet additional eligibility requirements for access to classified information or materials. Travel: Some travel may be required. Hours: Normal work schedule hours may vary, Monday through Friday. May be required to work additional hours and/or weekends, as needed, to meet deadlines or to fulfill travel obligations. Salary Range: Commensurate with experience. IDS offers a robust benefits package including employer paid health, dental, vision, disability, AD&D and life insurance plans. IDS also offers a variety of elective plans including flexible spending accounts, voluntary life insurance, and supplemental insurance plans. Employee benefits become effective the first of the month following start date of employment unless starting on the 1st of the month. IDS offers generous PTO accruals as well as a 401(k) 3% safe harbor contribution upon eligibility. IDS also offers generous employee referral bonuses. IDS is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regards to race, creed, age, sex, gender, physical or mental disability, sexual orientation, gender identity, gender expression, ancestry, pregnancy, perceived pregnancy, medical condition, marital status, familial status, color, religion, uniformed services, veteran status, national origin, genetic information, or any other characteristic protected under local, state or Federal law. A submission of a resume is an expression of interest and not considered an application. For more information, visit www.get-integrated.com. **U.S. citizenship is required; H1-B visas and other visas are not being sponsored. Relocation expenses are NOT compensated. All jobs are employer paid; no fees to candidates. Third parties or agencies inquiries are not being accepted.** This role can be performed remotely anywhere in the United States with the exception of Colorado. #IDS"
Data Science Senior Analyst – Machine Learning Engineer,Dell Technologies,Texas,https://www.indeed.com/rc/clk?jk=719eb4b64c6246ff&fccid=dd09fe3b43125016&vjs=3,"Data Science Senior Analyst – Machine Learning Engineer Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods and models. What’s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data. Join us to do the best work of your career and make a profound social impact as a Senior Analyst on our Data Science Machine Learning Engineering team in Round Rock, Texas. What you’ll achieve As a Machine Learning Engineer, you will be responsible for partnering with Data Scientists to automate workbook deployment onto machine learning platforms. Platforms you will work with include Microsoft Azure and Dell’s AI Accelerator. You will also be responsible for application deployment and virtualization. You will work with the Services Digitization, Intelligence, and Transformation team on multiple digital transformation and business automation projects. You will: Work with Data Scientists to deploy Jupyter Notebooks onto various Machine Learning platforms Deploy technology such as Docker, Kubernetes, or other container orchestration systems to automate deployment and scaling Collaborate with additional Machine Learning teams to determine best practices, and recommend future technologies Code and deploy web-based applications within Machine Learning platforms Take the first step towards your dream career Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role: Essential Requirements Proficiency in SQL, Python, Spark, Databricks, Azure, or other Machine Learning platforms Experience with container systems Desire to collaborate cross-functionally with team members and internal customers Desirable Requirements Software Engineering experience or education preferred Bachelor’s Degree Here’s our story; now tell us yours Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress. What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life - while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more. We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today. You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here. Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Equal Employment Opportunity Policy here."
Big Data Engineer,Big Data Engineer,Remote,https://www.indeed.com/rc/clk?jk=15b31cac6b5c83cd&fccid=0b1a6b85bfc3cecd&vjs=3,"SQL, Spark, Hive, AWS, Scala, EMR Contract W2, Contract Independent, Contract Corp-To-Corp, 12 Months Depends on Experience Travel not required Responsibilities: Looking for a Big Data Engineer to assist with designing, developing, and testing various database and ETL components within a cloud-based enterprise business application. This application handles the sales compensation function of a large telecom company, processing millions of transactions in each batch process. The role is responsible for analyzing business requirements, and delivering database objects (SQL, Stored Procedures, ETL functions) to meet those requirements. Must be able to write efficient SQL Queries for the most optimal system performance. The project follows an Agile development methodology. Requirements: Proficient in writing complex SQL Queries and Stored Procedures in SQL Server Good knowledge of database design concepts for optimal query performance. Proficiency in Spark SQL and Scala in AWS environment Hands-on experience to write MapReduce jobs. Good knowledge of spark architecture, multi-threading, and concurrency concepts Good understanding of Hadoop, Hive, Hue, YARN, AWS EMR"
Data Engineer,TAE TECHNOLOGIES INC,"Foothill Ranch, CA 92610+1 location",https://www.indeed.com/rc/clk?jk=ed3cbeb4d277aa0d&fccid=4974107f0d26209a&vjs=3,"TAE Technologies develops breakthrough solutions to the most complex problems of our time. Our core mission is to develop and distribute safe, cost-effective commercial fusion energy with the cleanest environmental profile. With close to 1,000 issued and pending patents and over $600 million USD in private capital, we are now on the cusp of delivering a transformational energy source capable of sustaining the planet for thousands of years. Our foundational technology has catalyzed a portfolio of spinoff opportunities in critical markets such as electric mobility, power management, life sciences and more. Multidisciplinary and mission-driven by nature, TAE Technologies is leveraging proprietary science and engineering to create a bright future for us all. We currently have an opening at our Foothill Ranch, CA (Orange County) facility for a Data Engineer in TAE Technologies’ Data Science team, within the AI organization. As a Data Engineer, you will partner with data scientists and physicists to help define and refine their data needs. You will use this information to create, maintain, and/or enhance scalable and sustainable data pipelines and structures. You will also help create and maintain detailed, comprehensive, and well-structured test/validation suites on all data and data producers. You will stay on top of the latest data technology developments and act as a knowledge hub for data-related issues at TAE Technologies. This is a unique opportunity for a Data Engineer to work directly within a data science team that is helping solve some of the biggest problems humanity is facing. If you're motivated by solving challenging problems and making an impact with data, this is the role for you. We are focused on building a diverse and inclusive workforce. If you’re excited about this role, but do not meet 100% of the qualifications listed, we encourage you to apply. This is a full-time position with a rich compensation package. Working at TAE: We are a diverse group of 200 brilliant physicists, engineers and other experts from 30 countries around the world – all committed to improving our world through clean technology. TAE values individual expertise within our culture of collaboration. We offer generous benefits, vacation, career development programs and intramural ping pong. Essential Duties and Responsibilities: Create, maintain, and/or enhance scalable and sustainable data pipelines and structures Ensure ongoing data quality and manage data governance that enables safe and rapid adoption, integration, and accuracy of data Create and maintain detailed, comprehensive, and well-structured test/validation suites on data and data producers Identify and report data resilience issues to key stakeholders Easily, effectively, and successfully work on multiple tasks both independently and collaboratively within a group Required Skills: 3-5 years as a Data Engineer showing incremental levels of complexity and responsibility Software Knowledge and Skills: You should have a passion for data accuracy and integrity Demonstrated experience working with ETL processes/pipelines with large volumes of data and strict expectations for reliability and performance Experience in virtualization or cloud native architectures, especially with Google Cloud Platform Experience or knowledge of data management fundamentals, data storage principles, and/or storage tiering Demonstrated experience scripting with Python and/or Shell Proficient working with Unix/Linux operating systems Experience or knowledge of SQL Working knowledge of Git Preferred Skills: Experience architecting data solutions in Google Cloud Platform Experience with data migration strategies to cloud Experience with developing data warehousing, data lakes, batch and/or real-time event processing Experience and/or interest in Machine Learning Collaborative environment experience (Git, JIRA, Confluence) Able to work in a diverse R&D environment and professionally communicate with co-workers at all levels Education: BS or MS Degree in Computer Science or the equivalent in experience as a Data Engineer"
Senior Data Engineer,Aristocrat Technologies Inc,"Hybrid remote in Austin, TX 78757",https://www.indeed.com/rc/clk?jk=a4a24a9bd851aa87&fccid=38fd7bd102c4d12e&vjs=3,"Job Posting Title Senior Data Engineer Summary We are looking for a Senior Data Engineer to join Pixel United's Product, Strategy and Insights (PSI) division where you will design, build, and operate best-in-class data pipelines and analytics solutions. We'll have the advantage of leveraging an established world-class Data Platform, utilizing Google Dataflow pup/sub pipeline and Snowflake. As well as be supported by and collaborate with the team who built that platform. This role requires you to apply a breadth of technical knowledge and strategic thinking to improve existing systems, and identify and build new capabilities. You’ll work closely with stakeholders across the company to create effective solutions for our analytics framework that powers top mobile games with millions of users per day. In this role you’ll be working closely other engineers as well as providing direction to our partner game studios. We are excited to be using the latest cloud native technologies and are looking for someone who wants to push the envelope of the software we deliver to our business and data science customers within Pixel United! Pixel United (formerly Aristocrat Digital) is a mobile- first games powerhouse, boasting three world-leading publishers in Product Madness, Plarium and Big Fish Games that entertain millions of players every day. The Product, Strategy and Insights (PSI) division of Pixel United is the entrepreneurial engine room of Pixel United. We bring together world-class competitive intelligence, customer research and product strategy to identify new market opportunities, stay ahead of shifting consumer demand and help PxU businesses to realize the full potential of their diverse product portfolio. What You'll Do Design systems across the Data Analytics space, including API integrations, telemetry event streams, data warehouses, data science workloads, dashboards, etc. Partner with other engineers and contractors to implement your data solutions, including code review, QA, deployment, and operation Work closely with other technology teams and business partners across Pixel United to deliver the right solution for the organization Collaborate with other data engineers to mutually grow skills across the team Own uptime/scalability/break-fixing of production systems operating at scale Partner with Technical Project Managers and Engineering Managers to build and deliver against team roadmaps Must be a “team-player” with the ability to work in collaborative environments with worldwide teams Effective communicator across in person and digital mediums with technical and non-technical audiences This is a partner-facing role, so a customer service mindset and demeanor are required What We're Looking For 5+ years working in Data Engineering or related fields Advanced knowledge of cloud-based data pipelines. We are building out a Pub/Sub, Dataflow, Snowflake, Looker data pipeline so preference given to those technologies. Worked with streaming analytics engines (e.g. Google’s Dataflow) Independent operator who can work with minimal supervision while collaborating with and assisting other team members Ability to handle ambiguity and transform business needs into software solutions Experience working with multi-terabyte data sets Advanced SQL, and Python programming skills with ETLs and Data Warehousing Experience with Linux and Windows as platforms for large scale data systems Experience with statistical or machine learning Experience with cloud migrations or data pipeline migrations Previous project lead role working with nearshore/offshore contractors Why Aristocrat? Aristocrat is a world leader in gaming content and technology, and a top-tier publisher of free-to-play mobile games. We deliver great performance for our B2B customers and bring joy to the lives of the millions of people who love to play our casino and mobile games. And while we focus on fun, we never forget our responsibilities. We strive to lead the way in responsible gameplay, and to lift the bar in company governance, employee wellbeing and sustainability. We’re a diverse business united by shared values and an inspiring mission to bring joy to life through the power of play. We aim to create an environment where individual differences are valued, and all employees have the opportunity to realize their potential. We welcome and encourage applications from all people regardless of age, gender, race, ethnicity, cultural background, disability status or LGBTQ+ identity. We offer a range of flexible working options through all.flex, our flexible hybrid work model and invite you to have a conversation with us about flexible working. EEO M/F/D/V World Leader in Gaming Entertainment Robust benefits package Global career opportunities Our Values All about the Player Talent Unleashed Collective Brilliance Good Business Good Citizen The US based roles may require registration with the Nevada Gaming Control Board (NGCB) and/or other gaming jurisdictions in which we operate."
Data Engineer,Cincinnati Children's Hospital,"Cincinnati, OH 45219 (CUF area)+1 location",https://www.indeed.com/rc/clk?jk=0d9faed7dd9b008a&fccid=1cf1d6e36473c700&vjs=3,"Description SUBFUNCTION DEFINITION: Focuses on how to design, integrate, and manage complex data and analytic systems over their life cycles. Uses a combination of core software engineering principles and domain specific data and analytic knowledge to ensure the enterprise as seamless access to actionable, meaningful and well-governed data across all domains. CCHMC SALARY GRADE:10 REPRESENTATIVE RESPONSIBILITIES Data Pipelines Build, test and manage simple data pipelines from data sources or endpoints of acquisition to integration to consumption for production for key data and analytics consumers like business/data analysts, data scientists, etc. Comply with data governance and data security requirements while creating, improving and operationalizing data pipelines, following standards set by more senior data and platform engineers. Perform maintenance changes and updates to ETL processes and support upgrade and testing initiatives as necessary Understand bench-marking and process improvement data requirements and develop solutions to address these requests. Metadata Management & Data Modeling Follow team standards for managing metadata to ensure data is used in the right business context and with minimal data duplication. Assist in curation of new data needs, business context association, or sensitivity analysis. Ensure the governance lifecycle for all onboarded data and change workflows as data or business context changes. Update documentation of data models and extract processes. Update support documentation so teams can be cross trained to support users and processes. Modify, test and deploy updates to data models under direction and guidance from senior staff. Work with reporting teams to help them develop best practices approaches to writing and tuning new reporting objects. Technical & Business Skill Foundational knowledge of several Data Management practices and architectures, such as Data Modelling, Data Warehousing, Data Lake, Data Hub, etc. and foundational understanding of the others. Proficiency with SQL, object-oriented/object function scripting and DevOps principles. Develop understanding of core CCHMC clinical, business and research processes to help build appropriate data solutions. Obtain Epic certifications as appropriate/needed. Technical Support & Customer Services Ensure outstanding end-user support is provided, including ongoing monitoring of Service Level Agreements for incident management and collaboration with other areas to ensure customer-centered incident management and support. Adhere to change management policies and procedures. Model outstanding customer service behavior, including timely and effective follow-up with customers. Work with vendors when necessary to ensure CCHMC investments and requests are being adequately supported and enhanced. Escalate support issues with urgency. Take 24 hour call on a staff rotation. Project Execution Execute own project tasks with urgency and to a high level of quality. Communicate status clearly and effectively using departmental project management tools. Follow time-tracking and other project management requirements. Qualifications EDUCATION/EXPERIENCE Required: Bachelor's degree in a computer science, statistics, applied mathematics, data management, information systems, information science or a related quantitative field. No directly related experience Preferred: Unique Skills:"
Data Driven Solutions Engineer,HP,"Vancouver, WA 98683 (Bennington area)",https://www.indeed.com/rc/clk?jk=4addee7f5e4fe157&fccid=c8eabfdb4fcf2d28&vjs=3,"The Data Driven Solutions team uses device information to provide innovative customer experiences in the consumer print market. The team includes cloud software and printer firmware engineers. We own the entire process, from printer firmware to cloud/printer communication to processing data in the cloud to provide a customized experience at the printer. The desired candidate will apply a basic foundation of engineering principles, theories, and concepts to assignments of limited scope. They should have a base knowledge of computer science, and they will develop expertise and practical knowledge of the print industry, cloud development, firmware, and data science, . The desired candidate will work on a team and interact with global organizations, providing information, analysis and recommendations in support of team efforts. Responsibilities: Engineer enhancements, updates, and changes for portions and subsystems of embedded firmware and cloud software. Execute established test plans and protocols for assigned portions of code; identify, log, and debug assigned issues on an agile team using Jira. Develop understanding and build relationships with internal and outsourced development partners on firmware design and development. Participate as a member of a project team with other firmware engineers and development partners to develop reliable, cost effective and high-quality solutions for low to moderately-complex problems. Education and Experience Required: Bachelor's or Master's degree in Computer Science, Information Systems, Electrical Engineering, or equivalent. Typically 0-2 years experience. Knowledge and Skills: Experience or understanding of software engineering; understands embedded C and C++ in Linux; can work with Java, Spring, MongoDb. Good analytical and problem-solving skills. Understanding of firmware and cloud design principles. Understanding of basic testing, coding, and debugging procedures. Good written and verbal communication skills; mastery in English. Where legally permitted, an offer of employment is conditional upon you providing proof that you are fully vaccinated against COVID-19 (as defined by the CDC) as of your first day of employment. HP is an equal opportunity employer: https://tbcdn.talentbrew.com/company/3544/v1_0/PDFs/HP%20Inc%20EEO%20Policy%20Statement%202017_Final_signed.pdf #LI-POST About HP You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you. So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference. HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere. Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are. From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!"
Senior Data Engineer,Tokyo Electron Limited,"Portland, OR",https://www.indeed.com/rc/clk?jk=6f7ad2e56b76cbca&fccid=d3e4d44cc99b633b&vjs=3,"Let’s search for your next career at TEL. Use the form below to search our current opportunities and then apply. Please consider joining our Talent Community so that we may continue to engage with you. Job Description Senior Data Engineer supporting team of Data Analysts, Data Scientists, and Semiconductor Product Engineers. The team focus is the design and implementation of data analytics products supporting the safety, quality, availability, and performance of TEL’s semiconductor products. Data analytics products include technical troubleshooting aids, predictive maintenance tools, and process characterizations. In this position, it is imperative that you have the willingness and desire to wear multiple hats and be interested in software development, analytical work, complex industrial systems, continuous learning, and mentoring teammates. Position location is flexible to be Hillsboro OR, Phoenix AZ, or Austin TX. *Responsibilities* Design and manage ETL pipeline jobs for an edge computing environment using DAG-based products. Data modeling. Participate in team code reviews. Set strategic goals for data engineering roadmap and products. May perform other duties, as needed, to assist the data team *Required Qualifications* A minimum of 2 years of hands-on work in Data Science, Data Analytics, or Data Engineering. Completion of Master’s degree meets qualifications in lieu of experience. Demonstrated proficiency in Python for manipulating datasets. Demonstrated proficiency in DataFrames. Data architecture, SQL experience. Experience in multidimensional data modeling, such as star schemas, snowflakes, deformalized models, and handling ""slow-changing"" dimensions/attributes. Ability to work in both Windows and Linux. Ability to clearly communicate data stories to stakeholders. *Preferred Qualifications* Bachelor’s degree in a STEM field. Semiconductor industry experience. DBA, MLOps, DevOps, CI/CD, Git, Data Visualization platform (e.g. PowerBI, Spotfire) skills. Willingness to work with low-code coding and orchestration platform (e.g. Knime Analytics Platform, Knime Server). Familiarity with robotics control systems and maintenance. Familiarity with industrial productivity concepts. Diversity creates an innovative culture. TEL US is an Equal Employment Opportunity / Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. Equal Opportunity Employer/Minorities/Females/Disabled/Veterans Diversity creates an innovative culture. TEL US is an Equal Employment Opportunity / Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. Subsidiary TOKYO ELECTRON AMERICA, INC."
Senior Azure Synapse Data Engineer,Performance Contracting Group,"Lenexa, KS 66219",https://www.indeed.com/rc/clk?jk=c25613aa7fccda81&fccid=df645f00a80e5b11&vjs=3,"Company Overview: Performance Contracting Group is a national employee-owned specialty contractor that offers quality services and products to the commercial, industrial, and non-residential construction markets. We are committed to recruiting, developing, and advancing employees from a diversity of backgrounds and experiences, as well as supporting a culture of safety and inclusiveness that allows you to contribute to your fullest potential. We place high value on training and professional development, encouraging you to broaden and strengthen your unique skill sets so you can fully realize your potential. Job Description: About this Role The Senior Azure Synapse Data Engineer will support our move to a modern data architecture and build-out of our data estate. Core activities include automating data ingestion from internal and external tools/platforms; identifying and linking individuals across different datasets/platforms for further analytics; creating sophisticated ETL processes to clean and organize our data using Azure Synapse pipelines, and providing Business Intelligence to establish the breadth, depth, and quality of the data. Our ability to have clean, well-organized data is fundamental. This individual will be responsible for: Architecture design. Design, develop and maintain the architecture of the Azure data estate (data lake, SQL Analytics store, pipelines, ML/AI environment and network) to meet business requirements. Data acquisition and integration: ensure feeds from various platforms – primarily internal but increasingly external are established. Use programming skills to develop, customize and manage ingestion tools, storage accounts, and analytical applications and their access. Perform ETL processes for optimal extraction, transformation, and loading of data from a wide variety of data sources using Azure Synapse tools and technologies. Data pipeline development/testing. Test the reliability and performance of each part of a system during the development phase. Identify, design, and implement process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability and data quality. Track pipeline stability. Monitor the overall performance and stability of the system and ensure automated parts/scheduled tasks are monitored. Manage structured and unstructured data and meta-data stored in the data estate. Ensure availability of clean, transformed data to meet business needs. Partner with IT Operations to provide Business Intelligence tools/infrastructure. Set up tools, views, and access permissions for different user groups enabling them to view data, generate reports, and create visuals. Data strategy. Contribute to the broader organizational data strategy, including data privacy and governance practices. Develop strong relationships with key stakeholders across the business and help determine critical objectives. Requirements: Minimum Requirements Microsoft Azure Synapse experience is essential. Excellent communication skills with the ability to work within a team, across the business, and build strong relationships. End-to-end Data Warehouse experience: ingestion, ETL, ‘big data’ pipelines, data architecture, message queuing, stream processing, BI/Reporting, and Data Security. Ability to build processes supporting data transformation, data structures, metadata, dependency, and workload management, as well as the ability to manipulate, process, and extract value from large, disconnected structured and unstructured datasets. Advanced SQL/relational database knowledge (including SSIS), query authoring (SQL). Experience performing root cause analysis on data, answer specific business questions and identify opportunities for improvement. Preferred Requirements Degree in Computer Science, Statistics, Informatics, Information Systems or quantitative field. Benefits: At Performance Contracting our employees are our greatest asset. We put our people first and are proud to provide a comprehensive benefits package designed to meet the needs of our employees at every stage of life. In our commitment to fostering an environment where everyone can thrive personally and professionally, we offer our salaried employees: Competitive pay Incentive bonus plan Employee stock ownership plan (ESOP) 401(k) retirement savings plan with match Medical, prescription drug, dental and vision insurance plans with flexible spending account option Life insurance, accidental death and disability benefits Employee assistance program (EAP) Flexible paid time off policy and paid holidays PCG provides equal employment and affirmative action opportunities to applicants and employees without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability. PCG is a background screening, drug-free workplace. Please note this job description is not designed to contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice. #PCG"
Senior Data Engineer,LCS,"Des Moines, IA",https://www.indeed.com/rc/clk?jk=2bd11fe76a670ce0&fccid=4afb8ace7b8acf0c&vjs=3,"Many roles at LCS may require that we ask about your COVID-19 vaccination status. Please note that this role will be required to provide proof of COVID-19 vaccination as a condition of employment. This Senior Data Engineer role is to create and maintain data solutions that meet department/functional needs that also create operational efficiencies with the business and IT. Primarily works with databases and different types of reporting, visualization or analytics software. This position is responsible for ensuring high level of quality by performing user support functions and in-depth QA testing. This role is open to being 100% remote for someone who resides outside of the Des Moines area. Experience is Everything; At LCS, experience is everything. We provide you the opportunity to use your talents in a progressive, growing organization that makes a positive difference in the lives of the seniors we serve. If you are seeking an organization that gives back, you’ll love working here. Our principles and hospitality promises define our company culture. LCS employees can be found participating in volunteer activities, getting involved in our committees or collaborating with team members in our innovative work space. You’ll find several opportunities to grow as a professional, serve the community, and enhance the lives of the seniors. The Role: Participate in the development lifecycle of design, testing, implementation, and deployment Works closely with business partners to define requirements, understand source systems, and business processes that impact the company’s key data Researches new and innovative Business Intelligence capabilities and effectively applies them to enhance the company’s analytical abilities Provides effective support to all levels of the company for products the team is responsible for delivering and maintaining Develops and maintains internal documentation Work with team members to maintain, develop, and document ETL processes Builds data systems and data infrastructures that collect and process data according to company needs and goals Builds, evolves, and scales out data infrastructure to ingest, process, and extract meaning out data Designs, develops, and implements statistical models to carry out various novel aspects of classification and information extraction from data Leverages existing data infrastructure to fulfill all data-related requests, perform necessary data housekeeping, data cleansing, normalization, hashing, and implementation of required data model changes Analyzes data to spot anomalies, trends, and correlate similar data sets Troubleshoots problems, identifies possible solutions, and resolves accordingly Handles complex issues and problems with minimal supervision required Thinks through long-term impacts of key design decisions and handles failure scenarios Identifies and champions initiatives to improve current processes Able to juggle multiple projects – can prioritize objectives, manage time, and communicate effectively to team members and business partners Interacts cross-functionally with other technical teams both internally and externally Serves as an informal leader to other team members to include delegating and managing tasks, as appropriate Develop Azure compute solutions, monitor/troubleshoot and optimize Azure solutions Experience: 4-year degree in Computer Science, MIS, or equivalent work experience 5-7 years of experience in developing, implementing, and supporting enterprise solutions Experience with database concepts, advanced SQL, and reporting/Business Intelligence software Microsoft Azure experience required • 2+ years' experience with Data Factory, Data Lake, and/or Synapse Knowledge & Skills: Strong SQL skills Familiar with database design Can design and develop enterprise Business Intelligence dashboards Analytical skills with the ability to collect, organize, analyze, and distribute significant amounts of information with attention to detail and accuracy Strong communication skills - both verbal and written Ability to provide quality customer service Thorough and detail oriented Leadership abilities Why LCS? Industry leader. The Nation’s second-largest senior living operator, ranked number one in customer satisfaction among senior living communities. Competitive pay, great benefits and vacation time. We are an equal opportunity employer with benefits including medical, dental, life insurance, disability, 401(k) with company match. Collaborative culture. We’re dedicated to creating a collaborative culture that provides an exceptional experience for every employee. Charity and community involvement. We are recognized as a national team for the Alzheimer’s Association and consistently a top contributor to United Way. We also support our employee’s individual community contributions and provide opportunities to get involved at our corporate locations and in our communities. Outstanding advancement opportunities. LCS is growing and we think you should too. Our company growth allows for internal growth opportunities across all of our business lines. Ongoing career development. Onsite education opportunities, education assistance, and continuing education credits allow LCS employees to keep their knowledge of current industry changes relevant. Top Iowa Workplace. LCS employees truly believe we are an employer choice. This recognition is in large part due to the culture of excellence that our employees help deliver every single day. LCS creates living experiences that enhance the lives of seniors. You’ll see this commitment in our people. They’re talented, dedicated professionals who truly care about residents, with each conducting his or her work with integrity, honesty and transparency according to the principles of LCS. We strive to help every community succeed—strengthening available resources, establishing proven practices that lead to long-term growth and creating lasting value for those living in, working for and affiliated with the community. Check us out on our website: www.lcsnet.com Travel Frequency: 0-10% Job Level: B A POST-OFFER BACKGROUND CHECK, INCLUDING REFERENCES, IS REQUIRED LCS IS AN EQUAL OPPORTUNITY EMPLOYER"
Data Engineer (Contract to Hire),Howard Hughes,"The Woodlands, TX",https://www.indeed.com/rc/clk?jk=e2d517150f657a98&fccid=858d75a780bb77b8&vjs=3,"The Howard Hughes name is synonymous with an unrelenting passion for excellence. While his achievements in aviation and the silver screen are legendary, it was his investments in real estate that form the foundation of our company. With passion, determination, and limitless imagination, he built one of the great American empires of the 20th century. At Howard Hughes, we live by our purpose to help people discover new ways of experiencing life - because it’s not just buildings and places that matter, it’s what you do with them that can change the way people live. We aspire to be the most creatively driven real estate company in the world and we believe in fostering a culture that is built to last by cultivating curiosity and empowering every employee to find their story in this great organization. POSITION SUMMARY: As the data engineer you will be responsible for managing, optimizing, overseeing, and monitoring data retrieval, storage, and distribution. You will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. You will support software developers, data architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. ESSENTIAL JOB RESPONSIBILITIES: Develop, construct, test and maintain data platforms and pipelines including enterprise data warehouses and data marts. Assemble large, complex data sets that meet functional / non-functional business requirements. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Develop data set processes for data modeling, mining, and production. Continuously improve data reliability, efficiency, and quality. DESIRED KNOWLEDGE, SKILLS & EXPERIENCE: 3+ years of experience working on large scale, full lifecycle data implementation projects BS/BA in data engineering, software engineering, data science, computer science, applied mathematics, or equivalent experience. A deep knowledge of performant SQL and understanding of relational database technology. Hands-on RDBMS experience (data modeling, analysis, programming, stored procedures). Expertise in developing ETL/ELT workflows with one or more of the following: Talend/Informatica/InfoSphere ETL tools; Python, Java. Deployment of data pipelines in the Cloud in at least AWS, Azure, or GCP. Proven success working in and promoting a rapidly changing, collaborative, and iterative product development environment. Strong interpersonal and analytical skills. Intellectual curiosity and an ability to execute projects. An understanding of “big picture” business requirements that drive architecture and design decisions. DevOps and DataOps skills including “infrastructure as code” systems Data system performance tuning. Implementation of predictive analytics and machine learning models (MLlib, scikit-learn, etc). ADDITIONAL INFORMATION: HHC has adopted a COVID-19 vaccination policy to safeguard the health and well-being of our employees and visitors. As a condition of employment, all employees based in the U.S. are required to be fully vaccinated for COVID-19, unless a reasonable accommodation is approved or as otherwise required by law. NOTICE TO THIRD PARTY AGENCIES: Please note that The Howard Hughes Corporation does not accept unsolicited resumes from recruiters or employment agencies. In the absence of a signed Recruitment Fee Agreement, HHC will not consider or agree to payment of any referral compensation or recruiter fee. In the event a recruiter or agency submits a resume or candidate without a previously signed agreement, HHC explicitly reserves the right to pursue and hire those candidate(s) without any financial obligation to the recruiter or agency. Any unsolicited resumes, including those submitted to hiring managers, are deemed to be the property of The Howard Hughes Corporation."
Lead Data Engineer,Tegus,Remote,https://www.indeed.com/rc/clk?jk=7f9141dcbf76f14f&fccid=fe4b478c876b3ef1&vjs=3,"Tegus is the leading market intelligence platform for key decision makers. We power some of the world’s most well-respected institutional investors, corporations, and consultancies through the largest and most comprehensive database of primary and market information. Our products and services enable clients to discover unmatched insights and answers to the most challenging questions they face to help them make better informed decisions. (And because a job description can only contain a fraction of how we operate, click here to learn more about the Tech Team at Tegus!) As a Lead Data Engineer, you will empower decision-making at Tegus in a dynamic, collaborative operating environment. As one of our first data engineers, you will have a big impact on shaping the technology stack for our data platform and will mentor future Data Engineers on the team. In this role you will work with Data Analytics, Product, Operations, Sales, Marketing, and upper management to develop a robust data infrastructure that supports strategic initiatives. You will design, develop, and maintain data sources, data models, ETL that support the efficient creation of recurring reports, dashboards, and structured analysis. To sustain the health of the data infrastructure, you will identify, define, and collaborate on requirements for data collection, transformation, and delivery. Responsibilities Create and own an end-to-end, efficient, and repeatable process for delivering data and data services to business stakeholders, including data modeling and building robust data pipelines. Assess the current technologies used in our data platform and make technology and process choices that optimally support the future growth of Tegus. Develop and maintain data lake and data warehouse schematics, layouts, architectures for data access and knowledge sharing. Create robust datasets that support insightful dashboards and reports. Establish and maintain company-wide standards for source-of-truth data and data quality, diagnose and resolve data infrastructure issues, and monitor the quality of data processes. Collaborate cross-functionally to deliver data-driven product and business insights. Help expand the capabilities of the team through hiring and mentoring. Qualifications Minimum of a bachelor’s degree in computer science, data science or similar fields or equivalent professional experience. Minimum of six years working in a data engineering role, including at least three in a lead or managerial role. Proven ability to expand the technical capabilities and effectiveness of less experienced colleagues. Expertise in data pipelines, ETL, ELT, data ingestion/cleansing, and engineering skills. Demonstrated success in making critical technology choices that drive the design, development, maintenance, and growth of an enterprise data platform including data warehousing with multiple data sources (for example, Snowflake or AWS). Demonstrated success delivering data models and ETL that create robust data pipelines using technologies such as Airflow, Fivetran, or AWS Glue. Expertise working in SQL, bonus for PostgreSQL experience. Strong experience supporting the build-out of dashboards and reporting in an enterprise business intelligence system such as Domo, Looker, or Tableau. Benefits & Perks Remote-friendly - work wherever you're most productive. (Note: this position is not currently open to Colorado residents). Comprehensive medical and dental plans. 401K plan with an employer match. Paid parental leave for all parents. All employees are granted equity through our Restricted Stock Units (RSU) Program. Unlimited paid vacation, flexible work hours, and 10 observed paid holidays per year. Employer funded long-term disability. Fantastic culture with regular virtual company-wide events, including cooking classes, yoga, meditation and more. Generous employee referral bonus program. The opportunity to attend peer-nominated quarterly DEI events. Working for a thriving, performance-based company that values promoting from within, career advancement and transparency. And for candidates in Chicago: The option to work from a state of the art office in the heart of Chicago’s Loop featuring standing desks, mother rooms, gender neutral bathrooms, subsidized gym access, and full amenity floor. Commuter benefits & a fully stocked kitchen with rotating snacks and beverages. Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Tegus we are dedicated to building a diverse, inclusive and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles. Tegus, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status. In addition to federal law requirements, Tegus complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company operates. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. Tegus expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, national origin, age, disability, or veteran status."
Data Security Engineer (DLP)- OPEN TO REMOTE,Holiday Inn Club Vacations,"Remote in Orlando, FL 32819",https://www.indeed.com/rc/clk?jk=08bf83f94e595b05&fccid=586ff15a77ff4338&vjs=3,"At Holiday Inn Club Vacations, we believe in strengthening families. And we look for people who exhibit the courage, caring and creativity to help us become the most loved brand in family travel. We’re committed to growing our people, memberships, resorts and guest love. That’s why we need individuals who are passionate in life and bring those qualities to work every day. Do you instill confidence, trust and respect in those around you? Do you encourage success and build relationships? If so, we’re looking for you. Holiday Inn Club Vacations is looking for a talented and experienced Cyber Security Data Security Engineer to lead the Data Protection program. The incumbent will actively work with the business to understand needs, while designing the program. Specifically, the incumbent will model policies, implement DLP technologies, identify, monitor, and investigate incidents. ESSENTIAL DUTIES AND TASKS: Assist in logical and physical architecture of the DLP solution, including tool configurations and integrations with SIEM. Evaluate and compare DLP tool capabilities and recommend tool configurations. Assist in defining common DLP tool rulesets and work with operational teams to consistently apply those rules to multiple DLP tools. Assess sensitive data exfiltration scenarios and quantify risk, map security controls, and make technical recommendations to address gaps. Assist in the definition, collection, and reporting of key DLP metrics to measure the effectiveness of people, process, and technology. QUALIFICATIONS: Bachelor's degree in CIS or related field, equivalent work experience can substitute for the degree. Detailed knowledge of appropriate data security controls for data at rest, in transit, and/or in use. Experience policy configurations, testing, and implementations for email, network, and endpoint DLP solutions. 5+ years of comprehensive experience around Network, Email and Endpoint DLP components and tools. Knowledge on basic security concepts (e.g., CASB, Data Classification, Data Discovery, encryption, etc.). 5+ years of work experience on DLP solutions. Experience with a variety of systems and applications including Cloud, Windows Server, Unix/Linux, SQL Server/Oracle. DLP product certifications (e.g., Symantec) CISSP, or equivalent certification desired."
Staff Data Engineer - 368,Rocket Lawyer,North Carolina+2 locations,https://www.indeed.com/rc/clk?jk=15ec857974672fac&fccid=d25e98cd4a33d7d9&vjs=3,"About Rocket Lawyer We believe everyone deserves access to affordable and simple legal services. Founded in 2008, Rocket Lawyer is the largest and most widely used online legal service platform in the world. With offices in North America and Europe, Rocket Lawyer has helped over 25 million people create over 50 million legal documents, and get their legal questions answered. We are in a unique position to enhance and expand the Rocket Lawyer platform to a scale never seen before in the company’s history, to capture audiences worldwide. We are expanding our team to take on this challenge! About the Role Rocket Lawyer is seeking an experienced, passionate Data Engineer who wants to work in a fast-paced, dynamic environment with a talented agile team. As part of a 5-person team of data engineers you will play a key role in providing product owners and executives the data they need to make intelligent decisions. We value a fun, collaborative, team-oriented work environment, where we celebrate our accomplishments. A Day in the Life Provide technical leadership with a team of data engineers who: Analyze, extract, transform and load data from multiple internal and external sources into a Snowflake warehouse to support a business intelligence team. Use SQL, API calls and Google Cloud to extract data. Use SQL to transform and load data. Use Airflow running in Google Cloud to orchestrate data flows. Write code. Participate in daily team huddles. Collaborate with report developers to create useful target tables and views. Collaborate with product owners, release managers and QA staff to validate and promote code to production. Required Experience Architecture and Design (8+ years) SQL language (8+ years) Python (4+ years) Git (4+ years) Linux (4+ years) Preferred Experience Google Cloud Platform Airflow Snowflake"
Data Engineer III,Grainger,"Remote in Chicago, IL 60603+2 locations",https://www.indeed.com/rc/clk?jk=ea3277b5ea951241&fccid=68bc43ebf2f50281&vjs=3,"About Grainger: Grainger is a leading broad line distributor with operations primarily in North America, Japan and the United Kingdom. We achieve our purpose, We Keep the World Working®, by serving more than 4.5 million customers with a wide range of products that keep their operations running and their people safe. Grainger also delivers services and solutions, such as technical support and inventory management, to save customers time and money. We're looking for passionate people who can move our company forward. We have a welcoming workplace where you can build a career for yourself while fulfilling our purpose to keep the world working. We embrace new ways of thinking and recognize everyone is an individual. Find your way with Grainger today. Position Details: We are looking for a Senior Data Engineer for our Insights, Data Engineering & Analytics (IDEA) team. The team's primary mission is to enable analytics and reporting by centralizing and integrating high-quality, trusted corporate data in a performant and scalable cloud analytical platform. You will help develop data pipelines and product. You will work with SMEs, architects, analysts, data scientists and others to build solutions that integrate data from many of our enterprise data sources. This role will be working closely with business analysts and other key stakeholders. This role will be reporting to the Manager, eCommerce Engineering and can be based in either Lake Forest, IL or downtown Chicago or remotely. You Will: Enable analytics and reporting by centralizing and integrating high quality, large, complex data sets in a highly performant and scalable cloud analytical platform. Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes. Build required tools for optimal extraction, transformation and loading of data from various data sources. Build frameworks, standards & product features to enable self-service analytics. Partner with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues. You Have: 5+ years of experience with Modern Data Engineering projects and practices: designing, building, and deploying scalable data pipelines 3+ years of experience designing building deploying cloud native solutions 3+ years of experience with AWS, SQL, Python, Docker/Kubernetes, CI/CD, Git, familiarity with: Snowflake, DBT, Airflow Developed POCs on large and complex data sets to meet business and technical requirements Experience with advanced analytics and machine learning Familiarity with BI tools such as Tableau, PowerBI Bachelor's Degree in Computer Science, Engineering, Business (or Management), related disciplines or equivalent work experience. Rewards and Benefits: With benefits starting day one, Grainger is committed to your safety, health and wellbeing. Our programs provide choice and flexibility to meet our team members' individual needs. Check out some of the rewards available to you at Grainger Medical, dental, vision, and life insurance plans Paid time off (PTO) and 6 company holidays per year Automatic 6% 401(k) company contribution each pay period Employee discounts, parental leave, 3:1 match on donations and tuition reimbursement A comprehensive set of emotional, financial, physical and social wellbeing programs DEI Statement We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal opportunity workplace."
Data Engineer,Matador Resources,"Dallas, TX 75240 (North Dallas area)",https://www.indeed.com/company/Matador-Resources-Company/jobs/Data-Engineer-8d2022171aeb35c8?fccid=c261accd951419f1&vjs=3,"JOB DESCRIPTION: As part of the Information Technology Team, the Data Engineer will design and build end to end solutions to deliver accurate and actionable information to various lines of business at Matador. *JOB RESPONSIBILITIES*Responsibilities Include: Design and deploy relational and dimensional data structures to support reporting and analysis solutions Design and deploy ETL processes in support of the warehouse Design and deploy ML workflows to enhance operational efficiency Working with end users, design user interfaces to present data in an accurate and actionable format Enhance and expand existing solutions Troubleshoot reported issues Help identify improvements and define optimal toolset for the warehouse / reporting environment Participate in setting standards as well as near/medium term direction for warehouse technologies JOB BENEFITSCompensation includes industry competitive salary commensurate with experience, performance incentives, plus medical and dental benefits, 401(k), etc. Details are available upon application.Education and Experience: College degree in Engineering, Computer Science, or Information Technology Applied experience using Microsoft SQL Applied experience in Microsoft SQL Server stack, including: SQL Server Management Studio SQL Server Reporting Services SQL Server Integration Services Applied experience w/ ETL concepts and techniques Applied experience with Python Familiarity with artificial intelligence and machine learning concepts Familiarity with modern toolsets such as Hadoop, Snowflake, etc. a plus Good time management, capable of multi-tasking, must be willing to work necessary overtime as needed to meet deadline Experience working in oil and gas is a plus Ability to work in a fast-paced setting, process work rapidly, set priorities, work under pressure, and follow through with assigned tasks with limited supervision Results orientation Have an assertive personality, excellent analytical and problem-solving skills Good written and verbal communication skills Must be flexible, detail-oriented, organized and a self-starter Location: 5400 LBJ Freeway Ste 1500, Dallas, TX 75240 Job Type: Full-time"
Data Engineer,HCL,"San Francisco, CA+8 locations",https://www.indeed.com/rc/clk?jk=ba9ba116c2c5f71a&fccid=92a79710d9899fa9&vjs=3,"Develop and deploy production-grade services, and data infrastructure emphasizing performance, scalability, and self-service. Assume a leadership role in developing solutions with experience in continuous delivery, immutable deployments, containerization, and micro-service architectural patterns. Are ""biased to action"" and not easily blocked by problems and difficulties, instead taking ownership Believe in monitoring, QA, and security as a first-class citizen in any data product. Excited to build data platforms and tools that abstract implementation details for developers, analysts, and data scientists, enabling data transit. Dedicated to automation, documentation, and collaboration at all stages of the engineering workflow. Passionate about mentoring colleagues and educating the organization on data engineering best practices. Maintain a firm understanding of the business long term goals and strategy to inform system implementation - able to see the forest through the trees. Skill Set Required: Experience in productionizing various big data technologies both open source and cloud native, AWS preferred (Kafka, Airflow, Dremio etc). Expertise in data model design with sensitivity to usage patterns and goals - schema, scalability, immutability, idempotency, etc. Expertise in of at least two of the following languages - Python, Go, Scala, Java Experience in handling Large Scale Time Series data Experience in GraphQL, Apollo and Hasura. Track record of choosing the right transit, storage, and analytical technology to simplify and optimize user experience. Real-world experience developing highly scalable solutions using micro-service architecture designed to democratize data to everyone in the organization. Put your passion of CICD to work and enjoy the impact it has to software quality and customers! Live and love Docker, EKS, GitLab, Terraform Build terraform scripts and other deployment and configuration automation Live, laugh, and love some flavor of Agile. With a side of Scrum. Work closely with other teams and individuals to plan, coordinate, and seek feedback. Pitch in where needed as a valued team member. There is no ""i"" in team…but 2 in ""idiot"". Docker, K8, Cloud, microservices, containerization, web services, DB/SQL, etc. etc. (You get it). Strong analytical, problem-solving, and troubleshooting skills. Let's face it, you are one of the smartest people you know. Experienced with modern coding, testing, debugging and automation techniques. Rave about the benefits of CI/CD, unless manual deployments really are your thing. Have a high bar for user experience and quality. You are data driven and customer obsessed. Good communication skills."
Data Engineer,Resonate,"Remote in Reston, VA 20190",https://www.indeed.com/company/Resonate/jobs/Data-Engineer-8d82f24adb54d978?fccid=ecaceeec437644ec&vjs=3,"Data EngineerReston, Virginia This position is fully remote with the option to work in one of our office locations in Reston, Virginia, Washington, D.C., and New York City.About the PositionAs a Data Engineer, you will be working within a team to design and implement highly available data services and pipelines. This is an ideal job if you have proven experience as a technical professional and have already collaborated with teams to deliver production systems based on big data solutions.If you are an engineer passionate for technology who wants to work with a mature, intensely skilled team, values total ownership of your work, and can’t imagine a day without coding, we want to speak to you! We're looking for a creative, focused, technically curious individual who enjoys both design as well as working hands-on with the code.Key Responsibilities Contribute to the design and development of data services, as part of an agile/scrum team Apply best practices in continuous integration and delivery Work with business Product Managers to translate high-level, ambiguous business goals into working software solutions. Design and develop stream and batch processing data pipelines Required Skills & Experience Requirements 3-5 years of experience designing and developing software systems using Java 2+ years of experience in Apache Spark or similar technologies Expertise in enterprise integration patterns and workflow management Experience with cloud technologies (AWS) Experience and practical knowledge of OOP design patterns Solid knowledge of computer science fundamentals Distributed System Development for large-scale applications Experience with continuous integration and testing Experience with agile methodologies and short release cycles Strong attention to detail, good work ethic, ability to work on multiple projects simultaneously, and exemplary communication skills *Desired Qualifications & Experience Requirements* Experience working on a SAAS Product in a commercial environment Experience in digital media, online advertising, or reporting/analytical applications Experience with large scale data warehousing is a strong plus Practical Machine Learning experience is a plus Educational Requirements Technical Bachelor’s Degree required, e.g. Comp Sci, Engineering, Math About Resonate: Resonate is disrupting the marketing and advertising landscape with cutting-edge technology that brings together real-time survey data and insights on over 230 million consumers and online behavioral data all in one platform. Resonate has pioneered a completely new way to identify, understand, and engage highly targeted audiences by uncovering 13,000 individual attributes that identify their underlying values, beliefs, and motivations. We get to the heart of ‘why’ consumers do what they do and the products, companies and causes they support.Resonate is a pioneer in A.I.-driven consumer data & intelligence. The Resonate Ignite Platform™ seamlessly enriches any data with the deepest understanding of the U.S. consumer and then integrates into the marketing ecosystem to drive insights into action. Resonate Elements, our proprietary consumer data set, has more than 13,000 attributes, including the Human Element that describes why consumers choose, buy, or support certain brands, products or causes. Hundreds of leading brands and agencies use Resonate to better understand their customers and prospects and power decision-making from strategy and execution to drive growth and revenue across the customer lifecycle.Headquartered in Reston, Virginia, Resonate is privately held and backed by Argentum Capital Partners, Revolution Growth, Greycroft Partners and iNovia Capital. Resonate has been named a best place to work for the last 7 years.More Information: Find out more about our story at www.resonate.com.Resonate offers a competitive compensation and benefits package. Job Type: Full-time"
Azure Data Engineer,Agama Solutions,"Houston, TX+6 locations",https://www.indeed.com/rc/clk?jk=4347485d05967b4a&fccid=db130263a2af3230&vjs=3,"We are looking for an Azure Security Data Engineer with strong technical expertise in Big Data, who is interested in joining our team to create and manage our data infrastructure and tools, including collecting, storing, processing, and analyzing a range of security data and data systems. As a key member of this team, you will be working as part of the small empowered, customer-centric agile squad to deliver a consolidated and easy to use data platform for reporting and analytics Responsibilities: Collect and process raw data at scale for a variety of projects and initiatives. Read, extract, transform, stage, and load data to selected tools and frameworks as required and requested. Build ingestion pipelines and ETL jobs to consume data feeds from security source systems (e.g. Azure feeds, O365, AD, Syslog, APIs). Designing and implementing Continuous Integration / Continuous Delivery (CI/CD) solutions using company standards for the squad. Creation and managing of data pipelines, transformation, and efficient storage. Build monitoring and alerting mechanisms for data pipelines and transformations. Managing infrastructure for Big Data and data pipelines. Build flexible data solutions that support the ingestion or the consumption needs of our data lake and its customers. You will be a pivotal member of the squad and can shape and support the success of this service. Requirements: Working knowledge of developing using the Azure analytics components including Data Lake, Power BI, Data Factory, Azure Data Explorer, Azure Synapse, Data Warehouse, and Data Bricks. General understanding of Agile and DevOps development methodology and concepts as applied to data-driven analytics projects. Including CI/CD Coding, security testing best practices, and standards. Experience in DevOps in Azure cloud environments. Experience with designing, building, and operating analytics solutions using Azure cloud and serverless technologies. Data Management experience e.g. data profiling, large volume data handling. Experience in automated data-driven testing. General knowledge of scripting languages such as Python, Scala, or PowerShell (at least one of them). General knowledge of database programming including relational (SQL, Maria) and nonrelational (NoSQL, MongoDB, Cassandra) databases. Nice to Have: Experience with security-related data sets. Object-Oriented Programming knowledge is a plus. General understanding of Machine Learning Models."
"Controls Project Engineer, AWS Data Centers Controls Team","Amazon Data Services, Inc.","Herndon, VA+14 locations",https://www.indeed.com/rc/clk?jk=53a5d5893b9ff0af&fccid=fe2d21eef233e94a&vjs=3,"Basic Qualifications 1. B.S. in Electrical, Mechanical, or other related engineering degrees as well as 5 years Controls related experience; or Associates degree and 7 years of Controls related experience; or High School diploma with 10 years of Controls related experience 2. Experience with industrial controls in critical environment (data center, pharmaceutical, manufacturing, oil & gas, petrochemical, laboratory, power, water etc.). 3. A minimum of two (2) years of experience in Controls or Electrical construction project management, coordination with multiple teams or vendors to meet project requirements. Job summary As part of the global controls team, you will work with highly motivated engineers, experts and innovators in the data center industry. You will be responsible for innovating, deploying and optimizing the automation systems within the data centers. Automation systems consist of building management system (BMS) and electrical power monitoring system (EPMS). Using Amazon leadership principles, you will develop new processes and standards while innovating in the controls space. You will also be able to grow your career on technical or management track. As a Controls Project Engineer you will: Manage scope, schedule and execution of BMS and EPMS improvement projects in AWS data centers. Develop BMS & EPMS related projects scope of work, schedule, budget, Level of Efforts (LOE) to the projects requested by various stakeholders. Review controls sequence of operation and provide feedback to design. Financially manage BMS and EPMS improvement projects and assist in procurement related activities including RFQs, responding to RFIs, review of vendors proposal and issuance of purchase orders. Perform comprehensive review of various BMS and EPMS projects submittals. Participate in AWS global on-call schedule to provide immediate BMS and EPMS technical support to in-service data centers. Ensure data center controls are deployed in accordance with scope of work (SOW) and specifications. Provide onsite management of vendor work and training the internal customers. Manage multiple stakeholder deliverables, requirements and navigate difficult situations. Review and provide feedback on mechanical, electrical, and plumbing (MEP) drawings. Attend project related meetings, approve vendor invoices, coordinate with project leaders and regularly report status to Controls and Operations management. Work under tight project timelines and handling multiple projects simultaneously. Interpret controls drawings and wiring diagrams. Interpret and develop controls bill of material (BOM). Understand and modify controls logic programming. Understand and modify graphical user interface. Support Controls related Commissioning activities in the data centers. Frequently visit the data centers during execution of project and development of scope. Preferred qualifications • M.S. in Mechanical, Electrical, or other related engineering degrees as well as 5 years related experience • Six (6) years of experience in project management/coordination (preferably in Controls domain) and/or technical management, preferably as Owner. • Multiple years of experience designing, configuring, programming, installing, troubleshooting or servicing BMS and EPMS applications specific controllers, software’s and networks. • Project Management Professional (PMP) or equivalent. • Experience with management of change. • Knowledge of electrical and/or mechanical systems. • Proficient with Microsoft Office Suite and project management software. • Demonstrated understanding of engineering documentation, electrical diagrams and standard operating procedures. • Excellent communication skills, teamwork, organizational and problem-solving skills. • Ability to create complex dependency schedules. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us."
Data Engineer,SkySlope,Remote in Indiana,https://www.indeed.com/rc/clk?jk=8d5ca5c5bc1aac8b&fccid=b8b33880c81de810&vjs=3,"In 2011 SkySlope started as an idea born at the kitchen table of our CEO, with just him and two others. Headquartered in Sacramento, California, we have since grown out of our previous 3 offices and many of our close to 180 employees are spread all across the United States. Those 180 employees support close to 300,000 users across 5,000 offices nationwide and now in Canada as well. Included in that is 8 out of the 15 largest Real Estate Brokerages in the nation. But, despite being happy with what we’ve achieved we know that as industry leaders in our space there’s a lot of work left to be done. All of the growth and success that has happened is a result of us obsessing over building cutting edge software that makes the Real Estate world a better place. We know this only happens by hiring people who don’t just come up with out of the box ideas but hiring people who actually see those ideas through and bring them to life. As we’ve grown, we’ve been fortunate enough to hire plenty of people who possess that quality and realize it’s equally important to hire people who can pair that skill with empathy, collaboration, and a keen sense of urgency. If you’re looking to join a company where you can have real impact and surround yourself with an incredible team of people then look no further. Data engineers at SkySlope develop, test, and deploy new and improved software, while managing deliverables in a fast-paced, agile work environment. They are expected to continue promoting their talent via self-learning and collaboration with our senior/staff engineers to pursue advancing their own seniority in the company. Essential Functions Optimize MS SQL OLTP databases including schema, stored procs, and views to increase performance and reliability of connected applications - all with zero downtime Understand, design, and support complex data structures Logical and physical database design Develop SQL stored procedures and views and optimize SQL processes Design and develop processes to support large scale systems for data processing, transformation, data quality, reporting, and analytics. Develop and maintain software through its full lifecycle Continually expand your engineering skills and techniques Increase domain knowledge about SkySlope and our clients Commit to team success by being an effective collaborator Manage project priorities, deadlines, issues, and deliverables Actively participate in discussions around process and solutions Contribute to the overall architecture of systems Communicate honestly, respectfully, and candidly with everyone Required Qualifications 4+ years database development experience DBA experience required (configure/tune/troubleshoot) Experience designing and optimizing OLTP databases in MS SQL. Packaging and release management exposure Source control (Git, TFS, SVN, etc.) Experience in an Agile environment AWS EMR Spark and the Python plugin, pyspark Experience with file storage, such as parquet or ORC. Preferred Qualifications Cloud services (AWS Lambdas, RDS, S3, EC2, CloudFormation, etc.) AWS DMS NoSQL experience (DynamoDB, Redis, etc.) Continuous Integration (CI) (Jenkins, CodePipeline, etc.) C# (.NET Core and Framework) Unit and Integration Testing Data warehousing experience MPP database experience (Redshift, Snowflake, Vertica, etc.) Knowledge of new and emerging technologies Has an intermediate understanding of development best practices and proficient writing code. Uses and understands tools needed to debug and diagnose issues in a test and/or complex production environment. Understands the scope of large features. Has a good understanding of all their product components. Performs complex programming tasks. Participates in code reviews and can sign off on small features. Writes and executes test plans. Can write functional specifications for small features. Given a medium to large understood problem, can design and implement a solution. Shows initiative and offers assistance when needed without being asked. Delivers feedback in a constructive manner. Provides guidance to entry-level engineers. Works well with technical leads, incorporating feedback as needed. Help Perks & PTO $1000 referral bonuses 15 PTO days per year 16 paid holidays per year (5 floating to be used at any time) Paid day off on your birthday Insurance Offerings Medical, Dental and Vision Insurance Short and Long Term Disability Insurance Company paid Life Insurance Flexible Spending Account 4 Weeks Paid Parental Leave Retirement and Investment 401k + match Employee Stock Purchase Plan opportunities"
"Lead Data Engineer (SSIS, Tableau and PowerBI)",TDG,"New York, NY",https://www.indeed.com/rc/clk?jk=7eb5b0c8dab4b21a&fccid=43cfb8a6a5aec861&vjs=3,"Role and Responsibility Details: Working knowledge of relational databases MS SQL server. T-SQL programming skills (queries, procedures, functions, etc.) and Writing and optimizing queries in T-SQL Hands on experience of database design, data modelling Should have expertized in SSIS Working knowledge of Tableau reports Experience in Microsoft Power BI Good to have Azure exposure. Strong understanding of database structures Develop solution architecture using business stakeholder's requirements and transforming them into conceptual data models. Demonstrated expertise of data modelling and data warehouse methodologies and best practices. Understanding in-depth concepts of RDBMS Understanding of database structure principles Expertise in creating technical and Architecture documentation (ex: HLD/LLD) Identify, evaluate and recommend hardware or software technologies to achieve desired database performance. Proven ability to rapidly analyse and design solution architecture in client proposals is an added advantage A good, applied understanding of the end-to-end data process development life cycle. Design databases to support business applications, ensuring system scalability, security, performance and reliability. Strong analytical and problem solving skills Ability to work effectively independently and/or as part of a team. Agile scrum experience"
Data Engineer,Riiid Labs,"Hybrid remote in Mountain View, CA+1 location",https://www.indeed.com/rc/clk?jk=7fc542aa83eaca26&fccid=933989f3b0ffe928&vjs=3,"Location: Mountain View, CA Here at Riiid Labs, as an AI SaaS organization, we partner with many global leaders in numerous industries to tailor our verified AI technology to the needs of students, educators, organizations and their employees, and many more throughout the world because we believe that there should be no limit in learning! Riiid Labs’ believes that everyone should have access to personalized education & learning platforms regardless of socio-economic status, age, race, gender, identity, or educational history. We help learners realize their goals in the fastest, most efficient way! Check out “Our Story” to learn more about what it means to be a part of our organization and what Riiid Labs hopes to accomplish! Riiid Labs is growing! - Join us as we continue to expand Riiid Labs and its products/solutions further into the US and Global educational & workforce/training development industries! To date, we have received $175M in funding from Softbank's Vision Fund 2, with over $250M in total funding. The Role/What you’ll do: We are looking for a Data Engineer to join our new project that requires large scale data analysis. You will be responsible for developing our data acquisition pipeline, optimizing multimodal data collection framework, and implementing APIs for accessing data storage. You will integrate unstructured data from different sources and create a stable data transformation pipeline. The ideal candidate is an experienced data pipeline builder who is enthusiastic on optimizing data especially in the education domain. They must be self-directed and comfortable supporting the data needs of multiple teams and products. Create and maintain an optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Collaborate with other teams across national boundaries to build centralized data storage solutions. Keep our data separated and secure across national boundaries through multiple data sources Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader Work with data and analytics experts to strive for greater functionality in our data systems What you’ll work on: Phone/Web Based AI powered tutor applications that support and enhance a student’s education. AI SaaS platforms supporting educators' efforts to enhance education for students in and out of the classroom. AI API integration projects to assist organizations with optimizing their workforce development, corporate training, and online learning systems. What you bring to Riiid Labs: At least 2 years of professional development experience. Demonstrated expertise in at least one of the following: Spring, Spring Boot, Node.js, Nest.js. Hands-on experience with at least one of the following programming languages: Kotlin, Java, JavaScript, TypeScript. Knowledge of RESTful web services. Experience with relational databases (PostgreSQL, MySQL).Experience with at least one of the following cloud platforms: AWS, Azure, GCP. Desire to refine your craft by proactively seeking out ways to hone your skill sets. Strong communication skills to effectively communicate with stakeholders and team. What Riiid Labs is offering to you! Hybrid Schedule (remote and in-person). Career Growth - opportunity to professionally grow within a rapidly expanding company. Competitive Salaries and Compensation Packages. Flexible Time Off Policy - allows you to take time off as you need it, without having to accrue a capped number of hours per year 100% paid benefit premiums (medical, dental, vision) for individual and family. 401K with 4% Match. Opportunity to travel and work with our Engineering Team at Riiid, in Seoul, Korea. Ability to have your voice & opinions heard within a small organization that is growing!Family oriented and friendly environment. Even if you don’t meet all of the qualifications, we still encourage you to apply! Riiid Labs, Inc. is an equal opportunity employer. In accordance with anti-discrimination law, it is the purpose of this policy to effectuate these principles and mandates. Riiid Labs, Inc. prohibits discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law. Riiid Labs, Inc. conforms to the spirit as well as to the letter of all applicable laws and regulations."
"Data Security Engineer - Dallas, TX",HEB,"Dallas, TX 75207 (Design District area)",https://www.indeed.com/rc/clk?jk=50b0f0818191444f&fccid=c629e32155ebd42c&vjs=3,"Overview: H-E-B is one of the largest, independently owned food retailers in the nation operating over 420+ stores throughout Texas and Mexico, with annual sales generating over $34 billion. Described by industry experts as a daring innovator and smart competitor, H-E-B has led the way with creative new concepts, outstanding service and a commitment to diversity in our workforce, workplace and marketplace. H-E-B offers a wealth of career opportunities to our 145,000+ Partners (employees), competitive compensation and benefits program and comprehensive training that lead to successful careers. Responsibilities: Our Partners thrive The H-E-B Way. As a Data Security Engineer, you would have a… HEART FOR PEOPLE… you have a passion for mentorship and guidance, and love for the direct person-to-person interactions that create strong bonds between teams HEAD FOR BUSINESS… you have an ownership mentality and a consistent track record of timely delivery of high-quality software PASSION FOR RESULTS… the ability to guide the discussion, remove roadblocks, and provide guardrails for your team as they identify challenges and propose solutions ROLE Data Security Engineers design and implement best-of-class solutions to improve the security posture of H-E-B technical controls and processes for Data Protection. Data Security Engineers are the Champions of Data Protection at H-E-B and will provide consultative services and work with internal business team members and external vendors to collect requirements, design specifications, and create solutions that improve and are aligned with H-E-B’s security strategy. Works with data governance and retention (Retention policies, data governance reports and dashboards, information holds). Works with Data Loss Prevention (DLP policies, data classification, sensitive information types). Works to ensure effective and measurable device control, encryption, and file integrity controls. Collaborate with Security, Engineering and Data teams to incorporate strong security controls, apply security best practices in our development life cycle, and mitigate risks and security vulnerabilities. Promote and drive the implementation of a data security architecture that supports Engineering’s goals and deliverables, through strategy, design, requirements, and code. Reviews audit logs, alerts and reports relevant to data protection scenarios and assesses for improvements. Works with H-E-B teams to educate and ensure understanding of H-E-B’s technical implementation of data security controls and solutions, and ensure gaps, dependencies and defects are identified and addressed. Works with H-E-B teams and external security solution vendors to scope, configure and validate solutions to support H-E-B’s data protection posture. Establishes plans and protocols to protect data and information systems against unauthorized access, modification, and/or destruction. Champions data protection amongst H-E-B partners, sharing and promoting security awareness and safe operating procedures. Researches and remains up to date with emerging threats and solutions relevant to data protection and its implementations. Maintains current knowledge of industry trends and standards in information security. Mentors team members. Develops and documents standards and best practices. Designs, develops, and documents network security architecture patterns as code. Participates in meetings with the Data Governance Team, and other departmental meetings, as needed. REQUIRED Minimum of five (5) years of development and support experience with system and security solutions in medium to large enterprises. Familiarity with File Integrity and DLP technologies. Working experience with production Big Data, Data Factories, Data Warehouses and the application of security classifications and controls in those environments. Experience in IT systems and data security policies, standards, industry trends, and techniques. Experience working with hybrid cloud infrastructures. Demonstrated experience designing, developing, configuring, implementing, and managing technical implementations and changes at enterprise scale with diverse solutions from multiple vendors. Experience with PKI, digital certificates, secrets management and vaulting, and platform/OS security. Able to handle highly confidential information in a strictly professional manner. Demonstrate a logical and structured approach to time management and task prioritization. Demonstrate a high level of communication skills, verbal and written. Familiarity with Agile and other project management methodologies. Ability to work well under pressure and have great organizational and interpersonal skills. Demonstrated experience working IT, Security, and R&D teams to achieve a coordinated privacy and security practice. RECOMMENDED A Bachelor’s degree in Computer Science or Software Engineering. Experience working in a highly regulated industry, ensuring compliance with GDPR, CCPA, HIPAA and other regulatory requirements. One or more professional security certifications such as CISSP, CISM, GCIH, CASP, AWS Security, or equivalent. Certified Data Management Professional (CDMP) Three (3) or more years’ experience in Information Security, IT Risk Management, or IT Compliance. Strong experience with GCP and Azure cloud security and preferably hands-on experience with AWS. Experience with DataBricks, PostgreSQL, Kafka, and other RDBMs Proficiency in languages such as Golang, Node.js, Python, Java. Knowledge of containerization, CI/CD pipeline, and orchestration with Kubernetes ISSEC3232"
"Software Engineer, Data Platform",Notion,"San Francisco, CA 94110 (Mission area)",https://www.indeed.com/rc/clk?jk=c650bb81e99f0002&fccid=7095ffd299c81ef3&vjs=3,"About Us: We're on a mission to make it possible for every person, team, and company to be able to tailor their software to solve any problem and take on any challenge. Computers may be our most powerful tools, but most of us can't build or modify the software we use on them every day. At Notion, we want to change this with focus, design, and craft. We've been working on this together since 2016, and have customers like Pixar, Mitsubishi, Figma, Plaid, Match Group, and thousands more on this journey with us. Today, we're growing fast and excited for new teammates to join us who are the best at what they do. We're passionate about building a company as diverse and creative as the millions of people Notion reaches worldwide. About The Role: Do you want to help define what data means at Notion? We are looking to hire engineers with a vision for what our data tooling and infrastructure should look like as we scale, and then to build and operate those systems over time. You'll partner with teams all around the company to empower every function with data and insights. You'll help evolve Notion and the infrastructure it uses to make sure that decisions can always be driven by high quality data. What You'll Achieve: You'll design and set up the foundations that enable everyone in the company - data scientists, finance, customer success, etc. - to effectively self-serve and leverage data. This can involve scalable ingestion infrastructure and tooling for data model, dashboards, query engines, experimentation and many other things! You'll articulate best practices around logging and ingestion frameworks and implement the changes to make those practices a reality. You'll implement monitoring and alerting systems to guarantee data quality and consistency. You'll determine the best ways to handle Notion's unique data model and usage patterns to derive insights and bring intelligence to product features like search and discovery. You'll create tools to enable the data science team to produce insights quickly, and help them apply and generalize statistical and econometric models efficiently across large datasets. Skills You'll Need to Bring: Team player: For you, work isn't a solo endeavor. You have worked cross-functionally to establish the right overarching data architecture for a company's needs, to build data ingestion (real-time & batch), and to provide guidance on best data practices for the business. Data expertise: You have built and managed highly scalable data processing solutions (e.g. Spark, Flink), data lakes or warehouses (e.g. Snowflake, Hive), authored queries (SQL), used workflow management (e.g. Airflow, Luigi), and have experience maintaining the infra that supports these. Thoughtful problem-solving: For you, problem-solving starts with a clear and accurate understanding of the context. You can decompose tricky problems and work towards a clean solution, by yourself or with teammates. You're comfortable asking for help when you get stuck. Pragmatic and business-oriented: You care about business impact and prioritize projects accordingly. You're not just going after cool stuff—you understand the balance between craft, speed, and the bottom line. Put users first: You think critically about the implications of what you're building, and how it shapes real people's lives. You understand that reach comes with responsibility for our impact—good and bad. Not ideological about technology: To you, technologies and programming languages are about tradeoffs. You may be opinionated, but you're not ideological and can learn new technologies as you go. Empathetic communication: You communicate nuanced ideas clearly, whether you are explaining technical decisions in writing or brainstorming in real time. In disagreements, you engage thoughtfully with other perspectives and compromise when needed. Nice to Haves: You've built out data infrastructure from, or nearly from, scratch at a fast-growing startup. You've led or managed a Data Engineering / Platform / Infrastructure Team. You've owned or managed mission-critical datasets. Our customers come from all walks of life and so do we. We hire great people from a wide variety of backgrounds, not just because it's the right thing to do, but because it makes our company stronger. If you share our values and our enthusiasm for small businesses, you will find a home at Notion. Notion is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Notion considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Notion is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation made due to a disability, please let your recruiter know. #LI-Onsite"
"Senior Software Engineer, TikTok Data Access",TikTok,"San Francisco, CA+6 locations",https://www.indeed.com/rc/clk?jk=cf734bd5983de457&fccid=caed318a9335aac0&vjs=3,"Job Description TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo. TikTok Data Access team is responsible for data access control to all online TikTok data, managing data schema in code for attribution and governing, layout foundation for modernized data tracking, deletion, retention, and linkage. We are building an Infrastructure as Code experience for all data models and storage systems and help automate the development and deployment process by providing frameworks and systems based on metadata and schema. We are looking for motivated individuals interested in complex engineering challenges around one of the most important aspects of TikTok. You will have the opportunity to work closely with a multidisciplinary team of Mobile Engineers, Frontend Engineers, Site Reliability Engineers, Data Engineers, and Data Scientists in a high-impact and fast-paced environment. As a Senior Software Engineer on our TikTok Data Access team, you will: Lead some of critical domains of data access, such Object-Relational Mapping, variable storage adapters and privacy and safety policy and management Design new massive-scale software systems that demand low latency, high reliability, and resilience against disaster, by applying the concept of Infrastructure as Code and Schema as Code. Develop systems to handle the next phase of growth TikTok's business and ensure high stability and performance. Collaborate with multiple cross-functional teams to identify new investments, solve critical problems, and deliver high-quality work in rapid product development. Requirements BS Degree in Computer Science or related major, with at least 5 years of working experience. Proficient in at least one OOP language, such as Java, Go, C++, Python, etc. Experience in building backend services for large-scale consumer-facing applications. Familiar with common open source distributed middleware and components such as MySQL, MongoDB, Redis, and MQ. Understanding of design ideas for distributed system and architecture, including but not limited to service-oriented, asynchronous, highly available, scalable, etc. Deep understanding of computer architectures, data structures, and algorithms. Good communication and collaboration skills. TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too. TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to us at usrc@tiktok.com."
Senior Data Solutions Engineer,VSP Global,Remote,https://www.indeed.com/rc/clk?jk=6fbb778832303fd8&fccid=274e39ee4b679fc5&vjs=3,"The Sr. Data Solutions Engineer works directly with business stakeholders to design data and analytics capabilities that support business strategies and to develop the data models and structures that enable data-driven solutions. The Sr Data Solutions Engineer develops data models and structures that can be used within the business to find data driven solutions. Work with business stakeholders to identify how data can be leveraged to improve decision making Work with technology teams to analyze data requirements (functional and non-functional) and provide data architectural design solutions for business and technology initiatives Assess the effectiveness and accuracy of data sources and data gathering techniques Design data structures, data models and data pipelines, leveraging the support of subject matter experts to deliver business intelligence / data science capabilities for the organization Create data models at all levels including conceptual, logical, and physical Collaborate within an agile, multi-disciplinary team of data engineers, data analysts, UX designers and scrum master to deliver solution Work with Data Scientists on optimizing batch and real-time processes for feature engineering, training models, and serving predictions Research, promote, and develop data architecture best practices, guidelines, procedures and scalable frameworks. Participate in architecture, governance and design reviews Participate in evaluations of existing and emerging analytical technologies and provide recommendations Minimum Qualifications Bachelor’s degree in computer science, data science, statistics, economics or related functional area; or equivalent experience Excellent written and verbal communication skills with the ability to gather requirements and effectively communicate technical concepts and ideas to all levels of employees and management 6 years’ experience working with end-users in development of analytical capabilities 6 years of hands-on experience in the data space spanning data modeling, SQL-based database management systems, integration, ETL / data pipeline design and data visualization Experience years expert level SQL coding experience Preferred Skills Significant experience in dimensional modeling Prior experience using Snowflake for data warehousing is beneficial, as is prior experience with Data Vault modeling Good interpersonal skills that support effective collaboration with business colleagues Capable of balancing solution design with effective modeling techniques Familiarity and strong technical understanding of REST APIs is valuable Python experience is not required but beneficial #LI-REMOTE #LI-VISIONCARE VSP Vision is an equal opportunity employer and gives consideration for employment to qualified applicants without regard to age, gender, race, color, religion, sex, national origin, gender identity, sexual orientation, disability or protected veteran status. We maintain a drug-free workplace and perform pre-employment substance abuse testing."
Virtual Data Room Engineer- VP,Citi,"Irving, TX",https://www.indeed.com/rc/clk?jk=15a859d010819ab5&fccid=5bcd1ef0a7f4fb99&vjs=3,"About Citi: Citi, the leading global bank, has approximately 200 million customer accounts and does business in more than 160 countries and jurisdictions. Citi provides consumers, corporations, governments, and institutions with a broad range of financial products and services, including consumer banking and credit, corporate and investment banking, securities brokerage, transaction services, and wealth management. As a bank with a brain and a soul, Citi creates economic value that is systemically responsible and in our clients’ best interests. As a financial institution that touches every region of the world and every sector that shapes your daily life, our Enterprise Operations & Technology teams are charged with a mission that rivals any large tech company. Our technology solutions are the foundations of everything we do from keeping the bank safe, managing global resources, and providing the technical tools our workers need to be successful to designing our digital architecture and ensuring our platforms provide a first-class customer experience. We reimagine client and partner experiences to deliver excellence through secure, reliable, and efficient services. Our commitment to diversity includes a workforce that represents the clients we serve from all walks of life, backgrounds, and origins. We foster an environment where the best people want to work. We value and demand respect for others, promote individuals based on merit, and ensure opportunities for personal development are widely available to all. Ideal candidates are innovators with well-rounded backgrounds who bring their authentic selves to work and complement our culture of delivering results with pride. If you are a problem solver who seeks passion in your work, come join us. We’ll enable growth and progress together. About Our Team: Citi Technology Infrastructure (CTI) provides the critical technical foundation for Citi’s operations and is responsible for delivering reliable IT solutions, scalable infrastructure services, and secure capabilities while creating a trusted customer experience and enabling Citi’s workforce to be the best for our clients. Making the bank simpler, greener, and better connected while powering it with trusted, well-secured data, and automating policy enforcement through code are all at the heart of our refreshed global strategy. Data Quality, Simplification, Environmental Stability, Automation, and Service Excellence are the key pillars and priorities on our strategic journey. CTI Business Operations enables technology managers across the organization to effectively manage their resources and deliver their commitments in support of CTI's strategy, goals, and performance metrics. This is achieved through the provision of commercial aspects of CTI, analytics and reporting (including expense and productivity), workforce, real estate, supplier management, leadership and talent development, including entry level and pipeline programs, and employee engagement and communications. The Employee Engagement, Product Marketing, and Change Adoption Team manages and strengthens CTI’s internal employee engagement, culture, onboarding, as well as talent and development initiatives. The team elevates knowledge and understanding of organizational changes and structures within CTI, ensures awareness of technology strategies across CTI and Citi, and drives user adoption through change management and impactful technology marketing. In CTI, we are focused on delivering the best for our clients, and we know that to do this we need a talented team with diverse experiences, backgrounds and skills.The Engineering Lead Analyst is a senior level position responsible for leading a variety of engineering activities including the design, acquisition and deployment of hardware, software and network infrastructure in coordination with the Technology team. The overall objective of this role is to lead efforts to ensure quality standards are being met within existing and planned framework. Job Requirements: Responsible for engineering certification of Virtual Data Rooms (specifical Intralinks in the short term). Design and integration of necessary security and compliance controls and any operational automation requirements. Collaborate with Operation and Product Management teams within End User Services to delivery Product Inception and maintain quality of service and grow to continuously meet business needs. Effectively apply Citi methodologies and enforce engineering standards. Oversee infrastructure and application testing against internal standards. Prepare and present roadmaps and engineering designs to architecture committees and senior management. Respond to user escalations and issues as Level 4. Own the technical vendor relationship. Contribute to define and implement best practices and process for the department. Ensure transparency and consistency across teams in the region and globally. Ensure role adheres to best practices and corporate processes. Set measurable / challenging goals for self-ensuring continuous improvement and self-development. Qualifications/Skills: Technology engineering lifecycle experience. Understanding and experience of introducing new services to highly regulated environments. Understanding of enterprise compliance, security, risk and control frameworks and requirements. Understanding of SaaS platforms in an enterprise environment. Experience with Virtual Data Room / Collaboration service technologies. - Job Family Group: Technology - Job Family: Systems & Engineering - Time Type: Full time - Citi is an equal opportunity and affirmative action employer. Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi. View the ""EEO is the Law"" poster. View the EEO is the Law Supplement. View the EEO Policy Statement. View the Pay Transparency Posting - Effective November 1, 2021, Citi requires that all successful applicants for positions located in the United States or Puerto Rico be fully vaccinated against COVID-19 as a condition of employment and provide proof of such vaccination prior to commencement of employment."
Data Engineer (Remote Availability),Lamb Weston,"Remote in Eagle, ID 83616",https://www.indeed.com/rc/clk?jk=229e5ab121146b78&fccid=1f4c92b4e554ec3b&vjs=3,"Title: Data Engineer (Remote Availability) Location: Eagle, ID Country: United States of America About Lamb Weston Lamb Weston is a leading supplier of frozen potato, sweet potato, appetizer and vegetable products to restaurants and retailers around the world. For more than 60 years, we’ve produced innovative, inventive products that make life better for our customers and their customers. Job Description Summary Lamb Weston is pursuing a modernization of its data assets and analytics environment. With executive support, Lamb Weston is building out its data assets to enable next generation analytics by strengthening its historical and diagnostic activities while enabling forward looking predictive, predictive, management science and optimization activities across it business functions. This role plays an exciting and central role in the success of this mission. The successful candidate will be closely aligned with business partners and be empowered to build enterprise business focused data models to drive tangible and material business value. Job Description Design, builds and maintain data warehouses (existing and from scratch) using Data Vault methodology Design and implement efficient data pipelines (ETLs) to integrate data from a variety of sources into Data Warehouse as well as data model changes that align with warehouse standards and backfill or other warehouse data management processes Evaluates data design, database architecture, metadata and repositories for performance and effective design Develop scalable ETL data pipelines with python, SQL, and AWS cloud tools. Optimization of existing SQL queries to improve reliability and performance. Develop and execute testing strategies to ensure high quality warehouse data Provide documentation, training, and consulting for data warehouse users Work with cross functional stakeholders to design and architect data warehouse and analytics solutions Perform requirement and data analysis in order to support warehouse project definition Provide input and feedback to support continuous improvement in team processes Analyze data to ensure information is accurate and reconcilable to its source of origin. Perform quality assurance testing as appropriate prior to releasing data/information/reports into production / end users. Basic & Preferred Qualifications Requires minimum BS in Computer Science or related field or combination of education and experience sufficient to perform duties at an experienced level Must have a minimum of 3 years’ experience (in addition to education) in a technical environment with data warehouse design and implementation. 3 Years of programming experience in SQL, Java or Python Experience modeling in Kimball or Data Vault methodologies Requires demonstrated ability to work in a team and collaborative environment Experience with AWS tooling, Snowflake are preferred but not necessary. Strong communication and interpersonal skills Love of learning new technologies and having fun Ability to travel 10% of the time. Industry-Competitive Benefits Coupled with our compensation and bonus incentive programs, our benefits deliver rewards that are market competitive. Some of the most attractive elements of our benefit programs include: Health Insurance Benefits - Medical, Dental, Vision Flexible Spending Accounts for Health and Dependent Care, and Health Reimbursement Accounts Well-being programs including companywide events and a wellness incentive program Paid Time Off Financial Wellness – Industry leading 401(k) plan with generous company contributions, Financial Planning Services, Employee Stock purchase program, and Health Savings Accounts, Life and Accident insurance Family-Friendly Employee events Employee Assistance Program services – mental health and other concierge type services Benefits may vary based on location, job role/level, job status, and/or the terms of any applicable collective bargaining agreements. Job Requisition ID: Req-222390 Time Type: Full time The state of Colorado requires Lamb Weston to include a reasonable estimate of the compensation range for this role. This compensation range is specific to individuals applying to work remotely from Colorado and takes into account a number of factors. A reasonable estimate of the range for this role is $42,680 - $137,470. Actual salaries may vary and may be above or below the range based on various factors, including, but not limited to work location, experience and expertise. Lamb Weston is an Equal Opportunity Employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status or any other protected factor under federal, state or local law"
Test Data Management Engineer,General Motors,"Austin, TX",https://www.indeed.com/rc/clk?jk=3cc8d341ebff55ee&fccid=116680a29a847a70&vjs=3,"Job Description This is a Hybrid position within our IT Organization. The role will allow employees to work offsite but will also require onsite work based on business needs. The selected candidate will be expected to commute to the innovation center to which they are assigned as their primary GM facility. Relocation may be provided."" For all external applicants, we are targeting a start date on or after January 10th 2022 for this position. In recent years, GM Information Technology has successfully executed the largest IT transformation in the history of the automotive industry, fully insourcing what once was a nearly completely outsourced IT function. Today GM IT is a dynamic and fast paced organization that designs, develops and maintains all IT infrastructure, applications and solutions enabling GM's global operations. From designing and building the next generation of electric and other vehicles to developing a world-class GM experience for our dealers and customers, GM IT is driving real change in the most iconic automaker on the planet. Our team delivers unique enterprise-wide IT solutions in cutting-edge technologies such as mobility, telematics, mission-critical business systems, supercomputing, cloud, vehicle engineering and real-time computing. We offer challenging positions for passionate professionals looking to advance their careers and be a part of an IT organization focused on innovation, speed and business value. The TDM Engineer, is a technical expert in analysis, design, coding and debugging of TDM provisioning solutions using TDM methodologies and commercial TDM products like IBM Optim. Required to perform Test Data Management functions of Data Setup on existing applications, developing methods for day-to-day data provisioning, build frameworks for Data Mining and Data Reservation, architect TDM (Test Data Management) solutions for data provisioning for Domain and Enterprise wide applications including Data Discovery, Data Masking and Data Subset and architect Gold Copy databases and Data Stores for quick data provisioning. RESPONSIBILITIES: Data model analysis of large databases Create subset plan and build subset queries for large databases Sensitive data analysis for PHI, PCI & PII data for large databases Build Data Masking Rules and Seed lists Develop and Build Data Subset, Data Masking and Data Generation jobs using IBM Optim Build custom code as needed to support TDM solution Build and maintain Gold copy databases REQUIREMENTS: 5+ Years of experience as TDM Engineer or ETL Developer Extensive knowledge of SQL, test data design and test data management tools with a proven history of providing effective test data solutions Experience with data masking / obfuscation Experience in integrating with DevOps Experience with any commercial TDM tool like Informatica TDM or IBM Optim or Talend TDM or Delphix or FileAID EX or CA TDM Proficient in Java, UNIX Shell Scripting & Windows Scripting Knowledge of relational database design, programming and information retrieval techniques; Solid experience in writing complex SQL queries, insert/update statements Expertise on Oracle, SQL Server, DB2 PREFERRED: Experience with IBM Optim Additional Job Description PREFERRED: Experience with IBM Optim 5+ Years' experience The successful candidate will play a key role in expanding and modernizing test data management framework and processes and will be accountable for designing, building, and implementing TDM solutions About GM Our vision is a world with Zero Crashes, Zero Emissions and Zero Congestion and we embrace the responsibility to lead the change that will make our world better, safer and more equitable for all. Why Join Us We aspire to be the most inclusive company in the world. We believe we all must make a choice every day - individually and collectively - to drive meaningful change through our words, our deeds and our culture. Our Work Appropriately philosophy supports our foundation of inclusion and provides employees the flexibility to work where they can have the greatest impact on achieving our goals, dependent on role needs. Every day, we want every employee, no matter their background, ethnicity, preferences, or location, to feel they belong to one General Motors team. Benefits Overview The goal of the General Motors total rewards program is to support the health and well-being of you and your family. Our comprehensive compensation plan incudes, the following benefits, in addition to many others: Paid time off including vacation days, holidays, and parental leave for mothers, fathers and adoptive parents; Healthcare (including a triple tax advantaged health savings account and wellness incentive), dental, vision and life insurance plans to cover you and your family; Company and matching contributions to 401K savings plan to help you save for retirement; Global recognition program for peers and leaders to recognize and be recognized for results and behaviors that reflect our company values; Tuition assistance and student loan refinancing; Discount on GM vehicles for you, your family and friends. Diversity Information General Motors is committed to being a workplace that is not only free of discrimination, but one that genuinely fosters inclusion and belonging. We strongly believe that workforce diversity creates an environment in which our employees can thrive and develop better products for our customers. We understand and embrace the variety through which people gain experiences whether through professional, personal, educational, or volunteer opportunities.GM is proud to be an equal opportunity employer. We encourage interested candidates to review the key responsibilities and qualifications and apply for any positions that match your skills and capabilities. Equal Employment Opportunity Statements The policy of General Motors is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's age, race, color, sex, religion, national origin, disability, sexual orientation, gender identity/expression or veteran status. Additionally, General Motors is committed to being an Equal Employment Opportunity (EEO) Employer and offers opportunities to all job seekers including individuals with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, email us atCareers.Accommodations@GM.com. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying."
(USA) Data Engineer III,Walmart,"Bentonville, AR 72712+21 locations",https://www.indeed.com/rc/clk?jk=6ffa0bbb812da775&fccid=822bc5d9a49270ea&vjs=3,"Position Summary... What you'll do... At Walmart, we help people save money, so they can live better. This mission serves as the foundation for every decision we make and drives us to create the future of retail. We can't do that without the best talent - talent that is innovative, curious, and driven to create exceptional experiences for our customers. Do you have boundless energy and passion for engineering data used to solve dynamic problems that will shape the future of retail? With the sheer scale of Walmart's environment comes the biggest of big data sets. As a Walmart Data Engineer, you will dig into our mammoth scale of data to help unleash the power of retail data science by imagining, developing, and maintaining data pipelines that our Data Scientists and Analysts can rely on. You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way. You will partner with Data Scientists, Analysts, other engineers and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers' lives. You'll make an impact by: Problem Formulation: Identifies possible options to address the business problems within one's discipline through analytics, big data analytics, and automation. Applied Business Acumen: Supports the development of business cases and recommendations. Owns delivery of project activity and tasks assigned by others. Supports process updates and changes. Solves business issues. Data Governance: Supports the documentation of data governance processes. Supports the implementation of data governance practices. Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function. Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current data science and analytics trends. Data Source Identification : Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data. Data Modeling: Analyzes complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyzes data-related system integration challenges and proposes appropriate solutions. Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports. Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical, and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbooks, and provides timely progress updates. You'll sweep us off our feet if you: Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales. Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities. Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices. The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process. What You'll Bring: Bachelor's degree in Computer Science and 4 years' experience OR Master's degree in Computer Science and 2 years' experience in the following ETL technologies (e.g., Airflow, Automic, SSIS, DataStage, etc) Relational Database platforms (e.g., SQL Server, MySQL, Informix, Oracle, etc) Troubleshooting skills in operating systems like Unix, Windows and in Containers Strong Programming skills in Java, SQL, and Python/Scala L1/L2/L3 Operational support Experience in Big Data Platforms (e.g., Spark, Hadoop HDFS, BigQuery, Cloudera) Working experience in handling large volumes of data. Experience in handling telemetry data in a plus Self-directed, well organized and have good follow-up skills Excellent written and oral communication skills Strong interpersonal skills Proven ability to drive results, especially in a matrixed or influence based environment Driven to work with the teams to dig into data, processes, and issues Benefits & Perks Beyond competitive pay, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more. Equal Opportunity Employer Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, ideas, and opinions - while being inclusive of all people. About Global Tech Imagine working in an environment where one line of code can make life easier for hundreds of millions of people and put a smile on their face. That's what we do at Walmart Global Tech. We're a team of 15,000+ software engineers, data scientists and service professionals within Walmart, the world's largest retailer, delivering innovations that improve how our customers shop and empower our 2.2 million associates. To others, innovation looks like an app, service or some code, but Walmart has always been about people. People are why we innovate, and people power our innovations. Being human-led is our true disruption. We're virtual Working virtually this year has helped us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives and spend less time commuting. Today, we are reimagining the tech workplace of the future by making a permanent transition to virtual work for most of our team. Of course, being together in person is an important part of our culture and shared success. We'll collaborate in person at a regular cadence and with purpose. Minimum Qualifications... Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. Option 1: Bachelor's degree in Computer Science and 2 years' experience in software engineering or related field. Option 2: 4 years' experience in software engineering or related field. Option 3: Master's degree in Computer Science. Preferred Qualifications... Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications. Data engineering, database engineering, business intelligence, or business analytics, Master's degree in Computer Science or related field and 2 years' experience in software engineering or related field Primary Location... 805 SE MOBERLY LN, BENTONVILLE, AR 72712, United States of America"
Big Data Engineer,Cotocus,"Sacramento, CA 95822 (Airport area)+2 locations",https://www.indeed.com/rc/clk?jk=bfa59c5316baa518&fccid=67014df0f8d8ef3d&vjs=3,"Job Description We are looking for an experienced and passionate Data Engineer with 6+ years of experience in building scalable, high-performance distributed systems that deal with large data volumes. You will be responsible for development work on all aspects of Big Data, data provisioning, modeling, performance tuning and optimization. Responsibilities: Work closely with business and dev teams to translate the business/functional requirements into technical specifications that drive Big Data solutions to meet functional requirements. Participate in software design meetings and write technical design documents. Design, develop, implement and tune large-scale distributed systems and pipelines that process large volumes of data; focusing on scalability, low -latency, and fault-tolerance in every system built. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Maintain application stability and data integrity by monitoring key metrics and improving code base accordingly. Understand & maintain existing codebase by regular re-factoring and applying requested fixes and features. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Should be flexible to learn new technology / required frameworks. To apply for this position, please upload your resume at : DevOpsSchool.com/Cv We prefer to select professionals those who are Certified in their domain from ""Official Certification company's"" like RedHat, Chef Software Inc, Puppet, Docker, Google, Amazon Inc. etc. or authorized training partners like scmGalaxy Inc. DevOpsCertification.co etc."
Data Engineer,Adobe,"Lehi, UT 84043+5 locations",https://www.indeed.com/rc/clk?jk=0ee328d7778e831f&fccid=f89deb5a97c7738a&vjs=3,"locations Lehi San Francisco Austin San Jose Remote Texas View All 6 Locations time type Full time posted on Posted 30+ Days Ago job requisition id R124519 Our Company Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours! Adobe Customer Solutions is looking for a full time Data Engineer with experience in building data integrations using AWS technology stack as part of the team's Data as a Service portfolio for Adobe’s Digital Experience enterprise customers. Customer facing Engineers who enjoy tackling complex technical challenges, have a passion for delighting customers and who are self-motivated to push themselves in a team oriented culture will thrive in our environment What you'll Do Collaborate with Data architects, Enterprise architects, Solution consultants and Product engineering teams to gather customer data integration requirements, conceptualize solutions & build required technology stack Collaborate with enterprise customer's engineering team to identify data sources, profile and quantify quality of data sources, develop tools to prepare data and build data pipelines for integrating customer data sources and third party data sources with Adobe solutions Develop new features and improve existing data integrations with customer data ecosystem Encourage team to think out-of-the-box and overcome engineering obstacles while incorporating new innovative design principles. Collaborate with a Project Manager to bill and forecast time for customer solutions What you need to succeed Proven experience in building/operating/maintaining fault tolerant and scalable data processing integrations using AWS Proven track record in Python programming language Software development experience working with Apache Airflow, Spark, MongoDB, MySQL Experience using Docker or Kubernetes is a plus BS/MS degree in Computer Science or equivalent proven experience Ability to identify and resolve problems associated with production grade large scale data processing workflows Excellent interpersonal skills Experience crafting and maintaining unit tests and continuous integration. Passion for crafting Intelligent data pipelines that customers love to use Strong capacity to handle numerous projects are a must At Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists. You will also be surrounded by colleagues who are committed to helping each other grow through our outstanding Check-In approach where feedback flows freely. If you’re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the significant benefits we offer. Adobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, religion, age, sexual orientation, gender identity, disability or veteran status."
Data Integration Engineer I/II/III/IV-7745 (Remote/Telecommu...,Univera Healthcare,"Remote in Rochester, NY 14604",https://www.indeed.com/rc/clk?jk=d2181cb814e4fb77&fccid=490b0dcbbe2e5b41&vjs=3,"PLEASE NOTE: With limited exceptions, our company is requiring all employees to be vaccinated against COVID-19 by Jan. 1, 2022. We also currently mandate vaccinations for employees who enter our buildings. Please keep this in mind when applying for positions at our organization. Summary: The Data Integration Engineer is responsible for the design, build, unit testing and deployment of the project's data integration components that link various sources of data together. The incumbent works with other teams in A&D and EIT to develop and maintain data integration standards and architecture. This position ensures implementation of data integration standards across projects/programs. The incumbent works closely with Solution/Data Architects, Platform Architects, Business Intelligence (BI) analysts, Testers, Delivery Leads, and Operations staff to ensure structure and migration of data for successful customer use. This position also assists in project management activities such as project planning, time/effort estimating, and status reporting. Essential Responsibilities/Accountabilities Level I Identifies and resolves personal time management problems at the appropriate level through recognition that time is an asset requiring forward-looking management so that it can be used when available Writes program code/logic according to predefined specifications Ensures the solution follows data integration best practices Acquires specialized knowledge spanning business, systems, data and technology, developing skills in practical application of specialized knowledge, while growing self-confidence to increase capacity for effective action Tests individual units of source code (sets of one or more computer program modules together with associated control data, usage procedures, and operating procedures) to ensure that code meets design needs and is fit for use Maintains processes that feed data from various systems across the enterprise, ensuring data quality and process efficiency Develops standards, policies and procedures for the form, structure and attributes of the data warehouse tools and systems Participates in rotating on-call support schedule working with Operations team as level 2 support Consistently demonstrates high standards of integrity by supporting the Lifetime Healthcare Companies’ mission and values and adhering to the Corporate Code of Conduct and leading to the Lifetime Way values and beliefs Maintains high regard for member privacy in accordance with the corporate privacy policies and procedures Regular and reliable attendance is expected and required Performs other functions as assigned by management Level II – in addition to Level I responsibilities: Anticipates, identifies and analyzes problems, accepting nothing at face value, instead gaining knowledge through examination of the truth and validity of arguments, classifying the relative importance of ideas, and applying reason, logic and judgment to determine the merits of arguments; develops solutions and decides on the most appropriate solution to achieve the desired outcome in a collaborative manner Applies technical/business knowledge, scope assessment, experience, predictive skills, risk awareness and analysis to define a level of effort and cost Includes and works together with cross-functional teams, diverse groups and individuals of all levels to achieve a common goal Documents the requirements, capabilities, limitations, design, operation, and maintenance of a system, such as a communications, computing, or information processing system Ensures technical metadata/documentation is maintained in appropriate repositories Works with the DBAs, Informatica Admins, Hadoop Admins, R-Studio Admins and data warehouse operations to determine how to meet SLAs defined with the business Level III – in addition to Level II responsibilities: Applies the information framework against business requirements within security and operational constraints in support of delivery of new technology or capability Analyzes existing systems, identifies impacted areas and changes to design at a system or functional level to support requirements for a given technology/platform/application Implements and measures audit, balance, and control procedures to monitor security and efficiency of the data warehouse environment Acts as development lead on projects as assigned, coordinating activities of development team Leads, manages and/or implements technical change initiatives, acting in a lead role to incorporate the change into day-to-day processes Provides training and mentoring to staff on the use of the tools Develops and applies standards and best practices for data storage, data processing and platform integration Develops the ability to work across multiple data platforms (Hadoop and Oracle) Level IV – in addition to Level III responsibilities: Transforms business requirements and functional specification into a set of components, modules, process flows, and interfaces required to satisfy those requirements. This includes dimensions such as stability, performance, maintainability, and disaster recovery Sets up rules for cleansing the data according to data quality policies Assists with system/UAT testing by providing expertise in data subset needs and job execution Helps with the selection of data integration tools for the solutions being implemented Interfaces with Solution Architecture, Data Architecture, Data Integration Analysts, Data Integration Architects, and Business Intelligence to ensure the business’ data requirements are designed for optimal use Mentors other Engineers in the Data Integration Engineer level I/II/III roles Develops and recommends standards and best practices related to Data Integration Researches new technology and makes recommendations on how to improve and evolve our ongoing data strategy Addresses performance and scalability issues and performs necessary capacity planning to meet new business initiatives Expert at working across multiple data platforms (Hadoop and Oracle) Minimum Qualifications NOTE: We include multiple levels of classification differentiated by demonstrated knowledge, skills, and the ability to manage increasingly independent and/or complex assignments, broader responsibility, additional decision making, and in some cases, becoming a resource to others. In addition to using this differentiated approach to place new hires, it also provides guideposts for employee development and promotional opportunities. Level I Bachelor’s degree in Computer Science, Information Technology, or relevant field (or four additional years of work experience in lieu of bachelor’s). Core classes within computer science and information systems track Course work in principles and practices of basic computer hardware, operating systems and software application Course work in principles and practices of applications programming Course work in principles and practices of software troubleshooting SQL (or Hive) experience developing queries, tables, functions, and stored procedures Knowledge of MS Word, Excel, and OneNote, Toad, Oracle 11g or higher, SharePoint, Unix, Java, SQL Developer, Cloudera Hadoop Platform, Spark, Python, R Has the ability to develop work plans and follow through on assignments with some guidance Understanding of architectural principles and data integration styles Understanding of various types of data models Novice in data integration tools Strong communication and written skills Ability to effectively organize one's work. Level II – requires additional qualifications as Level I, plus: 3 years production-level data integration of application development experience (or related experience) 2 years Data Warehouse experience 2 years database utilities (e.g., TOAD, SQL Developer, Cloudera Hadoop Platform, Spark, Python, R, Nifi) 1 year job scheduling software knowledge 2 years SQL experience (or Hive) Has the ability to develop work plans and follow through on assignments with minimal guidance Practitioner in data integration tools Level III – requires additional qualifications as Level II, plus: 5 years production-level data integration of application development experience (or related experience) 3 years Data Warehouse experience 3 years database utilities (e.g., TOAD, SQL Developer, Cloudera Hadoop Platform, Spark, Python, R, Nifi) 1 year of data services experience 3 years SQL experience (or Hive) Has the ability to develop work plans and follow through on assignments with minimal guidance Advanced knowledge of data integration tools Level IV – requires additional qualifications as Level III, plus: 8 years production-level data integration of application development experience (or related experience) 7 years large-scale Data Warehouse experience 5 years database utilities (e.g., TOAD, SQL Developer, Cloudera Hadoop Platform, Spark, Python, R, Nifi) 3 year of data services experience 5 years SQL experience (or Hive) Has the ability to develop work plans and follow through on assignments with minimal guidance Experience in Data Modeling (Conceptual, Logical and Physical). A plus if familiar with master data concepts such as Party, Product, Location, Agreement as well as patterns such as Data Vault Experience working with Change Data Capture Expert in data integration tools Ability to mentor Data Integration Developers levels I/II/III Physical Requirements Ability to travel across regions ************ The Lifetime Healthcare Companies aims to attract the best talent from diverse socioeconomic, cultural and experiential backgrounds, to diversify our workforce and best reflect the communities we serve. Our mission is to foster an environment where diversity and inclusion are explicitly recognized as fundamental parts of our organizational culture. We believe that diversity of thought and background drives innovation which enables us to provide leading-edge healthcare insurance and services. With that mission in mind, we recruit the best candidates from all communities, to diversify and strengthen our workforce. OUR COMPANY CULTURE: Employees are united by our Lifetime Way Values & Behaviors that include compassion, pride, excellence, innovation and having fun! We aim to be an employer of choice by valuing workforce diversity, innovative thinking, employee development, and by offering competitive compensation and benefits. In support of the American with Disabilities Act, this job description lists only those responsibilities and qualifications deemed essential to the position. Equal Opportunity Employer"
"Senior Data Engineer - Process, Technology & Materials Devel...",Kite Pharma,"Santa Monica, CA",https://www.indeed.com/rc/clk?jk=e5fedfb966c10e9e&fccid=14befa0aae3644d3&vjs=3,"Job Description We are seeking a highly motivated individual with data automation experience to join our Process Development Technology and Materials team as a Senior Data Engineer to contribute toward the advancement of innovative T-cell therapy programs and technologies for cancer treatment at Kite’s Santa Monica, CA facility. The Data Engineer will create and deploy tools and that will have a significant impact on how the organization collects and works with data. The Data Engineer will influence system and equipment design decisions through technology evaluation activities, write and/or review user requirements, functional requirement specifications, qualification protocols, user acceptance tests and reports, and provide technical assessments, rationales, and approvals for design changes to meet internal and regulatory requirements. A successful candidate will work independently as a data expert and actively partner with stakeholders across functions including Process Development, Analytical, IT, and others. Responsibilities Lead the development of tools for acquiring, managing, and viewing data generated by cell therapy process and analytical equipment Collaborate closely with internal teams and vendors to develop solutions for facilitating connectivity and data transfer between different types of equipment, databases, and services Contribute to operationalizing new process technology by ensuring it meets requirements for successful integration with GMP manufacturing systems Implement best practices to ensure quality and reliability of data pipelines Participate in mentoring new team members and help foster culture that is helpful, inclusive, and fun Define, manage, and communicate project timelines and risks Proactively seek opportunities to automate and make cell therapy bioprocessing techniques and workflows more efficient. Requirements PhD degree in relevant Science or Engineering discipline with 0+ years of industry experience OR MS degree in relevant Science or Engineering discipline with 6+ years of industry experience OR BS degree in relevant Science or Engineering discipline with 8+ years of industry experience OR High School Diploma with 12+ years of industry experience Preferred Qualifications Knowledge of common data architecture and Industry 4.0 principles Excellent verbal, written, and interpersonal communication skills Experience with at least one modern object-oriented language such as C# or Java Experience working with API documentation to integrate hardware or software systems Experience working with and analyzing scientific data Experience with SCADA or LIMS systems Experience with external vendor collaborations or partnerships Experience deploying solutions into regulated environments and 21 CFR Part 11 compliance Experience with software development lifecycle activities such as version control, issue tracking, and build pipelines Knowledge and understanding of biopharma processes or analytical techniques is a plus"
Senior ETL Data Engineer **THIS IS A W2 POSITION WITH BENEFI...,Braintrust,"Remote in San Francisco, CA+1 location",https://www.indeed.com/rc/clk?jk=145909ff58b9f1ff&fccid=cffd065f9ff9e672&vjs=3,"ABOUT US: Braintrust is the only network that gives in-demand talent all the freedom of freelance with all the benefits, community and stability of a full-time role. As the first decentralized talent network, our revolutionary Web3 model ensures the community that relies on Braintrust to find work are the same people who own and build it through the blockchain token, BTRST. So unlike other marketplaces that take 20% to 50% of talent earnings, Braintrust allows talent to keep 100% of earnings and to vote on key changes to improve the network. Braintrust is working to change the way freelance works – for good. JOB TYPE: Freelancer, Contactor NO C2C LOCATION: United States only - Remote (Time Zone: PST/CIST | Partial overlap) HOURLY RATE: Our client is looking to pay $75 – $85/hr ESTIMATED DURATION: Full time | 40 hrs/wk Long term Requirements **THIS IS A W2 POSTION WITH BENEFITS** Minimum 10 year experience in BI development and support 7 years of experience with data warehouse concepts and methodologies 2 years of experience with AWS environment Experience with database design & modeling Experience with business intelligence or reporting tools (preferably Tableau and Alteryx) is a plus Working experience in ecommerce industry and web analytics will be a plus Excellent written and oral communication skills Highly motivated self-starter, detail and quality oriented and able to work independently Top Skills AWS MySQL What you'll be working on Senior ETL Data Engineer is responsible for design, develop, deliver and support ETL solutions using SQL scripts and various ETL tools. Champion and manage new initiatives to completion to improve and streamline operations processes and maximize systems efficiency. Work as part of a team to support business analytics for growing online consumer subscription service. Play key role in building out a semantic layer through development of ETLs and virtualized views. Participate in requirement definition, solution development and implementation phases of semantic layer. Work with Engineering teams to explore and understand new data being introduced to front end application Consolidate existing long running SQL scripts to build new ETL solutions in SQL Create and maintain ETL specifications and process documentations to produce the required data deliverables (requirement, design, operational support guide, etc.). Configure and tune ETL infrastructure to optimize the semantic layer architecture Troubleshoot and resolve data, system, and performance issues. Apply now! ABOUT THE HIRING PROCESS: Qualified candidates will be invited to do a screening interview with the Braintrust staff. We will answer your questions about the project, and our platform. If we determine it is the right fit for both parties, we'll invite you to join the platform and create a profile to apply directly for this project. C2C Candidates: This role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we'd welcome your application. Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status."
Data Engineer,Amgen,"Remote in Thousand Oaks, CA 91360+11 locations",https://www.indeed.com/rc/clk?jk=2c06f4cf02eaaeb9&fccid=ec34037a9c92d805&vjs=3,"HOW MIGHT YOU DEFY IMAGINATION? You’ve earned your degree. How will you use that achievement to reach your goals? Do more with the knowledge you’ve worked hard to acquire and the passion you already have. At Amgen, our shared mission—to serve patients—drives all that we do. It is key to our becoming one of the world’s leading biotechnology companies, reaching over 10 million patients worldwide. Become the professional you are meant to be in this meaningful role. Data Engineer Remote Work Live What you will do Let’s do this. Let’s change the world! In this vital role, you will join a new technical product team within our Research and Development Information Systems department. You will develop data ingestion and transformation pipelines for clinical data from various data sources into enterprise data lake. You will build both front and back-end tech components using cloud and AI technology to enable data analytics across various business functions. Responsibilities: Design, develop, and deploy data pipeline for clinical domain dataset As an infrastructure programmer, continuously develop and support Data Scientist R-Platform and integration with various technology (Kubernetes Container, HashiCorp Vault, SAS Storage, and Data Science Work Bench) Design and build various reusable program components using innovative technology (NLP, AI, Python, R, etc) to transform and harmonize clinical dataset for insight generation Collaborate with Data Architects, Business SME’s, and Data Scientists to capture the business requirement and translate into Agile product backlog Serve as primary data engineer to manage and support AWS, Databricks, RStudio platform, and cloud AI based system production DevOps Align to best practices for coding, testing, and designing reusable code/component Explore new tools and technologies that will help streamline data pipeline and add new durable capability for clinical development Participate in sprint planning meetings and provide estimations on technical implementation Collaborate and communicate effectively with the product teams Win What we expect of you We are all different, yet we all use our unique contributions to serve patients. The innovative professional we seek is a self starter with these qualifications: Basic Qualifications: Master’s degree OR Bachelor’s degree and 2 years of Data Engineering and/or and Software Engineering experience OR Associate’s degree 6 years of Data Engineering and/or Software Engineering experience OR High school diploma and 8 years of Data Engineering and/or Software Engineering experience Preferred Qualifications: Experience with software development (Python, R preferred), end-to-end system design Experience with data modeling for both relationship databases, hands-on experience with SQL (PostgreSQL and Hive SQL is preferred) Experience with software DevOps CI/CD tools, such as Git and Jenkins Experience on AWS, familiar with EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, and API gateway Experience with Apache Airflow and Apache Spark Experience with UI Visualization technology (Dash, RSConnect, Tableau preferred) Hands on support and platform development experience with Databricks and RStudio, Kubernetes Container, and HashiCorp Vault is an asset Experience with Pharmaceutical industry, clinical trial design and development Ability to learn quickly, be organized and detail oriented Thrive Some of the vast rewards of working here As we work to develop treatments that take care of others, we also work to care for our teammates’ professional and personal growth and well-being. Full support and career-development resources to expand your skills, enhance your expertise, and maximize your potential along your career journey A diverse and inclusive community of belonging, where teammates are empowered to bring ideas to the table and act Generous Total Rewards Plan—comprising health, finance and wealth, work/life balance, and career benefits—with compensation and benefits rated above 4 stars (out of 5) on Glassdoor Apply now for a career that defies imagination Objects in your future are closer than they appear. Join us. careers.amgen.com Join Us If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen. Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses. As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients. Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. Amgen requires all staff in the United States, Puerto Rico and Canada to be vaccinated from COVID 19 as a condition of employment. In accordance with applicable law, Amgen will provide reasonable accommodations to staff members who qualify on the basis of a medical reason or a sincerely held religious belief, practice, or observance. Such accommodation may not pose an undue hardship to Amgen, its operations, or its staff."
"Developer Programs Engineer, Data Analytics",Google,"Raleigh, NC (Hillsborough area)",https://www.indeed.com/rc/clk?jk=6036f0cf98bcc720&fccid=a5b4499d9e91a5c6&vjs=3,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Raleigh, NC, USA; Durham, NC, USA. Minimum qualifications: Bachelor's degree in Computer Science, Engineering, a related field, or equivalent practical experience 3 years of experience in one or more of the following programming languages: Python, Node.js, or Go Preferred qualifications: Experience as a contributor to an open source project (e.g., contributor to communities such as GitHub and/or Stack Overflow) Experience designing APIs or developer tools Ability to understand the experiences of users Excellent verbal and written communication skills, and the ability to work cross-functionally across teams About the job As a Developer Programs Engineer (DPE), you will be at the intersection the people who build technology and the customers who use it. DPEs are the engineering portion of Developer Relations. We ensure that Google Cloud services like BigQuery and other data analytics products such as Pub/Sub and Dataproc are amazing for developers. We author Software Development Kits (SDKs)/client libraries, and provide feedback on API design, platform consistency, and functionality. We write sample code and work with our Technical Writing teams to produce developer documentation, quick starts, and tutorials. We release open source code, participate in developer forums, and help troubleshoot developer problems. As part of the Data Analytics DPE team, you will work cross-functionally and with external developers to improve the developer experience. You will focus on building and improving BigQuery client libraries and connectors and improving the BigQuery and cross-product experience for working with data science and analytics-focused products in the Data Analytics product portfolio. Responsibilities Build natural Software Development Kits (SDKs)/client libraries, samples and other developer tools to improve the developer experience of using Google’s platforms and APIs. Partner with product-aligned Engineering teams to understand and improve the developer experience of our products, specifically around Dataproc and BigQuery Machine Learning. Assist third party developers in troubleshooting their integrations with Google APIs and use of other Google developer products. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form."
Sr. Lead Data Engineer,"Chick-fil-A, Inc.","Atlanta, GA 30349+1 location",https://www.indeed.com/rc/clk?jk=9d5c9a01ba5e8ce4&fccid=ff1746cf19c4661b&vjs=3,"Overview: As a part of the Chick-fil-A Supply Chain Data Services team, the Supply Chain Data Engineer will design and implement necessary analytics infrastructure on technically complex projects, focusing on developing solutions to data modeling and/or analytics technology needs. They must be able to quickly develop mastery of the needed subject across any line of business for which they are responsible. The role must have strong analytical and data modeling skills, a deep understanding of database technology and data use within analytic platforms, and they must have strong programming skills with SQL and/or Python. This role will directly support our Chick-fil-A Supply Chain data foundation, focusing on transforming data for business and analytic needs. The data engineer plays an essential role, providing the business with the visibility required to manage our complex business. The ability to collaborate well with both IT and business partners to achieve goals is also essential.This role is also responsible to educate others about the use of key data assets and help drive overall data literacy Responsibilities: Develop and execute the strategic plan for the business data engine of the future. New design should increase in scale and function to support expanding and maturing analytic needs. Exhibits wide latitude in aligning business stakeholders and IT to translate business logic into scalable data and analytic solutions on complex projects. Enable a modern data architecture and/or referencing the need to build data models in support of advanced analytical models and systems Develops ETL pipelines for general business consumption, establishing patterns for repeatable, scalable ETL work that others can leverage in their work. Develops tool, data, and analytics best practices for the SC analyst community and advising on their integration into operational practices. Designs specific tool implementations, understanding both Tableau and Alteryx performance (including server) and cloud compute performance requirements and expectations. Owns and is accountable for data model and code quality and any relevant documentation. Monitor data quality by Establishing concise data quality measurements Developing automated models, dashboards and workflows necessary to track data quality Researching and resolving ongoing data issues Work closely with Data Governance Lead to follow established processes Drives complex projects to success and enables others to own the impact. Helps design patterns for efficient use of cloud compute resources Minimum Qualifications: Strong analytical skills Attentiveness to details with the ability to understand business context Ability to learn things quickly and work independently Ability to communicate your results effectively to others Ability to manage multiple projects and deadlines simultaneously Proficiency in a data blending tool and a visualization tool Preferred Qualifications: Proficiency in Data Analysis, AWS Redshift, AWS S3, SQL, Python, Alteryx, Tableau preferred Minimum Years of Experience: 5 Travel Requirements: 20% Required Level of Education: Bachelor's Degree Major/Concentration: Finance or Quantitative/Technical Discipline Minimum GPA (4.0 Scale): 3.2"
Development/Engineering - Data Warehouse Engineer Sr,Cygnet Global Resources,"Remote in Union, NJ",https://www.indeed.com/rc/clk?jk=29c782cc07e6dc09&fccid=dd616958bd9ddc12&vjs=3,"Job Description Designation: Data Warehouse Engineer Sr. Years of Experience:4+ yrs Location: Union, NJ(Work from home till back in the office) Hire: Corp to Corp Visa: H1B Visa Offer Rate: $90/hr Key Responsibilities: • Develop end to end scalable data applications and data pipelines. • Automate the data ingress, data quality checks and final table builds. • Develop optimal SQL queries and scripts for business logic implementation Requirements Basic Qualifications: • 3+ years of experience in Java or Python for Data Processing. • 3+ years of SQL experience in building data transformations. • 3+ years of experience with Unix / Linux including shell scripting. • 1+ year of experience in Google Cloud Platform – Composer, BigQuery. Preferred Qualifications: • Experience with Hadoop stack – Spark / Hive / Hbase. • Experience developing cloud applications and understanding of design for scalability. • Experience with requirements gathering and data modelling. • Knowledge of relational database techniques, data warehouse concepts and architecture. • Bachelor’s Degree in Information Systems, Computer Science or related field Industry IT Services Work Experience 4-5 years City Union State/Province New Jersey Country United States Zip/Postal Code 07083"
Data Engineer- Cloud,CapTech Consulting,"Remote in Denver, CO+15 locations",https://www.indeed.com/rc/clk?jk=92b4d4094da39229&fccid=6ce11bcd7af32730&vjs=3,"Company Description CapTech is a team of master builders, creators, and problem solvers who help clients grow efficient, successful businesses. We unite diverse skills and perspectives to transform how data, systems, and ingenuity enable each client to advance what’s possible in a changing world. As perceptive partners, our U.S-based consultants find inspiration in the unknown and enjoy getting our hands dirty solving our clients’ myriad of challenges. Across industries and business goals, we fuse technical depth and analytical prowess with creative savvy to move clients forward. This drive helps each organization use technology, management, and insight to turn ideas into action. Together, we create outcomes that exceed the expected — which is one of the reasons we’ve been on the Inc. 500/5000 list for over a decade. Job Description CapTech Data Engineering consultants enable clients to build and maintain advanced data systems that bring together data from disparate sources in order to enable decision-makers. We build pipelines and prepare data for use by data scientists, data analysts, and other data systems. We love solving problems and providing creative solutions for our clients. Cloud Data Engineers leverage the client’s cloud infrastructure to deliver this value today and to scale for the future. We enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other developers, architects, and our clients. Specific responsibilities for the Data Engineer – Cloud position include: Developing data pipelines and other data products using Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP) Advising clients on specific technologies and methodologies for utilizing cloud resources to efficiently ingest and process data quickly Utilizing your skills in engineering best practices to solve complex data problems Collaborating with end users, development staff, and business analysts to ensure that prospective data architecture plans maximize the value of client data across the organization. Articulating architectural differences between solution methods and the advantages/disadvantages of each Qualifications Typical experience for successful candidates includes: Experience delivering solutions on a major cloud platform Ability to think strategically and relate architectural decisions/recommendations to business needs and client culture Experience in the design and implementation of data architecture solutions A wide range of production database experience, usually including substantial SQL expertise, database administration, and scripting data pipelines Ability to assess and utilize traditional and modern architectural components required based on business needs. A demonstrable ability to deliver production data pipelines and other data products. This could be hands on experience, degree, certification, bootcamp, or other learning. Skills: Successful candidates usually have demonstrable experience with technologies in some of these categories: Languages: SQL, Python, Java, R, C# / C++ / C Database: SQL Server, PostgreSQL, Snowflake, Redshift, Aurora, Presto, BigQuery, Oracle DevOps: git, docker, subversion, Kubernetes, Jenkins Additional Technologies: Spark, Databricks, Kafka, Kinesis, Hadoop, Lambda, EMR Popular Certifications: AWS Cloud Practitioner, Microsoft Azure Data Fundamentals, Google Associate Cloud Engineer Additional Information We want everyone at CapTech to be able to envision a lasting and rewarding career here, which is why we offer a variety of career paths based on your skills and passions. You decide where and how you want to develop, and we help get you there with customizable career progression and a comprehensive benefits package to support you along the way. Alongside our suite of traditional benefits encompassing generous PTO, health coverage, disability insurance, paid family leave and more, we’ve launched extended benefits to help meet our employees’ needs. CapFlex – Employee-first mentality that supports a remote and hybrid workforce and empowers daily flexibility while servicing our clients Learning & Development – Programs offering certification and tuition support, digital on-demand learning courses, mentorship, and skill development paths Modern Health –A mental health and well-being platform that provides 1:1 care, group support sessions, and self-serve resources to support employees and their families through life’s ups and downs Carrot Fertility –Inclusive fertility and family-forming coverage for all paths to parenthood – including adoption, surrogacy, fertility treatments, pregnancy, and more – and opportunities for employer-sponsored funds to help pay for care Fringe –A company paid stipend program for personalized lifestyle benefits, allowing employees to choose benefits that matter most to them – ranging from vendors like Netflix, Spotify, and GrubHub to services like student loan repayment, travel, fitness, and more Employee Resource Groups – Employee-led committees that embrace and incorporate diversity and inclusion into our day-to-day operations Philanthropic Partnerships – Opportunities to engage in partnerships and pro-bono projects that support our communities. 401(k) Matching – Generous matching and no vesting period to help you continue to build financial wellness CapTech supports Equal Pay for all. In addition, in the State of Colorado, we are committed to Equal Pay for ALL in accordance with the Colorado Equal Pay for Equal Work Act. The base pay range for this role is: $75,000 - $160,000. CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace. For more information about our Diversity, Inclusion and Belonging efforts, click HERE. At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship. #LI-LM1 #LI-Remote"
Data Engineer,Coterra Energy,"Houston, TX 77024 (Greater Memorial area)",https://www.indeed.com/company/Coterra-Energy/jobs/Data-Engineer-908cb26533ad750e?fccid=6cc8a4a5b9bbf49e&vjs=3,"About Coterra EnergyCoterra Energy Inc. was formed in October 2021 as the result of a merger between Cabot Oil & Gas Corporation and Cimarex Energy. By merging, the two legacy companies have created one entity full of talented people with decades of experience in the energy industry. Our team is passionate about delivering reliable energy to all and achieving environmental excellence while doing so. We embrace innovation and technology and encourage an atmosphere of open dialogue between employees and leadership. This is just the beginning for Coterra. We’re preparing for the future by expanding our teams across the country. Open positions span across all areas of the business, and we encourage you to visit our website to learn more about Coterra and the opportunities available. At our Houston headquarters, located in the Memorial City area, Coterra is tripling the size of our corporate office. Not only are we building our teams with diverse, experienced, and talented individuals, but we are also transforming our workplace to inspire ideas, creativity, and collaboration. Individuals who enjoy building and creating a new company are encouraged to apply. Data Engineer JOB SUMMARY As a Data Engineer with the Data Services team, you will plan, develop and implement data projects for transformational company data initiatives, process improvements, master data models, application interfaces, and direct end user consumption. You are driven to understand unfamiliar business data and processes, and deliver sensible and valuable data products that drive innovation and decision-making. Your work will contribute to the enterprise data model, and will be built for performance and longevity. ESSENTIAL DUTIES AND RESPONSIBILITIES Develop logical data models in Denodo Data Virtualization environment, adhering to data governance policy, internal layered modeling strategy, and Denodo standards and best practices Gather data project requirements with team members and business stakeholders, applying technical expertise and business understanding to determine best solution Collaborate with technical and business SME's to understand relationships between business drivers, business processes, data sources, and requirements for the deliverable Develop and tune data objects and processes in multiple data platforms (Denodo Data Virtualization, SQL Server, Vertica) Develop, implement, and support data warehouse enhancements (SSIS, SSAS, SQL) Contribute to team best practices, policy, and standards for data development methods and technology As necessary, assist in researching and evaluating software and technologies to meet growing data analysis needs Manage code using Git code repository in Visual Studio Team Services (VSTS) Review team code for quality, accuracy and adherence to standards Other tasks as assigned SKILLS AND EXPERIENCE Expert SQL relational data skills: profiling, manipulation, integration, and validation Experience with data warehouse design, technologies, and usage patterns Experience with profiling business data to understand its structure, meaning, quality, and relationships to other data Ability to translate SQL knowledge to other SQL syntaxes (Denodo VQL, Vertica SQL, T-SQL, PL/SQL) Ability to make logical connections between business domains to help drive data strategy, architecture, and design from an enterprise standpoint Strong interpersonal, problem solving, analysis, verbal and written communications skills Experience in upstream oil and gas industry preferred Education Requirements Min/Preferred Education Level Description Minimum 4 Year / Bachelors Degree 4-year degree in Management Information Systems, Computer Information Systems, Computer Science or related field highly preferred; Combination of education and experience may be considered in lieu of degree Years of Experience Years of Experience Range Description 5-7 years Experience: 7+ years’ Preferred WORKING CONDITIONS AND PHYSICAL DEMAND Work is typically performed indoors in an office environment. Incumbents must be able to perform work which includes typing, sitting and standing. In the event that incumbent visits operations worksite, personal protection equipment, including head protection, hearing protection, safety glasses, safety shoes, and flame resistant clothing is required. Safety rules including OSHA and DOT requirements are strictly enforced. Employees must be willing to travel and work extended hours on short notice. Travel Requirements Percent of Travel Required Comments Less than 5% Travel may be required for mandatory meetings or training. EEO-1 STATEMENT Coterra Energy Inc. is an equal opportunity employer. Applicants and employees are considered for positions and are evaluated without regard to mental or physical disability, race, color, religion, gender, national origin, age, genetic information, military or veteran status, sexual orientation, marital status or any other protected Federal, State/Province or Local status unrelated to the performance of the work involved. Job Type: Full-time"
Senior Data DevOps Engineer,Columbia Sportswear Company,"Portland, OR 97229",https://www.indeed.com/rc/clk?jk=f9b99e93ed30410c&fccid=e87d9cecd33775c9&vjs=3,"OUTGROWN YOUR OWN BACKYARD? COME PLAY IN OURS. At Columbia, we’re as passionate about the outdoors as you are. And while our gear is available worldwide, we’re proud to be based in the Pacific Northwest, where natural wonders are our playground. Every product we make and every task we undertake is inspired by the famous words of our founder Gert Boyle: “It’s perfect. Now make it better.” As pioneers of relentless improvement, we are constantly evolving. We believe the outdoors is ours to protect and strive to keep our planet healthy. We believe in empowering people to experience the outdoors to the fullest. And we believe in you. ABOUT THE POSITION Although we're an apparel and footwear focused company, technology is central to everything we do. Columbia Sportswear’s Digital Technology (CDT) teams enable an IT infrastructure across four global brands, a global supply chain, and 500+ geographically dispersed stores. These teams support in-store, mobile, and data platforms to enhance customer interface and service in an ever-evolving industry. The Senior Data DevOps Engineer is a member of the Data & Analytics (D&A) team and is responsible for data and business intelligence design, development and testing of new capabilities/enhancements to existing solutions that meet CSC's business needs within an Agile environment. The Senior DevOps Engineer is responsible for investigating, documenting, and resolving production issues affecting enterprise data assets. The Senior DevOps Engineers will provide Tier 3 support to enterprise data assets and systems across D&A team, including critical processes and job failures. The Senior DevOps Engineer will also work closely with several enterprise support organizations and Columbia users in addition to the D&A team. HOW YOU’LL MAKE A DIFFERENCE Design, build, test and maintain existing data integrations, ETL processes and BI solutions within the D&A environment consisting of Azure, SAP BW/HANA and BI Platforms Participate in Azure environment refresh and cutover activities for system integration testing and go live for major and minor releases Participate in an on-call rotation to support D&A production processes and systems Implement automated solutions using scripting/programming languages in Azure environment Build and maintain Continuous Integration and Continuous Delivery pipelines Work independently and acts as a resource for co-workers with less experience Support existing reporting and visualizations solutions using Columbia’s enterprise BI tools YOU ARE Able to multi-task and work effectively and independently in a dynamic environment Highly organized and detail-oriented Able to work with fellow BI Engineers both onsite and offshore Willing to jump in where needed, learn new technologies, and work effectively across the full stack Able to work both independently and collaboratively You have a passion for continuous learning, leading, and sharing knowledge. Provide subject matter expertise and guidance to less experienced staff members regarding performance management and design best practices YOU HAVE Bachelor’s Degree required in Computer Science or Information Systems or equivalent experience 5 to 8+ years of hands-on experience developing and testing Data Warehouse and Business Intelligence solutions Skilled in database concepts, including normalization, indexing, physical and logical modeling, creation of SQL queries and performance tuning. Skilled in SQL and query optimization for data platforms such as SQL Server, Azure SQL DW, HDInsight, Teradata. 1+ years’ experience working with Cloud Technologies preferred. Azure Data factory, Azure Data Lake and Azure SQL Data Warehouse preferred, (Azure Databricks a plus) Experience supporting visualization tools such as Azure Analysis Services, Tableau, Power BI, Cognos, MicroStrategy Desire to contribute to the standardization and buildout of CI/CD processes. Columbia Sportswear Company and our portfolio of brands, including Columbia, SOREL, Mountain Hardwear and prAna, know a thing or two about adventures. After all, we've been on one since 1938, working to perfect the art of enjoying the outdoors. Behind everything we make is an employee who's found that the greatest adventure starts with joining a company that strives to do the right thing. This job description is not meant to be an all-inclusive list of duties and responsibilities, but constitutes a general definition of the position's scope and function in the company. At Columbia Sportswear Company (CSC), we are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, color, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, military and veteran status, and any other characteristic protected by applicable law. CSC believes that diversity and inclusion among our teammates is critical to our success as a global company, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. All employment is decided on the basis of qualifications, merit, and business need."
Data Engineer,Lawrence Livermore National Laboratory,"Livermore, CA 94550",https://www.indeed.com/rc/clk?jk=2a42ba0a384e2bdf&fccid=26727f1861532c63&vjs=3,"Company Description Join us and make YOUR mark on the World! Are you interested in joining some of the brightest talent in the world to strengthen the United States’ security? Come join Lawrence Livermore National Laboratory (LLNL) where our employees apply their expertise to create solutions for BIG ideas that make our world a better place. We are committed to a diverse and equitable workforce with an inclusive culture that values and celebrates the diversity of our people, talents, ideas, experiences, and perspectives. This is essential to innovation and creativity for continued success of the Laboratory’s mission. Job Description We have an opening for a Data Engineer to utilize, develop, and evangelize internal information tools, which are used by multiple disciplines in direct support of the W80-4 Life Extension Program. You will employ these tools to capture and characterize test data critical to defense and science projects. Effective deployment and usage of these tools will enable better tracking of experiment history and allow data sharing within LLNL and across the NNSA complex. This position is in the Applications, Simulations, and Quality (ASQ) Division within the Computing Directorate in support of the WTE Data Lifecycle Management Team. This position will be filled at the 320.1 or 320.2 level based on knowledge and related experience as assessed by the hiring team. Additional job responsibilities (outlined below) will be assigned if hired at the higher level. In this role you will Develop and deploy complex scripts to process, import, and export a wide variety of unstructured test data generated from multiple sources. Develop an in-depth understanding of data management web applications, APIs, and visualization tools to effectively communicate their capabilities to data producers. Serve as the liaison between internal scientists and the development team to advocate the use of software tools for effective data archival. Troubleshoot software issues as they arise and communicate with customers and developers to quickly resolve them. Facilitate automated data collection by building rigorous data pipelines. Work with customers to create an ontology for standardized test data characterization. Perform other duties as assigned. Additional job responsibilities at the 320.2 Level Exercise independent discretion and judgement to define, develop, and implement original solutions to complex data management across a broad set of disciplines at the team, directorate, and institutional level. Provide formal/informal technical leadership and/or domain expertise in researching, advising and recommending technical solutions and approaches. Qualifications Ability to obtain and maintain a US DOE Q-level security clearance which requires U.S. Citizenship. Bachelor’s degree in a Computer, Engineering, or Mathematics related field, or equivalent combination of technical training and extensive experience. Significant experience with a scripting language such as Python, JavaScript, MATLAB, or R. Experience using Markdown, JSON, YAML, or other similar markup language Knowledge of RESTful web APIs, HTTP, and version control systems (Git). Significant experience using Unix/Linux command prompt to navigate through file directories, create/delete files, and run scripts. Proficient verbal and written communication skills necessary to present/explain technical knowledge, and provide advice to management, regulators, reviewers, and stakeholders. Additional Qualifications at the 320.2 Level Highly advanced experience with a scripting language such as Python, JavaScript, MATLAB, or R. Highly advanced experience collaborating with management, customers or high-level technical personnel to provide direction in the design, evaluation, recommendation, and implementation of systems, services, or processes. Advanced experience independently analyzing and interpreting complex data/business processes requiring highly advanced knowledge of materials management, data management, and/or scientific experimentation. Qualifications We Desire Experience with scientific Python programming (numpy, pandas, matplotlib). Experience using REST APIs to send and receive data. Comfortable being an advocate for a new technical product. Additional Information All your information will be kept confidential according to EEO guidelines. Position Information This is a Career Indefinite position. Lab employees and external candidates may be considered for this position. Why Lawrence Livermore National Laboratory? Included in 2022 Best Places to Work by Glassdoor! Work for a premier innovative national Laboratory Comprehensive Benefits Package Flexible schedules (*depending on project needs) Collaborative, creative, inclusive, and fun team environment Learn more about our company, selection process, position types and security clearances by visiting our Career site. COVID-19 Vaccination Mandate LLNL demonstrates its commitment to public safety by requiring that all new Laboratory employees be immunized against COVID-19 unless granted an accommodation under applicable state or federal law. This requirement will apply to all new hires including those who will be working on site, as well as those who will be teleworking. Security Clearance This position requires a Department of Energy (DOE) Q-level clearance. If you are selected, we will initiate a Federal background investigation to determine if you meet eligibility requirements for access to classified information or matter. In addition, all L or Q cleared employees are subject to random drug testing. Q-level clearance requires U.S. citizenship. For additional information, please see DOE Order 472.2. Pre-Employment Drug Test External applicant(s) selected for this position will be required to pass a post-offer, pre-employment drug test. This includes testing for use of marijuana as Federal Law applies to us as a Federal Contractor. Equal Employment Opportunity LLNL is an affirmative action and equal opportunity employer that values and hires a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, marital status, national origin, ancestry, sex, sexual orientation, gender identity, disability, medical condition, pregnancy, protected veteran status, age, citizenship, or any other characteristic protected by applicable laws. If you need assistance and/or a reasonable accommodation during the application or the recruiting process, please submit a request via our online form. California Privacy Notice The California Consumer Privacy Act (CCPA) grants privacy rights to all California residents. The law also entitles job applicants, employees, and non-employee workers to be notified of what personal information LLNL collects and for what purpose. The Employee Privacy Notice can be accessed here."
"Senior Data Solutions Engineer, Cruise Products",Royal Caribbean Group,United States,https://www.indeed.com/rc/clk?jk=f332f60f23981fe5&fccid=fa65a3fcc2b211c1&vjs=3,"Journey with us! Combine your career goals and sense of adventure by joining our exciting team of employees. Royal Caribbean Group is pleased to offer a competitive compensation & benefits package, and excellent career development opportunities, each offering unique ways to explore the world. Position Summary At Royal Caribbean Group, the Senior Data Solutions Engineer, Cruise Products builds, manages, and optimizes reusable enterprise data pipelines for onboard systems. They use technical and analytical skills to solve business problems for onboard Cruise Products while ensuring data governance and data security compliance. Senior Engineers also mentor junior engineers in finding optimal and efficient solutions for designing, preparing, and storing data for analytical and operational use cases. Essential Duties and Responsibilities Participate in requirements gathering, data mapping, and designing while considering the interconnectivity of systems onboard Build and maintain data pipelines from disparate sources that meet functional and non-functional business requirements Create, maintain, and reuse existing ETL processes, employing a variety of data integration and data preparation tools Identify, design, and implement internal process improvements, i.e., automating manual processes, optimizing data delivery, re-designing pipelines for greater scalability, etc. Work with stakeholders, including Product, Data, and Business teams, to assist with data-related technical issues and support their data needs Create datasets for operational reports, KPIs/metrics, analytics, and data science to uncover insights helping the business make objective decisions and gain a competitive edge Write, debug, and implement complex queries involving multiple tables or databases across platforms Collaborate with the Enterprise Architecture team to ensure alignment on data standards and processes Work with data and analytics experts to strive for greater functionality in data systems On-call and off-hours support required Create and maintain technical design documentation Qualifications, Knowledge, and Skills Bachelor of Science in Computer Science, Information Technology, or related field 5+ years of experience in a data/cloud engineering, working/creating datasets for a data warehouse, and ETL development tools (Informatica, Azure Data Factory (ADF), or Crosser preferred) Clear understanding of data modeling patterns (relational and dimensional) Experience using best practices in designing, building, and managing data pipelines that require data transformations as well as metadata and workload management Experienced in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures, and integrated datasets using traditional and new data integration technologies (such as ETL, ELT, data replication, change data captures, message-oriented data movement, API design, stream data integration, and data virtualization) Experienced in performing root cause analysis on internal and external data and processes to identify issues and opportunities for improvement Expert-level knowledge with programming languages including Python, SQL, PL/SQL, T-SQL, and/or relational SQL databases such as Oracle and SQL Server NoSQL database experience is a plus Proven ability to collaborate with technical peers to best support cross-functional teams in a dynamic environment Capable of working independently Strive to help guide junior engineers Experience with continuous integration and continuous deployment practices Ability to approach complex problems with creativity and display analytical and problem-solving skills Display curiosity in understanding the data for the specific area of responsibility Knowledge and experience working with agile methodologies and tools (such as Jira) are a plus Familiarity with onboard system vendor data models such as Fidelio, BriefCam, SAIA, Silverwhere, Xcontrol, Tritan, Hybris We know there's a lot to consider. As you go through the application process, our recruiters will be glad to provide guidance, and more relevant details to answer any additional questions. Thank you again for your interest in Royal Caribbean Group. We'll hope to see you onboard soon. It is the policy of the Company to ensure equal employment and promotion opportunity to qualified candidates without discrimination or harassment on the basis of race, color, religion, sex, age, national origin, disability, sexual orientation, sexuality, gender identity or expression, marital status, or any other characteristic protected by law. Royal Caribbean Group and each of its subsidiaries prohibit and will not tolerate discrimination or harassment."
Data Engineer | Enterprise Solutions Delivery,NITSDATA,"Overland Park, KS",https://www.indeed.com/rc/clk?jk=6c3e8d75bc235f3b&fccid=9cf4f05f8fcd3cbd&vjs=3,"Snoqualmie,WA / Dallas,TX / Overland Park, Kansas Contract ID: 133248 Enterprise Solutions Delivery develops innovative closed-loop analytics solutions, enabling insights-driven decision making across the enterprise. We collaborate with multiple functional areas and impact every element of our business: corporate, security, networks, retail, IT, and others. We are looking for a result-oriented engineer to be part of the team, building scalable systems that can handle big data solutions, building and deploying components for container technologies such as Docker, Kubernetes. Will be taking ownership of performance / scalability tuning and building technical infrastructure on-prem and Azure. You will need to understand the business objectives, think like an end user, and know that 90% done is only half done. You love beautiful, simple user interfaces, and you constantly wonder what you could have done to simplify your last project. You are passionate about e2e architecture and database design, focusing on flexibility and scalability. You prioritize API design, as this is necessary to build scalable, future-proof products. You will work closely with data scientists / ML engineers, cloud, and full stack experts to build advanced analytics platform in a hybrid environment integrating on-prem assets, Azure infrastructure and services. Essential Functions • You will be responsible for collecting and transforming large amounts of data (structured and un[1]structured) into a format that can be used by Data Scientists for model training • Create and maintain optimal data pipeline architecture for complex business requirements, to integrate the real time data streaming with ML model serving • Support building custom images for ML environments including python packages, pickled models. • The role will require extensive experience and knowledge with Apache Spark, Python, Scala, and SQL • Participate in technical design discussions, influencing the team in strategic decisions • Work with data scientists / ML engineers, software developers and interfacing internal customers to translate their requirements to features and develop those solutions • Responsible for other duties/projects as assigned by business management / leadership. Qualifications Minimum Required - 5+ years' experience with relevant tools and technologies (Spark, PySpark, Python, Kafka, DScala, SQL) - 3+ years’ experience in building highly distributed pipelines, stream processing solutions, CICD, monitoring and alerting - 3+ years’ experience with data orchestration tools – Airflow/Celery/Apache Spark/Dask - Working experience on cloud technologies (Azure preferred) - Advanced knowledge of performance tuning, scalability, system architecture and engineering best practices with spark clusters - Experience in building end-to-end ETL pipelines on-prem - Strong Linux experience Desired • Knowledge on Docker, Kubernetes, Databricks or related technologies • Splunk knowledge is a Plus • Graph database experience • Experience in deploying ML models • Shell and YAML scripting experience • Ability to work cross functionally with engineering and operations teams • Bachelor's Degree, preferably from a science or engineering background."
"Production Engineer, Data Infrastructure",Facebook App,+1 locationRemote,https://www.indeed.com/rc/clk?jk=67b7db38a463b08e&fccid=ba07516c418dda52&vjs=3,"Production Engineers at Meta are hybrid software/systems engineers who ensure that Meta's services run smoothly and have the capacity for future growth. They are embedded in every one of Meta's product and infrastructure teams, and are core participants in every significant engineering effort underway in the company.Scaling Meta’s central data infrastructure is the critical limiting factor in our business model. These systems enable AI and the Data Warehouse to make significant insights into products as well as into Meta’s infrastructure itself to bring more value to our customers. Our mission is to Empower Meta to leverage data everywhere, efficiently, and at extreme scale. We do this by focusing on building intelligent infrastructure, bringing data and compute together and scaling them to be available everywhere. This includes vending compute capacity as well as managing all of the intelligent scheduling, data placement, visualization and turn-up necessary behind the scenes to operate at the gigawatt/exabyte scale. Each of these services and the teams that support them are in rapid development and expanding to support the new long-term mission of the company. (Analogues you may be familiar with are Apache Yarn, Google Borg, Kubernetes). The short-term criticality of this enablement is hard to overstate. As a technical leader for the eXtreme Data(XD) @Scale organization, the candidate will have broad influence within Meta’s Data Infrastructure and across the stack between AI and Storage as well as peripheral partner teams such as Instagram for Reels. In this role, a technical leader will collaboratively set direction for multiple large scale distributed systems, helping to define how we efficiently and reliably (with simplicity) provide an optimized customer resource management experience. The Data Infrastructure capabilities (AI, Real-Time/Interactive/Batch) must be efficiently developed and operated to meet the challenges involved with scaling. Some challenges include optimizing for elastic compute, identifying/solving data duplication, multi-dc/regions active-active, and optimized bin-packing/load placement. The larger Data Infrastructure capabilities compose a complex technology ecosystem requiring significant investments by dozens of teams, whereby cross-team collaboration will be a highly utilized skill to influence towards a desired outcome. This position is full-time. Production Engineer, Data Infrastructure Responsibilities: Own backend infrastructure services from real-time RPC services to batch processing pipelines Write and review code, develop documentation and capacity plans, and debug the hardest problems, live, on some of the largest and most complex systems in the world Together with your engineering team, you will share an on-call rotation and be an escalation contact for service incidents Lead your engineering team by example, mentor and help others around you grow, be a force multiplier of impact Minimum Qualifications: 10+ years of experience in UNIX and TCP/IP network fundamentals 10+ years of coding experience Experience learning development languages (PHP, Python, C++, or Java) Experience learning software, frameworks and APIs Knowledge of internet service architectures (such as load balancing, LAMP, CDNs) Experience capacity planning for internet service architectures Experience in leading teams of engineers and cross-functional partners to deliver multi-year business objectives Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience Preferred Qualifications: BS or MS in Computer Science Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."
Data Engineer,AmSurg,Remote,https://www.indeed.com/rc/clk?jk=17ecc4c1577e7a09&fccid=681be0cd380eaa96&vjs=3,"AMSURG, the Envision Healthcare solution for ambulatory surgery centers (ASCs), collaborates with physicians and health systems across the country to provide and promote quality patient care. We are the nationally recognized leader in the strategic and operations management of ASCs that deliver high quality, high value, same-day surgical services with a superior patient experience. Launched in 1992 as an ASC industry pioneer, AMSURG is currently partnered with nearly 2,000 specialty physicians providing outpatient surgical services in more than 250 facilities in 34 states. POSITION SUMMARY: In this role the Data Engineer’s primary job responsibilities involve preparing data for analytical or operational uses. The specific tasks handled by the Data Engineers include, but not limited to, building data pipelines to pull together information from different source systems; integrating, consolidating and cleansing data; and structuring it for use in individual analytics applications. The Data Engineer often works as part of an analytics team providing data aggregations to executives, business analysts and other end users for more basic types of analysis to aid in ongoing operations. This is a remote position, allowing the Data Engineer position to be based anywhere in the country. Candidate must be willing to work a Central Time Zone schedule Monday - Friday. ESSENTIAL RESPONSIBILITIES: The Data Engineer is required to have a thorough understanding of tools for creating and managing data integration jobs, and providing data analysts and business users with simplified access to prepared data sets. Design, construct, install, test and maintain highly scalable data management systems Ensure systems meet business requirements and industry practices Build high-performance algorithms, prototypes, predictive models and proof of concepts Research opportunities for data acquisition and new uses for existing data Develop data set processes for data modeling, mining and production Integrate new data management technologies and software engineering tools into existing structures Employ a variety of techniques and tools to marry systems together Recommend ways to improve data reliability, efficiency and quality Collaborate with data architects, modelers and IT team members on project goals KNOWLEDGE AND SKILLS: To perform this job successfully, an individual must be able to perform each essential responsibility satisfactorily. The requirements listed below are representative of the knowledge, skills and/or abilities required. Intermediate to Advanced level user of Microsoft Office products. Advanced/power user of Excel Knowledge of relational database principles including SQL and MS-Office products Excellent quantitative and analytical skills as well as the ability to translate findings into meaningful information appropriate to the audience/stakeholder High level of comfort with many types of data including financial, quality, clinic and security Ability to work independently and prioritize work appropriately Ability to work under tight deadlines and switch quickly and comfortably between projects as business needs dictate Displays a positive morale and a sense of teamwork Excellent organizational skills and strong oral and written communication skills a must Regular and reliable attendance required. Education/Experience: Bachelor’s degree from an accredited college or university with a minimum of three (3) years previous data management/data services experience. Highly proficient in database management and query tools, including SQL and/or other query languages, required. Language Skills: Ability to understand, read, write and speak English. Ability to read, analyze and interpret general business periodicals, professional journals, technical procedures or governmental regulations. Ability to successfully write business correspondence. Ability to effectively present information, respond to questions and professionally interact with managers, employees, clients, vendors and the general public. Other Qualifications: Must be able to handle multiple, simultaneous tasks effectively and efficiently while maintaining a professional, courteous manner. Must be able to work well with others. Strong verbal and written communication skills required. Must be detail oriented and organized. High integrity, including maintenance of confidential information. Must be able to exercise good judgment and positively influence and lead others, including handling confrontations with poise and efficiency. Based on business need, the ability to work a flexible schedule, including some evenings and weekends as approved in advance. CORPORATE CORE VALUES Puzzle Solving-Turning challenges into opportunities in a collaborative, agile and creative way Excellence-On a never-ending quest to improve and exceed expectations Ownership-Taking responsibility for our actions, relationships and partners’ success Positive Environment-Respectful, caring, trusting and supportive of the team Leadership-Leading by example, staying true to our values and dreams Ethics-Committing to always doing the right thing guided by integrity and transparency Effective November 1, 2021, AMSURG’s Vaccination Policy requires all teammates, including clinicians and independent contractors, to be fully vaccinated for COVID-19 as a condition of employment or engagement. Regardless of position, all new hires must submit proof of vaccination and or obtain an approved medical or religious exemption as a condition of employment. This policy is designed to protect the health and safety of our patients, communities and each other. Must pass a background check and drug screen. We do not discriminate in practices or employment opportunities on the basis of an individual's race, color, national or ethnic origin, religion, age, sex, gender, sexual orientation, marital status, veteran status, disability, or any other prohibited category set forth in federal or state regulations. We are an equal opportunity employer."
Data Center Engineer,Empower AI Inc.,"Fort Worth, TX 76102",https://www.indeed.com/rc/clk?jk=32ca275ccd47a20c&fccid=6f722b240cecf890&vjs=3,"Overview: Empower AI is AI for government. Empower AI gives federal agency leaders the tools to elevate the potential of their workforce with a direct path for meaningful transformation. Headquartered in Reston, Va., Empower AI leverages three decades of experience solving complex challenges in Health, Defense, and Civilian missions. Our proven Empower AI Platform® provides a practical, sustainable path for clients to achieve transformation that is true to who they are, what they do, how they work, with the resources they have. The result is a government workforce that is exponentially more creative and productive. For more information, visit www.Empower.ai. Empower AI is proud to be recognized as a 2022 Military Friendly Employer by Viqtory, the publisher of G.I. Jobs. This designation reflects the company’s commitment to hiring and supporting active-duty and veteran employees. Responsibilities: POSITION SUMMARY DIGIT is looking for a Data Center Engineer to support our customer with an enterprise data center migration within the Dallas/Ft. Worth, Texas area. This position will require a hands-on approach to support this large-scale effort for migrating infrastructure, which includes physical and virtual appliances from the existing data center to two other remote sites. The role requires problem solving skills and flexibility in a dynamic work environment. The candidate will interact closely with internal Infrastructure teams across multiple workstreams while consulting multiple vendors for developing Infrastructure Data Center documentation. The candidate must have experience in resource management and utilizing risk management. You will also analyze, troubleshoot and resolve complex problems with Data Center services (business applications, networking and hardware) and prioritize tasks based on service level criteria. POSITION RESPONSIBILITIES: Inventory validation of data center compute, storage, networking, and environmental support equipment. Collaborating with various IT teams to facilitate change management, logistics and coordination. Offlining equipment. Facilitating the packaging and shipping of equipment to alternate data centers. Coordinating with Data Center Operations on the install at destination data centers. Coordinating with various IT teams for the onlining. Be intensely involved in design, build, migration and capacity expansion; work on the problems and contribute to the solution development. Develop and execute Data Center technical drawings (ex. rack elevations, floor layouts). Capacity Expansion of servers, storage and network devices. Be intensely involved in design, build, migration and capacity expansion; work on the problems and contribute to the solution development. Will also play an integral role in the design, build, migration and capacity expansion and deployment of the overall solution to optimize, improve and future proof the customer’s strategy. Qualifications: CONTRACT REQUIRED QUALIFICATIONS: Public Trust clearance or ability to obtain. ITILv4 Foundation training and certification (no later than December 31st, 2022). Possesses and applies a comprehensive knowledge across key tasks and high impact assignments. Plans and leads major technology assignments. Evaluates performance results and recommends major changes affecting short-term project growth and success. Functions as a technical expert in data center migrations. May supervise others. CONTRACT DESIRED QUALIFICATIONS: Must have recent experience with one or more complex, enterprise-level physical data center migration or consolidation projects (Server Lift and Shift Move). Applies fundamental concepts, processes, practices, and procedures on technical assignments. Experience supporting industry standard software products. Direct experience with Data Center design and operations. Direct experience using ServiceNow for ticket management and inventory management. Self-motivated, detail oriented, positive in approach, professional persona. General knowledge of server/network equipment and software support configurations. Strong aptitude for an independent working environment and high productivity rate. Excellent communication and customer relationship skills. Server, OS, Network, BICSI or data center certification is a plus. Proficient with Microsoft Office (Word, Excel) and Visio. Direct experience with Data Center design and optimization initiatives. Must be a hands-on Engineer that is willing to ""roll up their sleeves"" to ensure server moves go smoothly. EDUCATION AND EXPERIENCE Bachelor’s degree or equivalent and 5-8 years of related experience. Minimum of 5 years relevant experience with a focus on Physical Data Center Migration / Data Center Lift and Shift Project Management. Experience as a remote worker demonstrating time management and self discipline. PHYSICAL REQUIREMENTS The physical demands described below are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee is regularly required to do the following: As a remote position, personnel are expected to maintain their home workspace in a safe manner, free from safety hazards. As a remote position, personnel are expected to appear on camera for meetings with co-workers and government partners via video chat. As a remote position, personnel are expected to maintain standard working hours per the DIGIT contract and to be available for meetings, Agile ceremonies and other collaborative efforts during working hours. Personnel are expected to ensure the protection of proprietary company and customer information accessible from their home office consistent with the company’s expectations of information security. Communicate verbally and respond to verbal communications in person, over the phone or by video chat. Communicate clearly and succinctly in writing, primarily utilizing a keyboard. Sitting for long periods. Standing for long periods. Viewing computer screens for long periods of time. Travel minimally, 10% of the time. Ambulate throughout an office and/or between several buildings. Must be able to work at heights, off of a ladder, lift up to 50 pounds, use pallet jack and server lift. Place of duty is located in the Fritz G. Lanham building, Fort Worth, TX area (40 min driving radius) of 819 Taylor Street, Fort Worth, TX 76102. About Empower AI: It is the policy of Empower AI to provide equal opportunity in recruiting, hiring, training, and promoting individuals in all job categories without regard to race, color, religion, national origin, gender, age, disability, genetic information, veteran status, sexual orientation, gender identity, or any other protected class or category as may be defined by federal, state, or local laws or regulations. In addition, we affirm that all compensation, benefits, company-sponsored training, educational assistance, social, and recreational programs are administered without regard to race, color, religion, national origin, gender, age, disability, genetic information, veteran status, sexual orientation, or gender identity. It is our firm intent to support equal employment opportunity and affirmative action in keeping with applicable federal, state, and local laws and regulations. Empower AI is a VEVRAA Federal Contractor."
Principal/Senior Data Engineer,Liberty Mutual Insurance,+1 locationRemote,https://www.indeed.com/rc/clk?jk=cd17c9fee378df1e&fccid=f33a9750898d12d4&vjs=3,"At Liberty Mutual, technology isn't just a part of our business, it's what drives us forward. We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as an Agile team within a Fortune 100 company, we are on the front edge of an IT transformation for how people work and deliver solutions. GRM Data and Analytics Engineering is actively searching for a highly productive member of a distributed, dynamic agile team to serve as a technical expert designing, developing, analyzing & testing innovative data warehouse reporting solutions. This Principal/Senior Data Engineer will join an energetic and engaged Business Data Solutions Engineering team focused on delivering exceptional value to our Claims business partners. As a Principal/Senior Data Engineer, you will work collaboratively in an agile squad to design and build data pipelines & workflows, ingest, curate & provision data workflows in a Cloud-based environment as well as own responsibility of thorough end-to-end testing. This is a fast-paced environment providing rapid delivery for our business partners. You will be working in a highly collaborative environment that values speed and quality, with a strong desire to drive change and foster a positive work environment. You will have the opportunity to help lead this change with us as we grow this culture, mindset and capability. Note: This is a range posting. Candidates will be considered at the Principal and Senior Level. We encourage you to apply if this interests you: Work as ONE team committed to excellence Model and promote a “Data First” attitude Help advance Data Engineering operations into the future Work with a modern tech stack In this role you will: Work in a dynamic and exciting agile environment with Scrum Masters, Product Owners, and team members to develop creative data-driven solutions with our ETL pipeline that meet business and technical initiatives Analyze, develop and execute data integration solutions, in order to manage the information lifecycle needs of an organization. Actively participates in and often leads peer development and code reviews within each Agile sprint, with focus on test driven development and Continuous Integration and Continuous Development (CICD). Designs and builds data provisioning workflows/pipelines, physical data schemas, extracts, data transformations, and data integrations and/or designs using ETL and API microservices Builds data architecture and applications that enable reporting, analytics, data science, and data management and improve accessibility, efficiency, governance, processing, and quality of data. Improve speed to market by focusing on current data needs as well as building out the long-term strategic data solutions using AWS, Snowflake, Snaplogic, SQL, Informatica, as well as other modern data technologies Design and develop programs and tools to support ingestion, curation and provisioning of complex enterprise data to achieve analytics, reporting, and data science Demonstrate open minded and collaborative approach to creating innovative technical solutions Continuously learn to maintain strong knowledge of technology enablers Mentor new and junior developers Provide successful deployment and provisioning of data solutions to production or other required environments. Analyze complex technical problems and is expected to recommend process improvements that address complex technology gaps within a single business process and improve data reliability, quality, and efficiency Bachelor's or Master's degree in technical or business discipline or equivalent experience, technical degree preferred. Generally, 5+ years of professional data engineering experience Highly proficient in data engineering languages and tools, and strong proficiency in general programming languages and frameworks; ability to develop on multiple platforms. Extensive understanding of agile data engineering concepts and processes, such as CICD, pipelines, and iterative development and deployments Demonstrated experience delivering data solutions via agile methodologies on AWS, S3, Athena, Snowflake, Snaplogic Requires critical thinking, data analysis, and data modeling experience (Data Vault experience a plus) Must be proficient in Python, Javascript functions and SQL Experience with ETL (Informatica/Snaplogic) and knowledge of variety of data platforms Demonstrates leadership and active pursuit of optimizing data, CI/CD process and tools, testing frameworks & practices Must be proactive and self-driven, demonstrated initiative and be a logical thinker. Strong leadership, communication, collaboration skills with a track record of taking solution ownership Thorough knowledge in the following areas; personal P&C insurance, general IT concepts, strategies and methodologies, thorough knowledge of new data architecture principles and concepts, thorough understanding of layered systems architectures, extensive knowledge of business operations, strategies and objectives. At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That's why we provide an environment focused on openness, inclusion, trust and respect. Here, you'll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession. Liberty Mutual has proudly been recognized as a “Great Place to Work” by Great Place to Work® US for the past several years. We were also selected as one of the “100 Best Places to Work in IT” on IDG's Insider Pro and Computerworld's 2020 list. For many years running, we have been named by Forbes as one of America's Best Employers for Women and one of America's Best Employers for New Graduates—as well as one of America's Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusion We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits Liberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran's status, pregnancy, genetic information or on any basis prohibited by federal, state or local law. 18"
Data Engineer,"Franchise World Hqts, LLC","Milford, CT 06461",https://www.indeed.com/rc/clk?jk=2dc017f422629cd7&fccid=43cf673720d39d1a&vjs=3,"Be a part of the Subway® Group – the world’s largest quick service restaurant franchisor and recognized leader in the Quick Service Restaurant industry. With more than 44,000 restaurants in over 100 countries, we continue to add talent to our team at our global headquarters in Milford, Connecticut. Subway seeks to hire an experienced Data Engineer to work closely with our Data Engineering Team and Business Users to continue to evolve our cloud enabled data ecosystem. The Data Engineer will be responsible for the design and development of data pipelines to support System Integrations as well as data pipelines that support our Analytical Platforms. The Data Engineer will work as part of a cross functional team to deliver integrations solutions for enterprise initiatives, including system to system integrations as well as Analytical solutions. A successful candidate will deliver scalable and flexible solutions that conform to Subway’s data design and governance strategies utilizing our AWS environment and Amazon Redshift data warehouse and other cloud-based technologies. Responsibilities include, but are not limited to: Design and develop data pipelines and integrations that are performant, scalable and flexible; Work with project teams to deliver system integration pipelines, ensuring a high degree of reliability and resiliency. Work with business users and project teams to provide SME guidance, finalize pipeline requirements and develop level of effort estimates. Develop automated testing and deployments scripts to support integrations and pipelines. Provide database support by coding utilities, responding to user questions, and resolving problems. Create and maintains documentation of the data pipelines including data flow and data lineage documentation. Responsible for tier 3 support and assisting our Operations Team as required to provide a great customer experience for our users. Responsible for overall data quality as it relates to our Enterprise Data Warehouse and associated Data Marts. Provide data analysis as required to troubleshoot data issues. Assist with integration related code reviews and mentorship of junior developers. Implement data governance and master data management principles as part of data pipeline development and delivery. The successful candidate will have: 3 - 5 years’ experience in creating quality data pipelines and system integrations with at least 1 year of experience in a cloud environment. Bachelor’s degree in Computer or Information Science or related field or equivalent combination of education and experience. Development experience with Matillion for Redshift & AWS ELT services. High proficiency of relational database, NoSQL, ETL/ELT and data integration technologies. Expert level data analysis and data management skills with highly effective problem-solving skills that can transform problems into solutions. Knowledge of integration methodologies and best practices. Expert level SQL programming experience. Python programming experience. js is a plus. Data Modeling skills and familiarity with BI Reporting Tools. Understanding of DevOps, Continuous Integration and Continuous Delivery technologies. Hands-on experience with Erwin Data Modeler & Erwin Mart Server. Experience which would set the candidate apart: Amazon Web Services Certifications (Architect or Developer track). Practical understanding of public cloud architecture. Experience in the processing of Real-Time Data Streams for Operational Reporting in an AWS Environment. Education Preferred Bachelors or better in Computer Sciences or related field Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Engineer,Zartico,"Salt Lake City, UT 84101 (People's Freeway area)",https://www.indeed.com/rc/clk?jk=bc8dad9da11f70a8&fccid=dd616958bd9ddc12&vjs=3,"Welcome to Zartico. We know applying for and taking on a new role at any company requires a leap of faith. Here are a few things about Zartico we think you should know: Zartico Mission and Purpose Zartico’s Purpose: We believe tourism is a force for good because it builds connection, understanding, and appreciation of our world’s cultures, history and natural resources. We believe data and the right metrics allow us to make better decisions because transparent data helps focus on the right issues, problems and therefore, solutions, to be better stewards of our world's most precious destinations. Zartico’s Mission: Zartico’s mission is to empower DMOs to be better stewards of the world’s tourist destinations through improved data intelligence and decision-making. Makers of the first Destination Intelligence Platform, Zartico harnesses and streamlines complex data to provide a full-spectrum of data science, benchmarking and analytical services for use in marketing, community development and sustainability efforts. Based in Salt Lake City, Utah, Zartico has over thirty years of experience in technology, tourism, and destination and travel marketing. If this resonates with you, Zartico is hiring Data Engineers. As an engineer on the core product team you'll provide intelligence to the rest of the company that will enable making better product decisions. You'll make use of the latest advances in large scale data processing to uncover insights in data. You’ll work on building critical data warehouse tables with world-class engineers towards the mission of enabling data-driven products and insights at Zartico. You will develop data infrastructure that is able to ingest and transform data at scale coming from many different sources, different customers, and in many different varieties. You will build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and build robust data pipelines that collect, process, and compute business metrics from activity data. You will create critical datasets for machine learning, growth funnels, business forecasting, and many other strategic initiatives. Primary Technologies Required Python Google Cloud Platform (BigQuery, GoogleCloud Storage) SQL Infrastructure as Code (e.g. Terraform) Extra Credit for Experience with data visualizations Experience and Mindset Needed 2+ Years of experience as a Data Engineer or Software Engineer BA/BS in a quantitative or computer science field Fluency in SQL and a programming language A successful history of manipulating, processing and extracting value from large disconnected datasets Quick learner - we face new challenges every day Expert in coding -we develop real products Compensation Competitive Salary and Benefits (unlimited PTO) Stock incentive program Career plan and lifelong learning - We want you to grow in your role based on their curiosity, passion, and ability to learn and evolve Zartico’s Commitment to Diversity and Inclusion Diversity, inclusion, and belonging. We’re building a global community—one that’s safe for people of all backgrounds. We are an equal opportunity employer where our diversity and inclusion are central pillars to our company strategy. We look for applicants who understand, embrace and thrive in a multicultural and increasingly globalized world. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. When you join our team, you agree to a code of conduct. Hiring Update: Due to the COVID-19 pandemic, our hiring process will now be completely virtual. All interviews and onboarding activities will be held online or over the phone."
Senior Data Engineer,Mavrck,"Denver, CO+1 location",https://www.indeed.com/rc/clk?jk=54e714437cb934e5&fccid=25b9f85ac7a01eb0&vjs=3,"Mavrck is the all-in-one, advanced influencer marketing platform enabling enterprise consumer brands to harness the power of social proof that consumers trust today. Marketers use Mavrck to discover and collaborate with influencers to create trusted content at scale. Mavrck is the #1 influencer marketing platform for the Enterprise on software review site G2, and was also named a “Leader” in Forrester’s evaluation, The Forrester New Wave™: Influencer Marketing Solutions, Q2 2020. In order to be the leading all-in-one advanced influencer marketing platform, Mavrck analyzes billions of assets to derive relevant information for our clients in a feasible time and cost. By being an early member of Mavrck’s Data Engineering team, you will have ample opportunity to work on many aspects of Mavrck’s Data Engineering platform. Day to day responsibilities include the architecture, execution, deployment and maintenance of: DataStores HBase, MySQL, Hadoop Search Technologies Solr, ElasticSearch Processing Pipelines YARN, Kafka, Spark API Provisioning & Deployments JVM ( Kotlin ) Kubernetes Data Analytics / Business Intelligence Roll Our Own ~ ad-hoc data request fulfillments Data Science ( Green Fields ) NLP Image Processing Modeling Machine Learning This role will offer the opportunity to work on the entire data stack! We don’t expect the candidate to have experience in all areas of our stack, but require a willingness and drive to learn. Curiosity and hustle is part of the DNA that makes up Mavrck’s squad and learning and building are natural consequences of that. Be a part of a creative group that solves challenging problems and has fun doing it! Mavrck is committed to building an inclusive, supportive place for you to do the best and most rewarding work of your career. If you identify with any of the following, we encourage you to apply! Required : Experience w/ JVM Technologies ( Java, Kotlin ) Experience w/ Web Technologies ( HTTP ) Experience w/ SQL & NoSQL Technologies ( ex: MySQL, HBase, Mongo, Redis) Experience w/ Search Technologies ( Solr / ElasticSearch ) Experience w/ Processing Pipelines ( YARN, Kafka, Spark ) Experience w/ Hadoop & YARN Required : An analytical mindset Some perks of being on our Squad include... Remote Work: We acknowledge (now more than ever) that you do not need to be in an office or at a desk to be successful! Unlimited PTO: To further support freedom and flexibility, we want you to take the time off when you want or need it to best recharge! Flex-Fridays: Summer Fridays are year long at Mavrck. Catch up on emails on Friday afternoons or start your weekend early - the time is yours! Paid Parental Leave: Take up to 12 weeks paid leave when a little one joins the family! Ongoing Learning: Growth is a big reason people join Mavrck and a core tenet of our culture, so we provide access to a variety of Learning and Development options, like online courses or coaching - and support you pursuing ones that you are passionate about! We Care: 401k, Health, Dental, Vision, Long Term and Short Term disability are part of a comprehensive benefits package Fun, Pet-Friendly Environment: When we’re in the office, music, jeans and t-shirts are the norm - and office dogs!! Yummy Food: Healthy snacks are always provided, and each Wednesday we enjoy catered lunches as a team. Mavrck is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you have a disability or special need that requires accommodation, please let us know by completing the form below."
Data Quality Engineer (Splunk Experience Required),Diligent Solutions,"McLean, VA 22102+1 location",https://www.indeed.com/rc/clk?jk=e13d11ca4712feb5&fccid=e9da322c73f8c190&vjs=3,"Key Role: Translate technical requirements into action, consult in working sessions on problems that may need to be addressed at the solution level or within the Data Quality App or make recommendations on improvements that can be made across the data quality team. Provide engineering support and consultation to the Data Quality team as well as the Integration teams as it relates to data quality. Responsibilities will include the following: Developing and testing new data quality metrics and measures across the program, this may include work in Splunk, Elastic, Python, and may include whitepaper contributions to justify approaches and methods Working with the Data Quality Delivery team to translate and determine technical requirements for the Data Quality Suite of applications as they arise Demonstrate new features of the data quality Suite to stakeholders Develop reporting requirements for the data quality application to meet stakeholder needs Detail and log progress and updates against data quality initiatives Attend weekly standup sessions and report current working status, ongoing initiatives and any blockers to progress against deadlines to the Data Quality team Advise team members on strategies to infer validation results and meaning from Agency environments Work with Agency teams to develop new requirements for the data quality suite of applications Work with the Data integration teams to determine progress against Data Quality Suite updates, provide technical feedback on tasks and assist testing updates to ensure they meet acceptance criteria PoP/Duration: 7 months with the possibility of extension. BASIC QUALIFICATIONS: 2+ years of experience with Splunk (Power User, Admin, etc) 2+ years of experience with Cyber Sensor Tools (Forescout, Bigfix, Tenable) Ability to obtain a security clearance CLEARANCE: DHS EOD or Top Secret Clearance"
Data Protection Engineer,Eze Castle Integration Inc,"Remote in Seattle, WA",https://www.indeed.com/rc/clk?jk=194627aba81770f0&fccid=6e86f74f69308df6&vjs=3,"ECI is the leading global provider of managed services, cybersecurity, and business transformation for mid-market financial services organizations across the globe. From its unmatched range of services, ECI provides stability, security and improved business performance, freeing clients from technology concerns and enabling them to focus on running their businesses. More than 1,000 customers worldwide with over $3 trillion of assets under management put their trust in ECI. At ECI, we believe success is driven by passion and purpose. Our passion for technology is only surpassed by our commitment to empowering our employees around the world. The Opportunity: The Data Protection Engineer is responsible for delivering first class service, advice and technical support to Eze Castle clients, through the highest standards of customer service, efficiency, knowledge and integrity. This would include supporting and maintaining Disaster Recovery and Backup solutions, configuring and maintaining server replication and backup software, performing DR site testing and activations as well as documenting, troubleshooting and maintaining client solutions. The candidate will interface with high profile financial industry clients daily thus requiring the highest level of presentation, communication and professionalism. This is a remote position and can be based anywhere in the U.S. The working hours for this position are 9a - 6pm PST or 12pm - 9pm EST. What you will do: Supports all implementations, testing and recovery efforts as it pertains to Disaster Recovery and Cloud Backup solutions. Configure, monitor, and support virtual replication and backup software Independently performs backup restorations of full machines, file and SQL databases as required Independently performs fail over testing of disaster recovery sites as required Works effectively with cross-functional teams within the organization Manipulate DNS, Active Directory and OU structure as required for failover testing Engages with Clients and Vendors to perform fail over testing of disaster recovery sites as required Collaborate with third party market vendors to assure clients’ ability to successfully work out of DR applications Ability to troubleshoot and resolve complications while performing testing or failovers Reinstallation and troubleshooting replication and backup software Ability to troubleshoot Citrix/Netscaler environment problems Monitors and maintains global client environments in the event of systems failure or disaster Monitors and maintains global backup cloud environments Conducts site assessments and software version upgrades Knowledge of automation for efficiency improvements Engages in self-directed continuous improvement and learning of various products: Participates in on-call engineer rotation for afterhours site monitoring and maintenance Who you are: Basic understanding of networking concepts: TCP/IP, LAN/WAN, DHCP, DNS, Routing, Switching and Firewalls General knowledge of virtualization software such as VMWare vSphere Knowledge of Zerto and ASR replication software or similar enterprise level software Knowledge of Data backup and recovery with Acronis and Azure Cloud Backups or similar enterprise level software Deployment and troubleshooting of operating systems and applications Microsoft Windows 7/8/10, Microsoft Office 2010-2019, Microsoft Server 2008 R2-2016, Basic experience with public cloud technologies Familiar with cyber-security concepts (Multi-Factor Authentication, Anti-virus/Anti-malware, Software Firewall, Web Filtering) General knowledge of Storage Area Networks General knowledge of Citrix Environments/Netscaler General knowledge of Linux and/or Solaris Operating Systems Ability to perform patching and maintenance of replication and backup software Financial industry experience including familiarity with market vendor applications ECI’s culture is all about connection - connection with our clients, our technology and most importantly with each other. In addition to working with an amazing team around the world, ECI also offers a competitive compensation package, unlimited PTO, benefit eligibility the first of the month, pet insurance, 401K with employer match and so much more! If you believe you’d be a great fit and are ready for your best job ever, we’d like to hear from you! Love Your Job, Share Your Technology Passion, Create Your Future Here! *ECI* #LI-Remote"
Data Engineer,"Avetta, LLC","Remote in Irvine, CA 92614",https://www.indeed.com/rc/clk?jk=37cf8d2e2682d737&fccid=b1588b29770d2107&vjs=3,"What we're about The Avetta Connect platform helps save lives, time and money by connecting companies with qualified certified suppliers who can safely and successfully complete their business-critical projects. Our Impact Our customers ask a lot of great questions. We have a lot of insightful answers locked in our data. We are a team of data engineers and data scientists continually helping our clients find insights as well as enabling clients to find their own insights through our killer analytics SaaS application. Stuff you'll find yourself doing Working with product management, business analysts, and data scientists to understand their questions Combing through our data sources to understand what's available and what isn't Designing and building intuitive relational and non-relational data models Writing and managing ETL processes Things you need to know Highly proficient with SQL (we can't over stress this) Highly proficient with relational databases (another must have) Ability to speak database and business and know when to speak what Strong understanding of relational data models Ability to use the tools of the trade to move data into, out of, over, under, between and around databases, spreadsheets, web pages and mobile devices Ability to code or script in one or more widely used languages Linux experience as well as some bash Working knowledge of GitHub Things it would be nice if you had Experience with a BI tools Experience with Document DBs Experience working in Agile teams Experience you bring 5+ years of Data Engineering B.S. in Computer Science or equivalent (experience and results matter most) How we go about what we're about We believe in results and understand that there are a lot of different ways of achieving them. We try to keep the overhead (needless meetings) low and the productivity (writing production code) high. We equip our developers with the best modern tools available and try to strike the right balance between structure and flexibility. #LI-HYBRID #LI-REMOTE"
"Software Engineer, Data Engineering, Diagnostics",Tesla,"Austin, TX+2 locations",https://www.indeed.com/rc/clk?jk=e018ecf19993e964&fccid=86e9be6ce380173e&vjs=3,"The Role Data is deeply embedded in the product and engineering culture at Tesla. We collect data from our vehicle fleet and use it to support service and engineering in identifying issues at the fleet or vehicle level, enabling diagnostic automation and technician workflow to identify issues and take corrective actions. We're looking for a talented engineer to join us in analyzing and reporting on data, creating ETL processes, and implementing improvements to our data platform. Your work will affect thousands of technicians and Tesla engineers daily, enabling them to keep our vehicle fleet on the road and improve customer experience. Responsibilities Develop analysis and reporting focused on operational, technical metrics and KPIs Deliver quick turnarounds on dashboards, identify trends and/or issues within data sets, and make recommendations to influence business decisions and investments Improve our data platform by improving performance, stability and maintainability of our relational databases, ETL pipelines, queue (Kafka, RabbitMQ) environments Evaluate the effectiveness of engineering initiatives and deliver actionable insights to improve service productivity Present analytical results and insights to business partners to answer strategic questions and influence business decisions Requirements Minimum of 2-3 years of experience in a data analytics related capacity Understanding of relational database theory and proficiency in writing, understanding, and optimizing complex SQL code Software engineering fundamentals Experience with Business Intelligence tools (eg Tableau or Superset) and real time dashboard development Experience with Jupyter, Pandas workflow Understanding of queue-based environments including Kafka or AMQP Robust DevOps abilities and a strong predilection for automation Strong communication, organizational, and analytical and problem solving skills Strong business acumen Nice to Have Knowledge of statistical models, predictive model development (Python, R, SAS, etc), machine learning, proficiency in Spark"
Senior Data Engineer,Handshake,"Denver, CO",https://www.indeed.com/company/Handshake/jobs/Senior-Data-Engineer-8c1eb8c24783b90b?fccid=5045f1e21f74624d&vjs=3,"We are thrilled to announce Handshake's $200M Series F funding round. At Handshake, we believe that a career opportunity shouldn't be determined by who you know or what you've done. It's about what you can - and will - do. Your future, not your past. Our Series F fundraise and new valuation of $3.5B will fuel our next phase of growth and propel our mission to help more people start, restart, and jumpstart their careers.Handshake is the #1 place to launch a career with no connections, experience, or luck required. Handshake's community includes 20 million students and young alumni around the world from 1,400 educational institutions, including four-year colleges, community colleges, boot camps, and 290+ minority-serving institutions. The platform connects up-and-coming talent with 650,000+ employers - from Fortune 500 companies like Google, Nike, and Target to thousands of public school districts, healthcare systems, nonprofits, and even sports teams like the LA Dodgers. Handshake is headquartered in San Francisco with offices in Denver, New York, and London and teammates working globally.Everyone is welcome at Handshake. We know diverse teams build better products and we are committed to creating an inclusive culture built on a foundation of respect for all individuals. We strongly encourage candidates from non-traditional backgrounds, historically marginalized or underrepresented groups to apply.If you are not sure that you're 100% qualified, but up for the challenge – we want you to apply. We believe skills are transferable and passion for our mission goes a long way. Your Impact: Handshake is building a diverse team of dynamic engineers who value creating a high quality, high impact product. You will use your technical knowledge to drive the architecture, implementation and evolution of the data platform we are current developing. You will also be working with product teams helping millions of students find meaningful careers regardless of where they go to school, who their parents know, or how much money they have.We're focused on building a data platform that will ensure all teams are capable of creating data-driven features, and all sides of the business have access to the right data to make the correct decisions.Your Role: Working closely with product managers and product engineers to ship data-driven features Closely interact with data scientists and analysts to build pipelines and warehousing solutions Translate business requirements into data models that are easy to understand and used by different disciplines across the company Design, implement and build pipelines that deliver data with measurable quality under the SLA Your Experience: You prefer taking projects from inception to completion and are outcome oriented. You have a consistent track record of designing and implementing scalable, robust data pipelines, data services and data products. You have experience working with tracking systems, click streams and session analytics. You have experience providing technical leadership and mentoring other engineers for best practices on data engineering. You are proud of your craft, and enjoy and value clean code that scales to keep large teams productive. You have the ability to navigate between big-picture and implementation details. Bonus Areas of Expertise You have experience debugging and creatively solving problems in the data landscape Experience developing data marts and creating and enforcing access/governance Experience in Spark or other distributed data applications Experience with any of the following: Airflow dbt Google Cloud Platform data technologies (BigQuery, DataFlow, etc) Compensation Range$163,625 - $200,000 For cash compensation, we set standard ranges for all roles based on function, level, and geographic location, benchmarked against similar stage growth companies. In order to be compliant with local legislation, as well as to provide greater transparency to candidates, we share salary ranges on all job postings regardless of desired hiring location. Final offer amounts are determined by multiple factors including geographic location as well as candidate experience and expertise, and may vary from the amounts listed above. Benefits: At Handshake, we'll give you the tools to feel healthy, happy and secure. Stock: Ownership in a fast-growing company. Hub-Based Remote Work: Handshakers can enjoy the flexibility of remote work whilst ensuring in-person collaboration, and team experiences remain possible. Financial Management with Origin: We provide you with a professional financial planner via Origin to gain a better understanding of making the most of your compensation, equity, benefits, and perks. Paid Parental Leave: All new parents at Handshake (both birth and non-birth giving) are encouraged to take time to focus on their growing family and are eligible for paid family leave. US Handshakers are provided up to 16 weeks of paid family leave for birth-giving parents and 10 weeks for non-birth-giving parents. Mental Health Assistance: We are here to support you in every step of your mental health journey; our benefits include Employee Assistance Programs that offer counseling support for those eligible. Home Office Stipend: Handshake offers $500/£360 for you to spend on setting up a productive and comfortable workspace at home. Learning: Learning & Development opportunities and an annual $2,000/£1,500 stipend for you to grow your skills and career. Team Bonding: Regularly scheduled virtual company-wide and team events! Once it's safe, we'll provide meaningful connection points throughout the year for Handshakers to build community and meet teammates in person. Great team: Working with fun, hardworking, nice people who are committed to making a difference! (US Handshakers) 401k: We care about your ability to save for your future. Launching Spring 2022, Handshake will offer a dollar-for-dollar match on 1% of deferred salary, up to a maximum of $1,200 per year. Healthcare: World-class medical, dental, and vision policies including LGTBQ+ Coverage. 2022 Time Off: All full-time US-based Handshakers are eligible for our flexible time off policy to get out and see the world. We also offer 8 standardized holidays, 2 additional days of flexible holiday time off, and 2 one-week periods of Collective Time Off (7/4-7/8/2022) and (12/26-12/30/2022). (UK Handshakers) Pension: Handshake matches 3% of your salary towards your pension scheme. Healthcare: Handshake's comprehensive healthcare policy covers 100% of employee premiums & 100% of dependent premiums for medical, dental, and vision benefits. 2022 Time Off: Up to 25 days of vacation to encourage people to reset, recharge, and refresh, in addition to 8 bank holidays throughout the year. Benefits above apply to employees in full-time positions. Looking for more? Explore our comprehensive US benefits at joinhandshake.com/careers. Interested in what Handshake's San Francisco HQ is like when we're together? Check out this video: Job Type: Full-time"
BI Data Engineer,HEARTLAND,Remote+1 location,https://www.indeed.com/rc/clk?jk=72f8ebbdbbbf64f2&fccid=de6dd9565e6db875&vjs=3,"Description: Position Summary: This position would require a candidate to possess a strong technical background in developing and delivering BI solutions along with a strong understanding of SQL Server environments. Business intelligence (BI) is a set of technologies and practices for transforming business information into actionable reports and visualizations. The BI Data Engineer transforms data into a useful format for analysis and is focused on the design and architecture. A BI Data Engineer is the data professional who prepares the data infrastructure to be leveraged by the HBS BI Data Developers. The BI Data Engineer will design, build, integrate data from various resources and manage big data. The BI Data Engineer ensure the operations of the data pipeline follow a consistent process of Ingestion, Processing, Storage and Access. The work involves tuning databases for fast analysis and creating table schemas. The BI Data Engineer is responsible for making data easily accessible, ensure the process works smoothly and is optimized. The BI Data Architect is a critical firm member of the Data Team, The BI Data Engineer will run Extract, Transform and Load (ETL) on top of datasets and create data warehoused that can be used for reporting and analysis. The BI Data Engineer ensure the operations of the data pipeline follow a consistent process of Ingestion, Processing, Storage and Access. Roles and Responsibilities/ Essential Functions: Meet with clients to understand their current business processes and needs to provide consulting services and direction on how to build or grow their current data strategy Work with HBS Sales Solutions consultants to identify and grow opportunities within HBS client environments Support and administer the underlining infrastructure and layout of a client data environment Develop and design the process for the customer data collection process Develop policies and procedures for the collection and analysis of data Review customer sources to ensure integrity of the data collection process Collaborate with the BI Data Developers to ensure the requirements are being met to build the right solution needed Estimate development effort required to delivery data customer needs and requests Use business analysis skillset to identify development needs for the purpose of streamlining and improving the operations of the organization for efficiency and profitability Ability to work independently or as a team on project-based solutions for clients Work with team mates to continue to grow and mature data services and delivery options for HBS clients Based on experience, one may mentor other engineers in developing scalable, secure, high-performance BI and Data solutions . Requirements: Competencies Accuracy – Ability to produce high quality work deliverables leveraging industry best practices Analytical Skills - Strong abilities require to effectively interpret customer business needs and translating them into application and operational requirements, resolving complex technical and business problems Communication – strong written, verbal, and non-verbal communication skills, especially conveying complex information in an understandable manner Leadership – Ability to motivate and guide others to ensure performance is an accordance with clear expectations and goals Learning – Ability to quickly learn new technologies to deliver solutions Presentation Skills – Ability to effectively conduct formal and informal presentations in both small and large group settings within all levels of a company Project Management – Ability to demonstrate an understanding of process engineering, planning, organizing, staffing, directing, and controlling work tasks Time Management – Ability to effectively utilize available time for managing multiple tasks/projects simultaneously Required Experience: Experience with needs analysis, software evaluation and selection, customization, and implementation Data Warehousing systems and architecture experience in 'real world', practical, successful implementations Understand multi-dimensional database structures and schemas Strong knowledge of system design, development, and deployment Microsoft BI Suite Experience Microsoft Excel Microsoft SQL Server Analysis Services (SSAS) Microsoft SQL Server Integration Services (SSIS) Programming and Processing Experience T-SQL ETL Azure Experience Azure SQL Database Azure SQL Manage Instance Azure Architecture Azure Data Factory Strong knowledge of SQL utilizing MS SQL Server Preferred Experience: Expertise in Professional Services or similar client facing roles Experience in multiple industry (Education, Healthcare, Retail, Manufacturing) verticals PowerShell knowledge and understanding Understanding of report writing and visualization Programming and Processing Experience DAX Power Query M Microsoft BI Suite Experience Microsoft SQL Server Reporting Services (SSRS) Microsoft Power BI Microsoft certified: Data Analyst Associate Microsoft certified: AI-900 - Microsoft Azure AI Fundamentals Microsoft certified: DP-200 - Implementing an Azure Data Solution Microsoft certified: DP-201 - Designing an Azure Data Solution Microsoft certified: DP-300 - Administering Relational Databases on Microsoft Azure Required Skills, Education and/ or Certifications: Bachelor’s degree in business or I.T. related discipline accepted Equal Opportunity Employer - Disabled/Vets #HBS"
Distinguished Engineer - Data Ingestion and Stream Processin...,Splunk,"San Francisco, CA 94107 (South Of Market area)+3 locations",https://www.indeed.com/rc/clk?jk=329309863e0d2196&fccid=aef928e89977f7f0&vjs=3,"Distinguished Engineer, Data Ingestion and Stream Processing Join us as we pursue our disruptive new vision to make machine data accessible, usable and valuable to everyone. We are a company filled with people who are passionate about our product and seek to deliver the best experience for our customers. At Splunk, we’re committed to our work, customers, having fun and most importantly to each other’s success. Learn more about Splunk careers and how you can become a part of our journey! Team: The Data Ingestion and Processing team is a dynamic technology group with a mission to be the primary data processing engine for any type of data transformation and routing activity in near real-time. If you embrace the challenge of working at the frontier of what is possible in the industry today, then this position is for you. We are building state-of-the-art capabilities, real-time messaging and streaming systems, support tools, and automation instrumentation that will greatly impact how our customers successfully use data to improve their businesses performance, scalability, profitability, and market strategies. Role: In this role, you will Evolve the architecture and design of our platform to meet ever-increasing scalability and performance requirements. Help define the future of our edge, hybrid and cloud products by designing, creating, testing, and maintaining critical services Bring creativity and passion to influence the strategic direction of our technology and products as well as mentor other members of your team Meet customers, build empathy towards their experiences, get a first-person view of the state of the art in ingestion and streaming systems Collaborate with product management to define and craft new products Provide technical leadership across multiple product areas, and be frequently consulted by senior leadership Be actively involved in hiring of technical leads, architects, and senior engineering leaders Requirements: To be successful, you have: A deep, technical understanding of streaming computation, including trade offs and factors driving design decisions A strong customer focus and working backwards from their needs Led the architecture of successful, large scale streaming products Have been through multiple full product life cycles Delivered exceptional business outcome in cloud and hybrid environments Mentored senior and/or principal engineers to get them to the next level Been recognized as an industry expert in distributed systems and data streaming Bachelor’s degree in Computer Science, Computer Engineering or equivalent 15+ years of engineering experience focused on application development (or Masters and 12 + years related experience or PhD and 8+ years experience) Plus: Not required, and would be good to have: Experience with Splunk software or a similar analytics solution Experience with leading or contributing to open source projects Experience with working in a direct customer facing environment We value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or any other applicable legally protected characteristics in the location in which the candidate is applying. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records."
Senior Data Engineer,Yukon-Kuskokwim Health Corporation,"Bethel, AK",https://www.indeed.com/rc/clk?jk=7cdc8035081418f4&fccid=864a7ea5427c484c&vjs=3,"Senior Data Engineer Bethel, Alaska The vision: Through Native Self-Determination and Culturally Relevant Health Systems, we strive to be the healthiest people. At the Yukon-Kuskokwim Health Corporation (YKHC) we administer a comprehensive healthcare system throughout 58 rural communities with a mission of Working Together to Achieve Excellent Health. YKHC serves 58 federally-recognized Tribes and operates 41 Village Clinics. Our five larger communities are served by five Sub-Regional Clinics. All communities in our service area are served by the 55 bed regional hospital in Bethel. For more information about our hospital or the region please visit Yukon-Kuskokwim Health Corporation – We Strive to be the Healthiest People (www.ykhc.org) Position Summary: A Senior Data Engineer is responsible for overseeing the maintenance, security, and use of company databases. Duties include storing and managing data, monitoring and ensuring security to combat potential security breaches, creating account data for authorized individuals to access databases, linking databases to the Enterprise Data Warehouse (EDW), and organizing databases so individuals can find important documents or retrieve information in an efficient manner. The Senior Data Engineer position will lead a small team in the development and availability of accurate, reliable, and timely information to assist leaders and staff. The position serves as a resource for the use of analytic tools to empower staff to continuously improve processes throughout the organization. This responsible for ensuring new and existing staff are proficient in the use of the reporting tools, and that they are made aware of training and education opportunities. The position will organize and facilitate the Data Governance committee – which includes agenda creation, meeting minutes, scheduling meetings, and prioritizing objectives. The position may be expected to complete other duties as assigned by the CIO. Position Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions and other duties as assigned. Bachelors’ degree preferably with an emphasis in statistics or computer sciences. Education may be substituted for experience. Minimum 7, 10 preferred – years of experience in working with databases. Base SAS certification preferred Must have computer skills needed to access computerized medical records, and warehouse, mine, and analyze data. Specialized Knowledge and Skills Extracting translating and loading data for the EDW Ensuring all hardware and software are updated Authenticating data Monitoring the performance of hardware and software Preserving data integrity Ethically handling private data, including financial and/or healthcare data Basic knowledge of interfaces Strong project management, verbal and written communication skills. Ability to teach basic data analysis tools to a diverse audience, including those without advanced training Familiarity with database queries Knowledge of database design and theories Knowledge of database structure languages, such as SQL and SAS Experience with server installation and maintenance Familiarity with database management best practices Knowledge of IT security best practices Experience with a variety of computer information systems Some supervisory experience Benefits Include: Generous PTO – beginning at 4.5 weeks Ten paid holidays Comprehensive healthcare coverage Life and Disability Insurance Flexible Spending Account Retirement plans Employee Wellness Center Additional Information: ID: 14400 Location: Bethel Department: Technology Employment Duration: 80 Full time Temporary Status: Not Applicable Hours per Week: 40 Yukon Kuskokwim Health Corporation is an Affirmative Action/Equal Opportunity Employer. All qualified individuals will receive consideration for employment without regard to race, ethnicity, age, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status and any other basis protected by law. Individuals with disabilities needing assistance in the recruitment process are encouraged to contact Human Resources directly. Under P.L. 93-638, preference is given to Alaska Native/American Indian applicants. For more information, please contact the YKHC Recruitment Department at YKHCRecruitment@YKHC.org or phone (907) 543-6060 and ask to speak with a recruiter. To view more positions available please visit YKHC Career Center (https://chu.tbe.taleo.net/chu01/ats/careers/v2/jobSearch?org=YKHC&cws=41)"
Data Engineer,Doximity,"Remote in Augusta, GA+1 location",https://www.indeed.com/rc/clk?jk=c4887df533bb44a4&fccid=cc9f04eed69b86b2&vjs=3,"Doximity is transforming the healthcare industry. Join our mission to help every physician be more productive and provide better care for their patients. As medicine's largest network in the United States, there's an elevated level of responsibility in everything we do. We don't take that responsibility lightly and are committed to building diverse teams with an inclusive culture that can make a direct impact on the healthcare system. One of Doximity's core values is stretching ourselves. Even if you don't check off all the boxes below we encourage you to apply. Doximity is full of exceptional people who bring their own unique experiences to work everyday and make us all better for it! This role can be filled in our San Francisco headquarters OR remotely in the U.S. About you You have professional experience developing data processing, enrichment, transformation, and integration solutions. You are fluent in Python and SQL. You are no stranger to data warehousing and designing data models. You are foremost an engineer, making you passionate for high code quality, automated testing, design patterns, and other engineering best practices. You care deeply about the data being generated. You study the data and extract insights from it before you process it. You are user experience and product focused. You build solutions while thinking about the impact it has on our users and enhances the product. You are able to work within an existing data architecture finding gaps in it and enhancing it to ensure solutions are fault tolerant, scalable, and easy to iterate upon. You have the ability to self-manage, prioritize, and deliver functional solutions. You can see a project from end-to-end, from idea generation, planning, execution through delivering. You agree that concise and effective written and verbal communication is a must for a successful team. Here's How You Will Make an Impact Collaborate with product managers, data analysts, and machine learning engineers to develop pipelines and ETL tasks in order to facilitate the extraction of insights. Build, maintain, and scale data pipelines that empower Doximity's products. Establish data architecture processes and practices that can be scheduled, automated, replicated and serve as standards for other teams to leverage. Work alongside others in planning and carrying out the implementation of solutions that are focused on enhancing products, leading one or two projects at any given time. About Us Explore our stack We have over 500 private repositories in Github containing our pipelines, our own internal multi-functional tools, and open-source projects We have worked as a distributed team for a long time; we're currently about 65% distributed Find out more information on the Doximity engineering blog Our company core values Our recruiting process Our product development cycle Our on-boarding & mentorship process Benefits & Perks Generous time off policy Comprehensive benefits including medical, vision, dental, Life/ADD, 401k, flex spending accounts, commuter benefits, equipment budget, educational resources and conference access Family support and planning benefits Stock incentives .. and much more! For a full list, see our career page More info on Doximity For the past decade, it's been our mission to help every physician be more productive so they can provide better care for their patients. We believe that when doctors are connected, the healthcare system works better and patients benefit. Doximity enables our verified clinician members to collaborate with colleagues, stay up-to-date with the latest medical news and research, manage their careers, and conduct virtual patient visits. Today, Doximity is the leading digital platform for U.S. medical professionals, with over 80% of physicians, 50% of all nurse practitioners and physician assistants, and 90% of graduating medical students as members. Joining Doximity means being part of an incredibly talented and humble team passionate about improving inefficiencies in our $4.3 trillion U.S. healthcare system. We are a team of doers who solve problems everyday by treating obstacles like an adventure, and we love creating technology that has a real, meaningful impact on people's lives. Doxers are committed to working towards a more equitable world both within and beyond our office walls. This starts by fostering an inclusive and diverse work environment where differences are valued and all employees are encouraged to bring their full, authentic selves to work daily. To learn more about our team, culture, and users, check out our careers page, company blog, and engineering blog. We're growing fast, and there's plenty of opportunity for you to make an impact—join us! For more information, visit Doximity.com. ____________________________________________ EEOC Statement Doximity is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law."
Data Engineer Ssr Ba3711,Nisum,+3 locationsRemote,https://www.indeed.com/rc/clk?jk=0d8785a96019a224&fccid=51280efa86c03cda&vjs=3,"Location: Remote Latin American Team: Data Science & Analytics Work Type: Full Time Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto “ Building Success Together®,” Nisum has grown to over 1,800 professionals across the United States, Chile,Colombia, India, Pakistan and Canada. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today’s world, with immersive and seamless experiences across digital and physical channels. Para tener éxito en este rol, esperamos que cuentes con las siguientes habilidades y experiencia: Spark HDFS (Hadoop Distributed File System) / Apache HIVE / ZEPPELIN Pruebas de performance (de carga de flujos de datos) Librerías o framework para desarrollo de ETL (mallas de procesos, desarrollo de procesos, integración con sistemas legados) GCP (Dataproc, Cloud Storage, gcloud, gsutil) Conocimiento de Scala Perfil de conocimientos (deseable) GCP (bigquery, data catalog) Huemul (http://www.huemulsolutions.com/) o similares #Li-Remote ¿Qué te ofrecemos? Pertenecer a una empresa internacional y multicultural que apoya la diversidad. Formar parte de proyectos internacionales con presencia en Norteamérica, Pakistán, India y Latam. Entorno de trabajo con amplia experiencia en trabajo remoto y distribuido, usando metodologías ágiles. Cultura de constante aprendizaje y desarrollo en tecnologías actuales. Ambiente agradable y colaborativo, con foco en el trabajo en equipo. Acceso a plataformas de aprendizaje, certificaciones Google Cloud, Databricks, clases de inglés y español, Tech Talks, etc. Formar parte de diversas iniciativas y participación continua en actividades internas y externas de innovación, hackathon, tecnología, agilidad, charlas, webinars, bienestar y cultura con posibilidades no solo de participar sino de ser expositor. Si resides en Chile, accedes además a estos beneficios: Tarjeta Sodexo, beneficio de Sala Cuna, convenio con el gimnasio SmartFit, acceso a Seguro Complementario de Salud, Mutual de Seguridad, ¡entre otros! Para que tengas en cuenta :) Nisum Latam se encuentra trabajando de manera remota. Este puesto es full time. Nisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace."
Data Engineer (Python),Tista Science and Technology Corporation,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=9771b184d8d0946c&fccid=1cd3fff6ba29c8a6&vjs=3,"Overview: Are you a Data Engineer (Python) looking to positively affect the lives of millions of people? If so, you can join a team helping to reshape healthcare IT at CMS! The sucessful candidate will be responsible for collecting, analyzing, and interpreting data. The end goal is to increase quality, expand business decisions, and determine areas of error that require data improvement. Responsibilities: Collect, analyze, and interpret data in to improve data quality, make effective business decisions, and determine areas of error that require data improvement. Conduct complex data analysis and report on results Explore ways to enhance data quality and reliability Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it Collaborate with business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making Perform data analysis required to troubleshoot data related issues and assist in the resolution of data issues Work closely with a team of Engineers, Product Managers, and Business Analysts Work closely with engineering teams to support development of data architecture Qualifications: 5+ years’ proven work experience as a data analyst on complex data systems 3+ years’ technical experience in dimensional and ER data models, and database design development 2+ years' hands-on in Python programming, Core Python and using libraries Expertise on Python Data structures and Data wrangling concepts Hands-on in CI/CD deployment processes Hands-On experience in Python ETL framework Advanced knowledge of SQL required Experience designing, building, and maintaining data processing systems Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy Experience writing queries, reports, and presentations of findings geared to Business Owners and to non-technical personnel Experience in Medicare and Medicaid data analysis is a plus Bachelor of Science (B.S.) in Mathematics, Economics, Computer Science, Information Management or Statistics Clearance: Must be eligible to hold a Public Trust security clearance Must have worked in the U.S. three out of the past five years Location: Remote"
Systems Engineer - Data Center Storage & Backup,Walt Disney Animation Studios,"Burbank, CA",https://www.indeed.com/rc/clk?jk=c2ee8c03af15fe39&fccid=779381286967ed9f&vjs=3,"Walt Disney Animation Studios’ world-class filmmakers, artists, and technical wizards collaborate to create the magic of animation. Bring your unique talents, passion, and ideas to our team and prepare to play in a creative environment. The Systems Engineer will lead efforts on the Data Center team to design, implement and administer complex systems in the Studio’s data center & related areas. This includes physical and virtual server environments, enterprise storage & compute systems, large scale backup & archive systems and other enterprise systems that provide foundational services and infrastructure for the Studio. The Systems Engineer will collaborate with other engineers and support staff to address challenges, plan/lead projects throughout the year, and identify long-term technical goals. Responsibilities : Data Backups, Archive, Disaster Recovery Manage the studio’s data backup processes. This includes the design of new systems & processes based on the Studio’s needs and improving existing systems. Author and maintain a thorough disaster recovery program that includes regular tests Work with studio leadership to create and/or improve a data archival process. Lead efforts to investigate cloud migration of relevant data Data Storage Design and maintain storage systems to support various applications Partner with other tech teams and production eadership to design and implement large scale production storage systems Servers & VMs Work with the team to design and maintain necessary server infrastructure for the studio’s various applications. Investigate best in class server hardware. Help to maintain annual installation, replacement and support budget and schedule Lead efforts/partner with other tech teams to design and implement VM environments. Maintain a support and upgrade budget and schedule for all systems. Data Center Lead efforts to plan and execute installation projects, including large replacements/expansions of equipment. Work with the team to schedule and perform necessary maintenance, upgrades and troubleshooting of all systems. Allow for a flexible work schedule to accommodate disruptive maintenance events. Help to create & maintain runbooks of all relevant processes and protocols Help to build and manage monitoring systems for relevant technologies, including storage systems, server health & status and physical infrastructure General Help to create an annual budget for technology purchases relating to the Data Center. This includes equipment recapitalization, integration of new, or expansion of existing technologies, maintenance, etc. Work with hardware vendors to evaluate new technologies. Basic Qualifications : At least 5 years experience in enterprise data center engineering & administration Expert knowledge of common scale-out/high-performance storage systems, such as Isilon, Qumulo, NetApp or Vast. Expert knowledge of design and administration of virtual computing environments, such as VMware, RHEV, Kubernetes, Docker, etc. Expert knowledge of design and administration of common backup/archival technologies, products and principles such as NetBackup and Bareos, Quantum, LTO. Expert knowledge of fiber channels. Strong knowledge of Linux, deep experience with common Linux environment administration (Red Hat, etc). Previous experience with co-location environments Preferred Qualifications: Experience with film production, CG Animation, Visual Effects, or Video Game production environments. Familiarity with Mac / Windows administration. Strong understanding of computer room design, installation, configuration, troubleshooting, monitoring, and security procedures. Familiarity of the physical data center environment, including HVAC, electrical and other systems Strong understanding of major cloud platforms including AWS, GCP and Azure. Familiarity with network technology and communication principles. Proficiency with common scripting languages, i.e. Python, Perl, JavaScript or similar Required Education : Degree in Computer Science, Computer Engineering, or related Information Technology/Computer Systems field, or equivalent work experience"
Senior Data Solutions Engineer,VSP Global,Remote,https://www.indeed.com/rc/clk?jk=6fbb778832303fd8&fccid=274e39ee4b679fc5&vjs=3,"The Sr. Data Solutions Engineer works directly with business stakeholders to design data and analytics capabilities that support business strategies and to develop the data models and structures that enable data-driven solutions. The Sr Data Solutions Engineer develops data models and structures that can be used within the business to find data driven solutions. Work with business stakeholders to identify how data can be leveraged to improve decision making Work with technology teams to analyze data requirements (functional and non-functional) and provide data architectural design solutions for business and technology initiatives Assess the effectiveness and accuracy of data sources and data gathering techniques Design data structures, data models and data pipelines, leveraging the support of subject matter experts to deliver business intelligence / data science capabilities for the organization Create data models at all levels including conceptual, logical, and physical Collaborate within an agile, multi-disciplinary team of data engineers, data analysts, UX designers and scrum master to deliver solution Work with Data Scientists on optimizing batch and real-time processes for feature engineering, training models, and serving predictions Research, promote, and develop data architecture best practices, guidelines, procedures and scalable frameworks. Participate in architecture, governance and design reviews Participate in evaluations of existing and emerging analytical technologies and provide recommendations Minimum Qualifications Bachelor’s degree in computer science, data science, statistics, economics or related functional area; or equivalent experience Excellent written and verbal communication skills with the ability to gather requirements and effectively communicate technical concepts and ideas to all levels of employees and management 6 years’ experience working with end-users in development of analytical capabilities 6 years of hands-on experience in the data space spanning data modeling, SQL-based database management systems, integration, ETL / data pipeline design and data visualization Experience years expert level SQL coding experience Preferred Skills Significant experience in dimensional modeling Prior experience using Snowflake for data warehousing is beneficial, as is prior experience with Data Vault modeling Good interpersonal skills that support effective collaboration with business colleagues Capable of balancing solution design with effective modeling techniques Familiarity and strong technical understanding of REST APIs is valuable Python experience is not required but beneficial #LI-REMOTE #LI-VISIONCARE VSP Vision is an equal opportunity employer and gives consideration for employment to qualified applicants without regard to age, gender, race, color, religion, sex, national origin, gender identity, sexual orientation, disability or protected veteran status. We maintain a drug-free workplace and perform pre-employment substance abuse testing."
Data Engineer/Developer,Byte Systems,"Reston, VA",https://www.indeed.com/rc/clk?jk=3904048ab4eed158&fccid=76f9e09af8745420&vjs=3,"The Sponsor applies technical resources to accelerate the timely, reliable, and secure delivery of open source data, information, and insights. The Sponsor requires support to maintain and enhance an existing big data exploitation platform. The Contractor will work within an agile team environment. Work will include creating Amazon Web Services (AWS)-based resources; writing, testing, and debugging custom application code; administering database services; and performing data cleaning, formatting, and other forms of data management. The Team shall work closely with the Sponsors product owner and program manager to deliver user stories necessary to realize product vision. The Team shall coordinate with multiple entities, including mission partners, to ensure tools meet defined requirements. The Team shall apply an agile approach to software development consistent with the Sponsors project management and software development frameworks with a focus on demonstrating and delivering releasable software every iteration. The Team shall create and maintain JWICS-accessible resources within the Sponsors Amazon Web Services (AWS) Cloud environment. The Team shall ensure all security vulnerabilities are addressed as appropriate by severity and maintain security accreditation, including maintaining plan of action for vulnerability remediation. The Team shall maintain all source code in Sponsor-wide, remote Git repository. The Team shall apply industry best practices (such as, but not specifically Test Driven Development) for ensuring custom application code is comprehensively tested. The Team shall administer and maintain relational and non-relational transactional database systems within the application security boundary. The Team shall perform data cleaning and formatting for ingested data ensuring they meet quality and content management standards.CERTS MUST be a US Citizen with a U.S. Government clearance - Intel with Polygraph NOTE: Must have an active TS-SCI with poly. No sponsorships or upgrades are available. Submissions without this requirement will not be considered. H1-B holders will not be considered. Benefits: 5 week paid vacation + 10 gov't holidays 15% contribution to 401k LTD, STD disability and life insurance Paid health, dental, and vision for employee and family. $5000 annual training expense reimbursement Computer purchase plan"
Senior Software Engineer - Data Platform,Panther Labs,"Remote in San Francisco, CA",https://www.indeed.com/rc/clk?jk=e5364122caf8854a&fccid=33ac3ace1a038a8d&vjs=3,"The Job As a Senior Data Platform Engineer at Panther, you will be responsible for enabling Panther teams and customers to have a seamless and performant experience utilizing our data platform and data features. The Company Panther is a cybersecurity company with the mission of detecting any breach, anywhere. The company was founded by security practitioners that lived through the challenge of protecting large organizations and wanted to build a solution that many teams could use. Panther solves modern security challenges with detection-as-code, a cloud-native architecture, and robust security data lake. Panther's platform, used by many industry leaders, enables security teams to focus on security, detect attacks, and protect their organizations without prohibitive overhead or excessive operational costs. Backed by Coatue Management, Lightspeed Venture Partners, S28 Capital, Snowflake Ventures, ICONIQ Growth, and Innovation Endeavors, Panther has raised $120M, at $1.4 billion-dollar valuation, and is quickly accelerating its mission and employee base across the United States and Greece. Panther's customers include industry-leading technology companies such as GitLab, Coinbase, and Dropbox, and the company was featured for a second year in a row on EnterpriseTech30's startup list, most as recently as #6 on the list of mid stage, emerging technology companies! Panther is a remote-first company with a culture of flexibility, written documentation, open company communication, and collaboration. Our values guide our every move: Be an Owner, Move Fast, and Take Care of the Team. We believe that by building a diverse group of remote individuals, we can push forward our mission and create a rewarding, inclusive, and fun work environment for our entire team. The Responsibilities Support new data platform providers when the business identifies the right partnership opportunities Support new data platforms when the Engineering organization has a need that isn't met by existing technologies (RDS, Redis etc.) Support new data platform provider features quickly to enable EPD teams to deliver new or enhanced capabilities to our customers Minimize downtime or reliability issues with our data platforms Minimize the work for engineers to safely and efficiently create, read, update or delete data in our supported data providers (Athena, Snowflake) Secure access to our data platforms and data platform providers, for both engineers, and customers, through RBAC and other security controls. Validate data correctness and completeness across our data platforms and data platform providers. Strategy and implementation of data models to ensure efficiency and scale across platforms The Requirements Experience writing backend code for customer-facing product features Experience with Golang or Python Experience partnering with engineers, and product managers Experience with Snowflake, preferably building applications Experience with AWS data services such as Aurora, DynamoDB Experience building client-facing data products The Perks Equity Unlimited PTO policy, with a minimum requirement of 15 days off per year, as well as Observing major US holidays, as well as a 2 -week break, end of year Latest tech equipment & budget for your customized tech needs Comprehensive medical, dental, and vision coverage 401k program Remote-friendly Opportunities to attend industry conferences (remote or in-person, and in conjunction with our in-person health and safety policy) Annual company off-sites in awesome locations (in conjunction with our in-person health and safety policy) Panther labs is an Equal Opportunity Employer. The Company prohibits discrimination and harassment on the basis of: race, color, national origin, ancestry, sex (including pregnancy, childbirth, breastfeeding), gender, gender identity, gender expression, sexual orientation, marital status, age, religious creed, physical disability, mental disability, genetic information, military or veteran status, or any other status protected by law. All employment decisions are decided on the basis of qualifications, merit, and business need."
Senior Data Engineer,"P3 Health Group Management,LLC","Remote in Henderson, NV 89074",https://www.indeed.com/rc/clk?jk=304c933ad718834b&fccid=030dfffce07f68ab&vjs=3,"P3 Health Partners is committed to ensuring the health and safety of our team members, patients and communities we serve. As a part of this commitment, all candidates must receive their COVID-19 vaccine prior to joining the team. If you have any questions about our interview and hiring procedures, please contact PeopleServices@p3hp.org. People. Passion. Purpose. At P3 Health Partners, our promise is to guide our communities to better health, unburden clinicians, align incentives and engage patients. We are a physician-led organization relentless in our mission to overcome all obstacles by positively disrupting the business of health care, transforming it from sickness care into wellness guidance. We are looking for a Sr. Data Engineer. If you are passionate about your work; eager to have fun; and motivated to be part of a fast-growing organization in Las Vegas, Nevada or remote, then you should consider joining our team. Senior Data Engineer Overall Purpose: Responsible for data integration to support all inbound/outbound Data Warehouse ETL processes. This includes but not limited to, development, testing and integration of ETL Processes (using Talend, SSIS or/other standard ETL tools) This position works closely with business systems analysts, project managers and various business stakeholders to support and provide quality delivery of data through extraction and transformation using defined business rules Education and Experience: Bachelor’s degree in computer science or related field 5-7 Years of proficient experience in designing and developing of mappings, transformations, sessions, workflows and deploying integration solutions using standard ETL tools (Talend Data Integration tools preferred) Previous experience in healthcare preferred Knowledge, Skills and Abilities: Strong experience in performance tuning of ETL processes Proficient in data integration between different data sources. Extensively worked on data extraction, Transformation and loading data from various sources like SQL Server and Flat files, in Talend Knowledge and experience of working on SQL Queries and database scripting (procedures, functions, jobs, physical data model creation) Experience in Development, Support, Maintenance, and Enhancement projects Development experience in Talend, MS SQL (SQL 2005/2008/2012), T-SQL, basic database design skills and application performance tuning Experience with Data Warehouse lifecycle including data analysis, data modeling and design Strong problem solving and troubleshooting skills Effective verbal and written communication skills Demonstrated ability to deliver working solutions on a tight/evolving schedule Essential Functions: Work with business users to define and understand business requirements related to changes and enhancements of existing enterprise data warehouse Perform unit testing of development jobs before production deployment Fulfill ad-hoc report requests for the supported business stream(s) as required Communicate all issues, risks, concerns and status to management, business partners and other departments in a timely manner Work with stakeholders at all levels in the organization and across departments to ensure compliance and governance methods, processes, and tools are followed/used"
Sr Data Science Engineer,Honeywell,"Tempe, AZ 85284",https://www.indeed.com/rc/clk?jk=ca60c283ebaa8e2b&fccid=50208b5bf45ee3b8&vjs=3,"Join a team recognized for leadership, innovation and diversity The future is what you make it. When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who make the things that make the future. That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings intelligent and safe and even making it possible to breathe on Mars. Working at Honeywell isn’t just about developing cool things. That’s why all of our employees enjoy access to dynamic career opportunities across different fields and industries. Why Honeywell? Oversee and direct operations (SBG) and be part of overseeing and directing operations for world-class integrated supply chain projects. You will assess project issues and develop enhanced resolutions to meet or exceed productivity, quality, and customers satisfaction goals and objectives. You will develop mechanisms for monitoring project progress and for intervention and problem solving with key stakeholders. Key Responsibilities Develop operational & functional metric data and coordinates with other functions to ensure consistency and data integrity Enables Management operating systems(MOS) Consolidate and summarize information at the Aerospace or function level, including key metrics, monthly highlights, and quarterly ops review material Provides data visualizations including creating, updating, and supporting databases and reports with key metrics to guide strategic decisions. Work directly with global Aerospace functions and sites to design new Aerospace standard analytic processes that enable operational improvement. Prepares presentation materials for both internal and external communications. Support the MOS Manage data and report Support to manage escalation YOU MUST HAVE Bachelor's Degree in IT, Computer Science, Data Engineering 5 Years of experience in data analytics, reporting and dashboard development Must be a US citizen due to contractual agreements WE VALUE Experience in data extraction, transformation, and load (ETL), using SQL Server integration services (SSIS) and Alteryx in large scale environment SAP/Functional experience in Planning and Procurement. Requires a high degree of initiative and accuracy Ability to manage multiple priorities Excellent problem-solving capability with creativity in providing solutions to new issues or in exploring alternatives Excellent verbal and written communications skills Six Sigma Green Belt or Lean/Black Belt certification preferred Lean expert or Black belt Global company working experience Professional in Microsoft Office Lead/drive change, and influence/mentor others 3 years of experience in SQL Programming and SQL server database. Minimum 2 years of experience in Tableau dashboard development. Excellent Microsoft Excel/PowerPoint skills, with particular emphasis on data retrieval, analysis and reporting Additional Information JOB ID: HRD169289 Category: Integrated Supply Chain Location: 1300 W Warner Rd.,Tempe,Arizona,85284,United States Exempt Must be a US Citizen due to contractual requirements. Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, religion, or veteran status."
TEST ENG DATA ENGINEER,Micron,"Atlanta, GA 30345+2 locations",https://www.indeed.com/rc/clk?jk=a869a2dbaa104194&fccid=be240c643a8631c5&vjs=3,"Our vision is to transform how the world uses information to enrich life for all. Join an inclusive team passionate about one thing: using their expertise in the relentless pursuit of innovation for customers and partners. The solutions we build help make everything from virtual reality experiences to breakthroughs in neural networks possible. We do it all while committing to integrity, sustainability, and giving back to our communities. Because doing so can fuel the very innovation we are pursuing. JR25846 TEST ENG DATA ENGINEER Responsibilities and Tasks: Establish and improve process condition and technology. Upgrade process capability and reduce production cost. Establish and modify process management projects. Set up process parameters for a variety of semiconductor equipment. Evaluation, promotion and planning of new equipment / materials. Abnormal analysis and improvement. About Micron Technology, Inc. We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life for all . With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron® and Crucial® brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience. To learn more, please visit micron.com/careers All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. To request assistance with the application process and/or for reasonable accommodations, please contact at hrsupport_tw@micron.com . Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards. Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron."
Senior Data Center Infrastructure Engineer,Zscaler,"San Jose, CA 95134 (North San Jose area)",https://www.indeed.com/rc/clk?jk=fc458372a4ea72fa&fccid=b8ce556031512ca3&vjs=3,"Company Description *** US Citizenship is Required *** At Zscaler, we are on a mission to redefine network security for the Cloud and Mobile-First World. The cloud and mobility are creating a mega-shift that’s disrupting 30 years of networking and security infrastructure. Traditional network security architecture is no longer suitable for the cloud and mobile-first world. Zscaler is a pioneer and leader in cloud security and we are enabling the world’s leading organizations to securely transform their networks and applications for the cloud and mobile-first world. With a solution born and built 100% in the cloud, Zscaler employees have built and operate a massive, global cloud security architecture, delivering the entire gateway security stack as a service. By providing fast, secure connections between users and applications, regardless of device, location, or network. Job Description Server and network hardware troubleshooting, followed by physical repair or replacement Perform initial configuration of servers and network devices and validate prior to deployment Create and follow documentation and processes that are used in preparation, installation and cabling of systems, including for use with remote services Assists remote Data Center and contractor staff during the course of installation Validate successful installations Interface with vendors and contractors directly and via ticketing systems Pack/unpack servers, network hardware, and other related equipment Attend team and vendor meetings to plan and schedule maintenance and repair work Support hardware firmware updates Innovate solutions to help streamline current processes Work with relevant groups to ensure all equipment is received and documented in a timely manner Manage and execute on small projects independently While on-call duty is not required occasional after hours work may be needed. Qualifications 5 years experience with computer networking and Data Center environments Expert knowledge and experience configuring servers and network devices Strong Linux administration skills as well as expert network device administration skills Strong organizational skills, work prioritization, effective communication, and the ability to react quickly Experience working with inventory systems and ticketing system (JIRA, Service Now, Remedy, etc.) Experience with remote Data Center operations Strong knowledge of LINUX/UNIX systems required Ability to lift, carry, and move up to 50 pounds when needed Maintain a positive work environment, encourage healthy organizational morale, and promote adherence to all policies and procedures You thrive in a fast-paced environment with tight timelines and changing priorities Education: Bachelor Degree or equivalent experience Additional Information What You Can Expect From Us: An environment where you will be working on cutting edge technologies and architectures A fun, passionate and collaborative workplace The pace and excitement of working for a Silicon Valley Cloud Security Leader Why Zscaler? Zscaler serves more than 3,250 customers across all major industries and currently counts over 300 of the Forbes Global 2000 as customers. The Zscaler™ cloud platform processes more than 60 billion transactions and detects 100 million threats per day from users across 185 countries. Glassdoor rating of 4.7/5.0 = Exceptional place to work! People who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement? If you said yes, we’d love to talk to you about joining our award-winning team. All your information will be kept confidential according to EEO guidelines. #LI-LG1 What You Can Expect From Us: An environment where you will be working on cutting edge technologies and architectures A fun, passionate and collaborative workplace Competitive salary and benefits, including equity Why Zscaler? People who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement? If you said yes, we’d love to talk to you about joining our award-winning team. Additional information about Zscaler (NASDAQ: ZS ) is available at https://www.zscaler.com. Zscaler is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees."
Software Engineer II - Data Provisioning,Bank of America,"Addison, TX 75001+7 locations",https://www.indeed.com/rc/clk?jk=68ef166ef884b039&fccid=5bd99dfa21c8a490&vjs=3,"Job Description: Position Summary: This position will deliver data provisioning solution for the payments domain, and will require advanced analysis, design, development, testing, tuning, and troubleshooting these solutions. Required Skills: 10 Years Relevant IT software experience (Technical-Developer) using DataStage, Database (DB2/ORACLE/Teradata), Unix Shell Script, Autosys 8 years of development experience in Datastage (Version V8.5 or higher) with experience in processing high volume jobs. Quick learner and self-starter who requires minimal supervision to excel in a dynamic environment Deep understanding of the software development process Strong Written and verbal communication skills Self-motivated and quick-learner team player who can take the full ownership of designs from concept to support Understand stakeholders expectations and objectives Work independently; Require less oversight/assistance Ensure processes are followed at all stages of Software Development Life Cycle Participate/host calls independently with onshore business and technology team Should be able to understand the problem and recommend solutions during JAD/discussions/meetings Strong Parallel job and Sequence job developing skills with proficient understanding of parallel framework. 10 years of experience in shell scripting, SQL and integration of Datastage to various other platforms Good understanding of version controlling and code deployment of Datastage assets in a Horizon BitBucket environment. Desired Skills: Working knowledge in application design & development Prior experience in Payments domain (ISO 20022, TCH-RTP) Able to contribute to Automation, Causal analysis, and develop shared/common solutions Able to identify risks and come up with mitigation plan. Comfortable working in a matrix environment Prior experience of working with globally distributed teams Job Band: H5 Shift: 1st shift (United States of America) Hours Per Week: 40 Weekly Schedule: Referral Bonus Amount: 0"
SF Data Engineer/Lead,Baldwin Risk Partners,+2 locationsRemote,https://www.indeed.com/rc/clk?jk=84de57f6c986195d&fccid=5cf6362cb82df67a&vjs=3,"What we are looking for This role offers an exciting opportunity to work on multiple projects that elevate our client experience with us. You will be playing a pivotal role in aligning the Salesforce platform’s data integrity and integrations with other applications. This role will be part of the Salesforce Platform Center of Excellence and will be working in an Agile team structure. Your responsibilities include, aligning data from various sources into the Salesforce data model, data mapping, ensuring data integrity, data de-duplication and reporting. Quality standards are paramount to us and we need you to assure that all teams’ individual work as well as dependent teams’ work is well thought out and designed appropriately. Our data leads are very hands on and we expect you to develop capabilities within the Salesforce platform such as API integrations, data rules, building reports and dashboards, preparing data sets, production to sandbox data refreshes and configure Einstein capabilities. Designing and developing proof of concepts, quickly showing results to elicit more detailed requirements is expected. Staying abreast of the Salesforce platform releases and new features is paramount to succeed in this role. An ideal candidate for this role is laser focused on delivering to our company’s objectives, able to wear multiple hats, has collaborative attitude to drive shared success with various stakeholders. Your demonstrated acumen in the Salesforce technologies, data management experience, certifications in both Salesforce and data toolkit will differentiate you as a candidate of choice for us. These credentials are strongly preferred. Position Responsibilities Strategy, Design and Planning Lead the overall data management between Salesforce platform and various connected applications. Create a plan and lead efforts towards keeping the Salesforce platform’s data clean. Continuous efforts in data migration, data de-duplication, research and development towards removing data debt is anticipated. Solution design for data integrations using APIs and other integration patterns Participate in product planning sessions and architecture sessions to contribute to the overall data flow design. Development, Testing and Deployment Build APIs, enrich data through various integrations Research, design, build and deploy various data solutions for data to and from the Salesforce platform Design and build reporting and dashboards using native Salesforce platform as well as Einstein/Tableau/BI tools where applicable. Prepare test data, ensure test data privacy in lower environments and data prep for various capabilities Assist in creating the deployment playbook for all releases, prepare data loads where necessary and ensure smooth deployment. Operational Management Continuous monitoring of the Salesforce platform data integrity. Own any data research from production issues and provide solutions. Perform all data related activities during sprint execution, testing, deployment and post go-live activities. Position Requirements Formal Education & Certification College diploma or university degree. Certifications in Salesforce technologies Certifications in any data management toolkit Knowledge & Experience Bachelor's degree with 5-8 years of experience in the Salesforce technologies 5-8 years of experience in working with data related projects and data integrations Proven experience with data management, data refreshes and data integrity within the Salesforce platform ecosystem Excellent software troubleshooting experience. Excellent understanding of the organization’s goals and objectives. Personal Attributes Hungry to learn, demonstrated continuous learning of relevant skills Excellent written, oral, and interpersonal communication skills. Ability to conduct research into data issues and tools as required. Ability to communicate ideas in both technical and business languages. Highly self-motivated and directed, with keen attention to detail. Proven analytical and creative problem-solving abilities. Able to prioritize and execute tasks in a high-pressure environment. Ability to work in a team-oriented, collaborative environment Click here for some insight into our culture!"
Data Engineer - Healthcare (s),Keyseries,"Albany, NY",https://www.indeed.com/rc/clk?jk=de2df2a4279662f8&fccid=25ddcfc98114b689&vjs=3,"JoB Title : Data Engineer - Healthcare (s) Location : Albany, NewYork Job Type : Full Time Reference Code : Key 304 Description Requirements Must Have Skills: ETL/ Quality/ MDM/ Harmonization/ Masking/ De-Lineanation/ Profiling, etc. 3-5 years’ experience in OLTP/OLAP data Modeling / DB architecture, including a working knowledge of various business process and system modeling tools including: data flow diagrams, process models, ER diagrams, dimensional data models, context models, event modeling, state modeling, process decomposition, and use case scenarios Strong understanding of data, data modeling and set-based processing 3-5 years’ experience in development of ETL and large data migrations 3-5 years’ experience in MySQL or SQL, including DDL, DML, stored procedures, triggers, events Excellent skills in troubleshooting data integrity issues, database issues, and SQL performance tuning Proficiency with one or more scripting languages: Shell, PHP, Perl, Ruby Experience with Agile methodology Strong Pluses: Working knowledge of Pentaho, Tableau, or other similar reporting tools Experience Migrating Data between platforms or major upgrades MapR, EMR, or equivalent experience Experience with Amazon Web Services Data trending and analytics using R Machine Learning Predictive Analytics"
Data Engineer,ZineOne,"Milpitas, CA",https://www.indeed.com/rc/clk?jk=0454627118d1dc42&fccid=f6c6952dc69eac33&vjs=3,"Data Engineer What You Will Do Design and implement data pipelines to process clickstream data for building online ML models. Implement, test and deploy scalable big data techniques to transform clickstream data into large-scale encoded and vectorized sequences Own data quality analysis to drive checks and improvements in data pipeline processing Collaborate with data scientists to train and evaluate new and existing models using RL, DL and GBMs. Improve automation and operations for model training, scoring and performance measurement using MLOps platform Represent data engineering within the Data Science team to ensure ML models maintain high quality implementations that are repeatable, performant, efficient and measurable Innovate to address new customer use cases in target or new industries, and contribute to expand our ML model portfolio Qualifications Bachelor's Degree or higher in Computer Science, Data Science or similar area 3+ years of hands-on data engineering experience implementing data pipelines and machine learning ideally in Retail, QSR or Finance Experience working with customers and in the software engineering process for delivering large scale and quality applications. Strong knowledge of big data techniques including the Hadoop/Hive ecosystem, distributed data processing, message queues, high-performance databases (columnar, sharding, etc.), and massive parallel processing and micro-batch processing engines such as Apache Spark. Experienced in statistics & analytical modeling, time-series data analysis, forecasting modeling, machine learning algorithms, and deep learning approaches and frameworks. Have a proven track record of delivering robust, scale and quality data analytical applications in a cloud environment. Comfortable working with a high performance, geographically distributed team with members in the US as well as overseas locations (India, Canada). Possess excellent communication skills and cross-team collaboration skills to effectively share customer needs across sales, customer success, and engineering."
"Lead Software Engineer, Data Governance Platform",Tableau,+1 locationRemote,https://www.indeed.com/rc/clk?jk=8c48b8c651abc5ed&fccid=f334737e3fd6818e&vjs=3,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts. Job Category Products and Technology Job Details The Data Governance Platform team is focused on delivering a self-service security and sharing platform to Tableau users. Via this platform, users will be able to set up security policies, sharing rules, manage metadata and audit data assets produced for consumption. This lead engineer role requires excellent technical skills and outstanding analytical and influencing skills paired with business insight. Join our team and build the next generation self-service data sharing and security experiences. We are executing on a new roadmap to allow customers to author security and sharing rules, manage and govern data assets, all via the delightful experiences Tableau is known for. Responsibilities/duties: Build scalable systems that support connecting Tableau’s customers with their data Contribute to architecture, design, and implementation of our next-generation product Collaborate with product owners, peer teams and partner teams to tackle tough design, product and engineering problems. Take ownership of your solutions and features from development to production and production support beyond just code deployment Promote code quality by writing readable, maintainable, modular and efficient code. Work with Customers and Support to resolve bugs and support issues. Skills and experience: 7+ years of software development experience building applications in Java, C# or similar object-oriented languages and/or modern web stacks. Experience in Typescript, React is a plus. Full stack experience is preferred but not required. Ability to independently design and deliver large complex projects Mentor others in development technologies, tools, and processes Experience with Agile development methodologies Enjoy collaborating, learning from, and teaching others so we can all become better developers. Ability to create an environment for honest and open discussion of all issues. You involve the right people, from your team and others, to resolve critical issues. Bachelors or Masters degree in Computer Science or equivalent experience in related field For Colorado-based roles: Minimum annual salary of $150,200. You may also be offered a bonus, restricted stock units, and benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com/ Accommodations If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form . Posting Statement At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at Salesforce and explore our benefits. Salesforce.com and Salesforce.org are Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce.com and Salesforce.org do not accept unsolicited headhunter and agency resumes. Salesforce.com and Salesforce.org will not pay any third-party agency or company that does not have a signed agreement with Salesforce.com or Salesforce.org . Salesforce welcomes all."
Senior Data Engineer,Skupos,"Remote in Denver, CO 80202",https://www.indeed.com/rc/clk?jk=0790de1e1f0735e1&fccid=52fe920cf8502d06&vjs=3,"Company. What we are building: Skupos drives revenue growth across all segments of the convenience retail industry through technology that connects both retailers and brands to their shoppers. With a focus on independent stores and small chains which make up nearly 80% of the market, the Skupos platform enables both retailers and brands to compete through better understanding and serving their customers. Founded in 2016, a growing network of 14,000+ customers across all 50 states rely on Skupos to boost sales volume and increase their customer base. Role. An overview of the opportunity: At Skupos, data is everything. Our data integrates the forgotten, fragmented world of mom-and-pop corner with the glitzy, gigantic world of CPG conglomerates. With tens of millions daily transactions, Skupos is looking for a data engineer to wrangle and tame our data flows, expand and optimize our data and data pipeline architecture. Team. The team and our people: This role will be part of the Data Platform team, the core functional team building our data products. The team works closely with the Data Infrastructure, Product and BI teams. Responsibilities. Your responsibilities will include: Building and maintaining the data and reporting layers for customer facing products. Collaborate closely with Data Infrastructure and Analytics teams to build complex data pipelines to deliver CICD complete deployment, move data cross - platforms including real time systems. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Work with the Data Infrastructure team to build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies. Create data tools, analytical datasets for Data Analytics and Machine Learning teams that assist them in building and optimizing our product Maintain and deliver continuous improvement of core projects through automation and process enhancement Work with all data teams and consumers to strive for greater functionality in our data systems Partner with engineers, product managers, and data scientists to breakdown data requirements, analyze source data sets, address data quality issues and effectively build and automate ETL pipelines at scale. Partner with ML engineers, data infrastructure team to define and own Data engineering tools, products and processes in place and define/set SLAs for each. Have deep understanding of existing data integration challenges and solutions with optimal ETL solutions and querying techniques Experience and Skills. Candidates should have: Bachelor's degree or equivalent, ideally in a technical or quantitative field (advanced degree is a plus). 4-6+ years of experience working with SQL Advanced with proficiency with Python, Java, or Scala in a production environment 1-3 years of experience building and optimizing large-scale data pipelines, architectures and data sets. Recent experience (2+ years) with a modern data warehouse (e.g., Snowflake, BigQuery, Redshift, Pentaho) Experience with data warehousing architecture and understanding of data modeling concepts and best practices (e.g., normalization/denormalization). Production experience with Spark Familiarity with stream-processing platforms and message-queues (e.g. Flink, Hadoop, Kafka) is a plus Salary is based on experience and location. Salary range based on Denver Market: $140,000 - $155,000. Benefits. What we offer: Competitive salary Medical, dental, and vision insurance 401(k) retirement savings plan Discretionary time off (DTO) Wellness stipend And more! A Note on Covid... We are fortunate to continue to grow during this unfortunate time. Our top priority is to ensure the health and safety of both our current and future Skupeeps. As of July, our physical office spaces have reopened on a voluntary basis. Our Skuad members are allowed onsite if they are fully vaccinated (2 weeks past final vaccine dose). That being said, we will continue to manage our interview process virtually, don't be surprised if children or pets make an appearance. We deeply care about you as our candidate, so let the People Team know if there's anything we can do to make your interview process go more smoothly - we are in your corner!"
Senior Data Engineer,Dassault Systèmes,"New York, NY",https://www.indeed.com/rc/clk?jk=37c1c55c502ac414&fccid=29d37d43c382c8fe&vjs=3,"Medidata: Powering Smarter Treatments and Healthier People Medidata is leading the digital transformation of life sciences, creating hope for millions of patients. Medidata helps generate the evidence and insights to help pharmaceutical, biotech, medical device and diagnostics companies, and academic researchers accelerate value, minimize risk, and optimize outcomes. More than one million registered users across 1,900+ customers and partners access the world’s most trusted platform for clinical development, commercial, and real-world data. Medidata, a Dassault Systèmes company, is headquartered in New York City and has offices around the world to meet the needs of its customers. Discover more at www.medidata.com and follow us @medidata. Your Mission: Member of the data engineering team responsible for data aggregation, transformation, modeling and delivery for both client usage and internal data science teams Full-stack design, development, and operation of core data capabilities like data lake, data warehouse, data marts and data pipelines Contribute to the team's roadmap and project planning process, partnering with stakeholders to develop business objectives and translate those into action Work with data architects to develop data flows and align to platform integration standards Build data flows for data acquisition, aggregation, and modeling, using both batch and streaming paradigms Consolidate/join datasets to create easily consumable, consistent, holistic information Empower other data teams, data scientists and data analysts to be as self-sufficient as possible by building core capabilities as services and developing reusable library code Ensure efficiency, quality, resiliency of the core data platform Your Competencies: Analytically minded and detail-oriented: you actually like working with data, looking for patterns and outliers, establishing data models, and finding the best answers to business & technology problems Expertise in data engineering languages such as Java, Scala, Python, SQL Data modeling experience; you've designed and implemented data marts, data warehouses or other large-scale data management systems; you have experience with Dimensional and Data Vault data modeling Experience working with cloud data warehouses such as Snowflake Computing, AWS Redshift or Azure SQL Data Warehouse Experience building ETL and data pipelines, both with traditional ETL solutions like Pentaho, Informatica, SSIS, Talend but also via code-oriented systems like Spark, Airflow or similar Cloud-oriented with strong understanding of SaaS models Experience operating in a secure networking environment, leveraging separate production support and SRE teams is a plus Excellent technical documentation and writing skills You have a bias towards automation, an Agile/Lean mindset and embrace the Devops culture Familiarity with streaming/messaging technologies like Kafka, Kinesis, Spark Streaming Familiarity with visualizing data with Tableau, Business Objects, Quicksight, PowerBI, Spotfire and similar tools Great customer focus and strong technical troubleshooting skills Proficiency in statistics and data science is a nice-to-have, and interest in learning these is even better Experience with clinical trial data is not required, but interest to learn and understand it is a must Hadoop/Spark and Graph/RDF/Ontologies experience a plus Your Education & Experience: Undergraduate or graduate degree in a technical or scientific field, such as Computer Science, Engineering, Mathematics, or similar 5+ years professional experience as a data engineer, software engineer, data analyst, data scientist, or related role Medidata is making a real difference in the lives of patients everywhere by accelerating critical drug and medical device development, enabling life-saving drugs and medical devices to get to market faster. Our products sit at the convergence of the Technology and Life Sciences industries, one of most exciting areas for global innovation. Nine of the top 10 best-selling drugs in 2017 were developed on the Medidata platform. Medidata Solutions have powered over 17,000+ clinical trials giving us the largest collection of clinical trial data in the world. With this asset, we pioneer innovative, advanced applications and intelligent data analytics, bringing an unmatched level of quality and efficiency to clinical trials enabling treatments to reach waiting patients sooner. COVID Statement Medidata requires all U.S. employees to be fully vaccinated against COVID-19 and to provide documentation of full vaccination, unless qualified for an accommodation as determined by Medidata, consistent with applicable law. Although accommodation requests will be considered (and granted where appropriate/possible), it may be determined that a candidate is unable to adequately perform the essential functions of the position without imposing an undue hardship on Medidata due to customer requirements, staffing needs, or other business reasons. Medidata Solutions, Inc. is an Equal Opportunity Employer. Medidata Solutions provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity, national origin, age, disability status, protected veteran status, or any other characteristic protected by the law. Medidata Solutions complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. Not available Equal opportunity In order to provide equal employment and advancement opportunities to all individuals, employment decisions at 3DS are based on merit, qualifications and abilities. 3DS is committed to a policy of non-discrimination and equal opportunity for all employees and qualified applicants without regard to race, color, religion, gender, sex (including pregnancy, childbirth or medical or common conditions related to pregnancy or childbirth), sexual orientation, gender identity, gender expression, marital status, familial status, national origin, ancestry, age (40 and above), disability, veteran status, military service, application for military service, genetic information, receipt of free medical care, or any other characteristic protected under applicable law. 3DS will make reasonable accommodations for qualified individuals with known disabilities, in accordance with applicable law."
Data Engineer,Burton,"Remote in Burlington, VT 05401",https://www.indeed.com/rc/clk?jk=968767ec5a96ec8c&fccid=48edf0ac3d689fc7&vjs=3,"Requisition Number: 762 Position Title: Data Engineer External Description: Burton’s benefits package includes health insurance (medical, dental and vision), life insurance (company paid), flex spending, short- and long-term disability insurance (company paid), great parental benefits, 401k plan with company match, and paid-time-off. Other perks include a discounted season pass, free lessons, product discounts, free demo equipment, ride days, casual work environment, and many more... The Breakdown: As a Data Engineer, you will play a key role in growing and transforming our operational and analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, and business intelligence/insights. This position may be based 100% remotely or in one of our global offices. What You Get to Do: Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment. Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate. Test data movement, transformation code, and data components. Experience with Informatica MDM Experience with configure Match and Merge and refining match rules based on business requirement and data specification. Experience with Web services and understanding of micro services architecture, experience integrate with MDM real time service. Basic understanding of Agile preferred. Basic understanding of DevOps preferred. Problem Solving - Strong problem solver who ensures solutions are built for the long term, canresolve new issues, recognizes mistakes using them as learning and teaching opportunities and consistently breaks down large problems into smaller, more manageable ones. Communication - Strong communicator who possesses the ability to articulate information clearly and concisely with the business, document work in a clear, easy to follow manner, collaborate well with team members as both a mentor and mentee What You'll Bring to The Team: Bachelor’s degree in STEM related field or equivalent training with data tools, techniques, and manipulation. 4 years of data engineering or equivalent experience / 5+ years of related experience Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices. Travel: The position does not require any travel. Work/Physical Environment: This position is in a typical, stationary office setting. Over 80% of the day will be spent sitting in 1 location. What’s next? Please submit an application with resume and cover letter on why you want to work for Burton. Applicants identified for first round selections will be provided with “Your Burton Timeline” encompassing what your work in this role will entail within 1 month, 3 months, 6 months, and 12 months on the job. Other steps may include questions via email to gain further insight into your experience, an informal phone call to connect on details of the role/ask questions, and one or more formal interviews via Zoom. City: State: Community / Marketing Title: Data Engineer Company Profile: EEO Employer Verbiage: At Burton, we are a purpose-led brand rooted in snowboarding and the outdoors. We fight for the future of our people, planet, and sport. We aim to maximize our positive social impact and minimize our negative environmental impact while delivering high-quality performance products. As a global leader in snowboarding, we’re committed to diversity, equity, and inclusion for the long-term health of our company, sport, and community. Through these efforts, we aim to make snowboarding and the outdoors accessible to all. Burlington, Vermont US The Burton community believes in respect for all people and the planet. We embrace and strive for a community that values differences and stands for equality and the fight to get there. Regardless of how you identify, how the world sees you, or how you play outside, please feel welcome to apply and join our community."
Data Engineer,EKIN Solutions,"Herndon, VA 20171",https://www.indeed.com/rc/clk?jk=23dee12fe27745db&fccid=6fd27b81ba0b10f4&vjs=3,"Master’s or equivalent in Computer Science, Information Systems Technology, or Computer Engineering + 1 year of experience or Bachelor’s + 5 years of post -Baccalaureate progressive experience in Database Application Development (Ref#2)"
Data Engineer,Jackson National Life Insurance Company,"Lansing, MI 48951+1 location",https://www.indeed.com/rc/clk?jk=26d18e35d5f1c2a2&fccid=bf59e5a86473f34c&vjs=3,"Job Purpose The Data Engineer will build and operate our enterprise data platform, prepare and deliver curated datasets for operational and analytical use cases. DE will design and provide analytical datasets to citizen data analysts, prepare training data and extract features to accelerate data science model development. In a complex enterprise data environment with numerous systems of record and systems of engagement, the Data Engineer will ensure that the Data Engineering services are delivered in a scalable, reliable, secure, and maintainable manner to support the service levels. The Data Engineer works closely with the Data Architects, System Architects, and Application Architects to align with the Architectural direction of the enterprise and will be required to understand the Architectural landscape and possess the ability to gather and analyze business requirements. In addition, the Data Engineer promotes data sharing across the enterprise while maintaining the accuracy, consistency, integrity, and security of the data sets in the Enterprise Data Repository. Essential Job Duties & Responsibilities Liberates data from data sources into the enterprise data lake and operational data stores. Maps data from the source systems into curated entities and their functional views. Implements master data management strategies. Designs, implements and deploys data pipeline solutions with data lineage capabilities using Azure Data Factory and Databricks. Manages and publishes curated data sets. Works with the business to manage data quality. Monitors availability, performance, capacity, continuity, security, and service levels of the enterprise data platform and its services. Provides subject matter expertise to other technical teams leveraging services from the enterprise data platform. Delivers and provides production support for Data Engineering services that meet performance standards and service level agreements. Participates in continually improving processes and procedures for enhancing the efficiency and effectiveness of Data Engineering services to analytic users. Participates in leveraging emerging innovations related to Data Engineering and work closely with Enterprise Architecture and other teams to operationalize them. Supports the Data Engineering department in conducting user groups and other forums as needed to evangelize and promote the adoption of Data Engineering best practices for accessing and using data sets efficiently, effectively, and securely. Supports enterprise initiatives in building a culture of data-driven decisions to contribute to operational excellence. Participates in the development of Data Engineering practices focusing on long-term sustainability, reuse, and technical debt reduction in the domain of data management. Works with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs. Publishes dashboards that summarize the utilization of data sets in delivering business value impact. Supports enterprise architecture function in establishing Policies, Standards, Architecture Patterns, Guidelines, and Best Practices related to Data Engineering discipline. Designs, implements and identifies internal process improvements: automating manual processes, optimizing data delivery, redesigning infrastructure for greater scalability. Other duties Supports the Enterprise Data Repository operations as needed in non-production environments. Develops tools to automate Enterprise Data Repository operations as needed and liaises with the Service Operations teams that manage production environments. Other duties as assigned. Knowledge, Skills & Abilities Expertise in programming, debugging, and testing utilizing various programming languages, tools and technologies related to Data Engineering. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience working with various operating systems, RDB platforms, NoSQL platforms, Big Data platforms, and environments for managing Data over its full lifecycle. Strong knowledge of how to compose and implement structural data models. Strong knowledge of using data as an enterprise asset – building and managing data marts and data warehouses. Proven Experience in managing structured data (application data bases, operational data stores, data marts and data warehouses). Experience in managing structured data, unstructured data, and big data at scale on cloud platforms, preferably on Microsoft Azure. Experience in managing large-scale storage solutions, preferably using Microsoft Azure. Experience molding fresh environments into cost-efficient, high performance, secure, and mature data platforms. Understanding of data security concepts including encryption at rest and in transit. Familiarity with data visualization techniques and tools. Flexible with a strong sense of urgency. Ability to effectively communicate technical issues both verbally and in writing. Ability to work in an Agile Scrum and Kanban environment. Excellent analytical and problem-solving skills. Experience in successfully managing large-scale data ecosystems preferred. Willingness to use of new software aids and programming techniques that are adopted within IT as needed for the role. Education and Experience Required Bachelor’s degree in Computer Science or equivalent education. 5-7 years of experience in information technology systems or data services delivery. 3+ years of overall experience in designing and delivering Data Engineering services using programming/scripting languages such as Python, Scala, R, SQL, C#, Java, or U-SQL. 1+ year(s) experience in delivering Data Engineering services using a NoSQL platform such as Cosmos DB, Mongo DB, Hadoop, CouchBase, or HDInsights. Experience in using ETL/ELT, Data Quality Management, Meta Data Management, and Master Data Management platforms is highly preferred. Azure Data Engineer certification strongly preferred. Experience with Microsoft Azure Data Management Platform is strongly preferred. Familiarity with the financial services and/or life insurance industry is preferred. The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not to be construed as an exhaustive list of all job duties performed by the personnel so classified. We don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Jackson is proud to be an equal opportunity workplace. The Company subscribes to and endorses federal and state laws and regulations relating to equal employment opportunity for all persons without regard to race, color, religion, gender, age, national origin, legally-recognized disability, marital status, legally-protected medical condition, citizenship, ancestry, height, weight, sexual orientation, veteran status, or any other factor not related to the needs of the job. The Company is committed to a policy of equal opportunity. Company facilities and campuses are tobacco-free environments."
Data Engineer,BXGI,"Remote in Palo Alto, CA",https://www.indeed.com/rc/clk?jk=2af08b861cf28136&fccid=359847eb6abf10b7&vjs=3,"Overview We are conducting a search for a Data Engineer to join our client’s engineering team in Palo Alto, CA or remotely anywhere in the United States. Interested in shaping the future of pediatrics behavioral health? Our client is looking for a skilled Data Engineer to join their Engineering team who has in-depth experience with a variety of databases and maintaining data repositories from multiple data sources using different schemas. Come join a world-class company delivering AI-powered diagnostics and therapeutics to dramatically improve the outlook of young children with cognitive and behavioral conditions. Ability to work remotely is possible, with quarterly visits to Palo Alto. Responsibilities Create and maintain a data repository for analytics by combining multiple data sources using different schemas. Work with various groups in Engineering to source the necessary data. Implement industry best practices including quality assurance and compliance standards related to Protected Health Information (HIPAA). Develop and maintain ETL processes to populate the data warehouse. Deploy utility applications to Amazon AWS EC2, Fargate or Kubernetes. Qualifications BS in Computer Science, Engineering or related discipline. 4+ years experience with two of MySQL, Oracle SQL, Postgres. Deep understanding of relational database structure and performance. Past experience maintaining data repositories with disparate data sources. Past experience building visualizations of underlying data. Experience with Linux, Python, REST API. Excellent verbal and written communication skills. Excellent organizational skills and attention to detail. Nice to Have Experience with Amazon Web Services (RDS) Experience building/supporting HIPAA-compliant software. Understanding of underlying technologies of Tableau (Hyper databases, Hyper API, server extracts, prep flows, Python libraries. Deep understanding of dimensional data warehouses Experience with design star and snowflake schemas Ability to come into the office every so often (once we actually can). If interested, please send your resume to lana@bxgi.com."
"Senior Software Engineer, Data (Remote)",SnapTravel,"Remote in New York, NY",https://www.indeed.com/rc/clk?jk=80e30946e9a38db7&fccid=960d8f54f5a1520f&vjs=3,"About Us Snapcommerce is a high-growth company that sits at the intersection of mobile commerce and fintech. Our flagship product, Snaptravel allows millions of users around the world to book their travel over messaging. We are currently in the scale-up phase of the company with plans to grow from ~150 employees to ~300+ employees as fast as possible while maintaining the competitive advantages and culture of being a startup. With a high-performing team of world-class leaders, Snapcommerce thrives on tackling complex problems within AI, E-commerce, and Conversational Design to push the boundaries of the value we can add to our users’ lives! At Snapcommerce, we pride ourselves on the performance-driven environment we’ve created for our team to prosper and excel. Our values are rooted in making data driven-decisions and risk-taking actions that add value to both the user and the company. Check out this article from our CEO, Hussein on Snapcommerce's Core Values to learn more! About the Role We are looking for a Senior Software Engineer with 3+ years of experience to join our growing Engineering team! As a Senior Software Engineer, Data at Snapcommerce, you will be responsible for building highly reliable and scalable data platforms and pipelines You will have full control over ensuring the accuracy and integrity of all data, and will build pipelines, tools and predictive models to help drive insights and decisions in our Product and Growth teams! In this role you will have the opportunity to build scalable and highly available data pipelines using bleeding-edge tech and tools in one of Toronto’s fastest-growing Data teams, with a focus on thinking big and moving quickly. Diving into more detail, as a Senior Software Engineer, Data you will Help to evolve and scale our data platform, with an eye towards growth of our business and reliability of our data Help productionize machine learning models Work closely with the analytics and business intelligence teams, as well as other stakeholders from finance, sales, marketing, and product, to understand the data needs of the business and produce processes that enable a better product and support growth decision-making Generate architecture recommendations and the ability to implement them Improve, manage, and teach standards for code maintainability and performance in code submitted and reviewed Help evolve our CI/CD strategy for our ELT jobs and pipelines Our Tech We use an SOA architecture powered by many micro-services, including the bot platform, the NLP model and the real-time pricing and recommendation engine Data pipeline tools including Fivetran, dbt, Airflow, Apache Spark, Snowflake, Looker We have a distributed ELT infrastructure hosted using Docker and AWS About You You have at least 3 years+ of software/data engineering experience, at least 2 of which has been in a Data Engineering role You learn quickly, regardless of the languages and technologies used You always strive to build the minimally viable product before over-engineering You have experience building scalable data pipelines and powerful reporting tools You love solving complex problems with logical, well-architected solutions You are well-versed in data modeling and have experience building distributed systems Clear communicator who can gather technical requirements and explain technical intricacies Predictive modeling and machine learning experience is a strong plus Why work at Snapcommerce? Work with a group of ultra-smart hard-working talent coming from companies such as Google, Uber, & Facebook Join a results-driven organization where performance is measured by your output and not the number of hours you work Be part of a 100% transparent culture where every employee has access to board decks, strategy, and financials Work on projects that have instant impact, with most engineers pushing code to production within their first week Every day you will be helping our customers save money, earn rewards, and experience more of what life has to offer, making this a very rewarding and meaningful career Perks & Benefits We are a Remote-first company, we offer flexible working hours with complete work-from-home freedom and a guilt-free unlimited vacation policy Enjoy employee rewards, and travel discounts using SnapTravel Competitive salaries, equity options, full benefits from day one, wellness budgets, and paid development - we’ve got you covered! UberEats credits, meal budgets, special treats, and team lunches. When in the office, enjoy daily snack services and unlimited coffee, tea, and other drinks Supporting continued growth with Learning & Development, Diversity & Inclusion events, TED talk Tuesdays, and Lunch & Learn opportunities We welcome new additions with a generous EI top-up, parental leave, additional vacation, and a flexible return-to-work plan Game nights, Happy Hours, internal hackathons, team building games, workouts, and more We Believe in Equal Opportunity We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."
Senior Data Engineer,CAP COM Federal Credit Union,"Albany, NY 12205",https://www.indeed.com/company/CAP-COM-Federal-Credit-Union/jobs/Senior-Data-Engineer-5e3f4ebac39645b3?fccid=282f5c01d32bc67f&vjs=3,"Job Summary: ABOUT THE TEAMAs part of our Software Engineering team, our Data Engineers expand and optimize data and data pipeline architecture, as well as optimize data flow and collection for cross functional teams. The Senior Engineer will plan, build, influence and lead data initiatives across multiple teams, systems and projects with software developers, database architects, and data analysts. *WHAT YOU’LL DO* Strategy & Planning Identify and recommend analytics applications/features in conjunction with business leaders. Contribute to the broader BA/BI program vision and supporting roadmap. Acquisition & Deployment Implement approved hardware, software, platforms, publishing tools, and programming languages for the development of system updates. System Development & Support Recommend and implement enhancements and modifications to the platform. Implement software changes using suitable technologies and applicable data warehousing design patterns. Identify rigorous data quality methodologies and incorporate them throughout warehousing architecture. Remain current on industry requirements for technology systems. Collaborate with senior technical team members on technical designs to ensure that they are consistent and aligned with the broader enterprise vision. Ensure system updates meet security standards. Maintain and administer database infrastructure Create/update/delete or alter databases. Provide timely resolution to support tickets in accordance with team service level targets. Testing Develop comprehensive testing plan that includes: Acceptance criteria Code coverage minimums are met Automated testing services are in place Define, Develop, and maintain unit tests. Processes Collaborate with key stakeholders on data warehousing best practices and standards. Keep apprised of current technology and secure programming practices. Apply established SDLC practices via Azure DevOps. Coordinate closely with Business and Technical owners of source systems to proactively plan for updates. LET’S TALK IF YOU Possess a bachelor’s degree in the field of Computer Science and 15 years experience or equivalent combination of education and experience. Have advanced knowledge of data warehousing design concepts (ex: schema models and normalization techniques). Can demonstrate advanced SQL expertise. Have a thorough understanding of granularity, facts and dimensions, as well as star and snowflake schemas. Possess strong knowledge of at least one major reporting package (ex: tableau or SSRS). Demonstrate excellent knowledge of TSQL and SSIS (or similar languages, platforms for data integration and workflow applications). Show experience with Pentaho and Microsoft Azure. Have previous experience with Agile development practices. Can develop knowledge of industry data privacy requirements. Are aware of emerging technologies (i.e. machine learning and advanced analytics). TO THRIVE AT CAP COM YOU NEED Effective oral, written and auditory communication skills. Strong organizational skills and attention to detail with the ability to work well in a dynamic environment. Strong interpersonal skills. Strong troubleshooting skills. OUR CULTUREOur reputation truly precedes us, and we recognize that our employees are our most valuable resource. We encourage an inclusive atmosphere of honesty, fairness and communication that creates a united force of successful professionals. At CAP COM you can bring your authentic self to work every day. *WHAT YOU GET*CAP COM invests in you and your future with development and training, mentoring and recognition programs. We are a professional and fun organization offering quality benefits including medical, dental, life insurance, flexible spending accounts, and 401(k) with generous profit sharing/matching contributions. We also provide competitive PTO, holidays, bonus potential and tuition reimbursement.At our headquarters there is an on-site gym and fitness classes, an on-site café, healthy meal deliveries and a 130-acre public park just out the back door (there is a reason we have been named a Healthiest Employer by the Albany Business review). All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other legally protected status. *Albany Business Review (confidential employee survey) Location: 4 Winners Circle, Albany, NY 12205 Job Type: Full-time"
Senior Data Engineer,SymphonyRM,"Palo Alto, CA 94301 (Professorville area)",https://www.indeed.com/rc/clk?jk=37248d567574d59f&fccid=397f47d47da45b68&vjs=3,"Introduction SymphonyRM helps health systems thrive in the rapidly evolving US Healthcare industry by keeping patients healthy and physicians happy. By analyzing large amounts of data from many sources, we empower clients to make smarter decisions at every turn in their business. Our clients love SymphonyRM’s ability to guide them to take the next best action for both patients and physicians. As a Senior Data Engineer, you’ll play a critical role in developing tools to automate data ETL processing, assess data quality from multiple sources, and build a powerful data pipeline, while working closely with our other engineers. We care deeply about building long-term careers and offer opportunities for our employees to grow towards project leadership, engineering management, or other roles to make a difference in the lives of patients. You’d be a great addition if… You have a Master’s degree in Computer Science, Statistics or similar degree OR Bachelor’s degree with at least 3 year related experience with Python programming OR 5+ years related experience with Python programming (e.g. completion of a Python-focused bootcamp). You seek to fully understand “big data” problems, and strategize to produce efficient, workable solutions. You are curious about emerging technologies, and like to evaluate and adapt where you see fit. You’re motivated by high-impact projects via automation or scaling data operations to drive business value. You’re excited to work with cross-functional teams in an agile environment. You appreciate working with people from diverse backgrounds. Building tools to automate data anomaly detection and alerting Scaling our data infrastructure and developing software that allows for improved data processing and automation Bonus qualifications if... You’ve worked on large-scale databases using cloud computing platforms like Amazon AWS You have strong knowledge with SQL/Relational databases You have experience in using data visualization tools (Looker, Matplotlib, Excel, etc.) Experience with Apache Airflow and/or Pandas You have studied or have experience designing data pipelines and loading large datasets into databases What You’ll Do: You will work closely alongside a small team of engineers to drive continuous improvements to our Python-based data platform. Write and deploy Python code to automate data ingestion using Apache Airflow. Support internal and external stakeholders in troubleshooting and resolving issues. Contribute new ideas in design to development to our data infrastructure - we are always looking to improve. Due to Covid-19, you will be working remotely for the time being. We are actively interviewing and hiring this position based out of our Palo Alto, CA office."
Data Engineer,Tata Elxsi,"Philadelphia, PA",https://www.indeed.com/rc/clk?jk=8abd5b24898587a1&fccid=cf9a392c0e128671&vjs=3,"5+ years’ experience with highly scalable, high performance and high availability server development 2 years of work or educational experience in big data. Experience with distributed processing and messaging systems, including Spark, Akka, Kafka, Pub/sub, Hive/pig, Mapreduce, etc. Experience with various distributed databases like Cassandra, Redis, MongoDB, etc. Demonstrate clear and concise communication and data-driven decision-making capability Expertise in some or all of the following: o Data Pipelines o Data Warehousing o Statistics o Metrics development Strong understanding of SQL Broad knowledge of the data infrastructure ecosystem Experience with one or more general purpose programming languages including but not limited to: Java/Scala, C/C++ or Python Solid background in algorithms, data structures, and object-oriented programming concepts B.S. and/or M.S. in Computer Science or a related technical field, or equivalent experience Job location:- Philadelphia, PA - USA Qualification - Bachelors/ Masters Job Code - Data Engineer"
Cloud Data Engineer,Pandera Systems,United States,https://www.indeed.com/rc/clk?jk=9189f2a6e2b59f87&fccid=505d1fb00d86d35b&vjs=3,"Pandera Systems is a highly specialized analytics and technology consulting firm with a core focus in developing data-driven solutions. As a Certified Google Partner, we bring together the most advanced software engineers, data scientists, and technologists to help transform the world’s leading brands. Pandera is now looking to expand our success by continuing to build our team of passionate, curious, and skilled engineering gurus to help deliver our products and services at scale! Join us! Type: Full time Salary: Competitive rate based on qualifications Education: Bachelor's or Master’s degree in technical discipline; Master's preferred, or equivalent years’ of experience in the field. Must be Authorized to work in the USA Cloud Data Engineer Do you like data? Do you know how to take data and transform it to get meaningful data into end users’ hands? Do you enjoy taking complex problems and turning them into technical solutions that power Reporting Solutions, Advanced Analytics, and Data Sciences? We are looking for a Cloud Data Engineer to join our team of engineers, analysts, and architects focused on designing, building, and delivering data solutions that drive business decisions. As a Pandera Employee, you will have the opportunity to build world-class solutions to help our clients and partners solve challenging problems through data. Responsibilities: Develop data pipelines for batch, micro-batch, and real-time data streams. Responsible for data modeling and schema design that will range across multiple business domains and industries. Partner with multiple client stakeholders including partners, business users, BI and Analytics teams. Work with teams to conduct workshops to identify data sources, flows, and requirements. Coordinate work with client teams to ensure a smooth development and transition. Requirements: Experience developing and deploying ETL / ELT processes and documentation including physical data model, source to target mappings, ETL / ELT packages (python, Airflow, Spark) Implement solutions for structured, semi-structured, and unstructured data sources, relational and non-relational databases. Implementing Data Quality rules and test cases into a data environment Experience in utilizing git within a CI/CD framework Proven ability to work with users to define requirements and business issues Excellent analytical and troubleshooting skills Strong written and oral communication skills 3+ years of experience working with cloud-based databases, specifically BigQuery. Additional Desired Requirements: Experience working in an AGILE environment Experience with GCP infrastructure (GCS, BigQuery, Composer, Dataflow, Dataproc, Data Fusion), or other equivalent Public Cloud offerings Experience developing logical data models within a data warehouse Experience with BMC Control-M Nice to Haves: Experience in KSH scripting Experience in Teradata Tools and Utilities (TTU) What Do You Get Out of This? You are a hot commodity and having you on the team would be an honor to us! Here are some of the ways we pay it forward to recognize your contribution to our vision! Be Healthy: Health, dental, and vision offered through top tier providers and sick leave to keep you feeling at the top of your game. Be Inspired: Collaborative workspace, personal days, paid birthday off, and vacation time to keep your mind fresh and ready to take on the next new idea. Be Rewarded: A competitive salary and company matched 401k plans are only a few of the rewards for a job well done. Be Supported: A large network of industry experts, internal training platform, and external learning opportunities to grow your skills and experience. Be a Team: Team outings, vitual happy hours, passion presentations, volunteer opportunities, meetups, etc. we are creating a community to continuously share and grow as a team."
Data Engineer - CDW,California State University,"San Jose, CA",https://www.indeed.com/rc/clk?jk=5c6de5c40e19268f&fccid=938c68fc89db4b9d&vjs=3,"Job no: 514379 Work type: Staff Location: San José Categories: Unit 9 - CSUEU - Technical Support Services, Probationary, Full Time, Information Systems & Technology Job Summary Reporting to the Interim Associate Chief Information Officer and Senior Director of Enterprise Solutions, the Data Engineer – Campus Data Warehouse (CDW) is responsible for SJSU’s Campus Data Warehousing/Business Intelligence implementation. This position will play an important role in the research, design, architecture, creation, development, implementation, and maintenance of Campus Data Warehouse. This includes identifying and pulling data from 500+ individual databases across SJSU and curating them into a single data source in order to facilitate data-driven decisions. Assist in conducting technical reviews, creating definitions of business problems, including the preparation of business/technical requirements to support the mission of the university and administrative departments, providing systems and technical support of vendor and locally developed software, and work with the Data Warehouse Project Manager, SJSU IT Enterprise Solutions resources, external vendors, and IT team members. Duties and system assignments can be temporarily or permanently changed to meet the needs and goals of the department and university. Key Responsibilities Develop and maintain ETL processes to populate the data warehouse Build and maintain Google BigQuery data warehouse interfaces to house data from various sources such as Oracle, MySQL, and Web APIs, etc. Building and maintaining production data pipelines for data analytics Partner cohesively with campus stakeholders to align with their strategic goals and initiatives through the implementation of Campus Data Warehouse Collaborate with key analytical vendors who can provide specialized expertise to assist with solution development while developing the in-house effort and managing CO interface Follow project plans, timelines, and vendor relationships to ensure releases are delivered with the highest quality, on-time and within budget Provide the data analytics infrastructure that supports and achieves operational organization goals and targets Apply performance tuning techniques to existing and new ETL scripts and analytical reports Develop efficient database manipulation code to ensure reliable and consistent result sets Develop appropriate and reusable data validation scripts to ensure the analytical dashboards are meeting the business requirements Assist the development team in performing the troubleshooting of Campus Data Warehouse components as identified by the Business groups Develop and deploy ad-hoc query extracts from Campus Data Warehouse as desired by the Business groups Participate in overall analytics architecture and application roadmap. Assist in the improvement of organization performance by utilizing not only the data already available to the organization, but also utilizing new and innovative sources of data Develop custom reports as necessary using visualization tools such as Google Data Studio, Tableau and other visualization tools Identify, interpret, analyze and address critical business issues, questions and to develop use cases. Organizing and creating an environment that makes data and information accessible with appropriate channels of access controls. Knowledge, Skills & Abilities Intermediate skills in a Data Engineer role Knowledge of Google Cloud Platform components including but not limited to Composer, Airflow, Dataproc, Sqoop, Cloud Storage, and BigQuery Advanced knowledge in high level programming languages like: Python, SQL, Java, and JavaScript Advanced knowledge of application development, testing and deployment processes and tools Knowledge of data visualizations tools like Tableau, Google Data Studio, or equivalent experience Knowledge and skills working with large data sets Solid knowledge of ETL, ELT, reporting and analytics tools and environments Ability to strategically think and build a Data Warehouse to answer important questions across a variety of functional areas Ability to collaborate with business stakeholders and IT management to understand solution requirements and system design Strong interpersonal, communication, organization and planning skills Proficiency in management of multiple priorities to produce quality products for customers Required Qualifications A bachelor’s degree, preferably in computer science or business, or equivalent training and applied experience 5+ years of experience in business applications analysis, design, and programming for medium or large scale, multi-programmed computers Preferred Qualifications 3+ years’ experience developing, maintaining and collecting structured and unstructured data sets for analysis and reporting 3+ years of working experience in implementing cloud-based architecture (i.e. Google Cloud Platform or similar) Compensation Classification: Analyst/Programmer-Expert Anticipated Hiring Range: $9,640/month - $9,834/month CSU Hiring Range: $6,249/month - $12,100/month San José State University offers employees a comprehensive benefits package typically worth 30-35% of your base salary. For more information on programs available, please see the Employee Benefits Summary. Application Procedure Click to complete the SJSU Online Employment Application and attach the following documents: Resume Letter of Interest All applicants must apply within the specified application period: June 9, 2022 through June 26, 2022. This position is open until filled; however, applications received after screening has begun will be considered at the discretion of the university. Contact Information University Personnel jobs@sjsu.edu 408-924-2252 CSU Vaccination Policy The CSU requires faculty, staff, and students who are accessing campus facilities to be fully vaccinated against the COVID-19 virus (including all booster doses of an approved vaccine for which an individual is eligible per current CDC recommendations) or declare a medical or religious exemption from doing so. As a condition of employment, any candidates advanced in a currently open search process should be prepared to comply with this requirement as well as with other safety measures established on the campus. The system wide policy can be found at https://calstate.policystat.com/policy/9779821/latest/ and questions may be sent to jobs@sjsu.edu. Additional Information Satisfactory completion of a background check (including a criminal records check) is required for employment. SJSU will issue a contingent offer of employment to the selected candidate, which may be rescinded if the background check reveals disqualifying information, and/or it is discovered that the candidate knowingly withheld or falsified information. Failure to satisfactorily complete the background check may affect the continued employment of a current CSU employee who was offered the position on a contingent basis. The standard background check includes: criminal check, employment and education verification. Depending on the position, a motor vehicle and/or credit check may be required. All background checks are conducted through the university's third party vendor, Accurate Background. Some positions may also require fingerprinting. SJSU will pay all costs associated with this procedure. Evidence of required degree(s) or certification(s) will be required at time of hire. SJSU IS NOT A SPONSORING AGENCY FOR STAFF OR MANAGEMENT POSITIONS. (e.g. H1-B VISAS) All San José State University employees are considered mandated reporters under the California Child Abuse and Neglect Reporting Act and are required to comply with the requirements set forth in CSU Executive Order 1083 as a condition of employment. Jeanne Clery Disclosure of Campus Security Policy and Crime Statistics Act and Campus Housing Fire Safety Notification: Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act, the Annual Security Report (ASR) is also now available for viewing at https://www.sjsu.edu/clery/docs/SJSU-Annual-Security-Report.pdf. The ASR contains the current security and safety-related policy statements, emergency preparedness and evacuation information, crime prevention and Sexual Assault prevention information, and information about drug and alcohol prevention programming. The ASR also contains statistics of Clery crimes for San José State University locations for the three most recent calendar years. A paper copy of the ASR is available upon request by contacting the Office of the Clery Director by phone at 408-924-1501 or by email at clerycompliance@sjsu.edu. Pursuant to the Higher Education Opportunity Act, the Annual Fire Safety Report (AFSR) is also available for viewing at https://www.sjsu.edu/clery/docs/SJSU-Annual-Fire-Safety-Report.pdf. The purpose of this report is to disclose statistics for fires that occurred within SJSU on-campus housing facilities for the three most recent calendar years, and to distribute fire safety policies and procedures intended to promote safety on Campus. A paper copy of the AFSR is available upon request by contacting the Housing Office by phone at 408-795-5600 or by email at uhs-frontdesk@sjsu.edu. Equal Employment Statement San José State University (SJSU) is an Equal Opportunity/Affirmative Action employer committed to nondiscrimination on the basis of age, ancestry, citizenship status, color, creed, disability, ethnicity, gender, genetic information, marital status, medical condition, national origin, race, religion or lack thereof, sex, sexual orientation, transgender, or protected veteran status consistent with applicable federal and state laws. This policy applies to all SJSU students, faculty and staff programs and activities. Title IX of the Education Amendments of 1972, and certain other federal and state laws, prohibit discrimination on the basis of sex in all education programs and activities operated by the university (both on and off campus). Advertised: June 09, 2022 (9:00 AM) Pacific Daylight Time Applications close:"
Associate Data & Machine Learning Engineer,"Amazon Web Services, Inc.","Los Angeles, CA+10 locations",https://www.indeed.com/rc/clk?jk=fa9af7fcf047138e&fccid=5cc0cdc6dbb121cc&vjs=3,"Bachelor’s degree in Computer Science, Engineering, Mathematics or a related field or equivalent professional or military experience 1+ years of experience of Data platform implementation 1+ years of hands-on experience in implementation and performance tuning of Kinesis, Kafka, Spark or similar implementations Hands on experience with building data or machine learning pipeline Experience with one or more relevant tools (Flink, Spark, Sqoop, Flume, Kafka, Amazon Kinesis) Experience developing software code in one or more programming languages (Java, JavaScript, Python, etc.) Current experience with hands-on implementation Are you a Data and Machine Learning specialist? Do you have Data platform experience? Do you like to solve the most complex and high scale (billions + records) data challenges in the world today? Do you like to work in a variety of business environments, leading teams through high impact projects that use the newest data analytic technologies? Would you like a career path that enables you to progress with the rapid adoption of cloud computing? At Amazon Web Services (AWS), we’re hiring highly technical Data and Machine Learning engineers to collaborate with our customers and partners on key engagements. Our consultants will develop and deliver proof-of-concept projects, technical workshops, and support implementation projects. These professional services engagements will focus on customer solutions such as Machine Learning, Data and Analytics, HPC and more. In this role, you will work with our partners, customers and focus on our AWS offerings such Amazon Kinesis, AWS Glue, Amazon Redshift, Amazon EMR, Amazon Athena, Amazon SageMaker and more. You will help our customers and partners to remove the constraints that prevent them from leveraging their data to develop business insights. AWS Professional Services engage in a wide variety of projects for customers and partners, providing collective experience from across the AWS customer base and are obsessed about customer success. Our team collaborates across the entire AWS organization to bring access to product and service teams, to get the right solution delivered and drive feature innovation based upon customer needs. You will also have the opportunity to create white papers, writing blogs, build demos and other reusable collateral that can be used by our customers. Most importantly, you will work closely with our Solution Architects, Data Scientists and Service Engineering teams. This is a customer facing role. You will be required to travel to client locations and deliver professional services when needed. Inclusive Team Culture Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have thirteen employee-led affinity groups, reaching 85,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. Work/Life Balance Our team puts a high value on work-life harmony. Striking a healthy balance between your personal and professional life is crucial to your happiness and success here. We are a customer-obsessed organization—leaders start with the customer and work backwards. They work vigorously to earn and keep customer trust. As such, this is a customer facing role in a hybrid delivery model. Project engagements include remote delivery methods and onsite engagement that will include travel to customer locations as needed. Mentorship & Career Growth Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future. Masters or PhD in Computer Science, Physics, Engineering or Math. Familiar with Machine learning concepts Hands on experience working on large-scale data science/data analytics projects Hands-on experience with technologies such as AWS, Hadoop, Spark, Spark SQL, MLib or Storm/Samza. Experience Implementing AWS services in a variety of distributed computing, enterprise environments. Experience with at least one of the modern distributed Machine Learning and Deep Learning frameworks such as TensorFlow, PyTorch, MxNet Caffe, and Keras. Experience building large-scale machine-learning infrastructure that have been successfully delivered to customers. Experience defining system architectures and exploring technical feasibility trade-offs. 2+ years experiences developing cloud software services and an understanding of design for scalability, performance and reliability. Ability to prototype and evaluate applications and interaction methodologies. Experience with AWS technology stack. AWS Certification(s) such as Solutions Architect Associate and/or Data Analytics Specialty Written and verbal technical communication skills with an ability to present complex technical information in a clear and concise manner to a variety of audiences. Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. For employees based in Colorado, this position starts at $82,600 per year. A sign-on bonus and restricted stock units may be provided as part of the compensation package, in addition to a range of medical, financial, and/or other benefits, dependent on the position offered. For more information regarding Amazon benefits, please visit https://www.amazon.jobs/en/benefits. Applicants should apply via Amazon’s internal or external careers site."
Senior Data Engineer,"Bluehawk, LLC","Quantico, VA 22134+1 location",https://www.indeed.com/rc/clk?jk=2b47ad38c1e43105&fccid=b2a0c86193849cf1&vjs=3,"Overview: Bluehawk is seeking a Senior Data Engineer to work in Quantico, VA. Responsibilities: Designs, implements, and operates data management systems for intelligence needs. Designs how data will be stored, accessed, used, integrated, and managed by different data regimes and digital systems. Works with data users to determine, create, and populate optimal data architectures, structures, and systems. Plans, designs, and optimizes data throughput and query performance. Participates in the selection of backend database technologies (e.g. SQL, NoSQL, HPC, etc.), their configuration and utilization, and the optimization of the full data pipeline infrastructure to support the actual content, volume, ETL, and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness. Qualifications: Demonstrates in-depth knowledge and understanding of the labor category activities required to meet mission requirements. Demonstrates mastery of qualitative and quantitative analytic methodologies and pursue developments in academia or other fields that affect tradecraft methodology. Demonstrates ability to define comprehensive, new, or unique research approaches that enable rigorous assessments to address and contribute to high-level tasks. Demonstrates in-depth analysis of analytic operations and knowledge management issues across organizational and intra-IC boundaries and clearly articulates key findings. Demonstrates ability to work independently and with minimal oversight. Demonstrates ability to review analytic products for cogent arguments, tradecraft standards, and adequate support for conclusions; routinely tests analytic rigor of analytic products. Desired Experience: Minimum 12 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years. Desired Education: Master’s degree in an area related to the labor category from a college or university accredited by an agency recognized by the U.S. Department of Education; or have Bachelor’s degree related to the labor category from a college or university accredited by an agency recognized by the U.S. Department of Education An additional 5 years of related senior experience, for a total of 17 years, as a substitute to the Master’s degree. Bluehawk, LLC. is an Equal Opportunity/Affirmative Action Employer/ /EOE Minority/Female/Disabled/Veteran/Sexual Orientation/Gender Identity/"
Senior Data Architect/Data Warehouse Engineer,First Eagle Investment Management,"New York, NY+1 location",https://www.indeed.com/rc/clk?jk=8c8f55b8ffe2ad8c&fccid=e45f2b9f76cc0de9&vjs=3,"What we do: First Eagle is an independent, privately owned investment management firm headquartered in New York with approximately $110 billion in assets under management (as of 12/31/21). Throughout a heritage that dates to 1864, the firm has sought to generate attractive real returns for our clients over the long term. This tradition remains central to our mission today, guided by a set of core investment tenets that sustains our culture while also allowing philosophical autonomy among our talented portfolio management teams. First Eagle’s range of actively managed equity and equity-oriented, public and private credit, multi-asset and alternative strategies reflect our dedication to disciplined and unconventional thinking, a global perspective and the long-term alignment of interests. What drives us: At First Eagle, clients come first, always. To deliver on this commitment, we nurture an environment that attracts, develops and retains a talented, inclusive workforce. We also aim to inspire each of our employees to do their life’s best work with us and for our clients. We have built a culture that promotes equity, diversity and respect, and holds every member of the organization to the highest standards of integrity and accountability. If this sounds right for you, please take a look at our open roles today. Who we are looking for : First Eagle is seeking a senior cloud data warehouse developer and architect to lead our effort to migrate our big data to cloud database technologies. The ideal candidate will have a proven track record of working with business users and other stakeholders to identify various data sets across the firm, evaluate and recommend a cloud database technology, and manage the implementation as the chief data architect. The candidate will work to develop a robust reporting platform around the cloud database and empower users across the firm by providing them with secure access to the raw data, when appropriate. The candidate will have direct responsibility for the initiative and will have the ability to develop a team of existing and new developers and architects to support the long-term effort. W hat yo u will do : Effectively function in a cross-team environment, and train experienced developers on cloud warehouse technologies to augment the team Administer and monitor the big data computing platform, and develop policies and procedures for its long-term support and success The qualities you shoul d ha ve : Minimum 10 years’ experience developing enterprise data warehouses, data migrations, data transformations, and data architecture Minimum 3 years’ hands-on experience working with Snowflake Data Cloud. Experience with migrating an existing on-premises data warehouse to Snowflake integrated with AWS is preferred. Extensive experience writing SQL queries and stored procedures preferred Experience in data migration from RDBMS to cloud data warehouse technologies Experience with Tableau or other data visualization software Experience in Python Framework to Process XML, CSV, JSON, TSV, TXT files Experience in gathering and analyzing system requirements Proven critical-thinking skills and problem-solving attitude Experience in Financial Services and management roles are a plus First Eagle requires employees to be fully vaccinated to work in the office unless an exemption is approved as a reasonable accommodation in accordance with applicable law. F irst E ag le Investment Mana gemen t, LLC (FEIM) is an Affirmative Action and Equal Opportunit y Employer. Equal Employmen t Opportunity has been, and will contin ue to be, a funda mental pr inciple at FEIM, w here employ ment is based upon p ersonal capabilities and qualifi cations without re gard to race, color, reli gious belief, including dress and groom ing practices, sex, sexual o rientation, gender identity, gender exp ression, age, nat ional ori gin, marital stat u s, c itizens hip, disability, vet eran status, pregnancy, breastfe eding or medical c ondit ions related to brea stfeeding, status as a victim of domest ic violence, sexual assault, or stalking, or any other basis protec ted by applicable federal, state or local l a w, g enetic information or chara cteristics (or those of a family member), or any o ther protected characteri stic as established by law."
Data Engineer,Liaison International,"Watertown, MA 02472",https://www.indeed.com/company/Liaison-International/jobs/Data-Engineer-c67f7469a9e3356e?fccid=4f7cefeb56d1c5b0&vjs=3,"Purpose: At Liaison, we’ve helped higher ed institutions build better, more diverse classes for three decades. You may recognize us as the company behind the Centralized Application Service (CAS), Enrollment Marketing services and platform (EMP), SlideRoom, Time2Track, TargetX (CRM) and Othot. *Everything we do is focused on taking that proven success and expanding its scope and scale. Over 31,000 programs on more than 1,000 campuses see us as a forward-thinking partner integral to meeting their total enrollment goals — and we’re building the data- and mission-driven team that will reinforce our role for decades to come.* Join a supportive collaborative growing team of problem-solvers to build impactful data analytics solutions. We learn constantly, improve our solutions proactively, innovate frequently and take advantage of modern data engineering technologies. The Liaison Data Engineering team owns data management, data integration, and analytics for a portfolio of analytics products, provides decision support for our Finance, Sales and Marketing teams, and is on a mission to take the Liaison data culture to the next level.**Accountabilities Collaborate with data engineers, product team, client success managers, and other stakeholders to address business needs and deliver valuable solutions to our clients Build data expertise, learn the business domain, and own data quality for the pipelines and dashboards the team builds Design, build, and launch scalable data stores and reliable integrations providing high quality data for analytics Extend the existing data warehouse to accommodate new data sets and solutions Design build, enhance, and maintain highly performant data pipelines Drive optimization, testing and tooling to improve data quality Perform data investigation as needed Participate in design decisions and in the peer review process, provide feedback, help improve our development practices and the quality of our products Understand various data security standards and use secure data security tools to apply and adhere to the required data controls and compliance requirements Work with data scientist and analytics team to assist in data ingestion and data related technical issues *Requirements* BS or MS in CS, CIS, Engineering, Mathematics or equivalent 3-5 years of experience in a data-focused role analyzing complex data sets and building high quality scalable data integration solutions/ ETL pipelines. Strong SQL and Python skills are required (Pandas, NumPy, Plotly, etc.). Experience with relational SQL and NoSQL databases Solid foundation in database and data warehouse design and development. Ability to work with a variety of databases including Postgres, SQL Server, data management solutions for analytics like Snowflake, and others as required Knowledge of modern data architecture for Analytics, data integration best practices and common patterns. Knowledge on structured and unstructured data design, data modelling, data access and data storage techniques Familiarity with the AWS ecosystem (RDS, EC2, S3) Experience using development tools like VS Code, Jupyter, source control (Git), and familiarity with Linux Awareness of best practices and regulations for handling PII Excellent analytical and problem-solving skills, and focus on quality Ability to communicate technical problems and solutions both in technical and non-technical terms Demonstrated ability to quickly grasp new technologies. Demonstrated experience working in agile environments Strong team player who enjoys working in a fast-paced, dynamic environment Ability to work under pressure, multiple deadlines and minimal supervision Ability to build positive working relationships within our Engineering team, across the company, and with partners and customers Data privacy and security experience *Bonus* Experience designing and building solutions in Snowflake, Airflow, AWS (RDS, EC2, S3) Experience building dashboards with Tableau or another reporting tool Location: 311 Arsenal Street, Watertown, MA 02472 Job Type: Full-time"
Data Engineer,MarketOne International,+1 locationRemote,https://www.indeed.com/rc/clk?jk=e33df11370eedebb&fccid=e808e30f36e8f9bd&vjs=3,"The DE is responsible for building, testing and providing QA on ETL processes that are put in place to support any client requirement. The DE skill set includes an in- depth knowledge general data principals, normalization, data aggregation, keys, indexes, etc. The tools used by the DE will include Transact SQL, SSIS, SSMS and other data utilities that work with them. A very strong understanding of data concepts of star join schema data architecture: Normalization, Denormalization, Facts, Dimensions and Aggregates as defined by Ralph Kimball. 3-5 years of experience working on data warehousing/data mart ETL projects Very strong understanding of MS SQL Server, T-SQL and SSIS. Optimization of SQL using Execution Plans PK and FK Constraints and Indexing The ability to document a stored procedure using a source to target map and data flow diagram Monitoring and trouble shooting as well as QA of SQL code written by other engineers Any experience with C#, Python or other scripting language a plus Any experience with basic reporting tools, Tableau, PowerBI or Klipfolio also very welcome"
"Data Engineer, Reporting",PlugShare,"Los Angeles, CA 90064",https://www.indeed.com/rc/clk?jk=dacee6e0c2ae84cb&fccid=a1e2458ea38781b8&vjs=3,"About PlugShare: PlugShare, a wholly owned subsidiary of EVgo, is home to the largest community of EV drivers in the world, with a community of over 3MM EV drivers who rely on us to plan their journeys and public charging stops. Every day, drivers add more station locations, constantly making the app more comprehensive and accurate. From within the app., users check-in when they charge, sharing tips, comments, reviews and photos of their charging experiences. Drivers, automakers, utilities, and the rest of the EV community rely on our comprehensive public charging dataset to power their navigation systems and guide their decision-making. We amplify the voice of the driver through PlugInsights, the world’s largest survey research panel of EV owners and leasers, and developed Pay with PlugShare (PWPS), a mobile payment platform enabling seamless and reliable payment for multiple charging networks through a single app. We also provide in-app and web advertising and digital marketing services to give brands and marketers access to the largest EV driver audience. Position Summary: We are seeking a Data Engineer, Reporting to join the PlugShare team. This is a great opportunity to work in the exciting, growing electric vehicle market. The ideal candidate has a deep understanding of SQL and supreme analytical skills. Beyond data queries and visualizations, many projects will focus on improving data quality. The person in this role will have a large level of ownership over our tooling and ETL processes. Responsibilities: Build, deploy and maintain ETLs to pull data out from all third-party systems Write complex SQL queries and provide easily queryable datasets in the form of Tableau extracts and database views Work with engineering teams and cross-functionally to build to improve data consumption, data integrity and automation Use SQL to query, manipulate and transform data consumed and exposed SQL Performance & Tuning Perform ETL to blend data sources through manual and automated processes Develop and maintain technical specification documentation for data flows and reports/dashboards. Manage and investigate data errors and work to improve Partner with teams to understand data requirements for analysis and reporting tools. Create Reports and Dashboard/Visualizations Develop and maintain technical specification documentation for data flows and reports/dashboards (Tableau), aggregating data from multiple data sources Review and verify data and reports for accuracy. Required Skills and Experience: BS/BA in Technical Field, Computer Science, Mathematics, Statistics, or equivalent experience. 3+ years of experience coding in SQL Some experience working in Python preferred Experience building ETLs against various sources, including REST endpoints Experience working in cloud environments (AWS, GCP) Experience in building and enhancing data pipelines Familiar with reporting tools (Tableau, PowerBI, QlikView, etc.); we use Tableau Employees are required to provide documentation of COVID 19 vaccination."
Lead Software Engineer - Data Warehousing,Nike,"Beaverton, OR",https://www.indeed.com/rc/clk?jk=6c27a0882061a497&fccid=2c62e4de04b8f952&vjs=3,"Become a Part of the NIKE, Inc. Team NIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game. NIKE is a technology company. From our flagship website and five-star mobile apps to developing products, managing big data and providing leading edge engineering and systems support, our teams at NIKE Global Technology exist to revolutionize the future at the confluence of tech and sport. We invest and develop advances in technology and employ the most creative people in the world, and then give them the support to constantly innovate, iterate and serve consumers more directly and personally. Our teams are innovative, diverse, multidisciplinary and collaborative, taking technology into the future and bringing the world with it. Who we are looking for We are building and supporting petabyte-class solutions that consume fast moving streams from eCommerce, retail, and partner channels to power the critical decisions that drive our business. As Lead Software Engineer, you will be a key part of Nike’s Digital Transformation initiative through Nike’s Data Technology Foundation capabilities helping deliver efficient and reliable data discovery, data access, data warehousing, and advanced computing platforms. Our capabilities look to simplify customer experiences while driving enhanced compliance and reduced risk. What you will work on We’re hiring a Lead Software Engineer with talent and persistence who can use their existing skills while quickly developing new ones. You should have extensive experience in many of the specific technical skills we’re looking for and be expert enough to help onboard others quickly. Operate as a Subject Matter Expert (SME) on an agile/SCRUM team with aggressive goals Be a key contributor to overall architecture, framework, and design of Data Technology Foundation solutions Help lead next generation cloud-based Data Warehouse platforms, emphasizing automation and scalability Ensure product and technical features are delivered to spec and on-time Develop tools and frameworks to improve security, reliability, maintainability, availability, and performance Leverage expert development skills to deliver performant customer focused solutions with modern tooling Who you will work with Onboard and mentor new/less experienced developers to advance their proficiency Partner with Product Owners, Engineering Managers, and Principal Engineers to deliver solutions that enable Nike's digital transformation What you bring Bachelor’s degree in Computer Science, Software Engineering, or related field or combination of relevant education, experience, and training 5+ years of experience in large-scale data warehouse/RDBMS deployments with emphasis on user experience, security, system performance and cost optimization 5+ years developing software systems that operate at scale 2+ years of experiencing onboarding & mentoring new team members and peers 2+ years of experience architecting and building scalable data architecture 2+ years developing software solutions w/ Python 2+ years developing Platforms on a commercial cloud (AWS, Azure or GCP) 2+ years with modern CI/CD pipeline patterns (Git) Exposure to Agile and test-driven development, ideally knowledge of the SAFe methodology Experience with securing RESTful APIs and Apps using OAuth, OpenID Connect, and JWT a plus Ideal technical skills Experience integrating COTS and open source to create petabyte scale solutions RDBMS Snowflake / Teradata Python Amazon AWS / S3 / Linux / IAAS Airflow Okta / IAM integration / Unified Access Tableau / Cognos / DOMO Apache Ranger / Privacera Starburst Autosys Terraform Distributed systems Nike requires all applicants for this position to be vaccinated for COVID-19 as a condition of hire, unless otherwise required by law. As an equal opportunity employer, Nike will make accommodations to individuals who cannot be vaccinated in accordance with applicable law. NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world. NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability."
Big Data Platform Engineer,Kraken Digital Asset Exchange,Remote,https://www.indeed.com/company/Kraken-Digital-Asset-Exchange/jobs/Big-Data-Platform-Engineer-5beb8da837c85356?fccid=fc7b3a033fd34a37&vjs=3,"About Kraken As one of the largest and most trusted digital asset platforms globally, we are empowering people to experience the life-changing potential of crypto. Trusted by over 8 million consumer and pro traders, institutions, and authorities worldwide - our unique combination of products, services, and global expertise is helping tip the scales towards mass crypto adoption. But we’re only just getting started. We want to be pioneers in crypto and add value to the everyday lives of billions. Now is not the time to sit on the sidelines. Join us to bring crypto to the world. Site Reliability Engineer - Big Data As a Site Reliability Engineer in Big Data you will work within a team of world-class engineers to establish and maintain infrastructure which is critical in enabling Kraken to make data-driven decisions.You'll be responsible for helping keep our data platform online and operating at full efficiency. The data platform processes hundreds of thousands of records per second and must provide stable and rapid access for all of our internal users and systems.You'll also have the opportunity to leverage your expertise and help implement best practices with regards to operating data infrastructure in Kubernetes and AWS. Responsibilities: * Monitor and support data infrastructure in UAT and production environments* Manage infrastructure releases using Kubernetes* Collaborate with data engineers and data software engineers to improve infrastructure stability, monitoring, and alerting.* Participate in support rotations to help respond to infrastructure issuesRequirements:* 3+ years in a DevOps role (SRE, Data Ops, DevOps, etc...)* Solid understanding of Infrastructure as Code, Linux, Docker and Kubernetes* Experience with monitoring tools such as Prometheus and Grafana* Experience using Git as a version control system* Previous experience operating one or more of the following tools: Debezium, Mirrormaker, Kafka, Druid, Superset, or Airflow.* Strong understanding of security best practices* Ability to work autonomously with little supervision Nice to have:* Understanding of Terraform* Experience with Helm and Helm chart customization* Experience with Go or Python programming languages* Experience managing EMR or maintaining hosted Jupyter/Zeppelin environments* Knowledge of AWS best practices* Understanding of best practices with regards to alerting and monitoring using Prometheus and Grafana* Experience with Slack, JIRA, or Gitlab APIs* Passion for crypto Role Summary: This role will help the Big Data team stabilize it's infrastructure to scale with the growing demand on our existing tools such as Superset and Airflow. It will also help stabilize our data pipelines to ensure tools like Superset and Zeppelin can provide accurate data in a timely manner. Location Tagging: #US #EU We’re powered by people from around the world with their own unique and diverse experiences. We value all Krakenites and their talents, contributions, and perspectives, regardless of their background. As an equal opportunity employer we don’t tolerate discrimination or harassment of any kind. Whether that’s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws. Job Type: Full-time Work Location: Remote"
Operations Data Engineer - MMIC Foundry - Hybrid,Raytheon Missiles & Defense,"Andover, MA 01810",https://www.indeed.com/rc/clk?jk=30a98e1fd0f4b0cd&fccid=285def9eed767e8e&vjs=3,"About Us: At Raytheon Missiles & Defense, you have the opportunity to try new things and make a bigger difference across a broader end-to-end solution, a richer technology and product set, an expanded range of disciplines, a growing global footprint and a more diverse team of colleagues and customers. Job Summary: The Raytheon Missiles & Defense RF Components (RFC) facility manufactures compound semiconductor devices and monolithic microwave integrated circuits (MMICs) for defense applications. The core of the facility is the integrated development and production manufacturing line for fabrication of Gallium Arsenide (GaAs) and Gallium Nitride (GaN) components using advanced processing technologies and industry-leading operational execution. The RFC Operations team has an opening for a hybrid Sr Operations Analyst. This role is responsible for working within a small team to assist with and expand the Eyelit Manufacturing Execution System (MES). Supporting duties include maintaining the MES and executing configuration changes requested by various RFC entities. The MES is a critical part of the data infrastructure, and RFC values data driven decision-making. To that end, additional support duties involve configuring the MES to collect the appropriate data and creating business intelligence (BI) tools derived from the data. Expansion duties could include configuring the MES to act as a remote factory host, development of web applications to interact with the MES, and data analytics from the data collected from the MES to facilitate improvements to key metrics. While the central responsibility of this role will be the configuration and sustainment of the MES application, someone in this role will have the opportunity to contribute to many projects and utilize or develop multiple skills. We value SECS/GEM experience for contributing to factory host development, Angular experience for web application build out, and data science experience for analytics/BI development. The individual must be able to work in a team-oriented environment, working with with multiple CBT (cross business team) members through verbal and written means of communications. The candidate should possess a strong working knowledge of data management, be detail orientated and a self-starter. We value diverse skills and experience, so don’t hold back. Your qualification could add tremendous value to our team. Our customers come from all different backgrounds, and so do our employees. If you’re passionate about what you could accomplish here, we’d love to hear from you. Responsibilities to Anticipate: Configuration of MES Application (Eyelit) Development of business intelligence tools Factory Automation Data Analysis Qualifications You Must Have: Typically requires Bachelor’s degree and two (2) years of prior relevant experience OR in absence of a degree, six (6) years of relevant experience is required. Qualifications We Value: Working knowledge of Java, JavaScript, C#, python or any other major programming language. Experience with SQL Experience with SECS/GEM Experience with Angular web application framework Experience with Data Visualization Tools, such as Tableau Good interpersonal skills to manage tasks that bridge operations, production control, engineering, supply chain, and customer relations What We Offer: Whether you’re just starting out on your career journey or are an experienced professional, we offer a robust total rewards package that goes above and beyond with compensation; healthcare, wellness, retirement, and work/life benefits; career development and recognition programs. Some of the first class benefits we offer include parental (including paternal) leave, flexible work schedules, achievement awards, educational assistance, and child/adult backup care. Additional Details: Employee Referral Award Eligibility: Only employees currently within RMD and RI&S have the potential to receive a Referral Award for submitting a referral to RMD and RI&S roles. ALL eligibility requirements must be met (see guidelines) to receive the Referral Awarding. Raytheon Technologies is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class."
Data Engineer,Deep Labs,United States,https://www.indeed.com/rc/clk?jk=2222e3f57ef5e8e3&fccid=df4d25d87e00f676&vjs=3,"Deep Labs is a rapidly growing artificial intelligence company that helps businesses reduce fraud and identity theft, optimize customer experience, and make better business decisions. Our Mission: We believe Persona-Based Intelligence is the next generation of true context-aware computing. Our mission is to be the world leader in the delivery of persona-based decisions through innovation and technology, helping our clients make faster and better decisions while improving customer experience. Position Overview: As a Data Engineer, reporting to the VP Data Science & Engineering, you'll speak up, solve problems, lead others, and be an owner in your role. If you enjoy the experience of turning the chaos of messy data into beautiful adaptable structures, live in the clouds both in terms of delivery and creative thinking, are opinionated on design, and prefer to take ownership of tasks – you are right for this role. If you understand that documentation is the heart of everything and are always the one to point out that more time should be spent on it, we want you! Roles & Responsibilities Build data pipelines for the entire data lifecycle, and be accountable for the technical design (with support from the lead architect) and end-to-end implementation of the application; Design & implement scalable Features Repository for constructing complex variables out of raw structured and unstructured data. Collaborate in a small squad, as part of a larger team, architecting, extending, maintaining, and tuning scalable & reusable distributed data capabilities, working with both product and engineering teams to ensure that our systems are fit for purpose Identify and drive ways to improve data quality, reliability and reuse across the platform; help develop, refine and manage data governance processes including: schema management, data discovery, metadata management & data versioning; contribute to technical project meetings, reviews and delivery activities. Manage technical debt, drive code quality, and implement best practice, making the right calls between balancing pragmatic delivery and compromising implementation patterns; monitor system performance and implement tuning, and accurately estimate and implement feature work to a high standard. Experience we're seeking 3+ years experience in a dedicated data engineer role, with exposure to complex Data Science/Machine Learning and Big Data problems Experience working on a daily basis with large structured & unstructured data in various formats Strong proficiency in one or more of: SQL, Python, Kafka, Linux Experience in distributed data processing & transformation Experience working in public cloud environments (Google Cloud or AWS preferred) Experience in application of SDLC best practices, in software delivery projects Strong analytical and quantitative skills; strong attention to detail Knowledge and experience of one or more of the following is a plus: data processing frameworks & libraries (e.g. Pandas, Dask, PySpark) graph data models & graph processing algorithms orchestration & data management tools (e.g. Apache Airflow) building & deploying software in containers (e.g. Docker, Kubernetes) data storage & query engines (e.g. PostgreSQL, Snowflake) notebooks (Jupyter and/or Databricks), and the wider notebook ecosystem event streaming frameworks (e.g. Apache Beam, Flink or Spark Streaming) We are a global group of unique, accomplished professionals who value the sharing of ideas, respect our diverse differences and values, are trusted advisors internally and externally, yearn to drive meaningful change, and continuously explore opportunities to improve. We motivate and support each other and know that each win is a win for us all. Our people are our most valuable asset. Driven by our Core Values, we foster an environment that attracts, motivates, and engages our people to achieve their full potential; individually and as a team. OUR COMMITMENT TO DIVERSITY, INCLUSION & BELONGING Deep Labs is committed to equal employment opportunity. We will not discriminate against employees or applicants for employment on any legally-recognized basis [”protected characteristics’] including, but not limited to: race, religious creed (including religious dress and grooming practices), color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy), gender, gender identity, gender expression, age for individuals over forty years of age, sexual orientation, military and veteran status of any person, or any other consideration made unlawful by federal, state or local laws."
Sr Quality Engineer (Trending and Data Analytics),Medtronic,"Mounds View, MN",https://www.indeed.com/rc/clk?jk=ca79cb3d48201e8a&fccid=f06a4d05bf5510ec&vjs=3,"Senior Quality Engineer (Trending and Data Analytics) Mounds View, MN Careers that Change Lives In this exciting role as a Trending and Data Analytics Senior Engineer you will have responsibility for monitoring product performance and identifying signals for further investigation for Medtronic Cardiac Ablation Solutions (CAS), supporting the full product life-cycle. The CAS Trending and Data Analytics team is part of the Post-Market Quality Organization, responsible for ensuring market released CAS products remain safe and effective through the entire product life cycle. This role will have responsibilities in analyzing multiple data sources including complaints, service, and returned product analysis data using established procedures and analysis tools. In addition, this role will lead continuous improvements in data management, driving efficient, high quality outputs to implement best-in-class trending and associated data analytics. Cardiac Ablation Solutions Cardiac Ablation Solutions offers cardiac mapping and ablation solutions for arrhythmia management. A Day in the Life Develop and maintains Data Monitoring Plan for new products. Lead the investigation of potential issues and provide data recommendations on actions to the broader post-market quality team. Consult with cross-functional Engineering groups to determine when observed trends should be escalated for additional investigation and provide on-going support through statistical analysis of relevant data Comparing observed rates to established risk management expectations Work with the Complaint Handling and Returned Product Analysis teams to ensure that complaint codes are properly assigned in the complaint handling system. Where appropriate, provide recommendations to improve the coding process. Provide the data necessary to support the corrective action (CAPA) and other internal processes (regulatory, clinical, R&D, etc.). Respond to requests for information related to product performance from competent authorities, Medtronic geographies, customers and management. Support Reliability Engineering with data collection and analysis. Regularly communicate product performance data to the organization (via email, product performance meetings and management reviews). Generate regular reports to document assessment results and on-going monitoring activities. Develop tests and/or validation protocols needed to assess the accuracy of data and/or coding used for report generation. Lead initiatives to drive data efficiencies utilizing automation tools and continuous improvement of required communications and deliverables. Responsibilities may also include the following and other duties may be assigned. Develops, modifies, applies and maintains quality standards and protocol for processing materials into partially finished or finished materials product. Collaborates with engineering and manufacturing functions to ensure quality standards are in place. Devises and implements methods and procedures for inspecting, testing and evaluating the precision and accuracy of products and production equipment. Designs or specifies inspection and testing mechanisms and equipment; conducts quality assurance tests; and performs statistical analysis to assess the cost of and determine the responsibility for products or materials that do not meet required standards and specifications. Ensures that corrective measures meet acceptable reliability standards and that documentation is compliant with requirements. May specialize in the areas of design, incoming material, production control, product evaluation and reliability, inventory control and/or research and development as they apply to product or process quality. Must Have: Minimum Requirements Bachelors degree in Engineering, Science or technical field with 4+ years of experience in Quality, Engineering, Data Analytics/Data Science and/or Statistics OR Advanced degree in Engineering, Science or technical field with 2+ years of experience in Quality, Engineering, Data Analytics/Data Science and/or Statistics Nice to Have Experience in the implantable medical device industry. Degree in statistics, data science or engineering strongly preferred Working knowledge of medical device regulations (21 CFR 820, ISO 13485 & 14971). Experience with trending and analysis of complex data from multiple sources Strong proficiency with Excel & analytics software such as Spotfire, Tableau, etc. Working knowledge of tools such as FMEAs and Reliability Predictions Experience with query/report validation Proficiency with Microsoft Word and PowerPoint Demonstrated time management, continuous improvement, problem solving & critical thinking skills Well-developed written and oral communication skills About Medtronic Together, we can change healthcare worldwide. At Medtronic, we push the limits of what technology, therapies and services can do to help alleviate pain, restore health and extend life. We challenge ourselves and each other to make tomorrow better than yesterday. It is what makes this an exciting and rewarding place to be. We want to accelerate and advance our ability to create meaningful innovations - but we will only succeed with the right people on our team. Let’s work together to address universal healthcare needs and improve patients’ lives. Help us shape the future. Physical Job Requirements The physical demands described within the Responsibilities section of this job description are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. For Office Roles: While performing the duties of this job, the employee is regularly required to be independently mobile. The employee is also required to interact with a computer, and communicate with peers and co-workers. Contact your manager or local HR to understand the Work Conditions and Physical requirements that may be specific to each role. (ADA-United States of America) 10% travel within the US"
Data Quality Engineer - Remote,Pure Integration - Consulting,"Remote in Herndon, VA",https://www.indeed.com/rc/clk?jk=753ae5185a5854fd&fccid=dd616958bd9ddc12&vjs=3,"Company Description pureIntegration, a technology consulting firm with 17+ years of experience servicing fortune 100 clients, is seeking a Data Quality Engineer who will be responsible for designing, developing, documenting, reporting and performing data quality checks across all data assets. That includes ETL jobs, reports, dashboards and data pipelines. The primary goal for this role is to ensure high quality of data delivered to internal stakeholders and customers. Validation of data in data repositories against data from source systems and validation of metrics and data in reports/dashboards against data in the repositories and alerting bad data to stake holders is a key responsibility. Principle responsibilities are to making data assets consistently accurate for users. Location: Herndon, VA (Remote) Work Arrangement: 1099 Hourly, Contract Role for 2 - 3 months with high possibility of extension Work Authorization: EAD, GC & USCIT only (We Do Not Sponsor H1B Visas, or work on C2C) Responsibilities: Work in conjunction with Developers and Data Engineers to ensure high quality Data Deliverable Working with the development teams from different groups in the organization, help identify inconsistent data patterns, and how they are manifested from the source processes. Analyze source data and prepare glossary and metadata. Experience in defining Data Lineage and creating Data Catalogue. Experience in Data Profiling, Standardization, Parsing, Identity resolution, Record Linage and Merging, Data cleansing, Data enhancement, Data Inspection and Monitoring. Experience in building and validating Business Intelligence Reports. Experience with various data quality tools preferably Open Source. Design, implement and use data quality assurance frameworks to support the process of identifying inconsistent data patterns. Write DB scripts to validate data in the data repositories against the data in the source systems Perform root cause analysis of data quality issues and define mitigation plan to fix. Track, monitor and document testing results Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity Perform tasks spanning the full lifecycle of data management activities with minimal supervision Qualifications: Bachelor’s degree or master’s degree in a quantitative field such as Computer Science and Information Systems, Database Management, Big Data, Data Engineering, Data Science, Applied Math, etc. 5+ years of professional data analytics working experience. Experience with automotive data is a plus. Pandas python library, CSVKit, R Plyr, Reshape2, ggplot2, Trifacta data wrangler, Informatica, Trillium Software (nice to have) Experience with any of the BI tools like Holistics, Metabase, Power BI, Looker, Tableau, DashboardFox, etc. 5+ years of experience with database software (SQL, Google Bigquery, etc), in writing complex SQL queries and stored procedures and ETL in Java. 2+ years of experience working with large data and variety of data sources. Experience working in virtualized cloud environment including cloud-based IaaS/SaaS/PaaS solutions. Understanding of ETL methodologies and Data Warehousing principles, approaches, technologies, and architectures including the concepts, designs, and usage of data warehouses and data marts. Knowledge of data warehousing, OLAP, multi-dimensional, star and snowflake schemas Knowledge and experience with database design principles including referential integrity, normalization, and indexing to support application development. Strong understanding and experience in development activities for all aspects of Software Development Life Cycle (SDLC). Additional Information All your information will be kept confidential according to EEO guidelines. Are you self-motivated, collaborative, and client-focused? Are you looking for a challenging and rewarding career? Then pureIntegration would love to hear from you! Your career journey starts here! pureIntegration, a systems integration company headquartered in the Washington DC area, serves clients in the fastest growing industries – communications, media, and entertainment. Our industry-focused offerings and collaborative client approach has resulted in a 97% client satisfaction rating. As a leading service organization, we recognize our most valuable assets are our people, both as individuals and how they come together as a whole. As such, we encourage our team members to become fearless in exploring ideas and opportunities to act on them. In over 17 years of Digital Transformation consulting and professional services, pureIntegration has successfully designed, integrated, and deployed winning solutions at scale which have resulted in measurable performance increases. Most importantly, we have done it while maintaining 97% client satisfaction for the past 17 years. With a rich heritage in Communications, Media and Entertainment, our diverse and expanding portfolio includes Fortune 500 enterprises spanning Utilities, Manufacturing, Insurance, CPG, Healthcare, Logistics and other select verticals. pureIntegration is an Equal Opportunity Employer (EOE), qualified applicants are considered for employment without regard to age, race, color, religion, sex, national origin, sexual orientation, disability, or veteran status."
Principal Data Engineer,ASU Enterprise Partners,"Chandler, AZ+1 location",https://www.indeed.com/rc/clk?jk=c7b2ac474b547d8a&fccid=2d77b0a9670ae5b7&vjs=3,"The Principal Data Engineer is a member of the Data Engineering team within the Technology & Solutions (T&S) department at ASU Enterprise Partners (ASUEP). Data Engineering supports the integrity, augmentation, integration, security, and stewardship of all ASUEP data assets. This position works closely with other teams at ASUEP and ASU to support technologies and processes to ensure data is available in an accurate, complete, and timely manner to support business decisions, processes, and reporting. This position reports to the Data Engineering Director. What you will do as a Principal Data Engineer Develop Data solutions on AWS and/or AZURE Work with stakeholders to identify sources of data in the environment Create solutions to make data available to end-users Develop new and manage existing integrations between various data sources and the Data Warehouse or Data Lake Create processes to manage the capacity and performance of data solutions in the Cloud Manage security of the Data Warehouse and Data Lake Debug complex database processes and implement fixes in a timely manner Deploy code from a repository to Production systems Classify data stored in the Data Warehouse and Data Lake Manage multiple projects and assignments concurrently What you will need to be successful as a Principal Data Engineer Bachelor’s degree in Information Technology or related field and (5) five years of experience delivering information technology services which include three years with AZURE or AWS cloud technologies Experience with the development of integrated strategies and solutions addressing differing needs, understandings, and objectives Expertise in managing Data Warehouses and Data Lakes on a cloud platform such as AWS or AZURE Expertise in integrating data from various sources into Data Warehouses and Data Lakes Experience with database technologies in a hybrid cloud/on-premises model Competency with ETL tools such as SSIS and Alteryx Compelling interest in data, Data Warehouses, Data Lakes, and the movement of data Proficiency in Microsoft Windows and Office applications Knowledge of applicable regulatory requirements associated with PII, FERPA, and PCI-DSS Certification, or willingness to complete certification, for Azure Fundamentals or AWS Cloud Practitioner or equivalent How you will be rewarded as a Principal Data Engineer Competitive Base Salary Hybrid working Schedule (Monday and Friday work from home, Tuesday-Thursday in the office) Medical, Dental, Vision Benefits, and Flexible Spending Accounts Basic Life and AD&D insurance Disability Insurance Accident Insurance 401k plan with a 4% company match HRA Plan Tuition Reduction for Dependents. Will pay 75% of dependents higher education Tuition PTO, Sick time, Parent leave, and bereavement"
Data Engineer,BTS Software Solutions,"Augusta, GA 30905+1 location",https://www.indeed.com/company/BTS-Software-Solutions/jobs/Data-Engineer-960ca1c674f66f09?fccid=c946a8d6abe04208&vjs=3,"BTS Software Solutions is seeking a Mid-level* Data Engineer *to provide Data Science support to the Army Intelligence Enterprise Global Information Services in Ft Gordon, GA.*This position is contingent upon award*Required Clearance: TS/SCI - if required must be willing to take Counterintelligence PolygraphWhat You'll Get To Do: Serve as the lead data strategist. Implement methods to improve data reliability and quality, working to combine raw information from different sources to create consistent and machine-readable formats. Will be responsible for the development and testing of architectures that enable data extraction and transformation for predictive or prescriptive modeling. Collaborate with an outstanding technical team to propel innovation. Skills You'll Bring Manage lifecycle of architecture used to analyze and process data in accordance with SOPs, TTPs and other such templates. Assess the effectiveness and accuracy of new data sources and data gathering techniques. Develop and maintain databases. Design new tools to help collect, analyze, and validate data. Productively work within a team of data scientists, analysts, and computer scientists to optimize data flow and consistency across projects. Two years of experience handling databases and software development is preferred. Experience with Data pipeline/workflow management tools Basic competency of algorithms and data structures, distributed computing, Hadoop cluster management, HDFS, MapReduce, Experience with Stream-processing solutions such as Storm or Spark, big data querying tools, frameworks, messaging systems, and big data toolkits. Working knowledge of SQL, R, Python, Ruby, C++, Perl, Java, SAS, SPSS, and MATLAB. EducationM.S. in Data Science, Statistics, Applied Mathematics or similar field plus a minimum of 6 years of experience as part of a Data Science Team B.S in Data Science, Statistics, Applied Mathematics or similar field plus a minimum of 8 years of Sr level experience About BTS Software SolutionsBTS Software Solutions is a Service Disabled Veteran Owned Small Business who are community-focused innovators who transform ideas into technology to serve people. We recognize that innovation is only valuable when applied towards a needed solution. Technology has no value without the hard work to turn ideas into reality. Our roots are in helping save Soldiers’ lives through technology. We bring that ethos to serving our community. We create solutions that touch people's lives - products to communicate, to connect companies with customers, to stay informed, to save lives, and to enhance lives.We have a small company persona with a large company ethos and capabilities; we create elegant solutions for complex problems that will enrich people’s lives. BTS offers one of the best benefits packages in the industry: 100% Company PAID health benefits, PTO, 401K matching and vested from day one of employment, to name just a few of our benefits and perks. To learn more about BTS Software Solutions visit us at www.unleashbts.com/careers/.BTS Software Solutions is an Equal Opportunity Employer (EOE). All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Job Type: Full-time"
Data Engineer,Promega,"Remote in Madison, WI 53711",https://www.indeed.com/rc/clk?jk=bf2365fc32ae6bc0&fccid=c5699f7e653e0cf5&vjs=3,"Job Description: **Full-time remote work is allowed for this position. OUR TEAM: We are the Data Science and Integration team. We are made up of different specialists who play multiple roles: data scientists, data architects, data engineers, business analysts, and database administrators. We provide our expertise in all things data to Promega. We lend our expertise to Integrating data, moving data, and providing insights into data. Our diverse internal clientele includes all area of Promega’s business. We strive to answer the questions our partners haven’t even asked us yet. YOUR ROLE: From Madison, WI or anywhere remotely, the Data Engineer provides oversight and development around the implementation of a modern data platform solution. You will design, develop, modify and support data solutions in Azure and on-premises environments. You are also a key contributor in modeling, developing, enhancing, and supporting curated data models. JOB OBJECTIVE: The Data Engineer will have oversight and development around the implementation of a modern data platform solution. CORE DUTIES: 1. Design, develop, modify, and support data solutions in Azure and on-premises environments. 2. Design and develop scalable, efficient (internal and external) data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation. 3. Key contributor in modeling, developing, enhancing, and supporting curated data models. 4. Ensure standards are met so that solutions deployed have technical integrity and stability. 5. Design and develop automated Data Quality solutions that ensures the integrity of a modern data platform. 6. Document production software, runbooks, and solution architectures. 7. Develop, communicate, and present solution architectures to both technology and business stakeholders. 8. Support critical strategic initiatives and architect simple to complex data engineering projects. 9. Collaborate with IT peers to understand the Data Landscape across the organization. 10. Collaborate with Data Scientists, Data Analysts and Business Stakeholders to deliver curated data models. 11. Build cross-functional relationships with Business Stakeholders, Architects, Data Scientists, BI Managers, and Business Partners to understand data needs and help projects and agile teams deliver on those needs. 12. Deliver collaborative products that align with organizational strategies. 13. Mentor junior level engineers and cross team peers in all levels of data engineering. 14. Stay up on current technologies and industry trends. 15. Demonstrates inclusion through their own words and actions and is accountable for a safe workspace. Acts with kindness, curiosity and respect for others. 16. Embracing and being open to incorporating Promega’s 6 Emotional & Social Intelligence (ESI) core principles in daily work. 15. Understands and complies with ethical, legal, and regulatory requirements applicable to our business. OCCASIONAL DUTIES: 1. Work with other IT teams to write and maintain technical and end-user documentation and provide training. 2. Provide off-hours (24x7) support for Promega’s Data systems as required. 3. Perform other duties as assigned. KEY QUALIFICATIONS: 1. Bachelor’s degree in computer science, MIS, or data relevant science discipline. 2. 5+ years’ experience as a Data Engineer or equivalent role. 3. Working knowledge of modern Data Engineering tools like Databricks, Synapse, Spark, PySpark, Scala, Data Factory as well as open source tools like NiFi, Kafka, Airflow, etc. specifically on the Azure cloud platform. 4. Comfortable in building effective analytical tools that utilize the data pipeline to provide actionable insights into data synchronization and operational efficiency of the data repositories. 5. Experience in designing database models to store structured & unstructured data efficiently and in creating effective data tools for analytics experts. 6. Advanced knowledge in relational databases, like MSSQL, MySQL, Oracle etc., and no-SQL databases, Azure cosmos DB, MongoDB, Elastic Search etc. 7. Knowledge on enterprise data lakes, delta lake, data analytics, in-memory data handling, enterprise integration tools, etc. 8. Knowledge of and ability to implement CI/CD best practices especially as they relate to data engineering. 9. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. 10. Experience in defining and setting up data architecture to support data warehousing and business intelligence. 11. Working knowledge on enterprise data lakes, data analytics, reporting, in-memory data handling, enterprise integration tools, etc. 12. Having an owner's mindset and experience working in a fast-paced and demanding environment. 13. Ability to work in an Agile development environment. PREFERRED QUALIFICATIONS: 2. Microsoft Azure experience, especially in the data engineering space. 3. Proven ability in working in an agile team environment, anticipating, and meeting team needs, working with little direction, and gaining cooperation from others. 2. Experience and/or training in designing, developing, supporting, and maintaining business application software, including extensive end-user contact. 3. Ability to work in a fast-paced, high-pressure environment with frequent changes in priorities and assignments. PHYSICAL DEMANDS: 1. Ability to use a personal computer and manipulate software to accomplish required tasks as outlined above daily including keyboarding skills. 2. Ability to distinguish different colors and shades, tints, and tones of color which is essential for graphical design work. 3. Availability to occasionally work overtime hours to complete assignments during peak work-load periods. Diversity is important at Promega. We are proud to be an Equal Opportunity Employer, and make employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability, or any other protected class."
Data Engineer,ViaSat,"Remote in Tempe, AZ 85284+1 location",https://www.indeed.com/rc/clk?jk=06cd53d792f10219&fccid=8b219f1987ef65ea&vjs=3,"Job Description One team. Global challenges. Infinite opportunities. At Viasat, we’re on a mission to deliver connections with the capacity to change the world. For more than 35 years, Viasat has helped shape how consumers, businesses, governments and militaries around the globe communicate. We’re looking for people who think big, act fearlessly, and create an inclusive environment that drives positive impact to join our team. Job Responsibilities Collaborate with cross functional teams working on data to design, build and automate and scale our business processes. Build both batch and real-time update processes to keep the data assets in sync. Work together with the Data Platform team to leverage existing data assets and to drive the creation of additional data assets. Leverage cloud technologies to host, manage and monitor multiple database systems. Develop, deploy, and sustain scalable, secure ETL processes. Requirements 3+ years’ experience as a data engineer or experience working on data engineering projects/platforms. Experience architecting, configuring, and designing data structures, curating data, troubleshooting, monitoring, and coordinating defect resolution related to ETL processing. Strong programming experience with Python. Familiarity in code versioning tooling (SCM). Capable of tuning databases, SQL queries to meet or exceed performance objectives. Experience with RDBMS technologies (MS SQL, PostgreSQL, Oracle, etc.). Proven team player with the ability to manage multiple projects simultaneously in a fast-paced dynamic agile work environment. BS in Computer Science, Computer Engineering, Software Engineering, or related experience. Ability to travel up to 10%. US Citizenship Required. Preferences Experience with knowledge graphs/graph database technologies (Neo4j, ArrangoDB, etc.). Familiarity with at least one cloud provider such as AWS, GCP, or Azure. Experience in design and implementation of robust and highly scalable data services Working knowledge building data pipelines using Argo, Airflow or Spark Understanding of distributed and parallel computing architectures “If the Federal Executive Order for Government Contractors becomes effective, this role may require vaccination. In such instance, absent an approved accommodation based on a religious or medical reason, employees in this role will be required to be fully vaccinated no later than applicable deadlines, which are unknown at this point. Viasat will strive to give individuals as much notice as practicable if a vaccine mandate becomes applicable to this role.” Additional Requirements and Information Minimum Education BA/BS Years of Experience 3-5 years Travel Up to 10% Citizenship US Citizenship Required Clearance None Worker Classification Employee At Viasat, we consider many factors when it comes to compensation, including the scope of the position as well as your background and experience. For Colorado-based jobs only: The minimum for this position is $136,450 annually; however, base pay may vary depending on job-related knowledge, skills, and experience. Additional cash or stock incentives may be provided as part of the compensation package, in addition to a range of medical, financial, and/or other benefits, dependent on the position offered. Learn more about Viasat’s comprehensive benefit offerings that are focused on your holistic health and wellness. Base Salary Low Hourly (Arithmetic) 65.6 Base Salary Low Annual (Arithmetic) 136,450 Viasat is proud to be an equal opportunity employer, seeking to create a welcoming and diverse environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, ancestry, physical or mental disability, medical condition, marital status, genetics, age, or veteran status or any other applicable legally protected status or characteristic."
"Front-End Engineer, AWS Data Wrangler","Amazon Web Services, Inc.","Santa Clara, CA 94085",https://www.indeed.com/rc/clk?jk=7cbc589e56fa562a&fccid=5cc0cdc6dbb121cc&vjs=3,"· Bachelor’s Degree in Computer Science or related field. · Equivalent experience to a Bachelor's degree based on 3 years of work experience for every 1 year of education · Experience with modern programming languages and open-source technologies. · Experience with web/mobile technologies (e.g., JavaScript/TypeScript, NodeJS, React, WebPack, HTTP mechanics/performance). Amazon SageMaker Data Wrangler's mission is to reduce the time and complexity of preparing data for machine learning. Data Wrangler automates provisioning, data transformation, featurization, analysis, and visualization; and does it all at small or large scale. We are looking for driven front-end engineers who are excited about our mission to democratize machine learning and who take pride is tackling difficult problems. You will design and implement new features, architect new systems, coordinate with other teams, and drive engineering excellence. You will be responsible for improving the usability of ML scenarios to help make them accessible and easy to use. You will use modern, open and closed source tools to deliver the best possible experience and help our customers quickly solve their problems. SageMaker offers tremendous learning and growth opportunities with a diversity of challenges. Join our team and have an impact on the world by making ML more accessible than ever. About Us Inclusive Team Culture Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust. Work/Life Balance Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives. Mentorship & Career Growth Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded engineer and enable them to take on more complex tasks in the future. Experience with modern front-end libraries and components such as React, Webpack, TypeScript, etc. Experience with machine learning, deep learning, data mining, and/or statistical analysis tools is a plus. Amazon is committed to a diverse and inclusive workforce. Amazon is an equal opportunity employer and does not discriminate on the basis of race, ethnicity, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us"
Data Engineer,Brookhaven National Laboratory,"Upton, NY 11973",https://www.indeed.com/rc/clk?jk=98b1ffa363423521&fccid=e3775e5ec8ee0d6e&vjs=3,"Brookhaven National Laboratory (www.bnl.gov) delivers discovery science and transformative technology to power and secure the nation’s future. Brookhaven Lab is a multidisciplinary laboratory with seven Nobel Prize-winning discoveries, 37 R&D 100 Awards, and more than 70 years of pioneering research. The Lab is primarily supported by the U.S. Department of Energy’s (DOE) Office of Science. Brookhaven Science Associates (BSA) operates and manages the Laboratory for DOE. BSA is a partnership between Battelle and The Research Foundation for the State University of New York on behalf of Stony Brook University. Organizational Overview Brookhaven National Laboratory is entering an exciting new chapter with one of the newest and most advanced synchrotron facilities in the world. National Synchrotron Light Source II (NSLS-II) enables the study of material properties and functions with nanoscale resolution and exquisite sensitivity by providing world-leading capabilities for X-ray imaging and high-resolution energy analysis. This facility is open to users from academia and industry and its operations are at a time when the world enters a new era with a global economy fueled largely by scientific discoveries and technological innovations. NSLS-II provides the research tools needed to foster new discoveries and create breakthroughs in critical areas such as energy security, environment, and human health. Position Description NSLS-II is seeking an exceptional candidate to contribute to a multi-disciplinary project where they will build a Data repository working with BNL, participating universities and other partners to design, develop, and implement a data repository solution to facilitate data sharing and enhance coordination across the center. The candidate will work closely with the C2QA Center’s Cross-cutting co-design team, Thrust Leaders and NIST partners to coordinate project milestones and deliverables. You will be based at BNL and part of National Synchrotron Light Source II's Data Science and Systems Integration (DSSI) Program, which provide supports and expertise to meet the scientific computing needs of the NSLS-II Essential Duties and Responsibilities: Spearhead a focused effort to develop a user-friendly data management tool/database which will be used by center members to support data sharing, coordination and collaboration Collaborate with the Center’s scientists to identify and implement strategies for data handling, sharing, management and analysis Provide documentation, training and support for the database and software solutions developed. Collaborate with NIST partners to develop the public facing interface for the data repository Develop protocols and tools for data validation and publication Position Requirements Bachelor's or higher level degree in Computer Science, Physical Sciences, Applied Mathematics or related field and a minimum of one (1) years of relevant experience Demonstrated experience of data and code management best practices Ability to implement agile software engineering methodologies Experience in collaborative development of software and cloud infrastructure, especially in distributed teams. Demonstrated experience in multiple programming languages, including Python and script Excellent communication skills Preferred Knowledge, Skills and Abilities (experience in one or more of the following): Software design, development and deployment with version control Working with NoSQL and/or Relational databases Use of infrastructure systems (storage, networked accessible systems, collaborative tools) Containerized development and deployment (e.g. AWS, Docker) Design and use of standard APIs Developing training resources, including documentation, manuals, and tutorials of software tools for users. Providing user support (i.e. center members) Experience with Linux operating systems. Other information: Candidate will be placed at appropriate level contingent upon depth and breadth of experience. At Brookhaven National Laboratory we believe that a comprehensive employee benefits program is an important and meaningful part of the compensation employees receive. Our benefits program includes, but is not limited to: Medical, Dental, and Vision Care Plans Flexible Spending Accounts Paid Time-off and Leave Programs (vacation, holidays, sick leave, paid parental leave) 401(k) Plan Flexible Work Arrangements Tuition Assistance, Training and Professional Development Programs Employee Fitness/Wellness & Recreation: Gym/Basketball Courts, Weight Room, Fitness Classes, Indoor Pool, Tennis Courts, Sports Clubs/Activities (Basketball, Ping Pong, Softball, Tennis). Brookhaven National Laboratory and the Energy and Photon Sciences Directorate are committed to your success. We offer a supportive work environment and the resources necessary for you to succeed. Brookhaven Science Associates requires proof of a COVID-19 vaccination for all employees. Proof of full vaccination as recognized by the CDC and/or WHO, inclusive of the two-week waiting period, is required at the start of your employment. Brookhaven National Laboratory (BNL) is an equal opportunity employer that values inclusion and diversity at our Lab. We are committed to ensuring that all qualified applicants receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, status as a veteran, disability or any other federal, state or local protected class. BNL takes affirmative action in support of its policy and to advance in employment individuals who are minorities, women, protected veterans, and individuals with disabilities. We ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. VEVRAA Federal Contractor"
Software Development Engineer- Data Platform,"Sonos, Inc","Remote in Seattle, WA",https://www.indeed.com/rc/clk?jk=4d491c51dd993ca8&fccid=a3ad90904ce59650&vjs=3,"At Sonos we want to create the ultimate listening experience for our customers and know that it starts by listening to each other. As part of the Sonos team, you’ll collaborate with people of all styles, skill sets, and backgrounds to realize our vision while fostering a community where everyone feels included and empowered to do the best work of their lives. This role can be done from home Building the world’s leading sound experience starts with the experience we provide for our people. That’s why we’ve been distributed from the start: initially between offices in Boston & Santa Barbara, and now with additional offices in Seattle, San Francisco & Paris. This role can be done from anywhere in the United States- any of our offices, or remotely from home. It’s about impact, not location. We have an unquenchable thirst for data at Sonos. Data helps us build a better business, a better product and ultimately helps us make happier customers. As a Software Engineer on the Data Platform Engineering team, you will be responsible to help achieve this goal by designing and implementing infrastructure, frameworks and tools used by Analytics Engineers, Data Scientists and Data Analysts to deliver data as a product to the business. You will help deliver a cutting edge next generation platform built on AWS and Snowflake. What You’ll Do Design and develop frameworks, tools and processes for reliably ingesting and processing vast amounts of data into our data platform Optimize data ingestion, storage and processing architecture to meet product, business and performance needs Work closely with Senior Engineers across a broad spectrum of projects Manage individual priorities and deliverables to meet requirements What You’ll Need Basic Qualifications Bachelor's Degree in Computer Science/Engineering or equivalent practical experience 2+ years of experience working in the software industry, ideally on data engineering focused teams Proficiency in at least one or more programming languages, preferably Python and/or Java/Scala Exposure to or hands-on experience working with one or more of the following: Apache Airflow, Rest APIs, and/or databases. Experience with AWS or other cloud technologies. Experience practicing Agile software development methodologies and best practices Preferred Qualifications Experience with containerization is a plus Experience with Snowflake or DBT #LI-Remote Your profile will be reviewed and you'll hear from us once we have an update. At Sonos we take the time to hire right and appreciate your patience. Notice to U.S. Job Applicants: Sonos is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics. Follow the links to review the EEO is the Law poster and its supplement . The pay transparency policy is available here . Sonos is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to accommodations@sonos.com and let us know the nature of your request and your contact information."
Data Engineer,USI Holdings Corporation,Remote,https://www.indeed.com/rc/clk?jk=6bce3d5aedeca3f3&fccid=1799f789a0c53bdc&vjs=3,"General Description: Responsible for expanding, optimizing, and monitoring data collection, data flows and datasets. Partner with data scientists and analysts on transforming, consolidating, integrating, and cleaning data. Support our next generation of products and data initiatives. Responsibilities: Build and maintain data pipelines and datasets for data science and analytics projects. Drive initiatives to analyze and acquire free and paid data from third parties. Collaborate with data science and data services teams to develop best practices. Includes data ingestion, dataset creation, storage and updates, naming conventions and retention. Work with stakeholders on data-related technical issues and data infrastructure needs. Implement methods to improve data reliability and quality. Partner with data and analytics experts to improve functionality in data systems. Assemble large and complex data sets that meet functional/non-functional business requirements. Identify, design, and implement internal process improvements. Includes automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability. Support data governance activities. Monitor and report on data lineage and data quality. Strong technical writing skills. Ability to work in a team environment. Knowledge, Skills and Abilities: Bachelor’s degree or equivalent experience in Computer Science, Statistics, or related field. 2 years + Python programming experience. Jupyter notebook experience a plus. 2 years + SQL programming, SQL database design, and data architecture concepts. 1 year + experience working with scrum agile processes. Azure Devops preferred. Technical expertise with data models, data mining, and data warehousing. Experience with Microsoft Azure components. Includes DevOps, ADLS, Databricks, ADLS, CosmosDB, ML Services or equivalent cloud resources. Broad working knowledge of insurance brokerage or sales workflows and systems preferred. Self-motivated. Comfortable managing needs of multiple teams, systems, and products. Physical Demands: Work is performed in a climate-controlled office environment with minimal noise and limited to no exposure to chemicals or toxins. Employees operate office equipment including telephone - headset, Computer, computer monitors, keyboard, mouse, copier, scanner, and mail machine. Physical tasks of job include walking, sitting, standing, and bending. Analysis of Physical Demands: Constantly (over 66% of time) work performed requires employees to use repetitive hand motions such as typing, using a keyboard, and sitting at a desk. Frequently (34%-66% of time) work performed requires employees to handle and grasp things, walk on normal surfaces, stand, bend and travel to various USI offices. Occasionally (1%-33% of time) work performed requires employees walk on uneven or slippery surfaces to and from work and occasionally reach outward to grab things and bend. Rarely (< than 1 hour per week) work performed requires lifting/carrying items that range from 10-50lbs, pushing/pulling items that range from 10-50lbs, twisting/ turning including reaching over shoulder or above head, kneeling or squatting. USI is committed to providing a full-suite of competitive benefits for our growing population and its diverse needs. We offer a wide range of health, welfare and financial benefits including medical, wellness, dental and vision, 401(k), flexible spending and health savings accounts, short and long-term disability, life insurance and other unique employer-sponsored and voluntary programs. USI also offers a generous paid time off policy, paid family leave benefit as well as paid holiday time. Job ID: 24360"
Data Engineer (Engineering),Morgan Stanley,"Alpharetta, GA 30009+5 locations",https://www.indeed.com/rc/clk?jk=a9558e468702f636&fccid=0c39fb2c91742dcf&vjs=3,"Data Engineer (Engineering) Job Number: 3178957 POSTING DATE: May 17, 2022 PRIMARY LOCATION: Americas-United States of America-Georgia-Alpharetta EDUCATION LEVEL: Bachelor's Degree JOB: Engineering EMPLOYMENT TYPE: Full Time JOB LEVEL: Vice President DESCRIPTION As a Data Engineer, you will work on high-quality data solutions, partnering with various engineering and business teams within the enterprise to design and develop data driven insights that inform business and product decisions. Additionally, you will be responsible for identifying, researching, and resolving complex technical problems that enhance the combined business decision making capabilities. Your technical skills, business acumen, and creativity will be essential as you build tools to automate reporting and generate timely business insights. Responsibilities: Define best practices, develop frameworks and architectural solutions for data movement and analytics at scale. Train and mentor members within the data engineering team on technology platforms and tools used to develop data solutions. Prepare documentation - runbooks, training documents and user guides - for frameworks and ETL jobs. Partner with engineering teams to operationalize/scale the deployment of solutions to achieve optimum performance and efficiency. Partner with business teams across the enterprise to help understand their data and analytic needs, identify the best data sources and design robust and maintainable solutions. QUALIFICATIONS Required Skills: BA/BS degree in a technical or quantitative/business-oriented field or equivalent practical experience. 5+ years of relevant experience.\Excellent communication, documentation, and planning skills. Expert-level analytical skills - specifically using SQL. Independent-working, fast-learning and problem-solving. Experience working with any big data platform developing ETL and analytic solutions using the tools provided. Leverage SQL, and other analytic platforms to gather, clean, and prepare data; create dashboards/reports; develop KPIs; analyze trends; provide insights. Preferred Skills: Experience working on Hadoop with hands-on knowledge of services within the ecosystem. Experience with data integration and ETL tools and platforms like IBM DataStage, Streamsets. Experience working with atleast one interpreted programming language such as Perl or Python. Exposure to business intelligence tools and creation of reports & analytics. Understanding of cloud-based technologies. Understanding of distributed data processing frameworks like Spark. Familiar with automation, workflow and data flow concepts. Experience working in the Financial industry. #etrade"
Senior Data Engineer,Avantor,Texas,https://www.indeed.com/rc/clk?jk=cf4d0ffde97da122&fccid=9647d3871391af12&vjs=3,"Job Summary The Senior Data Engineer will develop, optimize and oversee multiple data platforms and address scaling of capabilities including the management, movement, storage, access and security of data in modern ways. Apply advanced statistical data modeling techniques to large data sets to create actionable business insights- Use statistical analysis software packages and business intelligence and analytics platforms to create dashboards and reporting capabilities- Design, develop and deploy data integration flows through modern tools. Manage major/complex large projects and coaches, review and delegate work to entry/intermediate profession. MAJOR JOB DUTIES AND RESPONSIBILITIES (List in order of importance) Design, develop, deploy and maintain high performance data flows between source and target systems using modern ETL tools. Design scalable patterns and architecture to support both batch and real-time data products & platforms using big data technologies. Show expertise for data at all levels: low-latency, relational, and unstructured data stores; analytical and data lakes; data streaming, data in-transit. Contribute to the direction, road map and standards for functional, process and technical Data solutions. Analyzing and translating business requirements into functional and technical requirements and design. Designing, implementing and analyzing high performing queries on our EDW. Help with intake prioritization. QUALIFICATIONS (Education/Training, Experience and Certifications) BA/BS in a related field or equivalent experience. Minimum of five years of related work experience. Five or more years hands on experience with an ETL tool is required (SAP BODS) Five or more years of experience delivering Enterprise Data Solutions including Data Lakes, Data Warehouses and Data Pipelines. Experience with modern data movement, storage, management and security technology and tooling. Experience with at least one MPP database technology such as Snowflake. Experience in designing modern AI/ML mechanisms with AWS technology. Sound understanding of Data Streaming models with AWS technology. Experience with modern engineering practices and how to use and apply them to Data Architectures and solutions. Experience with data modeling, data warehousing, and building high volume ETL/ELT pipelines. Experience with integration of multi cloud services with on-premise technologies. Experience in cloud data engineering on AWS is a plus. Understanding of metadata management, data lineage, and data glossaries is a plus. Understanding of agile development, including DataOps is a plus. Familiarity with business intelligence tools (PowerBI, Tableau) Exceptional collaboration skills. KNOWLEDGE SKILLS AND ABILITIES (Those necessary to perform the job competently) Understanding business requirements and data-processes. Experienced in covering requirement analysis, configuration, design and development, testing and monitoring the launch. Ability to work effectively in a multi-disciplinary team. Ensure stability of data management and transfers through systems, for maintaining the integrity of the data residing on systems, facilitating and performing validations, and error resolution and decision making to complete or support business processing requirements. Effective written, oral communications and interpersonal skills. Ability to work effectively in a multi-tasking stressful environment, working independently and prioritizing work. Must have strong teamwork skills and the ability to develop working relationships. Must be able to communicate with different levels of management as well as to employees in the business. Must be highly motivated, have a great work ethic and enjoy working as part of a team. DISCLAIMER: The above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of employees assigned to this position. Avantor is proud to be an equal opportunity employer. EEO Statement: We are an Equal Employment/Affirmative Action employer. We do not discriminate in hiring on the basis of sex, gender identity, sexual orientation, race, color, religious creed, national origin, physical or mental disability, protected Veteran status, or any other characteristic protected by federal, state/province, or local law. If you need a reasonable accommodation for any part of the employment process, please contact us by email at recruiting@avantorsciences.com and let us know the nature of your request and your contact information. Requests for accommodation will be considered on a case-by-case basis. Please note that only inquiries concerning a request for reasonable accommodation will be responded to from this email address. 3rd Party Non-Solicitation Policy: By submitting candidates without having been formally assigned on and contracted for a specific job requisition by Avantor, or by failing to comply with the Avantor recruitment process, you forfeit any fee on the submitted candidates, regardless of your usual terms and conditions. Avantor works with a preferred supplier list and will take the initiative to engage with recruitment agencies based on its needs and will not be accepting any form of solicitation. Colorado and New York Equal Pay Transparency: Avantor is committed to equitable compensation practices. The compensation range for this role is: $93,000.00 - $158,000.00 Final compensation for this role will be determined by various factors such as minimum and preferred qualifications, knowledge, skills, abilities, education, experience and location."
Sr. Data Engineer,WP Engine,"Austin, TX",https://www.indeed.com/rc/clk?jk=35d6903cdbe8db8d&fccid=966a8dd715d10eb7&vjs=3,"It's fun to work in a company where people truly BELIEVE in what they're doing! We're committed to bringing passion and customer focus to the business. Since launching in 2010, WP Engine has become the world’s leading WordPress Digital Experience Platform (DXP), now with over 100,000 customers in 140 countries. We’re proud of the technology and service we offer our customers that move their businesses forward faster. At WP Engine, we strive to do the best work of our careers, and feel empowered to do what is right for our customers. We love investing in employee success and uncovering opportunities for you, the best, to get better. 99 percent of employees believe you’re made to feel welcome at WP Engine. Be you. Be here. What's cool about this job? WP Engine is on a mission to help our customers win online! Whether that’s helping an aspiring entrepreneur to turn a hobby into an online business or a multinational corporation to launch a new campaign in weeks instead of months, our platform is there to help them win — whatever that means for them. To help us make the right decisions and continue to offer this experience to our customers we are committed to maintaining high quality, insightful data assets. We are searching for a data engineer to help us by leveraging the latest tools/technologies such as Python/SQL, Docker, and Google BigQuery to build robust and maintainable data pipelines. In this role you will also contribute ideas to our data strategy with an emphasis on advocating for processes and tools that lead to higher data quality and adopting best practices. Our culture is renowned; we believe it is meaningful to hire the best and ensure that we provide an environment where the best get better. If you are great at solving problems, a hard worker with excellent interpersonal skills, and enjoy working across different time zones and cultures, you may be the person that we are looking for! The day to day. Build run and maintain data pipelines utilizing GCP including BigQuery, Storage, and various APIs and SDKs with Python Identify and resolve performance and data quality issues Basic understanding of the infrastructure required for optimal extraction, loading and transformation (ELT) of data from a wide variety of databases, platforms, and APIs Understand data access policies and procedures Actively contributing towards iterative innovation to improve the overall effectiveness of the data engineering group Maintain high standards of quality through best practices and leveraging alerting and monitoring tools Work with business partners to understand requirements and develop robust solutions to address them Your skills and expertise. 3+ years professional experience in a similar role Demonstration of handling both unstructured and structured data Demonstrated proficiency with Python, SQL, Git, Docker Experience with cloud computing (Google Cloud or AWS preferred) Experience building and optimizing ETL/ELT workflows Ability to communicate effectively with team members to define requirements A shown ability to understand and organize data from various sources The perks and benefits Company Stock Options (Every employee is an owner in the company) Great Health Benefits (Medical, Dental, Vision, Life Insurance) Fertility Benefits (IVF/Fertility drug coverage) HSA Company contribution $500 for employee / $1000 for family 401(k) with a 4% match Disability Insurance Paid Family and Caregiver’s Leave Employee Assistance Program Generous Vacation Time (Who doesn’t like time off) One-time $500 payment to set up your home office 4 Company Wellness Days a year 1 floating holiday $100 monthly wellness allowance to spend on what you want Access to free on-demand fitness classes Free subscription to Calm Pet Insurance On-going education through LinkedIn Learning, Workday Learning and our Career Growth Portal At WP Engine, we strive to have the broadest possible view of diversity, going beyond visible differences to include the background, experiences, skills, and perspectives that make each person unique. WP Engine is proud to be an equal opportunity workplace and is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or any other basis protected by law."
Data Integration Engineer,The Orvis Company,+1 locationRemote,https://www.indeed.com/rc/clk?jk=93cee5992ba16886&fccid=8f6d03f4be47dc58&vjs=3,"As a Data Engineer on our Orvis Technology team, you will support data delivery for new and existing applications. The role is a part of a team responsible for both maintaining and building data integrations for critical Orvis systems. You will work with an impactful and highly motivated team of product owners, engineers, program managers, and architects. You will be responsible for combining technical expertise with best practices and standards to align solutions with business strategy. You will present and communicate to all levels of the organization, participate in development, and ensure the overall solution is appropriate. We are looking for talented people who align with Orvis’ Mission and demonstrate our Core Values in your interactions with customers and team members. Responsibilities Technical knowledge of Enterprise Application Integration, Micro Services architecture, API Architecture including familiarity with Integration Patterns (Messaging, Routing, Data Transformation etc.) Daily hands-on responsibilities to code, test and stage applications and application interfaces consistent with established practices and standards. Responsible for security, performance, manageability, quality, scalability, and consistency of integration architecture across systems Analyze, design, and implement integrations for on-premises and cloud solutions Be a team player and a thought partner to steer the collective technology team to success Able to work with Program Managers, provide information for leadership updates and successfully collaborate to deliver finished products Conduct unit, system and user acceptance testing to ensure quality implementations. Qualifications 2+ years' experience with design and maintenance of enterprise data solutions including expertise in developing complex SQL, stored procedures, functions and data transformations 2+ years of Database Management and Administration experience 2+ years of experience with Microsoft SQL Server Integration Services Strong experience architecting, implementing, and supporting enterprise-grade SOAP and REST web services with a variety of data formats (e.g. JSON, XML, CSV) Experience with one or more cloud/SaaS solutions for ERP, CRM, e-Commerce, or mobile a plus (e.g., Salesforce, NetSuite/Oracle, Manhattan Associates) Demonstrate knowledge of on-premises/cloud-based infrastructures, SDLC pipelines, and deployments/configurations and definition/evangelism of best practices/standards Strong knowledge of SAFe and solid track record working in an Agile setting Demonstrate a working knowledge of one or more platforms (XML, Java, C#, VB, SQL, .Net). The ability to code, test and stage functional products in these environments is a plus. Sense of humor and desire to have fun while building amazing things About Orvis We are a family-owned, international multichannel retailer, and we are proud of our culture, in which associates deliver world-class customer service, and exceptional products & learning opportunities. We are passionate, curious, and approachable. Our team members enjoy teaching, mentoring, and solving problems. We love to develop and share our equipment, apparel, and expertise to create deeper connections and authentic experiences. We are the most-trusted lifestyle brand rooted in the innovation of fly-fishing and wing shooting. Everything we make, offer, or share flows from generations of curiosity on the water, in the field, and around the fire. The natural world is at the core of our passions and our business. We know the power that outdoor experiences provide and live for the anticipation it brings. And we must preserve these places for future generations. This is why we commit 5% of pre-tax profits to protecting what we love. We know our people are our most valuable asset. We empower our team members to take care of the customer and exceed expectations. To be at their best, we also recognize that our team members need time to recharge and connect with nature. We believe in ensuring our teams have great work/life balance and offer a comprehensive benefits package including: Medical, vison, and dental coverage Employer-matched 401(k) savings plan Paid time off and holiday pay Parental leave Generous associate discount, including discount opportunities with other brands"
Data Engineer,DemandJump,"Indianapolis, IN 46204 (Downtown area)",https://www.indeed.com/rc/clk?jk=917e97a2f73d0617&fccid=7a73785bca2bb8ba&vjs=3,"Indianapolis or Full Remote What Does DemandJump Solve? DemandJump is a marketing strategy platform showing users the exact content to create to increase 1st-page rankings and drive outcomes. DemandJump Culture Located in the heart of downtown Indianapolis, DemandJump is a fast-growing, innovative marketing technology company with a corporate culture that values individuality and diversity. We work hard and play hard and we do both with passion and respect for one another. Our open-concept office promotes a fast-paced, fun, friendly, and highly collaborative work environment, while our management goes out of their way to be transparent and approachable. Weekly team lunches, DemandFUN events, and group volunteer opportunities – these are just a handful of the reasons why DemandJump is consistently nominated and awarded one of the Best Places to Work in Indiana. What We Stand For Be Bold Be Transparent Be Purposeful Core Tenets Think Customer First Serve Each other Compete To Win See Things Differently Do the Right Thing. Always Job Description We are looking for a Data Engineer to help us build the most useful content marketing insights and attribution software on the market. Your primary focus will be building and delivering multi-tiered, enterprise-level software infrastructure for DemandJump while maintaining security and privacy compliance. What is a typical day at DemandJump like for a Data Engineer, a.k.a. Responsibilities? Mastering the DemandJump Platform to understand capabilities our customers have never seen before Utilize the Amazon AWS cloud platform Work with the engineering team to build scalable, high availability solutions Build and present Technology Design Documents to Engineering leadership for approval Designing procedures for system troubleshooting and maintenance Be proactive in communicating cross-functionally with the whole company, especially with our Product and Engineering team Write complex SQL statements and work with data transformation tools to transform data as it loads into our data warehouses Establish and maintain data models for 3rd party integrations and related dashboard visualizations Update and review code that supports our dashboard visualization configurations Document data flow and create related data flow diagrams Maintain Python codebase that controls part of our data ETL process Assist engineering team with data model and related ERD diagrams for building RESTful API What are the minimum requirements we are looking for from a Data Engineer? Experience with a wide variety of open source data technologies and tools like dbt Experience tuning SQL-related queries to maximize performance Experience reading and creating data flow architecture diagrams Strong grasp of automating a data flow to facilitate close to real-time data Experience with tools like Looker helping visualize structured data from a data warehouse Experience transforming data stored in a data lake into structured, ready to consume data Experience with a data cloud like Snowflake Experience extracting data from a datasource like Fivetran Experience fine-tuning data warehouse to serve data to a related data consumer Experience with RDBMS and related structured query languages, including tuning and operational issues Experience with workflow and monitoring tools (Prefect, DataDog, CloudWatch, New Relic, Nagios, etc) Experience with data security best practices Proficient with one or more scripting languages Experience with Git Legally eligible to work in the U.S. Experience supporting data models for RESTful APIs Experience adding monitoring, logging and documentation to data services What are the “nice to have” skills we are looking for from a Data Engineer? Experience with Terraform Experience with AWS Cloud platform Experience working with Java, Scala, Ruby on Rails or ElasticSearch Experience with the full software development cycle Experience working with sprints and completing work using a ticket management system Tuning and maintaining Neo4j What does DemandJump look for when hiring a Data Engineer? We look for people who are willing and hungry to learn our tech stack and all about DemandJump and ultimately understand WHY a prospect/customer would want to work with us. Are you able to contribute new features given a certain set of product requirements? Do you want to collaborate with your peers and also utilize current best practices and technology to improve your career as a data engineer?"
Data Conversion Engineer,Planet DDS,Remote,https://www.indeed.com/rc/clk?jk=08d3116cfb3ec478&fccid=ee7d98e98782cb1d&vjs=3,Location: RemoteDepartment: Conversions
Senior Software Engineer - Data Mobility,Nasuni,"Remote in Boston, MA 02210+1 location",https://www.indeed.com/rc/clk?jk=78673734310199b4&fccid=cf7074811ce1bd34&vjs=3,"Senior Software Engineer – Data Mobility The Position Nasuni is growing and looking for talented engineers to build-out its Data Mobility feature set. We're looking for multi-disciplined software engineers that have experience in cloud services and data replication/migration. This engineer will be involved in product design, but mostly responsible for development and performance scaling. Job responsibilities will include improving on current Nasuni products, integration of 3rd party products into the Nasuni ecosystem, and finally working on new Nasuni product offerings. This job role offers great opportunities for career growth. Qualifications + minimum experience BS in Computer Science or Engineering 3+ years of experience Experience in C (or C++) with at least 3years of experience Proficiency and experience in inter-process communication, threading models, synchronization concepts, and complex multithreaded software design Experience in Python with at least 3 years of experience Desired experience Experience with Lua and/or Go Cloud – S3 and object storage Ability to diagnose problems using logs, monitoring, and alerting Why Nasuni? With the world’s only cloud-native global file system at its heart, Nasuni delivers a file services platform built for the cloud that combines the performance of local file servers with the scalability and durability of cloud storage, all at about half the cost of traditional file infrastructures. Users can migrate NAS silos to the cloud storage of their choice for on-demand capacity expansion, built-in backup, instant disaster recovery, multi-site file sharing and a system that can span continents. Nasuni operates globally from its worldwide headquarters in Boston, Mass., USA. We will consider remote employees as well as candidates based in our Boston, Marlborough, MA or Cary, NC offices. #LI-Remote Why work at Nasuni? As part of our commitment to your well-being, we are pleased to offer comprehensive benefits packages to employees across the world. Benefits packages vary by geography, but generally include: Take-What-You-Need paid time off and potential flexible work hours Incentive stock options Comprehensive health, dental and vision plans Life and disability insurance Retirement Plan Generous employee referral bonuses To all recruitment agencies: Nasuni does not accept agency resumes. Please do not forward resumes to our job boards, Nasuni employees or any other company location. Nasuni is not responsible for any fees related to unsolicited resumes. Nasuni is an equal opportunity employer. The equal employment opportunity policy at Nasuni protects employees and job applicants from discrimination on the bases of race, religion, color, sex (including pregnancy, gender identity, and sexual orientation), parental status, national origin, age, disability, family medical history or genetic information, political affiliation, military service, or other non-merit based factors. These protections extend to all management practices and decisions, including recruitment and hiring practices, appraisal systems, promotions, and training and career development programs."
Data Implementation Engineer (Fully Remote),Meduit,"Remote in Charlotte, NC 28217",https://www.indeed.com/rc/clk?jk=6f9cac22092d3adf&fccid=e7434ab23b6ba6bc&vjs=3,"Education/Experience/Ability A four-year university or college degree or relevant experience is required. BC or BS in Computer Science, Statistics, or similar technical background. Minimum 1 year of implementing data into a financial business system. Healthcare related data experience is a plus. Need to have professional knowledge of developing ETL processes between source files to relational database targets Talend experience is not a requirement, but definitely a plus. Data analysis experience within SQL relational database platform MySQL MSSQL Oracle DB2 Snowflake experience is not a requirement, but definitely a plus Possess advanced SQL programming skills Ability to write complex, efficient queries against large, disparate data sources Working knowledge of Java programming is a plus. AWS experience is a plus. Ability to prioritize workload appropriately. Ability to work successfully in a matrix environment, working with staff in various business areas to accomplish required tasks and come to consensus. This includes: Being a self-starter Being able to self-teach Perform significant amounts of research and testing involved in implementing complex data formats Strong written and verbal communication skills Essential Job Functions Possess ability to understand business problems, assess relevant variables that impact the issue, recognize relevant patterns in data, and provide solutions and information related to the business requirements. Participate on client calls to present Meduit business system data specification requirements and iterate through client data files from development to testing to production. This position assists the Business Intelligence Team by participating in the development and maintenance surrounding of the Meduit Enterprise Data Warehouse on Snowflake. This person works with members of the Meduit Workflow team to design and implement both the data presentation layer available to the user community, as well as designs and maintains the underlying technical architecture of the data warehousing environment. Documentation of data implementation tasks for new and existing clients are essential to this position. Ability to cross-train fellow Team members and members of adjacent Teams is essential. Additional Job Functions Perform other job duties assigned by a competent authority Physical Demands/Working Conditions This position requires prolonged periods of sitting, some bending, stooping and stretching. Requires coordination and manual dexterity sufficient to operate a keyboard, mouse and other office equipment. Work in this position will be performed in a remote office environment. This position may require some travel. Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)"
Data Engineer 3,Kagr Llc,"Foxborough, MA 02035",https://www.indeed.com/rc/clk?jk=b1fb4ade4b97f392&fccid=ea149e1e335c2860&vjs=3,"SUMMARY: The Data Engineer 3 will drive the planning, design, and development of integration processes to build and improve the data warehouse. The Data Engineer will be responsible for building data integrations, data pipelines and other processes the data warehouse and KAGR product. This role will partner with Data Scientists, Analysts, other engineers and business stakeholders to solve complex and exciting challenges so that we can build our product to enable our clients to use data to drive their business. DUTIES AND RESPONSIBILITIES Building data integrations and data pipelines within the KAGR tech stack Translate business requirements into data pipelines Extract and load many disparate systems into a centralized data warehouse Assist in gathering requirements for new pipelines Implement data auditing strategies and processes to ensure data integrity Document complex integration pipelines into easy-to-understand technical specifications Perform data modeling to document existing and new tables in the data warehouse Monitor and successfully troubleshoot data problems Handle multiple projects effectively and meet deadlines Special projects and assignments as business dictates Responsible for the maintenance, creation and control of all personally identifiable information or any other information protected by any Confidentiality or Privacy Standards or Company policies that you have access or knowledge of, including but not limited to any state or federal regulations including HIPAA SUPERVISORY RESPONSIBILITIES This position has no supervisory responsibilities. SKILLS AND QUALIFICATIONS Bachelor's Degree in Computer Science, Information Systems, or related field 4-7 years of experience working with data using SQL or similar technology 3+ years of experience using cloud data warehouses such as Snowflake, Amazon Redshift, Google BigQuery, Azure Synapse Experience with languages like Python, Ruby, Java, or similar language 3+ years of experience using a data integration platform, such as Talend, Snaplogic, or Informatica Experience working in a cloud native environment Strong understanding of data warehousing principles and methodologies Ability to manage multiple projects in a fast-paced environment Strong communication skills to all levels of technical expertise Very high attention to detail Familiarity with BI Visualization tools PHYSICAL DEMANDS Sitting for extended periods of time Dexterity of hands and fingers to operate a computer keyboard, mouse, and other computing equipment The employee frequently is required to talk or hear The employee is occasionally required to reach with hands and arms Specific vision abilities required by this job include close vision, distance vision, color vision, peripheral vision, depth perception, and ability to adjust focus Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. WORK ENVIRONMENT The noise level in the work environment is usually moderate Fast paced office environment Ability to work nights and weekends as business dictates CERTIFICATES, LICENSES, REGISTRATIONS None required OTHER DUTIES Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice. This company is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics."
Big Data Engineer,TK Elevator Corporation,"Atlanta, GA 30339",https://www.indeed.com/rc/clk?jk=92e74a0548337b35&fccid=a20f221c5962130f&vjs=3,"Group presentation With customers in over 100 countries served by more than 50,000 employees, TK Elevator achieved sales of around €8 billion in the fiscal year 2018/2019. Over 1,000 locations around the world provide an extensive network that guarantees closeness to customers. After building its position as one of the world’s leading elevator companies in a mere 40 years’ time, TK Elevator became an independent company in August 2020. The company’s most important business line is its service business, with approximately 1.4 million units under maintenance and over 24,000 service technicians globally. The product portfolio covers commodity elevators for residential and commercial buildings to cutting-edge, highly customized solutions for state-of-the-art skyscrapers – such as One World Trade Center in New York. In addition, it also consists of escalators and moving walks, passenger boarding bridges, stair and platform lifts, as well as tailored service solutions such as MAX, the industry’s first cloud-based digitally enhanced maintenance solution – thus covering a broad spectrum of urban mobility. Who we are What we expect The first 3 letters in workplace safety are Y-O-U! TK Elevator is currently seeking an experienced Big Data Engineer in Atlanta, GA. TK Elevator is seeking a Sr. Data Engineer to be responsible for data engineering activities related to business’ information systems, data integration and data warehousing solutions. The candidate must demonstrate strong computer skills and a deep passion for analytics, possess an ability to perform complex data analysis and development with large data volumes, and have expert level knowledge in SQL, data warehousing and ETL. The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data solutions that facilitate deeper analysis for reporting and analytics to TKE’s corporate and field organizations in North America. Essential duties and responsibilities: Develop and maintain data pipelines using Azure Data Factory and Spark Jobs Create data models following industry standards for Data Warehousing and Big Data Build and maintain delta lake in Azure Databricks and Azure DataLake Gen2 (ADLS) Participate in data solution lifecycle from early stages of gathering requirements to solution deployment Support and cross train other business units such as data scientists and data analysts Who we are looking for Required Qualifications: Bachelor’s degree (B.A. / B.S.) in Information Technology or Computer Science or related field or the equivalent combination of education and experience 5+ years of data engineering, ETL, and data warehousing experience Cloud Experience (preferably Microsoft Azure) Azure Data Factory or similar data orchestration tools. Source Code Management using Git in Github, Azure DevOps or similar Microsoft Power BI SQL and Python Spark or Pyspark SQL Server, Azure SQL, Databricks, Azure DataLake Gen2(ADLS) Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions Nice to Have Qualifications: Familiarity with data science concepts Experience with Streaming data from IOT devices Machine or Deep Learning knowledge Experience with Profisee Master Data Management technology Contact To apply to a position, please click on the Apply Now button. For any additional questions or job specific requests, please use the contact below and include the Job Requisition Number as a reference. Elevatorjobs.AMS@tkelevator.com What we offer"
Data & Software Engineer - Delivery (19_2022),Affinity Solutions,"Remote in San Jose, CA 95113",https://www.indeed.com/rc/clk?jk=a1b1447aa54b76ff&fccid=44009c0a01dfb8f3&vjs=3,"Location: San Jose, CA (preferred); New York City, NY; or Remote Department: Engineering Hours/Shift: Full Time Reports To: SVP, Software Engineering and Enablement Affinity Solutions is the trusted partner for marketers and agencies developing and applying actionable insights to deliver personalized customer experience that increase spend and drive hypergrowth. Affinity is powered by Panorama, which is an always-on, privacy-safe platform, within a safe-haven environment. Panorama deterministically matches actual purchase data, and complementary data sets, for audience scoring and validation that drives precision marketing. We help companies go from campaigns, to moments that move at the speed of the consumer. We are looking for a self-motivated Data & Software Engineer who will bring their expertise with consumer purchase-level data and data analytics to leverage data analytics solutions embodying purchase-level data into different market segments (financial services, advertising agencies and marketing service providers, retailers and publishers, etc.), delivering maximum impact to both existing and potential customers. Responsibilities Work with product management and engineering teams to improve the features of existing products and develop new solutions for customer deliverables. Work with sales and account management teams to understand the customer requirements, develop use cases, and map them to Affinity products. Work with engineering team to expand product use and configure products for customer deliverables. Partner with sales and account management teams to explain and demonstrate data analytic solutions to existing and potential customers. Qualifications: BS in Computer Science, Information Management Systems, or related field 3+ years of experience in data integration/data engineering 3+ years of experience with SQL, noSQL, and analytics data marts on MPP databases (e.g., RedShift) 1+ years of experience with cloud platforms (e.g, AWS); Apache Spark, Hadoop, and python; scripting languages (e.g., AWK); Tableau; REST API; and EMR Experience in UNIX /Linux development and production environments Experience with Agile software development environments Very strong communication skills: written, verbal, and presentation Knowledge of data science/machine learning a plus As a full-time member of Affinity Solutions’ team, your benefits will begin on the first of the month following your date of employment, with a generous Affinity Solutions contribution for medical, dental, and vision. In addition to company paid holidays, wellness time off, other wellness benefits, and employee discounts, you will also get Affinity-paid life insurance and have the option to enroll into an Affinity-matched 401K Plan. We strongly encourage work/life balance by providing unlimited vacation days, available after 90 days from your first day as a team member."
Catalyst Data Engineer,ARK Solutions,"Raleigh, NC",https://www.indeed.com/rc/clk?jk=0309f2858f212a0c&fccid=ae3ba26fed950f3e&vjs=3,"The Technical Specialist is a senior level resource with specialized knowledge and experience in a specific technology. The Technical Specialist has an overall knowledge and understanding of application development and architecture that serves as a strong base for technical expertise in a specific product or program. Demonstrates expertise in conveying technical and functional concepts for a specific technical specialty. Identifies improvements to project standards to achieve high quality services/ products. Able to identify best practices and standards for the use of the product. Delivers support and design for industry specific applications that require integration with statewide systems or applications. Interacts with executive level business users or technical experts. May function as a niche technical SME. Advanced experience in the required technical subject matter. Proven experience with a technical specialty across large and complex implementations and systems. The Technology Center actively leads initiatives which contribute to the digital transformation and proliferation of new and emerging technologies across the Department. The Technology Center provides an organizational structure which encompasses Enterprise Architecture, Cloud Center of Excellence, Catalyst, and Health IT teams. This new organizational structure will provide an integrated framework which spans across DHHS and focuses on the key components enabling DHHS success as part of our ongoing Cloud Computing Strategy and Digital Transformation. Primary Purpose of the Position: The Redshift and Aurora Database Administrator (DBA) is responsible for the data workload management, query prioritization, capacity management, data warehouse tuning, designing and creating data warehouse schemas, tables, adding users, groups, other administrative tasks around the Departments Business Intelligence Data Platform (BIDP) and Master Patient Index Hub. The Redshift DBA is responsible for: Working with Data Architects, Analysts, and Scientist to aid in BIDP data modeling efforts General administration of Redshift and Aurora within the BIDP environment Conduct regular reporting on the health and performance of Redshift and Aurora environments and jobs Maintain ownership of activities around Redshift Provide consistent database maintenance, optimization and best practices inputs to existing Redshift Assist in discovering, evaluating, and qualifying new technologies around BIDP data lake functions Partner with BIDP stakeholders to establish and maintain policies, procedures, operational standards around the Redshift and Aurora functions Develop, and assist in the development of polices, process, standards, and operational documents related to Redshift, Aurora, or the BIDP environment (25%) Perform Redshift and Aurora process management and lifecycle support by outlining the processes and setting the boundaries for data processing and operations within the BIDP environment. Provide architecture management and support for Redshift and Aurora. Monitor and respond to audit logs, events and notifications. Ensure Redshift compliance with all regulatory standards. Prepare and report on Redshift and Aurora activities, utilization, and health. (65%) Develop and maintain clusters and nodes within the BIDP environment. Manage database workloads i.e., Data integration, Workflow orchestration and Analysis. Assist with schema design, code review, query and general database tuning. Minimize database downtime and manage parameters to provide fast query responses. Provide proactive and reactive data management support and training to users. Work with stakeholders to determine, enforce and document database policies, procedures and standards. (10%) Conduct testing of the Redshift based workloads and the ingestion of data pipelines into the Redshift and Aurora environment. Perform root cause analysis on all processes and resolve all production issues and validate all data and perform routine tests on Redshift and Aurora. Document all test procedures for Redshift coordinate with stakeholders and exchange partners to resolve issues and maintain quality."
Data Engineer,Broad Institute,"Cambridge, MA 02142 (Kendall Square area)",https://www.indeed.com/rc/clk?jk=a0cf54e11f5b04c9&fccid=b8295c348463e6f3&vjs=3,"Job Description The Broad Institute of MIT & Harvard is seeking a Data Engineer for the Broad’s Cancer Program to establish and implement the Program’s strategy and practices around data management, storage and compliance. The Manager will be an integral member of the team, collaborating with Principal Investigators (PIs), project managers, scientific researchers, administration, and the Broad Institute’s central IT. They will work closely with the Director of Operations to develop protocols for efficient data transfer and management, establish and maintain user-friendly databases to facilitate and optimize the interaction between scientific researchers and project managers, incorporate the use of cloud storage, and monitor the financial cost of our data footprint. Responsibilities: Compliance Assist Cancer Program PIs in submitting data to public genomic databases, such as GEO and dbGaP in compliance with the NIH Genomic Data Sharing Policy. Assist Cancer Program PI’s in obtaining sequencing and genotyping data sets from public databases such as dbGaP. Connect with other groups at Broad to share best practices and to learn about other data management and data pipeline work with a compliance component. Data Strategy and Management Work with project teams to establish appropriate petabyte level data storage (Broad Network, Cloud, Other) for use by the project team members and collaborators during the life of a project; this includes a review of the types (raw, intermediate, summary, support) and use of data (analysis, read, create), access requirements, and flow of data as it pertains to the project. Monitor data storage for potential cost savings and provide recommendations to leadership and project teams. Develop tools to monitor usage in the Cancer Program Establish best practices and develop a policy for data storage by project teams and staff. Monitor and report on usage trends, and expenses; evaluate services available internally and externally to ensure our strategy continues to be optimal and efficient. Help develop, implement & enforce data storage and retrieval policies for genome analyses. Engage with users to see that best practices are being followed. QUALIFICATIONS Bachelor's degree in computer science, biology or a related field. 2 to 4 years experience working in a computer or scientific environment Experience creating and managing reports (ie. trend analysis, summary reports, operational reports to support site collections). Familiarity/Experience with cloud computing technology(GCP preferred) Exceptional computer skills and must be comfortable learning new software and technology. Experience with Google Suite preferred. Must be able to effectively work on multiple tasks and prioritize appropriately. Strong communication and team skills are essential. #LI-POST All Broad employees, regardless of work location, must be fully vaccinated for COVID-19 by Tuesday, October 12, 2021. Requests for exemption for medical or sincerely held religious beliefs will be considered. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. EEO is The Law - click here for more information Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled Check out this video for a look into our community!"
IoT Data Engineer,Volkswagen Group of America - Chattanooga...,+1 locationRemote,https://www.indeed.com/rc/clk?jk=59bd7c62be079d93&fccid=f59b3329de972ea8&vjs=3,"IoT Data Engineer - EA 000142 - Fully Remote Primary Location United States-EA Home Based Role Summary Electrify America is building an exciting enterprise solution to solve complex, cutting edge business problems related to EV charging. As the IoT Data Engineer you will work with a team to develop advanced automated ETL/integration solutions. The IoT Data Engineer will be responsible for identifying solutions, deigning the identified solution, implementing the solution, testing the solution, and optimizing the solution. The IoT Data Engineer will work with an evolving tech stack currently leveraging AWS and Snowflake as the key tools for data integration, retention, and cleansing. The IoT Data Engineer will work closely with the data architect, other engineers, business and technical analysts to build a pool of clean, sustainable data. The IoT Data Engineer will build monitoring and quality checks to maintain the ongoing health of the data to support the quality team. Develop and maintain automated integration solutions. Engineer ETL/ETL solutions for various datasets. Support Electrify America in the mission to develop a clean, consolidate set of viable data for advanced analytics. Strong affinity for integrating quality checks and monitoring into all solutions. Develop technical documentation. Collaborate with business and technical users to align on complete technical requirements. Role Responsibilities Main responsibility – assign % of time spent (70%) Develop automated integration solutions. Develop complex ELT/ETL logic. Implement quality monitoring solutions. Optimize existing implementations. Develop cutting edge business KPIs using advanced logic directed by the business. Developing and maintaining a thorough knowledge of business requirements. Additional responsibilities – assign % of time (30%) Collaborate with data architects, analysts, and other developers to divide work and develop strong, business oriented solutions. Build technical documentation of implementation solutions. Experience 5 – 8 years of relevant experience Education Undergraduate degree in computer science, data science, information science, quantitative modeling, business intelligence or a has relevant work experience in a related field General Skills Experience working with evolving data models and expanding interconnected data sources. ETL/ELT experience. Experience with SQL and relational databases. Ability to take a data platform solution from start to finish – identify the solution, built it, test it, optimize it, and maintain it. Experience developing automated data integration. Ability to apply data quality and data cleaning principals in an automated manor. Ability to collaborate with a team and define strong ETL and data quality solutions. Experience designing advanced technical solutions to business problems. Ability to develop reporting solutions with an evolving pool of data. Experience solving complex business problems. Experience developing enterprise level KPIs. Experience developing quality data pipelines. Ability to explore and analyze data independently. Ability to keep up with ever evolving data engineering best practices and standards. Curious and self-driven. Analytical/logical thinker. Ability to consider both the problem and the proposed solution to determine what truly meets the business need; big picture thinking. Familiarity with SCRUM ideology. Strong communication skills and ability to communicate with both business and technical resources. Suggest improvements and optimized solutions for the data pipeline both to and from the data warehouse. Strong focus on best practices and sustainable, automated solutions. Desire to build things right, rather than build them twice. Strong documentation skills. Flexible when faced with scope or timeline changes. Experience working in an enterprise ecosystem. Ability to collaborate with other teams and business stakeholders to set clear delivery timelines. Strong solution oriented drive. Cross-functional coordination. Multi-stakeholder communication and collaboration. Results oriented. Ability to solve business requests in a creative manor. Specialized Skills ETL/ELT experience. Relational database experience. Experience working in an enterprise level ecosystem. Coding experience. Experience building automated, sustainable integration solutions. Experience with data quality and quality monitoring. Strong SQL knowledge. Experience with Agile workflow and SCRUM Experience writing technical documentation Familiarity with data modeling/data architecture. Experience analyzing Tool agnostic. Experience building solutions that incorporate change data capture Experience with Project Management Software/Jira. (desired) Experience with change management tools. (desired) ETL experience with Matillion, AWS (S3, Lambda, SNS, SQS, Glue, etc), and Snowflake (Snowpipe, etc). (desired) Experience with Python, Java, JavaScript, or Scala. (desired) Experience parsing complex JSON. (desired) Knowledge of EVs. (desired) Familiarity with OCPP/OCPI standards. (desired) Experience with Tableau dashboard development. (desired) Work Flexibility No/Minimal Travel, Remote Work Available Volkswagen Group of America is an Equal Opportunity Employer. We welcome and encourage applicants from all backgrounds, and do not discriminate based on race, sex, age, disability, sexual orientation, national origin, religion, color, gender identity/expression, marital status, veteran status, or any other characteristics protected by applicable laws. #LI-VR1"
Big Data Engineer,Bechtel,"Reston, VA",https://www.indeed.com/rc/clk?jk=013a65cb1ca385f0&fccid=40dab2048c41a718&vjs=3,"Requisition ID: 252627 Requisition Posting End Date: Bechtel Corporation is seeking talented and ambitious big data engineer to join our Big Data and Analytics Center of Excellence (BDAC) team. The Big Data team reports to our Corporate Project Controls group which aligns us directly with the project management function of the company. The successful candidate will be a strategic hire that will help drive the adoption of data science and proliferation of machine learning capabilities into our standard project execution methods and procedures. Who you are: You yearn to be part of groundbreaking projects that work to deliver world-class solutions on schedule Someone who is motivated to find opportunity in and develop solutions for evolving challenges, is passionate about their craft, and driven to deliver exceptional results You love to learn new technologies and guide junior engineers to raise the bar on your team You are imaginative and engaged about intuitive user interfaces, as well as new/emerging concepts and techniques Job Responsibilities: Big data design and analysis, data modeling, development, deployment, and operations of big data pipelines Collaborate with a team of other data engineers, data scientists, and business subject matter experts to process data and prepare data sources Mentor other data engineers to develop a world class data engineering team Ingest, Process, and Model data from many heterogenous data sources to support Data Science projects Basic Qualifications: Bachelor’s degree or higher in Computer Science, or equivalent degree and 3+ years working experience In depth experience with a big data cloud platform such as AWS or Azure. Strong grasp of programming languages (Python, Scala, or equivalent) and a willingness to learn new ones Experience writing database-heavy services or APIs Experience building and optimizing data pipelines, architectures, and data sets Working knowledge of queueing, stream processing, and highly scalable data stores Experience working with and supporting cross-functional teams Strong understanding of structuring code for testability Preferred Qualifications: Professional experience implementing complex ML architectures in popular frameworks such as Tensorflow, Keras, PyTorch, Sci-kit Learn, and CNTK Professional experience implementing and maintaining MLOps pipelines in MLflow or AzureML #LI-TN1 Shaping tomorrow together Bechtel is one of the most respected global engineering, construction, and project management companies. Together with our customers, we deliver landmark projects that foster long-term progress and economic growth. Since 1898, we’ve completed more than 25,000 extraordinary projects across 160 countries on all seven continents. We operate through four global businesses: Infrastructure; Nuclear, Security & Environmental; Energy; and Mining & Metals. Our company and our culture are built on more than a century of leadership and a relentless adherence to our values, the core of which are safety, quality, ethics, and integrity. These values are what we believe, what we expect, what we deliver, and what we live. www.bechtel.com Bechtel is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity and expression, age, national origin, disability, citizenship status (except as authorized by law), protected veteran status, genetic information, and any other characteristic protected by federal, state or local law. In accordance with Bechtel's duty to provide and maintain a safe workplace for our employees and to safeguard the health of our families, customers, and visitors, we have adopted mandatory COVID-19 safety protocols for each work location, which may include a vaccination or testing requirement. Please speak with your Bechtel recruiter to determine which protocols apply to the work location for the job you are seeking."
Data Engineer,Electronic Arts,"San Francisco, CA 94105 (Financial District/South Beach area)",https://www.indeed.com/rc/clk?jk=cdbc074aaec468fc&fccid=617d7f961cfcf54a&vjs=3,"Glu Mobile is now part of the Electronic Arts family. The combination of our talented teams at Glu and EA position us as a leader in the largest gaming category in the world. We are forming a powerful growth engine that will expand our current games and deliver more amazing new experiences across sports, lifestyle, mid-core, and casual for players everywhere. Come join us! Responsibilities The Data Engineering team at Glu builds core data infrastructure and applications in support of all areas of our business, including our studio teams, analytics, user acquisition, monetization, and finance. Glu is passionate about maximizing the value that data and analytics can provide to the business and is aggressively investing in new capabilities. Our team covers a lot of ground from real-time data ingestion through to scalable data pipelines. Qualifications As a Senior Engineer, you should have a strong engineering background and have built robust data platforms and pipelines, and take complete ownership of your area of expertise. This is a fantastic opportunity to use your engineering skills to make a material impact on a highly valued analytics platform and lead the team with best engineering practices. Taking ownership of and developing critical new features for our next-generation analytics platform, supporting Glu's worldwide studios and central functions such as marketing and finance Building scalable, accurate, and extensible stream processing applications using cutting-edge technology such as Spark Streaming and Apache Flink Implementing complex and highly scalable end-to-end data pipelines, using Elastic Beanstalk, Kinesis, EMR, Spark, Hive, Druid, Snowflake, AirflowEnsure best practices and standards in our data ecosystem are shared across teams Bachelor's degree in computer science/statistics/mathematics, data engineering, or other fields with equivalent proven engineering experience 5+ years of data engineering experience, especially working on back-end data infrastructure Proficiency with at least one of the following languages: Java, Python, Scala Experience with distributed batch and stream processing technologies such as Flink, Spark SQL, Spark Streaming, and/or Kafka Streams Experience with AWS Ecosystem, especially Kinesis, EMR, Lambda, and GlueExperience with CI/CD process, testing framework, and containerization technology Experience with workflow orchestration tools such as Oozie, Luigi, and AirflowKnowledge of NoSQL application data stores i.e. Druid, HBase, Cassandra, DynamoDB, Redis Expertise with high-scale machine learning, i.e. Spark M/L, SageMaker, etc Experience with SQL and SQL-like languages, especially Snowflake Expertise building data-rich web applications, especially with technologies like Angular, js, and Elastic Beanstalk Passionate about continuously adding automation process and optimization of data infrastructure Electronic Arts is an innovative tech company that creates incredible experiences for millions of players around the world. But what matters most is our people who inspire us, and the world, to play. As we bring new forms of entertainment to people around the world, we need innovative, collaborative, diverse and adaptable people to keep making Electronic Arts better."
Data Engineer,Aegion Corporation,"Indianapolis, IN 46077+5 locations",https://www.indeed.com/rc/clk?jk=d510d574e11218ed&fccid=a533a1eb2195c01e&vjs=3,"Overview: FULLY REMOTE Aegion Corporation and its family of companies shield and protect the world’s infrastructure from degradation and corrosion with a variety of technologies and services. With operations in multiple countries across the world, a career at Aegion will provide challenging and innovative opportunities with a company that is a technology leader in their industry. Aegion’s IT organization includes a team of exceptionally talented individuals responsible for supporting Aegion’s growing global businesses. The IT organization is team-oriented and forward thinking with multiple opportunities to develop an array of new business capabilities and technological skills. Aegion’s BI Team is looking for experienced Analytics professionals with the ability to develop our Enterprise Data Warehouse and Analytics environment. Our Data Operations Team supports the global functions of our business across all divisions of the enterprise. As a member of the Data Operations team, team members will have the opportunity to perform end-to-end development to include requirements gathering and analysis, data modeling, ETL development, design and tuning, semantic layer design, report, and dashboard creation as well as migration and administration activities. Responsibilities: The successful candidate will demonstrate a passion for delivering data analytics to all levels of an organization, flexibility, team-player attitude, excellent communication skills, and will be driven by curiosity without the fear of failure. The IT organization offers a challenging environment focused on teamwork and delivering value added solutions for the organization. We consistently strive to attract and retain intelligent, creative, energetic, and fun employees with a focus on building exceptional teams. Typical responsibilities and skills of this position include: Design and develop analytics solutions: Develop reports and dashboards Assist in monitoring and optimizing the analytics environment Provide support and education to analytics consumers and power users Use your creativity and experience to model and build an Enterprise Data Warehouse Create ETL, Semantic Layer and Data Warehouse modeling standards Develop semantic layer and metadata repositories Perform ETL, Semantic Layer and Reporting migrations Create, enhance, and tune stored procedures Execute throughout all phases of an analytics implementation Communicate with business leaders at all levels of the organization and translate business requirements into successful data warehouse & analytic solutions. jobsnow Qualifications: Must have a minimum 3 to 5 years of experience in a business analytics position within an IT department Must have a minimum of three years delivering Power BI solutions and hands on experience with DAX, Power Query and the Power BI Service Must have a minimum three to five years developing data warehouse solutions to include DDL creation, source to target mapping, hands on ETL experience, and working knowledge relational data warehouse modeling to include star and snowflake schemas Must have an understanding of modern reporting strategies including dashboard creation and how to tell a data story with actionable analytics Four-year college degree in Computer Science, Information Management, specialized training, or equivalent work experience Strong analytical, critical thinking and problem-solving capabilities Solid understanding of Agile Scrum project management methodologies We offer a Competitive Salary with Career Growth Opportunities and a Full Benefits Package including Medical, Dental and Vision Insurance, Matching 401k, Tuition Assistance, Paid Time Off, and much more. Aegion is an Equal Opportunity Employer. Equal opportunity is a sound and just concept to which Aegion is firmly bound. Aegion will not engage in discrimination against, or harassment of, any person employed or seeking employment with Aegion on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, non-disqualifying disability, status as a protected veteran or other characteristics protected by law. VEVRAA compliant – priority referral Protected Veterans requested"
Data Engineer,ZM Financial Systems,"New York, NY",https://www.indeed.com/rc/clk?jk=6c74e2b30d233f05&fccid=7e9f8411cc2b1ce8&vjs=3,"Imagine what we can DEVELOP with you True leaders are always learning. Moody’s is home to information architects, thinkers, builders, and passionate problem solvers, a collection of diverse viewpoints working together to bring out our best. Join us. Forward Together. Moody’s (NYSE: MCO) is a global integrated risk assessment firm that empowers organizations to make better decisions. Our data, analytical solutions and insights help decision-makers identify opportunities and manage the risks of doing business with others. We believe that greater transparency, more informed decisions, and fair access to information open the door to shared progress. With over 11,000 employees in more than 40 countries, Moody’s combines international presence with local expertise and over a century of experience in financial markets. Learn more at moodys.com. At Moody’s, we’re taking action. We’re hiring diverse talent and providing underrepresented groups with equitable opportunities in their careers. We’re educating, empowering and elevating our people, and creating a workplace where each person can be their true selves, reach their full potential and thrive on every level. Learn more about our DE&I initiatives, employee development programs and view our annual DE&I Report at moodys.com/diversity Moody’s Analytics provides financial intelligence and analytical tools supporting our clients’ growth, efficiency and risk management objectives. The combination of our unparalleled expertise in risk, expansive information resources, and innovative application of technology, helps today’s business leaders confidently navigate an evolving marketplace. Department Moody’s Analytics products are becoming an essential tool in the rapidly expanding Commercial Real Estate market. We deliver an integrated and holistic platform that automates critical processes and generates insights and recommendations to drive better decisions. Lenders, asset managers and brokers are some of our biggest customers. Our analytics provide key property performance indicators, research, and risk assessment, giving our customers a good understanding of their future cashflows. We have a team of brokerage and lending solutions experts as well as passionate sales, marketing and technology professionals who constantly strive to add value to our customers’ experience. Role/Responsibilities As a Data Engineer, you will be a core member of a cross-functional team responsible for developing and executing a vision for how to grow the CRE business monumentally through new product innovation. We practice an agile, highly customer focused, and learning-based approach to product development that aims to bring new products to market in 9-12 months. You will be responsible for building and maintaining high quality data pipelines that drive analytic solutions and product development. These solutions will draw on Moody’s Analytics unique and rich data sources to generate insights for innovative products that create a new standard in the CRE space. You bring not only a deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows, but also a passion for translating those skills into business impact for our customers. Specifically, you will have the opportunity to: Design, develop, optimize, and maintain scalable data architecture and pipelines that adhere to ETL principles and business goals Solve complex data problems to deliver insights that help the organization’s business to achieve their goals Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions Improve operational processes and documentation Qualifications 2+ years of experience working in a fast-paced software development environment Expertise in SQL and data analysis and experience with at least one programming language (Python preferred) Experience developing and maintaining data warehouses in big data solutions Experience with developing solutions on AWS cloud computing services and infrastructure in the data and analytics space (preferred) Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data Experience working on a collaborative product team passionate about Agile software processes, data-driven development, and experimentation Excellent communication, listening, and influencing skills Ability to work efficiently with a solid sense for setting priorities Ability to guide own learning and contribute to domain knowledge building Self starter Must be fully vaccinated for COVID-19 (i.e., at least 2 weeks after last dose) and, if hired, present proof of vaccination on start date, as determined by Moody’s. Moody’s is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, gender, age, religion, national origin, citizen status, marital status, physical or mental disability, military or veteran status, sexual orientation, gender identity, gender expression, genetic information, or any other characteristic protected by law. Moody’s also provides reasonable accommodation to qualified individuals with disabilities or based on a sincerely held religious belief in accordance with applicable laws. If you need to inquire about a reasonable accommodation, or need assistance with completing the application process, please email accommodations@moodys.com. This contact information is for accommodation requests only, and cannot be used to inquire about the status of applications. For San Francisco positions, qualified applicants with criminal histories will be considered for employment consistent with the requirements of the San Francisco Fair Chance Ordinance. This position may be considered a promotional opportunity, pursuant to the Colorado Equal Pay for Equal Work Act. Click here to view our full EEO policy statement. Click here for more information on your EEO rights under the law. Click here to view our Pay Transparency Nondiscrimination statement. For Colorado-based roles only: the anticipated base salary range for this position is $90,800 to $131,750, depending on factors such as experience, education, level, skills, and location. This range is based on a full-time position. In addition to base salary, this role is eligible for annual performance incentive compensation. Moody’s also offers a competitive benefits package, including not but limited to medical, dental, vision, parental leave, paid time off, a 401(k) plan with employee and company contribution opportunities, life, disability, and accident insurance, a discounted employee stock purchase plan, and tuition reimbursement. Candidates for Moody’s Corporation may be asked to disclose securities holdings pursuant to Moody’s Policy for Securities Trading and the requirements of the position. Employment is contingent upon compliance with the Policy, including remediation of positions in those holdings as necessary."
Data Engineer,EMD ELECTRONICS,"Tamaqua, PA 18252+1 location",https://www.indeed.com/rc/clk?jk=8e14c31c35ee1b79&fccid=8dabf7b1ececb62a&vjs=3,"What we offer: We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity. We believe that it drives excellence, innovation, and human progress. We care about our customers, patients, and our rich mix of people. This diversity strengthens our ability to lead in science and technology. We are committed to creating access and opportunities for all and empower you to fulfil your ambitions. Our diverse businesses offer various career moves to seek new horizons. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to bring their curiosity to life! Curious? Chat with one of our curious minds on our interactive Q&A platform and catch a glimpse of our people, values, and culture. You can also apply and find more information at https://jobs.vibrantm.com If you would like to know more about what diversity, equity, and inclusion means to us, please visit https://www.emdgroup.com/en/company/press-positions.html If you are a resident of a Connecticut or Colorado, you are eligible to receive additional information about the compensation and benefits, which we will provide upon request. You may contact 855 444 5678 from 8:00am to 5:30pm ET Monday through Friday, for assistance. Your Role: As a key materials supplier to the semiconductor industry, we are facing ever more complex and dynamic manufacturing and supply chain challenges. How do we manage the complexities of our manufacturing systems effectively? Data! To take our operations to the next level, putting our data to work is key. As Data Engineer in our Manufacturing Intelligence team, you will develop cutting-edge big data solutions to streamline operations and provide the highest levels of quality to our customers in the semiconductor industry. Design and deliver digital solutions using big data tools to help groups like supply chain, quality, and operations improve manufacturing planning and logistics, process monitoring and control, and root-cause investigation. Develop robust, automated end-to-end data pipelines to feed downstream analytics and data science use cases. Collaborate with operational teams to understand and prioritize user requirements, formulate clear development roadmaps, perform testing and validation, and deploy digital solutions aimed at improving quality, increasing labor efficiency, and/or maximizing production capacity. Own and improve existing solutions, and act as the technical point of contact for users. Manage change control processes and communication with local business groups impacted by solutions to ensure alignment between all parties and proper documentation. Who You Are: Minimum Qualifications: Bachelor's degree in science, technology, engineering, mathematics, or computer science 2+ years of industry experience in a data engineering, data science, or data analytics function 2+ years of experience in data engineering and pipeline development using Python, Spark, and/or SQL 1+ years of experience with data visualization and dashboard design in Tableau 1+ years of experience with SAP or other ERP systems Preferred Qualifications: Proficient using Python to perform data engineering, statistical modeling, and data visualization with libraries such as pandas, numpy, pyspark, scikit-learn, matplotlib, and seaborn. Experience using SAP or other ERP systems (Quattro, S/4HANA) Experience using Palantir Foundry and/or Alteryx analytics platforms. Experience using applied statistics to control and improve manufacturing operations. Ability to grasp complex data architectures quickly and independently. Capable of driving decision-making using data and visualization. Strong organizational and planning skills with attention to detail. Excellent communication skills to explain solutions to non-technical business users. Your Role: As a key materials supplier to the semiconductor industry, we are facing ever more complex and dynamic manufacturing and supply chain challenges. How do we manage the complexities of our manufacturing systems effectively? Data! To take our operations to the next level, putting our data to work is key. As Data Engineer in our Manufacturing Intelligence team, you will develop cutting-edge big data solutions to streamline operations and provide the highest levels of quality to our customers in the semiconductor industry. Key Accountabilities Design and deliver digital solutions using big data tools to help groups like supply chain, quality, and operations improve manufacturing planning and logistics, process monitoring and control, and root-cause investigation. Develop robust, automated end-to-end data pipelines to feed downstream analytics and data science use cases. Collaborate with operational teams to understand and prioritize user requirements, formulate clear development roadmaps, perform testing and validation, and deploy digital solutions aimed at improving quality, increasing labor efficiency, and/or maximizing production capacity. Own and improve existing solutions, and act as the technical point of contact for users. Manage change control processes and communication with local business groups impacted by solutions to ensure alignment between all parties and proper documentation. Who You Are: Minimum Qualifications: Minimum bachelor's degree in science, technology, engineering, or mathematics (STEM) 2+ years of industry experience in a data engineering, data science, data analytics, or engineering role using data to support manufacturing operations. Proficient using Python to perform data engineering, statistical modeling, and data visualization with libraries such as pandas, numpy, pyspark, scikit-learn, matplotlib, and seaborn. Proficient using SQL to create moderate to advanced queries and interact with relational databases. Proficient using Tableau for data visualization and dashboard design. Experience using applied statistics to control and improve manufacturing operations. Ability to grasp complex data architectures quickly and independently. Capable of driving decision-making using data and visualization. Strong organizational and planning skills with attention to detail. Excellent communication skills to explain solutions to non-technical business users. Preferred Qualifications: Experience using SAP ERP systems (Quattro, S/4HANA) Experience using Palantir Foundry and/or Alteryx analytics platforms. RSRMS The Company is an Equal Employment Opportunity employer. No employee or applicant for employment will be discriminated against on the basis of race, color, religion, age, sex, sexual orientation, national origin, ancestry, disability, military or veteran status, genetic information, gender identity, transgender status, marital status, or any other classification protected by applicable federal, state, or local law. This policy of Equal Employment Opportunity applies to all policies and programs relating to recruitment and hiring, promotion, compensation, benefits, discipline, termination, and all other terms and conditions of employment. Any applicant or employee who believes they have been discriminated against by the Company or anyone acting on behalf of the Company must report any concerns to their Human Resources Business Partner, Legal, or Compliance immediately. The Company will not retaliate against any individual because they made a good faith report of discrimination. As an employee of the Company, you will be required to comply with all of the Company's COVID-19 safety protocols and policies. The organization has currently suspended enforcement of its COVID-19 Vaccination Policy, but that policy may be reinstated by the Company in its discretion. Job Requisition ID: 242764 Location: Tamaqua Career Level: C - Professional (1-3 years) Working time model: full-time North America Disclosure The Company is committed to accessibility in its workplaces, including during the job application process. Applicants who may require accommodation during the application process should speak with our Candidate Services team at 844-655-6466 from 8:00am to 5:30pm ET Monday through Friday. If you are a resident of a Connecticut or Colorado, you are eligible to receive additional information about the compensation and benefits, which we will provide upon request. You may contact 855 444 5678 from 8:00am to 5:30pm ET Monday through Friday, for assistance. Notice on Fraudulent Job Offers Unfortunately, we are aware of third parties that pretend to represent our company offering unauthorized employment opportunities. If you think a fraudulent source is offering you a job, please have a look at the following information . Job Segment: Database, Semiconductor, ERP, SAP, Computer Science, Technology, Science"
Sr Data Software Engineer - Fully Remote,Paramount+,"Remote in New York, NY 10036",https://www.indeed.com/rc/clk?jk=354ff77fd138d7ce&fccid=30cb52ad6dd37131&vjs=3,"Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage. As a Senior Data Engineer, you will be collaborating with architects and engineers of the team! You will build and evolve our streaming and batch data pipelines, delivery of services, and cloud infrastructure! What you will do : Design, build and implement large-scale, sophisticated, and high-volume data pipelines for analytics and data science. Collaborate with product, data scientists, and engineers to understand the business domain and craft technical requirements and solutions optimally. Work in multi-functional agile teams to continuously experiment, iterate and deliver on new product objectives. Mentor junior colleagues on coding, architecture, and data engineering processes. Lead the technical design of scalable data architectures. Lead DevOps initiatives for continuous integration, monitoring, deployment, automated, testing, golden datasets, data governance, process management, incident response, developer tooling, artifact delivery Define standard methodologies, tune and debug streaming & batch jobs, and data pipeline workflows. Basic Qualifications : Bachelor's Degree (BA, BSc) and or Graduate level (MA, MSc, MFA) in Computer Engineering/Computer Science or equivalent experience. 5+ years of programming experience, demonstrated ability to write clean and modular code in Python or/and Java. 3+ years in working with large data sets, data warehouses, and pipelines (e.g. Spark, Snowflake, SQL). 3+ years in with workflow scheduling/orchestration such as Airflow or Oozie. Experience with schema design and data modeling. Strong in code versioning and partnership tools/repositories like GitHub Strong knowledge of modern software delivery practices like CI/CD (using tools like Jenkins, shell script, etc. and various build pipeline automation tools) BI/Reporting data workflow experience preferred - aggregated data sources, metric definition, data visualization with tools like Tableau. Strong debugging, critical thinking, and technical design skills with the ability to learn new technologies quickly. Clear and effective verbal, visual, and written communication skills. Preferred Qualifications: Experience in Apache Kafka & stream processing. Interest & knowledge in Machine Learning, understanding of supervised, unsupervised & deep learning techniques. Experience with machine learning frameworks (e.g., sci-kit-learn, TensorFlow, PyTorch). Experience with container orchestration and deployment frameworks (e.g. Kubernetes, Docker). Experience with Django or other web frameworks. Cloud certifications. Paramount is an equal opportunity employer (EOE) including disability/vet. At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies, we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources, and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers/experienced as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to viacomaccommodations@viacom.com . Only messages left for this purpose will be returned. Paramount believes in creating environments that allow our primary focus to remain on providing entertainment, education, and information to our millions of viewers around the world. As part of this commitment to health and safety, Paramount requires COVID-19 vaccines for current U.S. employees, including all newly hired employees, subject to applicable law. Union employees are subject to what is outlined in their applicable collective bargaining agreement. Paramount is an equal opportunity employer (EOE) including disability/vet. At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to viacomaccommodations@viacom.com. Only messages left for this purpose will be returned."
"Battery Manufacturing Engineer, Data Process",Tesla,"Austin, TX",https://www.indeed.com/rc/clk?jk=0745b434a2b71fdd&fccid=86e9be6ce380173e&vjs=3,"The Role Under Tesla’s Manufacturing Engineering Organization, Manufacturing Launch Engineers are dedicated to installing, commissioning, and ramping some of the most advanced manufacturing equipment in the world. The Manufacturing Engineering Launch Team is responsible for equipment installation, alignment and calibration of equipment, quality validation (PFMEA/Process Control Plan), root-cause analysis to improve OEE as well as managing the integration of the Manufacturing Operating System (MOS) on each manufacturing line. Successful Manufacturing Engineers have a proficient understanding of database systems, data analytics, scripting, and query development that allows them to effectively identify and root-cause inefficiencies and drive solutions that achieve or exceed design targets related to performance, yield and availability. In certain circumstances, Manufacturing Engineers are also considered subject matter experts on particularly complex manufacturing processes in order to better optimize them. Manufacturing Engineers should have thorough understanding of one or more of the following core competencies; Statistical Process Control, Factory Database Systems, Root-Cause Analysis, Data Analytics, Scripting, Database Query Development, Product Flow Optimizations, Buffer Modeling and Simulations, Tableau Dashboard Development, PLC Data Extraction, Bottleneck Analysis, Product Traceability, 2D/3D Vision Systems, Test Equipment, Process Capability, and Process Repeatability and Reproducibility, FANUC Robotics, and Mechanical Design. The best candidate for this position has a high aptitude and desire to learn all things related to high-volume, industrial automation. This role is specifically tailored to the GFTX Manufacturing Launch Data Systems Engineer. Manufacturing Engineering is responsible for launching manufacturing equipment, and all the subsequent processes and data systems of Tesla’s production lines. Improving our systems through the application of experimental findings is crucial for Production Engineering to continue to improve the quality of our increasingly complicated and increasingly tuned production lines. This role collaborates with members of Manufacturing Engineering and Quality Engineering to improve our most-difficult manufacturing processes and equipment through data science, experimentation and modeling to drive tangible optimizations to the production environment. The Data Scientist also trains others to improve the sophistication and effectiveness of their scientific investigations within the organization. Responsibilities: Collaborate with Process Engineering and Controls to create dashboards/pareto charts for new manufacturing equipment to pinpoint areas of opportunity Review academic and industry literature for applicable knowledge Design and maintain well-structured rational database schemas Create automated ETL pipelines for a variety of raw manufacturing data sources Research and develop new data storage architectures for growing data volumes Design experiments to generate empirical optimizations Analyze existing in-process data to Inform process development by analyzing equipment in-process data to understand the mechanisms of root causes Build mathematical models to accelerate future optimizations Determine what and how data should be collected on new production lines Identify novel techniques for instrumenting equipment to better control process Determine product characterizations methods for durability testing Educate others on statistical analysis and scientific investigation Collaborate daily with other members of Manufacturing Engineering Process Ownership: Act as the owner/subject matter expert to collect and analyze data that pinpoints and drives process improvement projects. Champion and lead continuous improvement projects and trials, to increase yield, performance and availability. Monitor and audit manufacturing processes to ensure product specifications and standards are achieved. Work with Equipment Engineers to maintain Manufacturing Work Instructions Process Data Analytics: Lead the integration of factory data systems using software such as MySQL, Python, MatLab, R, JMP, Tableau, and Ignition to enable data driven operational and financial decisions through predictive insights into manufacturing and process effectiveness. Facilitate structured problem solving techniques such as Design of Experiments (DoE), Five Why (5W) and the Eight Disciplines (8D), to improve manufacturing processes Process Capability: Work closely with Process Engineers and Equipment Engineers in other manufacturing areas to redefine and improve manufacturing capability of specific processes. Understand product tolerances, and stack-up effects. Leverage Product Design and Quality Teams to determine the ideal nominal conditions to mitigate upstream/downstream variability Process Repeatability & Reproducibility: Monitor and reduce process variation using techniques such as Statistical Process Control (SPC), and Measurement Systems Analysis (MSA) Process Commissioning and Ramp: Work closely with the Manufacturing Engineering team during the commissioning and ramp of new equipment to collect, analyze and communicate critical data that enables the prioritization of improvements Process Optimization: Analyze and optimize manufacturing processes to maximize Overall Equipment Effectiveness (OEE) to world-class levels (> 90%). Work with Equipment Engineers and champion continuous improvement projects to increase yield, performance and availability Collaboration: Work collaboratively with cross-functional teams; Quality Engineering, Manufacturing Engineering, Process Engineering, Controls Engineering, Production Operations, Maintenance, and Product Design Requirements: Bachelor of Science in Mechanical, Electrical, Industrial, or Computer Engineering, or equivalent experience Three years’ experience in a high-volume manufacturing environment Expert experience with data visualization and data-driven optimization Proficiency with data analysis languages such as R, Python, SQL, Matlab, and/or SAS Thorough understanding of database systems, and data analytics Must possess process engineering skills (process development/improvement, troubleshooting, data analysis, constraint analysis, flow optimization, root cause analysis, etc.) Strong team working skills at all levels of an organization, especially skilled at working with direct labor to understand challenges and work on developing optimal solutions using structured methods Good understanding of process controls, part variation, manufacturability, process design, process validation, assembly methods, and cost reduction methodologies. Previous experience with Manufacturing Execution Systems desired Experience breaking down high-level (e.g. device level) performance issues into addressable action items Experience with statistical analysis similar to 6-Sigma methodology Basic understanding of PLC systems and programmable logic Capable of identifying critical process parameters and applying statistics to process measurement and control Ability to read and interpret basic mechanical and electrical drawings"
BI Big Data Engineer,DoubleDown Interactive,"Hybrid remote in Seattle, WA 98104",https://www.indeed.com/rc/clk?jk=b4070f8db3b0c4bb&fccid=66b193f1f8905c7d&vjs=3,"Want to be part of something new and exciting? The Business Intelligent department is responsible for providing information and insights from our massive data sets. This information enables DoubleDown to understand our business, our players, and our games which will help us grow our business. DoubleDown is seeking to hire a Big Data Engineer to support our growing workload and to provide additional capabilities to support upcoming games, new API integrations and process optimizations. We utilize many AWS products including RedShift, S3, EC2, and Elasticache to create and manage our state-of-the-art multi-Terabyte Enterprise Data Warehouse solution. Our team is very-closely knit learning-oriented group who contribute greatly to the studio’s success and has the opportunity to develop a wide range of technical and interpersonal skills and interact directly with our customers to deliver solutions that work well and are useful. Be a key player in building new worlds and experiences at DoubleDown ! Our Seattle studio is the hub for all things creative – think Game Designers, Artists, Marketers, and more! Located in Seattle’s International District, we are exploring beyond social casino and focusing on creating multiple, all-new casual and mid-core franchises – expanding to create experiences in fun new worlds, developing characters, stories & gameplay! As a leader in the social casino space, we are excited to continue revolutionizing mobile games through constant innovation. Known for our fun and collaborative culture, we move quickly to deliver exciting game experiences to all sorts of gamers. Your XP , Badges and Skill Tree Bachelors or Master of Science, in Computer Science or other IT-related major 3-5 years of ETL experience in data warehousing or transactional systems Proficient in at least one programming language (Python, Java, Perl, etc.) Understanding and implementation experience or coursework with both relational and data warehousing models including star-schema, dimensional design, data mart, and database architecture Proficient in development of automated ETL processes (both through the use of automation tools and through manual scripting) Proficiency in a UNIX / Linux environment Understanding of Big Data mechanics, analytical processing, modeling, and implementation Proficiency in SQL, stored procedures, views, and triggers Strong problem solving and analytical skills; excellent communication skills Other Super P ower s and Abilities Experience with Amazon Web Services (AWS) Experience in one of the reporting tools such as Airflow, Tableau, Talend, Business Objects, etc. Your Mission In this high-visibility role reporting to the Manager, Business Intelligence Engineering, the candidate will: Create detailed specs for ETL design/development/support and then transform those designs into system capabilities utilizing standard coding tools and processes. Work with end users to identify their ad hoc and scripted reporting needs Maintain and streamline the existing data flow to improve accuracy and efficiency Stay current with technical best practices and industry trends and advise and educate management on their importance Instill a strong customer service and business-oriented ethic when working with both the team and end users Identify and fix defects and reuse existing software components New Adventures By the end of your first year, you will be making major contributions to the EDW as demonstrated by: The creation of rock solid ETL processes and SQL queries that populate the EDW Providing successful support of BI analysts and data-hungry people in other parts of DoubleDown with data to support their reporting needs Rewards and Perks As our studio transitioned into a hybrid work environment (1 collaboration day per week in the office) the cool things we do for employees have slightly changed. Here is a glance of fun things we do as a studio! Take a break and participate in our bi-weekly (sometimes themed) trivia session! Stay zen throughout the week by taking advantage of one or more of our virtual yoga classes. Hungry? Anticipate monthly snack boxes courtesy of SnackMagic! Does your home “office” need some comfort? Take advantage of our office chair lending program! Still not comfortable? Schedule a virtual visit from our team of ergonomics assessment professionals. Miss seeing your coworkers faces? We also do virtual company events! Here is a snapshot of things we have done this past year: Pride Bingo Wine Tasting & Trivia Escape Room Extravaganza Painting Class Virtual Murder Mystery Virtual Candle Making Story Time with Santa Still hungry? Depending on the month, you’ll get carefully curated goodie boxes, to feed you and your family! Giving back to the community is just as important as giving to our employees. We have sponsored a company match for Juneteenth, hosted a virtual bike challenge benefiting the Boys & Girls Club of King County and partnered once again with NBCF, and other local organizations. As if all of this isn't cool enough, you'll love our benefit package. We offer medical, dental, vision, prescription coverage, maternity/paternity leave, disability protection (short- and long-term) and a 401(k) employer match and both traditional and Roth plans. Not sure where to start with benefits? Health Advocate is here to help navigate benefits with you, like finding a doctor or help answer any medical related questions 24/7! Every team member receives 15 days of vacation, 56 hours of sick time, 4 personal floating holidays, and 9 paid calendar holidays per year. With everything that’s going on in the world right now, we’ve got your back! Between our Employee Assistance Program and our medical provider, you have up to 8 free counseling visits annually. Our Simply Engaged and Rally Wellness Programs provide at home workouts, wellness resources and healthy recipes. Need more motivation? They also reward your healthy habits with gift cards! And finally, to give you peace of mind, InfoArmor provides around the clock identity theft protection. Combine all of this with our amazing work/life balance and company-matched retirement options, and you have the dream job! Looking for another reason we're the best place in Seattle to work? We're committed to our role as an Equal Opportunity Employer – we embrace a diverse mix of voices and create a positive environment where everyone belongs. We don’t just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products, and our communities. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. DoubleDown is committed to providing reasonable accommodation to individuals with physical and mental disabilities. If you need help completing your application, let us know! Email us at Careers@DoubleDown.com and one of our awesome HR team members will get you everything you need. We look forward to meeting you soon! To learn about us, please visit us here and watch us here! To be considered, you must be at least 18 years of age with the ability to successfully pass a security criminal background investigation. You must be legally authorized to work in the United States without visa sponsorship as DoubleDown does not sponsor, renew, or extend immigration visas for this position. DoubleDown partners with E-Verify, an Internet-based system that allows businesses to determine the eligibility of their employees to work in the United States. *How we're handling COVID-19* We are still hiring, so we’ve adapted our process to keep people safe. All positions at DoubleDown are subject to interviewing & onboarding virtually/remotely. Starting in June 2022, we are transitioning into a hybrid environment based out of our Seattle, WA studio, where teams are expected to collaborate in the office for a minimum of 1 day per week. In person collaboration is an important part of making awesome gaming experiences so when it is safe, we look forward to working together both virtually and in person!"
Data Engineer,Level Ex,+1 locationRemote,https://www.indeed.com/rc/clk?jk=b6d982777a612372&fccid=dd616958bd9ddc12&vjs=3,"Open to Long-Term Remote For U.S.-Based Candidates Level Ex is transforming the way medical professionals hone their skills by practicing high-risk procedures and earning training credit with the latest medical devices and diagnostic treatments in our industry-leading 3D mobile games. In the last five years Level Ex has exponentially grown, hiring top talent from the video games industry, the digital health ecosystem, and leading medical institutions. Our clients include top 20 pharmaceutical, biotech, and medical device companies including Baxter, Pfizer, Merck, and Medtronic, as well as leading medical associations. We're now looking for another experienced Data Engineer who, working across multiple teams, will build and refine a centralized data warehouse that is efficient, flexible, and scalable in a pioneering domain that combines mobile games data with healthcare provider data. We need a self-starter that will marshall the company’s data and surface it to business users and data scientists, and that will develop data pipelines and APIs to fuel data applications and business intelligence. Why You Should Join Us This job will be fun. This is a great opportunity for a data engineer to lead the implementation of important projects with autonomy and with the best, cutting-edge, cloud tooling. We use the best tools, and will continue to seek the best tools. Our Stack: AWS cloud data stack, with DBT, Snowflake, Prefect and Github. Currently using tableau for business intelligence. You'll be working on important and challenging projects. Some projects: re-architecting our events management system to increase flexibility and reduce latency; Building out our data warehouse for self-serve analytics and extending to new product classes; Integrating new data sources like Hubspot and JIRA into the data warehouse; Building a data monitoring service that identifies outliers and notifies business users of an anomaly event. The team is good. We have a positive, collaborative, open-minded team culture that is focused on learning, helping each other and finding long-term solutions to global problems rather than short term fixes. We're set up for a positive work-life. We're an agile data & analytics team that uses 2 weeks sprint cycles and 6 month product roadmaps to make a large impact with a great work life balance. What You’ll Be Doing with Us Work across multiple teams to develop and maintain data pipelines from different data sources - telemetry, sales, product cost, marketing, finance, etc - to fuel data applications, APIs and business intelligence tools. Architect, build and refine a cloud-native data warehouse that is scalable, efficient, and flexible, as new products, games, and features are introduced. Implement best-practices with metadata files and data models. Documenting pipeline details, changes to telemetry, and other important information. Load and structure new data sources and integrate them with reporting and operational tools. Develop automated testing to discover and correct data quality, structure and integrity issues. Evaluate and implement tools that will increase access to data and increase the number of questions that can be self-served by business partners. Lead large projects on a data & analytics roadmap. Act as a subject matter expert for the data engineering discipline and best practices. Writing and monitoring JIRA/development tickets. Who We Want to Meet Minimum of 1+ years of experience in building data pipelines using cloud technologies (like AWS, GCP, etc.), preferably using Python. Minimum of 2+ years of experience focusing on data engineering projects. Minimum of 2+ years of proficient SQL. Experience with Serverless cloud deployment. Experience with a programming language like Python, Scala or Java, preferably Python. Experience with cloud data warehouse tools like Snowflake. Excellent understanding of data modeling techniques. Experience with data orchestration tools like Prefect or Airflow. Ability to collaborate effectively and work as part of a team at a growing start-up. B.S. in Computer Science, Mathematics, Statistics, Economics, Analytics, Engineering or equivalent combination of education and experience. Bonus Points For Experience with ETL/ELT tools like dbt. Experience with AWS Services. Experience with Snowflake and, specifically Snowpipe. Experience with Prefect. Working knowledge of one or more business intelligence of tools like Tableau, Looker, Sisense, etc. Experience in data engineering for mobile game analytics and/or on medical analytics. M.S. or Ph.D. in Computer Science, Mathematics, Statistics, Economics, Analytics, Engineering or equivalent combination of education and experience. How We Make You Happy Multiple health insurance plans with 100% company-paid premiums 401(k) with generous company-paid match 100% remote for all U.S. employees Family-friendly benefits; Dental, vision, and optional pet insurance, 4 weeks of PTO, 2 weeks of company holidays, and more! Monthly snack allowance sent to your home- or choose a snack pack instead Remote-friendly events ie. board games tabletop simulator, Jackbox Games, DEI events, game jams, virtual happy hours Interested? Please send us your resume along with an optional cover letter detailing why you’re an excellent fit using the links below. We look forward to hearing from you and exploring the possibilities. Diversity Statement Level Ex is the collective sum of all our individual experiences, backgrounds, and influences and we pride ourselves in growing and learning together. We are an Equal Opportunity Employer committed to building an inclusive and diverse environment where everyone’s individuality is respected, and everyone has an Identity. Our commitment to inclusion across race, gender, age, religion, identity, and experience drives us forward every day. No Agency or Recruiter submissions will be accepted. Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job. Socials Twitter, LinkedIn, Facebook, YouTube"
Data Scientist/machine Learning Engineer,Colsh Consultants,"Monmouth Junction, NJ 08852",https://www.indeed.com/rc/clk?jk=769e533c8e36d203&fccid=f7b4fcc3fc83b5ad&vjs=3,"Our client, which is a large communications company based in Plano, TX needs to fill the contractor role very quickly. This position will define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment. This function needs to support the standardization, customization and ad-hoc data analysis, and will develop the mechanisms to ingest, analyze, validate, normalize and clean data. Implements statistical data quality procedures on new data sources, and by applying rigorous iterative data analytics, supports Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Will work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques. - 1-2 years of hands-on experience in Java, Scala/Python, Maven, Jenkins, Git, Spring, SOA/Web Services - SOAP/REST, XML/JASON, Java Thread Management/GC analysis, SQL, MongoDB, Drools, Hadoop, HDFS, Apache Hive, Apache Spark, Apache Storm PhD in Computer Science, Mathematics, Statistics, Physical Sciences"
Geospacial Data Engineer,Applied Information Sciences,"Remote in Reston, VA 20191+4 locations",https://www.indeed.com/rc/clk?jk=716a9c3844c0bbf8&fccid=edbbf93fc5210a17&vjs=3,"Intro: As a Geospacial Data Engineer, you will use cutting-edge cloud and data technologies to help global brands and federal agencies solve challenging problems through innovative technology solutions. Work on exciting projects, future-proof your skills, and grow into your dream job alongside some of the most talented, knowledgeable, and dedicated technologists in the industry. What You'll Be Doing: Work in a team using cutting edge technologies to solve challenging business problems and build solutions Apply your skills in Azure Cognitive Services, Azure PaaS, data science, data analytics, and data warehousing to pioneer Azure cloud and data services Interact directly with our client(s) to understand their needs and meet, or exceed their expectations by meeting delivery deadlines Location and Travel Details: This is a remote position with occasional travel once COVID restrictions are lifted. Profile of Success: Minimum of five years of comparable data engineering experience Deep knowledge of data ingestion strategies and understanding of the V-dimensions of data (velocity, volume, variety, veracity) Experience with Cloud Services - Azure preferred, open to AWS experience Comfortable with Microsoft SQL data technologies (SSAS/SSIS/SSRS) Programming focus – full stack development experience with python, cloud (Azure), and web front/backends. Experience preparing data and data pipelines for ML model development Experience with many of the following: AutoCAD, ArcGIS Desktop Suite, ArcGIS Server, QGIS, Google Earth Engine, GeoServer, PostgreSQL, PostGIS, MySQL, Docker, Git, OpenLayers, Leaflet, GDAL, netCDF4, Xarray, Pandas, Anaconda, Scikit-learn, SciPy, NumPy, PySpark, Plotly, Google Apps Script, Jupyter, TensorFlow, Keras, etc. Very comfortable with data, 3rd part dad sources through APIS – processing data with python, api calls. Experience with GIS tools – QGIS – Open-Source version of ARCGIS, AcrGIS, ESRI suite of tools for looking at: GIS data -geospatial data Aerial imagery– satellite imagery Machine learning Desirable Skills: Microsoft related certifications Experience with visualization tools such as Power BI or Tableau Experience with GIS tools – QGIS – Open-Source version of ARCGIS, AcrGIS, ESRI suite of tools for looking at GIS data -geospatial data Aerial imagery– satellite imagery Machine learning About AIS: AIS, Dedicated to Our People AIS employees can spend their entire career at AIS doing challenging, rewarding work and reach their desired level of achievement and responsibility. We offer the opportunity to move up, without the obligation to move out of a position where one excels. We are committed to our employee's success; however, they define it. It's our dedication to our employees that inspired our leadership to invest in our future and become partially employee-owned through an Employee Stock Ownership Program (ESOP). Our employees are our greatest strength, and we do all that we can to serve them. We invest in technology as early adopters, allowing us to create transformative and innovative solutions for our customers while exposing our team to cutting edge technology. We hire outstanding individuals who are committed to curiosity, passionate about emerging technology, and who are excited to find innovative solutions for the biggest tech challenges facing international brands and government agencies today. We Invest in Individuals Committed to Innovation AIS is seeking professionals of a certain character and level of excellence. People that we can learn from and that we can help grow to achieve their personal career goals. We are looking for: Smart people with a passion for technology Strong technical capabilities with a consultancy mindset Close involvement with local technical communities A willingness to think outside of the box to provide innovative solutions to clients Ability to solve challenging technical business problems Self-directed professionals Our Core Values Client Success Continued Learning and Technical Excellence Strong Client Relationships Citizenship and Community EEO Statement: Applied Information Sciences is an Equal Opportunity Employer and does not discriminate on the basis of race, national origin, religion, color, gender, sexual orientation, age, disability, protected veteran status or any other basis covered by law. Employment decisions are based solely on qualifications merit, and business need."
Junior Data Engineer,Huntington Bank,"Remote in Columbus, OH+2 locations",https://www.indeed.com/rc/clk?jk=44d22ba1e571221f&fccid=35685a87fca04108&vjs=3,"Description As a Junior Data Engineer you will be: Responsible for expanding and optimizing our data and data pipeline Analyze and organize raw data Build and support data systems and pipelines Evaluate business needs and objectives Experience building and optimizing ‘big data’ data pipelines & data sets Requirements: Hands on experience with big data tools: Hadoop, Spark, Kafka, etc. Hands on experience with relational SQL and NoSQL databases, including SQL, Oracle, DB2, Hive, Hbase etc. 3+ years of experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. Experience with data pipeline and any workflow management tools: Zena, control M, Oozie, Airflow, etc. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Working knowledge of DevOps pipeline using Jenkins, Urban code, Azure devops etc. Working knowledge of source code management using Git, Gitlab etc. Able to perform analysis and review of existing or proposed system features and integration, security, scalability and performance requirements with users, product teams, business analysts, architects and team members Develop systems and software integration patterns across a diverse IT ecosystem. These patterns should align to high level IT goals and business initiatives Provide subject matter expert advice on system design issues and contribute to ongoing planning and development of system enhancements Identify and specify technical / functional requirements, resources and required that may be needed to meet user requirements Provide guidance and reinforcement around established engineering best practices Participate in product planning and implementation Serve as an escalation point in product level support for ongoing maintenance and production issues Experience with AWS cloud services like Glue, Athena, EC2, RDS, Redshift etc. #LI-Remote Workplace Type: EEO/AA Employer/Minority/Female/Disability/Veteran/Sexual Orientation/Gender Identity Tobacco-Free Hiring Practice: Visit Huntington's Career Web Site for more details. Agency Statement: Huntington does not accept solicitation from Third Party Recruiters for any position"
Data Analytics Engineer,GS1 US,"Ewing, NJ 08628",https://www.indeed.com/rc/clk?jk=36d539731280ed83&fccid=fb827e171c1a8a6a&vjs=3,"Are you ready for a change? At GS1 US, employees at every level play a vital role and provide a meaningful voice on issues that affect consumers across the country. We are a small company with a world-class culture. We make a huge impact on the way the world does business. Our nimble Analytics and Reporting team transform disparate data sets into actionable insights for our product owners and other internal customers. As a Data Engineer, you will work closely with product management and internal customers to define reporting requirements and design and implement solutions that provide insights on business performance that impact supply chain trends. The role will develop certified data sets and help move to predictive analytics, creating enormous value in anticipating member needs and developing new data offerings. Who you are: You can communicate insights through creative and intuitive visualizations that help monitor business performance and identify organizational improvement opportunities. You have been a part of a dynamic team that has used a unique combination of technical skills, business acumen, and strong communication and interpersonal skills to provide insights for internal business users. You have designed, built, and maintained scalable data repositories using Azure Synapse Analytics, Data Lake, and Data Factory. You are passionate about staying up to date on evolving cloud services and technologies. What you will do: With your keen eye for building and optimizing data systems, you will contribute to the full-stack development of a complete enterprise reporting platform. From data extraction and curation to data visualizations, you will directly impact our operations and drive change as we modernize our data platform using the Azure Synapse toolset. Design, develop, and implement data pipelines, flows, and ELT processes as required for analytics. Build and deliver visualizations and reports using Microsoft Power BI and Azure data services Are you ready to be part of a team that believes the identification of everything makes anything possible? Apply today – we can’t wait to hear your story. GS1 US is an Equal Opportunity Employer - All qualified applications will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, gender identity, or national origin GS1 US is not accepting unsolicited resumes from search or staffing firms. All resumes submitted by search or staffing firms to any employee at GS1 US via email, internet or directly without a valid written search agreement will be deemed the sole property of GS1 US, and no fee will be paid in the event a candidate is hired by GS1 US."
"Data Engineer, Mid",Advantage SCI,"Fort Belvoir, VA 22060+1 location",https://www.indeed.com/rc/clk?jk=648d0891eb2b6df5&fccid=79418d497db53e12&vjs=3,"Job Description: Position: Data Engineer, Mid Reports To: The Customer and Program Manager Clearance Type: Active TS/SCI with ability to obtain CI polygraph Work Location: Fort Belvoir, VA Job Description: Advantage SCI is seeking a Data Engineer, Mid to be considered for employment. Designs, implements, and operates data management systems for intelligence needs. Designs how data will be stored, accessed, used, integrated, and managed by different data regimes and digital systems. Works with data users to determine, create, and populate optimal data architectures, structures, and systems. Plans, designs, and optimizes data throughput and query performance. Participates in the employment of backend database technologies (e.g. SQL, NoSQL, HPC, etc.), their configuration and utilization, and the optimization of the full data pipeline infrastructure (eg. NiFi, Streamsets, Apache Airflow, etc.) to support the actual content, volume, ETL, and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness. Required Experience: Active TS/SCI with ability to obtain CI polygraph Demonstrates comprehensive mission knowledge and skills that affirms completion of all developmental training and experiences for the labor category. Demonstrates ability to communicate understanding from information that may be incomplete, indirect, highly complex, seemingly unrelated, and/or technically advanced. Demonstrates ability to structure analysis based on trends in reporting and a range of analytic perspectives from other analysts, organizations, and intelligence disciplines. Demonstrates ability to work independently with minimal oversight and direction. - Demonstrates ability to collaborate and work with other IC members on information sharing, driving collection, and addressing analytic disputes and conflict resolution. Demonstrates ability to develop concise, insightful, and comprehensive products for defense intelligence. Demonstrates ability to lead teams in researching multifaceted or critical problems. Provides guidance in selecting, designing, and applying analytic methodologies. Uses argument evaluation and validated analytic methodologies to challenge differing perspectives. Desired Experience: Minimum 8 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years. Required Experience: 7 years demonstrated experience in an intelligence discipline working in the DoD or IC within the last 2 years. Intermediate Experience using Microsoft SharePoint 2013 Required Education: Associates degree with 7 years experience in an intelligence discipline OR High School Diploma with 9 years experience in an intelligence discipline Working Conditions: Able to sit and work at a computer keyboard for extended periods of time Able to stoop, kneel, bend at the waist and reach daily Able to lift up to 35 pounds occasionally. Noise level: Low to moderate Advantage SCI, LLC is an Equal Opportunity Employer EXECUTIVE ORDER 11246 Prohibits discrimination against any employee or applicant on the basis of race, sex, color, religion, or national origin and requires affirmative action to ensure that applicants are employed, and employees treated, without regard to race, sex, color, genetic information, religion, or national origin. (Enforcement Agency: U.S. Department of Labor, Office of Federal Contract Compliance Programs) From: Advantage SCI"
Data & Tools Engineer 3 [HYBRID],Southern California Edison,"Pomona, CA 91767",https://www.indeed.com/rc/clk?jk=02304c78dec7d7e8&fccid=699f2e990e95e8eb&vjs=3,"Job Description Join the Clean Energy Revolution Become a Data & Tools Engineer 3 at Southern California Edison and build a better tomorrow. In this position, you will be working in the Data & Tools team under the Integrated System Planning (ISP) department within SCE’s Asset Strategy and Planning (ASP) organization. In this role, you will be working on developing, deploying, and improving Grid and Distributed Energy Resource (DER) Solutions. You will be directly supporting various System Planning efforts through data and tools and contribute to enabling planning capabilities addressing climate change, decarbonization and regulatory drivers. The Data & Tools Engineer 3 will develop vision, strategy and translate technical specifications into business requirements for the Grid and DER solutions. The role will test technical solutions, meet Engineering requirements and standards as well as perform engineering assessments to address process & technology gaps. Are you ready to take on the challenge to help us build the future? A day in the life - Get ready to think big, work smart and shine bright! Lead the development of vision, strategy and roadmap for the Grid and DER software solutions (i.e., Grid Connectivity Model, DER Data Manager) Interpret technical requirements and standards into business requirements for IT and verify solutions meet Engineering requirements Perform Business Product Owner (BPO) functions for various Grid and DER software solutions (i.e., use case development, criteria sign off, testing and stakeholder coordination) Provide Engineering Subject Matter Expertise as it pertains to Grid, System Planning data, studies, and reports Perform Engineering assessments and monthly system planning processes Support the development of Regulatory Tariffs and Standard requirements Lead Regulatory Rule 21 and DER Data Requests Perform root cause analysis of DER and Load Profile Data Quality issues and lead remediation efforts Develop, enhance, and implement forecasting models for PV profiles Qualifications The essentials Bachelor’s degree in electrical engineering or related discipline Five or more combined years of engineering experience, such as Field Engineering or System Planning or engineering support or experience related to tool support or any other experience related to supporting engineering solutions The preferred Experience with regulatory requirements for Generation and Load Tariffs Experience with power system engineering analysis (e.g., power flow, short circuit duty) including knowledge of applicable regulations, standards, codes and analysis software such as CYME, PSLF, CAPE Experience working with T&D tools such as Circuit eMaps and SCEGeoView Experience with coding/scripting to automate engineering processes and data collection (i.e., SQL, Python, VBA) Ability to explain complex technical concepts and deliver technical presentations to both a technical and non-technical audience, including external settings Work effectively in areas where processes are not clearly defined, self-starter Influence others and maintain positive working relationships Stay current with relevant technology and innovation You should know … Work Mode: When a return-to-office date has been determined, this position’s work mode is hybrid. The employee will report to an SCE facility for a set number of days with the option to work remotely on the remaining days. Unless otherwise noted, employees are required to reside in the state of California. Further details of this work mode will be discussed at the interview stage. Visit our Candidate Resource page to get meaningful information related to benefits, perks, resources, testing information, and hiring process, and more! Testing This position requires testing and applicants who are identified to continue through the selection process will be invited to test via email. Please access our Information Guides to reference test(s): Edison Individual Contributor Workstyles (Test 8203). Candidates who have previously passed this assessment, in some cases, may not need to retest again for this position. About Southern California Edison The people at SCE don't just keep the lights on. Our mission is so much bigger. We’re fueling the kind of innovation that’s changing an entire industry, and quite possibly the planet. Join us and create a future with cleaner energy, while providing our customers with the safety and reliability they demand. At SCE, you’ll have a chance to grow personally and professionally, making a real impact in Southern California and around the world. At SCE, we celebrate our differences. We are a proud Equal Opportunity Employer and will not discriminate based on race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status or any other protected status. We are committed to ensuring that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodations at (833) 343-0727. #LI-SG1"
Data Engineer,Atlassian,"Austin, TX 78701 (Downtown area)+2 locations",https://www.indeed.com/rc/clk?jk=271f3798b92760c6&fccid=e6d4ba9e2cfe7902&vjs=3,"Working at Atlassian Atlassian can hire people in any country where we have a legal entity. Assuming you have eligible working rights and a sufficient time zone overlap with your team, you can choose to work remotely or return to an office as they reopen (unless it’s necessary for your role to be performed in the office). Interviews and onboarding are conducted virtually, a part of being a distributed-first company. Atlassian is looking for a Data Engineer to join our Go-To Market Data Engineering (GTM-DE) team which is responsible for building our data lake, maintaining our big data pipelines / services and facilitating the movement of billions of messages each day. We work directly with the business stakeholders and plenty of platform and engineering teams to enable growth and retention strategies at Atlassian. We are looking for an open-minded, structured thinker who is passionate about building services that scale. On a typical day you will help our stakeholder teams ingest data faster into our data lake, you'll find ways to make our data pipelines more efficient, or even come up ideas to help instigate self-serve data engineering within the company. Then you will move on to building micro-services, architecting, designing, and enabling self serve capabilities at scale to help Atlassian grow. You'll get the opportunity to work on a AWS based data lake backed by the full suite of open source projects such as Spark and Airflow. We are a team with little legacy in our tech stack and as a result you'll spend less time paying off technical debt and more time identifying ways to make our platform better and improve our users experience. More about you: As a data engineer in the GTM-DE team, you will have the opportunity to apply your strong technical experience building highly reliable services on managing and orchestrating a multi-petabyte scale data lake. You enjoy working in a fast paced environment and you are able to take vague requirements and transform them into solid solutions. You are motivated by solving challenging problems, where creativity is as crucial as your ability to write code and test cases. On your first day, we'll expect you to have: At least 3 years of professional experience as a software engineer or data engineer A BS in Computer Science or equivalent experience Strong programming skills (some combination of Python, Java, and Scala preferred) Experience writing SQL, structuring data, and data storage practices Experience with data modeling Knowledge of data warehousing concepts Experienced building data pipelines and microservices Experience with Spark, Hive, Airflow and other streaming technologies to process incredible volumes of streaming data A willingness to accept failure, learn and try again An open mind to try solutions that may seem crazy at first Experience working on Amazon Web Services (in particular using EMR, Kinesis, RDS, S3, SQS and the like) It's preferred, but not required, that you have: Experience building self-service tooling and platforms Built and designed Kappa architecture platforms A passion for building and running continuous integration pipelines. Built pipelines using Databricks and well versed with their API's Contributed to open source projects (Ex: Operators in Airflow) Our perks & benefits To support you at work and play, our perks and benefits include ample time off, an annual education budget, paid volunteer days, and so much more. About Atlassian The world’s best teams work better together with Atlassian. From medicine and space travel, to disaster response and pizza deliveries, Atlassian software products help teams all over the planet. At Atlassian, we're motivated by a common goal: to unleash the potential of every team. We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines. To learn more about our culture and hiring process, explore our Candidate Resource Hub."
Data Analyst/Data Engineer,RakirS Systems,"Henderson, NV 89052 (Westgate area)",https://www.indeed.com/rc/clk?jk=e6932977ab445965&fccid=dd616958bd9ddc12&vjs=3,"Data Analyst/Data Engineer Job ID: 1362 Job Posted: 11/16/2020 Responsibilities: Conceptualize, build and maintain pre-aggregated datasets, reports and other analytical products Collaborate with business stakeholders to understand business problems and build/automate analytics products such as: Well architected (re-usable, scalable) aggregate tables that meet current and future reporting needs in the EDW Intuitive and actionable dashboards and data visualizations for data-drive decision making using presentation layer BI tools like Tableau, SSRS etc., Develop a deep understanding of the Snowflake EDW, dimensional models and ETL business logic Become a subject matter expert in TFG’s upstream source systems over time Translate data and insights into a meaningful story to drive strategy, action, and decision-making at an executive level Work closely with the Data Platforms team to determine the best strategy for process scheduling and follow best practices set by the team Required Skills: Expert SQL skills, particularly in an analytics / reporting capacity. Significant experience creating and maintaining DW and reporting processes Advanced Data modeling skills (hands-on experience + theoretical understanding) Implementing star-schemas/snowflake-schemas Slowly changing dimensions Advanced SQL skills required Primary/foreign keys, indexes (when to use them) Joins and unions Tables and Views (How are they different? Pros and cons of using) Be able to describe differences between DML/DDL statements Window functions Scalar and aggregate functions Requirements: Master's degree or equivalent in Computer Science, Engineering, Information Technology or Related field. How to Apply: Mail resume to Rakirs Systems LLC, Attn: HR, Work Hours: 9:00 a.m. to 5:00 p.m. HR@rakirssystems.com"
Snowflake Data Engineer,visualbi,"Remote in Plano, TX",https://www.indeed.com/rc/clk?jk=01136083cf5f54e1&fccid=287e7c051394fbcc&vjs=3,"Description Visual BI is one of the nation’s fastest growing boutique firms focusing exclusively on Business Intelligence & Analytics. Headquartered in Plano, Texas, Visual BI has won recognition from customers for high-touch engagements driven by its team of platinum-level consultants, agile delivery model and innovative solutions and products. Visual BI offerings cover end-to-end BI services, industry and domain-specific solutions, and advanced visualization controls and products. Activities Analysis, design, and development of traditional data warehouse and business intelligence solutions Work with customers to understand and execute on their requirements Build data flows for data warehousing Proficient with Git and CI/CD best practices Experience designing highly scalable ETL processes with complex data transformations, data formats including error handling and monitoring. Location remote, can be anywhere in the US. Requirements 6+ years of experience in data warehousing projects Deep experience in traditional Data Warehousing & Cloud data warehousing Mastery of SQL, especially within cloud-based data warehouses like Snowflake, Google BigQuery, and Amazon Redshift Expertise with python Experience on AWS, Azure or Snowflake with data architecture, design, analytics and deployment Understanding of the competitive ETL space in cloud data warehousing Working knowledge of software engineering best practices Experience with GIT Strong communicator Benefits Excellent Pay Excellent Medical, Dental, Vision, Life, AD&D, Dependent Life, Short Term and Long Term Disability Benefits 401(k) plan administered through employee fiduciary Generous communication allowance Apply here: https://apply.workable.com/visualbi/j/59B72B5E81/"
Data Engineer,Horizon,"Deerfield, IL 60015",https://www.indeed.com/rc/clk?jk=d1f73081a76552bd&fccid=f094d29b1b48c0f4&vjs=3,"Working at Horizon is more than a job – it’s personal. For us, success is measured by the numbers that matter most – the number of lives we touch, the number we change and those we work tirelessly to help save. We’re a team of agile, out-of-the-box thinkers who are inspired to do more because we know we’re a part of something bigger. We strive to build meaningful careers at a company whose values we share because when we live up to our potential, we help others live up to theirs. Position Summary: The Data Engineer will help our analytics team provide the best possible insights to our business partners across the organization. They will be responsible for expanding and optimizing our data pipeline and pipeline architecture. As new analytics initiatives begin, the Data Engineer will help to create an ideal architecture for capturing, storing, and transforming the necessary data. This role is ideally suited for an intellectually curious and forward-thinking candidate with a strong technical background. The right candidate will be self-directed and able to handle multiple projects and deadlines. The Data Engineer should be enthusiastic about learning new technologies and applying them solve data problems efficiently. Responsibilities: Develop a deep understanding of available data sources, including capture methodologies and data limitations Create automated data pipelines and ETL procedures to capture and curate data from many sources Design and optimize data architecture to best answer business questions presented to the analytics team Advise on how new technologies can improve current data processes Support the data science and business insights teams with data queries and investigations on an ad-hoc basis Qualifications and Skills Required: BS in Software Engineering, Computer Science, Information Technology, or other technical discipline Master’s degree in a related field preferred but not required 1-4 years of related experience required Extensive experience in modern data storage technologies, including relational SQL and NoSQL databases, graph databases, and cloud storage Advanced programming knowledge related to data manipulation, extraction, and automation – python and Linux background strongly preferred Ability to manage multiple projects in an ambiguous environment with shifting priorities and time-pressure Ability to translate business questions into clearly documented data manipulation and ETL procedures Excellent problem solving capabilities Strong communication skills (verbal and written); proven ability to work cross functionally and liaise across a complex set of stakeholders Experience generating data, including from APIs, web scraping, or behavior logging Expert at: Microsoft Office (Word, Excel, PowerPoint, Outlook) Horizon Core Values & Competencies: Growth Manages Ambiguity Strategic Mindset Demonstrates Self-awareness Cultivates Innovation Develops Talent Accountability Drives Results Ensures Accountability Decision Quality Transparency Courage Collaboration Instills Trust Horizon requires all U.S. employees to be fully vaccinated, as a condition of employment, with either Pfizer (fully approved by the U.S. Food and Drug Administration), Moderna or Johnson & Johnson (currently granted emergency-use authorization by the FDA). “Fully vaccinated” is defined as two weeks after your final dose of the Pfizer, Moderna, or Johnson & Johnson vaccine. Horizon will provide medical and religious accommodations as required by law. Horizon Therapeutics plc does not discriminate on the basis of race, color, religion, gender, sexual orientation, national origin, age, disability, veteran status, or any other characteristic protected by law. It is our intention that all qualified applications are given equal opportunity and that selection decisions be based on job-related factors. Any individual, who, because of a disability, needs accommodation or assistance in completing this application or at any time during the application process, should contact the Human Resources Department."
Data Engineer,Sapient Industries,"Remote in Philadelphia, PA 19103",https://www.indeed.com/rc/clk?jk=45341abb4cf5e208&fccid=f72f53be78a80693&vjs=3,"Data Engineer Sapient is ushering in a new paradigm of building intelligence by building the first-ever building operating system. We ingest, analyze and convert billions of data points into meaningful insights through AI, machine learning, and always-on optimization. Insights that enable enterprises to fight climate change and transform the way their spaces are planned and run. From the tallest skyscrapers to the widest portfolio of buildings spanning the globe. From how space is used to how it is physically constructed. From driving enterprise sustainability goals to bottom-line profits. From creating engaged employees to satisfied shareholders. The world's largest enterprises are joining us on this journey because they, like us, care about making substantial, lasting positive changes to the built world and our planet. Join us, and together we will accomplish incredible, previously unimagined things. For a better future. Role Overview Sapient is looking for a Data Engineer. This role requires an experienced, highly intelligent, creative, and strategic person who can drive and manage positive change across the organization. The ideal candidate will be able to design, build, and deploy complex data pipelines in cloud environments given requirements from the business. You should be able to understand how to work with time-series data and how to apply functions to time-series data. You will be responsible for establishing metrics around data quality, reporting quality, and how to improve the speed of analysis. Understand complex SQL queries involving windowing functions and how to create chart points in SQL such as cumulative value over time. The ideal candidate will own the performance of our data pipelines. You'll work within a team focused on building cutting-edge data products, services, and APIs. Requirements 3+ years of hands-on data engineering in petabyte-scale data systems. Understand and balance the roles of Innovation, GSD, Security, and Automation. Ability to collaborate and debate ideas, with the outcome of finding the best solution we can quickly. You are fearless, aggressive, and creative in solving problems including automating human workflows and tasks. Take ownership and improve upon our project management process. Experience with big data systems including Spark, KubeFlow, BigQuery, Athena, Postgres, Cockroach, etc. Minor experience with systems automation and configuration systems such as Kubernetes, Lambdas, Cloud Functions, Airflow, Etc. Understanding of time-series data and how to report events and occurrences on that data correctly. Programming languages like Go, Python, or Scala You will want to work for us if you Help build a multi-billion dollar company while fighting climate change and building the next generation of intelligent buildings. Care about the planet and how to save it through completely novel ideas at scale. Like to move fast - you thrive in a fast-paced environment of innovation and cross-team collaboration. Love to roll up your sleeves and get things done. Want to deliver new products and delight customers. Benefits/Perks include, but are not limited to: Flexible, remote work arrangements Flexible Paid Time Off (PTO) 14 Paid Holidays Comprehensive and affordable health benefits 401k Plan Pet Insurance Generous Paid Parental Leave Team building and volunteering events Monthly internet stipend Employee Referral Bonus program Unlimited professional growth potential Disclaimer Sapient is an Equal Opportunity Employer and strictly prohibits discrimination of any kind. We believe that great ideas can come from anywhere. We are committed to building the best team possible and all employment decisions are based on business needs, job requirements, and individual potential and qualifications, without regard to race, color, age, religion, socioeconomic status, orientation, gender identity, national origin, or disability. The Sapient team is diverse — we welcome and learn from different individual experiences and points of view that our teammates bring to the table. We're excited to have you inspire us with yours!"
Data Engineer III,Teladoc Health,"Hybrid remote in Quincy, MA+2 locations",https://www.indeed.com/rc/clk?jk=df91efe433c05ea7&fccid=88f5d9a70576ec2a&vjs=3,"The Opportunity Teladoc Health is transforming how people access and experience healthcare. Recognized as the world leader in virtual care, we are partnering with over a thousand clients to serve millions! of people around the globe every day. Teladoc Health offers a whole person virtual care platform that empowers all people everywhere to live their healthiest lives by transforming the healthcare experience, from acute and primary care to chronic care, mental health, and specialty care. Our team of data engineers aggregate and transform substantial amounts of health data and information to support actionable, personalized, and timely health signals for our members. This approach delivers better clinical and financial outcomes while creating a different and better healthcare experience for people everywhere. The applicant should have a strong interest in the interface between real-time and reporting systems, pulling data from multiple sources into central data storage, and collaborating with internal teams to help provide for their data needs. About You You flourish in a fast paced and highly collaborative team environment. You are a quick learner and have the expert ability to prioritize tasks efficiently, while delivering high quality work. You understand that solutions provided by a Data Engineer, support in empowering an organization’s business in decision making. You will be part of a great working atmosphere, performing complex work in a collaborative team of amazing people, with forward-thinking managers. You will have the opportunity to make an impact. Responsibilities Data is significant at Teladoc and our data engineers design and develop data pipelines to integrate data across disparate systems and create tools and data sets to support data science Work with Python, Spark SQL, Scala, TensorFlow, Keras, SKL (or Scala/DL4J) to build production-grade machine learning (ML) pipelines and tools Perform continuous integration to ensure that every step of a data pipeline is testable and automated Collaborate closely with Teladoc Health’s ML experts, Data Scientists, Product Managers, and clinical researchers to define, analyze, and provide data that contributes to our mission of total health for our members Document code, provide progress reports, and perform code review and peer feedback Track milestones, activities and inter-dependencies across projects and tasks, with frequent status updates to stakeholders Continuously evaluate and identify improvements in the system processes and architecture Assist in maintaining data quality and fidelity in production systems Participate in Agile planning around data feature requests and advocate for the best data engineering projects in priority planning. Candidate Profile BS degree in Engineering, Computer Science, or a related field 5+ years’ experience in software development/engineering 5+ years’ experience in a data engineering role Strong experience with big data technologies, and skills in data processing using Spark Expertise in creating and maintaining production data pipelines using Airflow Strong SQL development experience (Postgres/MySQL/SQL Server/Oracle) Expertise in Python(preferred), Scala, or Java 3+ years of experience working in Azure cloud Experience in performance tuning and query optimization Experience in Cloud data engineering in Azure stack. Azure certification is a plus. Tool based data pipeline development experience is desirable (Talend/Informatica/ IBM Datastage). Streaming data flow experience is desirable (Kafka). Experience in deploying production pipelines in CI/CD environment Excellent communication skills, supporting recommendations, design ideas, and analysis to team and stake holders Experience in leading and guiding other data engineers The base salary range for this position is $125,000 - $140,000. In addition to a base salary, this position is eligible for performance bonus, RSU’s, and benefits (subject to eligibility requirements) listed here: Teladoc Health Benefits 2022. Total compensation is based on several factors including, but not limited to, type of position, location, education level, work experience, and certifications. This information is applicable for all full-time positions. People and culture are Teladoc Health’s greatest and most valued assets! We’ve built a culture we are proud of that reflects our values of diversity and inclusion where everyone’s voice is equally important. #LI-RK1 #LI-Hybrid Why Join Teladoc Health? A New Category in Healthcare: Teladoc Health is transforming the healthcare experience and empowering people everywhere to live healthier lives. Our Work Truly Matters: Recognized as the world leader in whole-person virtual care, Teladoc Health uses proprietary health signals and personalized interactions to drive better health outcomes across the full continuum of care, at every stage in a person’s health journey. Make an Impact: In more than 175 countries and ranked Best in KLAS for Virtual Care Platforms in 2020, Teladoc Health leverages more than a decade of expertise and data-driven insights to meet the growing virtual care needs of consumers and healthcare professionals. Focus on PEOPLE: Teladoc Health has been recognized as a top employer by numerous media and professional organizations. Talented, passionate individuals make the difference, in this fast-moving, collaborative, and inspiring environment. Diversity and Inclusion: At Teladoc Health we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position. Growth and Innovation: We’ve already made healthcare yet remain on the threshold of very big things. Come grow with us and support our mission to make a tangible difference in the lives of our Members. As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy."
Senior Data Engineer,AppFolio,+13 locationsRemote,https://www.indeed.com/rc/clk?jk=f9890aa09913fd66&fccid=1a5bf8d2e39d8e2e&vjs=3,"Hi, We’re AppFolio. We’re innovators, changemakers, and collaborators. We’re more than just a software company — we’re a cloud-based Software company that creates products to make our customers’ lives easier. We’re revolutionizing the way people do business, and we want your ideas, your enthusiasm, and your passion to help us keep on innovating. We love where we work, and you can, too. Whom we are looking for: We are hiring a Senior or Staff Data Engineer to contribute to our growing Data Operations team. We work collaboratively to set the technical direction for our Data Platform, developing easy-to-use solutions for our customers. You’ll get the opportunity to work to develop, design, and operate all aspects of the Data Platform infrastructure. This is an ideal opportunity for someone who has a passion for building a leading-edge data platform and is driven to work as an individual contributor and a great team player. We foster an environment that empowers small teams to collaboratively set the technical direction of our solutions. Responsibilities: Design, build, deploy, and operate next generation data infrastructure. Develop and promote Apache Kafka best practices in the Data platform. Collaborate with engineers and analysts to ensure that our data infrastructure meets the needs of our most data-intensive customers Develop techniques for monitoring the correctness and reliability of our data infrastructure Leverage agile practices, encourage collaboration, prioritization, and urgency to develop at a rapid pace Research, share, and recommend new technologies and trends You know you’re the right fit if… You've worked with Apache Kafka in production You have excellent SQL skills and have worked with change data capture systems in production You have experience working with Infrastructure as Code, configuration management, and monitoring tools. Our team uses Terraform, Ansible, and Datadog. You have some experience working with languages like Python or Ruby. You care about work-life balance and want your company to care about it too; you'll put in the extra hour when needed but won't let it become a habit. You want to work with a high degree of autonomy, while at the same time working on initiatives of high importance to the company. Additional Skills and Knowledge: Experience with Confluent, Kafka Connect, Kafka Streams or KSQLDB is desirable Experience with CDC (change data capture) systems in general, or Debezium in particular, is highly desirable. Experience with clickstream tracking technology in general, or Snowplow in particular, is desirable. Experience with data warehouse technology is desirable, particularly with Snowflake. Experience in visualization tools like tableau Experience with containers and container orchestration tools. Docker and Kubernetes experience in particular is desirable. Light data science skills for analyzing data and communicating with ML engineers a plus. Nice to Have: Bachelors in Computer Science or other quantitative fields. Experience working across all levels of the development stack Experience with AWS If you are interested in creating exceptional SaaS products, and contributing to a successful company, apply today! Our Story AppFolio (NASDAQ: APPF) was founded in 2006 with the mission to revolutionize vertical industry businesses by providing great software and service. Our easy-to-use, cloud-based software helps our customers more effectively market, manage, and grow their businesses. Our software solutions exist in the real estate vertical, including AppFolio Property Manager and AppFolio Investment Management. To find out more about what AppFolio has to offer, check out appfolioinc.com/careers. #LI-EB1"
Data Engineer (Hybrid Schedule),MAPFRE,"Webster, MA 01570+1 location",https://www.indeed.com/rc/clk?jk=ab0789a6ae65c202&fccid=9ff30236c910acd3&vjs=3,"Design, implement and maintain a unified data repository with the ability to process and store large amounts of data from unrelated sources. · Design and build the ingestion processes for several formats (files, DBs, social nets …) and data types (structured and unstructured) using the most appropriate techniques (batch, streaming) in each case. · Define an appropriate model for the right organization and relationship between data, optimized for fast and scalable queries. · Develop and maintain the data maps and their relationships. · Design, develop and maintain a sure APIs layer that allows the external access for reading and writing in the data repository. · Implement scalable, flexible and high performance data pipelines to support analytics activities and the creation of consolidated data sources for business self-service dashboards and Advanced Analytics · In collaboration with the Data Analytics & Reporting profiles, for further data analysis and exploitation, implement the processes for the adequate data enrichment and transformation. · In collaboration with Data Governance profiles implement the quality rules and data governance (dictionary, metadata, traceability, …) · Communicate the results effectively and propose improvements and actions based on the obtained results. · Generate associated technical documentation. · Required follow-up reports generation. Advanced knowledge and experience with Python, Scala, HDFS, Hive, Spark. Knowledge, Skills and Abilities: Bachelor’s Degree with 8+ years of experience. Database architectures Hadoop-based technologies (MapReduce, Hive…) Data modeling tools, ETL tools (e.g. Informatica Power Center) Computer code: Python, C/C++ Java, Perl… SQL technologies, NoSQL technologies. Artificial Intelligence, Machine learning and Deep Learning: Understanding of algorithms to work with Data Scientists UNIX, Linux, Solaris and MS Windows Multidimensional data modeling If you require an accommodation for a disability so that you may participate in the selection process, you are encouraged to contact the MAPFRE Insurance Talent Acquisition team at talentacquisition@mapfreusa.com. We are proud to be an equal opportunity employer."
Data Engineer,BAXTER,"Deerfield, IL 60015+1 location",https://www.indeed.com/rc/clk?jk=234128d0bf237dac&fccid=a108770a4ae3a921&vjs=3,"This is where you save and sustain lives At Baxter, we are deeply connected by our mission. No matter your role at Baxter, your work makes a positive impact on people around the world. You’ll feel a sense of purpose throughout the organization, as we know our work improves outcomes for millions of patients. Baxter’s products and therapies are found in almost every hospital worldwide, in clinics and in the home. For over 85 years, we have pioneered significant medical innovations that transform healthcare. Together, we create a place where we are happy, successful and inspire each other. This is where you can do your best work. Join us at the intersection of saving and sustaining lives— where your purpose accelerates our mission. Summary: Perform development work and technical support related to our data transformation and ETL jobs in support of a global data warehouse. Can communicate results with internal customers. Requires the ability to work independently, as well as in collaboration with a variety of customers and other technical authorities. What you'll be doing Development of new ETL/data transformation jobs, using PySpark and IBM DataStage in AWS. Improvement and support on existing transformation jobs. Can explain technical solutions and resolutions with internal customers and communicate feedback to the ETL team. Perform technical code reviews for peers moving code into production. Perform and review integration testing before production migrations. Provide high level of technical support, and perform root cause analysis for problems experienced within area of functional responsibility. What you'll bring 5+ years of ETL experience. Experience with core Python programming for data transformation. Intermediate-level PySpark skills. Can read, understand and debug existing code and write simple PySpark code from scratch. Strong knowledge of SQL fundamentals, understanding of subqueries, can tune queries with execution hints to improve performance. IBM DataStage experience preferred. Able to write SQL code sufficient for most business requirements for pulling data from sources, applying rules to the data, and stocking target data Experienced in solving ETL jobs and addressing production issues like performance tuning, reject handling, and ad-hoc reloads. Proficient in developing optimization strategies for ETL processes. Basic AWS technical support skills. Has ability to log in, find existing jobs and check run status and logs Will lead jobs via Control-M Can create clear and concise documentation and communications. Can document technical specs from business communications. Ability to coordinate and passionately follow up on incidents and problems, perform diagnosis, and provide resolution to minimize service interruption Ability to prioritize and work on multiple tasks simultaneously Effective in multi-functional and global environments to lead multiple tasks and assignments. Experienced in analyzing business requirements, defining the granularity, source to target mapping of the data elements, and full technical specification. Understands data dependencies and how to schedule jobs in Control-M. Knowledgeable in working at the command line in various flavors of UNIX, with basic understanding of shell scripting in bash and korn shell. Education and/or Experience Bachelors of Science in computer science preferred. 5+ years of ETL and SQL experience 3+ years of python and PySpark experience 3+ years of AWS and unix experience 2+ years of IBM DataStage experience Preferred certifications: AWS Certified Cloud Practitioner (amazon.com) Certified DataStage Professional Python and PySpark certifications The successful candidate for this job may be required to verify that he or she has been vaccinated against COVID-19, subject to reasonable accommodations for individuals with medical conditions or religious beliefs that prevent vaccination, and in accordance with applicable law. Equal Employment Opportunity Baxter is an equal opportunity employer. Baxter evaluates qualified applicants without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity or expression, protected veteran status, disability/handicap status or any other legally protected characteristic. EEO is the Law EEO is the law - Poster Supplement Pay Transparency Policy Reasonable Accommodations Baxter is committed to working with and providing reasonable accommodations to individuals with disabilities globally. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please click on the link here and let us know the nature of your request along with your contact information. Recruitment Fraud Notice Baxter has discovered incidents of employment scams, where fraudulent parties pose as Baxter employees, recruiters, or other agents, and engage with online job seekers in an attempt to steal personal and/or financial information. To learn how you can protect yourself, review our Recruitment Fraud Notice. 066002"
